<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="MLRF: Lecture 05" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Lecture 05" /><meta property="og:description" content="Lecture 05" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/mlrf_fith_course/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/mlrf_fith_course/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-18T10:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="MLRF: Lecture 05" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-10-03T16:45:54+02:00","datePublished":"2021-06-18T10:00:00+02:00","description":"Lecture 05","headline":"MLRF: Lecture 05","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/mlrf_fith_course/"},"url":"https://lemasyma.github.io/cours/posts/mlrf_fith_course/"}</script><title>MLRF: Lecture 05 | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>MLRF: Lecture 05</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>MLRF: Lecture 05</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-06-18 10:00:00 +0200" data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 18, 2021, 10:00 AM +0200" >Jun 18, 2021</em> </span> <span> Updated <em class="timeago" date="2021-10-03 16:45:54 +0200 " data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 3, 2021, 4:45 PM +0200" >Oct 3, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1719 words"> <em>9 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/Hy2LfRFju">note Hackmd</a></p><h1 id="agenda">Agenda</h1><ol><li>Introduction<li>Image classification overview<li>Some classifiers - part 1<li>Classifier evaluation</ol><h1 id="summary-of-last-lecture">Summary of last lecture</h1><p>Content-based image retrieval</p><ul><li>2 strategies: keep all local descriptors for all images vs <strong>1 descriptor per image</strong><li>Bag of Visual Words pipeline<ul><li>Focus on encoding</ul></ul><p>Evaluation of image retrieval systems</p><ul><li>Precision<li>Recall<li>F-Measure<li>mAP</ul><p>Texture descriptors (on les a pas du tout vu)</p><ul><li>What is a texture ?<li>Fast and classic approaches<li>Descripteurs a l’ancienne</ul><h1 id="practice-session-4-take-home-messages">Practice session 4: Take home messages</h1><p>BoVW</p><ul><li>Usually requires some <strong>preprocessing</strong> of the descriptors: centering, rotation/axes permutation, dimensionality reduction…<li>Is based on a <strong>quantization step</strong> (assign descriptors to clusters)<li>Is <strong>just a histogram</strong>, like the color histogram of sessino 2<li>We can compute <strong>more advanced statistics</strong> to get better results (VLAD, FVs)</ul><div class="alert alert-warning" role="alert"><p><strong>Best practices:</strong></p><ul><li>Test arrays shapes and types as soon as possible<li>Make a small change, test, fix, tes, validate, repeat<li>Get a complete, basic pipeline ASAP and improve it until time is over</ul></div><h1 id="next-practice-session">Next practice session</h1><p>Implement a simple <strong>image classifier</strong>:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/JRTgDIl.png" alt="" /></p><div class="alert alert-danger" role="alert"><p><strong>Will be graded</strong></p></div><h2 id="steps">Steps<a href="#steps"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>Load resources<li>Train a BoVW model<li>Split the dataset into training and validation sets<li>Compute the BoVW descriptor for each image<ul><li>We will make a small change here (sqrt + L2-norm)</ul><li>Prepare training structures<li>Train a classifier and evaluate its performance<ul><li>Training and evaluating is easy with scikit learn</ul><li>Display some results<li>Test on meme image<li>Compute the results on the test set and export them</ol><h1 id="image-classification-overview">Image classification overview</h1><h2 id="instance-recognition-vs-class-recognition">Instance recognition vs Class recognition<a href="#instance-recognition-vs-class-recognition"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="instance-recognition">Instance recognition<a href="#instance-recognition"><i class="fas fa-hashtag"></i></a></h3></h3><p>Re-recognize a known 2D or 3D rigid object, potentially being viewed from a novel viewpoint, against a cluttered background, and with partial occlusions</p><p><em>Ex: practice session 3</em></p><p><img data-proofer-ignore data-src="https://i.imgur.com/zjxx8F3.png" alt="" /></p><h3 id="class-recognition">Class recognition<a href="#class-recognition"><i class="fas fa-hashtag"></i></a></h3></h3><p>Recognize any instance of a particular general class such as “cat”, “car” or “bicycle”</p><p>Aka <em>category-level</em> or <em>generic</em> object recognition</p><div class="alert alert-warning" role="alert"><p>More challenging</p></div><p><em>This lecture and next practice session</em></p><p><img data-proofer-ignore data-src="https://i.imgur.com/fvvBXlU.png" alt="" /></p><h2 id="pipeline-overview">Pipeline overview<a href="#pipeline-overview"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/ufF8vdn.png" alt="" /></p><h2 id="our-image-classification-pipeline">Our image classification pipeline<a href="#our-image-classification-pipeline"><i class="fas fa-hashtag"></i></a></h2></h2><p>This is a <strong>supervised</strong> machine learning task</p><ul><li>We need a dataset with samples<li>Images will be represented as BoVW vectors of fixed size <img data-proofer-ignore data-src="https://i.imgur.com/iGnNMb9.png" alt="" /><li>Targets will be encoded as integers <img data-proofer-ignore data-src="https://i.imgur.com/OV5hiUn.png" alt="" /><ul><li>0: Muffin<li>1: Chihuahua</ul></ul><p>This is a very usual data representation for a classification problem</p><div class="alert alert-info" role="alert"><p>Classifier inputs = “samples” with “features” Classifier outputs = “labels” <img data-proofer-ignore data-src="https://i.imgur.com/RUZZam9.png" alt="" /></p></div><p>Now we just need to select an appropriate method, prepare our data, run some training, test the results, adjust some parameters, compare approaches, display results, …</p><h1 id="data-preparation">Data preparation</h1><h2 id="numpy-formatting">NumPy formatting<a href="#numpy-formatting"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/WnT18Ch.png" alt="" /></p><h2 id="trainingvalidationtest-separation">Training/validation/test separation<a href="#trainingvalidationtest-separation"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li><strong>You cannot estimate the generalization performance of your predictor/estimator/classifier on its training set</strong><li>You need to keep some samples aside for later evaluation</ul><h2 id="other-funny-things-to-do-irl">Other “funny” things to do IRL<a href="#other-funny-things-to-do-irl"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Collect data<li>Clean data<li>Check data<li>Clean again<li>Annotate<li>Check<li>Compute/convert/scale features</ul><h2 id="feature-selection">Feature selection<a href="#feature-selection"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Consists in dropping some data columns</p></div><p>Can help later stages:</p><ul><li>Less data to process<li>Better properties (like decorrelated features, etc.)</ul><p>Which columns ?</p><ul><li>Hard problem in general<ul><li>Because features may be informative <strong>as a group</strong></ul><li>Some simpler and helpful techniques:<ul><li>Remove features with low variances<li>Dimensionality reduction techniques are not exactly feature selection, but can still have a similar effect</ul></ul><h1 id="some-classifiers---part-1">Some classifiers - part 1</h1><h2 id="disclaimer">Disclaimer<a href="#disclaimer"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-warning" role="alert"><p>What follows is a very limited selection</p></div><p>Only classifiers suitable for image classification as we present it today</p><div class="alert alert-info" role="alert"><p><strong>input = feature vector</strong> <strong>output = label</strong></p></div><p>Many other approaches</p><h2 id="what-is-our-goal-">What is our goal ?<a href="#what-is-our-goal-"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-danger" role="alert"><p>Given samples (described by features) and true lables, find a good function which will correctly predict labels given new data samples</p></div><h2 id="parametric-vs-non-parametric-classifiers">Parametric vs Non Parametric Classifiers<a href="#parametric-vs-non-parametric-classifiers"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="parametric-examples">Parametric examples<a href="#parametric-examples"><i class="fas fa-hashtag"></i></a></h3></h3><p>Logisitic regression, Linear Discriminant Analysis, naive Bayes, Perceptrion, Simple Neural Networks..</p><blockquote><p>A learning model that summarizes data with a set of parameters of fixed size (independant of the number of training examples) is called a parametric model. No matter how much data you throw in nature</p></blockquote><h3 id="non-parametric-examples">Non-parametric examples<a href="#non-parametric-examples"><i class="fas fa-hashtag"></i></a></h3></h3><p>k-Neares Neighbors, Decision Trees, SVMs</p><blockquote><p><em>“Non-parametric models differ from parametric models int that hte model structure is not specified a priori but is instead determined from data. The term non-parametric is not meant to imply that such models completely lack parameters but that the number and nature of the parameters are flexible and not fixed in advance”</em> Wikipedia</p></blockquote><blockquote><p><em>“Nonparametric methods are good when you have a lot of data and no prior knowledge”</em></p></blockquote><h2 id="dummy-classifiers">Dummy classifiers<a href="#dummy-classifiers"><i class="fas fa-hashtag"></i></a></h2></h2><p>Say you have a dataset with 9 muffins and 1 chihuahua.</p><p>You have a new sample to classify.</p><p><strong>Which class should you bet on ?</strong></p><p><img data-proofer-ignore data-src="https://i.imgur.com/Sy1wvkC.png" alt="" /></p><p>If your class prior probabilities $P(C_1), P(C_2),\dots$ are not equal, then you should bet on the <strong>most frequent class!</strong> ($g(x)=argmax_yp(y)$)</p><p>Without such information, you can just pick at random</p><p><em>Waht is the expected accuracy (true predictions / total predictions) if you have N classes an pick one at random ?</em></p><div class="alert alert-info" role="alert"><p>Scikit-learn offers a DummyClassifier class which helps testing such a strategy</p></div><h3 id="whats-the-point-">What’s the point ?<a href="#whats-the-point-"><i class="fas fa-hashtag"></i></a></h3></h3><ol><li>Quickly build and test your complete pipeline with a mockup classifier<li>Quickly get a baseline for the performance<li>(look for obvious bias in the dataset, but you should have cleaned it before !)</ol><h2 id="k-nearest-neighbor-knn">K Nearest Neighbor (kNN)<a href="#k-nearest-neighbor-knn"><i class="fas fa-hashtag"></i></a></h2></h2><p>Keep all training samples</p><p>View new samples as quieries over the previously learned / indexed samples</p><p><img data-proofer-ignore data-src="https://i.imgur.com/vGq3eFP.png" alt="" /></p><p>Assign the class of the closest(s) samples</p>\[f(x) = y_i, i = argmin_j\Vert x_j-x\Vert\]<p><img data-proofer-ignore data-src="https://i.imgur.com/13qgkgU.png" alt="" /></p><p>We can check more than one sample</p><p><img data-proofer-ignore data-src="https://i.imgur.com/yQB482y.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/NYzoX1K.png" alt="" /></p><h3 id="remember-thi-biasvariance-compromise-">Remember thi bias/variance compromise ?<a href="#remember-thi-biasvariance-compromise-"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/LxXw7gB.png" alt="" /></p><h3 id="pros">Pros<a href="#pros"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>very simple to implement<li>Capacity easily controlled with k<li>Can be tuned to work on large datasets: indexing, data cleaning, etc.<li>Good baseline<li>Non parametric<li>Lazy learner</ul><h3 id="cons">Cons<a href="#cons"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>In high dimension, all samples tend to be very close (for Euclidean dimension)<li>Large memory consumption on large datasets<li>Requires a large amount of samples and large k to get best performance</ul><div class="alert alert-danger" role="alert"><p><strong>Setting K:</strong></p>\[K\simeq\sqrt{\frac{m}{C}}\]<p>$\frac{m}{C}$: average number of training sample/class</p></div><h2 id="other-distance-based-classifier">Other distance-based classifier<a href="#other-distance-based-classifier"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="minimal-euclidean-distance">Minimal euclidean distance<a href="#minimal-euclidean-distance"><i class="fas fa-hashtag"></i></a></h3></h3><p><strong>Very basic classifier</strong></p><p>Distance to the mean $m_i$ of the class</p><p>It does not take into account differences in variance for each class</p><p>Predicted class for x:</p>\[g(x) = argmin_iD_i(x)\]<p><img data-proofer-ignore data-src="https://i.imgur.com/zTOkAeB.png" alt="" /></p><h3 id="minimal-quadratic-distance-mahalanobis">Minimal quadratic distance (Mahalanobis)<a href="#minimal-quadratic-distance-mahalanobis"><i class="fas fa-hashtag"></i></a></h3></h3><p>For each class $i$, the mean $m_i$ and covariance matrix $S_i$ are computed from the set of examples</p><p>The covariance matrix is taken into account when computing the distance from an image to the class $i$</p><p>The feature vector of the image $x$ is projected over the eigenvectors of the class</p>\[g(x) = argmin_iD_i(x)\]<p><img data-proofer-ignore data-src="https://i.imgur.com/iBAfkDT.png" alt="" /></p><h1 id="a-quick-introduction-to-bayesian-decision-theory">A quick introduction to Bayesian Decision Theory</h1><h2 id="example---robocup">Example - RoboCup<a href="#example---robocup"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/6znaC7D.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/gS6isnG.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.comkITm9Y.png" alt="" /></p><h2 id="general-case-maximum-a-posteriori-map">General case: maximum a posteriori (MAP)<a href="#general-case-maximum-a-posteriori-map"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>General case: need to tale into consideration $p(y)$ and $p(x)$</p></div><ul><li>$p(x\vert y)$: class conditional density (here: histograms)<li>$p(y)$: class priors, e.g. for indoor RoboCup<li>$p(floor) = 0.6$, $p(goal) = 0.3$, $p(ball) = 0.1$<li>$p(x)$: probability of seeing data $x$</ul><p>Optimal decision rule (Bayes classifier): maximum a posteriori (MAP):</p>\[g(x) = argmax_{y\in Y}p(y\vert x)\]<h3 id="how-to-compute-pyvert-x-">How to compute $p(y\vert x)$ ?<a href="#how-to-compute-pyvert-x-"><i class="fas fa-hashtag"></i></a></h3></h3>\[p(y\vert x) = \frac{p(x\vert y)p(y)}{p(x)}\quad\text{Bayes' rule}\]<p>If classes are equiprobables and error cost is the same, then, because $p(x)$ is constant, we get the maximum likelihood estimation:</p>\[g(x) = \underbrace{argmax_{y\in Y}p(y\vert x)}_{\text{MAP}}\simeq\underbrace{argmax_{y\in Y}p(x\vert y)}_{\text{ML}}\]<h2 id="generative-discriminant-and-direct-classifiers">Generative, discriminant and “direct” classifiers<a href="#generative-discriminant-and-direct-classifiers"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/UlPjAcK.png" alt="" /></p><h1 id="generative-probabilistic-models">Generative Probabilistic Models</h1><h2 id="some-classical-generative-probabilistic-models">Some classical Generative Probabilistic Models<a href="#some-classical-generative-probabilistic-models"><i class="fas fa-hashtag"></i></a></h2></h2><p>Training data $X={x-1,\dots,x_n}$, $Y={y_1,\dots,x_n}$. $X\times Y\in\mathcal X\times\mathcal Y$</p><p>For each $y\in\mathcal Y$, build model for $p(x\vert y)$ of $X_y:={x_i\in X:y_i=y}$</p><ul><li>Histogram: if $x$ can have only a few discrete values<li>Kernel Density Estimator <img data-proofer-ignore data-src="https://i.imgur.com/ZIJ8gxo.png" alt="" /><li>Gaussian <img data-proofer-ignore data-src="https://i.imgur.com/KFvVTpi.png" alt="" /><li>Mixture of Gaussians <img data-proofer-ignore data-src="https://i.imgur.com/KDKezfM.png" alt="" /></ul><p>Typically, $\mathcal Y$ small (few possibles lables), $\mathcal X$ low dimensional</p><h2 id="class-conditional-densities-and-posteriors">Class conditional densities and posteriors<a href="#class-conditional-densities-and-posteriors"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/DUCdiKg.png" alt="" /></p><h2 id="naive-bayes-classifiers">Naive Bayes Classifiers<a href="#naive-bayes-classifiers"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/E5Pz6Qx.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/VxjSGbd.png" alt="" /></p><h1 id="linear-discriminant-classifiers">Linear discriminant classifiers</h1><h2 id="general-idea-for-binary-classification">General idea for binary classification<a href="#general-idea-for-binary-classification"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/l6uLtyC.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/H4NM4Za.png" alt="" /></p><p>Learn w and b</p><ul><li>you can compute $p(y\vert x)\simeq\hat y$</ul><div class="alert alert-warning" role="alert"><p>Problem: how to learn w and b ?</p></div><h2 id="logistic-regression">Logistic Regression<a href="#logistic-regression"><i class="fas fa-hashtag"></i></a></h2></h2><p>Linear classifier, $f$ is logistic function</p><p>\(\sigma(x) = \frac{1}{(1+e^{-x})} = \frac{e^x}{(1+e^x)}\)</p><ul><li>Maps all real $\to[0,1]$</ul><p>Optimize $\sigma(w^Tx+b)$ to find best $w$</p><p>Trained using gradient descent (no closed form solution)</p><p><img data-proofer-ignore data-src="https://i.imgur.com/RZoBc0Y.png" alt="" /></p><h2 id="gradient-descent">Gradient descent<a href="#gradient-descent"><i class="fas fa-hashtag"></i></a></h2></h2><p>Formally:</p>\[w_{t+1}=w_t-\eta\nabla L(w)\]<p>Where $\eta$ is <em>step size</em>, how far to step relative to the gradient</p><p><img data-proofer-ignore data-src="https://i.imgur.com/eXfRl8J.png" alt="" /></p><h2 id="from-2-classes-to-c-classes-2-strategies">From 2 classes to C classes: 2 strategies<a href="#from-2-classes-to-c-classes-2-strategies"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/hB0yq8C.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/E8QRm0Z.png" alt="" /></p>\[\hat y = argmax_{i\in Y}w_ix\]<h2 id="maximum-margin-classification">Maximum Margin classification<a href="#maximum-margin-classification"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/8zbmVyB.png" alt="" /></p><p>What is the best $w$ for this dataset ?</p><p>Trade-off: large margin vs few mistakes on training set</p><p><img data-proofer-ignore data-src="https://i.imgur.com/3tH5H3Z.png" alt="" /></p><h2 id="support-vector-machin-svm">Support Vector Machin (SVM)<a href="#support-vector-machin-svm"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/AMNYWuJ.png" alt="" /></p><h2 id="logistic-regression-vs-svm">Logistic Regression vs SVM<a href="#logistic-regression-vs-svm"><i class="fas fa-hashtag"></i></a></h2></h2><p>Optimization problems:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/NGEFBBe.png" alt="" /></p><h2 id="about-the-regularizer">About the regularizer<a href="#about-the-regularizer"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/zY3MiZQ.png" alt="" /></p><h2 id="effect-of-cost-parameter-c-regularization-again">Effect of cost parameter C (regularization, again)<a href="#effect-of-cost-parameter-c-regularization-again"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/QEjgzaK.png" alt="" /></p><h1 id="non-linear-discriminant-classifiers">Non-linear discriminant classifiers</h1><h2 id="non-linear-classification">Non-linear classification<a href="#non-linear-classification"><i class="fas fa-hashtag"></i></a></h2></h2><p>What is the best linear classifier for this dataset?</p><p><img data-proofer-ignore data-src="https://i.imgur.com/4IRGUzO.png" alt="" /></p><div class="alert alert-success" role="alert"><p>None. We need something nonlinear!</p></div><p>2 solutions:</p><ol><li>Preprocess the data (explicit embedding, kernel trick…)<li>Combine multiple linear classifiers into nonlinear classifier (boosting, neural networks…)</ol><h1 id="non-linear-classification-using-linear-classifiers-with-data-preprocessing">Non-linear classification using linear classifiers with data preprocessing</h1><h2 id="data-preprocessing-idea">Data preprocessing idea<a href="#data-preprocessing-idea"><i class="fas fa-hashtag"></i></a></h2></h2><p>Transform the dataset to enable linear separability</p><p><img data-proofer-ignore data-src="https://i.imgur.com/iJr7bVs.png" alt="" /></p><h2 id="linear-separation-is-always-possible">Linear separation is always possible<a href="#linear-separation-is-always-possible"><i class="fas fa-hashtag"></i></a></h2></h2><p>The original input space can always be mapped to some higher-dimensional feature space where the training set is separable.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/21JoSx4.png" alt="" /></p><h2 id="explicit-embedding">Explicit embedding<a href="#explicit-embedding"><i class="fas fa-hashtag"></i></a></h2></h2><p>Compute $\phi(x)$ for all $x$ in the dataset.</p><p>Then train a linear classifier just like before</p><div class="alert alert-warning" role="alert"><p>Used to be avoided because of computation issues, but it is a hot topic again.</p></div><h2 id="kernel-trick">Kernel trick<a href="#kernel-trick"><i class="fas fa-hashtag"></i></a></h2></h2><p>Linear classification requires to compute only dot products $\phi(x_i),\phi(x_j)$</p><p><strong>The function $\phi(x)$ does not need to be explicit,</strong> we can use a kernel function</p>\[k(x,z)=\phi(x)\phi(z)\]<p>which represents a dot product in a “hidden” feature space.</p><div class="alert alert-success" role="alert"><p>This gives a non-linear boundary in the original feature space.</p></div><h2 id="popular-kernel-functions-in-computer-vision">Popular kernel functions in Computer Vision<a href="#popular-kernel-functions-in-computer-vision"><i class="fas fa-hashtag"></i></a></h2></h2><p>Linear kernel”: identical solution as linear SVM</p><p><img data-proofer-ignore data-src="https://i.imgur.com/dtD4CbJ.png" alt="" /></p><p>“Hellinger kernel”: less sensitive to extreme value in feature vector</p><p><img data-proofer-ignore data-src="https://i.imgur.com/Cz0oSkY.png" alt="" /></p><p>“Histogram intersection kernel”: very robust <img data-proofer-ignore data-src="https://i.imgur.com/CDbNlrq.png" alt="" /></p><p>“$X^2$-distance kernel”: good empirical results <img data-proofer-ignore data-src="https://i.imgur.com/dG3QTIm.png" alt="" /></p><p>“Gaussian kernel”: overall most popular kernel in Machine Learning <img data-proofer-ignore data-src="https://i.imgur.com/f0yjvx6.png" alt="" /></p><h2 id="explicit-embedding-for-the-hellinger-kernel">Explicit embedding for the Hellinger kernel<a href="#explicit-embedding-for-the-hellinger-kernel"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/bakMDIs.png" alt="" /></p><p>Using simple square root properties, we have:</p>\[k(x,x’) = \phi(x)\phi(x’) = \sqrt{x} \sqrt{x'}\]<p>Tricks for next practice session: given a BoVW vector,</p><ol><li>L1 normalize it (neutralizes effect of number of descriptors)<li>Take its square root (explicit Hellinger embedding)<li>L2 normalize it (more linear-classifier friendly)</ol><h1 id="metrics">Metrics</h1><h2 id="confusion-matrix-and-accuracy">Confusion matrix and Accuracy<a href="#confusion-matrix-and-accuracy"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/OZXWA8Q.png" alt="" /></p><h2 id="problems-with-accuracy">Problems with Accuracy<a href="#problems-with-accuracy"><i class="fas fa-hashtag"></i></a></h2></h2><p>All the following classifiers have a 90% accuracy</p><p><img data-proofer-ignore data-src="https://i.imgur.com/2ciC5Uz.png" alt="" /></p><p><em>Do all errors have the same cost?</em></p><h2 id="precision-recall-f-score">Precision, recall, F-score<a href="#precision-recall-f-score"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/VMpNMQH.png" alt="" /></p><h2 id="plotting-a-precisionrecall-for-classification-data">Plotting a Precision/Recall for classification data<a href="#plotting-a-precisionrecall-for-classification-data"><i class="fas fa-hashtag"></i></a></h2></h2><p>For binary classification</p><p>Instead of $\hat y = argmax_yp(y\vert x)$, take <strong>all possible thresholds</strong> for $p(y\vert x)$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/VtynSfU.png" alt="" /></p><h2 id="tpr-fpr-roc">TPR, FPR, ROC<a href="#tpr-fpr-roc"><i class="fas fa-hashtag"></i></a></h2></h2><p>ROC: “Receiver Operating Characteristic” Kind of signaloise measure under various tunings</p><p><img data-proofer-ignore data-src="https://i.imgur.com/k3BeCv0.png" alt="" /></p><p>Ligne rose: random results</p><h2 id="more-about-roc-curves">More about ROC curves:<a href="#more-about-roc-curves"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="adjusting-the-threshold">Adjusting the threshold<a href="#adjusting-the-threshold"><i class="fas fa-hashtag"></i></a></h3></h3><p><a href="http://www.navan.name/roc/">http://www.navan.name/roc/</a></p><p><img data-proofer-ignore data-src="https://i.imgur.com/2CQamZr.png" alt="" /></p><h3 id="class-overlap">Class overlap<a href="#class-overlap"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/BWAThY5.png" alt="" /></p><h1 id="split-the-dataset-to-assess-generalization-performance">Split the dataset to assess generalization performance</h1><h2 id="bootstrap">Bootstrap<a href="#bootstrap"><i class="fas fa-hashtag"></i></a></h2></h2><p>Draw randomly, with replacement samples from the training set.</p><p>Enables us to estimate the variance of estimators we use in the classification rule.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/ZuxQOyR.png" alt="" /></p><h2 id="holdout">Holdout<a href="#holdout"><i class="fas fa-hashtag"></i></a></h2></h2><p>Just keep a part of the dataset for later validation/testing</p><p><img data-proofer-ignore data-src="https://i.imgur.com/513iOG6.png" alt="" /></p><h2 id="cross-validation">Cross validation<a href="#cross-validation"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/4KkbALB.png" alt="" /></p><h3 id="with-meta-parameter-tuning">with meta parameter tuning<a href="#with-meta-parameter-tuning"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/vf2xEDm.png" alt="" /></p><h2 id="stratifiedkfold-best">StratifiedKFold (best)<a href="#stratifiedkfold-best"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/IELUcaX.png" alt="" /></p><h2 id="missing-things">Missing things<a href="#missing-things"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Cost of misclassification<li>Multiclass classification evaluation<li>…</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s8/'>Image S8</a>, <a href='/cours/categories/mlrf/'>MLRF</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/scia/" class="post-tag no-text-decoration" >SCIA</a> <a href="/cours/tags/mlrf/" class="post-tag no-text-decoration" >MLRF</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=MLRF: Lecture 05 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_fith_course/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=MLRF: Lecture 05 - Cours&u=https://lemasyma.github.io/cours/posts/mlrf_fith_course/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=MLRF: Lecture 05 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_fith_course/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/mlrf_first_course/"><div class="card-body"> <em class="timeago small" date="2021-05-14 10:00:00 +0200" >May 14, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 01</h3><div class="text-muted small"><p> Lien de la note Hackmd Scope of this course Apply Machine Learning (ML) techniques to solve some practical Computer Vision (CV) problems About Computer Vision (CV) It should be called C...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_second_course/"><div class="card-body"> <em class="timeago small" date="2021-05-21 10:00:00 +0200" >May 21, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 02</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 2 Introduction Global image descriptors Clustering Local feature detectors Introduction Summary of last lecture Machine learning Machine lea...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_third_course/"><div class="card-body"> <em class="timeago small" date="2021-05-28 10:00:00 +0200" >May 28, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 03</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 3 Introduction Finish lecture about local feature detectors Local feature descriptors Descriptor matching and indexing Projective transformatio...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/ase3_td2-1/" class="btn btn-outline-primary" prompt="Older"><p>ASE3: TD 2</p></a> <a href="/cours/posts/tifo_recalage/" class="btn btn-outline-primary" prompt="Newer"><p>TIFO: Cours recalage</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
