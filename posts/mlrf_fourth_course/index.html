<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="MLRF: Lecture 04" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Lecture 04" /><meta property="og:description" content="Lecture 04" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/mlrf_fourth_course/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/mlrf_fourth_course/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-04T10:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="MLRF: Lecture 04" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-11-17T09:04:12+01:00","datePublished":"2021-06-04T10:00:00+02:00","description":"Lecture 04","headline":"MLRF: Lecture 04","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/mlrf_fourth_course/"},"url":"https://lemasyma.github.io/cours/posts/mlrf_fourth_course/"}</script><title>MLRF: Lecture 04 | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>MLRF: Lecture 04</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>MLRF: Lecture 04</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-06-04 10:00:00 +0200" data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 4, 2021, 10:00 AM +0200" >Jun 4, 2021</em> </span> <span> Updated <em class="timeago" date="2021-11-17 09:04:12 +0100 " data-toggle="tooltip" data-placement="bottom" title="Wed, Nov 17, 2021, 9:04 AM +0100" >Nov 17, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1378 words"> <em>7 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/BJj638vqd">note Hackmd</a></p><h1 id="agenda-for-lecture-4">Agenda for lecture 4</h1><ol><li>Introduction<li>Content-based image retrievalasl (CBIR) using bags of features<li>Evaluating CBIR / Ranked Retrieval (RR) systems<li>Texture descriptors<li>Character descriptors</ol><h1 id="summary-of-last-lecture">Summary of last lecture</h1><ul><li>Descriptor matching<ul><li>1-way<li>Cross check<li>Ratio test<li>Radius threshold</ul><li>Descriptor indexing<ul><li>Indexing pipeline: train/query<li>Linear matching<li>kD-Trees<li>FLANN/hierarchical k-Means<li>LSH<li>Aproximate NN problem</ul><li>Projective transformations<ul><li>Translation<li>Rotation<li>Scaling<li>…<li>Projective</ul><li>Homography estimation<ul><li>Least square<li>RANSAC</ul><li>Geometric validation</ul><h1 id="practice-session-3-take-home-messages">Practice session 3: Take home messages</h1><p><em>Twin it!</em>: Extracting descriptors, matching them <strong>by hand</strong></p><ul><li>Detect keypoints and extract surrounding pixels to flat vector<li>Normalize them and compare them using cross correlation ($\sum_if_i\bullet g_i$)</ul><p>Augmented Documents: Use an off-the-shelf detector/descriptor: ORB</p><p>Augmented Documents: Projective transforms and Homography estimation</p><ul><li>OpenCV provides the solver for machinery: list of matches $to$ $3\times 3$ matrix<li>Just som coordinate transform (2D $\to$ 2D transform)<li>Remember the classical matrix forms: <strong>translation, rotation, …</strong></ul><h1 id="next-practice-session">Next practice session</h1><div class="alert alert-success" role="alert"><p>Implement a simple <strong>image search engine</strong></p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/uwclkII.png" alt="" /></p><div class="alert alert-danger" role="alert"><p>Will be graded</p></div><h1 id="local-feature-descriptors">Local feature descriptors</h1><h2 id="introduction">Introduction<a href="#introduction"><i class="fas fa-hashtag"></i></a></h2></h2><p><em>Given some keypoints in image 1, what are the more similar ones in image 2 ?</em></p><p><img data-proofer-ignore data-src="https://i.imgur.com/vDMNGYF.png" alt="" /></p><div class="alert alert-info" role="alert"><p>This is a <strong>nearest neighbor problem</strong> in <strong>descriptor space</strong> This is also a <strong>geometrical problem</strong> in <strong>coordinate space</strong></p></div><div class="alert alert-success" role="alert"><p>Local feature <strong>detectors</strong> give use the same feature under several perturbations: perspective, illumination, blur…</p></div><p>Local feature descriptors will associate a <strong>vector to each local feature</strong>.</p><p>Such description vector should be:</p><ul><li><strong>Compact</strong> - to enable fast indexing and matching<li><strong>Discriminative</strong> - to enable object recognition<li><strong>Robust to perturbations</strong> - to tolerate real conditions</ul><p>We will focus on 2 widely used descriptors for their pedagogical interest</p><ul><li><strong>HOG</strong> (Histogram of gradients), used im SIFT<li><strong>BRIEF</strong> (Binary Robust Independent Elementary Features), used in ORB</ul><h1 id="histogram-of-gradient">Histogram of Gradient</h1><h2 id="algorithm-overview">Algorithm overview<a href="#algorithm-overview"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>(optional) global image normalization<li>Compute the gradient image in $x$ and $y$<li>Compute gradient hisograms<li>Normalise across blocks<li>Flatten into a feature vector<li>(quantify to integers)</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/zACmsUy.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/xSKmwma.png" alt="" /></p><h2 id="exemple">Exemple<a href="#exemple"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/vQ4mY5v.png" alt="" /></p><blockquote><p>Cette sensation quand tu cogne ton coude au niveau du nerf</p></blockquote><h2 id="summary">Summary<a href="#summary"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="pros">Pros<a href="#pros"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Very stable over illuminations changes perpectives changes, blur</ul><h3 id="cons">Cons<a href="#cons"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Slow to compute<li>Quite large (128 bytes for original SIFT)</ul><h1 id="brief">BRIEF</h1><p>General idea:</p><ol><li>Sample pairs of points \(\{p(x), p(y)\}\) in the <strong>smoothed</strong> (very spiky otherwise, like derivatives) keypoints neighborhood<li>Compute a simple <strong>binary test</strong>: $p(x)\lt p(y)$<li>Accumulate the results of $n_d$ tests to form a <strong>binary vector of $n_d$ bits</strong> (256 in ref.)</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/1SDVx4U.png" alt="" /></p><h2 id="sampling-strategies">Sampling strategies<a href="#sampling-strategies"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>GI: $(x_i, y_i)\sim$ i.i.d. Uniform($-\frac{S}{2}$, $+\frac{S}{2}$)<li>GII: $(x_i, y_i)\sim$ i.i.d. Gaussian($0$, $\frac{1}{25}S^2$)<li>GII:<ul><li>$x_i\sim$ i.i.d. Gaussian($0$, $\frac{1}{25}S^2$)<li>$y_i\sim$ i.i.d. Gaussian($x_i$, $\frac{1}{100}S^2$)</ul><li>GIV: $(x_i, y_i)$ randomly sampled from discrete locations of a coarse polar grid introducing a spatial quantization<li>GV:<ul><li>$x_i=(0,0)$<li>$y_i$ takes all possible values on a coarse polar grid containing $n_d$ points</ul></ul><p><img data-proofer-ignore data-src="https://i.imgur.com/AXKYqZM.png" alt="" /></p><p><strong>What is the best approach ?</strong></p><div class="alert alert-success" role="alert"><p>C’est la strategie 2</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/llHURZA.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/MBS2vD7.png" alt="" /></p><h2 id="summary-1">Summary<a href="#summary-1"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="pros-1">Pros<a href="#pros-1"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Very fast to compute<li>Very fast to match<li>Very compact to store<h3 id="cons-1">Cons<a href="#cons-1"><i class="fas fa-hashtag"></i></a></h3></h3><li>Less robust than HoG(SIFT), DoH(SURF) on several real cases</ul><h1 id="invariance-check">Invariance check</h1><h2 id="rotation-invariance">Rotation invariance<a href="#rotation-invariance"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Add an angle measure<li>Take the main gradient orientation<ul><li>(Take the averga around the keypoints)</ul></ul><p>We now have for each keypoint:</p><ul><li>Coordinates<li><strong>Orientation</strong></ul><p>Descriptor: computed over <strong>normalized patch</strong></p><p><img data-proofer-ignore data-src="https://i.imgur.com/zBuVgaq.png" alt="" /></p><h2 id="scale-invariance">Scale invariance<a href="#scale-invariance"><i class="fas fa-hashtag"></i></a></h2></h2><p>Multi scale feature detection and computation:</p><ul><li>Add a keypoint for each relevant scale<li>Possibly several keypoints at the same position</ul><p>We now have for each keypoint:</p><ul><li>Coordinates<li>Orientation<li><strong>Scale</strong></ul><p>Descriptor: computed on a <strong>scaled patch</strong></p><p><img data-proofer-ignore data-src="https://i.imgur.com/yMyMl4u.png" alt="" /></p><h3 id="reminder-gaussian-sigma-vs-window-size">Reminder: Gaussian sigma vs window size<a href="#reminder-gaussian-sigma-vs-window-size"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/tXEAYNh.png" alt="" /></p><h2 id="illumation-invariance">Illumation invariance<a href="#illumation-invariance"><i class="fas fa-hashtag"></i></a></h2></h2><p>SIFT approach:</p><ol><li>Normalize the vector<ul><li>Solves Affine but what non-linear sources like camera saturation?<li><img data-proofer-ignore data-src="https://i.imgur.com/SIti7h8.png" alt="" /></ul><li>Cap the vector elements to $20\%$ (!) and renormalize<ul><li>Now we have some illumination invariance<li><img data-proofer-ignore data-src="https://i.imgur.com/NJb8ayu.png" alt="" /></ul></ol><h2 id="viewpoint-invariance">Viewpoint invariance<a href="#viewpoint-invariance"><i class="fas fa-hashtag"></i></a></h2></h2><p>Better, but more complex approaches can tolerate extreme viewpoint change</p><p><img data-proofer-ignore data-src="https://i.imgur.com/AM7wRyG.png" alt="" /></p><h1 id="complete-pipelines">Complete pipelines</h1><h2 id="sift-scale-invariant-feature-tr">SIFT (Scale invariant feature tr.)<a href="#sift-scale-invariant-feature-tr"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>Construct scale space<li>Take difference of Gaussians<li>Locate DoG Extrema<li>Sub pixel locate potential feature points<li>Filter edge and low contrast responses<li>Assigne keypoints orientations<li>Build keypoint descriptors<li>Matching, etc.</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/ULWDf5s.png" alt="" /></p><h2 id="orb-oriented-fast-and-rotated-brief">ORB (oriented FAST and rotated BRIEF)<a href="#orb-oriented-fast-and-rotated-brief"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>Use FAST in pyramids to detect stable keypoints<li>Select the strongest features using FAST or Harris response<li>Finds their orientation using first-order moments<li>Computes the descriptors using BRIEF<ul><li>Where the coordinates of random point pairs are rotated according to the measured orientation</ul></ol><h1 id="conclusion-about-feature-extraction">Conclusion about feature extraction</h1><p>Selection of appropriate features:</p><ul><li>It is a <strong>critical</strong> decision<li>Depends on the <strong>specific application</strong></ul><p>Features must:</p><ul><li>Be <strong>invariant</strong> to data variations (depending on the application)<ul><li>rotation<li>perpective<li>noise<li>etc.</ul><li>Have <strong>low dimensionality</strong> for fast training, matching, reasonable storage</ul><p>Features determine the <strong>type of info</strong> to work with:</p><ul><li>gray-level, binary, color image<li>contours, vectorization, skeleton</ul><p>Features also determine the <strong>type of classifier / indexer</strong></p><h1 id="content-based-image-retrieval">Content based image retrieval</h1><h2 id="two-strategies-using-local-descriptors">Two strategies using local descriptors<a href="#two-strategies-using-local-descriptors"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="keep-all-local-descriptors">Keep all local descriptors<a href="#keep-all-local-descriptors"><i class="fas fa-hashtag"></i></a></h3></h3><p>Pros:</p><ul><li>Enables geometric validation<li>better part detection in theory</ul><p>Cons:</p><ul><li>Huge memory requirements</ul><div class="alert alert-success" role="alert"><p>Like what we did in practice session 3 to match parts of an image (useful to validate geometric constraints and classify an image at the same time)</p></div><h3 id="build-a-global-descriptor-using-local-ones">Build a global descriptor using local ones<a href="#build-a-global-descriptor-using-local-ones"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Inspired by text retrieval<li>Compact representation<li>Tricks to embed spatial information<li>Limited memory requirements</ul><div class="alert alert-success" role="alert"><p>Like what we did in practice session 2 with the color histogram, at the bubble level</p></div><div class="alert alert-info" role="alert"><p><strong>Bag of Feature</strong> approach</p></div><h2 id="pipeline-with-local-descriptors-prev-lecture">Pipeline with local descriptors (prev. lecture)<a href="#pipeline-with-local-descriptors-prev-lecture"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/kCXVXCa.png" alt="" /></p><h2 id="pipeline-with-bag-of-features-current-lecture">Pipeline with bag of features (current lecture)<a href="#pipeline-with-bag-of-features-current-lecture"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.comJqjwCc.png" alt="" /></p><h1 id="features-extraction">Features extraction</h1><h2 id="sparse-vs-dense-detection">Sparse vs Dense detection<a href="#sparse-vs-dense-detection"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/vvZpbRA.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/9ksurAN.png" alt="" /></p><div class="alert alert-info" role="alert"><p>For dense detection, we usually filter regions with low variance</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/ww37BoR.jpg" alt="" /></p><h2 id="dimensionality-reduction">Dimensionality reduction<a href="#dimensionality-reduction"><i class="fas fa-hashtag"></i></a></h2></h2><p>Often used before encoding to:</p><ul><li>limit dictionary sizes<li>facilitate quantization</ul><p>Several techniques:</p><ul><li>Principal Component Analysis<li>Signualr-Value Decomposition</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/hk6hNrO.png" alt="" /></p><h1 id="encoding">Encoding</h1><h2 id="bag-of-visual-words">Bag of Visual Words<a href="#bag-of-visual-words"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Modern approaches are derived from this one<li>Reuses ideas of text/we search to images<li><strong>From a set of descriptor, build a histogram of quantized descriptors</strong> much alike a color histogram</ul><h2 id="quantization">Quantization<a href="#quantization"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Discretization of some signal - <strong>Lossy process!</strong><li>Vectorial formulation: $f:R^d\to F$, with $F={1,2,…,k}$<li>Defines a <strong>Voronoi diagram</strong>, ie a decomposition of a metric space determined by the distances to a discrete set of points</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/MwrAUQh.png" alt="" /></p><h2 id="bag-of-visual-words-continued">Bag of Visual Words (continued)<a href="#bag-of-visual-words-continued"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Cluster centers are determined using k-Means (once for all on a training set)<li>Each descriptor is quantized: store the code of the closest centroid<li>Build a histogram of descriptor count for each cluster</ul><div class="alert alert-info" role="alert"><p>The set of cluster centers is called the dictionary, the codebook or also the visual vocabulary</p></div><div class="alert alert-warning" role="alert"><p>We can choose the number of words !</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/RGjy5BK.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/RJUhOE7.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/f1QlwOv.png" alt="" /></p><h3 id="vector-size">Vector size<a href="#vector-size"><i class="fas fa-hashtag"></i></a></h3></h3><p>The resulting vector size for a given image is given by:</p>\[D=\text{vocabulary size}\]<p>Usually, the bigger the vocabulary the better the results. Several thousands of words are common.</p><h3 id="normalization">Normalization<a href="#normalization"><i class="fas fa-hashtag"></i></a></h3></h3><h4 id="premiere-methode">Premiere methode<a href="#premiere-methode"><i class="fas fa-hashtag"></i></a></h4></h4><p>Problem:</p><ul><li>The values in the histogram are <strong>absolute</strong>: each bin count the number of occurence of each <em>visual word</em><li>This make the descriptor <strong>sensitive to the variation of number of descriptors</strong></ul><p>Solution:</p><ul><li>Normalize the histogram</ul><h4 id="seconde-technique">Seconde technique<a href="#seconde-technique"><i class="fas fa-hashtag"></i></a></h4></h4><ul><li>Like for text retrieval, it is common to <strong>reweight the BOVW vectors</strong> using the <strong>TFDIF</strong> technique<li>Goal: give more importance to rare words than to frequent ones<li>For each dimension of the histogram, compute a new value $t_i$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/URzKx5n.png" alt="" /></p><h2 id="variant-soft-bovw">Variant: Soft BoVW<a href="#variant-soft-bovw"><i class="fas fa-hashtag"></i></a></h2></h2><p>Use soft assignment to clusters, add counts to neighbor bins</p><p><img data-proofer-ignore data-src="https://i.imgur.com/a4WbGkI.png" alt="" /></p><h2 id="other-variants">Other variants<a href="#other-variants"><i class="fas fa-hashtag"></i></a></h2></h2><p>BoVW is only about counting the number of local descriptors</p><h2 id="vlad-vector-of-locally-aggregated-descriptors">VLAD: vector of locally aggregated descriptors<a href="#vlad-vector-of-locally-aggregated-descriptors"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/fClfKFr.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/Sr75DHs.jpg" alt="" /></p><h2 id="fisher-vector">Fisher vector<a href="#fisher-vector"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/cMgDD7Y.png" alt="" /></p><h1 id="ir-evalutation">IR evalutation</h1><h2 id="how-to-evaluate-a-retrieval-system-">How to evaluate a retrieval system ?<a href="#how-to-evaluate-a-retrieval-system-"><i class="fas fa-hashtag"></i></a></h2></h2><p>We need a set of queries for which we know the expected results “Ground truth”, aka “targets”, “gold standard”</p><h2 id="precision-and-recall">Precision and recall<a href="#precision-and-recall"><i class="fas fa-hashtag"></i></a></h2></h2><p>Used to measure the balance between</p><ul><li>Returning many results, hence a lot of the relevant results present in the database, but also a lot of noise<li>Returning very few results, leading to less noise, but also less relevant results</ul><div class="alert alert-info" role="alert"><p>Precision ( P ) is the fraction of retrieved documents that are relevant:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/IhJjsv6.png" alt="" /></p></div><div class="alert alert-info" role="alert"><p>Recall ( R ) is the fraction of relevant documents that are retrieved</p><p><img data-proofer-ignore data-src="https://i.imgur.com/r1Czp0V.png" alt="" /></p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/8isRfsq.png" alt="" /></p><h2 id="f-measure">F-measure<a href="#f-measure"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>F-measure is the wighted harmonic mean of precision and recall <img data-proofer-ignore data-src="https://i.imgur.com/haBncXm.png" alt="" /></p></div><h2 id="how-to-evaluate-a-ranked-retrieval-system-">How to evaluate a <strong>ranked</strong> retrieval system ?<a href="#how-to-evaluate-a-ranked-retrieval-system-"><i class="fas fa-hashtag"></i></a></h2></h2><p>When results are ordered, more measures are availables.</p><p>Common useful measure are:</p><ul><li>Precision-recall<li>ROC graph nd the area under it (AUC)</ul><h3 id="precision-recall-graph">Precision-recall graph<a href="#precision-recall-graph"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/kHO9icg.png" alt="" /></p><h4 id="mean-average-precision">Mean-average precision<a href="#mean-average-precision"><i class="fas fa-hashtag"></i></a></h4></h4><p><img data-proofer-ignore data-src="https://i.imgur.com/v9hTxL6.png" alt="" /></p><h4 id="example-compute-the-ap-for-a-given-query">Example: Compute the AP for a given query<a href="#example-compute-the-ap-for-a-given-query"><i class="fas fa-hashtag"></i></a></h4></h4><p>For this query and the followinf results, plot the precision/recall graph</p><p><img data-proofer-ignore data-src="https://i.imgur.com/XHvHYC9.png" alt="" /></p><div class="alert alert-success" role="alert"><p>1, 3 et 9 sont pertinents ici</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/rpHF2Lx.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/I13Ey9Q.png" alt="" /></p><p><em>Is the first result relevant ?</em> Oui</p><ul><li>compute current precision: 1 relevant / 1 retrieved = 1<li>Recall: 1 relevant</ul><p>Repeter pour chaque resultat</p><p><img data-proofer-ignore data-src="https://i.imgur.com/cSj8Sl2.png" alt="" /></p><div class="alert alert-danger" role="alert"><p>Construction du graphe en dent de scie</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/Qy0tjaT.png" alt="" /></p><div class="alert alert-warning" role="alert"><p>Certaines librairies garde les valeurs superieures, <strong>c’est pas bien</strong></p></div><p>Case 2: what if $\vert e_i\vert=4$ ?</p><p><img data-proofer-ignore data-src="https://i.imgur.com/aRmeh6t.png" alt="" /></p><div class="alert alert-danger" role="alert"><p>Ce qu’on veut c’est l’aire sous la courbe</p></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s8/'>Image S8</a>, <a href='/cours/categories/mlrf/'>MLRF</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/scia/" class="post-tag no-text-decoration" >SCIA</a> <a href="/cours/tags/mlrf/" class="post-tag no-text-decoration" >MLRF</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=MLRF: Lecture 04 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_fourth_course/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=MLRF: Lecture 04 - Cours&u=https://lemasyma.github.io/cours/posts/mlrf_fourth_course/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=MLRF: Lecture 04 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_fourth_course/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/mlrf_first_course/"><div class="card-body"> <em class="timeago small" date="2021-05-14 10:00:00 +0200" >May 14, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 01</h3><div class="text-muted small"><p> Lien de la note Hackmd Scope of this course Apply Machine Learning (ML) techniques to solve some practical Computer Vision (CV) problems About Computer Vision (CV) It should be called C...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_second_course/"><div class="card-body"> <em class="timeago small" date="2021-05-21 10:00:00 +0200" >May 21, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 02</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 2 Introduction Global image descriptors Clustering Local feature detectors Introduction Summary of last lecture Machine learning Machine lea...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_third_course/"><div class="card-body"> <em class="timeago small" date="2021-05-28 10:00:00 +0200" >May 28, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 03</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 3 Introduction Finish lecture about local feature detectors Local feature descriptors Descriptor matching and indexing Projective transformatio...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/pogl_second_course/" class="btn btn-outline-primary" prompt="Older"><p>POGL: Second class</p></a> <a href="/cours/posts/ase3_composantes_principales/" class="btn btn-outline-primary" prompt="Newer"><p>ASE3: Analyse en composantes principales</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
