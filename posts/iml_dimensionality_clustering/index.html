<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="IML: Unsupervised clustering" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Unsupervised clustering" /><meta property="og:description" content="Unsupervised clustering" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-04-02T13:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="IML: Unsupervised clustering" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-10-03T16:45:54+02:00","datePublished":"2021-04-02T13:00:00+02:00","description":"Unsupervised clustering","headline":"IML: Unsupervised clustering","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/"},"url":"https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/"}</script><title>IML: Unsupervised clustering | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>IML: Unsupervised clustering</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>IML: Unsupervised clustering</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-04-02 13:00:00 +0200" data-toggle="tooltip" data-placement="bottom" title="Fri, Apr 2, 2021, 1:00 PM +0200" >Apr 2, 2021</em> </span> <span> Updated <em class="timeago" date="2021-10-03 16:45:54 +0200 " data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 3, 2021, 4:45 PM +0200" >Oct 3, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="962 words"> <em>5 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/HJmN9d4Su">note Hackmd</a></p><h1 id="why-do-we-care">Why do we care</h1><div class="alert alert-info" role="alert"><p>Group the input data into clusters that share some characteristics</p></div><ul><li>Find pattern in the data (data mining problem)<li>Visualize the data in a simpler way<li>Infer some properties of a given data point based on how it relates to other data point (satistical learning)</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/T01V0W4.png" alt="" /></p><h1 id="why-is-it-tricky">Why is it tricky</h1><p>Belongs to unsupervised learning</p><ul><li>No grounds truth available to learn/evaluate quality of the algorithm</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/1vBcxct.png" alt="" /></p><p>How to assess how much data points are related to each other?</p><ul><li>Which criteria (features) are the most relevant<li>Which metrics make the most sense</ul><p>How to assess the soundness of the resulting cluster? Is it relevant ? <img data-proofer-ignore data-src="https://i.imgur.com/ojmJbwz.png" alt="" /></p><h1 id="families-of-clustering-approaches">Families of clustering approaches</h1><ul><li><strong>Distance-based clustering</strong><ul><li>centroid-based approach (k-mean)<li>connectivity-based approaches (based on distance)</ul><li><strong>Density-based clustering</strong><ul><li>set of dense points</ul><li><strong>Distribution-based clustering</strong><ul><li>likelihood of point to belong to the same distribution</ul><li><strong>Fuzzy clustering</strong><ul><li>Relaxed clustering paradigm where a data point can be assigned to multiple clusters with a quantified degree of belongingness metric (fuzzy $c$-means clustering,…).</ul></ul><h1 id="k-means-clustering">$k-$means clustering</h1><p>Partition $n$ observations $x_1,…,x_n$ int $k$ clusters $C={C_1,…,C_k}$ where each observations $x_i$ belongs to the cluster $C_{j*}$ whose mean $\mu_{j*}$ is the closest: $x_i\in S_{j*}$ with $j^{*}=argmin_j\Vert x_i-\mu_j \Vert_2$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/JvfTtlf.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/LVIwYHS.png" alt="" /></p><p>La croix represente le centre, on veut la plus petite distance depuis un centre pour ajouter un point dans un cluster: <img data-proofer-ignore data-src="https://i.imgur.com/qrvcbBc.png" alt="" /></p><ul><li>Minimize within-cluster sum of squares (variance)<li>Overall optimization problem:</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/ZOvFM5r.png" alt="" /></p><ul><li>NP-hard problem, no guarantee to find the optimal value<li>Stochastic and very sensitive to initial conditions<li>Sensitive to outliers (thank you $L_2$ norm)<li>Probably the most used clustering algorithm</ul><h2 id="k-means-and-voronoi-tesselation">$k-$means and Voronoi tesselation<a href="#k-means-and-voronoi-tesselation"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p><strong>Voronoi tesselation</strong> parition of the Euclidean space relatively to discrete points/seeds. Each region/Voronoi cell is composed of all the points in the space that are closer to the cell seed than any other seed</p><p><img data-proofer-ignore data-src="https://i.imgur.com/5xj4XVA.png" alt="" /></p></div><ul><li>$k$-mean provides a way to obtain a Voronoi tesselation of the input space, where seeds are the final cluster means<li>Alternatively, one case use some pre-computer Voronoi tesselation seeds as initial clusters for $k$-means</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/qtY0EkL.png" alt="" /></p><h2 id="determining-the-optimal-number-of-cluster">Determining the optimal number of cluster<a href="#determining-the-optimal-number-of-cluster"><i class="fas fa-hashtag"></i></a></h2></h2><p>Combien de clusters a vue de nez pour cette image ? <img data-proofer-ignore data-src="https://i.imgur.com/7c42CyF.png" alt="" /></p><blockquote><p>2, 3, 4, 14….</p></blockquote><p>Compute explained variance for an increasing number of clusters $k$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/THW7YRL.png" alt="" /></p><div class="alert alert-success" role="alert"><p>Plot and find the bend of the elbow</p><p><img data-proofer-ignore data-src="https://i.imgur.com/2GEZX4h.png" alt="" /></p></div><div class="alert alert-warning" role="alert"><p>Sometimes it does not work :(</p><p><img data-proofer-ignore data-src="https://i.imgur.com/eelA1rX.png" alt="" /></p></div><h2 id="sometimes-k-means-works">Sometimes, $k$-means works…<a href="#sometimes-k-means-works"><i class="fas fa-hashtag"></i></a></h2></h2><p>But most of the time not as expected.</p><div class="alert alert-warning" role="alert"><p>Probably because the $L_2$ norm that $k$-means tries to minimize</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/l8CifIm.png" alt="" /></p><ul><li>Sensible of <em>curse of dimensionality</em><li>Form “normalized Gaussian” clusters<li>Does not adapt to manifold geometry<li>Sensible to class imbalance<li>Sensible to outliers</ul><h2 id="simple-linear-iterative-clustering">Simple Linear Iterative Clustering<a href="#simple-linear-iterative-clustering"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>A kick-ass image segmentation algorithm using $k$-means</p></blockquote><div class="alert alert-info" role="alert"><p>SLIC superpixels uses a modified $k$-means clustering in the $Labxy$ space to produce $k$ clusters regurlaly sampled and perceptually coherent from a color point of view.</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/gpGsA50.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/t4AZsqN.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/TM6AfmQ.png" alt="" /></p><h2 id="k-medoids-clustering">k-medoids clustering<a href="#k-medoids-clustering"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Possible extension to $k$-means</p></blockquote><div class="alert alert-warning" role="alert"><p>Cluster centroids are not initial data points $\Rightarrow$ can be problematic</p></div><p>$\Rightarrow$ Replace centroids by medoid (points with the smallest distance to all other points in the cluster) <img data-proofer-ignore data-src="https://i.imgur.com/JgMr7rx.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/sgBbLcY.png" alt="" /></p><p>$\Rightarrow$ $k$-medoid algorithm</p><p>Overall objective: find $k$ medoids $m_1, . . . , m_k$ that minimize the partitioning cost</p><p><img data-proofer-ignore data-src="https://i.imgur.com/9nQxiRq.png" alt="" /> <img data-proofer-ignore data-src="https://i.imgur.com/Zeasggl.png" alt="" /></p><h1 id="fuzzy-c-means-clustering">Fuzzy $c$-means clustering</h1><div class="alert alert-warning" role="alert"><p>$k$-means is a <strong>hard</strong> clustering method: each data point 100% belongs to the cluster</p></div><div class="alert alert-info" role="alert"><p><strong>Soft</strong> clustering methods allow each data points to belong to several clusters with various degrees of membership</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/6LY1olR.png" alt="" /></p><h1 id="gaussian-mixture-models">Gaussian mixture models</h1><blockquote><p>$k$-means on steroids</p></blockquote><p>$k$-means works for spherical clusters, but fails in any other cases $\Rightarrow$ try harder Model probability density function $f$ of data as a mixture of multivariate Gaussian</p><p><img data-proofer-ignore data-src="https://i.imgur.com/L9AKAI7.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/1wFKjes.png" alt="" /> Cette courbe est une superposition de plusieurs Gaussiennes: <img data-proofer-ignore data-src="https://i.imgur.com/BQPOTaP.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/agg6coo.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/otkQSp3.png" alt="" /></p><div class="alert alert-danger" role="alert"><p>Il faut pouvoir estimer les facteurs de proportions de ces gaussiennes dans la somme</p></div><h2 id="the-em-algorithm">The EM algorithm<a href="#the-em-algorithm"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="initialization">Initialization<a href="#initialization"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Select $k$ random points as initial means $\hat\mu_1,…,\hat\mu_k$<li>Init all covariance matrices $\hat\sum_1,…,\hat\sum_k$ as whole data sample covariances matrix $\hat\sum$<li>Set uniform mixture weight $\hat\phi_1,…,\hat\phi_k=\frac{1}{k}$</ul><h3 id="alternate-until-convergence">Alternate until convergence<a href="#alternate-until-convergence"><i class="fas fa-hashtag"></i></a></h3></h3><p><strong>Expectation step</strong> Compute membership weight $\hat\gamma_{ij}$ of $x_i$ with respect to $j^{th}$ component $\mathcal N(x\vert\mu_j,\sum_j)$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/klkB7x8.png" alt="" /></p><p><strong>Maximization step</strong> Update weights (in that ordre)</p><p><img data-proofer-ignore data-src="https://i.imgur.com/i59ad2z.png" alt="" /></p><div class="alert alert-success" role="alert"><p>Tadaaaa</p><p><img data-proofer-ignore data-src="https://i.imgur.com/fxyRwVS.png" alt="" /></p></div><h2 id="k-means-vs-gmm">$k$-means vs GMM<a href="#k-means-vs-gmm"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Let the fight begin!</p></blockquote><p><img data-proofer-ignore data-src="https://i.imgur.com/Z4GXU9M.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/DypjLho.png" alt="" /></p><h1 id="kernel-density-estimation">Kernel Density Estimation</h1><blockquote><p>Nonparametric estimation</p></blockquote><div class="alert alert-info" role="alert"><p><strong>Goal</strong> Estimate probability density function $f$ based on observations $x_1,…,x_n$ only, assumed to derive from $f$ <del>otherwise wtf are we doing here</del></p><p><img data-proofer-ignore data-src="https://i.imgur.com/m6D3SSw.png" alt="" /></p></div><p>The kernel density estimator with bandwith $h$ at given point $x$ is given by</p><p><img data-proofer-ignore data-src="https://i.imgur.com/fzYYYkY.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/raArYI8.png" alt="" /></p><h2 id="exemples">Exemples<a href="#exemples"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/YaZHrgS.png" alt="" /></p><h2 id="mean-shift-clustering">Mean shift clustering<a href="#mean-shift-clustering"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>shift each point to the the local density maximum of its KDE, and assign to the same cluster all points that lead to the same maximum</p><p><img data-proofer-ignore data-src="https://i.imgur.com/dfK2m9G.png" alt="" /> <img data-proofer-ignore data-src="https://i.imgur.com/I8GJKaQ.png" alt="" /></p></div><h3 id="exemples-1">Exemples<a href="#exemples-1"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/kqlMnY4.png" alt="" /></p><p>On peut faire la meme chose sur les images en couleurs: <img data-proofer-ignore data-src="https://i.imgur.com/k29t87Y.png" alt="" /></p><h1 id="dbscan">DBSCAN</h1><blockquote><p>Density-base spatial clustering of applications with noise</p></blockquote><ul><li>Divide points into 3 categories (core, boundary, outliers) whether there are at least $minPts$ in their $\epsilon$-neighborhood or not<li>Find the connected component of core points (ignore all non-core points)<li>Assign non-core points to nearby clusters if it is less than $\epsilon$ away, otherwise assign to noise</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/k5bta0x.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/AbrcJDe.png" alt="" /></p><h1 id="spectral-clustering">Spectral clustering</h1><div class="alert alert-info" role="alert"><p>View clustering task as a min-cut operation in a graph</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/Y4Kj0pb.png" alt="" /></p><ul><li>Compute similarity graph (but which one?) of data $x_1,…,x_n$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/S6F7mS5.png" alt="" /></p><ul><li>Compute (weighted) adjacency matrix $W$, degree matrix $D$ and Laplacian matrix $L=D-W$<li>Perform eigendecomposition of $L=(E,\triangle)$</ul><div class="alert alert-info" role="alert"><p><strong>Fact #1</strong> 0 is and eigenvalue of $L$ with multiplicity $\sim#$ connected components in graph, its eigenvectors are identity vectors of those connected components</p><p><img data-proofer-ignore data-src="https://i.imgur.com/VZycsNT.png" alt="" /></p></div><div class="alert alert-info" role="alert"><p><strong>Fact #2</strong> Eigenvector of smallest non-zero eigenvalue (Fiedler vector) gives the normalized min-cut of graph</p><p><img data-proofer-ignore data-src="https://i.imgur.com/TTP3aX6.png" alt="" /></p></div><ul><li>Performs $k$-means clustering of the $k$ smallest eigenvectors $[e_1,…,e_k]_{n\times k}$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Cpn3550.png" alt="" /></p><h1 id="hierarchical-clustering">Hierarchical clustering</h1><blockquote><p>A very natural way of handling data</p></blockquote><div class="alert alert-info" role="alert"><p><strong>Goal</strong> Generate a sequence of nested clusters and ordre them in a hierarchy, represented by a dendogram <img data-proofer-ignore data-src="https://i.imgur.com/j8dnpgU.png" alt="" /></p></div><ul><li>Leaves the dendogram = initial data<li>Inner nodes of the dendogram = clusters</ul><h2 id="exemple">Exemple<a href="#exemple"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/apVnKYK.png" alt="" /></p><h2 id="agglomerative-vs-divise-clustering">Agglomerative vs Divise clustering<a href="#agglomerative-vs-divise-clustering"><i class="fas fa-hashtag"></i></a></h2></h2><p>Agglomerative: merge clusters from fine to coarse (bottom-up approach) <img data-proofer-ignore data-src="https://i.imgur.com/VJunfOZ.png" alt="" /></p><p>Divisive clustering: split clusters (top-down approach) <img data-proofer-ignore data-src="https://i.imgur.com/eypuhD0.png" alt="" /></p><ul><li>Needs some heuristics to avoid the $O(2^n)$ ways of spitting each cluster…<li>Not so used in practice</ul><h2 id="bestiarity">Bestiarity<a href="#bestiarity"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/WKmG55N.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/SnuNeX5.png" alt="" /></p><h1 id="overall-comparison-of-all-methods">Overall comparison of all methods</h1><p><img data-proofer-ignore data-src="https://i.imgur.com/C0N9moV.png" alt="" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s8/'>Image S8</a>, <a href='/cours/categories/iml/'>IML</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/scia/" class="post-tag no-text-decoration" >SCIA</a> <a href="/cours/tags/iml/" class="post-tag no-text-decoration" >IML</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a> <a href="/cours/tags/clustering/" class="post-tag no-text-decoration" >clustering</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=IML: Unsupervised clustering - Cours&url=https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=IML: Unsupervised clustering - Cours&u=https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=IML: Unsupervised clustering - Cours&url=https://lemasyma.github.io/cours/posts/iml_dimensionality_clustering/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/iml_introduction/"><div class="card-body"> <em class="timeago small" date="2021-03-17 11:00:00 +0100" >Mar 17, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Introduction</h3><div class="text-muted small"><p> Lien de la note Hackmd Motivation What is learning ? It’s all about evolving Definition Learning: Improver over experience to perform better in new situations. Quoting S. Bengio Learning ...</p></div></div></a></div><div class="card"> <a href="/cours/posts/iml_dimensionality_reduction/"><div class="card-body"> <em class="timeago small" date="2021-03-19 13:00:00 +0100" >Mar 19, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Dimensionality reduction</h3><div class="text-muted small"><p> Lien de la note Hackmd Why do we care ? We have at hand $n$ points $x1,…, xn$ lying in some N-dimensional space, $x_i \in\mathbb R^n , \forall i = 1, . . . , n,$ compactly written as a $n × N$ mat...</p></div></div></a></div><div class="card"> <a href="/cours/posts/iml_supervised_learning/"><div class="card-body"> <em class="timeago small" date="2021-04-16 14:00:00 +0200" >Apr 16, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Supervised learning</h3><div class="text-muted small"><p> Lien de la note Hackmd Supervised learning Supervised learning: process of teaching a model by feeding it input data as well as correct output data. The model will (hopefully) deduce a correct...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/tifo_morpho_maths_exemples/" class="btn btn-outline-primary" prompt="Older"><p>TIFO: Introduction a la morphologie mathematique, exemples</p></a> <a href="/cours/posts/coin_coin/" class="btn btn-outline-primary" prompt="Newer"><p>COIN: Communication Interpersonnelle</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
