<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="IML: Supervised learning" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Supervised learning" /><meta property="og:description" content="Supervised learning" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/iml_supervised_learning/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/iml_supervised_learning/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-04-16T14:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="IML: Supervised learning" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-10-03T16:45:54+02:00","datePublished":"2021-04-16T14:00:00+02:00","description":"Supervised learning","headline":"IML: Supervised learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/iml_supervised_learning/"},"url":"https://lemasyma.github.io/cours/posts/iml_supervised_learning/"}</script><title>IML: Supervised learning | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>IML: Supervised learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>IML: Supervised learning</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-04-16 14:00:00 +0200" data-toggle="tooltip" data-placement="bottom" title="Fri, Apr 16, 2021, 2:00 PM +0200" >Apr 16, 2021</em> </span> <span> Updated <em class="timeago" date="2021-10-03 16:45:54 +0200 " data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 3, 2021, 4:45 PM +0200" >Oct 3, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="998 words"> <em>5 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/HknU58EIO">note Hackmd</a></p><h1 id="supervised-learning">Supervised learning</h1><div class="alert alert-info" role="alert"><p><strong>Supervised learning:</strong> process of teaching a model by feeding it input data as well as correct output data. The model will (hopefully) deduce a correct relationship between the input and output</p></div><ul><li>An input/output pair is called <em>labeled data</em><ul><li>All pairs form the <em>training set</em></ul><li>Once training is completed, the model can infer new outputs if fed with new inputs.</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Qldp6N6.png" alt="" /></p><p>Given some training data ${x_i,y_i}^n_{i=1}$, supervised learning aims at finding a model $f$ correctly mapping input data $x_i$ to their respective output</p><ul><li>The model can predict new outputs<li>The learning mechanism is called <em>regression</em> or <em>classification</em></ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Xfx2W4Y.png" alt="" /></p><h1 id="managing-data-for-supervised-learning">Managing data for supervised learning</h1><p>Hide some data out during training ($\simeq20\%$ data) to further evaluate model performances $\Rightarrow$ train/test split Use validation set ($\simeq15\%$ data) if parameters are iteratively adjusted $\Rightarrow$ tain/validation split</p><p><img data-proofer-ignore data-src="https://i.imgur.com/dNjoxrs.png" alt="" /></p><h2 id="stratified-sampling">Stratified sampling<a href="#stratified-sampling"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>For classification purposes</p></blockquote><p>CLasses might be imbalanaced $\Rightarrow$ use stratified sampling to guarantee a fair balance of train/est samples for each class</p><p><img data-proofer-ignore data-src="https://i.imgur.com/LEWGAc9.png" alt="" /></p><h1 id="regression">Regression</h1><blockquote><p>The art of predicting values</p></blockquote><div class="alert alert-info" role="alert"><p><strong>Regression</strong>: the output value to predict $y$ is quantitative (real number)</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/ASmFdgA.png" alt="" /></p><p>$\Rightarrow$ How to mathematically model the relationship between predictor variables $x_i$ and their numerical output $y_i$ ?</p><h2 id="linear-regression">Linear regression<a href="#linear-regression"><i class="fas fa-hashtag"></i></a></h2></h2><p>Sometimes, there’s no need for a complicated model…</p><p><img data-proofer-ignore data-src="https://i.imgur.com/KnOVw16.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/v2HuFrX.png" alt="" /></p><h2 id="ordinary-least-squares">Ordinary Least Squares<a href="#ordinary-least-squares"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/o2HCOeb.png" alt="" /></p><h2 id="anscombes-quartet">Anscombes’ quartet<a href="#anscombes-quartet"><i class="fas fa-hashtag"></i></a></h2></h2><p>For all 4 datasets ${(x_1,y_1),(x_2,y_2),…,(x_{11},y_{11})}$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/5GCBu59.png" alt="" /></p><p>Le 3e regression a une <em>donnee aberrante</em>, cad une donnee tres eloignee des autres qui risque de fausser la regression (probablement du au capteur qui s’est chie dessus)</p><p>$\Rightarrow$ Linear regression line $y=3+0.5x$ and $R^2=0.67$ are the <strong>SAME</strong> for all 4 datasets</p><h2 id="least-absolute-deviation">Least absolute deviation<a href="#least-absolute-deviation"><i class="fas fa-hashtag"></i></a></h2></h2><p>Linear regression by OLS is sensitive to outliers (tj=hank you $L_2$ norm…)</p><p><img data-proofer-ignore data-src="https://i.imgur.com/GLH1gJh.png" alt="" /> <img data-proofer-ignore data-src="https://i.imgur.com/joBDMuK.png" alt="" /></p><p><em>Is it a good idea ?</em></p><ul><li>$\beta_{LAD}$ is the MLE estimator of $\beta$ when noise follows a Laplace distribution<li>No analyticial formula for LAD<ul><li>Harder to find the solution<li>Must use gradient descent approach</ul><li>Solution of LAD <strong>may not be unique</strong></ul><p><img data-proofer-ignore data-src="https://i.imgur.com/OnwIuhP.png" alt="" /></p><div class="alert alert-warning" role="alert"><p>Toutes les droites dans le cone sont optimales</p></div><h2 id="adding-some-regularization">Adding some regularization<a href="#adding-some-regularization"><i class="fas fa-hashtag"></i></a></h2></h2><p>Add apenalty term to OLS to eforce particular properties to $\hat\beta$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/2Kcnvje.png" alt="" /></p><h2 id="from-regression-to-classification">From regression to classification<a href="#from-regression-to-classification"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="logistic-regression">Logistic regression<a href="#logistic-regression"><i class="fas fa-hashtag"></i></a></h3></h3><p>Linear regression predicts a real value $\hat y$ based on predictor variables $x=(x^{(1)},…,x^(k))$</p><ul><li>Does not work is $y$ is boolean<li>$P(y=1)=p$ and $P(y=0)=1-p$<li>Use logistic regression instead</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/lLIaSGd.png" alt="" /></p><p>Linear relationship between predictor variables and logit of event:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/JA8tFGp.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/bsuCgNc.png" alt="" /></p><h1 id="k-nearest-neighbors">k-nearest neighbors</h1><p>k-NN classifier simply assigns test data points to the majority class in the neighborood of the test points</p><ul><li>no real training step</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/lv8noT8.png" alt="" /></p><p>Result: <img data-proofer-ignore data-src="https://i.imgur.com/pBdj6Wt.png" alt="" /></p><h2 id="choosing-k">Choosing k<a href="#choosing-k"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>small k: simple but noisy decision boundary<li>large k: smoothed boundaries but computationally intensive<li>$k=\sqrt{n}$ can also serve as a starting heuristic, refined by cross-validation<li>$k$ should be odd for binary classification</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/ydcwHXm.png" alt="" /></p><h2 id="k-nearest-neighbors-for-regression">k-nearest neighbors for regression<a href="#k-nearest-neighbors-for-regression"><i class="fas fa-hashtag"></i></a></h2></h2><p>Use the k nearest neighbors (in terms of features only) and average to get predicted value</p><p><img data-proofer-ignore data-src="https://i.imgur.com/XDcEhsh.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/ETtZj4O.png" alt="" /></p><h1 id="support-vector-machine">Support Vector Machine</h1><h2 id="linear-svm">Linear SVM<a href="#linear-svm"><i class="fas fa-hashtag"></i></a></h2></h2><p>Training set: \(\{x_i,y_i\}_{i=1}^n\) with $x_i\in\mathbb R^p$ and $y_i\in{-1,+1}$</p><p>Goal: find hyperplane that best divide <em>positive</em> sample and <em>negative</em> samples</p><p><img data-proofer-ignore data-src="https://i.imgur.com/Lw1a9SK.png" alt="" /> <em>Qu’est-ce qu’on a envie de faire ici ?</em> Une moyenne</p><p><img data-proofer-ignore data-src="https://i.imgur.com/DxOBlOY.png" alt="" /></p><div class="alert alert-success" role="alert"><p>On cherche la droite qui <em>passe le plus au centre</em></p><p><img data-proofer-ignore data-src="https://i.imgur.com/yLBeNxo.png" alt="" /></p></div><p>Rappel: produit scalaire de 2 vecteurs colineaires:</p>\[&lt;\vec w, \vec{AB}&gt; = \Vert \vec w\Vert.\Vert \vec{AB}\Vert\]<p><img data-proofer-ignore data-src="https://i.imgur.com/Bg7DrvS.png" alt="" /></p><h2 id="soft-margin-svm">Soft margin SVM<a href="#soft-margin-svm"><i class="fas fa-hashtag"></i></a></h2></h2><p>Data may not be fully linearly separable</p><h2 id="kernel-svm">Kernel SVM<a href="#kernel-svm"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Remember the kernel trick ?</p></blockquote><p>Kernel trick:</p><ul><li>map data points into high dimesional space where they would become linearly separable<li>Effortlessly interfaced with the SVM by replacing dot product $&lt;.,.&gt;$ by kernelizes version $k(.,.)$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Eb8S2SB.png" alt="" /></p><p>Widely used kernel functions:</p><ul><li>Polynomial kernel <img data-proofer-ignore data-src="https://i.imgur.com/jWSsnBZ.png" alt="" /><li>Gaussian RBF kernel <img data-proofer-ignore data-src="https://i.imgur.com/qFneRGj.png" alt="" /><li>Sigmoid kernel <img data-proofer-ignore data-src="https://i.imgur.com/0j7NqQr.png" alt="" /></ul><h2 id="choosing-the-right-kernel-with-the-right-hyperparameters">Choosing the right kernel with the right hyperparameters<a href="#choosing-the-right-kernel-with-the-right-hyperparameters"><i class="fas fa-hashtag"></i></a></h2></h2><p>Kernel $\Rightarrow$ Try linear first. If does not work, RBF is probably the best kernel choice (unless you have some prior information on the geometry of your dataset)</p><p>Hyperparameters ($C$ + kernel parameter(s)) $\Rightarrow$ grid search and cross-validation</p><h1 id="mutliclass-svm">Mutliclass SVM</h1><h2 id="what-if-we-have-more-than-2-classes-">What if we have more than 2 classes ?<a href="#what-if-we-have-more-than-2-classes-"><i class="fas fa-hashtag"></i></a></h2></h2><p>2 possible strategies</p><p><strong>one vs all:</strong> One SVM model <em>per class</em> $\to$ separate the class from all other classes</p><ul><li>Assign new points with <em>winner takes all</em> rule<li>if no outright winner, assign point to the class of closest hyperplane (Platt scaling)</ul><p><strong>One versus one</strong>: one SVM model <em>per pair of classes</em> $\to$ separate 2 classes at a time, ignoring the other data</p><ul><li>assign new points with <em>majority voting</em> rule</ul><p><img data-proofer-ignore data-src="https://i.imgur.comRtugaz.png" alt="" /></p><h1 id="decision-trees">Decision trees</h1><div class="alert alert-info" role="alert"><p>Decision trees use recusrive partitioning to create a sequence of decision rules on input features that nested split of data points</p></div><p>Input features can be numeric (decision $\le$) or categorical (decision $==$)</p><p>Decision node $=$ decision rule for one feature</p><p>Classification tree $\to$ predict class Regression tree $\to$ predict real number</p><p><img data-proofer-ignore data-src="https://i.imgur.com/boFTfRm.png" alt="" /></p><p>On the current node, try to apply all the possible decision rules for all features and select the decision that best split the data Classification tree $\to$ impurity riterion Regression tree $\to$ variance reduction</p><p><img data-proofer-ignore data-src="https://i.imgur.com/QV9u5WY.png" alt="" /></p><p>Final decision boundaries $\equiv$ overlapping orthogonal half planes Decision on new data $\to$ running it down through the branches and assign classes</p><h2 id="how-to-split-a-node">How to split a node<a href="#how-to-split-a-node"><i class="fas fa-hashtag"></i></a></h2></h2><p>Which split should we choose between <img data-proofer-ignore data-src="https://i.imgur.com/upBo3VQ.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/GBwhhZY.png" alt="" /></p><blockquote><p>La reponse est goche</p></blockquote><p><img data-proofer-ignore data-src="https://i.imgur.com/E0oAirn.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/REyBYVW.png" alt="" /></p><div class="alert alert-success" role="alert"><p>Stop recursive partitionning if node is pure</p></div><h2 id="pros-and-cons-of-decision-trees">Pros and cons of decision trees<a href="#pros-and-cons-of-decision-trees"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="pros">Pros<a href="#pros"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Simple decision rules<li>Surprisingly computationally efficient<li>Handle multiclass problems<li>Handle numeric and categorical features at the same time</ul><h2 id="cons">Cons<a href="#cons"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Strongly overfit data<ul><li>Bad predictive accuracy</ul></ul><p><img data-proofer-ignore data-src="https://i.imgur.com/NWFghGJ.png" alt="" /></p><div class="alert alert-success" role="alert"><p><strong>Potential solution</strong> Restrain the growth of the tree by imposing a maximal tree depth</p></div><h2 id="random-forests">Random forests<a href="#random-forests"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Bagging several decision trees</p></blockquote><p>Decision trees are <em>weak</em> classifiers when considered individually</p><ul><li>Average the decision of several of them<ul><li>Compensate their respective errors (<em>wisdom of crowds</em>)</ul><li>Useless if all decision trees see the same data<ul><li>introduce some variability with <em>bagging</em> (bootstrap aggregating)</ul><li>Introduce more variability by selecting only $p$ out of $m$ total features for each split in each decision tree (typically $p=\sqrt{m}$)</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/sypxX62.png" alt="" /></p><p>Final decision is taken by majority voting on all decision tree outputs <img data-proofer-ignore data-src="https://i.imgur.com/ToaBCwg.png" alt="" /></p><h1 id="decision-boundaries-comparison">Decision boundaries comparison</h1><p><img data-proofer-ignore data-src="https://i.imgur.com/iizKHKj.png" alt="" /></p><h2 id="evaluating-regressionclassification-performances">Evaluating regression/classification performances<a href="#evaluating-regressionclassification-performances"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/fvXdKV8.png" alt="" /></p><h1 id="cross-validation">Cross-validation</h1><p>$k$-fold cross validation</p><ul><li>Divide whole data into $k$ non-overlapping sample blocks<li>Train $k$ models on $(k-1)$ training blocks and test on remaining block<li>Compte perf metrics of each model + avergae &amp; standard deviation of all $k$ models</ul><p><img data-proofer-ignore data-src="https://i.imgur.comrYJlCm.png" alt="" /></p><h1 id="confusion-matrix">Confusion matrix</h1><p><img data-proofer-ignore data-src="https://i.imgur.com/KHqLVmX.png" alt="" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s8/'>Image S8</a>, <a href='/cours/categories/iml/'>IML</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/scia/" class="post-tag no-text-decoration" >SCIA</a> <a href="/cours/tags/iml/" class="post-tag no-text-decoration" >IML</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=IML: Supervised learning - Cours&url=https://lemasyma.github.io/cours/posts/iml_supervised_learning/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=IML: Supervised learning - Cours&u=https://lemasyma.github.io/cours/posts/iml_supervised_learning/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=IML: Supervised learning - Cours&url=https://lemasyma.github.io/cours/posts/iml_supervised_learning/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/iml_introduction/"><div class="card-body"> <em class="timeago small" date="2021-03-17 11:00:00 +0100" >Mar 17, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Introduction</h3><div class="text-muted small"><p> Lien de la note Hackmd Motivation What is learning ? It’s all about evolving Definition Learning: Improver over experience to perform better in new situations. Quoting S. Bengio Learning ...</p></div></div></a></div><div class="card"> <a href="/cours/posts/iml_dimensionality_reduction/"><div class="card-body"> <em class="timeago small" date="2021-03-19 13:00:00 +0100" >Mar 19, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Dimensionality reduction</h3><div class="text-muted small"><p> Lien de la note Hackmd Why do we care ? We have at hand $n$ points $x1,…, xn$ lying in some N-dimensional space, $x_i \in\mathbb R^n , \forall i = 1, . . . , n,$ compactly written as a $n × N$ mat...</p></div></div></a></div><div class="card"> <a href="/cours/posts/iml_dimensionality_clustering/"><div class="card-body"> <em class="timeago small" date="2021-04-02 13:00:00 +0200" >Apr 2, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IML: Unsupervised clustering</h3><div class="text-muted small"><p> Lien de la note Hackmd Why do we care Group the input data into clusters that share some characteristics Find pattern in the data (data mining problem) Visualize the data in a simpler w...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/ocvx_differentielle_exercices/" class="btn btn-outline-primary" prompt="Older"><p>OCVX: TD Differentielle</p></a> <a href="/cours/posts/conf_talan/" class="btn btn-outline-primary" prompt="Newer"><p>Conference Talan</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
