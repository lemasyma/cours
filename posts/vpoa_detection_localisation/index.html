<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="VPOA: Detection et localisation" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Lien de la note Hackmd" /><meta property="og:description" content="Lien de la note Hackmd" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-05T09:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="VPOA: Detection et localisation" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-11-12T16:56:30+01:00","datePublished":"2021-11-05T09:00:00+01:00","description":"Lien de la note Hackmd","headline":"VPOA: Detection et localisation","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/"},"url":"https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/"}</script><title>VPOA: Detection et localisation | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>VPOA: Detection et localisation</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>VPOA: Detection et localisation</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-11-05 09:00:00 +0100" data-toggle="tooltip" data-placement="bottom" title="Fri, Nov 5, 2021, 9:00 AM +0100" >Nov 5, 2021</em> </span> <span> Updated <em class="timeago" date="2021-11-12 16:56:30 +0100 " data-toggle="tooltip" data-placement="bottom" title="Fri, Nov 12, 2021, 4:56 PM +0100" >Nov 12, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1680 words"> <em>9 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/ryDODPGDK">note Hackmd</a></p><h1 id="introduction">Introduction</h1><p><em>Qu’est-ce que la vision ?</em></p><ul><li>Percevoir le monde<ul><li>Compose d’objets<li>Structure en 3D<li>Efficacement interprete par l’Homme</ul><li>Receuil d’information<ul><li>Ensemble de points<li>Information sur la lumiere<li>Quantite et contenu spectral</ul><li>Representation du monde reel<ul><li>Les objets n’existent pas sur la retine<li>Processus visuel d’interpretation</ul></ul><p>Vision humaine</p><ul><li><strong>Extremement complexe</strong><li>Active de nombreuses zones du cerveau<li>Possede des capacites nombreuses et variees</ul><p>Vision par ordinateur</p><ul><li>Bio inspiree ou non<li>Production d’un modele algorithmique fonctionnellement similaire aux capacites du cerveau humain<li>Reprosudit seulement un sous-ensemble de capacites</ul><h2 id="quelques-termes">Quelques termes<a href="#quelques-termes"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p><strong>Traitement d’images</strong>:</p><ul><li>manipulation dont l’entree et la sortie sont des images<li>Aide l’humain ou la machine a examiner des images</ul></div><div class="alert alert-info" role="alert"><p>Analyse d’images: analyse ou l’entree est une image mais la sortie est une information</p></div><p>TODO</p><h2 id="processus-dintegration-dans-un-systeme">Processus d’integration dans un systeme<a href="#processus-dintegration-dans-un-systeme"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/B9vP5wM.png" alt="" /></p><h2 id="objectifs-de-la-seance">Objectifs de la seance<a href="#objectifs-de-la-seance"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Trouver/extraire dans l’image des informations pertinentes pour TODO</ul><h3 id="detection-deep-learning">Detection Deep-learning<a href="#detection-deep-learning"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/iY54sij.png" alt="" /></p><blockquote><p>On a entraine le modele a detecter des voitures mais ca ne reconnais que l’avant des camions</p></blockquote><h3 id="detection-et-tracking">Detection et tracking<a href="#detection-et-tracking"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/A7pJ63x.jpg" alt="" /></p><h1 id="geometrie-projective">Geometrie projective</h1><h2 id="coordonnees-homogenes">Coordonnees homogenes<a href="#coordonnees-homogenes"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Systeme de coordonnees pour la geometrie projective</p></div><p>Passer des coordonnees cartesiennes aux coordonnees homogenes:</p>\[\begin{bmatrix} x\\ y \end{bmatrix} \Rightarrow \begin{bmatrix} x\\ y\\ 1 \end{bmatrix}\]<p>Passer des coordonnees homogenes aux coordonnees cartesiennes:</p>\[\begin{bmatrix} u\\ v\\ w \end{bmatrix}= \begin{bmatrix} u / w\\ v / w\\ 1 \end{bmatrix} \Rightarrow \begin{bmatrix} u / w\\ v /w \end{bmatrix} = \begin{bmatrix} x\\ y \end{bmatrix}\]<p><img data-proofer-ignore data-src="https://i.imgur.com/u6CNtwy.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/cSZsGnh.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/aR3SU38.png" alt="" /></p><p>Propriete homogene: $\bar x\sim\lambda \bar x, \forall \lambda\in\mathbb R, \lambda \neq =0$</p><p>Point a l’infini:</p>\[\bar x_{inf} = \begin{bmatrix}x \\ y \\0 \end{bmatrix}\]<p><img data-proofer-ignore data-src="https://i.imgur.com/kzwe2kq.png" alt="" /></p><h2 id="modele-du-plan-projectif">Modele du plan projectif<a href="#modele-du-plan-projectif"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Le plan projectif $P^2$ represente l’espace 3D sur un plan</p></div><p>Intrepretation geometrique de l’homographie</p><p><img data-proofer-ignore data-src="https://i.imgur.com/PeupaZz.png" alt="" /></p><h2 id="homographies">Homographies<a href="#homographies"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/B7uW7aT.png" alt="" /></p><h3 id="estimation-dhomographie">Estimation d’homographie<a href="#estimation-dhomographie"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/wWf5gMc.png" alt="" /></p><p>Estimation par Direct Linear Transform</p><ul><li>Necessite au moins 4 points pour obtenir une solution exacte (2 equations par point et 8 inconnues)<li>Etant donne $n\ge 4$, correspondances de points 2D, determiner $H$ tel que $\bar x_i’=H\bar x_i$</ul><p>Algorithme:</p><ul><li>Pour chaque correspondance $\bar x_i\leftrightarrow \bar x_i’$ pour claculer $A_i$<li>Assembler les matrices $A_i$ en une matrice $9\times 9$: $A$<li>Calculer le SVD de $A$: $U\Sigma V$<li>Solution pour $h$: derniere colonne de $V$<li>Determiner $H$ a partir de $h$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/JrKRkqE.png" alt="" /></p><h2 id="homographie-et-plan-3d">Homographie et plan 3D<a href="#homographie-et-plan-3d"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/muiUmRQ.png" alt="" /></p><p>Le passage de n’importe quel plan vers n’importe quel autre plan (y compris le plan image) est une homographie</p><p><img data-proofer-ignore data-src="https://i.imgur.com/iuhko5j.png" alt="" /></p><h1 id="extraction-de-caracteristiques-locales">Extraction de caracteristiques locales</h1><h2 id="representation-dune-image">Representation d’une image<a href="#representation-dune-image"><i class="fas fa-hashtag"></i></a></h2></h2><p>$I(x, y)$: valeur d’un pixel</p><ul><li>Dans $\mathbb R$ en monochrome<li>Dans $\mathbb R^3$ en couleurs</ul><h3 id="variations">Variations<a href="#variations"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>De luminosite globale: $I(x,y)\to I(x,y)+\alpha$<li>De contraste: $I(x,y)\to\lambda I(x,y)$<li>Par translation</ul><h2 id="comparaison-de-points">Comparaison de points<a href="#comparaison-de-points"><i class="fas fa-hashtag"></i></a></h2></h2><p>Trouver le point le plus similaire</p><p><img data-proofer-ignore data-src="https://i.imgur.com/TIuMbWD.png" alt="" /></p><p>Stereo-vision: on suppose que les points similaires sont sur la meme ligne</p><p><img data-proofer-ignore data-src="https://i.imgur.com/SOmWfvj.png" alt="" /></p><p><em>Comment trouver des points facilement identifiables ?</em></p><blockquote><p>Gradients Contours Etc</p></blockquote><h2 id="kernel">Kernel<a href="#kernel"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Aussi appele noyau ou masque ou matrice de convolution</p></div><ul><li>Permet d’appliquer une operation a l’image<li>Convolution:</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/BEBUXgp.png" alt="" /></p><h2 id="gradient">Gradient<a href="#gradient"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-success" role="alert"><p>Va nous permettre d’obtenir une caracteristique de variabilite autour d’un point</p></div><p>En 1D: <img data-proofer-ignore data-src="https://i.imgur.com/mDCiKnB.png" alt="" /></p><p>En 2D: Filtre de Sobel</p><p><img data-proofer-ignore data-src="https://i.imgur.com/AkWZgZz.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/RT91Spq.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/Norvcpq.png" alt="" /></p><h3 id="laplacien">Laplacien<a href="#laplacien"><i class="fas fa-hashtag"></i></a></h3></h3><p>Detection de contours</p><p><img data-proofer-ignore data-src="https://i.imgur.com/g7YZ4xd.png" alt="" /></p><h2 id="detection-de-coins">Detection de coins<a href="#detection-de-coins"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Zones ou le gradient varie dans plusieurs directions</p></div><p>Detecteur de Harris:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/nHRZMFX.png" alt="" /></p><h3 id="changement-dechelle">Changement d’echelle<a href="#changement-dechelle"><i class="fas fa-hashtag"></i></a></h3></h3><p><em>Comment reconnaitre un point apres un changement d’echelle ?</em></p><p><img data-proofer-ignore data-src="https://i.imgur.com/Vqw9JpI.png" alt="" /></p><div class="alert alert-success" role="alert"><p>Avec des descripteurs !</p></div><h2 id="descripteur">Descripteur<a href="#descripteur"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Moyen de decrire une zone locale de l’image<li>Les “features” sont associees a des points localement distincts dans l’image<li>Les descripteurs sont la signature de ces points</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/GaTjlU0.png" alt="" /></p><h3 id="differences-de-gaussiennes">Differences de Gaussiennes<a href="#differences-de-gaussiennes"><i class="fas fa-hashtag"></i></a></h3></h3><p>Detection de blobs par differences de Gaussiennes:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/ngGG4El.png" alt="" /></p><p>On soustrait l’image floutee a l’image normale</p><p>Invariance par changement d’echelle pour les differences de Gaussiennes:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/oVczY6i.png" alt="" /></p><h3 id="descripteur-sift">Descripteur SIFT<a href="#descripteur-sift"><i class="fas fa-hashtag"></i></a></h3></h3><div class="alert alert-info" role="alert"><p>Scale Invariant Feature Transform</p></div><p>Detection de blobs par la methode des differences de gaussienne</p><p><img data-proofer-ignore data-src="https://i.imgur.com/wPVNwyJ.png" alt="" /></p><h2 id="rotation">Rotation<a href="#rotation"><i class="fas fa-hashtag"></i></a></h2></h2><p><em>Comment reconnaitre un point apres une rotation ?</em></p><h3 id="descripteur-sift-1">Descripteur SIFT<a href="#descripteur-sift-1"><i class="fas fa-hashtag"></i></a></h3></h3><p>Histogramme d’orientations du gradient</p><p><img data-proofer-ignore data-src="https://i.imgur.com/XOLda1b.png" alt="" /></p><ul><li>Decoupage en $4\times 4$ fenetres<li>Histogramme sur 8 directions</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/RuGMtQo.png" alt="" /></p><p>Resume:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/funLyNS.png" alt="" /></p><ul><li>Identification/Matching des keypoints</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/nYLkqcf.png" alt="" /></p><h2 id="autres-descripteurs">Autres descripteurs<a href="#autres-descripteurs"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>MSER (Maximally Stabel Extremal Regions)<li>SURF (Speeded Up Robust Features)<li>ORB (Oriented FAST and Rotated BRIEF)<ul><li>SIFT et SURF sont brevetes<li>OpenCV a invente ORB comme alternative open-source et gratuite</ul><li>BRIEF<li>FAST<li>KAZE<li>etc</ul><h2 id="extraction-de-caracteristiques-locales-1">Extraction de caracteristiques locales<a href="#extraction-de-caracteristiques-locales-1"><i class="fas fa-hashtag"></i></a></h2></h2><p><em>Comment valoriser l’information ?</em></p><ul><li>Reconaissance/detection d’objets<li>Estimation de la pose/localisation<ul><li>De la projection d’objets 3D sur le plan Image<li>D’objets 3D dans le monde<li>De la camera dans le monde</ul><li>Estimation du mouvement</ul><h1 id="reconaissance-dobjets">Reconaissance d’objets</h1><p>Objectifs:</p><ul><li>Detection d’instances d’objets par points d’interet<ul><li>Transformee de Hough<li>RANSAC</ul><li>Detection de categories d’objets<ul><li>Sac de mots visuels</ul></ul><p><img data-proofer-ignore data-src="https://i.imgur.com/ILLjg3c.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/nvH682P.png" alt="" /></p><h2 id="transformee-de-hough">Transformee de Hough<a href="#transformee-de-hough"><i class="fas fa-hashtag"></i></a></h2></h2><p>A l’origine, detection de lignes droites:</p><ul><li>Chaque point votre pour “toutes” les lignes qui passent par lui<li>Les votes sont accumules<li>Un maximum local corresponds a des lignes candidates</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/hcSfnBE.png" alt="" /></p><p>Possible probleme: trouver le maximum vrai</p><ul><li>Mean shift<li>Gaussian convolution<li>…</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/BTxhMam.png" alt="" /></p><p>Transformee de Hough generalisee</p><ul><li>Contour/forme arbitraire<ul><li>Choix d’un point de reference our le contour (e.g. le centre)<li>Pour chaque point du contour, se rappeler de sa position par rapport au point de reference<li>Calcul de l’angle</ul></ul><h2 id="ransac">RANSAC<a href="#ransac"><i class="fas fa-hashtag"></i></a></h2></h2><p>Cas de lignes</p><ul><li>Choix aleatoire de droites<li>Vote base sur le nombre de points proches de la ligne<li>todo</ul><p>Amelioration</p><ul><li>Elimination de outliers par RANSAC<li>Amelioration de l’estimation de RANSAC TODO</ul><h3 id="comparaison">Comparaison<a href="#comparaison"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-proofer-ignore data-src="https://i.imgur.com/vfwAGTw.png" alt="" /></p><h2 id="reconnaissance-dobjets-3d">Reconnaissance d’objets 3D<a href="#reconnaissance-dobjets-3d"><i class="fas fa-hashtag"></i></a></h2></h2><p>Base sur la detection de features</p><ul><li>3 features minimum sont necessaires pour la reconnaissance</ul><p>Reconnaissance d’objet 3D base sur la detection d’un modele 3D connu</p><p><img data-proofer-ignore data-src="https://i.imgur.com/Cwgmt5I.png" alt="" /></p><h2 id="mots-visuels">Mots visuels<a href="#mots-visuels"><i class="fas fa-hashtag"></i></a></h2></h2><p>Principe: extraction de features locales a partir d’un certain nombre d’images</p><p><img data-proofer-ignore data-src="https://i.imgur.com/0UOpkQy.png" alt="" /></p><ul><li>Cartographie des descripteurs vers de mots visuels qui quantifient l’espace des features<li>Le centre des clusters definissent les prototypes de mots</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/fftVGoo.png" alt="" /></p><ul><li>Determination de quel mot doit etre assigne a chaque nouvelle region de l’image en trouvant le centre du cluster le plus proche</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/dVROtkP.png" alt="" /></p><h3 id="exemple">Exemple<a href="#exemple"><i class="fas fa-hashtag"></i></a></h3></h3><p>Chaque groupe de patch correspond a un meme mot visuel</p><p><img data-proofer-ignore data-src="https://i.imgur.com/ynnmD0x.png" alt="" /></p><ul><li>Resumer une image entiere a partir de sa distribution de presence de mots<li>Analogue a un sac de mots souvent utilise pour les documents de texte</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/RmeoXEY.png" alt="" /></p><p>Creation d’un vocabulaire visuel:</p><ul><li>Repertorier un ensemble de mots visuels (~ dictionnaire)<li>Differentes strategies<ul><li>Apprentissage supervise<li>Deep learning<li>etc</ul></ul><p>Strategies d’echantillonnage:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/ixWAtiB.png" alt="" /></p><p>Arbre de vocabulaire:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/iCpzPCg.png" alt="" /></p><ul><li>Remplissage:</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/HEpcWhN.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/bDsQ99t.png" alt="" /></p><p>Probleme:</p><ul><li>certains mots visuels sont discriminants<li>D’autres apparaissent dans de nombreuses images</ul><p>Calcul d’un poids pour chaque mot visuel</p><ul><li>Le poid correspond a la quantite d’info esperee<li>Normalisation des histogrammes en fonction de ce poids</ul><h1 id="estimation-du-mouvement">Estimation du mouvement</h1><h2 id="objectifs">Objectifs<a href="#objectifs"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Detection/ Estimation du mouvement dans la scene<ul><li>Du au mouvement de la cmaera<li>Mouvement des objets</ul><li>Perception du mouvement apparent<ul><li>Champs des vecteurs de deplacement<li>Flux optique</ul></ul><h2 id="flux-optique">Flux optique<a href="#flux-optique"><i class="fas fa-hashtag"></i></a></h2></h2><p>Difficultes de l’estimation du flux optique</p><ul><li>Ambiguites</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/jceMWVx.png" alt="" /></p><ul><li>Premiere image: deplacement de drone, champ de vecteurs = deplacement des pixels<li>Si on aune voiture qui se rapproche de nous, on peut segementer la voiture du reste de l’image a partir de champs de vecteurs</ul><p>Interpretation du flux:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/RUSDZIj.png" alt="" /></p><p>Vitesse:</p><ul><li>La camera se deplace a une vitesse $(X’, Y’, Z’)$ par rapport a la scene<li>Si on derive les equations de perspective on a donc:</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/ufEgE5x.png" alt="" /></p><h3 id="interpretation-du-flux">Interpretation du flux<a href="#interpretation-du-flux"><i class="fas fa-hashtag"></i></a></h3></h3><p>Translation pure selon $X$ (ou $Y$)</p><p><img data-proofer-ignore data-src="https://i.imgur.com/SAjpekQ.png" alt="" /></p><p>Translation pure selon $Z$:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/7KY4y9P.png" alt="" /></p><p>Cas general:</p><ul><li>Donne la direction du deplacement<li>Mouvement $(X’, Y’, Z’)$<li>Soit $[X_0, Y_0, Z_0]^T$ un point de la scene, apres un temps $t$, il est projete sur l’image au point $[u_t, v_t]^t$ avec:</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/oZhsKcm.png" alt="" /></p><p>Temps avant collision:</p><ul><li>Mesure de la taille d’‘un element $\lambda = f\frac{\Lambda}{z}$</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/mJblqFp.png" alt="" /></p><h2 id="bundle-adjustment">Bundle adjustment<a href="#bundle-adjustment"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Nous avons pour l’instant uniquement utilise des paires d’image pour obtenir une information de profondeur<li>Dans le cas general, il est possible d’utiliser $N\gt 2$ images/cameras</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/8LGDpMS.jpg" alt="" /></p><div class="alert alert-info" role="alert"><p>Le Bundle (block) adjustment ou ajustement de faisceaux en bloc, est une methode de resolution au sens des moindres carres les coordonnees 3D des points et aligner les images</p><p>Plusieurs images sont corrigees “en bloc”</p></div><p>Principe:</p><ul><li>Demarrer avec une approximation initiale<li>Projeter les points 3D sur les plans images des cameras<li>Comparaison avec la mesure<li>Ajustement pour minimiser l’erreur</ul><div class="alert alert-warning" role="alert"><p>Le BA est une approche non-lineaire de resolution par moindres carres:</p><ul><li>$\bar x_{ij} + \hat e_{x_{ij}} = \lambda_{ij}P_{ij}\bar X_i$<li>Avec $\hat e_{x_{ij}}$ l’erreur de mesure du point $\bar X_i$<li>$i l’indice du point, $j$ l’indice de la camera</ul></div><p>Elimination du facteur d’echelle:</p><ul><li>$\bar x_{ij} + \hat e_{x_{ij}} = \frac{P_{1:2<em>{ij}}\bar X_i}{P</em>{3_{ij}}\bar X_i}$<li>Resolution par SVD</ul><h2 id="odometrie-visuelle">Odometrie Visuelle<a href="#odometrie-visuelle"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Estimation du mouvement de la camera par rapport au monde</p></div><p>Necessaire a de nombreuses applications</p><ul><li>Pas de GPS<ul><li>Genre sur Mars</ul><li>IMU et/ou odometrie des roues insuffisants<ul><li>On va mettre des encodeurs sur les roues et lire de combien s’est deplace la roue</ul></ul><p>Odometrie:</p><ul><li>Estimation du mouvement base sur le modele cinematique<li>Extansion a la vision</ul><p>Triangulation</p><ul><li>Permet de connaitre la position 3D d’un point</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/vrUQGxx.png" alt="" /></p><div class="alert alert-danger" role="alert"><p>Principe:</p><ul><li>Trouver des correspondances de points entre 2 images successives: utilisation de descripteurs<li>Si le monde est statique et les points bien apparies alors on peut estimer la transformation $(R,t)$ a partir des parametres extrinseque<li>Probleme de minimisation de l’erreur de reprojection<ul><li>Necessite d’une bonne calibration</ul></ul></div><div class="alert alert-warning" role="alert"><p>Peu robuste aux rotations pures</p><ul><li>On compense ave l’IMU et l’odometrie des roues</ul></div><p>Pseudo code:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Capturer l'image I_k
Calculer les correspondannce entre I_k-1 et I_k
Calcul de la matrice essentielle E et que p^TEp' = 0
Decomposition de E en R_k et t_k par SVD
Calcul du modele 3D (coordonnees des points de correspondance)
Redimensionnement de t_k pour prendre en compte l'echelle
    Attention ! p^TEp' = 0 &lt;=&gt; lambda p^TEp'=0
k = k + 1
</pre></table></code></div></div><h2 id="slam">SLAM<a href="#slam"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Simultaneous Localization and Mapping</p></div><ul><li>Si une carte est fournie, possibilite de se localiser dans cette carte uniquement<li>Si une position est fournie, possibilite de creer une carte de l’environnement<li>Le SLAM est l’estimation conjointe d’une carte de l’environnement et de la position de la camera dans cette carte<li>Necessaire des qu’un robot doit explorer un environnement totalement ou partiellement inconnu<li>Amelioration de l’odometrie visuelle<li>On sauvegarde les coordonnees des points 3D extraits et de leurs caracteristiques locales<li>Creation d’une carte de features 3D</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/FLT34Uv.png" alt="" /></p><p>3 categories principales de methodes pour l’estimation de l’etat:</p><ul><li>Extended Kalman Filter<li>Particle Filter<li>Least Squares =&gt; Graph-based SLAM</ul><p>Graph-based SLAM</p><ul><li>Utilisation d’un graphe pour representer les variables et les relations entre ces variables<li>Pose Graph: contient uniquement les positions<li>Factor Graph: contient des facteurs reliant les differentes variables</ul><p>Pose Graph:</p><ul><li>Chaque noeud represente une pose<li>Les liaisons entre ces noeuds contiennent leur relation spatiale<li>L’optimisation essaye de trouver la position optimale d’un noeud qui minimise l’erreur introduite dans les liaisons</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Fu6J4Sf.png" alt="" /></p><p><em>Quels sont les avantages ?</em></p><ul><li>Meilleure estimation des coordonnees 3D des points/features<li>Fermeture de boucles (Loop-closure)<li>Plus robuste face aux rotations pures</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/i5zUBRl.png" alt="" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s9/'>Image S9</a>, <a href='/cours/categories/vpoa/'>VPOA</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/s9/" class="post-tag no-text-decoration" >S9</a> <a href="/cours/tags/vpoa/" class="post-tag no-text-decoration" >VPOA</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=VPOA: Detection et localisation - Cours&url=https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=VPOA: Detection et localisation - Cours&u=https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=VPOA: Detection et localisation - Cours&url=https://lemasyma.github.io/cours/posts/vpoa_detection_localisation/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/vpoa_perception_3d/"><div class="card-body"> <em class="timeago small" date="2021-11-03 09:00:00 +0100" >Nov 3, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>VPOA: Perception 3D</h3><div class="text-muted small"><p> Lien de la note Hackmd Introduction Magellium Observation de la terre Analyse et traitement de donnees satelittes Geo-information Imagerie et Applications Es...</p></div></div></a></div><div class="card"> <a href="/cours/posts/vpoa_analyse_3d/"><div class="card-body"> <em class="timeago small" date="2021-11-04 09:00:00 +0100" >Nov 4, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>VPOA: Analyse de l'environnement 3D</h3><div class="text-muted small"><p> Lien de la note Hackmd Introduction On sait obtenir de l’info en 3D sous la forme d’un nuage de points (sous forme de nuage de points, carte de disparite). Comment valoriser cette donnee ? On...</p></div></div></a></div><div class="card"> <a href="/cours/posts/imed2_tp3/"><div class="card-body"> <em class="timeago small" date="2021-11-25 09:00:00 +0100" >Nov 25, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IMED2: TP3</h3><div class="text-muted small"><p> Reconstruction tomographique (2/3) Vous avez tous les outils pour comprendre la reconstruction tomographique 2D en géométrie parallèle dans le cadre idéal : à partir des lignes intégrales (transfo...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/vpoa_analyse_3d/" class="btn btn-outline-primary" prompt="Older"><p>VPOA: Analyse de l'environnement 3D</p></a> <a href="/cours/posts/tvid_pixel_a_image/" class="btn btn-outline-primary" prompt="Newer"><p>TVID: Du pixel a l'ecran</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
