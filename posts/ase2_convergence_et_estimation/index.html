<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="ASE2: Convergence et estimation - 2" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Convergence et estimation - 2" /><meta property="og:description" content="Convergence et estimation - 2" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-03-10T09:30:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ASE2: Convergence et estimation - 2" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-10-03T16:45:54+02:00","datePublished":"2021-03-10T09:30:00+01:00","description":"Convergence et estimation - 2","headline":"ASE2: Convergence et estimation - 2","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/"},"url":"https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/"}</script><title>ASE2: Convergence et estimation - 2 | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>ASE2: Convergence et estimation - 2</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ASE2: Convergence et estimation - 2</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-03-10 09:30:00 +0100" data-toggle="tooltip" data-placement="bottom" title="Wed, Mar 10, 2021, 9:30 AM +0100" >Mar 10, 2021</em> </span> <span> Updated <em class="timeago" date="2021-10-03 16:45:54 +0200 " data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 3, 2021, 4:45 PM +0200" >Oct 3, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1346 words"> <em>7 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/HJjhGXImd">note Hackmd</a></p><h1 id="introduction">Introduction</h1><p>Le problème central de l’estimation en statistique est le suivant : disposant d’observations sur un échantillon de taille $n$ on souhaite en déduire les propriétés de la population dont il est issu.</p><p>On cherchera à estimer, par exemple, la moyenne d’une population à partir de la moyenne d’un échantillon. Le mode de tirage le plus important est l’échantillonnage aléatoire simple correspondant à des tirages équiprobables et indépendants les uns des autres.</p><p>L’une des premières qualités d’un estimateur est d’être convergent en probabilité vers le paramètre à estimer. Un échantillon de $X$ est une suite de variables aléatoires $(X_1,X_2,…,X_n)$ indépendantes et de même loi que $X$. Un estimateur d’un paramètre $\theta$ inconnu est une fonction qui dépend de l’échantillon et donc doit converger en probabilité vers le paramètre $\theta$. La précision d’un estimateur sera mesuré par sa variance.</p><h1 id="rappels-de-la-loi-gamma-et-la-loi-normale">Rappels de la loi Gamma et la loi Normale</h1><div class="alert alert-info" role="alert"><p>On dit qu’une variable aléatoire positive $X$ suit une loi gamma de paramètre $r$, notée $\gamma_r$ si sa densité est donnée par :</p>\[f(x) = \frac{1}{\Gamma(r)}e^{-x}x^{r -1}\]<p>Avec $\Gamma(x) = \int_0^{+\infty}e^{-t}t^{x-1}dt$ (fonction Gamma) definie pour $x\gt0$</p></div><h2 id="propriétés-de-la-fonction-gamma">Propriétés de la fonction Gamma<a href="#propriétés-de-la-fonction-gamma"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>$\Gamma(x+1)=x\Gamma(x)$ (intégration par partie)<li>$\Gamma(1) = 1$<li>$\Gamma(n+1)=n!$<li>$\Gamma(k+\frac{1}{2})=\frac{1.3.5…..(2k-1)}{2^k}\Gamma(\frac{1}{2})$<li>$\Gamma(\frac{1}{2}) = \sqrt{\pi}$</ol><p>Espérance de la loi $\gamma_r$ : Soit $X$ une variable aléatoire suivant la loi gamma de paramètre $r$. \(E(X)=\frac{1}{\Gamma(r)}\int_0^{+\infty}te^{-t}t^{r-1}dt=\frac{1}{\Gamma(r)}\int_0^{+\infty}t^{r}e^{-t}dt=\frac{\Gamma(r+1)}{\Gamma(r)}=r\)</p><p>Variance de la loi $\gamma_r$ : $V(X) = E(X^2)-E^2(X)$</p>\[E(X^2)=\frac{1}{\Gamma(r)}\int_0^{+\infty}t^2e^{-t}t^{r-1}=\frac{1}{\Gamma(r)}\int_0^{+\infty}t^{r+1}e^{-t}dt = \frac{\Gamma(r+2)}{\Gamma(r)} = r(r+1)\]<p>Donc $V(X) = r(r+1)-r^2 =r$.</p><h2 id="loi-normale-de-paramètresmsigma">Loi Normale de paramètres$(m,\sigma)$<a href="#loi-normale-de-paramètresmsigma"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>On dit qu’une variable aléatoire $X$ suit la loi normale notée $\mathcal N(m,\sigma)$ si sa densité est</p>\[f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-m}{\sigma})^2}\]<p>où:</p><ul><li>$m = E(X)$<li>$\sigma = \sqrt{V(X)}$ (écart type)</ul></div><p>Avec le changement de variable $U=\frac{X-m}{\sigma}$ (variable normale centrée réduite), la densité de $U$ est:</p>\[f(u) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}u^2}\]<h3 id="demonstration">Demonstration<a href="#demonstration"><i class="fas fa-hashtag"></i></a></h3></h3><p>Montrons que $V(U) = 1$.</p><p>On a: \(V(U) = E(U^2) = \int_{-\infty}^{+\infty}\frac{1}{\sqrt{2\pi}}u^2e^{-\frac{1}{2}u^2}du = \frac{2}{\sqrt{2\pi}}\int_0^{+\infty}u^2e^{-\frac{1}{2}u^2}du\)</p><p>Posons $t=\frac{u^2}{2}$, $dt = udu$</p><p>\(V(U) = \frac{2}{\sqrt{2\pi}}\int_0^{+\infty}2te^{-t}\frac{dt}{\sqrt{2t}} = \frac{2}{\sqrt{\pi}}\Gamma(\frac{3}{2})=\frac{2}{\sqrt{\pi}}\frac{1}{2}\Gamma(\frac{1}{2})\) Donc $V(U) = \frac{1}{\sqrt{\pi}}\sqrt{\pi}=1$</p><h2 id="moments-de-la-loi-normale-centrée-réduite">Moments de la loi normale centrée réduite<a href="#moments-de-la-loi-normale-centrée-réduite"><i class="fas fa-hashtag"></i></a></h2></h2><p>Soit $U$ une variable normale centrée réduite, on appelle moment d’ordre $k$ de $U$ : $u_k=E(U^k)$</p><ul><li>Si $k=2p+1$ alors $u_{2p+1} = 0$ (car fonction impaire)<li>Si $k=2p$ alors $u_{2p} = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}u^{2p}e^{-\frac{1}{2}u^2}du = \frac{2}{\sqrt{2\pi}}\int_0^{+\infty}u^{2p}e^{\frac{1}{2}u^2}du$</ul><p>Posons $t=\frac{u^2}{2}$, $dt=udu$</p>\[u_{2p} = \frac{2}{\sqrt{2\pi}}\int_0^{+\infty}(2t)^pe^{-t}\frac{dt}{\sqrt{2t}}=\frac{2^p}{\sqrt{\pi}}\int_0^{+\infty}t^{p-\frac{1}{2}}e^{-t}dt = \frac{2^p}{\sqrt{\pi}}\Gamma(p+\frac{1}{2})\\ \text{Or } \Gamma(p+\frac{1}{2}) = \frac{1.3.5...(2p-1)}{2^p}\Gamma(\frac{1}{2}) \text{ et } \Gamma(\frac{1}{2})=\sqrt{\pi}\\ \text{Donc } u_{2p}=1.3.5....(2p-1)=\frac{(2p)!}{2^pp!}\]<h1 id="fonctions-caractéristiques">Fonctions caractéristiques</h1><div class="alert alert-info" role="alert"><p><strong>Definition</strong>: la fonction caractéristique d’une variable aléatoire réelle $X$ est la transformée de Fourier de sa loi de probabilité. Elle est notée $\phi_X(t)$ et on a:</p>\[\phi_X(t)=E(e^{itX}) \text{ (} i \text{ complexe)}\]</div><p>Si $X$ est une variable à densité ($X$ est une v.a continue de densité $f$) alors :</p>\[\phi_X(t) = \int_{\mathbb R}e^{itx}f(x)dx\]<p>Si $X$ est une variable discrète alors sa fonction caractéristique est :</p>\[\phi_X(t)=\sum_ke^{itk}P(X=k)\]<h2 id="propriétés">Propriétés<a href="#propriétés"><i class="fas fa-hashtag"></i></a></h2></h2><ol><li>$\phi_{\lambda x} = \phi_X(\lambda t)$, $\forall\lambda$ un scalaire<li>$\phi_{X+a}(t)=e^{ita}\phi_X(t)$, $\forall a$ un scalaire<li>Si $X$ est une variable aléatoire d’espérance $m$ et d’écart type $\sigma$ et $U = \frac{X-m}{\sigma}$</ol>\[\phi_{\frac{X-m}{\sigma}} = \phi_U(t) = e^{-\frac{itm}{\sigma}}\phi_X(\frac{t}{\sigma})\]<h3 id="remarque">Remarque<a href="#remarque"><i class="fas fa-hashtag"></i></a></h3></h3><p>La fonction caractéristique se prête bien aux additions de variables aléatoires indépendantes.</p><p>Si $X$ et $Y$ sont deux variables aléatoires indépendantes alors \(\phi_{X+Y}(t) = \phi_X(t)\phi_Y(t)\\ \text{En effet } \phi_{X+Y}(t) = E(e^{it(X+Y)})=E(e^{itX}e^{itY})\\ \text{Or } X \text{ et } Y \text{ sont indépendantes } E(e^{itX}e^{itY}) = E(e^{itX})E(e^{itY})\\ \text{Donc } \phi_{X+Y}(t)=\phi_X(t)+\phi_Y(t)\)</p><h2 id="proposition">Proposition<a href="#proposition"><i class="fas fa-hashtag"></i></a></h2></h2><p>Soit $X$ une variable aléatoire de fonction de répartition $\phi_X(t)$.</p><p>On a $\phi_x(0)=1$ et $\frac{d^k\phi_X}{dt^k}(0)=\phi_X^{(k)}(0)=i^kE(X^k)$</p><h3 id="démo">Démo<a href="#démo"><i class="fas fa-hashtag"></i></a></h3></h3><p>Supposons que $X$ est une variable continue de densité $f$</p><p>On a:</p>\[\phi_X(t)=\int_{\mathbb R}e^{itx}f(x)dx\Rightarrow\phi_X(0)=\int_{\mathbb R}f(x)dx=1 \text{ (car f est une densité)}\\ \text{En dérivant } \phi_X(t) \text{ par rapport à t: } \phi_X'(t)=i\int_{\mathbb R}xe^{itx}f(x)dx\\ \text{Si } t=0: \phi_X'(t)i\int_{\mathbb R}xf(x)dx=iE(x)\\ \text{Si on dérive 2 fois, } \phi_X^{(2)}(t)=\int_{\mathbb R}(itx)^2e^{itx}f(x)dx\\ \text{En dérivant k fois par rapport à t: }\phi_X(t)^{k}(t)=\int_{\mathbb R}(ix)^ke^{itx}f(x)dx\\ \text{Donc } \phi_x^{(k)}(0)=(i^k)\int_{\mathbb R}x^kf(x)dx=i^kE(X^k),\forall k\in\mathbb N\]<h2 id="formule-de-mac-laurin">Formule de Mac-Laurin<a href="#formule-de-mac-laurin"><i class="fas fa-hashtag"></i></a></h2></h2><p>Si $\phi_X(t)$ est indéfiniment dérivable on a:</p>\[\phi_X(t)=\sum_{k=0}^{+\infty}\frac{t^k}{k!}\phi_X^{(k)}(0)=\sum_{k=0}^{+\infty}\frac{t^k}{k!}i^kE(X^k)\]<h3 id="exemple-1">Exemple 1<a href="#exemple-1"><i class="fas fa-hashtag"></i></a></h3></h3><p>Soit X une variable aléatoire continue de densité:</p>\[f(x)= \begin{cases} e^{-x} &amp;\text{si } x\gt0\\ 0 &amp;\text{sinon} \end{cases}\]<p>Déterminer la fonction caractéristique de $X$</p><details> <summary>Solution</summary> \[\begin{aligned} \phi_X(t) &amp;= \int_{\mathbb R}e^{itx}f(x)dx=\int_{-\infty}^{+\infty}e^{itx}e^{-x}dx=\int_{0}^{+\infty}e^{-(1-it)x}dx\\ &amp;= \int_{0}^{+\infty}e^{-(1-it)x}dx=\biggr[\frac{-e^{-(1-it)x}}{1-it}\biggr]_0^{+\infty}=\frac{1}{1-it} \end{aligned}\]<p>Car $-e^{-(1-it)x}=e^{-x}e^{itx}\to0$ lorsque $x\to+\infty$.</p><p>Puisque $e^{itx}$ est bornée de module 1 et $e^{-x}\to0$ quand $x\to+\infty$</p></details><h3 id="exemple-2">Exemple 2<a href="#exemple-2"><i class="fas fa-hashtag"></i></a></h3></h3><p>Déterminer la fonction caractéristique de la loi de Bernoulli de paramètre $p$</p><details> <summary>Solution</summary><p>Soit $X$ une variable de Bernoulli</p>\[\begin{cases} X=1 &amp;\text{avec la probabilité }p\\ X=0 &amp;\text{avec la probabilité }1-p \end{cases}\]<p>X étant discrète, donc sa fonction caractéristique est:</p>\[\begin{aligned} \phi_X(t)&amp;=\sum_ke^{itk}P(X=k)=\sum_{k=0}^1e^{itk}P(X=k)=P(X=0)+e^{it}P(X=1)\\ &amp;= 1-p+pe^{it}=q+pe^{it} \text{ avec } q=1-p \end{aligned}\] </details><h1 id="convergences-des-suites-de-variables-aléatoires">Convergences des suites de variables aléatoires</h1><p>Une suite $(X_n)$ de variables aléatoires étant une suite de fonctions il existe diverses façons de définir la convergence de $(X_n)$ dont certaines jouent un grand rôle en statistiques.</p><h2 id="convergence-en-probabilité">Convergence en probabilité<a href="#convergence-en-probabilité"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p><strong>Definition</strong> La suite $(X_n)$ converge en probabilité vers une variable aléatoire $X$ si $\forall\varepsilon\gt0, \eta\gt0$ (arbitrairement petits) il existe un entier $n_0$ tel que $\forall n\gt n_0\Rightarrow P(\vert X_n-X\vert\gt\varepsilon)\to_{n\to+\infty}0$, c’est-à-dire $P(\vert X_n-X\vert\gt\varepsilon)\to_{n\to+\infty}0$.</p><p>On notera $(X_n)\to^PX$.</p></div><h3 id="inégalité-de-bienaymé-tchebychev">Inégalité de Bienaymé-Tchebychev<a href="#inégalité-de-bienaymé-tchebychev"><i class="fas fa-hashtag"></i></a></h3></h3><div class="alert alert-danger" role="alert"> \[P(\vert X_n-E(X)\vert\gt\varepsilon)\lt\frac{V(X)}{\varepsilon^2},\forall\varepsilon\gt0\]</div><h3 id="remarque-1">Remarque<a href="#remarque-1"><i class="fas fa-hashtag"></i></a></h3></h3><p>Lorsque $E(X_n)\to_{n\to+\infty}a$, il suffit de montrer que $V(X_n)\to_{n\to+\infty}0$ pour établir la convergence en probabilité de la suite $(X_n)$ vers $a$.</p><p>En effet d’après Tchebychev: $P(\vert X_n-E(X_n)\vert\gt\varepsilon)\lt\frac{V(X)}{\varepsilon^2}\to0$<br /> Donc en passant à la limite $\lim_{n\to+\infty}P(\vert X_n-a\vert\gt\varepsilon)=0,\forall\varepsilon\gt0$</p><h2 id="convergence-en-moyenne-quadratique">Convergence en moyenne quadratique<a href="#convergence-en-moyenne-quadratique"><i class="fas fa-hashtag"></i></a></h2></h2><p>On suppose que $E(\vert X_n-X\vert^2)$ existe</p><div class="alert alert-info" role="alert"><p><strong>Definition</strong> On dit qu’une suite de variables aléatoires $(X_n)$ converge en moyenne quadratique vers une variable $X$ si $E(\vert X_n-X\vert^2)\to_{n\to+\infty}0$</p><p>On notera $(X_n)\to^{m.q}X$</p></div><h2 id="convergence-en-loi">Convergence en loi<a href="#convergence-en-loi"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p><strong>Definition</strong> La suite $(X_n)$ converge en loi vers la variable $X$ de fonction de répartition $F$ si en tout point de continuité de $F$ la suite $(X_n)$ des fonctions de répartition des $(X_n)$ converge vers $F$.</p><p>C’est-à-dire $\lim_{n\to+\infty}F_n(x)=F(x)$ pour tout $x$ point de continuité de $F$.</p><p>On notera $(X_n)\to^LX$</p></div><h3 id="remarque-2">Remarque<a href="#remarque-2"><i class="fas fa-hashtag"></i></a></h3></h3><p>Pour les variables discrètes, la convergence en loi est équivalente à</p>\[\lim_{n\to+\infty}P(X_n=k)=P(X=k)\]<h3 id="théorème">Théorème<a href="#théorème"><i class="fas fa-hashtag"></i></a></h3></h3><div class="alert alert-warning" role="alert"><p>Si la suite des fonctions caractéristiques $\phi_{X_n}(t)$ converge vers $\phi_X(t)$ alors $(X_n)\to^LX$</p></div><h1 id="applications-convergence-en-loi-de-la-binomiale-vers-la-loi-normale">Applications: Convergence en loi de la binomiale vers la loi Normale</h1><h2 id="théorème-moivre-laplace">Théorème (Moivre-Laplace)<a href="#théorème-moivre-laplace"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-danger" role="alert"><p>Soit $(X_n)$ une suite de variables binomiales $\mathcal B(n,p)$ alors</p>\[\frac{X_n-np}{\sqrt{npq}}\to^L\mathcal N(0,1) \text{ lorsque } n\to+\infty\]</div><h3 id="démonstration">Démonstration<a href="#démonstration"><i class="fas fa-hashtag"></i></a></h3></h3><p>La fonction caractéristique de la loi $\mathcal B(n,p)$ est:</p>\[\phi_{X_n}(t)=(pe^{it}+1-p)^n \text{ donc celle de } Y_n=\frac{X_n-np}{\sqrt{npq}} \text{ est:}\\ \phi_{Y_n}(t) = (pe^{\frac{it}{\sqrt{npq}}}+1-p)^ne^{\frac{-itnp}{\sqrt{npq}}}\\ \ln(\phi_{Y_n}(t))=nLn(p(e^{\frac{it}{\sqrt{npq}}}-1)+1)-\frac{itnp}{\sqrt{npq}}\]<p>On rappelle le développement limité de l’exponentielle à l’ordre 2</p>\[e^x\simeq1+x+\frac{x^2}{2} \text{(au voisinage de 0)}\\ \ln(\phi_{Y_n}(t))\simeq n\ln(p(\frac{it}{\sqrt{npq}}-\frac{t^2}{2npq})+1)-\frac{itnp}{\sqrt{npq}}\]<p>On rappelle $\ln(1+x)\simeq x-\frac{x^2}{2}$ (au voisinage de 0)</p><p>Donc: \(\begin{aligned} \ln(\phi_{Y_n}(t))&amp;\simeq n\biggr[\frac{pit}{\sqrt{npq}}-\frac{pt^2}{2npq}+\frac{p^2t^2}{2npq}\biggr]-\frac{itnp}{\sqrt{npq}}\\ &amp;\simeq-\frac{t^2}{2q}+\frac{pt^2}{2q}=\frac{t^2}{2q}(p-1)=-\frac{t^2}{2} \end{aligned}\)</p><p>En composant par l’exponentielle:</p><div class="alert alert-success" role="alert"> \[\phi_{Y_n}(t)\simeq e^{-\frac{t^2}{2}}\]<p>fonction caractéristique de la loi normale $\mathcal N(0,1)$</p></div><p>Conclusion $\frac{X_n-np}{\sqrt{npq}}\to^L\mathcal N(0,1)$</p><h3 id="remarque-3">Remarque<a href="#remarque-3"><i class="fas fa-hashtag"></i></a></h3></h3><p>lorsque n est assez grand on peut donc approximer la loi Binomiale par la loi normale. On donne généralement comme condition $np$ et $nq\gt5$.</p><p>Il convient cependant d’effectuer la correction de continuité : on obtient donc une valeur approchée de $P(X=x)$ par la surface sous la courbe de densité de la loi normale $\mathcal N(np,\sqrt{npq})$ comprise entre les droites d’abscisse $x-\frac{1}{2}$ et $x+\frac{1}{2}$</p>\[P(X=x)\simeq P(x-\frac{1}{2}\lt X\lt x+\frac{1}{2})=P\biggr(\frac{x-\frac{1}{2}-np}{\sqrt{npq}}\lt \frac{X-np}{\sqrt{npq}}\lt \frac{x+\frac{1}{2}-np}{\sqrt{npq}}\biggr)\\ \text{Et } P(X\lt x)\simeq P\biggr(\frac{X-np}{\sqrt{npq}}\lt \frac{x+\frac{1}{2}-np}{\sqrt{npq}}\biggr)\]<h3 id="exemple">Exemple<a href="#exemple"><i class="fas fa-hashtag"></i></a></h3></h3><p>Soit X une variable binomiale $\mathcal B(n=40; p=0,3)$.</p><p>La valeur exacte pour $P(X=11)$ est $0,1319$. La formule d’approximation : \(P(X=11)\simeq P\biggr(\frac{11-\frac{1}{2}-12}{\sqrt{8,4}}\lt \frac{X-12}{\sqrt{8,4}}\lt \frac{11+\frac{1}{2}-12}{\sqrt{8,4}}\biggr)=P(-0,52\lt U\le-0,17)=0,131\)</p><p>Avec $np=12$ et $npq=8,4$</p><p>Donc l’erreur est de moins de $1\%$</p><h2 id="convergence-en-loi-de-la-loi-de-poisson-vers-la-loi-normale">Convergence en loi de la loi de Poisson vers la loi normale<a href="#convergence-en-loi-de-la-loi-de-poisson-vers-la-loi-normale"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-warning" role="alert"><p><strong>Theoreme</strong> Soit $(X_{\lambda})$ une suite de variables de Poisson de paramètre $\lambda$.</p><p>Si $\lambda\to+\infty$, $\frac{X_{\lambda}-\lambda}{\sqrt{\lambda}}\to^L\mathcal N(0,1)$</p></div><h3 id="démonstration-1">Démonstration<a href="#démonstration-1"><i class="fas fa-hashtag"></i></a></h3></h3><p>on rappelle la fonction caractéristique de la loi de Poisson:</p>\[\phi_{X_i}(t)=e^{\lambda e^{it}-\lambda}\]<p>On rappelle aussi la formule $\phi_{\frac{X-m}{\sigma}}=e^{-\frac{it\lambda}{\sqrt{\lambda}}+\lambda+\frac{\lambda it}{\sqrt{\lambda}}-\frac{t^2}{2}-\lambda}=e^{-\frac{t^2}{2}}$</p><div class="alert alert-success" role="alert"><p>On retrouve la fonction caractéristique de la loi normale centrée et réduite.</p></div><p>Conclusion $\frac{X_{\lambda}-\lambda}{\sqrt{\lambda}}\to^L\mathcal N(0,1)$</p><h2 id="théorème-central-limite">Théorème (Central-limite)<a href="#théorème-central-limite"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-danger" role="alert"><p>Soit $(X_n)$ une suite de variables aléatoires, indépendantes et de même loi d’espérance $m$ et d’écart-type $\sigma$ alors :</p>\[\frac{X_1+X_2+....+X_n-nm}{\sigma\sqrt n}\to\mathcal N(0,1)\]</div><h3 id="démonstration-2">Démonstration<a href="#démonstration-2"><i class="fas fa-hashtag"></i></a></h3></h3>\[\frac{X_1+X_2+....+X_n-nm}{\sigma\sqrt n}\to\mathcal N(0,1) = \sum_{i=1}^n\frac{X_i-m}{\sigma\sqrt n}\]<p>Posons $Y_n=\sum_{i=1}^n\frac{X_i-m}{\sigma\sqrt n}$</p>\[E(\frac{X_i-m}{\sigma\sqrt n})=\frac{E(X_i)-m}{\sigma\sqrt {n}}=0 \\ \text{et}\\ V(\frac{X_i-m}{\sigma\sqrt n})=\frac{1}{\sigma^2 n}V(X_i)=\frac{\sigma^2}{n\sigma^2}=\frac{1}{n}\]<p>La fonction caractéristique de $Y_n=\sum_{i=1}^n\frac{X_i-m}{\sigma\sqrt{n}}$ est:</p>\[\phi_{Y_n}(t) = \Pi_{i=1}^n\phi_{\frac{X_i-m}{\sigma\sqrt{n}}}(t)=\phi_{\frac{X_i-m}{\sigma\sqrt{n}}}(t)^n=(1-\frac{t^2}{2n}+o(\frac{1}{n^2}))^n\]<p>On rappelle que $(1+\frac{x}{n})^n\to e^{x}$ Car $(1+\frac{x}{n})^n=e^{n\ln(1+\frac{x}{n})}\simeq e^{n\frac{x}{n}}=e^x$ Donc $\phi_{Y_n}(t)=(1-\frac{t^2}{2n}+o(\frac{1}{n^2}))^n\to e^{-\frac{t^2}{2}}$ lorsque $n\to+\infty$</p><h1 id="estimateurs">Estimateurs</h1><div class="alert alert-info" role="alert"><p><strong>Définition</strong> Soit $(X_1,X_2,…,X_n)$ un échantillon de $X$, c’est-à-dire une suite de variables aléatoires indépendantes et de même loi que $X$. La statistique $\bar X$ ou moyenne empirique de l’échantillon est:</p>\[\bar X=\frac{1}{n}\sum_{i=1}^nX_i\]</div>\[E(\bar X)=\frac{1}{n}\sum_{i=1}^n E(X_i)=\frac{nm}{n}=m \text{ où } m=E(X)\\ V(\bar X)=\frac{1}{n^2}\sum_{i=1}^n V(X_i)=\frac{n\sigma^2}{n^2}=\frac{\sigma^2}{n}\to 0 \text{ lorsque } n\to+\infty\]<p>Donc d’après Tchebychev $\bar X=\frac{1}{n}\sum_{i=1}^nX_i\to^Pm=E(X)$ quand $n\to+\infty$</p><div class="alert alert-success" role="alert"><p>C’est la loi des grands nombres.</p></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/tronc-commun-s8/'>tronc commun S8</a>, <a href='/cours/categories/ase2/'>ASE2</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/tronc-commun/" class="post-tag no-text-decoration" >tronc commun</a> <a href="/cours/tags/ase2/" class="post-tag no-text-decoration" >ASE2</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a> <a href="/cours/tags/convergence/" class="post-tag no-text-decoration" >convergence</a> <a href="/cours/tags/normale/" class="post-tag no-text-decoration" >normale</a> <a href="/cours/tags/gamma/" class="post-tag no-text-decoration" >gamma</a> <a href="/cours/tags/poisson/" class="post-tag no-text-decoration" >poisson</a> <a href="/cours/tags/loi/" class="post-tag no-text-decoration" >loi</a> <a href="/cours/tags/mac-laurin/" class="post-tag no-text-decoration" >Mac-Laurin</a> <a href="/cours/tags/moivre-laplace/" class="post-tag no-text-decoration" >Moivre-Laplace</a> <a href="/cours/tags/central-limite/" class="post-tag no-text-decoration" >central limite</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ASE2: Convergence et estimation - 2 - Cours&url=https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ASE2: Convergence et estimation - 2 - Cours&u=https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ASE2: Convergence et estimation - 2 - Cours&url=https://lemasyma.github.io/cours/posts/ase2_convergence_et_estimation/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/ase2_exercices_convergence_estimation_suite/"><div class="card-body"> <em class="timeago small" date="2021-03-10 09:00:00 +0100" >Mar 10, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ASE2: TD 1, suite (encore)</h3><div class="text-muted small"><p> Lien de la note Hackmd Exercice 5 Soit $X$ une v.a. normale centree et reduite $X\to\mathcal N(0,1)$. Montrer que $\forall x\in\mathbb R^*_+$ [\int_0^x e^{-\frac{t^2}{2}}dt\ge\sqrt{\frac{\pi}{2}}...</p></div></div></a></div><div class="card"> <a href="/cours/posts/ase2_rappels/"><div class="card-body"> <em class="timeago small" date="2021-03-10 09:00:00 +0100" >Mar 10, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ASE2: Rappels sur les lois</h3><div class="text-muted small"><p> Lien de la note Hackmd Loi normale centree reduite $E(X) = 0$ $V(X) = 1$ $f(X) = \frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}$ $F(X) = \frac{1}{\sqrt{2\pi}}\int_0^Xe^{-\frac{t^2}{2}}$ Loi Po...</p></div></div></a></div><div class="card"> <a href="/cours/posts/ase2_td2/"><div class="card-body"> <em class="timeago small" date="2021-03-17 10:00:00 +0100" >Mar 17, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ASE2: TD 2</h3><div class="text-muted small"><p> Lien de la note Hackmd Avec Poisson: approximation en serie, mieux de passer par la Gaussienne (loi binomiale) car moins de calculs Exercice 9 Une usine fabrique des pieces, dont $3\%$ ont de...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/ase2_rappels/" class="btn btn-outline-primary" prompt="Older"><p>ASE2: Rappels sur les lois</p></a> <a href="/cours/posts/dbre_droits_auteur/" class="btn btn-outline-primary" prompt="Newer"><p>DBRE: Titularite des droits d'auteurs</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
