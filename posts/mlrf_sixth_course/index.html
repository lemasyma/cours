<!DOCTYPE html><html lang="fr-FR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://cours-v2.ew.r.appspot.com/query?id=agplfmNvdXJzLXYychULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="MLRF: Lecture 06" /><meta property="og:locale" content="fr_FR" /><meta name="description" content="Lecture 06" /><meta property="og:description" content="Lecture 06" /><link rel="canonical" href="https://lemasyma.github.io/cours/posts/mlrf_sixth_course/" /><meta property="og:url" content="https://lemasyma.github.io/cours/posts/mlrf_sixth_course/" /><meta property="og:site_name" content="Cours" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-25T10:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="MLRF: Lecture 06" /><meta name="google-site-verification" content="mErcVOJcxNzULHvQ99qSclI_DTX0zANqgpsd3jGhkfs" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-10-03T16:45:54+02:00","datePublished":"2021-06-25T10:00:00+02:00","description":"Lecture 06","headline":"MLRF: Lecture 06","mainEntityOfPage":{"@type":"WebPage","@id":"https://lemasyma.github.io/cours/posts/mlrf_sixth_course/"},"url":"https://lemasyma.github.io/cours/posts/mlrf_sixth_course/"}</script><title>MLRF: Lecture 06 | Cours</title><link rel="apple-touch-icon" sizes="180x180" href="/cours/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/cours/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/cours/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/cours/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/cours/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Cours"><meta name="application-name" content="Cours"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/cours/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cours-v2.ew.r.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://cours-v2.ew.r.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/cours/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/cours/" alt="avatar" class="mx-auto"> <img src="/cours/assets/img/favicons/logo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/cours/">Cours</a></div><div class="site-subtitle font-italic">Certains cours sont en francais, certains sont en anglais, d'autres sont un mix des deux</div></div><ul class="w-100"><li class="nav-item"> <a href="/cours/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/cours/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/cours/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/cours/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/cours/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/lemasyma" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="" aria-label="" target="_blank" rel="noopener"> <i class=""></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/cours/"> Home </a> </span> <span>MLRF: Lecture 06</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>MLRF: Lecture 06</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/lemasyma">lemasyma</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-06-25 10:00:00 +0200" data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 25, 2021, 10:00 AM +0200" >Jun 25, 2021</em> </span> <span> Updated <em class="timeago" date="2021-10-03 16:45:54 +0200 " data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 3, 2021, 4:45 PM +0200" >Oct 3, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2129 words"> <em>11 min</em> read</span> <span> <em id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </em> views </span></div></div></div><div class="post-content"><p>Lien de la <a href="https://hackmd.io/@lemasymasa/Hy2LfRFju">note Hackmd</a></p><h1 id="practice-5-take-home-messages">Practice 5: Take home messages</h1><div class="alert alert-danger" role="alert"><p>BoVW is linear classification friendly</p></div><ul><li>And linear classifier are to be prefered whenever possible</ul><p>Data preparation is tedious</p><ul><li>An important part of the time is dedicated to data analysis<li>Plus we prepared a lot of things for you in the previsous sesssions</ul><p>Scikit-learn is easy and super powerful</p><ul><li>Calssifier evaluation in 1 line<li>But there is more: parameter tuning, cross-validation, etc. in 1 or 2 lines<li>Data preprocessing + classification (pipelines) in 1-3 lines</ul><h1 id="some-classifiers--part-2">Some classifiers – part 2</h1><h2 id="how-to-build-non-linear-classifiers-">How to build non-linear classifiers ?<a href="#how-to-build-non-linear-classifiers-"><i class="fas fa-hashtag"></i></a></h2></h2><p>2 solutions:</p><ol><li><strong>Preprocess</strong> the data - <em>seen last time</em><ul><li><em>Ex: explicit embedding, kernel trick…</em><li>Change the input to make it linearly separable</ul><li><strong>Combine</strong> multiple <strong>linear classifiers</strong> into nonlinear classifier - <em>current topic</em><ul><li><em>Ex: boosting, neural networks…</em><li>Split the input space into linear subspaces</ul></ol><h1 id="non-linear-classification-using-combinations-of-linear-classifiers">Non-linear classification using combinations of linear classifiers</h1><h2 id="multi-layer-perceptron">Multi-layer Perceptron<a href="#multi-layer-perceptron"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Combine features linearly, apply a linear activation function $\phi$, repeat</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/Da6rwGt.png" alt="" /></p><h2 id="universal-approximation-theorem">Universal approximation theorem<a href="#universal-approximation-theorem"><i class="fas fa-hashtag"></i></a></h2></h2><p>What if $\phi$ not linear ?</p><div class="alert alert-success" role="alert"><p>Universal approximation theorem (Cybenko 89, Hornik 91) <img data-proofer-ignore data-src="https://i.imgur.com/JYVtKXM.png" alt="" /></p></div><h2 id="decision-tree">Decision tree<a href="#decision-tree"><i class="fas fa-hashtag"></i></a></h2></h2><p>Works on categorical (like, “red”, “black”) and numerical (both discrete and continuous) random variables</p><p><img data-proofer-ignore data-src="https://i.imgur.com/s1NXMQV.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/xzuMcj6.png" alt="" /></p><p>Train by optimizing classification “purity” at each decision (threshold on a particular dimension in numerical case)</p><p>Very fast training and testing. Non parametric.</p><p>No need to preprocess the features</p><p>BUT: very prone to <strong>overfitting</strong> without strong limits on depth</p><p><img data-proofer-ignore data-src="https://i.imgur.com/PHHgLkO.png" alt="" /></p><h2 id="random-forests">Random Forests<a href="#random-forests"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p><strong>Average</strong> the decision of multiple decision trees</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/oe9tXJS.png" alt="" /></p><p>Randomize in 2 ways:</p><ol><li>For each tree, pick a <strong>bootstrap</strong> sample of data <img data-proofer-ignore data-src="https://i.imgur.com/pu6Gxp8.png" alt="" /><li>For each split, pick random sample of features <img data-proofer-ignore data-src="https://i.imgur.com/2vQd5KX.png" alt="" /></ol><p>More trees are always better</p><h1 id="ensemble-methods">Ensemble methods</h1><h2 id="bagging-or-bootstrap-aggregating">“Bagging” or “bootstrap aggregating”<a href="#bagging-or-bootstrap-aggregating"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Underlying idea: part of the variance is due to the specific choice of the training data set</p></div><ol><li>Let use create many similar training data sets using <strong>bootstrap</strong><li>For each of them, train a new classifier<li>The final function will tbe the <strong>average</strong> of each function ouptuts</ol><div class="alert alert-danger" role="alert"><p>If generalization error is decomposed into bias and variance terms then bagging reduces variance (averag of large number of random error $\simeq 0$)</p></div><p><em>Random forest = a way of bagging trees</em></p><h2 id="boosting-adaboost-variant">“Boosting”, AdaBoost variant<a href="#boosting-adaboost-variant"><i class="fas fa-hashtag"></i></a></h2></h2><p>Combinaison of weak classifiers $\sum_m\alpha_mG_m(x)$</p><p>$\alpha_m$ increases with precision (less errors, bigger $\alpha_m$)</p><p>The classifier $G_m$ is trained with <strong>increased error cost</strong> for the observatins which were misclassified by $G_{m-1}$</p><p><img data-proofer-ignore data-src="https://i.imgur.com/3iISNzY.png" alt="" /></p><h1 id="a-quick-comparison">A quick comparison</h1><p><img data-proofer-ignore data-src="https://i.imgur.com/mofCSdU.jpg" alt="" /></p><h1 id="more-tricks">More tricks</h1><h2 id="data-augmentation">Data augmentation<a href="#data-augmentation"><i class="fas fa-hashtag"></i></a></h2></h2><p><em>Add realistic deformations to your input in order to improve domain coverage.</em></p><p>For <strong>image data</strong>, depending on what is possible in productin: rotations, horizontal &amp; vertical dlips, scaling, translation, illumination change, warping, noise, etc.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/ulNegtw.png" alt="" /></p><p>For <strong>vector data</strong>: intersting problem. Possible approach: train/fit PCA then add random noise in low-energy features</p><h2 id="reject">Reject<a href="#reject"><i class="fas fa-hashtag"></i></a></h2></h2><p>Several options:</p><ol><li><em>Improve the model of class boundary</em><ul><li>In 1-vs-all training, add noise to the “others” samples</ul><li><em>Adjust the decision function dependinf on your application</em><ul><li>Look at the prediction probabiblity of your classifier, and threshold it as per your need using a ROC curve</ul><li><em>Model the noise</em><ul><li>Add a “none” class to your classifier, with samples for real life cases of negatives samples</ul></ol><h1 id="more-theory-on-ml">More theory on ML</h1><h2 id="what-is-our-goal-">What is our goal ?<a href="#what-is-our-goal-"><i class="fas fa-hashtag"></i></a></h2></h2><blockquote><p>Given <strong>samples</strong> (described by features) and <strong>true labels</strong>, find a <strong>good</strong> function which wil correctly <strong>predict labels</strong> given new <strong>data samples</strong></p></blockquote><p>Problems:</p><ul><li>Which family for our function?<li>What is “good”?<li>How to train / find such function?</ul><h2 id="what-are-the-sources-of-error-">What are the sources of error ?<a href="#what-are-the-sources-of-error-"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Noise<ul><li>Your data is not perfect. (or “<em>Every model is wrong.</em>”)<li>Even if there exist an optimal underlying model, the observations are corrupted by noise (e.g. multiple y for a given x).<li><strong>- Even the optimal solution could be wrong.</strong><li><img data-proofer-ignore data-src="https://i.imgur.com/Jukh31q.png" alt="" /></ul><li>Bias<ul><li>You need to simplify to generalize.<li>You classifier needs to drop some information about the training set to have generalization power.<li><strong>The set of solutions explored does not contain the optimal solution.</strong><li><img data-proofer-ignore data-src="https://i.imgur.com/MlmJgiw.png" alt="" /></ul><li>Variance<ul><li>You have many ways to explain your training dataset<li>It is hard to find an optimal solution among those many possibilities.<li><strong>If we draw another training set from the same distribution, we would obtain another solution.</strong><li><img data-proofer-ignore data-src="https://i.imgur.com/504PfiR.png" alt="" /></ul></ul><h2 id="2-big-issues">2 big issues<a href="#2-big-issues"><i class="fas fa-hashtag"></i></a></h2></h2><p>Under-fitting</p><ul><li>Caused by <strong>bias</strong><li>Your model assumptions are too strong for the data, so the model won’t fill well<li><img data-proofer-ignore data-src="https://i.imgur.com/Ivvw6xL.png" alt="" /></ul><p>Over-fitting</p><ul><li>Caused by <strong>variance</strong><li>Your algorithm has memorized the data including the noise, so it can’t generalize.<li><img data-proofer-ignore data-src="https://i.imgur.com/rB8koEQ.png" alt="" /></ul><h1 id="the-theory">The theory</h1><h2 id="bias-statistical-definition">Bias (statistical definition)<a href="#bias-statistical-definition"><i class="fas fa-hashtag"></i></a></h2></h2><p>Let $T$ be a statistic used to estimate a parameter $\theta$.</p><p>If $E[T] = \theta + bias(\theta)$ then $bias(\theta)$ is called the bias of the statistic $T$, where $E[T]$ represents the expected value of the statistics $T$.</p><p>If $bias(\theta) = 0$, then $E[T] = \theta$. So, $T$ is an unbiased estimator of the true parameter, say $\theta$.</p><h2 id="expected-risk">Expected Risk<a href="#expected-risk"><i class="fas fa-hashtag"></i></a></h2></h2><p>Let $D_n$ be a training set of examples $z_i$ drawn independently from an unknown distribution $p(z)$</p><p>We need a set of functions F. Example: linear functions $f(x) = a \times x + b$</p><p>We need a loss function $L(z, f)$. Example: $L((x, y), f ) = (f (x) − y)^2$</p><div class="alert alert-info" role="alert"><p>The <strong>Expected Risk</strong>, i.e. the expected generalization error, is:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/hU9xLCN.png" alt="" /></p></div><p>But we do not know $p(z)$, and we cannot test all $z$!</p><h2 id="empirical-risk">Empirical Risk<a href="#empirical-risk"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-info" role="alert"><p>Because we cannot measure the real <strong>Expected Risk</strong>, we have to estimate it using the <strong>Empirical Risk</strong>: <img data-proofer-ignore data-src="https://i.imgur.com/buQaJeQ.png" alt="" /></p><p>$D_n$ is our dataset</p></div><p>And our training procedure then relies on <strong>Empirical Risk Minimization (ERM)</strong>: <img data-proofer-ignore data-src="https://i.imgur.com/t8tiBBp.png" alt="" /></p><p>And the training error is given by: <img data-proofer-ignore data-src="https://i.imgur.com/9revSrN.png" alt="" /></p><h3 id="does-this-make-sense">Does this make sense?<a href="#does-this-make-sense"><i class="fas fa-hashtag"></i></a></h3></h3><div class="alert alert-success" role="alert"><p><strong>The empirical risk is an unbiased estimate of the risk</strong>, i.e. the more test samples we have, the more accurate our estimate is, <strong>under iid assumption</strong>.</p></div><p><img data-proofer-ignore data-src="https://i.imgur.com/Mo0ZQBM.png" alt="" /></p><h2 id="but-the-training-risk-is-biased">But the training risk is biased<a href="#but-the-training-risk-is-biased"><i class="fas fa-hashtag"></i></a></h2></h2><p>The training error is a biased estimate of the risk, i.e. the solution $f^★ (D_n)$ found by minimizing the training error is better on $D_n$ than on any other set $D’_n$ drawn from $p(z)$.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/brPepp2.png" alt="" /></p><p>However, under certain assumptions, the difference between the expected and the empirical risks can be bounded. This is an important result from the work of Vapnik</p><p>Note that the empirical risk on the test set is an unbiased estimate of the risk. <img data-proofer-ignore data-src="https://i.imgur.com/dLakZp5.png" alt="" /></p><h2 id="estimate-the-expected-risk-with-the-empirical-risk">Estimate the Expected Risk with the Empirical Risk<a href="#estimate-the-expected-risk-with-the-empirical-risk"><i class="fas fa-hashtag"></i></a></h2></h2><p><em>For a given capacity</em>, using more samples to train and evaluate your predictor <strong>should</strong> make your Empirical Risk converge toward the best possible Expected Risk, if the ERM is consistent for $F$, given your training set $D_n$.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/aUHJXBD.png" alt="" /></p><p>The difference between Expected Risk and Empirical Risk is <strong>bounded</strong> but depends on the <em>capacity</em> of $F$ (set of possible functions).</p><p>There is an <strong>optimal</strong> capacity for a given number of training samples $n$.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/8cPTpvd.png" alt="" /></p><h2 id="capacity">Capacity<a href="#capacity"><i class="fas fa-hashtag"></i></a></h2></h2><p>The capacity $h(F)$ is a measure of its size, or complexity (or VC dimension)</p><p>For classification, the capacity of $F$ is defined by Vapnik &amp; Chervonenkis as:</p><ul><li>the largest $n$<li>such that there exist a set of examples $D_n$<li>such that one can always find an $f \in F$<li>which gives the correct answer for all examples in $D_{n’}$<li>for any possible labeling.</ul><h2 id="the-bias-variance-dilemma">The Bias-Variance Dilemma<a href="#the-bias-variance-dilemma"><i class="fas fa-hashtag"></i></a></h2></h2><p>Intrinsic dilemma: when the capacity $h(F)$ grows, the bias goes down, but the variance goes up!</p><p><img data-proofer-ignore data-src="https://i.imgur.com/mgX4zCj.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/rxjY8kI.png" alt="" /></p><h2 id="decomposing-the-bias-variance-error-for-mse">Decomposing the bias-variance-error for MSE<a href="#decomposing-the-bias-variance-error-for-mse"><i class="fas fa-hashtag"></i></a></h2></h2><p>For a regression problem with a mean square loss, we have the following decomposition. Let $Y = f(X) + \varepsilon$, with $\varepsilon \sim N(0, \sigma_{\varepsilon}^2)$ and $f_D(X)$ an estimator of $f(X)$, learned over the training set $D$. The error at a particular point $X = x_0$ is:</p><p><img data-proofer-ignore data-src="https://i.imgur.com/LRsxpLB.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/7S5ueXj.png" alt="" /></p><h1 id="in-practice">In practice</h1><h2 id="empirical-risk-and-expected-risk">Empirical Risk and Expected Risk<a href="#empirical-risk-and-expected-risk"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-danger" role="alert"><p>Measure train and test error</p></div><p>Use hold-out sets, cross-validations, etc. to get a test error.</p><p><strong>Train</strong> error: <strong>Empirical</strong> Risk. <em>Can my model learn something (by heart)?</em></p><p><strong>Test</strong> error: Coarse estimate of the <strong>Expected</strong> Risk. <em>Can my model generalize to unseen data?</em></p><h2 id="detect-under-fitting-and-over-fitting">Detect under-fitting and over-fitting<a href="#detect-under-fitting-and-over-fitting"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/tA9gs0r.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/iFls3iy.png" alt="" /></p><h2 id="some-solutions--hints">Some solutions / hints<a href="#some-solutions--hints"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/fwFAoQX.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/0fD8QHJ.png" alt="" /></p><h1 id="how-to-get-started">How to get started?</h1><ol><li>Get enough data in the right format from your customer <em>(hard)</em><li>Check and split data <em>(boring but mandatory)</em><li>Agree on a loss function and minimum performance goal <em>(moderate)</em><li>Try to overfit a predictor on some samples (train set loss), increase complexity only if needed (capacity check)<li>Fit on more data <em>(more = better)</em><li>Check for overfitting (val set loss) and add regularization if needed<li>Evaluate performance thoroughly (test set loss) <em>(reports, identify failure cases, etc.)</em><li>Do some hyper-parameter optimization, try other models…<li>…</ol><h1 id="introduction-to-practice-session-6">Introduction to practice session 6</h1><h2 id="using-classification-to-segment-images">Using classification to segment images<a href="#using-classification-to-segment-images"><i class="fas fa-hashtag"></i></a></h2></h2><p>Until now</p><ul><li>1 image $\to$ many vectors (instance recognition)<li>1 image $\to$ 1 vector (image retrieval, image classification)</ul><p>Today / next practice session :</p><ul><li>1 pixel →1 vector (pixel classification, image semantic segmentation)</ul><h1 id="brain-anatomy-and-imaging">Brain Anatomy and Imaging</h1><h2 id="human-brain--where-human-os-is-stored-and-run">Human brain = Where human OS is stored and run<a href="#human-brain--where-human-os-is-stored-and-run"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/ysWPXnI.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/zOtjdsr.png" alt="" /></p><h2 id="to-investigate-brain-malfunction-two-options">To investigate brain malfunction, two options:<a href="#to-investigate-brain-malfunction-two-options"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/BfAL7lO.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/acPZDvM.png" alt="" /></p><h2 id="magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)<a href="#magnetic-resonance-imaging-mri"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/ttg3xJf.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/S8aRYVR.png" alt="" /></p><h2 id="everything-you-always-wanted-to-know-about-mri">Everything you always wanted to know about MRI<a href="#everything-you-always-wanted-to-know-about-mri"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/geUyEAg.png" alt="" /></p><p>Hydrogen atoms are naturally abundant in humans, particularly in water and fat.</p><p>Pulses of radio waves excite the nuclear spin energy transition, and macroscopic polarization that is detected by antennas.</p><p>Magnetic field gradients localize the polarization in space. By varying the parameters of the pulse sequence, different contrasts may be generated between tissues based on the relaxation properties of the hydrogen atoms therein.</p><h2 id="what-you-actually-need-to-know">What you actually need to know<a href="#what-you-actually-need-to-know"><i class="fas fa-hashtag"></i></a></h2></h2><p>MRI is a large family of imaging techniques</p><p>They can produce 3D scans of various appearances in order to emphasize some human tissues versus others.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/fuh9DXP.png" alt="" /></p><h1 id="brats-brain-tumor-segmentation-competition">BraTS: Brain Tumor Segmentation Competition</h1><h2 id="original-segmentation-task">Original segmentation task<a href="#original-segmentation-task"><i class="fas fa-hashtag"></i></a></h2></h2><p>Given a 3D scan (skull-stripped, registered) of a patient with T1, T2, T1C and FLAIR modalities, predict a tumor class for each voxel (the patient suffers from a glioma):</p><p><img data-proofer-ignore data-src="https://i.imgur.com/fJN1dK4.png" alt="" /></p><p>Avec:</p><ul><li>edema (yellow),<li>non-enhancing solid core (red),<li>necrotic/cystic core (green),<li>enhancing core (blue).</ul><h2 id="original-dataset">Original dataset<a href="#original-dataset"><i class="fas fa-hashtag"></i></a></h2></h2><p>The 2018 competition we use the data from originally contains 285 brain scans.</p><h1 id="your-mission">Your Mission</h1><h2 id="a-simplified-competition">A simplified competition<a href="#a-simplified-competition"><i class="fas fa-hashtag"></i></a></h2></h2><p>Because dealing with 3D and data normalization would take you much time and pain, we:</p><ol><li>already performed <strong>data normalization</strong><li>extracted <strong>2D (axial) slices</strong> that you have to process</ol><h2 id="actual-task">Actual task<a href="#actual-task"><i class="fas fa-hashtag"></i></a></h2></h2><p>Given a $240\times240$ image with $4$ modalities (already normalized), predict for each pixel whether it belongs to a tumor or nor.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/TTDbvMR.png" alt="" /></p><h2 id="actual-dataset">Actual dataset<a href="#actual-dataset"><i class="fas fa-hashtag"></i></a></h2></h2><p>Train set</p><ul><li>$256$ normalized slices, one per patient, containing $240\times240$ images with $4$ channels ($1$ for each modality), <code class="language-plaintext highlighter-rouge">float32</code><li>$256$ target segmentations, one per patient, containing $240\times240$ images with $1$ channel (indicating tumor or clean region), <code class="language-plaintext highlighter-rouge">uint8</code></ul><p>Test set</p><ul><li>$29$ normalized slices, one per patient (not in the training set), containing $240\times240$ images with $4$ channels ($1$ for each modality), <code class="language-plaintext highlighter-rouge">float32</code><li><em>Ground truth kept secret for grading</em></ul><h1 id="suggested-pipeline">Suggested Pipeline</h1><h2 id="data-preprocessing">Data preprocessing<a href="#data-preprocessing"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-warning" role="alert"><p>We already did this step.</p></div><h2 id="choose-and-train-a-classifier">Choose and train a classifier<a href="#choose-and-train-a-classifier"><i class="fas fa-hashtag"></i></a></h2></h2><p>There are several suggestions in the reference notebook: SVM, neural network, etc.</p><ul><li>Input = 1 vector of 4 components for each pixels<li>Output = 1 for tumor, 0 for “not tumor”</ul><div class="alert alert-warning" role="alert"><p>Do not use background (“black”) pixels for training, they would ruin your classification</p></div><div class="alert alert-warning" role="alert"><p>Deep nets can work but they are harder to train well.</p></div><div class="alert alert-warning" role="alert"><p>And don’t use deep nets, we’ll play with them next semester</p></div><h2 id="validate-your-training">Validate your training<a href="#validate-your-training"><i class="fas fa-hashtag"></i></a></h2></h2><p>Create and use a validation set extracted from the full training set.</p><p>To not train on the samples it contains.</p><p><code class="language-plaintext highlighter-rouge">sklearn.model_selection.train_test_split</code> may be your friend.</p><div class="alert alert-danger" role="alert"><p>Check visually results from both train and val sets!</p></div><h2 id="interpret-your-results">Interpret your results<a href="#interpret-your-results"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/6euveJc.png" alt="" /></p><h2 id="add-some-context-to-each-pixel">Add some context to each pixel<a href="#add-some-context-to-each-pixel"><i class="fas fa-hashtag"></i></a></h2></h2><p>You can get better results by looking at the neighborhood of a pixel to classify it better: train with vectors of size $N\times M$ instead of $1\times M$.</p><h2 id="fighting-underfitting-and-overfitting">Fighting underfitting and overfitting<a href="#fighting-underfitting-and-overfitting"><i class="fas fa-hashtag"></i></a></h2></h2><div class="alert alert-danger" role="alert"><p>You do not have much data to train on</p></div><p>If you pick a classifier which is too simple, you may underfit: you will get low and similar scores both on the train and test sets</p><p>Choosing another classifier may be a good idea here.</p><p>You may also easily overfit your classifier, especially if you use one with a large capacity: you will get excellent scores on the train set, and bad ones on the test set.</p><p>Regularization may be necessary.</p><h2 id="post-processing">Post processing<a href="#post-processing"><i class="fas fa-hashtag"></i></a></h2></h2><p>We suggest in the notebook to “clean up” the results by removing very small isolated pixels marked as tumor.</p><p>You may have many other ideas here</p><h1 id="going-further">Going Further</h1><h2 id="many-options">Many options<a href="#many-options"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Data augmentation to increase train set<li>Larger / better neighborhood for each pixel<li>Better ANN structure than the one suggested in the notebook<li>Change the representation space? (Fourier, wavelets…)<li>As the tumors under consideration may not have “holes”, improve the post-processing<li><del>Super heavy classifiers (UNet, Gradient Boosted Trees…)</del><li>…</ul><h1 id="conclusion">Conclusion</h1><h2 id="course-overview-a-very-small-glimpse-of-cvprml">Course overview: a very small glimpse of CV/PR/ML<a href="#course-overview-a-very-small-glimpse-of-cvprml"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/D2H4xvT.png" alt="" /></p><h2 id="welcome-to-2012">Welcome to 2012<a href="#welcome-to-2012"><i class="fas fa-hashtag"></i></a></h2></h2><p>AlexNet by A. Krizhevsky, I. Sutskever, G. E. Hinton halved error rate on ImageNet competition</p><p><img data-proofer-ignore data-src="https://i.imgur.com/WtFw5va.png" alt="" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/0vA9SRl.png" alt="" /></p><h2 id="deep-learning">Deep learning<a href="#deep-learning"><i class="fas fa-hashtag"></i></a></h2></h2><p>Will be there for a few years!</p><p>Is a natural extension of what we saw: feature extraction, encoding, pooling, classification in a <strong>single, integrated, globally optimized pipeline.</strong></p><p>Requires skills you learned: <strong>dev, math, data preparation, evaluation.</strong> <em>Input data still need to be properly normalized, for instance.</em></p><p>Requires <strong>a lot of practice</strong>: read papers, don’t be impressed by the math, implement them.</p><p>If not applicable, then pick one of the good old technique we talked about.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/cours/categories/image-s8/'>Image S8</a>, <a href='/cours/categories/mlrf/'>MLRF</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/cours/tags/image/" class="post-tag no-text-decoration" >Image</a> <a href="/cours/tags/scia/" class="post-tag no-text-decoration" >SCIA</a> <a href="/cours/tags/mlrf/" class="post-tag no-text-decoration" >MLRF</a> <a href="/cours/tags/s8/" class="post-tag no-text-decoration" >S8</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=MLRF: Lecture 06 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_sixth_course/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=MLRF: Lecture 06 - Cours&u=https://lemasyma.github.io/cours/posts/mlrf_sixth_course/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=MLRF: Lecture 06 - Cours&url=https://lemasyma.github.io/cours/posts/mlrf_sixth_course/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recent Update</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/cours/posts/ocvx_norme/">OCVX: Norme</a><li><a href="/cours/posts/imed2_tp3/">IMED2: TP3</a><li><a href="/cours/posts/prsta_revisions_1/">PRSTA: Revisions 1</a><li><a href="/cours/posts/prsta_td5/">PRSTA: TD 5</a><li><a href="/cours/posts/prsta_td4/">PRSTA: TD 4</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/cours/posts/mlrf_first_course/"><div class="card-body"> <em class="timeago small" date="2021-05-14 10:00:00 +0200" >May 14, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 01</h3><div class="text-muted small"><p> Lien de la note Hackmd Scope of this course Apply Machine Learning (ML) techniques to solve some practical Computer Vision (CV) problems About Computer Vision (CV) It should be called C...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_second_course/"><div class="card-body"> <em class="timeago small" date="2021-05-21 10:00:00 +0200" >May 21, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 02</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 2 Introduction Global image descriptors Clustering Local feature detectors Introduction Summary of last lecture Machine learning Machine lea...</p></div></div></a></div><div class="card"> <a href="/cours/posts/mlrf_third_course/"><div class="card-body"> <em class="timeago small" date="2021-05-28 10:00:00 +0200" >May 28, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MLRF: Lecture 03</h3><div class="text-muted small"><p> Lien de la note Hackmd Agenda for lecture 3 Introduction Finish lecture about local feature detectors Local feature descriptors Descriptor matching and indexing Projective transformatio...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/cours/posts/tifo_recalage/" class="btn btn-outline-primary" prompt="Older"><p>TIFO: Cours recalage</p></a> <a href="/cours/posts/dbre_masterclass_v2/" class="btn btn-outline-primary" prompt="Newer"><p>DBRE: Masterclass V2</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/lemasyma">lemasyma</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/cours/tags/image/">Image</a> <a class="post-tag" href="/cours/tags/s8/">S8</a> <a class="post-tag" href="/cours/tags/s9/">S9</a> <a class="post-tag" href="/cours/tags/tronc-commun/">tronc commun</a> <a class="post-tag" href="/cours/tags/scia/">SCIA</a> <a class="post-tag" href="/cours/tags/s6/">S6</a> <a class="post-tag" href="/cours/tags/shannon/">Shannon</a> <a class="post-tag" href="/cours/tags/cama/">CAMA</a> <a class="post-tag" href="/cours/tags/loi/">loi</a> <a class="post-tag" href="/cours/tags/rvau/">RVAU</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/cours/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/cours/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/cours/assets/js/dist/post.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" }, tagSide: "right" }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true }, CommonHTML: { linebreaks: { automatic: true } }, "HTML-CSS": { linebreaks: { automatic: true } }, SVG: { linebreaks: { automatic: true } } }); MathJax.Hub.Register.StartupHook("TeX AMSmath Ready", function () { MathJax.InputJax.TeX.Stack.Item.AMSarray.Augment({ clearTag() { if (!this.global.notags) { this.super(arguments).clearTag.call(this); } } }); }); </script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <script type="text/javascript" charset="utf-8" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS_CHTML"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/cours/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-PVWXSNG5J8"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-PVWXSNG5J8'); }); </script>
