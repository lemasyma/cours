[ { "title": "TNSI: Filtres lineaires stationnaires - 2", "url": "/cours/posts/tnsi_filtres_lineaires_stationnaires_2/", "categories": "Image S9, TNSI", "tags": "Image, S9, TNSI", "date": "2021-12-15 14:00:00 +0100", "snippet": "Lien de la note HackmdFiltres lineaires Linearite \\(\\begin{aligned}\\mathcal H\\{ax_1[n]+bx_2[n]\\} &amp;amp;= a\\mathcal H \\{x_1[n]\\}+b\\mathcal H\\{x_2[n]\\} \\\\ &amp;amp;= ay_1[n] + by_2[n]\\end{aligned}\\) Stationnarite \\(y[n]=\\mathcal \\{x[n]\\}\\Leftrightarrow \\mathcal H\\{x[n-n_0]\\}=y[n-n_0]\\)\\[x[n] = \\sum_{p=-\\infty}^{+\\infty}x[p]\\delta[n-p]\\\\\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}x[p]\\mathcal \\{\\delta[n-p]\\}\\\\\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}x[p]h[n-p]=x \\ast h[n]\\] $h[n]$ est la reponse impulsionnelle discrete3.La causalite\\[\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}h[p]x[n-p]\\to h[p]=0\\text{ pour } p\\lt0\\]4.Stabilite\\[\\vert\\mathcal H\\{x[n]\\}\\vert\\le \\sum_{p=-\\infty}^{+\\infty}\\vert h[p]\\vert \\vert x[n-p]\\vert \\le \\sup_{n\\in\\mathbb Z}\\vert x[n]\\vert\\sum_{p=-\\infty}^{+\\infty}\\vert h[p]\\vert\\] On parle de BIBO stability: Bounded Input Bounded output Filtres a reponse impulsionnelle finie (RIF) Filtres a reponse impulsionnelle infinie (RII) Filtre causal Filtre non causalLa TF joue un role fondamental dans lâ€™analyse des operateurs stationnaires\\[\\hat y (\\omega)=\\hat h(x)\\hat x(\\omega)\\quad \\omega=2i\\pi f\\quad \\omega\\in[-\\pi, \\pi]\\] $\\hat h(\\omega)$ est la fonction de transfert ou reponse frequentielle du filtre2 effets: amplitude: amplification $(\\vert \\hat h(\\omega)\\vert\\lt 1)$ phase: decalage et deformation de $x$ExempleSoit $x[n]\\to x_b[n]=x[n]+b[n]$Filtre moyenneur \\(h_{\\Pi}[n]=\\begin{cases}1 \\\\ 0\\end{cases}\\) pour $\\Pi$ echantillons.\\[\\hat h(\\omega)=\\frac{1}{\\Pi}\\frac{\\sin(\\frac{\\omega}{2}\\Pi)}{\\sin(\\frac{\\omega}{2})}e^{-\\frac{\\omega}{2}(\\Pi-1)}\\]Un filtre causal va etre centre en $0$:Un filtre non causal ne lâ€™est pas:On a une suite dâ€™echantillons:Si on applique un filtre causal, on va forcement avoir un decalage dans le tempsTypes de filtres Filtres a phase nulle Filtres a phase lineaire (implique un decalage en temps) Filtre a phase non lineaire\\[\\hat h(\\omega) = e^{-i\\omega a}\\\\\\hat y (\\omega)=\\hat h(\\omega)\\hat x(\\omega) = e^{-i\\omega a}\\hat x(\\omega)\\\\y[n] = x[n-a]\\]Passe-bas ideal\\[\\hat h(\\omega) = \\begin{aligned}1 &amp;amp;\\forall \\vert\\omega\\vert \\le w_c\\\\0\\end{aligned}\\\\\\hat h (\\omega)=\\Pi(\\frac{\\omega}{2\\omega_c})\\quad\\text{ou }\\Pi(x)=\\begin{cases}1&amp;amp;\\vert x\\vert\\le\\frac{1}{2}\\\\0\\end{cases}\\]Reponse impulsionnelle dâ€™un filtre passe-bas ideal TFTd inverse\\[\\begin{aligned}h[n] &amp;amp;= \\frac{1}{2\\pi}\\int_{-\\pi}^{pi}\\hat h(\\omega)e^{i\\omega n}d\\omega\\\\&amp;amp;= \\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega}e^{i\\omega n}d\\omega\\\\&amp;amp;= \\frac{1}{2\\pi}\\frac{1}{in}(e^{i\\omega_cn}-e^{-i\\omega_cn})=\\frac{1}{\\pi n}\\sin(\\omega_cn)\\\\\\end{aligned}\\]Quand on applique une fonction porte en frequence, ca revient a faire une convolution en temps de:En augmentant le nombre dâ€™echantillons: On introduit des artefacts numeriques dus aux approximations mathematiquesConstruire un filtre Lobe principalPente de coupure (transition abrupte de niveau) TODOEquations recurrentes a coefficients constantsOn souhaite resoudre une equation de forme:\\[\\sum_{k=0}^{N-1}a_ky[n-k]=\\sum_{k=0}^{\\Pi-1}b_kx[n-k]\\] $a_k$ equivalent a construire un filtre en passant par lâ€™espace de Fourier $b_k$ controle lâ€™entree pour eviter les effets indesirablesComment calculer ces coefficients ?Et la fonction de trasnfert de ce filtre ? Fourier ?\\[\\frac{\\hat y(\\omega)}{\\hat x(\\omega)}=\\frac{\\sum_{k=0}^{M-1}b_ke^{-ik\\omega}}{\\sum_{k=0}^{N-1}a_ke^{-ik\\omega}}=\\hat h(\\omega)\\]Transformee en ZLa TZ dâ€™un signal discret $x[n]$:\\[X(z) = \\sum_{n=-\\infty}^{+\\infty}x[n]\\underbrace{z^{-n}}_{\\color{red}{\\mathbb C}}\\quad\\text{avec } R_1\\le \\vert z\\vert\\le R_2\\]La TFtd avec $z=e^{i\\omega f}$ La TFtd est egale a la TZ sur le cercle unite Pour nos filtres, il faut donc que le cercle unite appartienne au domaine de convergenceSi on reprend lâ€™equation de depart, sa TZ:\\[Y(z)\\sum_{k=0}^{N-1}a_kz^{-k}=X(z)\\sum_{k=0}^{M-1}b_kz^{-k}\\\\Y(z)=H(z)X(z)\\\\H(z)=\\frac{\\sum_{k=0}^{M-1}b_kz^{-k}}{\\sum_{k=0}^{N-1}a_kz^{-k}}=\\color{red}{c\\frac{\\prod_{k=0}^{M-1}(1-Z_kZ^{-1})}{\\prod_{k=0}^{N-1}(1-Z_kZ^{-1})}}\\]roniqp3ihprelkwfnwlef\\[h[n] = \\frac{1}{N}(ğŸ™_{\\{0,\\dots,N-1\\}})\\\\\\downarrow\\\\H(z) = \\frac{1}{N}(\\sum_{n=0}^{N-1}z^{-n})\\to\\frac{1-z^{-N}}{1-z^{-1}}\\\\H(\\omega) = \\frac{1-e^{-i\\omega N}}{1-e^{-i\\omega}}\\]Specification pour la synthese de filtre Choix dâ€™une bande passante et dâ€™une bande stoppante Forme de la phase Limite de calcul $\\to$ le degre de la fonction de tranfert (cad $M$ et $N$) $\\omega_p$: frequence de coupure de la bande passante $\\omega_s$: frequence de coupure de la bande coupee $\\delta_p$: ondulation en bande passante $\\delta_c$: ondulation en bande coupee $(\\omega_p + \\omega_s) / 2$: frequence de coupure du filtreFiltres RII vs RIFFiltres RII Avantages Desavantage Calcul efficace (recursif) Probleme de stabilite Facile dâ€™obtenir une attenuation forte Difficulte a construire Adapte a lâ€™audio Phase non lineaire \\[H(z) = \\frac{\\Sigma b_kz^{-k}}{\\Sigma a_kz^{-k}}\\]Filtre RIF Avantages Desavantage Toujours stable Probleme de stabilite Synthese optimale possible (algorithme de Parks McCellan) Difficulte a construire Phase lineaire possible Cout computationnel plus eleve \\[H(z) = \\Sigma b_kz^{-k}\\]Filtres RIIFiltres couramment utilises sont issus du monde analogiqueExercice Comparer les filtres de: Butterworth, Chebyshev I, Chebyshev II et Elliptic scipy.signal.iirfilter scipy.signal.freqs $\\to$ tracer entre $[-1, 1]$ Interpreter Suppression composante directe $\\to$ DC biais ($\\to$ signal non centre) Quel filtre frequentiel ? Supprimer $\\omega = 0$ $\\color{red}{\\text{A faire a lâ€™aide de la TZ}}$ \\[\\color{green}{H(z) = c\\frac{\\Pi(1-\\overbrace{z_n}^{\\color{red}{\\text{zeros}}}z^{-1})}{\\Pi(1-\\underbrace{P_n}_{\\color{red}{\\text{pole}}}z^{-1})}}\\]On veut supprimer la frequence a $0$\\[H(z)=c\\frac{\\Pi(1-z_nz^{-1})}{\\Pi(1-P_nz^{-1})}\\quad\\text{on s&#39;en fiche du denominateur}\\\\\\color{red}{\\Pi(1-z_n\\underbrace{z^{-1}}_{=1})=0\\to (1-z_n\\times 1) = 0 \\\\ z_n=1}\\\\H(z) = \\overbrace{1-z^{-1}}^{z^0}\\\\H(\\omega) = 1-e^{-i\\omega n}\\to y[n] = x[n - 0] - x[n-1]\\\\H(z) = \\frac{1-z^{-1}}{1-\\alpha z^{-1}}\\to y[n]-\\alpha y[n-1]=x[n]-x[n-1] \\quad \\alpha\\in[0;1]\\\\h(\\omega) = \\frac{1-e^{-i\\omega}}{1-\\alpha e^{-i\\omega}}\\to y[n]=x[n]-x[n-1]+\\alpha y[n-1]\\]Filtres RIFConstruction optimal par minimaxAlgorithme de Parks % McClellan / algorithme de Remez Phase lineaire Oscillation en bande passante et stoppanteLâ€™algorithme consiste a minimiser lâ€™oscillation maximaleLa phase lineaire est obtenue a partir dâ€™une reponse impulsionnelle symetrique ou antisymetrique (longueur paire ou impaire)\\[H(\\omega) = A(\\omega)e^{-i\\omega\\delta + \\phi_0}\\] Â  Symetrique Asymetrique Impaire $\\color{red}{\\text{Type I}}$ \\(\\text{Retard entier} \\\\ \\phi_0 = 0 \\\\ \\text{pas de zeros imposes}\\) $\\color{red}{\\text{Type III}}$ \\(\\text{Retard entier} \\\\ \\phi_0 = 0 \\\\ \\text{zeros imposes en }\\omega = 0 \\text{ et } \\pi\\) Paire $\\color{red}{\\text{Type II}}$ \\(\\text{Retard non entier} \\\\ \\phi_0 = \\pi/2 \\\\ \\text{zeros imposes en }\\omega = \\pi/2\\) $\\color{red}{\\text{Type IV}}$ \\(\\text{Retard non entier} \\\\ \\phi_0 = \\pi/2 \\\\ \\text{zeros imposes en }\\omega = 0\\) Exercice Designer un filtre simple par troncature en choisissant judicieusement la fenetre Creer un filtre avec scipy et lâ€™algorithme de minimax (signal.remez) Analyser lâ€™impact des parametres Solution On fait comme si Fourier se met des oeilleres On veut appliquer une fonction porte Soit $P$ impulsion dâ€™une fonction $e$ emise a differents instant. On souhaite retrouver les instants des differentes impulsions\\[\\begin{matrix}e[n] = \\underbrace{\\sum_{k=0}^{K-1}\\alpha^k\\delta[n-k]}\\quad \\alpha\\in]0;1[&amp;amp;y[n] = (x\\ast e)[n]\\\\\\sum_{n=0}^{K-1}\\alpha^kz^{-n}=\\frac{1-\\alpha^Kz^{-K}}{1-\\alpha z^{-1}}&amp;amp;Y(z)=X(z)\\ast E(z)\\begin{aligned}&amp;amp;\\to \\frac{Y(z)}{E(z)} \\\\ &amp;amp;\\to \\frac{1}{E(z)}\\end{aligned}\\end{matrix}\\\\H(z)\\cdot Y(z)\\\\H(z) = \\frac{1-\\alpha z^{-1}}{1-\\alpha^Kz^{-K}}\\to y[n]-\\alpha y[n-1] = x[n] - \\alpha^K x[n-K]\\] Trouver un filtre a lâ€™aide de la TZ qui permet de retrouver $x$ (en connaissant $e$) Determiner le filtre en temps" }, { "title": "ISAT: HSI", "url": "/cours/posts/isat_hsi/", "categories": "Image S9, ISAT", "tags": "Image, S9, ISAT", "date": "2021-12-10 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionHyperspectral imagesLes acquisitions dans le domaine spectral (les bandes) presente un echantillonage beaucoup plus fin.Lâ€™image est en fausse couleur, on a des tenseurs a 3 voies: $x$, $y$ et les bandes spectrales. Sur cette image on a associe 3 bandes au RGB, câ€™est une reconstruction partielle mais ca permet de visualiser.Câ€™est des images aeriennes du massif du Mont Blanc.Quelle est la variable physique qui nous interesse ? Ici, la variable physique qui nous interesse si on veut faire une analyse continue de la scene est la reflectance.Sâ€™il nâ€™y a pas de transmission, la reflectance est directement liee a lâ€™absorbance.On souhaite avoir des images exploitable, on veut un rapport image/bruit suffisant. On a typiquement un seul capteur qui a un systeme de diffraction optique (prisme, etc.), la lumiere va arriver et etre diffractee et reflechie dans differentes longueurs dâ€™onde. On nâ€™arrive pas a voir un bloc entier tout dâ€™un coup lors dâ€™une acquisition Si on veut 600 bandes, on va devoir faire un compromis sur la resolution spatiale et spectrale.On va avoir des imageurs qui ont une faible resolution spatiale ($\\sim 30m$) mais il y a un 2e capteur associe qui fait lâ€™acquisition dâ€™une bande panchromatique.On arrive a avoir des informations assez precises sur la reflectance des differents materiaux. On a $\\sim 600$ echantillons pour la reflectance.Des quâ€™on passe dans lâ€™infrararouge, on a une reflectance plus importante, due a la presence de la chlorophyle.Toutes les bandes sur le â€œred edgeâ€ ($\\sim 0.7\\mu m$), ou on a la montee raide du spectre de reflectance de la vegetation, qui permet de discriminer certaines especes. Câ€™est la variable physique dâ€™interet que lâ€™on essaie dâ€™extraire.ExampleQuel est lâ€™interet de faire des acquisitions au-dela du domaine visible ?Regardons differentes bandes des plantes:Dans le proche IR: On trouve une difference dans la 3e plante (elle est en plastique)ApplicationsDans des contextes pas forcements lie a la teledetection: Detection dâ€™hydrocarbure dans lâ€™eau Lâ€™huile superposee a de lâ€™eau a un spectre relativement proche de celui de lâ€™eauSi on fait le traitement dâ€™une image avec plus dâ€™acquisition: On extrait de lâ€™information â€œcacheeâ€ Monitorage et caracterisation des differents mineraux Biomedical Detection de tumeurs de la peau Astronomie Telescope â€œMuseâ€ Lâ€™art Certaines oeuvres ont des proprietes de transmittance variant selon la longueur dâ€™onde Câ€™est possible de detecter des couches invisibles a lâ€™oeil nu Controle non-destructif Evolution dâ€™un poisson dans le temps Detection precoce de la peremption de lâ€™echantillon Spectral UnmixingUne potentielle limitation de cette imagerie quâ€™on trouve assez souvent: la resolution spatiale faible $\\to$ certains objets ne sont pas completement resolusOn mesure des combinaisons en fonction des spectres des elements constituant la scene.On souhaite des echantillons en reflectance, on a une conversion a faire depuis la radiance.Si on traite une image RGB, chaque pixel est un vecteur avec $3$ composantes. Ici, on a $600$ composantes, câ€™est une problematique liee a la grande dimension des donnees.What to mine ?On peut utiliser une bibliotheque/catalogue de spectres de differents materiaux pour lâ€™unmixingOn a 2 possibilites de traitement: Spectral processing Information resides in the spectral signature of the pixels Pixels can be processed independently Approaches issuing from multivariate statistics and linear algebra Objects of interest could by sub-pixel size Analysis done on the full image Spatial processing Information resides in the spatial organization of pixels Pixels are processed together (analysis done on local parts of the image) Use image processing tools Objects of interest are fully resolved Analysis of the spectral domainHSI scene classificationSpectral classificationHigh number of features ? When the dimensionality of the problem is high How calssification accuracy depends upon the dimensionality (and amount of training data)? Computational complexity of designing the classifier ? Classification accuracy Bayes error depends on the number of statistically independant features Exampe: consider binary classification problem with $p(x\\vert \\omega_j)\\sim\\mathcal N(\\mu_j,\\Sigma_j)$ $(j=1,2)$, when $P(\\omega_{1,2})=0.5$: \\[P(e) = \\frac{1}{\\sqrt{2\\pi}}\\int_{r/2}^{+\\infty}e^{-\\frac{u^2}{2}}du\\] with $r^2=(\\mu_1-\\mu_2)^T\\Sigma^{-1}(\\mu_1-\\mu_2)$ the squared Mahalanobis distance $P(e)\\searrow$ for $r\\nearrow$ In the case of conditionally independent features $\\Sigma = \\text{diag}(\\sigma_1^2,\\dots,\\sigma_d^2)$ $r^2 = \\sum_{i=1}^d(\\frac{\\mu_{i,1}-\\mu_{i,2}}{\\sigma_2})^2$ Il y a des zones ou on a un recouvrementOn peut augmenter la dimensionnalite, rajouter un descripteurAttention a la malediction de la dimensionnalite Intuition fails in high dimensions Curse of dimensionality (Bellman, 1961): many algorithms working fine in low dimensions become intractable when the input is high-dimensional Generalizing correctly becomes exponentially harder as the dimenonality grows, because a fixed-size training set covers a smaller fraction of the input space In high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful Similarity measures based on $l_k$ norms loose meaning with respect to $k$ in high dimensions $l_1$ norm (Manhattan distance metric) is more preferable thant the Euclidean distance metric $(l_2)$ for high dimensional data miningHSI in high dimensions Volume of a hypersphere The volume of a hypersphere of radius $r$ in a $p$-dimensional \\[V_s(r)=\\frac{r^p\\pi^{\\frac{p}{2}}}{\\Gamma(\\frac{p}{2}+1)}\\] Volume of a hypercube $[-r, r]^p$ \\[V_c(r) = (2r)^p\\] The fraction of the volume contained in the inscribed hypersphere \\[f_{p_1}=\\frac{V_s(a)}{V_c(a)}=\\frac{\\pi^{\\frac{p}{2}}}{2^p\\Gamma(\\frac{p}{2}+1)}\\] Fraction of the volume of a thn spherical shell defined by a sphere of radius $r$ inscribede inside a sphere of radius $(r-\\varepsilon)$ to the volume of the entire sphere: \\(\\begin{aligned}f_{p_2}&amp;amp;=\\frac{V_s(r)-V_s(r-\\varepsilon)}{V_s(r)}\\\\&amp;amp;=\\frac{r^p-(r-\\varepsilon)^p}{r^p}\\\\&amp;amp;= 1-\\biggr(1-\\frac{\\varepsilon}{r}\\biggr)^p\\end{aligned}\\)On veut voir le rapport du volume entre une sphere et le carre qui inscrit la sphere. Small sample size Number of samples for accurate classification: Si on nâ€™a pas assez dâ€™echantillon pour notre estimation, notre estimation ne sera pas robuste Curse of dimensionality ! Computational complexity The blessing of non-uniformity In most application examples are not spread uniformly throughout the instance space, but are concentrated on or near a lower-dimensional manifold Intrinsic dimensionality of the data might be difficult to estimate in real data Dimensionality reduction Dimension reduction aims at representing data in a reduced number of dimensionsReasons: Easier data analysis Improved classifcation accuracy More stable representation Removal of redundant or irrevelant information Attempt to discover underlying structure by obtaining a graphical representation Dimensionality reduction is usually obtained by feature selection or extraction Feature selection keeps only some of the features according to a criterion leading to new subset of features with lower dimensionality\\[x&#39;=[x_1,x_2,x_3,x_4,\\dots,x_d]^T\\\\x&#39;=A^Tx\\] with\\[A=\\begin{pmatrix}\\color{red}{1}&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;\\color{red}{0}&amp;amp;0&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;0&amp;amp;\\color{red}{1}&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;\\color{red}{0}&amp;amp;\\dots&amp;amp;0\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;\\dots\\color{red}{1}\\end{pmatrix}\\] Feature extraction transform the data in a space of lower dimensionality with an arbitrary function $f$\\[x&#39;=f(x)\\quad\\text{with } f:\\mathbb R^d\\to\\mathbb R^n, n\\lt d\\]Example: Color compositeThe pigment in plant leaves, chlorophyll, strongly absorbs visible light (from $0.4$ to $0.7\\mu m$) for use in photosynthesis. The cell structure of the leaves, on the other hand, strongly reflects near-infrared light (from $0.7$ to $1.1\\mu m$). The more leaves a plant has, the more these wavelengths of light are affected, respectively.Normalized Difference Vegetation Index (NVDI)\\[\\text{NDVI} = \\frac{b_{NIR}-b_{RED}}{b_{NIR}+b_{RED}}\\] ExampleExploratory analysis Covariance matrix A partir du moment ou câ€™est tres correle, on peut reduire les dimensions tout en conservant une partie de lâ€™informationQuelle est la definition de la matrice de covariance ? Câ€™est ce qui permet de visualiser la dependance des bandes entre ellesSur lâ€™image ci-dessus, les variables globalement entre $80$ et $100$ ont une correlation relativement elevee. Correlation matrix Si on affiche les valeurs de la diagonale de la matrice:Feature extractionEigen decomposition of the covariance matrix:\\[\\Sigma = \\phi \\Lambda \\phi^T\\]with $\\Lambda$ the matrix of eigenvalues (values only on the diagonal) and $\\phi$ the matrix of eigenvectorsPrincipal Component AnalysisApplicationDenoisingTestLet us consider the data $X\\in\\mathbb R^{b\\times n}$ with $n$ samples of $b$ bands and centered at the origin. Matrix $\\Phi=[\\phi_1,\\dots,\\phi_d]$ is composed of $d\\lt b$ eigenvectors extracted from the $n\\times n$ covariance matrix $\\Sigma$ of the data $X$Which transformation would you apply to the data for denoising based on the concepts seen so far ? $Y=X_{[1:d,:]}$ $Y=\\Sigma X$ $Y=\\Phi X$ $Y=\\Phi^T X$ $Y=\\Phi\\Phi^T X$ $Y=\\Phi^T\\Phi\\Phi^T X$Spectral Mixture AnalysisSpectral mixingLinear mixing model\\[x=\\sum_{k=1}^ma_ks_k+e=Sa+e\\] $x$: Spectrum of a pixel $a$: Coefficients in the mixture (abundance) $S$: Spectra of the sources of the mixture (endmembers) $e$: NoiseContraintes: Sum to $1$\\[\\sum_{k=1}^ma_k=1\\] Non negativity\\[\\begin{aligned}a_g\\ge 0\\\\S_{k,\\lambda}\\ge 0\\end{aligned} \\quad \\forall k\\]Geometrical interpretationOn a un cas tres simple:\\[\\begin{cases}x = a_1s_1 + a_2s_2\\\\a_1+a_2 = 1\\end{cases}\\]Dâ€™un point de vue representation, si on considere les vecteurs $s_1$ et $s_2$, toutes les valeurs de $x$ definies par lâ€™equation ci-dessus sont retrouvees dans le segment $s_1\\leftrightarrow s_2$Endmember determination techniquePrinciples: Endmembers are the vertexes of the simplex $\\to$ find extrema when projecting the data on a line The convex-hull of the data encloses the simplex $\\to$ find endmembers such as to maximise the volumeAbundance If the endmembers are available: Solve a minimization problem of the form:\\[\\hat A = \\text{arg}\\min_A\\Vert X-AS\\Vert^2_F\\quad \\text{s.t. Constraints}\\] If the endmembers are not available: Use alternating minimization techniques (e.g., Non-negative matrix factorization)Hyperspectral in nature Mantis shrimp visual system $12$ different types of color photoreceptors see in the UV, VIS and NIR spectral domains $3$ focal points per eye ($6$ in total, we have $2$) see polarized light (linear vs circular) Bonus" }, { "title": "ISAT: Remote sensing", "url": "/cours/posts/isat_remote_sensing/", "categories": "Image S9, ISAT", "tags": "Image, S9, ISAT", "date": "2021-12-09 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionRemote sensingWhat is remote sensing ? Remote: operating without a direct contact Sensing: perform a measure Measure something at a distance, rather than in situ. It relies on propagated signal of some sort, for example optical, acoustical, or microwaveRemote sensing imagePanchromatic imageLa particularite de ces systemes est quâ€™ils ont leur propre source dâ€™illumination, en envoyant des signaux qui interagissent avec des objets dâ€™interete. Exemple: on prend une photo avec de la lumiere, câ€™est un systeme actifIci on sâ€™interesse a la teledetection ou on utilise des sources dâ€™illumination externe (le soleil)On sâ€™interesse principalement au regime optique de la lumiere, avec de lâ€™optique geometrique. On est dans les plages du visible a lâ€™infrarouge.On va regarder lâ€™heterogeneite des donnees quâ€™on peut avoir en teledetection:MultispectralOn a aussi des images multispectral:HyperspectralFrom low spatial resolutionâ€¦To high spatial resolutionSpatial details in satellite imagesSpatial details in aerial imagesSpatial details in drone images Bonne precision pour identifier des feuilles de plante, utile pour verifier leur etat de sante Jâ€™espere que vous vous en rappelezMultitemporal images Ce sont les Alpes, par-dessus GrenobleCe sont des recombinaisons fausses couleursIl y a des parties manquantes sur lâ€™image a cause des nuagesOn a une acquisition par jour par satellite, et on a 2 satellites. On arrive a faire un suivi de certains phenomenesOn a certaines satellites â€œAgileâ€ capablent dâ€™orienter leurs camerasVoici dâ€™autres acquisitions:En comparant les images, on voit clairement le deplacement de la cameraMultiangular drone imagesOn entre en convergence en computer vision, on retrouve les memes problematiques.ApplicationsThematic classificationOn veut tirer des informations de ces images, par exemple: semantic segmentationAnomaly detectionDetecter des evenements rares comme des phenomenes naturels.(Video) Nearly 20 Years of Change at Your FingertipsOptical radiation modelOptical Remote sensing principleQuant a la source dâ€™illumination:On a des longueurs dâ€™ondes beaucoup plus elevees par rapport a ce quâ€™on utilise dans les capteurs optiques, on peut aller jusquâ€™aux ondes radiosSolar radiation The spectral radiant exitance ($M_{\\lambda}[Wm^{-2}\\mu m^{-1}]$) of a black body is modeled by Plancâ€™s blackbody equation\\[M_{\\lambda} = \\frac{C_1}{\\lambda^5(e^{\\frac{C_2}{\\lambda T}}-1)}\\] $C_1, C_2$ constant $\\lambda$ wavelength $[\\mu m]$ $T$ black body temperature $[K]$ The blackbody function peaks at a wavelength given by Wienâ€™s law\\[\\lambda_{max} = \\frac{2989}{T}\\]Pour le soleil, le pic dâ€™emission par rapport a sa temperature se trouve dans le visibleSolar spectral irradiance $E_{\\lambda}^0$ spectral irradiance $[Wm^{-2}\\mu m^{-1}]$ power density that reaches the earth Quantite dâ€™energie Spectral irradiance at the top of atmosphere \\[E_{\\lambda}^0 = \\frac{M_{\\lambda}}{\\pi}\\times\\frac{\\text{area solar disk}}{(\\text{distance to earth})^2}\\]Et le Red-Shift ? On a un soleil dans une autre galaxie, si lâ€™emission de cette etoile etait dans le jaune mais que la galaxie se deplace, on a une reduction en frequence quâ€™on voit comme un shift dans le spectre dâ€™emissionCâ€™est lâ€™effet Doppler qui fait ca, caracterise par la nature ondulatoire de la lumiereCâ€™est comme ca quâ€™on arrive a estimer les velocite de galaxiesOn relie ca aux gazs presents dans les etoiles, ces derniers ont des spectres dâ€™emissions particulier donc avec le red-shift on peut estimer le decalageSolar/Earth radiationTout corps avec une temperature $\\le 0K$ aura un spectre dâ€™emission hors du visibleRadiation ComponentsOn est a lâ€™exterieur de lâ€™atmosphere:Optical remote sensing componentRadiation mechanismRadiation component Radiance reaching the satellite sensor\\[L_{\\lambda}^s = L_{\\lambda}^{su} + L_{\\lambda}^{sd} + L_{\\lambda}^{sp}\\] $L_{\\lambda}^{su}$ the unscattered, surface-reflected radiation $L_{\\lambda}^{sd}$ the down-scattered, surface-reflected skylight $L_{\\lambda}^{sp}$ the up-scattered path radiance Surface-reflected, unscattered component $L_{\\lambda}^{su}$ The atmosphere interacts with radiation both on the solar and view path The fraction or radiation that arrives at the earthâ€™s surface is the solar path transmittance, $\\tau_s(\\lambda)$ The molecular absorption bands of water and carbon dioxide cause deep absorphtion features that, in 2 bandas near $1.4\\mu m$ and $1.9\\mu m$, completely block transmission of radiationSolar path $0$: Rien qui est transmis $1$: La couche est totalement transparenteExemple: Sentinel-2 spectral responsesAtmospheric scattering mechanismsLâ€™aerosol est la composante principale qui va determiner lâ€™absorption. Ces bandes ne sont pas forcement utiles pour le monitorage de la surface terrester mais sont des indicateurs lors du moment de lâ€™acquisition.Si on considere lâ€™interaction de la couche atmospherique avec la source dâ€™illumination, on a la transmission qui va determiner une modulation de lâ€™energie. Atmospheric scattering Absorption mainly due to molecules of oxygen, carbon dioxide, ozone and water which attenuates the radiation very strongly in certain wavelengths Scattering by atmospheric particles is the dominant mechanism that leads to radiometric distortion in image data Rayleigh scattering scattering due to air molecules effect proportional to $\\lambda^{-4}$ scattering mechanism in a clear sky Mie scattering scattering by aerosol (e.g. smoke, clouds, haze) with molecules larger than those of the air ($1-10$ times $\\lambda$) not much dependent on the wavelength On a du scattering avec des nuages ou du brouillard Ce type de scattering nâ€™est pas forcement selectif en fonction de la longueur dâ€™ondeInteraction with the surfaceSolar path Spectral irradiance at the earthâ€™s surface\\[E_{\\lambda} = \\tau_s(\\lambda)E_{\\lambda}^0\\]Irradiance at the surface The irradiance at the surface depends on the incident angle The incident irradiance \\[E_{\\lambda}(x,y) = \\langle\\tau_s(\\lambda)E_{\\lambda}^0n(x,y), s\\rangle = \\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]\\]Surface radiance The incidence radiation interacts with the materials on the surface Assumption of a Lambertian surface $\\to$ equal radiance in all directions surface radiance $L_{\\lambda}(x,y)$ \\[\\begin{aligned}L_{\\lambda}(x,y) &amp;amp;= \\rho(x,y,\\lambda)\\frac{E_{\\lambda}(x,y)}{\\pi}\\\\&amp;amp;=\\rho(x,y,\\lambda)\\frac{\\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]}{\\pi}\\end{aligned}\\] with $\\rho$ the diffuse spectral reflectance, $\\pi$ geometric factor Bi-directional Reflectance Distribution Function (BRDF) \\[BRDF(x,y,\\phi,\\theta)\\simeq \\frac{L_{\\lambda}(\\phi)}{E_{\\lambda}(x,y)}\\]Measuring the BRDFAt the sensorRadiation mechanismOn mesure la combinaison de ces 3 composantes au niveau du capteurRadiance at the sensor Radiance reaching the sensor passes through the atmosphere Depends on the view angle at-sensor radiance \\[\\begin{aligned}L_{\\lambda}^{su}&amp;amp;= \\tau_{v}(\\lambda)L_{\\lambda}\\\\&amp;amp;= \\rho(x,y,\\lambda)\\frac{\\tau_{v}(\\lambda)\\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]}{\\pi}\\end{aligned}\\] with $\\tau_v(\\lambda)$ the view path transmittance.Surface reflected, atmosphere-scattered component $L_{\\lambda}^{sd}$ The sensor also sees radiance arising from radiation that is scattered downward by the atmosphere (â€œskylightâ€) and then reflected at the earth upward Radiance due to skylight \\[L_{\\lambda}^{sd} = F(x,y)\\rho(x,y,\\lambda)\\frac{\\tau_v(\\lambda)E_{\\lambda}^d}{\\pi}\\] with $E^{d}_{\\lambda}$ the irradiance at the surface due to skylight and $F(x,y)$ the fraction of the sky hemisphere that is visible from the pixel of interest.On peut comparer ces 2 images:Les zones dâ€™ombre nâ€™ont pas de composante direct dâ€™illumination. On recoit lâ€™information dâ€™une composante qui est reflechi sur cette zone qui est reflechi par lâ€™atmosphere.Sans atmosphere, on nâ€™a pas dâ€™information car pas dâ€™eclairage (photo 2). Lâ€™interet est dâ€™essayer de voir, si on traite une image donnee, quelles sont les variables physiques dâ€™interet.Image formation in optical sensorsAcquisition geometry Directions Cross-track Along-track Scanners Line scanner Whiskbroom scanner Pushbroom scanner Geometry of acquisition different from pinhole Field of view (FOV) full cross-track angular coverage Ground-projected Field Of View (GFOV) ground coverage of the FOV Instaneous Field of View (IFOV)\\[\\text{IFOV} = 2\\arctan \\biggr (\\frac{w}{2f}\\biggr)\\simeq \\frac{w}{f}\\] $f$: focal length $w$: size of a detector element Instantaneous Ground-projected Field Of View (GIFOV)\\[\\text{GIFOV} = 2H\\tan\\biggr(\\frac{\\text{IFOV}}{2}\\biggr)\\simeq \\frac{w}{m}\\] Ground-projected Sample Interval (GSI)\\[\\text{GSI} = w_d\\cdot\\frac{H}{f}=\\frac{w_d}{m}\\] with $w_d$ the inter-detector spacing GSI determined by cross-track and in-track sampling rates Cross-track GSI usually matches the GIFOV In-track GSI depends on the sampling rate and the platform velocity (and scanning velocity) Overall sensor modelSensor characterizationThe sensor will sense the physical signal with a non-zero Integration time Spectral bandwith Spatial distance Generic sensor model\\[o(z_0)=\\int_w i(\\alpha)r(z_0-\\alpha)d\\alpha\\\\o(z) = i(z) * r(z)\\] $z$ physical quantity to measure $o(z)$ sensor output $i(z)$ input signal $r(z)$ sensor response Spatial resolutionPourquoi on descend a des resolutions tres poussees ? Car dâ€™un point de vue technologique, on arrive a produire des capteurs avec des grande precisionsOn est limites a un facteur qui est le rapport signal/bruitPoint spread functionDâ€™un point de vue de caracterisation des instruments:Cette transformation est donnee par la point spread function. Câ€™est la reponse a une impulsion sur un Dirac (ici un point tres brillant qui va etre â€œetaleâ€ par un point optique)The sensor modifies the spatial properties of the signal blurring distortion of geometry The blur is characterized by Point Spread Function (PSF) The acquired electronix signal $e_b$ representing the signal $s_b$ given by: \\(e_b(x,y)=\\int_{\\alpha_{min}}^{\\alpha_{max}}\\int_{\\beta_{min}}^{\\beta_{max}}s_b(\\alpha,\\beta)\\text{PSF}(x-\\alpha, y-\\beta)d\\alpha d\\beta\\\\e_n = \\text{PSF}*s_b\\)The PSF is composed of different components: optical PSF $\\text{PSF}_{opt}$ image motion $\\text{PSF}_{im}$ detector PSF $\\text{PSF}_{det}$ electronix PSF $\\text{PSF}_{el}$\\[\\text{PSF} = \\text{PSF}_{opt} * \\text{PSF}_{im} * \\text{PSF}_{det} * \\text{PSF}_{el}\\] The 2D PSF is assumed to be separable:\\[\\text{PSF}(x,y) = \\text{PSF}_c(x)\\text{PSF}_i(y)\\] Optical PSF The optics spread a punctual light source on the focal plane Effect due to Optical diffraction Lens aberrations Misalignments of the optics Typically the $\\text{PSF}_{opt}$ is modeled as a 2D Gaussian function \\[\\text{PSF}_{opt}(x,y) = \\frac{1}{2\\pi ab}e^{-\\frac{x^2}{a^2}}e^{-\\frac{y^2}{b^2}}\\] with $a$ and $b$ the width of the PSF in the cross- and in-track direction Detector PSF Blurring due to the non-zero spatial extent of each cell in the detector The blur is uniform over the spatial area of the detector Typically the $\\text{PSF}_{det}$ is modeled as a 2D rectangular pulse function \\[\\text{PSF}_{det}(x,y) = \\text{rect}\\frac{x}{w}\\text{rect}\\frac{y}{w}\\] with $w$ the width of the PSFModulation Transfer Function Câ€™est les modules de la reponse sous filtreOn retrouve ces profils dans les directions de deplacement de la plateforme Dâ€™un point de vue configuration, on ne veut pas avoir de superpositionPoint Spread Function and samplingOn fait une sorte de filtre anti aliasingSpectral resolution Si on prend un capteur quâ€™avec 4 bandes, on aura 4 valeurs par acquisitionLa resolution sera differentes quâ€™avec plus de capteursSpectral response The digital number (DN) stored in a pixel $p$ is (approximately) given by\\[\\text{DN}_{pb} = K_bL_{pb} + offset_b\\] with $K_b$ and $offset_b$ the gain and offset in the A/D conversionBayer patternMultispectral sensorsExample: WorldView2 sensorSpectral responses Ca permet de garantir dâ€™avoir des niveaux dâ€™energie suffisantExample: Sentinel-2 spectral responseExample: VEN$\\mu$SVEN$\\mu$S (Vegetation and Environment monitoring on a New MicroSatellite)Illustration of a three-array TDI detector unit (image credit: EIOp Ltd.)Question - The rainbow plane Trouvee sur Google EarthOn a des repliques colorisees differement de cet avionPourquoi ? On a fait les acquisitions de differents spectres a differents momentsPourquoi on a les â€œcontoursâ€ de lâ€™avion ? On dirait le domaine frequentiel On dirait un gradient de lâ€™avionCe sera donc une derivee premiere ou seconde calculee sur lâ€™image de lâ€™avion.Pourquoi faire ca ? Car câ€™est la fusion dâ€™une image panchromatique avec une image multispectrale RECAP: surligner les effets lies a la physique et la nature, et aborder les concepts lies a la formation de lâ€™image dâ€™un point de vue de lâ€™acquisition" }, { "title": "TVID: L&#39;audio numerique en pratique", "url": "/cours/posts/tvid_audi_numerique/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-12-06 10:00:00 +0100", "snippet": "Lien de la note HackmdOnde sonoreLe briques de base de la compression du son sont un peu differentes de celle de la video.Perception du sonQuâ€™est-ce que câ€™est le son ? Onde sonoreVariations de pressions convoyees par un milieu gazeux Pour la perception: Oreille humaine Transducteur sonore $\\Rightarrow$ signaux electriques Trois parties: Oreille externe: captation Oreille moyenne: amplification Oreille interne: transducteur Oreille externe Collecte et amplifie les sons Localise les sons (pavillon, phase) Lâ€™envoie dans le conduit auditif Protege le tympa (cerumen)Oreille moyenne Vibration aerienne $\\to$ solidienne (tympan) Transformer les vibrations accoustiques en vibrations solides Amplification: marteau / enclume / etrier Protection niveaux forts (80dB): reflexe stapedienOreille interne Transforme le signal en signal electrique Vestibule: centre de lâ€™equilibre Cochlee: transforme les vibrations en signaux electriques Recouverte de cellules cillees Hautes Frequences en bas (debut) Basses Frequences en haut (fin) Membrane basilaire: filtre special parole meme en environnement bruyant Accouphenes: cellules cillees petees qui envoient nâ€™importe quoiLie aux problemes de circulation du sangAussi lâ€™usure: on a ecoute des trucs trop fortsSpecifications Spectre: $20 HZ \\to 20 KHz$ Perception dâ€™intensite logarithmique $dB = 3\\times\\log_2(ratio)$ $3 dB: \\times2, 20 dB:\\times 100$ Jusquâ€™a $120dB$ pour lâ€™oreille Seuils de perception minimale variablesEnregistrement du son ObjectifCapter les variations acoustique dans un materiauAnalogique: Transduction solide Transduction magnetiqueNumeriques: Representations binaires Nombreuses Fete du string pour les formats Transduction solide du son Principe Amplifier lâ€™onde avec un pavillon Graver lâ€™onde dnas un materiau par un mobile Pionnier: phonographe, Thomas Edison, 1877 En verite, câ€™est un francais, Edouard-Leon Scott de Martinville, 1860 le pionner avec le Phonautographe On ne pouvait que ecrire, relire detruisais le charbon quâ€™il utilisait pour graver On a reussi a reconstruire un de ses enregistrements ou il chante au clair de la lune aÌ·Í‚Ì€Í„Í‘ÍƒÌ†Í‚ÍŒÍƒÌ€ÌˆÌÍÌ’ÍÌ‚ÍÌ•Í›Í‘Í’Ì‘Í‘Ì™Í”Ì³Ì¹Ì±Ì­Í”Ì²ÌºÌ³Í‰ÌªÌ°Ì¼uÌ¸Ì’Ì…Ì‰ÌšÌ¾Ì•Í„ÍÍŒÌÍÌ¼Ì¼Ì«Ì™Í”Ì³ÍœÌºÌ–ÍœÌ¯Ì³Ì¼Ì³Í“ÌªÌªÌ¨Ì«Ì¨Í”Í–Ì˜Ì¤Ìœ Ì´Ì”Í‘Ì¹Ì¥ÌÌºÌ«Ì˜Ì¬Ì©Í“Ì£ÍˆcÌ¶Ì‹ÍœÌ²Ì Ì¥Ì«Í“ÍœÍœÌ lÌ¶Í—Ì‰Ì‡Ì†ÌƒÌ‡ÌŠÌ•Ì€Ì“ÍÌ”ÌˆÍ†Ì•Ì›Ì¾Ì…ÌÌÌ€Ì‘ÍÌ”ÌÍ ÌšÌÌ¿Ì†Í”ÌŸÌ¥ÌœÍšÍšÌ—ÌªÌ±ÍÌ§ÍœÍˆÍÌ¡Í…Í–ÌªÌ£Ì£Í•Ì§Ì¨Ì©Í•Ì©Í…Í”Ì­Í–ÌŸÍšaÌ¸Í’ÌÍ‘Í›Ì…Ì€ÍƒÍ—Ì½Ì‘Ì†Í‘Ì€Í‚Í‚Í‚ÌŸÍ‡ÍšÌ£Ì²ÌœÍ‰Í“Ì¨ÌºÌ¡Ì«Ì­ÌŸÌ–Ì˜ÌÌÌ¼Ì™ÌÌ­Ì­Ì¢ÍÍšÌ¤Ì™ÌºÌ Ì§iÌ´Ì‚Ì…ÍÌ„Ì¿Í‚Í‰Ì¢Ì¨ÌÌ˜Ì˜Í•Ì¨Ì¡Ì–Ì¤ÍœÌ®Ì±ÍšÌÍœÌ˜ÌºrÌ·ÌŒÍ„Í„Í Ì†Ì¿Ì‚Ì½Ì‚Ì”Ì¾ÍÍ„ÌƒÌ›Í‚Í›Ì“Ì‘Í‹Ì’Í‹Ì›ÌÌ†Í„ÌÌ“ÍƒÍ€Ì†Í‹ÍˆÍœÍšÌ¥Ì­ÍœÌ–Ì­Í‰ÌºÍ“Ì°ÍšÍÌ³Ì¹ÌŸÌœÍ”Ì­Ì–Ì°Ì¥Ì– Ì´Í’ÌšÍ†Ì¿Ì‡Ì•Ì“ÌŒÍŒÌ…ÌˆÍÌ’Ì‘Ì½ÍÌˆÌ›ÌÌˆÌ…Ì¾ÍƒÌ’Í€Ì„ÍÍÍƒÌŠÍ—Ì‚Í„Í†ÍŒÌªÌ¯ÌÌÍˆÌ–ÌœÌ»ÌºÍ“Ì¥Ì­ÌÌ¥Ì˜ÌÌ–Ì°Ì Ì¢Ì©Ì±Ì¬Ì¼Í™Ì—ÍˆÌ³ÍœÌ³Ì§Ì¡Ì¡Í…ÌÍ‰Ì—Ì©dÌ¸Í‘ÌˆÌ”ÍÍ€Ì’Ì‚Í€Í‹ÌÍ„ÍƒÍ„Ì”Ì½Ì“ÌÌ…ÌÍÍŠÌ‘ÌºÌÌ¦Í‡Ì¢Í…Ì˜Ì™ÌªÍ–Ì»ÍÍšÌºÍ•Ì¼Í“Ì¦Ì²Í–Ì©ÌÌ«Ì ÍœeÌ¶Ì¿ÌÌšÍ›ÍÍ‚Ì‘ÍÌ“Ì‘Í’Ì€ÌÍ„Ì³Í‰Ì¼ÍÍ‰Ì¯Í Ì¶Í’Í„ÌÌ’Ì”ÌÍ„ÌšÌ„ÌŒÍ‹Ì‘ÍÍ‹Ì„Í—ÍÌ½Ì…Í‘Ì‹Í—ÌÍÍ„ÌšÍŠÌ¾ÌÌ’Í„Í„Ì•ÌÍÌ¿ÌÍÌ„ÌªÌ»Ì˜Í“Ì¹Ì°Ì¬Ì¥ÍšÌŸÌ»ÌÍ…ÍœÌ¢ÍšÍÍÍÌ—Ì²Ì©Ì¦ÌªÌ£Ì¦Í‰ÍˆÌ©Ì¯Ì¤Í•ÍœÌŸÍ™ÌÌ™lÌµÌŠÌ†Ì‰ÌÌ”ÍÌšÌ’Ì‹Í’Ì‚ÌŒÌšÍ„Ì’Ì„Ì„ÌšÌ–Ì¹ÌŸÍšÌÍˆÌ™Ì¡Ì˜Ì—ÍˆÌ­ÍÌ²Í‰Ì©Ì¥Ì™Í–Ì»Í“Ì¼ÍšÌ±ÍÍ–Ì¤ÌÌºÌ±ÌºÍÌ²Ì°Ì¯Ì¥aÌ¶Ì„ÍÌƒÍ€Ì€ÌŠÍƒÍ‚ÍƒÌÍÌÌÌ½Ì­ÌÌºÌ™Í–ÍÍ–Ì£Ì˜Ì¯Ì¢Ì¤Í“ÌºÌÌ Í‡Ì¢Í™ÍˆÌ¦Ì»Ì˜Í”Ì­Ì®ÌÍ“ÌªÍ…Ì˜Ì¨Ì¡ Ì´Ì•Í‹Ì”Ì‘ÍÌÍ’Ì“Í‚ÍÌ‘ÌˆÌˆÌŒÌ†Í ÍÌÍ’Ì‘Í‹Ì”Ì‚Í‘Í„ÌšÍ‚Ì­Ì¨Ì§Ì¢Ì³Ì—Ì®Í”ÍˆÍÌ˜Í™Ì£Ì ÌÌ™lÌµÌ•ÌˆÍ Ì¾Í—ÌÌÌŠÌ†Ì›Ì…ÌÌ„ÌšÌ“ÌÌ•ÌÌ‰ÌÌ›Í›Í‚Í Í›Í‹Ì“Í‚Ì‹ÍÍ‘Ì‘ÍÌšÍÌ…ÌÍ’Ì†Ì¬Ì¥Í“Í‡Í‡Í–uÌ¸Ì„Ì‰ÍŠÍ™Ì±Í™Ì©Í–Ì Ì¼Ì³Ì®ÍÍ…Ì¡ÌÌ¡ÌªÍ‰Ì®Ì©Ì®Ì­ÌÌÌ¦Ì¬Ì¹Ì³ÍÌ°Ì™Ì¨ÌŸÌªÍ•Ì¥Ì°Ì¬Ì Ì™Ì°Í…nÌ¶ÍÌÌ’ÍÌ‚Ì›Í€ÍƒÍ’ÌŠÍ„Ì¿ÌšÌ‘Í„ÌÌÍ›Í‹ÍÌ¬Í“Í•Í™Ì³Ì˜Ì£Ì—ÍÌ²Ì£Ì¨Ì®Ì¬ÌÍ”ÌÌ¬Ì¡Ì¢Í…Ì£Í™Í•Ì˜Ì¦eÌµÌ„Ì¿ÍÍÌ…ÍÌÌ‰Í‹Ì½ÍÌÌ™Ì¬ÌœÍ”Ì§Ì³ÍÌ¹Ì£ÌªÌ¦Ì®Ì®Ì°Ì®Ì«Ì¤Ì»Ì³Ì—Ì¦Í•Ì°ÌÌªÌ£Í Thomas Edison avait compris que ca devait etre reproductibleGramophone, Emile Berliner, 1886 Meme principe qe le Phonographe Disque rotatif industrialisable Carton (fragile) Celluloid (inflammable) Vinyle (compromis) Vitesse angulaire constante: $78$ a $100$ rpm Du bord vers le centre Perte de qualite au centre Perte de bande passante Les microsillons reconstruisant le son: En faisant les reflets quâ€™on voit sur un disqueTransduction magnetique du son Principe Onde accoustique $\\to$ signal electrique Signal electrique $\\to$ champ magnetique Polariser un substrat magnetisable Assez coercitif Coercitivite magnetique: resistance dâ€™un milieu magnetique a se faire remagnetiser Plus un milieu est coercitif, plus il est resistant Comment ca se passe ? Tete en anneau, magentisation horizontale On a une bande magnetique qui defile On induit ce champ magnetique qui polarise les particules On a un signal accoustique quâ€™on a electrise et magnetiseEcrite: Courant electrique $\\to$ Champ magnetiqueLecture: Champ magnetique $\\to$ Courant electriquePionnier: Telegraphone a fil, Valdemar Poulsen (neerlandais), 1898 Magnetisation dâ€™un fil de fer Bande quelques minutes $1^{er}$ enregistrement: Empereur Franz Josef dâ€™Autriche, 1900 Evolution immediate: fil de fer $\\to$ lame dâ€™acier Plus robuste, plus dangereuxMagnetophone a bande, BASF/AEG (allemands), 1930Cassete 8 pistes, Ampex/RCA/MOTOROLA (US), 1963 On dirait une bobine mais elle sâ€™enroule sur elle-meme Lecture sans fin ! Quand on le mettais dans lâ€™auto-radio (câ€™etait fait pour les voitures), ca rembobinait et ca jouait en bouclePourquoi 8 pistes ? Câ€™est en stereo en 4 voie, des quâ€™on arrive a la fin dâ€™une piste, on saute 2 voiesIl y a ~1h30 de musiqueCompact Cassette, Philips (Neerlandais), 1963Enregistrement numerique du sonOnde sinusoidale Une onde sinusoidale est: continue dans le temps continue en intensite Discretiser un signal continu periodiquement $\\Rightarrow$ Choix dâ€™une frequence $F_e$Theoreme de ShannonUn signal est une somme de sinusoides: La frequence la plus elevee est $f_{max}$ Echantillonner a $F_e$ est valide si\\[F_e\\gt 2\\times f_{max}\\]En dessous: aliasing $=$ repliement de spectre $=$ frequences parasitesEchantillonage Signal echantillone en intervalles reguliersQuid de lâ€™intensite ? Sous-ensemble discret de valeur dâ€™un espace contine ${0\\to V_{max}}$ Idealement les valeurs quantifiees appartiennent a la courbe Sauf que nonPas de quantificationEspace discret a $N$ valeurs $[0\\dots V_{max}/N]$ En numerique: $N=2^M$ aec $M$: nombre de bits Erreur de quantification $e$ \\(0\\lt e\\lt V_{max} / 2^M\\) Erreur de quantification inevitable $N$ petit $\\to$ $\\color{red}{e}$ eleve $\\color{orange}{Visible}$ $\\color{red}{Audible}$$\\color{red}{e}$ dâ€™un signal triangulaire$\\color{red}{e}$ dâ€™un signal sinusoidalFormat PCM Pulse Coded Modulation Signal continu discretise en temps et en intensite Via circuits CNA/ADC Echantillonnage temporel a $F_e$ $F_e\\ge 2f_{max}$ Sinon aliasing Quantification dâ€™intensite sur $N$ bits: $2^{N}$ valeurs Erreur de quantification $e$ Dynamique $\\simeq 6dB$ par bit ($16bits\\simeq96 dB$) Reconstruction Via circuits CNA/DAC Filtre passe-bas fort a $F_e/2$ Audio numerique non compresseCD Sony + Philips, 1982 Diametre: $12 cm$ PCM: $44.1KHz$, $16$ bits, stereoo Debit: $2\\times44100\\times2=176.4Ko/s (1.411 Mb/s)$ Lecture: Du centre vers le bord Laser infrarouge Vitesse lineaire constante $500\\to200 rpm$ $74$ minutes de son $\\Rightarrow 783Mo$ Peu de correction dâ€™erreur Pas graveâ€¦ Avec correction dâ€™erreur: $650Mo$ $\\Rightarrow$ CD-ROM (Read Only Memory) DAT Sony, 1987 2 canaux PCM, $48KHz$, $16$ bites Debit: $2\\times 48000\\times 2 = 192Ko/s (1.536 Mb/s)$ Lecture: Bande magnetique $\\sim 50cm/min (8.15mm/s)$ $4mm$ dâ€™epaisseur Jusquâ€™a 3h par bandeComment ? $\\Rightarrow$ Lecture hellicoidale Tete rotative $2000rpm$ Inclinee $\\Rightarrow 3.15m/s$ Comme VHS Et streamers (DDS, AIT, LTO, â€¦) DVD-A Un DVD contient bien plus de donnees On etait dans lâ€™infrarouge pour les CDs, on est dans les rouges pour les DVD-ADâ€™ou le nom blu-ray DVD Forum, 2000 2 a 6 canaux $44.1 KHz$ a $192KHz$ $16$, $20$, $24$ bits Majoritairement non compresse Cas extremes: Meridian Lossless Packing $\\color{green}{\\text{Sans perte}}$ Lecture: Laser rouge Simple couche/double couche ($8.5Go$) Incompatible DVD-VIDEO, CD AUDIO, CD-ROMSuper Audio CD Sony + Philips, 1999 â€œSuccesseur du CDâ€ 2 a 6 canaux $\\color{red}{2.8224MHZ !?}$ $\\color{orange}{1\\text{ bit ??}}$ LISIBLE PAR LA PS3 ??? Format DSDFormat PWM Approximation dâ€™un signal analogique par des pulses Bruit de quantification $=V_{max}/2^N$ Rappel PCM: Densite constante $=$ Largeur pulses constante Amplitude variable Bruit audible (8 bits, 16 bitsâ€¦) Reconstruction du signal Filtrage BF a $F_e/2$ $\\color{red}{\\text{PMW: Pulse With Moderation}}$ Densite variable $=$ Largeur pulses variable Amplitude constante Reconstruction du signal: Integration +Filtrage BF Inconvenients Electronique rapide Bruit max de quantification fort $[0\\dots V_{max} / 2]$ !Avantages Bruits de quantification tres haute frequence ($MHz$) Personne nâ€™est capable de lâ€™entendre Inaudible ! Qualite $++$ Filtrage BF simple Cout $â€“$ Compression numerique du sonLâ€™audio non compresse,Qualite CD 2 canaux, $44.1KHz$, $16$ bits Non compresse: $2\\times 44.K * 2$ $\\color{red}{176.4 Ko/s = 1.411 Mb/s}$ CD: 650 Mo data, $\\sim 780 Mo$ audio $\\Rightarrow 74$ min ADSL de 2000: $64 Kb/s$ a $45$ euros par mois: non $128 Kb/s$ a $90$ euros par mois: non $2 Mbits$ a $200$ euros par mois: $100\\%$ du debit en audio â€œet mon internet ?â€ Aujourdâ€™hui (fibre, 4G, 5G) Toujours pas mainstream Reste un service Premium (Deezer HiFi, Spotify HD, â€¦) Qualite â€œHome Cinemaâ€ $\\ge 6$ canaux, $48KHz$, $16$ bits Non compresse: $6\\times 48K* 2$ $\\color{red}{576 Ko/s = 4Mbit/s = 2Go/h}$ Dvd: $4.9 Go$ $\\Rightarrow 2.5h$ de son pas de video ! ADSL, mauvaise 4G: 8 Mbits 50\\% du debit juste en audio Et le debit video ? Injouable sans compresseurAlgorithmes temporelsDifferential PCM (DPCM) Hypothese: signal source stationnaire $=$ proprietes independantes dans le temps (esperance, variance) Ok avec des basses frequences (Pas sur en hautes frequences) Principe: pas le sample PCM courant depend du precedent Codage des differences $\\Rightarrow$ Differential PCMEncodeur Memoriser les 2 valeurs consecutives Calcule la difference $\\Rightarrow$ dynamique reduite Encodage du residu avec moins de bits Compression de $25\\%$Decodeur Accumule la valeur reconstruite courante Dequantifie le residu Signal reconstruit $=$ dâ€™origine ? $\\color{red}{NON!}$ La quantification des differences induit de lâ€™erreur $\\color{red}{\\text{qui sâ€™accumule a la reconstruction}}$DPCM in-loopEncodeur ameliore Memorise deux valeurs consecutives Calcule la difference $\\Rightarrow$ dynamique reduite Encodage sur moins de bits ! Compression de $25\\%$ Calcule la valeur reconstruite en prevision du decodeur Erreur de construction contenueDecodeur Idem decodeur simpleAdaptive DPCM Codage differentiel adaptatifEncodeur Minimise lâ€™erreur differentielle adaptativement: Prediction du signal courant avec les valeurs passees Polynome ordre $\\sim 8$ Quantification variable du residu 4 a 6 bits Compression de 75\\% Usages Multimedia (MS/IMA ADPCM, 44.1KHz, 4 bits) Telephonie ($G.721$ $8KHz$, $5-6$ bits) Dans les DS et GBA, le son est exclusivement en ADPCMOn se mange lâ€™erreur de la compressionRaffinement: deux bandes de frequences Deux residus, deux debits Bande passante plus grande ($7KHz\\Leftrightarrow F_e = 14 KHz$) $\\Rightarrow G.722$ (VolP HQ, DECT HQ)NICAM Nearly Instantaneous Companded Audio Multiplex BBC, $\\sim1986 \\to 2012$, France $1995\\to 2011$ $32kHz$, $14$ bits stereo, $728Kbits/s$ Codec multiplexe avec signal video analogique (QPSK) Exemple: signal SECAM + NICAM @ 5.85 MHzFiltrage BF luma: image plus floue :( On ne peut pas faire rentrer plus que ce qui est possible dans un meme tuyauParenthese perceptuelleComment on percois le son ? Quâ€™entend lâ€™oreille ? Le son peut etre masque par dâ€™autres sons Phenomene de masquage sonore temporel Posterieur Si on son $\\color{red}{faible}$ suit un son $\\color{green}{fort}$, lâ€™oreille nâ€™entend $\\color{red}{\\text{pas}}$ le son $\\color{red}{faible}$Est-ce quâ€™il y a un masquage anterieur ? Oui ! Anterieur Si on son $\\color{green}{fort}$ suit un son $\\color{red}{faible}$, lâ€™oreille nâ€™entend $\\color{red}{\\text{pas}}$ le son $\\color{red}{faible}$ (non causal !) Autant quâ€™on le deteste, notre cerveau un bien un temps de latence de traitement$\\Rightarrow$ Latence de perception des transitoires de dynamiqueNICAM: Principe de fonctionnement Echantillonnage PCM 32 KHz 14 bits Decoupage en tranches de $1ms=32$ samples Pour chaque tranche: Prendre le plus grand sample $\\Rightarrow$ sert de facteur dâ€™echelle Quantifier a $10$ bits tous les samples Selon le facteur dâ€™echelle (â€œCompandâ€) $\\color{red}{Faible}$: enlever les bits de poids $\\color{green}{forts}$ vides (petits signaux, pas de perte) $\\color{green}{Fort}$: enlever les bits de poids $\\color{red}{faibles}$ (signaux fortsm pertes â€œnegligeableâ€) Au pire: quantification forte et breve de petits signaux $\\to$ RSB eleve Variations dynamiques et masquage temporels cachent la misereDecodeur Dequantifier selon le facteur dâ€™echelle CNA avec $1ms$ de latence (â€œNearly instantaneousâ€)SchematisationQuantification CompandQuantification non-lineaire : A-LAWContexte Proprietes temporelles de la voix: Peu de niveaux $\\color{green}{forts}$ Beaucoup de niveaux $\\color{red}{faibles}$, silences Voix numerique: typiquement $8KHz/8$ bits Rappel numerisation PCM: Bruit de quantification uniforme Fort dans les niveaux $\\color{red}{faibles}$, faible dans les niveaux $\\color{green}{forts}$ Autrement dit: PCM 8 bits degrade souvent la voix Quelles alternatives ? PrincipeModifier la dynamique Augmenter les niveaux $\\color{red}{faibles}$ Baisser les niveaux $\\color{green}{forts}$ Bruit de quantification remodeleQuelle fonction fait cela ? Loi logarithmique\\[F(x)=\\text{sgn}(x)\\begin{cases}\\frac{A\\vert x\\vert}{1+\\ln(A)}, &amp;amp;\\vert x\\vert\\lt \\frac{1}{A}\\\\\\frac{1+\\ln(A\\vert x\\vert)}{1+\\ln(A)}, &amp;amp;\\frac{1}{A}\\lt \\vert x\\vert \\lt1\\end{cases}\\]En pratiqueAnalogiquement: Avant CAN + apres CNA Paquets numeriques: PCM 8 bits classiquesNumeriquement: Apres CAN PCM $\\color{green}{HQ}$ (12 bits) + avant CNA PCM HQ Paquets numeriques: traitement A-Law $12\\leftrightarrow 8$ bitsResultat On a inverse la tendance des erreursErreur de quantification: Forte sur les signaux $\\color{green}{forts}$ Faible sur les signaux $\\color{red}{faibles}$Standard telephone $G.711$" }, { "title": "EPIQUANTI : Noisy Intermediate-Scale Quantum (NISQ) Computing", "url": "/cours/posts/epiquanti_nisq/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-11-30 16:00:00 +0100", "snippet": "Lien de la note HackmdNISQ ComputingMotivationShorâ€™s algorithm - how many qubits does it take to factor an integer ?Textbook examples of quantum algorithm largely assume that qubits and gates are not subject to noise. In the absence of noise, to factor and integer ,ade of $1024$ bits takes about $2050$ qubits and over $10^9$ gatesIn the presence of noise, quantum error correction has to be incorporated into the computation, adding a large overhead.Fault-tolerant quantum computations of arbitrary length are not within reach of todayâ€™s technology (need qubits in the millions)Algorithms for small number of qubits (in the $\\sim100$) and limite coherence time will need to offload pre and post-processing to classical computers. Noisy Intermediate Scale quantum (NISQ) computed is thriving field of research: $50-100$ qubits Limited gate fidelity Limited qubit connectivity Limited correction capabilities $\\to$ low depth circuit Killer apps: simulate correlated matter, machine learning, optimizationVariational Quantum AlgorithmsVariational Quantum Algorithms are a hybrird quantum-classical approach. Goal: finding ground state of a Hamiltonian $H$, or alternatively, optimizing a cost function Choose a good Ansatz $\\vert\\psi(\\theta)\\rangle$ Design a quantum circuit that implements $\\vert\\psi(\\theta)\\rangle$ Measure cost function $E_{\\theta}=\\langle\\psi(\\theta)\\vert H\\vert\\psi(\\theta)\\rangle$ Use classical optimizer to find optimal $\\theta^{*}$VQA consist of a quantum processor that can prepare quantum states belonging to a parameterized class ${\\psi(\\theta)\\rangle}$ efficiently and an external loop (running on classical hardware) that optimizes its parameters The absence of error correcting means that the effective error rate will be non-vanishing, and as a consequence, the length of the possible circuit will be boundedVQA: Inner routine The inner routine prepares a state parameterized by $\\theta$Quantum Approximate Optimization AlgorithmCombinatorial optimization Combinatorial optimization is about finding an optimal configuration in a set of possible configurations.In general, combinatorial problems are very big so exhaustive search is not tractable.There are many methods to tackle optimisation problems, such as Constraint Programming, Branch and Bound/Cut methods, and local search heuristics.A specific NP-hard problem under consideration, known Quadratic Unconstrained Binary Optimization Problem (QUBO), can be expressed a a local energy problem and therefore phrased as an Ising model. Given a set of spins $s_i = \\pm1$, the foal is to find the configuration which minimizes the energy function.\\[H(s_1,\\dots s_N) = -\\sum_{i\\lt j}J_{ij}s_is_j-\\sum_{i=1}^Nh_is_i\\]Simulated AnnealingHeuristic algorithms are used to find approximate solutions to combinatorial problems that, while being suboptimal, are â€œgood enoughâ€. Simulated Annealing is a local search heuristic inspired by the physical process of thermal annealing.SA performs local changes in the current candidate solution and checks whether the new candidate has lower energy. If it does, it becomes the leading candidate, if it does not, one may still accept the new candidate with probability, in the hope that it will help explore the space of solutions. This hill-climbing events become less liekly as the algorithm progresses, and they are controller by an effective temperature parameter. Câ€™est du recuit simule !Tunneling effect Tunneling is the intuition behind QA.Classicaly, particles with low energy will rebound upon collision with a high energy barrier.In the quantum setting, it is possible for a low energy particle to pass through the energy wall. This is because quantum particles are not point-like, but rather like wave-packets.Quantum annealing recapRecall that in QA, an easy Hamiltonian is graduallyAnsatzQAOA For MaxCut" }, { "title": "EPIQUANTI : Quantum Fourier Transform", "url": "/cours/posts/epiquanti_quantum_fourier/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-11-30 14:00:00 +0100", "snippet": "Lien de la note HackmdOverviewThree kind of quantum advantage Oracle-based Adiabatic optimisation Simulation of quantum systemsQuer model and Oracles Oracle: boite noire qui repond oui ou non a une questionIn the query model, you are given access to some function $f$, giving a Y/N answer to all inputs in polynomial time. This function is called the blac-box, or the oracle. An oracle with input $i$ and output $x_i$ can be described by the unitary operation\\[O_x:\\vert i,b\\rangle\\to\\vert i, b\\otimes x_i\\rangle\\]By linearity, this oracle gate can be applied to quantum superpositions. In order to measure the time complexity of an algorithm, one determines the number of queries it makes to the oracle.\\[U_TO_xU_{T-1}O_x\\dots O_xU_1O_xU_0\\vert 0\\dots0\\rangle\\]Quantum Fourier TransformDFT RecapGiven a vector $x$ of dimension $2^N$ with components $x_j$, the Discrete Fourier Transform of a vect $x$ is avector $y$ of dimension $2^N$\\[y_k=\\sum_{j=0}^{2^N-1}x_je^{2ipi jk/2^N}\\]Matrix-vector multiplication takes $O(2^{2N})$ steps. The Fast Fourier Transform algorithm reduces this to $O(N2^N)$, which renders DFT computable in linear time This is done by exploiting symmetry of the DFT matrix representationKet NotationA state on $N$ qubits corresponds to a vector $x$ of dimension $2^N$ with components $x_j$. Take the computational basis:The Fourier transform of state $\\vert x\\rangle$ is a state $\\vert y\\rangle$, i.e. vector of $2^N$ components $y_k$\\[\\vert y\\rangle = \\sum_{k=0}^{2^N-1}y_k\\vert k\\rangle = \\sum_{\\lambda=0}^{2^N-1}\\sum_{j=0}^{2^N-1}e^{2i\\pi j\\frac{k}{2^N}}x_j\\vert j\\rangle\\]1 qubit caseExploiting the symmetryLet us see how the QFT acts upon a computational basis vector. By linearity of QM, this will suffice for any quantum stateNotice that the $\\omega_{N_j}$ in ($\\vert 0\\gt\\omega_{N_j}1\\gt$) depends on the integer value, i.e. on the value of all the qubitsThis is implemented by performing controlled rotations on each qubit. The number of controlled rotations is the number of remaining qubits in the QFT.This means that one needs around $N\\times (N-1)/2$ gates to implement DFTRuntime analysis Number of gates: $N(N+1)/2$ Last reversed-ordering step: $sN/2$ swap gates, each needing 3 CNOTs Then the QFT on $N$ qubits has a runtime of $O(N^2)$ while the FFT takes about $O(N2^N)$ steps. So we have obtainend an exponential speed-upQuantum Phase EstimationGoal and assumptionsThe most salient application of QFT is the Quantum Phase Estimation routine, which is the workhorse behind several quantum algorithms featuring exponential speed-up, such as Shorâ€™s algorithm and Quantum Matrix Inversion Goal: Estimate the eigenvalue $\\lambda=\\exp(2\\pi\\phi)$ associated to a given eigenvector $\\vert u\\rangle$ of a unitary operator $U$Two assumptions uynderly the QPE routine: Implement the gate $U^k$ in a controlled way with states from $t$ qubit register and non-negative $K$ Prepare the state $\\vert u\\rangle$ as input. This can be relaxed at the expense of introducing randomnessCircuit for QPEThe QPE algorithm ises 2 different qubit registers Register 1: necessary to implement the controlled $U$ gate. The length of this register determines the accuracy of the phase estimation Register 2: Used to prepare the state $\\vert u\\rangle$. The lenght will depend on the problem under consideration The number $\\phi = 0.\\phi_0\\phi_1\\phi_2\\phi_3\\dots$ can be expressed in binary form:\\[\\phi = \\sum_{j=0}^{+\\infty}\\phi_j2^{-j-1}\\]The QFT needs $O(t^2)$ gates. The number of needed gates is polynomial in the number of bits $\\phi$. It can be shown that if the binary fraction expression of $\\phi$ is truncated to some bit length the error can be controlled with logarithmic overheadAmplitude AmplificationClassical motivationGiven the promise that ther is only one tagged marble in this jar containing $N$ crystal marbles, how many times, on average, do you need to randomly draw a marble before finding it ? Given a set of $N=2^n$ databases entries, with $n$ the number of bits used to denote the address of an entry, and no knowledge about the database searching for a particular entry takes on average $N/2$ querie, and $N$ queries in the worst case In the quantum case, this can be sped up to abour $\\sqrt{N}$ queries thanks to Groverâ€™s algorithmGroverâ€™s algorithmLes us assume that the database of size $N=2^n$ can be indexed by $n$ qubits. Starting with:\\[\\vert +++\\dots+\\rangle = H^{\\otimes n}\\vert 000\\dots0\\rangle=\\frac{1}{\\sqrt{2^n}}(\\vert 000\\dots0\\rangle+\\vert 000\\dots1\\rangle + \\vert 111\\dots0\\rangle + \\vert 111\\dots1\\rangle)\\]The problem is to find indices of the states that correspon to a â€˜taggedâ€™ solution. GA finds thos indexes by successive applications of an oracle gate (which can identify such a solution) and a diffusion gateA signle Grover iteration consists of 4 steps: Phase Oracle H wall Phase Gate H wallThe oracle gate A phase oracle checks, via the black-box function $f$, whether the entry is part of the solution space and, if it is, it flips te sign of the corresponding index. otherwise it does nothing. Setps 2, 3,and 4 are collectively known as the mean-reflection operationGeometric interpretationGiven that $m\\lt\\lt N=2^n$ entries are solutions to the search problem, a Grover iteration can be seen as a small rotation in the $2$-dimensional subspace spanned by $\\vert\\phi_{YES}\\rangle$ and $\\vert\\phi_{NO}\\rangle$" }, { "title": "DLIM: Deepfake", "url": "/cours/posts/dlim_deepfake/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-29 14:00:00 +0100", "snippet": "Lien de la note HackmdDeepfakeLes GAN permettent de creer de faux surprenat avec des reseaux profonds (dâ€™ou Deepfakes) Creation de visage (StyleGAN) Fausse video comme celle de Poutine soulignant la faiblesse des democratiesAutoencoders Avant les GAN il y a eu les autoencodeurs qui ne demandent pas de verite terrainLes resultats sont moyensU-net U-net est une sorte dâ€™autoencodeur avec une verite terrain et des pontsAutoencodeur variationel (VAE)On decoupe lâ€™espace latent en sa moyenne et son ecart-typePour construire ce reseau on definit 2 fonctions dâ€™erreur: Distance image dâ€™arrivee/image de depart (cf autoencodeur) Divergence de Kullback-Leibler entre le vecteur de lâ€™espace latent et une gaussienne type: $KL(N(\\mu, \\sigma), N(0,I))$\\[E=\\alpha E_{reconstruction} + \\beta[\\text{mean}^2 + \\text{std_deriv}^2 - \\log (\\text{std_deriv}^2)-1]\\]VAE - generation On peut crÃ©er de nouvelles images en gardant la moyenne et en modulant lâ€™Ã©cart type $z=\\mu+\\varepsilon\\sigma$Avec les chiffres manuscrits et un espace latent a 2 dimensions $[\\mu, \\sigma]$ on a:Exemple de KerasVector Quantised-Variational AutoEncoder (VQ-VAE)On fabrique une collection de valeurs de vecteurs latents (embedding space). Une valeur est un vecteur lorsque le vecteur latent est en 3DSi la sortie de lâ€™encodeur est de $32\\times 32\\times 50$ alors la collection a des vecteurs de dimension $50$.On traduit la sortie de lâ€™encodeur en prenant pour chaque valeur, la plus proche dans la collectionVQ-VAE CompressionUn facteur de compression de $42$: Lâ€™image dâ€™origine a $128\\times128\\times 3\\times 8$ bits Lâ€™image est encodee avec $32\\times32\\times9$ bits ($521$ valeurs possibles) (il faut aussi stocker la collection de valeurs soit $512\\times D$)On peut entrainer un classifieur sur les images $32\\times 32\\times 1$, ca marcheVQ-VAE-2 - Multi-echelleGAN Un Generative Adversarial Network (GAN) est un autoencodeur avec un discriminateur qui indique si le resultat est un vrai ou faux Lâ€™erreur du discriminateur permet quâ€™il se corrige (minimise lâ€™erreur) et que le generateur se corrige (maximise lâ€™erreur du discriminateur)Conditional GAN Le principe est dâ€™enrichier un GAN en ajoutant des informations supplementaires (la classe de lâ€™image par ex.) en entree du generateur et du discriminateur On a ainsi des images plus realistes en sortiePix2PixCâ€™est un GAN conditionelLe generateur est un reseau en U et le discriminateur un classifieur CNN adapte.On peut ainsi generer des images a partir de dessins.Cycle GANPeut-on faire de lâ€™auto-apprentissage (sans verite terrain) avec un GAN ?Si le but est de passer dâ€™un type dâ€™image a un autre, câ€™est possible.Pour cela on utilise 2 generateurs, $G$ et $F$, et 2 discriminateurs, $DX$ et $DY$ $G$ fabrique une image de type $Y$ a partir dâ€™une image de type $X$ $F$ fabrique une image de type $X$ a partir dâ€™une image de type $Y$ $DX$ indique si lâ€™image donnee est vraie ou a ete generee par $F$ $DY$ indique si lâ€™image donnee est vraie ou a ete generee par $G$ApplicationsStyleGANMelange de styleAvec 2 vecteurs de lâ€™espace latent on peut melanger $2$ visage en injectant le 1er jusquâ€™a une couche dans la synthese, puis le secondPlus on injecte tard le 2e, moins lâ€™impact est important (seulement les hautes frequences)Vers le visage moyenLorsquâ€™on est dans lâ€™espace $\\mathcal W$ avec une valeur latente $w$ on peut interpler le visage moyen $\\bar w$\\[w=\\bar w+\\psi(w-\\bar w)\\]" }, { "title": "IMED2: 3D/3D registration with labeled atlas", "url": "/cours/posts/imed2_registration_3D/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-26 09:00:00 +0100", "snippet": "DPH and TURP treatmentThe endo-vascular treatment for BPHCâ€™est quoi le challenge ? La prostate a BEAUCOUP de variantes anatomiquesLa variante anatomique la moins embetante est la C. Meme si on bouche les vaisseaux, les os ne risque pas de se necroser.La plus compliquer est la B car le point de bifurcation est proche des arteres et du penis, boucher les vaisseaux pourrait tout niquer.Quand on fait un volume rendering, on voit ca:From CBCT to clinical informationUne fois sur le centerline, on peut labeliser les vaisseaux a la main, en fonction de si câ€™est des vaisseaux dâ€™interets ou non.Pourquoi on nâ€™essaierai pas de faire ca automatiquement ?On a essaye dans un premier temps de classifier les arteres: on fait une boule autour de la prostate et on regarde Mais ca ne marche pas pour regarder tous les vaisseaux autoursState of the art on vessel classification Pour tester les classifier, on ouvre scikit et on teste tous les classifiers a la mainVascular tree labeling as a classification problem on subtreesOverview Compute descriptors Predict a lable Branch label assignmentTackle a machine learning problem A best practice proposal inspired from different courses Data splitting To ensure statistical relevance of the results Metric definition To compare algorithms and evaluate performances Define metrics targets Human level Dumb algorithm State of the art Data preprocessing Explore, outlier removal, feature engineering normalization Model selection Identify relevant models to test Hyper-parameter tuning Either panda or caviar Iterate Evaluate the model Learn from failure Augment data Large Diffeomorphic Deformations Metric MappingCompute the registrationPourquoi utiliser ca ? Utiliser une deformation tres non-rigide On a besoin de statistiquesToward atlas building" }, { "title": "IMED2: Project", "url": "/cours/posts/imed2_project/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 11:00:00 +0100", "snippet": "Lien de la note HackmdPart 1Retinal fundus image segmentationIterative Closest Point - ICPQuand on itere, on reste bloques sur des minimums localEn remplacant points par courbes:On construit un ensemble de courbes problables et on associe ces courbes probablesCa marche pas car on recale un objet 3D sur un objet 2DPart 2Iterative Closest Point RegistrationVedoICPProject part 3Mosaicking applicationCVRL A la fin, ca ne marchera pasMais câ€™est pas grave, on aura essaye :)Pathology evolutionCVRL On fait un suivi temporel dâ€™une pathologie" }, { "title": "IMED2: TP3", "url": "/cours/posts/imed2_tp3/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 09:00:00 +0100", "snippet": "Reconstruction tomographique (2/3)Vous avez tous les outils pour comprendre la reconstruction tomographique 2D en gÃ©omÃ©trie parallÃ¨le dans le cadre idÃ©al : Ã  partir des lignes intÃ©grales (transformÃ©e de Radon), il est possible via le thÃ©orÃ¨me coupe-projection de rÃ©cupÃ©rer lâ€™objet correspondant aux projections (rÃ©troprojection filtrÃ©e). Cette thÃ©orie est bien jolie, maisâ€¦ la rÃ©alitÃ© est assez diffÃ©rente ! Le but de ce Notebook est de vous familiariser avec un certain nombre de non-idÃ©alitÃ©s des systÃ¨mes tomographiques, et dâ€™identifier les effets de ces non-idÃ©alitÃ©s dans les images reconstruites. Nous passerons en revue : Une non-idÃ©alitÃ© du tube : son caractÃ¨re intrinsÃ¨quement polychromatique Une non-idÃ©alitÃ© du dÃ©tecteur : la prÃ©sence de gains et dâ€™offsets (cela doit vous dire quelque chose !) Une non-idÃ©alitÃ© liÃ©e aux interactions photon/matiÃ¨re : le diffusÃ©Mais il existe de nombreuses autres sources de non-idÃ©alitÃ©s, par exemple une non-idÃ©alitÃ© liÃ©e Ã  lâ€™objet lui-mÃªme (ou au patient) : la prÃ©sence de mouvement au cours de lâ€™acquisition (avez-vous des exemples en tÃªte ?)import numpy as npfrom matplotlib import pyplot as pltfrom skimage.draw import circle, diskfrom skimage.transform import radon, iradonimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)Partie 1 - Durcissement de faisceauOn se donne un vecteur dâ€™angles theta. Puis, on construit deux images via la fonction buildImage. Cette fonction prend en entrÃ©e une Ã©nergie en keV, et gÃ©nÃ¨re une image constituÃ©e dâ€™os, de matiÃ¨re molle du cerveau, et dâ€™iode (cas dâ€™une imagerie vasculaire avec injection de produit de contraste). Les coefficients dâ€™attÃ©nuation dÃ©pendant de lâ€™Ã©nergie considÃ©rÃ©e, nous pouvons avoir deux images diffÃ©rentes selon que lâ€™on se place Ã  80 keV ou Ã  100 keV. Vous remarquerez que jâ€™ai aussi ajoutÃ© un facteur de dilution de lâ€™iode : câ€™est que lâ€™on nâ€™injecte pas toujours de lâ€™iode pure dans le corps du patient !Lancez les deux cellules suivantes.N = 360theta_min = 0.*np.pitheta_max = 180.0+theta_mintheta = np.linspace(theta_min, theta_max, N, endpoint=False)# in g/cm3dilution = 0.25densities = {&#39;Brain&#39;:1.043, &#39;Bone&#39;: 1.8, &#39;Iodine&#39;: 4.93*dilution }massAttenuationCoefficient = {&#39;Brain&#39;: {80: 1.831e-1, 100: 1.701e-1}, &#39;Bone&#39;: {80: 2.229e-1, 100: 1.855e-1}, &#39;Iodine&#39;: {80: 3.51, 100: 1.942} }def buildImage(kev): N = 256 img = np.zeros((N,N)) rr, cc = disk(((N-1)*0.5,(N-1)*0.5),(N-1)*0.45) img[rr,cc] = massAttenuationCoefficient[&#39;Bone&#39;][kev]*densities[&#39;Bone&#39;] rr, cc = disk(((N-1)*0.5,(N-1)*0.5),(N-1)*0.4) img[rr,cc] = massAttenuationCoefficient[&#39;Brain&#39;][kev]*densities[&#39;Brain&#39;] rr, cc = disk(((N-1)*0.25,(N-1)*0.5),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] rr, cc = disk(((N-1)*0.65,(N-1)*0.7),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] rr, cc = disk(((N-1)*0.65,(N-1)*0.3),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] return imgimg = {80:buildImage(80), 100:buildImage(100)}fig, ax = plt.subplots(1,2,figsize=(12,4))ax[0].imshow(img[80],vmin=0,vmax=0.5)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(img[100],vmin=0,vmax=0.5)ax[1].set_title(&#39;100 keV&#39;)plt.show()Nous allons gÃ©nÃ©rer les sinogrammes correspondant Ã  ces deux images. Si ASTRA est une trÃ¨s bonne toolbox pour vous amuser Ã  gÃ©nÃ©rer diffÃ©rentes gÃ©omÃ©tries dâ€™acquisition, utiliser des algorithmes de reconstruction itÃ©rative, etc., il existe Ã©galement une fonction standard de scikit-image pour la gÃ©omÃ©trie parallÃ¨le 2D : radon pour la projection, et iradon pour la reconstruction. On Ã©crira, pour projeter une image selon un vecteur dâ€™angles theta :radon(img, theta=theta, circle=True, preserve_range=True)De mÃªme, pour reconstruire lâ€™image Ã  partir de son sinogramme, on Ã©crira :iradon(sino, theta=theta, circle=True)Questions GÃ©nÃ©rez les sinogrammes des deux images ci-dessus. Reconstruisez les images issues de ces sinogrammes.# Question 1# Sauvez les sinogrammes dans un dictionnaire :# p = {80: **sinogramme Ã  80 keV** ; 100: **sinogramme Ã  100 keV**}p = {80:radon(img[80], theta=theta, circle=True, preserve_range=True), 100:radon(img[100], theta=theta, circle=True, preserve_range=True)}fig, ax = plt.subplots(1,2,figsize=(12,4))im0 = ax[0].imshow(p[80].T)fig.colorbar(im0,ax=ax[0])ax[0].axis(&#39;auto&#39;)ax[0].set_title(&#39;80 keV&#39;)im1 = ax[1].imshow(p[100].T)fig.colorbar(im1,ax=ax[1])ax[1].axis(&#39;auto&#39;)ax[1].set_title(&#39;100 keV&#39;)plt.show()# Question 2# Sauvez les reconstructions dans un dictionnaire :# mono = {80: **reconstruction Ã  80 keV** ; 100: **reconstruction Ã  100 keV**}mono = {80:iradon(p[80], theta=theta, circle=True), 100:iradon(p[100], theta=theta, circle=True)}fig, ax = plt.subplots(1,2,figsize=(12,4))ax[0].imshow(mono[80],vmin=0,vmax=0.5)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(mono[100],vmin=0,vmax=0.5)ax[1].set_title(&#39;100 keV&#39;)plt.show()Le modÃ¨le de Beer-Lambert polychromatique empÃªche la possibilitÃ© de rÃ©cupÃ©rer la partie linÃ©aire, puisque :\\(I = \\int_{\\mathrm{spectre}} I_0(E)e^{-p(E)}dE.\\)En supposant (câ€™est encore une nouvelle simplification, mais elle suffira Ã  illustrer le problÃ¨me) que le spectre est constituÃ© uniquement de deux Ã©nergies $E_0$ et $E_1$, lâ€™intensitÃ© reÃ§ue est donc $I=I_0(E_0)e^{-p(E_0)}+I_0(E_1)e^{-p(E_1)}$, quâ€™on peut rÃ©Ã©crire de la faÃ§on suivante :\\(I = I_0\\left(a\\times e^{-p(E_0)}+(1-a)\\times e^{-p(E_1)}\\right)\\)avec $a\\in[0,1]$. Si on utilise la transformation $I\\mapsto \\log(I_0)-\\log(I)$, comme on le fait en monochromatique, on obtient ici une projection $p_E$ Ã©gale Ã \\(p_E = \\log(I_0)-\\log\\left(a\\times e^{-p(E_0)}+(1-a)\\times e^{-p(E_1)}\\right).\\)On se propose de simuler une acquisition polychromatique, câ€™est-Ã -dire, une acquisition issue dâ€™un faisceau de rayons X distribuÃ© sur plusieurs Ã©nergies. Le plus simple est de considÃ©rer une approximation bichromatique du faisceau. Dans ce contexte, on considÃ¨re que les photons X incidents sont de deux Ã©nergies, Ã  savoir 80 keV et 100 keV. La probabilitÃ© que le photon incident soit Ã  80 keV est donnÃ©e par $P(80) = a_{80}$, et celle dâ€™avoir un photon incident Ã  100 keV est $P(100)=1-P(80)$.Questions Avec une telle distribution de probabilitÃ©, et les sinogrammes prÃ©cÃ©demment calculÃ©s Ã  80 keV et 100 keV, quelle est lâ€™intensitÃ© reÃ§ue au dÃ©tecteur ? Calculez la projection $p_E$ dans la fonction bichromatic (on suppose $I_0=1$) ; attention : les sinogrammes que vous avez calculÃ©s sont en unitÃ©s â€œpixelsâ€ ; il faut se remettre en centimÃ¨tres pour prendre des exponentielles qui aient un sens. Reconstruisez lâ€™image Ã  partir de ce sinogramme : quâ€™observez-vous ?# Question 4def bichromatic(p,a80=0.66): pixel2cm = 0.1 return -np.log(a80*np.exp(-pixel2cm*p[80]) + (1 - a80)*np.exp(-pixel2cm*p[100]))/pixel2cma80 = 0.66sinogram = bichromatic(p,a80)fig, ax = plt.subplots(1,3,figsize=(18,4))ax[0].imshow(p[80].T)ax[0].axis(&#39;auto&#39;)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(p[100].T)ax[1].axis(&#39;auto&#39;)ax[1].set_title(&#39;100 keV&#39;)ax[2].imshow(sinogram.T)ax[2].axis(&#39;auto&#39;)ax[2].set_title(&#39;Bichromatic&#39;)plt.show()# Question 5out = iradon(sinogram, theta=theta, circle=True)plt.imshow(out,vmin=0,vmax=0.25)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce5a3361f0&amp;gt;On se propose de comprendre lâ€™origine de ces artefacts (dits de durcissement de faisceau).Questions GÃ©nÃ©rez un vecteur dâ€™Ã©paisseurs en cm, variant de zÃ©ro Ã  45 cm (choisissez $n=500$ Ã©chantillons). Pour chaque Ã©paisseur testÃ©e $T$, calculez $T\\times \\mu_{\\mathrm{iodine}}(\\mathrm{keV})$ pour 80 keV et 100 keV. Utilisez la fonction bichromatic pour calculer la projection bichromatique de $T\\mu_{\\mathrm{iodine}}$, et tracez ce vecteur en fonction du vecteur correspondant Ã  une acquisition monochromatique Ã  80 keV. Quâ€™observez-vous ? Pouvez-vous relier cette observation aux artefacts de lâ€™image ci-dessus ? On veut â€œrecalerâ€ les mesures bichromatiques Ã  leurs mesures â€œidÃ©alesâ€ monochromatiques Ã  80 keV. Utilisez la fonction np.polyfit Ã  lâ€™ordre 3 pour obtenir un fit polynomial.# Question 6# Sauvez les T*Âµ dans un dictionnaire comme fait avec les sinogrammes et reconstructions prÃ©cÃ©dentesx = np.linspace(0, 45, 500)iodineProjection = {kev : x * mu * densities[&#39;Iodine&#39;] for kev, mu in massAttenuationCoefficient[&#39;Iodine&#39;].items()}# Question 7# y est la projection bichromatique# x0 est la projection monochromatiquey = bichromatic(iodineProjection, a80)x0 = iodineProjection[80]plt.plot(x0,y, label=&#39;Mono vs Bichro&#39;)plt.plot(x0,iodineProjection[80], label=&#39;Mono vs Ideal&#39;)plt.xlabel(&#39;Monochromatic&#39;)plt.ylabel(&#39;Bichromatic&#39;)plt.legend()plt.show()# Question 8params = np.polynomial.polynomial.Polynomial.fit(y, x0, 3)polynomial = paramsprint(params)88.09429686309687 + 103.43751237094426Â·xÂ¹ + 9.090711918937586Â·xÂ² -6.380448144804321Â·xÂ³plt.plot(y,polynomial(y)-x0)[&amp;lt;matplotlib.lines.Line2D at 0x7fce5a115970&amp;gt;]On se propose dâ€™utiliser ce fit polynomial pour corriger lâ€™image. Pour cela, et en premiÃ¨re approximation, nous allons supposer que les artefacts observÃ©s viennent uniquement des inserts dâ€™iode. Ceux-ci sont reconstruits correctement, avec peut-Ãªtre une valeur Ã  lâ€™intÃ©rieur de lâ€™insert lÃ©gÃ¨rement diffÃ©rente de la vraie valeur, mais en tout cas, ces inserts sont identifiables. Ils sont aussi beaucoup plus intenses que les autres structures de lâ€™image reconstruite.Questions Trouvez manuellement un seuil qui vous permette dâ€™isoler les inserts dâ€™iode dans lâ€™image reconstruite. Projetez les valeurs de ces inserts dâ€™iode ; transformez le sinogramme obtenu en utilisant le polynÃ´me trouvÃ© prÃ©cÃ©demment. Reconstruisez une image Ã  partir de ce sinogramme transformÃ©. Lancez la boucle dâ€™images suivante : quâ€™observez-vous ?# Question 9seg = out.copy()seg[seg &amp;lt; 0.4] = 0plt.imshow(seg)&amp;lt;matplotlib.image.AxesImage at 0x7fce5a606820&amp;gt;# Question 10segProj = radon(seg, theta=theta, circle=True, preserve_range=True)plt.imshow(segProj.T)plt.show()tmp = polynomial(segProj)plt.imshow(tmp.T)&amp;lt;matplotlib.image.AxesImage at 0x7fce5a5df2b0&amp;gt;# Question 11reproj = iradon(tmp, theta=theta, circle=True)plt.imshow(reproj,vmin=0,vmax=0.25)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce5a02cd00&amp;gt;# Question 12search = np.linspace(0,1,11)for alpha in search: rec = out+alpha*reproj f,ax = plt.subplots(1,2,figsize=(12,5)) ax[0].imshow(rec,vmin=0,vmax=0.5) ax[0].set_title(alpha) im = ax[1].imshow(img[80]-rec) f.colorbar(im,ax=ax[1]) ax[1].set_title(&#39;Difference from ground truth&#39;) plt.show()Partie 2 - Non-idÃ©alitÃ©s du dÃ©tecteurUn dÃ©tecteur prÃ©sente plusieurs non idÃ©alitÃ©s ; en premier lieu, il prÃ©sente des dÃ©rives en gains et en offsets. Cela signifie que la mesure faite au niveau dâ€™une cellule du dÃ©tecteur (un pixel dâ€™un dÃ©tecteur plan, ou un bin dâ€™un dÃ©tecteur linÃ©aire), au lieu de mesurer lâ€™intensitÃ© $I$ des photons X qui arrivent Ã  la cellule, on mesure\\(I_c = \\alpha I + \\beta.\\)$\\alpha$ est un gain (proche de 1 gÃ©nÃ©ralement), et $\\beta$ est un offset. Si on ne fait pas attention Ã  $\\alpha$ et $\\beta$, on se retrouve avec une projection corrompue $p_c = \\log(I_0)-\\log(I_c)$.Chargez lâ€™image ci-dessous, et regardez son sinogramme :scale = 1e-5img = np.fromfile(&#39;CTscan.raw&#39;,dtype=&#39;float32&#39;).reshape((256,256))*scalectDisplay = {&#39;vmin&#39;:950*scale,&#39;vmax&#39;:1150*scale}plt.imshow(img,**ctDisplay)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56e10fd0&amp;gt;sinogram0 = radon(img, theta=theta, circle=True, preserve_range=True)#sinogram0[100] = (sinogram0[99] + sinogram0[101]) / 2#sinogram0[100] *= 0.9plt.imshow(sinogram0.T, aspect=&#39;auto&#39;)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56d6cd60&amp;gt;Reconstruisez lâ€™image Ã  partir de ce sinogramme :img_ = iradon(sinogram0, theta=theta, circle=True)plt.figure(figsize=(10,10))plt.imshow(img_,**ctDisplay)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56ca4b80&amp;gt;Questions Partant du dÃ©tecteur utilisÃ© pour le sinogramme prÃ©cÃ©dent (de taille sinogram.shape[0]), gÃ©nÃ©rer un vecteur de gains Ã©gaux Ã  1 et un vecteur dâ€™offsets Ã©gaux Ã  0 (cas idÃ©al). Corrompez le vecteur de gain tous les n bins par un bruit dâ€™Ã©cart-type de 1%. Affichez le vecteur des gains. GÃ©nÃ©rez le sinogramme qui aurait Ã©tÃ© obtenu si la mesure avait subi ces gains Ã  chaque acquisition. Reconstruisez lâ€™image : quâ€™observez-vous comme artefacts ? Corrompez le vecteur dâ€™offsets tous les n bins (en partant de n//2 cette fois) par un bruit dâ€™Ã©cart-type de 1%. Affichez le vecteur des offsets. GÃ©nÃ©rez le sinogramme qui aurait Ã©tÃ© obtenu si la mesure avait subi ces gains et ces offsets Ã  chaque acquisition. Reconstruisez lâ€™image : quâ€™observez-vous comme artefacts ? (Fixez I0=10) Changez la valeur de I0 Ã  100, 1000, 10000 : quâ€™observez-vous ? Quels artefacts disparaissent / se maintiennent ? Pourquoi ?sinogram = sinogram0.copy()np.random.seed(42)n = sinogram.shape[0] // 5# Question 1# Vecteur de gainsgain = np.ones(sinogram.shape[0])gain[::n] += np.random.rand() * 0.01plt.figure()plt.plot(gain)plt.show()# Question 2# Vecteur d&#39;offsetsoffset = np.zeros(sinogram.shape[0])offset[::n-1] += np.random.rand() * 0.1plt.figure()plt.plot(offset)plt.show()I0 = 10# GÃ©nÃ©ration du sinogramme corrompu en gains / en offsets / les deuxsinogram = gain.reshape(-1, 1) * sinogram + offset.reshape(-1, 1)plt.imshow(sinogram.T)plt.show()# Reconstructionout = iradon(sinogram, theta=theta, circle=True)f,ax = plt.subplots(1,2,figsize=(20,10))ax[0].imshow(img,**ctDisplay)ax[1].imshow(out,**ctDisplay)plt.tight_layout()Partie 3 - Interactions avec la matiÃ¨re : rayonnement diffusÃ©Le rayonnement diffusÃ© est inhÃ©rent Ã  la physique des rayons X. Il rÃ©sulte dâ€™interactions avec la matiÃ¨re (avec le patient, notamment). De deux choses lâ€™une : soit on bloque le rayonnement diffusÃ© avant quâ€™il nâ€™atteigne le dÃ©tecteur ; soit on ne le bloque pas, et si on ne corrige pas la mesure par une estimation du diffusÃ©, la qualitÃ© image peut sâ€™en trouver rÃ©duite.Questions Si on calcule toujours $p=\\log(I_0)-\\log(I)$, mais que cette fois-ci $I$ nâ€™est plus Ã©gal au primaire $P=I_0 e^{-p}$, mais au primaire plus le diffusÃ© (autrement dit: $I=P+S$), quelle erreur fait-on sur $p$ ? Les lignes intÃ©grales sont-elles sous-estimÃ©es ? sur-estimÃ©es ? On se propose de simuler un modÃ¨le trÃ¨s simple de diffusÃ© ; on suppose que le diffusÃ© ressemble Ã  une versions floutÃ©e du rayonnement primaire (celui qui vient directement de la source). Utilisez la fonction gaussian() de skimage pour gÃ©nÃ©rer une version lissÃ©e du rayonnement primaire (on se fiche de I0 ici, quâ€™on supposera Ã©gal Ã  1). Prenez sigma=10 comme Ã©cart-type du lissage. Ajouter 10% de cette image au primaire, et rÃ©cupÃ©rez le sinogramme associÃ©. Reconstruisez lâ€™image : quâ€™observez-vous ? Et avec 20%, 30% ? Calculez le â€œscatter-to-primary ratioâ€ (ou SPR), Ã©gal Ã  $S/P$ ; quelles sont les valeurs de ce ratio ? $\\hat P = P - log(1 + SPR)$from skimage.filters import gaussian# Question 2sinogram = sinogram0.copy()# GÃ©nÃ©ration du diffusÃ©sigma = 10qty = 0.1primary = np.exp(-sinogram)scatter = qty * gaussian(primary, sigma=sigma)# GÃ©nÃ©ration du sinogramme corrompu en diffusÃ©sinogram = -np.log(primary + scatter)# Reconstructionout = iradon(sinogram, theta=theta, circle=True)f,ax = plt.subplots(1,2,figsize=(20,10))ax[0].imshow(img,**ctDisplay)ax[1].imshow(out,**ctDisplay)plt.tight_layout()# Question 3# SPRSPR = scatter / primaryplt.figure()plt.imshow(SPR.T)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce4e72f880&amp;gt;La question du diffusÃ© en particulier â€“ et des artefacts en gÃ©nÃ©ral â€“ est loin dâ€™Ãªtre anodine ; non seulement la qualitÃ© image sâ€™en trouve dÃ©gradÃ©e, mais pire encore, les applications utilisÃ©es en aval (segmentation, recalage, quantification) peuvent voir leurs performances baisser Ã  cause dâ€™une image de mauvaise qualitÃ©.Questions Regardez lâ€™histogramme de lâ€™image CT â€œpropreâ€ ; jouez avec des seuils min et max pour isoler lâ€™hypodensitÃ© circulaire dans la tÃªte du patient : y arrivez-vous ? Avez-vous des idÃ©es pour nettoyer votre segmentation des pixels segmentÃ©s nâ€™appartenant pas Ã  lâ€™hypodensitÃ© ?# Question 4mask = np.zeros(img.shape)_=plt.hist(img.flatten(),bins=128)mask[img&amp;lt;0.0104] = 1mask[img&amp;lt;0.0101] = np.nanmask[mask==0] = np.nanplt.figure(figsize=(10,10))plt.imshow(img,**ctDisplay)plt.imshow(mask,cmap=&#39;hot&#39;,alpha=0.3,vmin=0,vmax=2)&amp;lt;matplotlib.image.AxesImage at 0x7fce4e5dddc0&amp;gt;Questions Refaites lâ€™exercice, mais sur lâ€™image reconstruite en prÃ©sence du diffusÃ© Ã  30%. Comment est lâ€™histogramme des valeurs comparÃ© au prÃ©cÃ©dent cas ? Est-il aussi simple de segmenter lâ€™hypodensitÃ© ?# Question 5mask = np.zeros(img.shape)_=plt.hist(out.flatten(),bins=128)mask[out&amp;lt;0.0104] = 1mask[out&amp;lt;0.005] = np.nanmask[mask==0] = np.nanplt.figure(figsize=(10,10))plt.imshow(out,**ctDisplay)plt.imshow(mask,cmap=&#39;jet&#39;,alpha=0.3)" }, { "title": "IMED2: Registration in medical imaging", "url": "/cours/posts/imed2_registration/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 09:00:00 +0100", "snippet": "Lien de la note Hackmd Cours de recalage dâ€™image !GE HealthcareQuâ€™est-ce que câ€™est ? Un scanner !Mais câ€™est une question piege, câ€™est dur de savoir Pour les echographie Une radio dernier criCâ€™est portable, utile quand le patient ne peux pas etre bougeGE Healthcare in Buc Pour les mamographiesPourquoi on compresse le sein ? Pour avoir moins de matiere a traverserLes seins ont des tissus qui se superposent et qui sont super durs a analyserAvant, on compressait le sein pour lâ€™empecher de bouger, maintenant câ€™est parce quâ€™on fait de la 3D du sein AW: station de revue dedieeLe prof @ HealthcareThese sur: Le coeur Recalage Ceci nâ€™est pas un foieIngenieur de recherche @ GE Identification dâ€™un besoin/manque/innovation repondant a un besoin clinique Transformer la problematique clinique en un ensemble de problematiques techniques Etude biblio sur les differents sujets techniques et identification des solutions les plus prometteuses Preuve de concept technique et evaluation de la capacite de la solution technique a resoudre le probleme clinique Rendre robuste la preuve de concept a lâ€™ensemble des conditions dâ€™utilisation potentielles Etablissement dâ€™une strategie de verification et de validation de la technique Support pour le lancement du produit, la generation dâ€™evidence clinique et gestion de potentiels problemes3D/2D registration of coronary arteriesCoronary artery diseaseOn peut avoir une artere avec une section bien moins importante Si le sang passe moins bien, les tissus qui se nourrit par cette artere seront beaucoup moins nourris Douleur a lâ€™effort, etc.Souvent, quand on a des douleurs a la poitrine apres lâ€™effort, câ€™est le premier symptome: on a un vaisseau boucheSur lâ€™image a droite, il y a une partie qui est compressee Si câ€™est une artere du coeur, on peut faire un infarctus Infarctus: le but est de retructurer les vaisseaux coronaires pour continuer a avoir du sang Câ€™est pas forcement une mauvaise chose ! Coronary artery bypass surgery General anesthesia Extract small artery/vein from leg or arm Open rib-cage Heart stopping On-pump Link aorta to occlusion distality Off-pump + restart the heart ~3 to 6 hours ~1 to 2 weeks of hospitalizationPercutaneous coronary intervention Le genre dâ€™operation quâ€™on fait plus aujourdâ€™hui car moins couteuxCâ€™est quoi la difference entre les veines et les arteres ? Les arteres envoient le sang depuis le coeur, ce sont des muscles qui pulsent au meme niveau que le coeurSi on se prend un coup et quâ€™on a un bleu, une veine a pete mes les arteres sont tranquillesLes veines le ramene et ne sont plus un muscleOn amene un catether pour aller jusquâ€™a lâ€™artere bouchee, on met un â€œbalonâ€ pour eviter que lâ€™artere se reboucheComment on gonfle le balon ? Il ne faut JAMAIS avoir de lâ€™air dans les arteres Câ€™est pour ca quâ€™on vide une seringue de quelques goutes, pour eviter les bulles dâ€™air Lâ€™air peut faire un caillot sanguin On gonfle le balon avec une solution saline, aka de lâ€™eau La machine pour visualiser lâ€™interieur du patientMais et en termes de rayons X ? As Low As Reasonably PossibleAussi les patients sont deja malades, certes on augmente le risque de cancer mais aussi les chances de surviesEt pour les medecins alors ? Chaque medecin porte un tablier de plomb Il y a egalement une vitre plombee (cf a tige au milieu finissant par un cercle) Il y a beaucoup de choses auxquelles ont ne pense pas en tant quâ€™ingenieur dans nos locaux (la vitre prenant de la place, le nombre de personnes dans la salle, les moniteurs un peu partout, etc.)Pourquoi dans une video, les vaisseaux apparaissent et disparaissent ? Câ€™est en fonction de la solution pour les faire ressortir On injecte un produit de contraste (le metal le moins nocif, lâ€™iode)Le guide sort du vaisseau ? Quand ca arrive, câ€™est la merde. Dans ce cas, le vaisseau est completement boucheOn creuse dans tous ce qui est bouche, et comme le sang ne passe pas, il nâ€™y a pas de produit de contrasteIl y a des methodes non-intrusives pour voir les veines ? Lâ€™echo dopplerLe scanner Ce vaisseau est lâ€™aorte Potential applications for enhanced visualization On va fusionner un objet 3D avec la surface 2D pour se reperer Mais tres gagdet et medecins pas fans :( Proposition plus simple: on segemente lâ€™artere, on extrait la ligne centrale et on la â€œdeplieâ€, on peut visualiser ou on se situe Point de vue ingenieur: â€œMais ca ressemble a ca non ?â€Point de vue medecin: â€œOH WOW TROP BIEN !â€The registration problemOn veut bouger un truc en 3D pour le repositionner et le superposer de facon nickel.Aim at compensating: No link between imaging systems Patient motion Position on the table Repiratory motion Beating heart General registration problemeOn a 2 objets: bleu rougeOn a une fonction de distance qui estime notre recalage, et on veut minimiser cette valeur Avec une mamographie: The 3D/2D registration problem Difficulties due to vessels projection â€œfakeâ€ bifurcations â€œlateâ€ bifurcations detection On peut confondre 2 vaisseaux et detecter la difference tard projective foreshortening (self-superimposition)2D vasculature extractionCombien de temps ca met a calculer ? Des plombesEt si on veut segmenter cette image ? Detecter des frontieresEt pourquoi pas juste un seuillage ? Ca peut etre trop simple pour que ca marche Le niveau de gris des veines peut etre confondu avec celui du foieOn fait du pre-traitement: remove background On utilise de la morpho math On prend que les vaisceaux principaux (hysteresis thresholding) Si ton montre ca a des gens: â€œCâ€™est de la merdeâ€ (mais câ€™est pas si pire)Avec la reconnexion:A qui appartiennent les donnees ?Le patient ne peux pas faire lâ€™image sans lâ€™hopital et lâ€™hopital ne peux pas faire sans le patient Mais si câ€™est des organes, pas moyen de reconnaitre le patientAnonymiser les donnees ? Possible de desanonymiserMotion compensation for liverTrans-Arterial Chemo-Embolization - TACE procedure Radio-embolization procedurePour essayer de tuer la tumeur, on fait de la chimiotherapie Chimio therapie: version NAPALM du traitement, on balance tout en esperant de tuer la tumeur TACE: chimio et embolization On donne du poison et on coupe les vaisseaux sanguins La tumeur peut recreer des vaisseaux et se re-alimenter mais ca dimniuera deja sa taillePar rapport a lâ€™appareil precedent: le detecteur est plus grosLe systeme est sur roulette pour pouvoir sâ€™ecarter pendant lâ€™intervention: Mais il faut trouver la tumeur !3D Set Up Brief patient Leave the room Set-up injector Set-up system Start test-spin STOP BREATHING Acquire ! Il y a des TONNES de raison pour lesquelles ont peut avoir une reconstruction de merde Il y a eu du mouvement pendant lâ€™interventionOur proposition: motion compensated reconstructionEst-ce quâ€™il nâ€™y a pas moyen de refaire lâ€™acquisition avec de la compensation de mouvement ?Quâ€™est-ce que GE Healthcare a fait ? Il nâ€™est pas possible de breveter un algo mais on peut breveter un workflowOn teste formellement: La cage est un â€œpatientâ€What we measured for absolute &amp;amp; relative comparisonClinical impact evaluationStatistical analysis on clinical features Cases with significant motionPearson Chi square test N-categorical Unpaired dataFisher exact test: 2-categorical Unpaired dataMcNemar test Categorical Paired dataClinical impact evaluation" }, { "title": "TVID: Codec Video", "url": "/cours/posts/tvid_codec/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-24 14:00:00 +0100", "snippet": "Lien de la note HackmdQue faire ?Identifier les repetitions Spatiales TemporellesOptimiser leur codage de rouceDessiner le moins possible 2x les memes dessins pour chaque oeil On va decimer ce qui nâ€™est pas important Spatialement ? Temporellement ?Detruire selectivement: En fonction de lâ€™application: TV, DVD/BD, streaming Compromis qualite &amp;lt;=&amp;gt; debitCompression entropique (compromis qualite) Huffman (CAVLC) Arithmetique (CABAC)Codec ImageJPEG Le veteran: Join Photographic Experts Group (1992) Limitations de la vision humaine HF Chroma Decoupage en blocs $8\\times 8$ Transformation DCT Quantification des coefficients Lecture Zig-Zag Huffman Decoupage en blocs $8\\times 8$ Transformation DCT Quantification des coefficients ExempleBloc DCTParcours Zig zag Codage RLE: paires {Valeur, Nombre} $79; 0; -2; {-1;3}; {0;2}; -1;$ EOB Image animee: Motion JPEG DV Codec VideoMPEG-1 Le pere fondateur Motion Pictures Experts Group (1993) Base sur JPEDG et H.261 (NetMeeting, PSX FMV) CF. JDG les jeux FMVs Support: Stockage numerique: VCD Reseaux fiables En pratique $352\\times 240$ (â€œNTSCâ€) / $352\\times288$ (â€œPALâ€) 30 i/s YUV $4:2:0$ MPEG-1 $1, 5 Mbs$ Blocs, Macroblocs Bloc: matrice de pixels $8\\times 8$ Aggregation en macroblocs MB-Luma: 4 blocs $\\times 8=16\\times 16$ MB-Chroma: $1$ bloc U $8\\times 8$ + 1 bloc V $8\\times 8$ =&amp;gt; 1Mb complet = 4 blocs de Luma + 2 blocs Chroma Slices Suite de macroblcos Sans recouvrement =&amp;gt; Partition de lâ€™image Multiusage Facteur de quantification individuel Synchronisation (start codes) Pictures Suite de slices Start code Prediction full / half pel Types: I, B, P, Dâ€œIntraâ€: I Quasi-JPEG Reference: elle-meme Quantification par defaut (â€œintraâ€) surchargeable Macroblocs intra, codage DC: DPCM AC: Huffman Difference entre images Le lapin apparait dâ€™une image a lâ€™autresImage 1 Traitement par blocs Recherche de mouvement Calcul des residusImage 2 Vecteurs de mouvement (pixel, demi-pixel) balle Residus Lapins Yeux Quantification nonintra uniforme Exemple: Big Buck BunnyVecteurs de mouvementsPrediction IPOn a des images qui dependent les unes des autresAvantages: Debit(P) &amp;lt; Debit(i) Aucune latenceInconvenients: Decoder une P =&amp;gt; conserver la I et les P precedents Prediction + quantification =&amp;gt; $\\color{red}{\\text{propagation dâ€™erreur}}$Prediction IBPAvantages Debit(B) Â«Â Debit(P) â€œLisse les erreursâ€ entre I et P B bidirectionnelle =&amp;gt; moyenne des reconstructionsInconvenients: Decoder une B: garder les I et P apparentees $\\color{red}{\\Rightarrow RAM}$ Ordre de decodage $\\neq$ ordre affichage $\\Rightarrow$ Latence Zapper: besoin dâ€™intercaler des $I$ frequemment $\\Rightarrow$ â€œGroup Of Picturesâ€ Suite dâ€™image avec au moins une $I$ Parametres: $M$: distance entre une $I$ et une $P$ $N$: distance entre deux $I$ Ordre affichage vs decodage DO: Display Order - CO: Coding Order A cause des B, $CO\\neq DO$ Supposons ces images en DO: Lâ€™ordre des GOP correspondant est (en CO):Sequence Header Resolution PAR Frame rateEn resumeEncodeur MPEG-1Convoyer du son et de la video en meme tempsMPEG Program stream Fichier composite contenat: 1+ flux audio elementaire 1+ flux video elementaire MPEG PES Packetized Elementary StreamPES: Flux elementaire decoupe Stream ID $\\color{red}{PTS/DTS}$ CRCMPEG Program Stream Sequence: Pack header System Clock Reference = Horloge createur PS (pour synchro PTS) Pack: Suite de PES Convient pour un support fiable (VCD, DVD) Pas adapte a la diffusion de chaines de TV (broadcast) Peu resistant au BER Une seule base de temps (SCR) MPEG-2: Le premier codec video Objectif: polyvalence applicative Broadcast DTV SD, HD (DVB, ATSC) Home video (DVD, PVR) Videoconf Differences avec MPEG-1 Profils et niveaux (7) Entrelacement Scalabilite (pseudo-HLS) Plusieurs vues Profils et niveaux MPEG-2 SDTV, DVD, MP@ML SDTV Studio: HP@ML HDTV: MP@H14Entrelacement MPEG-2 Frame entrelacee + Topness bit Field individuels Câ€™etait bizarre et ca fait chier Ordre arbitraire Peu commodeCodecs et applicationsConvoyer plusieurs chaines: MPEG-2 Transport Stream Decoupage PES en paquets de 188 bits Multiplexage pour broadcast Packet IDentifier (PID) Program Specific Information (PSI) Program Allocation Table (PAT) Program Management Table (PMT) Horloge: Program Clock Reference (PCR)MPEG-2 TS Transport Stream Decoupage PES en paquets de 188 bits Multiplexage pour broadcast Packet Identifier (PID) Program Specific Information (PSI) Program Allocation Table (PAT) Program Management Table (PMT) Horloge: Program Clock Reference (PCR)Demultiplexage MPEG2-TS PSI (PAT + PMTs) repetes regulierement Choix dâ€™une chaine Choix dâ€™un PID de PMT and la PAT Recuperation de la PMT correspondante Filtrage des PIDs decrits dans la PMT Assemblage PES correspondants Extraction ES + PT PTS : TS Image PCR Distinguer PCR de PTS PTS: TS image Cadence dâ€™affichage des images PCR: â€œheure de lâ€™encodeurâ€ Synchronise le decodeur (STC) avec lâ€™encodeur En longevite (Heures) Indispensable pour du streaming realtime (DVB-S/C/T) Comparable a SCR pour un MPEG-PS (CVD, DVD) Streaming Streaming implique: Producteur Consommateur Fifos Realtime implique: Flux tendu Fifo limitees (faible buffering) Synchronisation producteur et consommateur STC VS PCR FIGHTPas de synchro STC $\\leftrightarrow$ PCR ? STC $\\gt$ PCR Decodeur consomme plus vite que prevu Que se passe-t-il ? Drainage des FIFOs A/V $\\Rightarrow$ Video: saccades / ralentissements $\\Rightarrow$ Audio: micro-silences / repetitions STC $\\lt$ PCR Decodeur consomme plus lentement que prevu Que se passe-t-il ? Buffering limite $\\Rightarrow$ blocage impossible $\\Rightarrow$ Depassement des FIFOs $\\Rightarrow$ Perte de paquets $\\Rightarrow$ Flux elementaires discontinus $\\Rightarrow$ Audio: blips, squeals, silences $\\Rightarrow$ Video: mosaiques, prediction surrealistes Synchronisation STC PCR Besoin dâ€™asservir STC a PCR VCXO: Voltage COntrol Xtal Oscillator Mesurer diff = STC - PCR Asservir les cloks A/V correspondantes Audio: Reguler la vitess du decodeur Controle du remplissage de la fifo de samples Video Reguler la vitesse du decodeur Controle de la vitesse de production des pixels pour lâ€™affichage $\\color{orange}{\\text{Variations Pixel Clock de sortie}}$ $\\color{orange}{\\text{Tolerance en analogique (â€œeffet de volantâ€)}}$ $\\color{red}{\\text{TOUCHY en HDMI !}}$ H.264 Le championObjectifs Reprendre les applications de MPEG-2Couvrir tous les nouveaux usages: Disques optiques avances (BD, HD-DVD) Streaming actif (VOD, VCONF) Enregistreurs embarques StereoscopieNouveautes Nouveau protocole: Network Abstraction Layer Limite les repetitions Sâ€™adapte aux moyens de transmission Nouveaux outils dâ€™analyse dâ€™image Macroblocs plus fins Predictions plus elaborees Filtrage a lâ€™encodage des MV Nouveaux compresseurs entropiques CABAC: Codage arithmetique binaire Intervalles adaptatifs par modeles statistiques CAVLC VLC type Huffman Dictionnaire adapatatif par rapport aux blocs voisins Historique 1998: Initiative VCEG H26L 2001: MPEG + VCEG = Joint Video Team 2003: Finalisation premiere ebauche 2005: Fidelity Range Extension $4:2:2$ $4:4:4$ bit depth &amp;gt; 8 2007: Scalable Video Coding 2009: Multiview Video CodingArithmetique Integer DCT Calculs entiers Plus simples (que MPEG-2) Entierements specifies $\\Rightarrow$ Reconstruction exacte NAL Network Abstrasction Layer NAL: Objets semantiques du flux video VCL: Video Coding Layer NAL VCL: images, macroblocs, MVs, coefficients IDCT NAL Non-VCL: parametres, metas Changent rarement Decouplage NAL vs mode dâ€™envoi: Byte-Stream : signalisation par start codes (~MPEG-2) Packer-Transport Pour reseaux (RTP) Le protocole sous-jacent sait quel NAL il envoie/recoit ExemplesQuelques NAL IDR: Instant Decoder Refresh (VCL) Contient seulement une nouvelle image synchronisation du decodeur avec parsing minimal Besoin prealable de metas non-VCL SPS: Sequence Parameter Set (non-VCL) Profil, niveau, resolution, cadence ~ MEPG-2 Sequence Header PPS: Picture Parameter Set Codage entropique, mode de prediction, groupe et ordre des slices, filtrage de blocs En resumeASO Arbitrary Slice Order Les slices peuvent etre envoyees dans le desordre non continument dans le temps Avantages Limite lâ€™impact FMO Flexible Macroblock Ordering Partition des MB par motifs Type 0: Interlaced: Lignes Type 1: Dispersed En sequnces Type 3: Foreground: par zones (ROI) Explicitement par lâ€™encodageAvantages Forme de segmentation Adaptation a la nature du contenu $\\color{green}{\\text{Resout des cas difficiles}}$ $\\color{green}{\\text{Dispersion des impacts BER}}$Inconvenients Pas dans tous les profilsPrediction InterPartitions de MB et sous-MBReferences multiples: 16 en theorie 5 a 6 en pratique $\\color{green}{\\Rightarrow\\text{Moins de residus}}$ Ponderations possibles (fdes)Motion Vectors au quart de pixel pres:Prediction Intra Prediction spatiale: INTRA $4\\times 4$ 9 directions de recherche Pour sous-blocs $4\\times 4$ INTRA $16\\times 16$ Pour regions plus lisses / BF Filtrage in-loop In-loop deblocking filter Filtrage frontieres Luma $8\\times 8$ ou $4\\times 4$ (resp. Chroma % sampling mode) $\\color{red}{\\text{Pendant lâ€™encodage des MV}}$ $\\color{red}{\\text{Obligatoire}}$ Filtrage depend de la structure du bloc: Plusieurs references ? F++ Frontieres intra et/ou inter ? F++ Frontieres de MB ? F++!! Contours ? Fâ€“ Avantages Encodeur et decodeur fournissent la meme image (pas un post) Meilleurs MV $\\color{green}{\\Rightarrow \\text{Residus â€“}}$ $\\color{green}{\\text{Qualite perceptuelle +++}}$ PSNR identique ?!Inconvenients $\\color{red}{\\text{Complexite}}$ En baisse vu le beneficePAFF Picture Adaptative Frame/FieldFrame Mode (MPEG-2)Field mode: lâ€™un sous lâ€™autreMBAFF Macro Block Adaptative..Paire de MBs: $16\\times 32$ Mode frame: $32$ lignes progressives Mode field: $2\\times 16$ lignes entrelacees Entrelance par partiesAvantages Integrite spatiale maximum Prediction MV TOP BOT possible pour une paire de MBs en mode field $\\color{green}{\\text{Precision}++}$ Pas de MV TOP BOT pour une paire de MBs en mode frame $\\color{green}{\\text{Frugalite}++(16\\%)}$ Indices de mouvement $\\color{green}{\\text{Desentrelacement}++}$ (c) H. 265 / HVECObjectifs Ceux de H. 264 Debit /= 2 Scalabilite des calculs Simplification Parallalisation 4K, 8K, 120 i/s Free Viewpoint (VR) 10/12 bpc (HDR) Simule la sensation dâ€™eblouissement Historique 2007-2009: Rivalites MPEG - VCEG Rivalites MPEG - VCEG MPEG HPC : mauvais resultats Union JVT VC 2010: Janvier: Appel a propositions Avril: tests, Nommage HEVC Octobre: Premiere ebauche 2013: Janvier: Ebauche finale Avril: Standard ITU 2014: Avril: Ebauche V2 MV-HEVC, Rext, Scalability Octobre: V2 approuvee 2015: Janvier: Publication officielle Avril: V3 approuvee Puis definition Screen Contents: ACT, AMVR, IntraBC, Palette 2016: Juin: V4 refusee Decembre: V4 approuvee (Extension Screen Contents) Principes Decouplage enCodage Prediction Transformation CTU: Coding Tree Unit â€œMacroblocâ€ haut niveau $16\\times 16$, $32\\times 32$, $64\\times 64$ CU Partition carree dâ€™une CTUPU Partition de la CU Uniquement la predictionIntra: CU == PU Sauf au dernierTU Transformation Unit Parition de la CU Uniquement les residus Independante de la partition PURessemble a â€¦ Une TU peut couvrir plusieurs PU Ou une partie de PU Ou plusieurs parties de PUOutils 33 Modes de prediction intra 9 pour H.264 Most Probable Modes Indexation dynamique $\\color{green}{\\text{Moins de prefixe (2b vs 5b)}}$ IDCT: $4\\times4$, $16\\times 16$, etc. ~IDST $4\\times 4 possible$ Slices et Tiles Slices Comme H.264 Headers individuels $\\color{green}{\\text{Limitations de lâ€™erreur}}$ $\\color{red}{\\text{Jonctions imparfaites}}$ Tiles Partition rectangulaire de lâ€™image Header/sequence $\\color{green}{\\text{Decodage parallelisable}}$ $\\color{green}{\\text{ROI/VCONF}}$ Slices in Tiles, Tiles in slices: Video Split Wavefront parallel processing Slices divisees en lignes de CTU Pipeline multithreadable $\\color{green}{\\text{Efficace}}$ $\\color{red}{\\text{Intensif}}$ Strategie de parallelisationFiltrage Deblocking Filter Plus simple que H.264 Grille $8\\times 8$ $\\color{green}{\\text{Parallelisable}}$ SAO: Sample Adaptative Offset Filtre non-lineaire post-DBF Reduit les distorsions locales Categorie des samples selon voisinage Moyenne, contour, min, max LUT / index dâ€™offset Reduction des effets dâ€™aplats (banding)SAOOriginal:$\\color{red}{\\text{SANS}}$$\\color{green}{\\text{AVEC}}$EpilogueAutres CODECS MPEG/VCEG/JVT: Versatile Video Codec ITU Universite Industriels Evolution de H.265 Debit $\\sim 40\\%$ Finalise 07/2020 Encodeurs dispo (09/2021) Licences, royaltiesâ€¦ comme HEVC Alliance for Open Media: AV1 Amazon, Google, Samsung, ARM Temps dâ€™encodageÂ Â»&amp;gt; VVC Sâ€™ameliore avec ML (Google) En deploiement: Netflix: depuis 2018 Android TV 10: obligatoire Twitch: 2022 Evolution du marche Changer de code $\\Rightarrow$ $ Nouveau HW + SW Nouvelle conso (W) Nouvelles box utilisateur Bandes passantes plus importantes Fibre, 4G, 5G, 802.11ax $\\Rightarrow$ taux de compression en second plan (cf H.264) Nouveau Netflix, Hulu, Amazon, Apple TVâ€¦ Veulent le code â€œmagiqueâ€ Pour toutes les box Dont la licence est la moins chere (cf AV1) Evolution du streaming Trivia $60\\%$ du trafic internet $\\color{green}{\\text{Netflix}: \\sim$ 2.25 B / an}$ 2018: +50\\%, 2019: + 59\\%, 2020: +47\\% 300 MT $CO_2$/an (~Espagne) $1\\%$ des emissions $CO_2$ mondiales Questions financieres et sociales evidentes " }, { "title": "DLIM: Face detection", "url": "/cours/posts/dlim_face_detection/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-22 14:00:00 +0100", "snippet": "Lien de la note HackmdFace detection in generalWhy is facre detection so difficult ? Pose (Out-of-Plane Rotation) and orientation (In-Plane Rotation)Presence or absence of structural componentsOcclusionsImaging conditionsFaces are highly non-rigid object (deformations)Related problems Face localization Facial feature extraction (landmarks such as eyes, mouth, â€¦) Face recognition Verification Facial expressionOverview of different approaches: Knowledge top-down base method Feature invariant methods (localization) Template-matching methods (localization) Appearance-based methods (detection)Apparence-based methods in details Eigenfaces Distribution-based methods Support Vector Machines (SVM) Sparse Network of Winnows Naive Bayes Classifier Hidden Markov models Information Theoretic Approaches (ITA) Inductive Learning (C4.5 and Find-S algorithms) Artficial Neural Networks (ANN) techniques Shallow networks (inverse de Deep) Deep learning Les connections residuelles permettent de faire une retropropagation beaucoup plus loin que le reste du reseau. Le gros defaut des VGG: ils ont enormement de poids poids $=$ parametres $\\neq$ hyperparametresIl y a de moins en moins de neurones en \\%. Plus on a de poids, plus on a de chance que notre reseau soit puissant mais plus on a de chance quâ€™une partie serve a rien.The beginning in 1994 Burel et Carel proposent une methodologie pour les ANNâ€™s: La phase dâ€™entrainement ou un systeme tunes les parametres internes La phase dâ€™entrainement local ou le systeme adapte les poids specifiques a lâ€™environnement dâ€™un site local La phase de detection durant laquelle les poids ne bougent pas Vaillant, Montcoq et Le Cun: first translation invariant ANN, decides if each pixel belong or not to a given objectYang et Huang: first fully automatic human face recoginition system1997 Rowleu, Baluja, Kanade propose the first rotation-invariant method: Uses template-based approach Methodology: Regions are proposed A router network estimates the orientation of this region This network prepares the windows using this angle A detector network decides if the window contains a face 2004 First real-time face detection algo by Viola &amp;amp; Jones Tells if a given image of arbitrary size contains a human face, and if so, where it is Minimizes false positive and false negative rates Usually 5 types of Haar-like features $24\\times 24$ image contains a huge number of features ($162886$) Integral image for feature computation $A=1$, $B=2$, $C=3$, etc. Allows a low computational cost of features Principle The algorithm should deploy more resources to work on those windows more likely to containa face while spending as little effort as possible on the rest We can use weak classifiers Then we can mae a strong one with a sequence of weak ones Viola &amp;amp; Jones: use AdaBoostThe more layers, the less false positive:Overfeat (2014) Winner of the ImageNet Large Scale Visual Recognition Challenger of 2013 Makes at the sae time classification (blocks), localization (grouping blocks) and detection (merge windows) This multitask approach boosts the performance of the network Trained on ImageNEt 2012 Inspired for multi-viewing voting Uses multiscale factor of 1.4 Using a dense sliding windows thanks to convolution The better aligned the network window and the object, the strongest the confidence of thenetwork response. Efficiency: convolution computations in overlapping regions are shared Bounding boxes are accumulated instead of suppressed Only one shared network for 3 functionalities Uses a feature extractor for classification purpose Use offset to refine the resolution of the proposed windows Detection fine-tuning: negative training on the flyMethodology decomposition into blocks with 3 offsets for each block, estimation of the most probable corresponding class (overlapping) region proposals for each class (see below) bounding box deduction for each class (see below)The MTCNN face detection algorithm (2016)Zhang, Zhang &amp;amp; Li Real-time deep-learning-based face detection algorithm The MTCNN is a cascade of 3 similar networks (P/R/O-nets) The four steps: Computation of the (multiscale) image pyramid P-nEt: propositional network R-net: refinement net (filters and refines the results of the P-Net) O-net: output network (still refines, and propose landmarks) Use hard sample mining (the $30\\%$ easier cases fo not intervene in the retropropagation) to improve the detection results Originality: uses multi-task learning, that is, every network predict bounding boxes use regression to refine/calibrate the position of the edges of the bounding box applies Non-Maxmal Suppression (NMS) to keep only relevant candidate windows (merge of highly overlapped candidates) (can) propose 5 facial landmarks This multi-task seems to improve face detection compared to usual mono-task learning How does it work in pratice? It minimizes:\\[Loss=$\\alpha_1\\times L_{detection} + \\alpha_2\\times L_{regression} + \\alpha_3\\times L_{landmarks}$\\]where the first is based on cross-entropy, and the others are based on Euclidian lossFast R-CNN and its predecessors (2014-2015)Spatial-Pyramid Pool network (2014) Have been proposed to speed up R-CNN by sharing computation, The SPPnet computes a shared feature map using convolutions over the entire image, and only then extract features corresponding to each proposal to make the prediction, Then it concatenates the features of the proposal coming from each scale thanks to MaxPooling to a $6 \\times 6 \\times$ scales map (spatial pyramid). SPP-nets accelerates R-CNN by 10 to 100 times at test times and by 3 at training time. Drawback 1: Like the R-CNN, it is a multi-stage approach: First, feature extraction using convolution, Second, fine-tuning of a network using log loss, Third, SVM training, Fourth, fitting bounding-box regressors. Drawback 2: Features are written to disk, The fine-tuning cannot update the convolutional layers that precede the spatial pyramid pooling (limited accuracy).Fast R-CNN0 (2015) a Fast Region-based Convolutional Network method, Mainly made of several innovation to make is faster Uses Singular Value Decomposition (SVD) truncation to fasten the computations, Uses a multi-task loss to train all the network in one single stage (it jointly learns to classify objects proposals (windows) and refine their spatial locations), Trains the VGG16 9 times faster than the RCNN and 3 times faster than the SPP-nets, Is able to retropropagate the error in the convolutional layers (contrary to SPPnets and RCNN) and then increases the accuracy, No disk storage is required for feature caching.Faster R-CNN (2016) Usual object detection methods depended on (slow) region proposal algorithms, They got the original idea to use ANNâ€™s to do these predictions on GPU (much faster), They called this technology Region Proposal Networks (RPNs). Properties is just made of several convolutional layers applied on the feature maps, It is then a fully convolutional layer (weights are shared in space), It is then translation-invariant in space (contrary to MultiBox method), it can be seen as a mini-network with a sliding-window applied on the feature map to predict proposals, predicts at the same time proposals using regression and objectness scores, is able to predict proposals with a wide range of scales and aspect ratios (bye default, 3 and 3 respectively). Since the Fast R-CNN does not have region proposal, they added their RPN before the Fast-RCNN to obtain the Faster R-CNN, The RPN is then an attention network since it tells to the Fast R-CNN where to look Since the efficiency of the Fast R-CNN depends on the region proposals, better proposal thanks to the RPN implies a better accuracy of the Faster R-CNN, To ensure that features used between the RPN and the Fast R-CNN are the same, they shared the weights of the Feature Extractor between them (faster, more accurate). It took then 10 milliseconds to compute the predictions of the RPN.Mask R-CNN (2018) Extension of Faster R-CNN aim is instance segmentationHas 3 outputs/prediction the usual bounding box predictions (from Faster R-CNN), the usual classification predictions (still from Faster R-CNN), the mask predictions (A small FCN applied to each RoI â€“ NEW !!),No competition is done among classes prediction Mask prediction is done in parallel The training is done with a multi-task loss:\\[Loss = \\alpha_1L_{class} + \\alpha_2L_{reg}+\\alpha_3L_{mask}\\] We can easily change the backbone (feature extractor) It runs a 5 fpsR-FCN Architectures (2016) Region-based Fully Convolutional Networks 2-stage object detection strategy Every layer is convolutional, whatever its role Almost all the computations are shared on the entire image Rols (candidate regions) are extracted to a Region Proposal Network (RPN) Uses position-sensitive score mapsOn decale la fenetre sur la droite: At top-middle probability map, the white pixels correspond to the probability that a headRetinaNet (2018) One-stage detector Uses an innovative focal loss Naturally handles class imbalance Uses a Feature Pyramid Network (FPN) backbone of ResNet architecture Then it provides a rich multi-scale feature pyramid (efficiency) At each scale, they attach subnetworks to classify and make regressionsDetectrons (2018-2019)Detectron V1 2018 (Facebook)Detectron V2 (Facebook)Real-time detection algorithmsYOLO (You Only Look Once) (2016) single-shot detection architecture Designed for real-time applications It does NOT predict regions of interests It predicts a fixed amount of detections on the image directly, They are then filtered to contain only the actual detections. faster than region-based architectures lower detection accuracy performs a multi-box bounding box regression on the input image directly Method: the image is overlayed by a grid, and for each grid cell, a fixed amount of detections are predicted.SSD (Single Shot Multibox Detector) (2016) Is a single-shot detection architecture Instead of performing bounding box regression on the final layer like YOLO, SSDs append additional convolutional layers that gradually decrease in size. For each additional layer, a fixed amount of predictions with diverse aspect ratios are computed, It results in a large number of predictions that differ heavily across size and aspect ratio.YOLOv2 (YOLO 9000) (2016) Extension of YOLOv1 Ability to predict objects at different resolutions, Computes the first bounding box predictions using clustering, Better performance than SSD." }, { "title": "TVID: De l&#39;image a l&#39;ecran", "url": "/cours/posts/tvid_image_ecran/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-17 14:00:00 +0100", "snippet": "Lien de la note HackmdCadences en pratique On a des problemes de precisionsTout est entier: PTS: temps image source STC: temps horloge affichageResolution dâ€™increment: TIR TIR(PTS) = duree dâ€™une seconde dans le flux video TIR(STC) = duree dâ€™une seconde a lâ€™affichageSi TIR(PTS) non \\% TIR(STC), probleme de $\\color{red}{\\text{fraction continue!}}$ExempleTIR PTS = 90000 = 1 secondeSupposons STC = timer hardware a 5 KHz TIR(STC) $=5000$Pour un affichage a 50 fps: $\\Delta STC=5000/50=100$ (TIR \\%)Comment comparer STC avec TIR(STC) = 5000 vs PTS avec TIR(PTS) = 90000 Produit en croix\\[STC&#39; = STC \\times TIR(PTS) / TIR(STC) = STC \\times 18\\]STCâ€™ comparable avec PTS Mais jitter de STC multiplie par $18$Adaptation source 59,97 ips -&amp;gt; affichage 60 ips Theoriquement: adaptation par repetition 1 image sur 1000 En pratique: jitter PTS + jitter STC Tremblement du criteres PTS - STC BufferisationOn veut envoyer a lâ€™affichage une image a lâ€™heure !On fait de la bufferisation pour les jeux CGI realtime Bufferisation: art de choisir lâ€™image a afficher Il faut quâ€™il y ait toujours une image a lâ€™ecranBufferisation non VSYNC Envoyer le backbuffer suivant des quâ€™il est pretAvantages: Un seul backbuffer RapideInconvenient: $\\color{red}{\\text{Tearing back/front}}$Bufferisation VSYNC Permutter frontbuffer et back bufferAvantages Pas de tearingInconvenient $\\color{red}{\\text{Producteur aussi leant que lâ€™afficheur}}$ Notre jeu/application va etre ralenti Câ€™est le meme phenomene que celui du passage des jeux japonais aux consoles europeennes avec des jeux $20\\%$ plus lentBufferisation triple + VSYNC Deux backbuffers composes en alterance Au VSYNC: envoyer le backbuffer pret en front buffer Avantages Pas de tearing Decouplage cadence production vs affichage Inconvenients $\\color{red}{\\text{Deux backbuffers}}$ $\\color{red}{\\text{CPU/GPU a donf}}$ Comment afficher ?Comment cadrer lâ€™image dans lâ€™ecran ? En frequence En phaseEn frequence: Pulses verticaux: VSYNC Pulses horizontaux: HSYNCEn phase: Palliers avant/arrierePulses et palliers normalisesVGA, DVI, HDMI: Display Data Channel =&amp;gt; Extended Display Identification DataXorg: â€œModelinesâ€Cadrage dâ€™une image Vertical blanking Horizontal blankingDVI/HDMIHDMI 3DComment afficher des images 3D ? Plusieurs formats 3D numeriques Dans tous les cas, pixel clock $\\times 2$Checkerboard (NVIDIA): VBlank + VSync HSyncs + Lignes de pixels OG/OD en quinconce Lignes deux fois plus largesFrame pack (HDMI 1.4A)Analogique" }, { "title": "IMED2: Reconstruction tomographique - quand rien n&#39;est ideal", "url": "/cours/posts/imed2_tomographie/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-17 10:00:00 +0100", "snippet": "Lien de la note HackmdLes hypotheses fortes de FBP Beaucoup trop ideal La ligne est supposee connue Autrement dit: on a recupere $p$ dans $I=I_0e^{-p}$ .. ou plutot dans $I=\\int I_0(E)e^{-p(E)}dE$ Le detecteur nâ€™a aucun defaut (la mesure est supposee parfaite) Or un detecteur est loin dâ€™etre parfait Un photon qui atteint le detecteur est un photon qui vient de la source Or le rayonnement diffuse ne respecte pas cette hypothese Lâ€™objet est statique pendant lâ€™acquisition Or un patient respire, ses organes bougent, ses vaisseaux pulsentâ€¦ Lâ€™objet est integralement vu sous toutes les angulations Nous parlerons de ce sujet et dâ€™autres sujets lies a lâ€™echantillonnage au prochain cours ! Problematiques de troncationNon-idealite du tube Les basses energies sont absorbees en permier: a mesure quâ€™on traverse des epaisseurs de materiaux, le spectre se reduit vers les hautes energies: lâ€™energie moyenne du spectre augmente, on appelle ce phenomene le durcisement du faisceauNon-idealite du detecteur Les problemes de la radiographie 2Dâ€¦ sont aussi les problemes de tomographie ! + spread dans le detecteur + Reponse differente en fonction de lâ€™energie du photon + â€¦Comment on envisagerait de reparer ces artefacts circulaires ? Changer de detecteur (mais câ€™est cher)Compenser le phenomeneAvec quelle methode ? Avec la transformee de HoffCâ€™est une transformee qui detecte les lignes, utile dans la projection polaireComment on recupere les nouvelles colonnes ? On regarde le gradientQuand on travaille dans le sinogram, toutes nos colonnes sont traitees de la meme facon.On peut travailler dans 2 domaines: Le domaine image Dans le sinogramme Besoin de plus de finesse mais detection plus robuste \\[\\begin{aligned}\\bar p &amp;amp;= -log(\\frac{I}{I_0})\\quad I = P+S\\\\&amp;amp;= \\log(I_0) - \\log(P+S)\\\\&amp;amp;= \\log(I_0) - \\log(P(I+\\underbrace{\\frac{S}{P}}_{\\color{red}{\\text{SPR} \\\\ \\text{scatter-to-primaray} \\\\ \\text{ratio}}}))\\end{aligned}\\]\\[\\bar p = p_{\\text{tree}} - \\log(1+SPR)\\]Interactions avec la matieres et rayonnement diffuse Ennemi public numero 1 de la tomographie RXRejection de diffuse: Augmenter lâ€™air gap Reduire le champ de vue (collimation) Inserer une grille anti-diffuseCâ€™est aussi un probleme en 2D:Est-ce que ca fait sens de forcer les contrastes en imagerie medicale ? Oui !Il faut que le contraste de lâ€™image global soit confortableComment fixer cette image ? Estimer la non-uniformiteOn a en non-uniformite pure:Si on applique la correction, on a:Quâ€™est-ce quâ€™on a comme defaut ? La forte surbrillance sur le bordLâ€™arc de cercleLes niveaux de gris en bas de lâ€™image sont un peu plus clairs, on a presque trop corrige notre image Il faut faire attention avec ces methodes: ca peut etre pratique dâ€™un POV visuel mais il ne faut pas creer de nouveaux artefactsPlein de gens on travaille sur des methodes pour corriger ces artefacts, lâ€™un est la retroprojection differenciee. Et ca, câ€™est magique ! On a lâ€™impression que lâ€™axe horizontale est privilegieQuâ€™est-ce qui nous donne une information ligne a ligne ?On est en train de dire que les lignes sont exactement les memes.Comme algorithme, on prend notre projection, on prend la projection ligne a ligne et on retroprojecte ca\\[p\\to\\delta_u p\\to\\boxed{DBP}\\to\\text{ligne}(i) = -2\\pi \\mathcal Hf[\\text{row#}i]\\\\\\mathcal H[\\mathcal H[f]] = -f\\]Avec $\\mathcal H$: transformee de HilbertIci, elle est mal calculee: Prenons par exemple la ligne $100$: on sait que notre objet est fini.Pourquoi câ€™est interessant ?Si notre objet est gros est quâ€™on a quâ€™un champ de vue (notre objet depasse), on fait une retroprojection differenciee et on inverse toutes les lignes de notre vue. On arrivera a reconstruire notre vue, tant bien meme que lâ€™objet est tronquee Mouvement et incoherence des donnees Catastrophique en image de bas de contrastes (tissus mous) comme en imagerie vasculaire" }, { "title": "IMED2: TP2", "url": "/cours/posts/imed2_tp2/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-15 09:00:00 +0100", "snippet": "Reconstruction tomographique (1/3)Vous avez dÃ©jÃ  apprivoisÃ© la radiographie numÃ©rique rayons X, nous voici maintenant partis pour explorer lâ€™univers de la tomographie ! La tomographie (du grec $\\tau\\omicron\\mu\\omicron\\varsigma$, coupe) recouvre lâ€™ensemble des technologies permettant de visualiser lâ€™intÃ©rieur dâ€™un patient (comme une tranche de jambon), sans lâ€™ouvrir pour autant (car le jambon, dans notre cas, câ€™est le patient !).Ce premier cours sur la tomographie focalise sur les mathÃ©matiques de la reconstruction tomographique. Il est plus aride que votre cours sur la radiographie numÃ©rique, mais la maÃ®trise des outils mathÃ©matiques appliquÃ©s Ã  la tomographie est absolument indispensable : ce notebook doit vous aider Ã  vous les approprier ! Vous allez Ã©galement dÃ©couvrir ASTRA Toolbox, dont vous trouverez les dÃ©tails ici : https://www.astra-toolbox.com/from google.colab import drivedrive.mount(&#39;/content/gdrive&#39;,force_remount=True)import sysfrom pathlib import Pathroot = Path(&quot;/content/gdrive/My Drive/EPITA-2021/TP2 - Q4 2021&quot;)sys.path.append(str(root))import numpy as npfrom pathlib import Pathimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)from matplotlib import pyplot as pltfrom PIL import Imagenp.random.seed(26)root = Path.cwd()from ipywidgets import interact!pip install scikit-image==0.18from skimage.draw import diskMounted at /content/gdriveRequirement already satisfied: scikit-image==0.18 in /usr/local/lib/python3.7/dist-packages (0.18.0)Requirement already satisfied: scipy&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.4.1)Requirement already satisfied: networkx&amp;gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2.6.3)Requirement already satisfied: numpy&amp;gt;=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.19.5)Requirement already satisfied: matplotlib!=3.0.0,&amp;gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (3.2.2)Requirement already satisfied: PyWavelets&amp;gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.2.0)Requirement already satisfied: imageio&amp;gt;=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2.4.1)Requirement already satisfied: pillow!=7.1.0,!=7.1.1,&amp;gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (7.1.2)Requirement already satisfied: tifffile&amp;gt;=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2021.11.2)Requirement already satisfied: python-dateutil&amp;gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (2.8.2)Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (2.4.7)Requirement already satisfied: kiwisolver&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (1.3.2)Requirement already satisfied: cycler&amp;gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (0.11.0)Requirement already satisfied: six&amp;gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&amp;gt;=2.1-&amp;gt;matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (1.15.0)# !apt-get install automake libtool# !pip install astra-toolbox# !apt-get install automake libtool# !git clone https://github.com/astra-toolbox/astra-toolbox# %cd astra-toolbox/build/linux# !./autogen.sh# !./configure --with-cuda=/usr/local/cuda \\# --with-python \\# --with-install-type=module# !make -j2# !make installimport astraPartie 1 - GÃ©omÃ©trie parallÃ¨le, projection parallÃ¨le, sinogrammesComme prÃ©sentÃ© au dÃ©but du cours, on considÃ¨re la gÃ©omÃ©trie parallÃ¨les suivante :Le principe de la reconstruction tomographique est le suivant. Dans le cas idÃ©al, la mesure au dÃ©tecteur correspond Ã  une loi de Beer-Lambert $I=I_0e^{-p}$, dâ€™oÃ¹ je peux rÃ©cupÃ©rer $p$, qui est ma ligne intÃ©grale. Si mon image est bi-dimensionnelle, $p$ est un signal mono-dimensionnel. On appelle acquisition tomographique, la collection de telles lignes intÃ©grales $p$, lorsque lâ€™angle des lignes intÃ©grales couvre un certain intervalle angulaire :\\(A_\\Theta = \\left\\lbrace p_\\theta \\right\\rbrace_{\\theta\\in\\Theta}, \\quad p_\\theta(u) = \\iint_{u_\\theta(\\underline{x})=u} \\mu(\\underline{x})\\mathrm{d}\\underline{x}.\\)En gÃ©omÃ©trie parallÃ¨le, dans notre cas dâ€™Ã©tude, $\\Theta = [0,\\pi]$. En mots simples, lâ€™acquisition tomographique revient donc Ã  collecter les projections dâ€™un objet sous tous les angles dâ€™un demi-cercle. En mots compliquÃ©s, lâ€™acquisition tomographique est la transformÃ©e de Radon de $\\mu$.Le problÃ¨me de la reconstruction tomographique consiste Ã  rÃ©pondre Ã  la question suivante : Etant donnÃ©e $A_\\Theta$, est-il possible de reconstruire une carte 2D des $\\mu$ ? Selon que lâ€™on se place dans un cas idÃ©al ou non, que lâ€™on couvre bien tout le demi-cercle $[0,\\pi]$ ou non, que les projections soient tronquÃ©es ou non, etc., la rÃ©ponse Ã  cette question sera plus ou moins simple. Dans la suite, on appellera $f$, la quantitÃ© reconstruite Ã  partir de $A_\\Theta$.Nous allons reprendre les rÃ©sultats mathÃ©matiques fondamentaux qui permettent de rÃ©pondre au problÃ¨me de la reconstruction tomographique dans un cas idÃ©al en gÃ©omÃ©trie parallÃ¨le 2D. Comme nous lâ€™avons fait en radiographie numÃ©rique, nous verrons quâ€™il est nÃ©cessaire de rÃ©flÃ©chir hors du cadre idÃ©al dans les cours 2 et 3 de tomographie.Questions Quelle est lâ€™Ã©quation qui relie le point $\\underline{x}=(x,y)$ Ã  sa coordonnÃ©e projetÃ©e $u_\\theta(\\underline{x})$ ? On se donne un nombre nbins de bins de dÃ©tecteurs (voyez cela comme un nombre de pixels sur une image Ã  une ligne). DÃ©finissez lâ€™axe detector, dont lâ€™origine est au milieu du dÃ©tecteur ; on sâ€™attend Ã  quelque chose comme : [-191.5 -190.5 -189.5 -188.5 â€¦ 188.5 189.5 190.5 191.5] lorsque nbins=384. On dÃ©finit une taille dâ€™image N et une image synthÃ©tique, constituÃ©e dâ€™un simple petit carrÃ© blanc sur fond noir. Afin de coller Ã  la dÃ©finition de la gÃ©omÃ©trie ci-dessus, dÃ©finissez les axes X et Y afin de placer lâ€™origine au centre de lâ€™image, comme sur la figure ci-dessus. DÃ©duisez-en les valeurs des coordonnÃ©es $(x_0, y_0)$ du centre du carrÃ© blanc, dans ce systÃ¨me de coordonnÃ©es. VÃ©rifiez sur lâ€™image que les lignes rouges intersectent bien le centre du carrÃ©. Attention aux axes : rappelez-vous quâ€™en Python, la premiÃ¨re coordonnÃ©e donne la position verticale, la second coordonnÃ©e donne la position horizontale. On dÃ©finit un vecteur dâ€™angles de $[0,\\pi]$. Quelle est la trajectoire du point $(x_0,y_0)$ en fonction des angles ? On utilise les fonctionnalitÃ©s dâ€™ASTRA pour crÃ©er une gÃ©omÃ©trie dâ€™image et un projecteur (regardez la documentation dâ€™ASTRA pour en savoir plus). Puis, on gÃ©nÃ¨re un sinogramme : il sâ€™agit dâ€™une image dont chaque ligne correspond Ã  la projection au dÃ©tecteur pour une angulation donnÃ©e (on parcourt le vecteur des angles dâ€™acquisition en parcourant les lignes du sinogramme). Rajoutez Ã  cette image votre estimation de la trajectoire du point $(x_0,y_0)$ : quâ€™observez-vous ? Faites de mÃªme pour une image avec plusieurs carrÃ©s de diffÃ©rents niveaux de gris ; observez le sinogramme gÃ©nÃ©rÃ© : que pouvez-vous en dire ?# Question 2def getDetectorAxis(nbins): return (np.arange(nbins) - 0.5 * (nbins - 1))nbins = 384detector = getDetectorAxis(nbins)N = 256img = np.zeros((N,N))m = 3ctr = [32,192]img[ctr[0]-m:ctr[0]+m+1,ctr[1]-m:ctr[1]+m+1] = 1# Question 3X = getDetectorAxis(img.shape[1])Y = -getDetectorAxis(img.shape[0])x0, y0 = X[ctr[1]], Y[ctr[0]]plt.figure()plt.imshow(img,extent=[X.min(),X.max(),Y.min(),Y.max()])plt.axvline(x0,0,1,c=&#39;r&#39;,ls=&#39;--&#39;)plt.axhline(y0,0,1,c=&#39;r&#39;,ls=&#39;--&#39;)plt.show()# Question 4def getTrajectory(x0,y0,angles): return x0 * np.cos(angles) + y0 * np.sin(angles)angles = np.linspace(0,np.pi,180,False)traj = getTrajectory(x0,y0,angles)plt.figure()plt.plot(angles,traj)plt.xlabel(&#39;Angles (rad)&#39;)plt.ylabel(&#39;Detector coordinate&#39;)plt.show()# ASTRA framework :# - create image geometry (NxN image array)# - create projection geometry (parallel-beam, detector bin size, detector size, angular positions)# - create a projector (projection method, from an image geometry to a projection geometry)# - apply the projector to an existing image (img is adapted to the image geometry that was defined)# returns: an ID and a sinogramvol_geom = astra.create_vol_geom(N,N)proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles)proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom)sinogram_id, sinogram = astra.create_sino(img, proj_id)plt.imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])plt.title(&#39;Sinogram&#39;)plt.axis(&#39;auto&#39;)plt.xlabel(&#39;Detector coordinate&#39;)plt.ylabel(&#39;Angle (deg)&#39;)# Question 5plt.plot(traj,angles * 180 / np.pi,&#39;r&#39;,alpha=0.5)plt.show()img = np.zeros((256,256))m = 5centers = [[50,250],[250,50],[128,128],[64,128]]for i,ctr in enumerate(centers): img[ctr[0]-m:ctr[0]+m+1,ctr[1]-m:ctr[1]+m+1] = i+1 # Question 6 x0, y0 = X[ctr[1]], Y[ctr[0]] plt.axvline(x0,0,1) plt.axhline(y0,0,1)plt.imshow(img,extent=[X.min(),X.max(),Y.min(),Y.max()])plt.show()sinogram_id, sinogram = astra.create_sino(img, proj_id)plt.imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])plt.title(&#39;Sinogram&#39;)plt.axis(&#39;auto&#39;)plt.xlabel(&#39;Detector coordinate&#39;)plt.ylabel(&#39;Angle (deg)&#39;)plt.show()Partie 1 : Ce quâ€™il faut retenir Un peu de gÃ©omÃ©trie de lycÃ©e suffit Ã  caractÃ©riser la gÃ©omÃ©trie dâ€™acquisition parallÃ¨le ! Lorsquâ€™on tourne autour dâ€™un point du plan image, celui-ci se projette Ã  diffÃ©rents endroits du dÃ©tecteur ; sa trajectoire en fonction de lâ€™angle dâ€™acquisition dÃ©crit une sinusoÃ¯de. On reprÃ©sente lâ€™acquisition $A_\\Theta$ sous la forme dâ€™un sinogramme : il sâ€™agit simplement des profils projetÃ©s au dÃ©tecteur Ã  chaque angle dâ€™acquisition.Partie 2 - RÃ©tro-projection filtrÃ©eRÃ©tro-projection filtrÃ©eCâ€™est lÃ  quâ€™il va falloir refaire appel Ã  vos cours de mathÃ©matiques ! Au programme : calcul intÃ©gral, changements de variables, analyse de Fourierâ€¦ et distributions de Dirac !Tout commence avec le thÃ©orÃ¨me coupe-projection qui est le suivant :\\(\\mathcal{F}_2[f](\\rho\\underline{\\theta}) = \\mathcal{F}_1[p_\\theta](\\rho),\\)oÃ¹ : $\\mathcal{F}n$ dÃ©signe la transformÃ©e de Fourier en $n$ dimensions, $f$ est lâ€™image 2D correspondant Ã  lâ€™acquisition tomographique, $p\\theta$ est la projection de $f$ selon lâ€™angle $\\theta$, $\\rho\\in\\mathbb{R}$, et $\\theta\\in[0,\\pi]$.Questions On se propose de dÃ©montrer le thÃ©orÃ¨me fondamental de la reconstruction tomographique, appelÃ© â€œthÃ©orÃ¨me coupe-projectionâ€ : Partez de la dÃ©finition de la transformÃ©e de Fourier 1D de $p_\\theta$ Utilisez la dÃ©finition de la ligne intÃ©grale de $p_\\theta$ pour exprimer $p_\\theta$ en fonction de $f$ Trouvez une transformÃ©e de Fourier 2D dans lâ€™expression que vous obtenez Ce thÃ©orÃ¨me fondamental est en rÃ©alitÃ© tout ce dont vous avez besoin pour reconstruire $f$ Ã  partir de $A_\\Theta$. Ecrivez $f$ comme la transformÃ©e de Fourier inverse de $\\mathcal{F}_2[f]$ Appliquez un changement de variables Utilisez le thÃ©orÃ¨me coupe-projection Le rÃ©sultat de la question 2 doit aboutir Ã  lâ€™inversion classique de la rÃ©troprojection filtrÃ©e :\\(f(\\underline{x}) = \\int_0^\\pi (h * p_\\theta)(u_\\theta(\\underline{x})) \\mathrm{d}\\theta,\\)oÃ¹ $h$ est appelÃ© le filtre rampe et correspond Ã  une multiplication dans lâ€™espace de Fourier par $\\rho\\mapsto|\\rho|$. Pourquoi cette Ã©tape de filtrage est-elle vraiment nÃ©cessaire ? Câ€™est ce quâ€™on va Ã©tudier dans la suite de ce notebook.Questions On gÃ©nÃ¨re une image synthÃ©tique constituÃ©e dâ€™un disque uniforme centrÃ© de rayon $R$. On dÃ©finit le sinogramme associÃ© avec ASTRA (https://www.astra-toolbox.com/files/misc/ICTMS2019/20190722_ICTMS_ASTRA_workshop_2d.pdf). Auriez-vous pu calculer analytiquement la valeur de cette projection ?On se propose de rÃ©aliser une rÃ©troprojection â€œsimpleâ€ (backprojection en anglais). Cela revient Ã  reconstruire : $f_{\\mathrm{BP}}(\\underline{x}) = \\int_0^\\pi p_\\theta(u_\\theta(\\underline{x})) \\mathrm{d}\\theta.$ En termes simples, la rÃ©troprojection dâ€™une projection $p_\\theta$ revient Ã  prendre la valeur de chaque point de $p_\\theta$, et Ã  recopier cette valeur tout le long de la ligne de projection. Observez lâ€™image reconstruite : comment vous semble-t-elle ? Renormalisez lâ€™image reconstruite pour que son maximum corresponde Ã  lâ€™image idÃ©ale. Tracez un profil horizontal au milieu de lâ€™image pour lâ€™image idÃ©ale et lâ€™image reconstruite : que pouvez-vous en dÃ©duire ? Lâ€™observation sur ces profils est-elle cohÃ©rente avec votre lecture de lâ€™image ? A vous dâ€™ajouter le filtre rampe ! Une faÃ§on de faire est de remarquer que $ \\rho = \\frac{1}{2\\pi}(2i\\pi\\rho)(-i\\mathrm{sign}(\\rho))$. Reconnaissez-vous Ã  quoi correspond la multiplications par $2i\\pi\\rho$ dans Fourier ? Et la multiplication par $-i\\mathrm{sign}(\\rho)$ ? RÃ©alisez un filtre rampe et appliquez-le Ã  notre sinogramme. Tracez une ligne du sinogramme. Lâ€™effet du filtre est-il passe-bas ? passe-haut ? passe-bande ?â€¦ Lancez la reconstruction du sinogramme filtrÃ©, et comparez Ã  nouveau les profils horizontaux au centre de lâ€™image : quâ€™observez-vous ?# Question 3angles = np.linspace(0,np.pi,180,False)N = 512vol_geom = astra.create_vol_geom(N,N)nbins = int(1.5*N)proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles)detector = getDetectorAxis(nbins)proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom)R = 32rr, cc = disk((N//2, N//2), R, shape=(N,N))img = np.zeros((N,N))img[rr,cc] = 1000sinogram_id, sinogram = astra.create_sino(img, proj_id)f,ax = plt.subplots(1,2,figsize=(12,5))ax[0].imshow(img)ax[0].set_title(&#39;Synthetic image&#39;)ax[1].imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])ax[1].set_title(&#39;Sinogram&#39;)ax[1].axis(&#39;auto&#39;)ax[1].set_xlabel(&#39;Detector coordinate&#39;)ax[1].set_ylabel(&#39;Angle (deg)&#39;)plt.tight_layout()plt.show()def analyticalCenteredDiskProjection(detector,R,mu): &quot;&quot;&quot; Projection analytique d&#39;un disque uniforme centrÃ© de rayon R et de coefficient linÃ©aire d&#39;attÃ©nuation mu sur le dÃ©tecteur detector &quot;&quot;&quot; return 2 * mu * np.sqrt(R**2 - (detector ** 2)).clip(max = R ** 2)plt.figure(figsize=(12,5))plt.plot(detector,sinogram.mean(axis=0),label=&#39;Sinogram profile&#39;)plt.plot(detector,analyticalCenteredDiskProjection(detector,R,1000),&#39;--&#39;,label=&#39;Analytical projection&#39;)plt.legend()plt.tight_layout()plt.show()/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in sqrt# Create a data object for the reconstructionrec_id = astra.data2d.create(&#39;-vol&#39;, vol_geom)# Set up the parameters for a reconstruction algorithm using the CPUcfg = astra.astra_dict(&#39;BP&#39;)cfg[&#39;ReconstructionDataId&#39;] = rec_idcfg[&#39;ProjectionDataId&#39;] = sinogram_idcfg[&#39;ProjectorId&#39;] = proj_id# cfg[&#39;FilterType&#39;] = &#39;none&#39;# Create the algorithm object from the configuration structurealg_id = astra.algorithm.create(cfg)# Run the algorithmastra.algorithm.run(alg_id)# Get the resultrec = astra.data2d.get(rec_id) / angles.sizeplt.imshow(rec)plt.colorbar()plt.title(&#39;BP Reconstruction&#39;)plt.show()# Question 4width = (np.arange(N)-0.5*(N-1)).astype(&#39;int&#39;)prof0 = rec[:,rec.shape[1]//2] * 1000/ np.max(rec)prof = img[:,rec.shape[1]//2]plt.plot(width,prof,label=&#39;BP middle profile&#39;)plt.plot(width,prof0,label=&#39;Ideal profile&#39;)plt.legend()plt.show()# Question 6from scipy.signal import hilbertprof = analyticalCenteredDiskProjection(detector,R,1000) *1000 / np.max(rec)prof_grad = np.gradient(prof)filt = hilbert(prof_grad).imagprof0_grad = np.gradient(prof0)filt0 = hilbert(prof0_grad).imagfor k in range(sinogram.shape[0]): sinogram[k] = filtsdiff = len(filt) - len(filt0)f,ax = plt.subplots(1,2,figsize=(12,5))ax[0].plot(detector,filt, label=&#39;BP profile&#39;)ax[0].plot(detector[sdiff//2:-sdiff//2], filt0, label=&#39;Ideal profile&#39;)ax[1].imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])ax[1].set_title(&#39;Sinogram&#39;)ax[1].axis(&#39;auto&#39;)ax[1].set_xlabel(&#39;Detector coordinate&#39;)ax[1].set_ylabel(&#39;Angle (deg)&#39;)plt.tight_layout()plt.show()/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in sqrt/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:452: UserWarning: Warning: converting a masked element to nan. dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:459: UserWarning: Warning: converting a masked element to nan. a_min = np.float64(newmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:464: UserWarning: Warning: converting a masked element to nan. a_max = np.float64(newmax)&amp;lt;string&amp;gt;:6: UserWarning: Warning: converting a masked element to nan./usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan. return array(a, dtype, copy=False, order=order)# Question 7out_id, out = astra.creators.create_reconstruction(&#39;BP&#39;, proj_id, sinogram)out /= angles.size*2plt.imshow(out)plt.show()print(cfg)width = np.arange(N)-0.5*(N-1)prof = out[out.shape[0]//2]plt.plot(width,prof,label=&#39;FBP middle profile&#39;)plt.plot(width,img[img.shape[0]//2],label=&#39;Ideal profile&#39;)plt.legend()plt.grid()plt.show()/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:452: UserWarning: Warning: converting a masked element to nan. dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:459: UserWarning: Warning: converting a masked element to nan. a_min = np.float64(newmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:464: UserWarning: Warning: converting a masked element to nan. a_max = np.float64(newmax)&amp;lt;string&amp;gt;:6: UserWarning: Warning: converting a masked element to nan./usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan. return array(a, dtype, copy=False, order=order){&#39;type&#39;: &#39;BP&#39;, &#39;ReconstructionDataId&#39;: 12, &#39;ProjectionDataId&#39;: 10, &#39;ProjectorId&#39;: 8}On peut directement appliquer le filtre rampe en choisissant non pas une rÃ©troprojection simple (BP) mais une rÃ©troprojection filtrÃ©e (FBP). Câ€™est ce qui est fait ci-dessous. Le rÃ©sultat est normalisÃ© par la taille dâ€™un bin dÃ©tecteur.cfg = astra.astra_dict(&#39;FBP&#39;)cfg[&#39;ReconstructionDataId&#39;] = rec_idcfg[&#39;ProjectionDataId&#39;] = sinogram_idcfg[&#39;ProjectorId&#39;] = proj_idcfg[&#39;FilterType&#39;] = &#39;ram-lak&#39;# Create the algorithm object from the configuration structurealg_id = astra.algorithm.create(cfg)# Run 20 iterations of the algorithm# This will have a runtime in the order of 10 seconds.astra.algorithm.run(alg_id)# Get the resultrec = astra.data2d.get(rec_id)plt.imshow(rec)plt.colorbar()plt.title(&#39;Reconstruction&#39;)plt.show()width = np.arange(N)-0.5*(N-1)prof = rec[rec.shape[0]//2]plt.plot(width,prof,label=&#39;FBP middle profile&#39;)plt.plot(width,img[img.shape[0]//2],label=&#39;Ideal profile&#39;)plt.legend()plt.grid()plt.show()En regardant lâ€™image avec un fenÃªtrage plus serrÃ© autour de zÃ©ro, on voit apparaÃ®tre des motifs dans le fond de lâ€™image : ce sont des motifs typiques de phÃ©nomÃ¨nes dâ€™interpolation liÃ©s Ã  lâ€™implÃ©mentation des projecteurs / rÃ©troprojecteurs. Regardez cette image avec ou sans zoom !zoom = slice(150,-150),slice(150,-150)zoom = slice(None,None)plt.imshow(rec[zoom],vmin=-20,vmax=20)plt.colorbar()plt.title(&#39;Reconstruction&#39;)plt.show()Partie 2 : Ce quâ€™il faut retenir La rÃ©troprojection simple est un opÃ©rateur qui redistribue un profil projetÃ© le long de sa direction de projection. La rÃ©troprojection simple ne reconstruit pas lâ€™image attendue ; pour reconstruire lâ€™image, un prÃ©-filtrage des projections par le filtre rampe est nÃ©cessaire. ASTRA Toolbox permet de rÃ©aliser ces reconstructions.Partie 3 - Echantillonnage angulaireDans cette partie, nous allons commencer Ã  toucher du doigt les problÃ©matiques dâ€™Ã©chantillonnage angulaire. La formule FBP est une formule continue, que lâ€™on discrÃ©tise ensuite pour en faire un algorithme : on boucle sur chaque projection, on filtre, on rÃ©troprojette en accumulant le rÃ©sultat dans un buffer. Que se passe-t-il si le nombre de projections nâ€™Ã©chantillonne plus correctement lâ€™intervalle $[0,\\pi]$ ?On se construit Ã  nouveau une image synthÃ©tique, constituÃ©e dâ€™un disque centrÃ©, et dâ€™un point de trÃ¨s fort contraste.highIntensity = TrueN = 512R = 32img = np.zeros((N,N))rr, cc = disk((N//2, N//2), R, shape=(N,N))img[rr,cc] = 1000if highIntensity: rr, cc = disk((N//2, N//5), R//8, shape=(N,N)) img[rr,cc] += 5000plt.imshow(img)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fbe107756d0&amp;gt;Questions DÃ©finissez deux fonctions, project et reconstruct, pour automatiser la projection et la reconstruction. project prend en entrÃ©e une image, un nombre dâ€™angles, et un offset ; cela permet de crÃ©er un vecteur dâ€™angles entre angleOffset et angleOffset+np.pi, dont la taille est donnÃ©e par le nombre dâ€™angles. On peut ensuite crÃ©er la gÃ©omÃ©trie de projection, le dÃ©tecteur, le projecteur, et le sinogramme. reconstruct prend en entrÃ©e un identifiant ASTRA dâ€™un projecteur, un identifiant ASTRA dâ€™un sinogramme, et crÃ©e un reconstructeur FBP, quâ€™on utilisera pour reconstruire une image. Lancez les diffÃ©rentes expÃ©riences, en gÃ©nÃ©rant diffÃ©rents sinogrammes avec un nombre dÃ©croissant de vues, et en reconstruisant les images Ã  partir de ces sinogrammes. Quâ€™observez-vous ?# Question 1def project(img,nAngles,angleOffset=0): angles = np.linspace(angleOffset, angleOffset + np.pi, nAngles, False) N = img.shape[0] vol_geom = astra.create_vol_geom(N,N) nbins = int(1.5*N) proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles) detector = getDetectorAxis(nbins) proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom) sinogram_id, sinogram = astra.create_sino(img, proj_id) return proj_id, sinogram_id, sinogram, angles, vol_geomdef reconstruct(proj_id, sinogram_id, vol_geom): rec_id = astra.data2d.create(&#39;-vol&#39;, vol_geom) cfg = astra.astra_dict(&#39;FBP&#39;) cfg[&#39;ReconstructionDataId&#39;] = rec_id cfg[&#39;ProjectionDataId&#39;] = sinogram_id cfg[&#39;ProjectorId&#39;] = proj_id cfg[&#39;FilterType&#39;] = &#39;ram-lak&#39; alg_id = astra.algorithm.create(cfg) astra.algorithm.run(alg_id) rec = astra.data2d.get(rec_id) return rec# Question 2for nAngles in 180//2**np.arange(5): print(nAngles) # projection de img avec nAngles vues proj_id, sinogram_id, sinogram, angles, vol_geom = project(img, nAngles) # reconstruction rec = reconstruct(proj_id, sinogram_id, vol_geom) plt.imshow(rec,vmin=-500,vmax=500) plt.colorbar() plt.title(&#39;Reconstruction&#39;) plt.show() plt.plot(rec[rec.shape[0]//2]) plt.show()18090452211Dans cette derniÃ¨re expÃ©rience, on gÃ©nÃ¨re une image trÃ¨s grande (de taille 5120x5120), dans laquelle on nâ€™a quâ€™un petit disque (de rayon 8 !).N = 5120R = 8img = np.zeros((N,N))rr, cc = disk((N//2, N//2), R, shape=(N,N))img[rr,cc] = 1000zoom = slice(img.shape[0]//2-128,img.shape[0]//2+128), slice(img.shape[1]//2-128,img.shape[1]//2+128)plt.imshow(img[zoom])plt.colorbar()plt.show()Questions Choisissez nAngles=32 vues, et gÃ©nÃ©rez un sinogramme Ã  partir de cette image. Cela peut prendre un peu de temps, lâ€™image est plus grande quâ€™avant ! Reconstruisez lâ€™image Ã  partir de ce sinogramme, et visualisez lâ€™image avec le petit zoom proposÃ© (afin de mieux voir les artefacts dâ€™Ã©chantillonnage). LÃ  encore, soyez patient ! RegÃ©nÃ©rez un sinogramme Ã  partir de cette reconstruction, mais cette fois-ci, dÃ©calez les angles dâ€™acquisition dâ€™un demi-pas dâ€™Ã©chantillonnage angulaire. Que remarquez-vous sur le sinogramme obtenu ? Justifiez ce rÃ©sultat mathÃ©matiquement ! Repartez cette fois de lâ€™algorithme FBP en tant que boucle sur les angles dâ€™acquisition, et remontez jusquâ€™au plan de Fourier !â€¦# Question 3nAngles = 32vol_geom = astra.create_vol_geom(N,N)nbinsIdeal = int(1.5*N)proj_id, sinogram_id, sinogram, angles, vol_geom = project(img, nAngles)# Question 4rec = reconstruct(proj_id, sinogram_id, vol_geom)plt.imshow(rec,vmin=-100,vmax=100,interpolation=&#39;none&#39;)plt.show()zoom = slice(rec.shape[0]//2-128,rec.shape[0]//2+128),slice(rec.shape[1]//2-128,rec.shape[1]//2+128)plt.imshow(rec[zoom],vmin=-100,vmax=100,interpolation=&#39;none&#39;)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fbe0a33dfd0&amp;gt;# Question 5angleOffset = np.gradient(angles).mean() * 0.5proj_id, sinogram_id, sinogram, angles, vol_geom = project(rec, nAngles, angleOffset)plt.imshow(sinogram)plt.axis(&#39;auto&#39;)plt.colorbar()plt.show()# Question 5plt.plot(sinogram.mean(axis=0))plt.axhline(0,0,1,color=&#39;r&#39;)print(np.median(sinogram))0.0Partie 3 : Ce quâ€™il faut retenir FBP, en tant quâ€™algorithme, rÃ©troprojette des projections filtrÃ©es avec leurs rebonds liÃ©s au filtre rampe. Lorsque lâ€™Ã©chantillonnage angulaire diminue, ces rebonds ne se compensent plus entre eux et ils deviennent visibles dans lâ€™image sous forme de stries de sous-Ã©chantillonnage. Ces stries sont intrinsÃ¨quement liÃ©es au peuplement du plan de Fourier de lâ€™image reconstruite." }, { "title": "PRSTA: Revisions 1", "url": "/cours/posts/prsta_revisions_1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-11-12 14:00:00 +0100", "snippet": "Lien de la note HackmdExercice 1Partie 1Une variable aleatoire $X$ suit une loi normale de moyenne et de variance $1$. Nous voulons tester lâ€™hypothese $H_0 : m = 0$ contre lâ€™hypothese $H_1 : m \\gt 0$.Pour ce faire, nous disposons des observations : $-2.3, -0.2, 4.3, 1.1, 0,2.4, -1.6, 1.4, -1$ et $0.8$.Lâ€™hypothese $(H_0)$ est-elle rejetee avec un risque dâ€™erreur de premiere espece de $5\\%$. Solution Sous lâ€™hypothese $H_0$,\\[T = \\sqrt{n} \\frac{\\bar X_n - m}{\\sigma}\\sim N(0,1)\\\\t= \\sqrt{10}\\frac{0,48 - 0}{1}\\simeq 1,55\\] Zone de rejet:\\[\\color{red}{R=}\\{T\\gt q_{0,95}\\}\\\\\\{T\\gt1,64\\}\\] Est-ce que $t$ appartient a notre zone de rejet ? $t\\not\\in \\color{red}{R}$ $\\color{red}{\\text{donc}}$ lâ€™hypothese $(H_0)$ nâ€™est pas rejetee.Partie 2Une variable aleatoire $Y$ suit une loi normale de moyenne et de variance inconnue. Nous voulons tester lâ€™hypothese $H_0 : m = 0$ contre lâ€™hypothese $H_1 : m \\neq 0$.Pour ce faire, nous disposons des memes observations : $-2.3, -0.2, 4.3, 1.1, 0, 2.4, -1.6, 1.4, -1$ et $0.8$.Lâ€™hypothese $(H_0)$ est-elle rejetee avec un risque dâ€™erreur de premiere espece de $5\\%$. Solution\\[Z_n = \\sqrt{n}\\frac{\\bar X_n - m_0}{\\sqrt{S_n^2}}\\sim T_{n-1}\\\\S_n^2:= \\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X_n)^2\\] Ici,\\[t = \\sqrt{10}\\frac{0,49 - 0}{1,96}\\simeq 0,79\\] Zone de rejet: on rejette des 2 cotes\\[\\{T\\gt 2.26\\}\\cup\\{T\\lt \\color{green}{-2.26}\\}\\\\R=\\color{green}{\\{T\\gt q_{0,975}\\}\\cup\\{T\\lt q_{0,025}\\}}\\] Pourquoi on nâ€™a pas besoin dâ€™utiliser Python ? Car câ€™est symetrique $\\color{green}{\\text{Pas}}$ de rejet car $\\color{blue}{t\\not\\in R}$Partie 3Une variable aleatoire $Z$ suit une loi normale de moyenne inconnue et de variance $\\sigma^2$. Nous voulons tester lâ€™hypothese $H_0 : \\theta^2 = 4$ contre lâ€™hypothese $H_1 : Ïƒ^2 \\lt 4$.Pour ce faire, nous disposons des memes observations : $-2.3, -0.2, 4.3, 1.1, 0, 2.4, -1.6, 1.4, -1$ et $0.8$.Lâ€™hypothese $(H_0)$ est-elle rejetÂ´ee avec un risque dâ€™erreur de premiereespece de $10\\%$. Solution\\[T = (n-1)\\frac{S_n^2}{\\sigma_0^2}=\\boxed{\\frac{1}{\\sigma^2_0}\\sum_{i=1}^n(X_i-\\bar X_n)^2}\\] Sur lâ€™echantillon,\\[t\\simeq \\frac{1}{4}\\times 34, 55 = 8,64\\]\\[\\begin{aligned}&amp;amp;P(T\\lt t)\\quad\\text{ou } T\\sim\\chi^2(9)\\\\&amp;amp;= P(T\\lt 8,64)\\\\&amp;amp;\\simeq 0,53\\color{orange}{\\gt 0,1}\\end{aligned}\\] Comment resonne-t-on avec la P-value ? Il faut que la P-value soit superieure ou egale Donc lâ€™hypotese $(H_0)$ nâ€™est pas rejetee.Exercice 2Selon une etude, la duree des smartphones de la marque Pomme suit une loi exponentielle de parametre $\\frac{1}{\\theta}$ avec $\\theta \\gt 0$ inconnu.Considerons un echantillon de taille $n$ que nous noterons $(X1,\\dots,Xn)$. Lâ€™entreprise souhaite savoir si elle peut garantir ses telephones pour une duree de deux ans. Justifier que le probleme se ramene au test des hypotheses : $H_0 : \\theta = 2$ contre $H1 : \\theta \\lt 2$. Francois propose la regle de decision suivante : Lâ€™hypothese $(H_0)$ est rejetee si $T \\lt 2$ ou \\(T = \\min_{1 \\le i\\le n} Xi\\). Justifier que la variable alÂ´eatoire T suit une loi exponentielle dont le parametre sera precise. En deduire que, sous lâ€™hypothese $(H_0)$, $P(T \\lt 2) = 1 âˆ’ \\exp(âˆ’n)$. (a) Pour $n = 10$, determiner la valeur de $\\alpha$. (b) De meme, pour $n = 100$, que remarquez-vous ? Que pensez-vous de la regle de decision retenue par Francois ? Solution 1. Comme le parametres est $\\frac{1}{\\theta}$, on veut affirmer sur la duree de vie moyenne $\\theta$ est $2$ ans, et on aura un probleme si jamais elle est inferieure car $E(\\varepsilon(\\frac{1}{2}))=2$ 2. $H_0$ rejetee si $T\\lt 2$ avec \\(T:=\\min_{1\\le i\\le n}X_i\\) 3.\\[\\begin{aligned}F(x)&amp;amp;=\\int_0^x\\lambda e^{-\\lambda t}dt\\\\&amp;amp;= [-e^{\\lambda y}]_0^x\\\\&amp;amp;= -e^{-xt} + 1 = 1-e^{-xt}\\end{aligned}\\]\\[\\begin{aligned}R(x) &amp;amp;= 1-F(x)\\\\&amp;amp;=e^{-\\lambda x}\\end{aligned}\\]\\[\\begin{aligned}P(T&amp;amp;\\gt x)\\\\P(\\min_{1\\le i\\le n}X_i&amp;amp;\\gt x)\\\\P(\\bigcap_{i=1}^n\\{X_i&amp;amp;\\gt n\\})\\end{aligned}\\] Sous $H_0$:\\[\\begin{aligned}P(T\\gt x) &amp;amp;= \\prod_{i=1}^nP(X_i\\gt x)\\\\&amp;amp;= P(X_1\\gt x)^n\\\\&amp;amp;= e^{-\\frac{n}{\\color{blue}{\\theta}}x}\\end{aligned}\\] \\[T\\sim\\varepsilon(\\frac{n}{\\color{blue}{\\theta}})\\] 4.\\[\\begin{aligned}P(T\\lt 2) &amp;amp;= F(2)\\\\&amp;amp;= 1-e^{-\\frac{n}{2}\\times 2}\\\\&amp;amp;= \\color{red}{1-e^{-n}}\\end{aligned}\\] 5.\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T\\lt 2\\vert \\theta=2)\\\\&amp;amp;= \\color{red}{\\boxed{1-e^{-n}}}\\end{aligned}\\\\n = 10\\\\\\alpha\\simeq = 0.9999\\] 6. Rien quâ€™avec $n=10$, on a un $\\alpha$ extremement eleve, la regle est donc NULLE. Test GLR\\[\\color{red}{H_0:\\theta = 2\\text{ contre } H_1:\\theta\\lt 2}\\]\\[T=\\frac{L(X_1,\\dots, X_n,2)}{L(X_1,\\dots, X_n,\\hat\\theta)}\\] Soit:\\[\\color{red}{H_0:\\frac{1}{\\theta} = \\frac{1}{2}\\text{ contre } H_1:\\frac{1}{\\theta}\\lt \\frac{1}{2}}\\]\\[\\begin{aligned}T&amp;amp;=\\frac{L(X_1,\\dots, X_n,\\color{green}{\\frac{1}{\\bar X_n}})}{L(X_1,\\dots, X_n,\\frac{1}{2})}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n\\color{green}{\\frac{1}{\\bar X_n}}e^{-\\color{green}{\\frac{1}{\\bar X_n}} X_i}}{\\prod_{i=1}^n\\frac{1}{2}e^{-\\frac{1}{2}X_i}}\\\\&amp;amp;= (\\color{green}{\\frac{2}{\\bar X_n}})^ne^{-\\sum_{i=1}^n(\\color{green}{\\frac{1}{\\bar X_n}}-\\frac{1}{2})X_i}\\end{aligned}\\] Lâ€™hypothese $(H_0)$ est rejetee si $T\\gt S_{\\alpha}$. Nous allons utiliser Wilks. \\[\\begin{aligned}R&amp;amp;=2\\ln(T)\\\\&amp;amp;= 2n\\ln(\\color{green}{\\frac{2}{\\bar X_n}})-2\\sum_{i=1}^n(\\color{green}{\\frac{1}{\\bar X_n}}-\\frac{1}{2})X_i\\\\\\end{aligned}\\] Pour $n$ suffisamment grand:\\[\\{R\\sim\\chi^2(1)\\}\\]" }, { "title": "Petit disclaimer", "url": "/cours/posts/disclaimer/", "categories": "Image S9, blabla", "tags": "Image, S9, blabla", "date": "2021-11-12 10:00:00 +0100", "snippet": "Hello tres chers Images (oui je precise Image parce que je sais que les autres majeures vont direct dans categories-&amp;gt;ASE2/3)En ce moment mes notes sont plus que bancales. Jâ€™ai envie de dire que câ€™est â€œnormalâ€, on croule sous les projet. Dâ€™habitude la facon dont le site fonctionne câ€™est que je rentre $\\to$ je retravaille mes notes $\\to$ je poste. Je vous laisse deviner quâ€™en ce moment câ€™est pas trop le cas vu que jâ€™ai pas vraiment le temps pour.Jâ€™ai poste des nouvelles notes non retravaillees, elles sont super brouillon et yâ€™a des TODO partout.Une fois cette vague de projet passes, je retravaillerais les notes en question pour que vous ayez un truc un chouia plus potable que ce quâ€™il y a actuellement.Voila voila, je sais pas qui va lire ca mais au moins maintenant vous savez pourquoi mes notes les plus recentes sont aussi degueu." }, { "title": "IMED2: TP1", "url": "/cours/posts/imed2_tp1/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-12 09:00:00 +0100", "snippet": "# from google.colab import drive# drive.mount(&#39;/content/gdrive&#39;,force_remount=True)import sysfrom pathlib import Pathroot = Path(&quot;./&quot;)sys.path.append(str(root))import numpy as npfrom pathlib import Pathimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)from matplotlib import pyplot as pltfrom PIL import Imagenp.random.seed(26)Partie 1 - Loi de Beer-Lambert, bruit, contrastesJouer avec les projectionsâ€¦Loi de Beer-LambertTout matÃ©riau est caractÃ©risÃ© par un coefficient linÃ©aire dâ€™attÃ©nuation $\\mu$ qui a comme dimension lâ€™inverse dâ€™une longueur. A la traversÃ©e dâ€™un milieu, lâ€™intensitÃ© initiale dâ€™un faisceau de rayons X ($I_0$) est attÃ©nuÃ©e selon la loi de Beer-Lambert suivante :\\(I = I_0 \\exp(-p),\\)oÃ¹ :\\(p = \\int_L \\mu(l)dl,\\)et $L$ est la ligne suivie par les photons X. Nous raffinerons cette formule au fur et Ã  mesure du cours, car cette modÃ©lisation est incomplÃ¨te. A commencer par lâ€™absence de bruit statistique ! En rÃ©alitÃ©, lâ€™observation $I$ fluctue autour de la valeur donnÃ©e par la loi de Beer-Lambert selon une loi de Poisson :\\(I \\sim \\mathcal{P}\\left(I_0 \\exp\\left(-\\int_L \\mu(l)dl\\right)\\right).\\)En pratique, si on mesure $I$, on sâ€™intÃ©resse plutÃ´t Ã  lâ€™intÃ©grale $p$, obtenue (lorsquâ€™on nÃ©glige le bruit) par passage au logarithme:\\(p=\\log(I_0)-\\log(I).\\)Questions Une loi de Poisson a pour densitÃ© de probabilitÃ© $P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}$. Calculer lâ€™espÃ©rance et la variance dâ€™une variable alÃ©atoire suivant une loi de Poisson. Quâ€™en dÃ©duisez-vous sur lâ€™Ã©volution du SNR en fonction de $I_0$ ? (Faites le calcul !) Ecrire une fonction sumCols(img) qui prend une image 2D en entrÃ©e et retourne le profil somme le long de lâ€™axe vertical (lâ€™axe des $x$ de lâ€™image). A quoi correspond cette fonction dans la loi de Beer-Lambert ? Ecrire une fonction beerLambert(img,I0) qui calcule le signal au dÃ©tecteur aprÃ¨s application de la loi de Beer-Lambert (avec sa statistique de Poisson) sur un profil 1D tel que sorti de sumCols().1.\\(\\begin{aligned}E[X]&amp;amp;=\\sum_{k=0}^{+\\infty}kP(X=k)\\\\&amp;amp;= \\sum_{k=0}^{+\\infty}k\\frac{\\lambda^k}{k!}e^{-\\lambda}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k=1}^{+\\infty}\\frac{\\lambda^k}{(k-1)!}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k=1}^{+\\infty}\\frac{\\lambda^{k+1}}{k!}\\\\&amp;amp;= \\lambda e^{-\\lambda}\\underbrace{\\sum_{k=0}^{+\\infty}\\frac{\\lambda^k}{k!}}_{e^{\\lambda}}\\end{aligned}\\\\\\boxed{E[X] = \\lambda}\\\\\\)\\[\\sigma^2=\\lambda\\]3.sumCols(img) $\\to[\\int_{c_1}\\mu d, \\int_{c_2}\\mu d, \\dots]$ car une integrale nâ€™est rien dâ€™autre quâ€™une somme# Question 2def sumCols(img): &quot;&quot;&quot; img est un np.ndarray (de dimension 2) sumCols(img) retourne un vecteur de mÃªme taille que le nombre de colonnes de img, chaque Ã©lÃ©ment du vecteur Ã©tant Ã©gal Ã  la somme des Ã©lÃ©ments de la colonne correspondante dans img &quot;&quot;&quot; return np.sum(img, axis = 0)# Question 3def beerLambert(prof,I0): &quot;&quot;&quot; prof est une sortie de sumCols() I0 est un paramÃ¨tre correspondant Ã  l&#39;intensitÃ© dans l&#39;air (feu nu) beerLambert(prof,I0) renvoie une rÃ©alisation de la loi de Beer-Lambert (statistique de Poisson) &quot;&quot;&quot; return np.random.poisson(I0*np.exp(-prof))arr = np.array([[1, 2],[3, 4]])arr, beerLambert(sumCols(arr), 1)(array([[1, 2], [3, 4]]), array([0, 0]))Questions Lancez le code ci-dessous, qui gÃ©nÃ¨re une image synthÃ©tique composÃ©e dâ€™un objet de â€œfondâ€ (le grand carrÃ©) et dâ€™une structure dâ€™intÃ©rÃªt (le petit carrÃ©). Distinguez-vous bien le petit carrÃ© du grand carrÃ© Ã  lâ€™oeil nu? GÃ©nÃ©rez des profils de mesures selon la loi de Beer-Lambert (loi de Poisson), avec I0 = 1e6, I0 = 1e4, I0 = 1e2, et I0 = 1. Quâ€™observez-vous sur le profil dâ€™attÃ©nuation ? sur le profil reconverti en log ?# Question 4backgroundValue = 0.01relativeContrast = 0.05# GÃ©nÃ©ration d&#39;une image synhtÃ©tiqueimg = np.zeros((128,128))img[32:-32,32:-32] += backgroundValueimg[48:-48,48:-48] += relativeContrast*backgroundValueplt.figure()plt.imshow(img)plt.colorbar()plt.show()# I0 = 1e6, 1e4, 1e2, 1I0=1e6# Question 5 : gÃ©nÃ©ration du profil d&#39;attÃ©nuationprof0 = sumCols(img)attenuation = beerLambert(prof0, I0)f,ax = plt.subplots(1,3,figsize=(18,4))ax[0].plot(prof0,&#39;-o&#39;)ax[1].plot(attenuation,&#39;-o&#39;)# profil reconverti en logprof = np.log(I0)-np.log(attenuation)ax[2].plot(prof,&#39;-o&#39;)plt.show()Analyser les donnÃ©es de faÃ§on plus quantitativeNous allons quantifier les phÃ©nomÃ¨nes observÃ©s pour en tirer des conclusions plus solides. Le but de lâ€™exercice est ici de comparer le niveau de contraste que lâ€™on observe dans img entre le petit et le grand carrÃ©, et le niveau de â€œcontrasteâ€ associÃ© dans le profil issu de sumCols(img). Aller chercher de faÃ§on plus ou moins automatique ce genre dâ€™informations nÃ©cessite de savoir jouer un peu avec les signaux.Questions Calculez (sans fonction toute faite) une diffÃ©rence finie dâ€™ordre 1 : Si $p$ est le profil issu de sumCols(img), alors la diffÃ©rence finie Ã  lâ€™indice $i$ est $g_i = p_{i+1}-p{i}$. Tracez le profil de la valeur absolue de cette diffÃ©rence finie : que fait-il ressortir ? Nous allons extraire des informations de ce nouveau profil $g$. Utilisez la fonction np.where pour rÃ©cupÃ©rer les points de $g$ qui correspondent Ã  la zone projetÃ©e du grand carrÃ©. Pouvez-vous rÃ©pÃ©ter lâ€™opÃ©ration pour trouver les points correspondant Ã  la projection du petit carrÃ© ? DÃ©duisez-en les calculs des quantitÃ©s suivantes : valeur moyenne $B$ dans le â€œfondâ€ (la projection du grand carrÃ© seul), valeur moyenne $C$ dans la â€œstructureâ€ (la projection du grand carrÃ© et du petit carrÃ© ensemble), Ã©cart-type $\\sigma_B$ dans le â€œfondâ€. Calculez les valeurs de contraste relatif $C_r$ et de CNR (https://howradiologyworks.com/x-ray-cnr/) dÃ©finis comme suit :\\(C_r = \\frac{C-B}{B}, \\quad \\mathrm{CNR} = \\frac{|C-B|}{\\sigma_B}.\\)# Question 6 : diffÃ©rence finie d&#39;ordre 1def g(x): &quot;&quot;&quot; g(x) calcule la diffÃ©rence finie &quot;Euler forward&quot; g(x)[i] = x[i+1]-x[i] &quot;&quot;&quot; return x[1:]-x[:-1]grad = np.abs(g(prof0))plt.plot(grad)[&amp;lt;matplotlib.lines.Line2D at 0x7efe27a46490&amp;gt;]# Question 7 : trouver les points de grad (et donc de prof0) qui correspondent Ã  la projection du grand carrÃ©bmin, bmax = np.where(grad &amp;gt; 0.9 * grad.max())[0]bmin += 1f,ax = plt.subplots()ax.plot(range(bmin,bmax),prof0[bmin:bmax])ax1=ax.twinx()ax1.plot(range(bmin,bmax),grad[bmin:bmax],c=&#39;r&#39;,ls=&#39;--&#39;,alpha=0.4)[&amp;lt;matplotlib.lines.Line2D at 0x7efe27963070&amp;gt;]# Question 8 : mÃªme principe, pour rÃ©cupÃ©rer la zone de projection du petit carrÃ©bmin1, bmax1 = np.where(grad[bmin:bmax] &amp;gt; 0.9 * grad[bmin:bmax].max())[0]bmin1 += bmin + 1bmax1 += bmin plt.plot(range(bmin1,bmax1),prof0[bmin1:bmax1])[&amp;lt;matplotlib.lines.Line2D at 0x7efe278dd4c0&amp;gt;]# Question 9 : Construction des zones d&#39;intÃ©rÃªt du profil# [u00,u01[ : zone de fond gauche# [u10,u11[ : zone de contraste# [u20,u21[ : zone de fond droitemargin = 5u00 = bmin + marginu01 = bmin1 - marginu10 = bmin1 + marginu11 = bmax1 - marginu20 = bmax1 + marginu21 = bmax - marginplt.plot(range(bmin,bmax),prof0[bmin:bmax])plt.plot(range(u00,u01),prof0[u00:u01],c=&#39;r&#39;,lw=5)plt.plot(range(u10,u11),prof0[u10:u11],c=&#39;g&#39;,lw=5)plt.plot(range(u20,u21),prof0[u20:u21],c=&#39;r&#39;,lw=5)[&amp;lt;matplotlib.lines.Line2D at 0x7efe278c1d60&amp;gt;]# Question 9 (suite) : calcul du contraste relatif et du CNR sur profbackground = np.concatenate([prof[u00:u01], prof[u20:u21]])backgroundEstimate = background.mean() # BbackgroundNoiseEstimate = background.std() # CcontrastEstimate = prof[u10:u11].mean() # teta_brelativeContrast = (backgroundNoiseEstimate - backgroundEstimate) / backgroundEstimate # Cr = (C - B) / Bcnr = np.abs(backgroundNoiseEstimate - backgroundEstimate) / contrastEstimate # CNR = |C - B| / teta_b print(&#39;Relative contrast:&#39;,np.round(relativeContrast,3))print(&#39;CNR:&#39;,np.round(cnr,3))Relative contrast: -0.998CNR: 0.975Partie 1 : Ce quâ€™il faut retenir Il est plus facile dâ€™identifier un contraste dans une image que dans une projection Le bruit de Poisson rend la tÃ¢che dâ€™identification de faibles contrastes dans les projections encore plus difficile Le bon cÃ´tÃ© du bruit de Poisson, câ€™est que le bruit augmente moins vite que le signal avec $I_0$: ainsi le SNR sâ€™amÃ©liore lorsque $I_0$ augmente Une image en dynamique exponentielle est difficile Ã  lire: on prÃ©fÃ¨re rÃ©cupÃ©rer une dynamique plus linÃ©aire en passant au logPartie 2 - ChaÃ®ne de traitement dâ€™une image de radiographie numÃ©riqueUne image brute lue au dÃ©tecteur Ã  rayons X est loin dâ€™Ãªtre acceptable pour un radiologue ; dans cette partie, nous allons explorer la chaÃ®ne de traitement appliquÃ©e sur une image brute afin de la prÃ©parer Ã  Ãªtre prÃ©sentÃ©e au radiologue.Chargez lâ€™image mesurÃ©e au dÃ©tecteur : câ€™est une image inexploitable en lâ€™Ã©tat ! â€œBad pixelsâ€, non-uniformitÃ©s du fond, dynamique exponentielleâ€¦ Cette image a besoin dâ€™Ãªtre traitÃ©e avant dâ€™Ãªtre regardable.I0 = 1e6fn = Path(&quot;homer_measurement_noisy.704.640.raw&quot;)measurement = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))plt.imshow(measurement)plt.axis(&#39;off&#39;)plt.show()Correction dâ€™offsets, de gains, bad pixelsEn thÃ©orie, lorsque la loi de Beer-Lambert annonce que lâ€™on doit (au bruit prÃ¨s) mesurer une valeur $I$ au dÃ©tecteur, on sâ€™attend Ã  ce que la mesure soit Ã©gale Ã  $I$. En pratique, ce nâ€™est pas le cas : le plus souvent, on considÃ¨re que la mesure est une fonction affine de la valeur thÃ©orique : $I_m = aI+b$. Cette fonction affine est diffÃ©rente pour chaque pixel.On appelle offsets, les valeurs qui sortent dâ€™un dÃ©tecteur alors quâ€™il nâ€™est pas exposÃ© aux rayons X : en thÃ©orie, le dÃ©tecteur devrait retourner une image noire (zÃ©ros) ; en pratique, lâ€™Ã©lectronique du dÃ©tecteur, les dÃ©fauts de conception, font que lâ€™image non exposÃ©e nâ€™est pas nulle. Les offsets correspondent donc au paramÃ¨tre $b$ de la fonction linÃ©aire.Lorsque le dÃ©tecteur nâ€™est pas exposÃ© aux rayons X, il peut lire Ã  vide plusieurs images Ã  la suite : câ€™est Ã  partir de ces lectures multiples que lâ€™on peut estimer une carte dâ€™offsets $b$.De mÃªme, lorsque lâ€™on exposre uniformÃ©ment le dÃ©tecteur sans objet dans le champ, on sâ€™attend Ã  mesurer une intensitÃ© constante au dÃ©tecteur aprÃ¨s soustraction des offsets ; en pratique, on mesure $I_m-b=aI$, lÃ  encore, avec des valeurs de $a$ diffÃ©rentes par pixel.Une lecture multiple du dÃ©tecteur exposÃ© aux rayons X peut permettre dâ€™estimer la carte des gains $a$.Les â€œbad pixelsâ€ sont des pixels du dÃ©tecteur qui ne rÃ©pondent tout simplement plus ; il y en a forcÃ©ment, car malgrÃ© toutes les prÃ©cautions lors de la production et de lâ€™acheminement des dÃ©tecteurs, il est impossible de garantir lâ€™infaillibilitÃ© de tous les pixels du dÃ©tecteur. Heureusement, il est possible dâ€™identifier la position de ces bad pixels, et dâ€™interpoler les valeurs Ã  partir des pixels voisins.Questions Chargez la sÃ©rie dâ€™images de lectures Ã  vide du dÃ©tecteur ; affichez la premiÃ¨re image de la sÃ©rie : que voyez-vous ? Quâ€™est-ce qui diffÃ¨re dâ€™une image Ã  lâ€™autre ? Proposez une estimation de la carte dâ€™offsets Ã  partir de cette sÃ©rie dâ€™images; corrigez la mesure en offsets : voyez-vous beaucoup de diffÃ©rences entre lâ€™image corrigÃ©e et non corrigÃ©e ? pourquoi ?# Question 1fn = Path(root/&quot;offsetMapAcq.50.704.640.raw&quot;)offsetMapAcq = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((50,704,640))plt.imshow(offsetMapAcq[0])plt.colorbar()plt.axis(&#39;off&#39;)plt.show()Dâ€™ou vient ce bruit ? Il y a un bruit inherent a lâ€™electronique du detecteur# Question 2offsetMap = offsetMapAcq.mean(axis = 0)plt.imshow(offsetMap,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.axis(&quot;off&quot;)plt.colorbar()plt.show()# Question 2 (suite)f,ax = plt.subplots(1,2)ax[0].imshow(measurement,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_axis_off()ax[0].set_title(&#39;Measurement&#39;)ax[1].imshow((measurement-offsetMap).clip(min=0),cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_axis_off()ax[1].set_title(&#39;Offset-corrected&#39;)Text(0.5, 1.0, &#39;Offset-corrected&#39;)Question Chargez la sÃ©rie dâ€™images de lectures du dÃ©tecteur uniformÃ©ment exposÃ© ; proposez une estimation de la carte dâ€™offsets Ã  partir de cette sÃ©rie dâ€™images, et corrigez la mesure en gain : quâ€™observez-vous ?# Question 3fn = Path(root/&quot;gainMapAcq.50.704.640.raw&quot;)gainMapAcq = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((50,704,640))plt.imshow(gainMapAcq[0])plt.axis(&#39;off&#39;)plt.colorbar()plt.show()gainMap = (gainMapAcq - offsetMap).clip(min=0).mean(axis = 0)gainMap /= np.median(gainMap)plt.imshow(gainMap,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.axis(&quot;off&quot;)plt.colorbar()plt.show()# Question 3 (suite)tmp = (measurement - offsetMap).clip(min=0) / gainMapplt.imshow(tmp,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-17-a5367ba78078&amp;gt;:3: RuntimeWarning: invalid value encountered in true_divide tmp = (measurement - offsetMap).clip(min=0) / gainMapQuestion Proposez une dÃ©tection des pixels â€œmortsâ€ (bad pixels) ; comparez votre dÃ©tection Ã  la carte des bad pixels que vous aurez chargÃ©. Terminez la correction de lâ€™image dÃ©jÃ  corrigÃ©e en offsets et en gains, en fournissant la carte des bad pixels Ã  la fonction dâ€™inpainting.# Question 4# (...)badPixelMap = (offsetMap == 0)plt.imshow(badPixelMap,interpolation=&#39;none&#39;)plt.axis(&quot;off&quot;)plt.show()fn = Path(root/&quot;badPixels.704.640.raw&quot;)badPixels = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))plt.imshow(badPixels-badPixelMap)plt.axis(&quot;off&quot;)plt.show()# Question 4 (suite)import cv2tmp[badPixelMap==1] = 0output = cv2.inpaint(tmp.astype(&#39;float32&#39;), badPixelMap.astype(&#39;uint8&#39;), 1, cv2.INPAINT_NS)plt.imshow(output,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.colorbar()plt.axis(&quot;off&quot;)plt.show()Question Chargez la dÃ©tection â€œidÃ©aleâ€ ; comparez lâ€™image idÃ©ale et lâ€™image corrigÃ©e : quâ€™observez-vous ?# Question 5fn = Path(root/&quot;Inoisy.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))res = (output-I)/Iplt.imshow(res,vmin=res.mean()-3*res.std(),vmax=res.mean()+3*res.std())plt.colorbar()plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-20-63d627f3aeb6&amp;gt;:5: RuntimeWarning: divide by zero encountered in true_divide res = (output-I)/I&amp;lt;ipython-input-20-63d627f3aeb6&amp;gt;:5: RuntimeWarning: invalid value encountered in true_divide res = (output-I)/ITransformation logRappelez-vous que la loi de Beer-Lambert fournit $I=I_0e^{-p}$ ; puisque $p$ est la quantitÃ© rÃ©ellement intÃ©ressante, on transforme les mesures suivant : \\(p = \\log(I_0)-\\log(I).\\)Questions Transformez lâ€™image corrigÃ©e via lâ€™Ã©quation prÃ©cÃ©dente ; afin de ne pas appliquer le log Ã  zÃ©ro, utilisez la fonction np.clip pour clipper les valeurs infÃ©rieures Ã  $10^{-3}$. Quâ€™observez-vous ? DÃ©finissez une fonction linlog(x,x0) qui correspond au logarithme de $x$ au-delÃ  dâ€™un seuil $x_0$, et qui se prolonge linÃ©airement jusquâ€™Ã  zÃ©ro avec continuitÃ© des pentes. Transformez lâ€™image corrigÃ©e en utilisant cette nouvelle fonction : le rÃ©sultat est-il plus convaincant ?# Question 6plt.imshow(np.log(I0)-np.log(output.clip(min=1e-3)))plt.axis(&quot;off&quot;)plt.colorbar()plt.show()Des quâ€™on arrive dans des zones petites, notre lof sâ€™effondre, dâ€™ou le bruit blanc.Câ€™est pour ca quâ€™on prefere linearise le $\\log$ pour avoir des pentes plus douces# Questions 7 &amp;amp; 8def linlog(x,x0): &quot;&quot;&quot; linlog(x,x0) est un logarithme naturel standard au-dessus de x0 En-dessous de x0, linlog(x,x0) est linÃ©aire, avec une continuitÃ© de pentes en x0 &quot;&quot;&quot; x0 = float(x0) x = float(x) if isinstance(x,(int,float)) else x.astype(float)# return np.where(x &amp;gt;= x0, np.log(x), (1/x0)*x) return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + bplt.figure()x = np.linspace(0,10,1000)x0 = 3plt.plot(x[1:],np.log(x.max())-np.log(x[1:]),label=&#39;log&#39;)plt.plot(x,np.log(x.max())-linlog(x,x0),label=&#39;linlog&#39;)plt.axvline(x0,0,1,color=&#39;k&#39;,ls=&#39;dashed&#39;)plt.legend()plt.show()outLog = np.log(I0)-linlog(output,x0)plt.imshow(outLog)plt.colorbar()plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + b&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + bf,ax = plt.subplots(1,2)ax[0].imshow(measurement,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_axis_off()ax[1].imshow(outLog,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_axis_off()On a moins de bruit et on recupere des infos interessantes.Partie 2 : Ce quâ€™il faut retenir Une image brute doit Ãªtre traitÃ©e avant dâ€™Ãªtre prÃ©sentÃ©e Ã  lâ€™utilisateur Ces traitements comprennent gÃ©nÃ©ralement une correction en offsets et en gains, et une correction de bad pixels Ces corrections sont issues de procÃ©dures de calibration offline, fournissant des informations utilisÃ©es ensuite online sur les images La transformation via le logarithme peut poser problÃ¨me dans les zones de faible exposition : dans ce cas, un logarithme linÃ©arisÃ© dans les faibles valeurs est pertinentPartie 3 - ContrÃ´le automatique de lâ€™exposition (AEC)Le principe ALARA (as low as reasonably achievable, de plus en plus remplacÃ© par le terme ALADA â€“ as low as diagnostically achievable) signifie que si lâ€™on doit fournir une dose importante lÃ  oÃ¹ on en a besoin (et oÃ¹ lâ€™analyse bÃ©nÃ©fice/risque est en faveur de cette exposition aux radiations), en revanche il faut Ã  tout prix rÃ©duire la dose de rayonnements ionisants lorsque celle-ci nâ€™apporte rien dâ€™un point de vue clinique. Câ€™est dans cette optique que les techniques de contrÃ´le automatique de lâ€™exposition (automatic exposure control, ou AEC) ont Ã©tÃ© dÃ©veloppÃ©es dans diffÃ©rentes modalitÃ©s.Dans lâ€™exemple qui suit, on se place dans le cadre dâ€™une adaptation ligne Ã  ligne de lâ€™exposition du patient ; cela peut Ãªtre le rÃ©sultat dâ€™un filtre physique qui sâ€™adapterait en sortie du tube, ou dâ€™un systÃ¨me Ã  balayage qui scannerait ligne Ã  ligne.Supposons que les structures dâ€™intÃ©rÃªt soient â€œcorrectementâ€ centrÃ©es au niveau du dÃ©tecteur ; le bruit au dÃ©tecteur dÃ©pendant de la ligne intÃ©grale traversÃ©e $p$, si lâ€™on veut garantir un niveau de bruit supÃ©rieur ou Ã©gal Ã  un niveau cible sur une ligne du dÃ©tecteur, il faut identifier la zone â€œcentrÃ©eâ€ la plus radio-opaque de cette ligne. En rÃ©pÃ©tant cette recherche ligne Ã  ligne, on obtient des points ${p_{\\max,i}}_i$ qui nous dÃ©finissent une courbe caractÃ©ristique $t$.Questions Re-dÃ©finissez lâ€™image idÃ©ale $p$ Ã  partir de I et I0 ; pour chaque ligne, rÃ©cupÃ©rez le maximum de cette ligne dans le tiers central, ainsi que les indices des points rÃ©alisant ce maximum. Tracez le profil rÃ©sultant de cette opÃ©ration. Lissez ce profil Ã  lâ€™aide dâ€™un filtre Ã  moyenne glissante : il sâ€™agit dâ€™une convolution par un noyau constituÃ© uniquement de 1. Utilisez une taille de 32 pour le noyau.# Question 1fn = Path(root/&quot;Inoisy.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))img = np.log(I0) - linlog(I, 3)n = 3idx = img.shape[1] // n + img[:,img.shape[1] // n : (n-1) * img.shape[1] // n].argmax(axis=1)integrals = np.array([img[k,idx[k]] for k in range(img.shape[0])])plt.figure()plt.plot(integrals)plt.xlabel(&#39;Row number (from top to bottom)&#39;)plt.ylabel(&#39;Max value (in central area)&#39;)plt.show()&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + b# Question 1 (complÃ©ment)plt.imshow(I)plt.scatter(idx,np.arange(I.shape[0]),c=&#39;r&#39;,s=2)plt.show()# Question 2size = 32kernel = np.ones(size) / size window = size//2integrals = np.convolve(np.pad(integrals,(window,window),&#39;edge&#39;),kernel,&#39;same&#39;)[window:-window]f,ax = plt.subplots()ax.imshow(img.T)ax1 = ax.twinx()ax1.plot(integrals,&#39;r&#39;,lw=3)plt.show()Questions Utilisez les mÃªmes coordonnÃ©es de lâ€™image pour tracer le profil des signaux dÃ©tecteurs de I. Varient-ils beaucoup ? Vous avez jusquâ€™ici travaillÃ© en supposant $I_0$ constant pour toute lâ€™image : on parle dâ€™exposition constante ou uniforme. Essayez maintenant dâ€™adapter les paramÃ¨tres de tir dâ€™une ligne Ã  lâ€™autre de lâ€™image, afin de ramener le profil que vous venez de tracer constant autour de 100. On va donc adapter la valeur de $I_0$ dâ€™une ligne Ã  lâ€™autre. Pouvez-vous dÃ©terminer ce profil de modulation I0Vector, de la taille de la hauteur de lâ€™image ? En supposant que le kVp reste fixe, quelle quantitÃ© physique est ainsi modulÃ©e ?# Question 3detectorSignal = np.array([I[k, idx[k]] for k in range(idx.size)])plt.plot(detectorSignal)plt.yscale(&#39;log&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;Detector signal&#39;)plt.title(&#39;Signal profile&#39;)plt.show()On a un profile qui va essayer de baisser les valeurs la ou on a sous-expose et les augmenter la ou on a sur-expose.On a $p_i=\\int udl$ qui est lâ€™epaisseurLe profil au-dessus est\\[I_n=I_0^{\\text{(red)}}e^{-p}\\]\\[I\\simeq \\text{target}\\]# Question 4targetSignal = 100I0Vector = targetSignal * np.exp(integrals)plt.plot(I0Vector)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;$I_0$ value&#39;)plt.show()Par rapport a notre image avec la courbe et Homer, quand on regarde le profil dâ€™epaisseur, on se rend compte que la dynamique est faible $\\in[3;14]$. Il faut un peu plus dâ€™epaisseur pour en tirer le maximum et obtenir le meilleur resultat possible.Questions Etant donnÃ©s $p$ et le vecteur de modulation $I_0$, simulez lâ€™image ainsi acquise (sans ajout de bruit). Tracez le profil des signaux dÃ©tecteurs de I avec cette nouvelle acquisition. Comparez-le au profil qui aurait Ã©tÃ© obtenu avec un $I_0$ fixe Ã©gal Ã  la moyenne du vecteur de modulation. Quâ€™observez-vous ? Estimez le niveau de rÃ©duction de dose par rapport Ã  une acquisition Ã  techniques fixes lorsque : (a) $I_0$ est constant Ã©gal au maximum des valeurs du vecteurs de modulation ; (b) $I_0$ est constant Ã©gal Ã  la valeur moyenne du vecteur de modulation. A quoi correspondent ces deux cas ?# Question 5Imod = I0Vector[:,None] * np.exp(-img)f,ax = plt.subplots(1,2)ax[0].imshow(I,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_title(&#39;Unmodulated&#39;)ax[0].set_axis_off()ax[1].imshow(Imod,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_title(&#39;Modulated&#39;)ax[1].set_axis_off()# Question 6plt.plot([Imod[k,idx[k]] for k in range(idx.size)],label=&#39;With modulation&#39;)plt.plot([I[k, idx[k]] / I0 * I0Vector.mean() for k in range(idx.size)],label=&#39;Without modulation&#39;)plt.axhline(targetSignal,0,1,color=&#39;r&#39;,ls=&#39;dashed&#39;)plt.yscale(&#39;log&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;Detector signal&#39;)plt.title(&#39;Signal profile&#39;)plt.legend()plt.show()# Question 7cumulativeI0 = np.trapz(I0Vector)# Cas (a)cumulativeI0FixedMax = cumulativeI0.max()# Cas (b)cumulativeI0FixedMean = cumulativeI0.mean()print(&#39;Case (a): dose reduction of&#39;, np.round(100*(1-cumulativeI0/cumulativeI0FixedMax),2),&#39;%&#39;)print(&#39;Case (b): dose reduction of&#39;, np.round(100*(1-cumulativeI0/cumulativeI0FixedMean),2),&#39;%&#39;)plt.figure()plt.plot(I0Vector)plt.axhline(I0Vector.max(),0,1,color=&#39;k&#39;,ls=&#39;dashed&#39;)plt.axhline(I0Vector.mean(),0,1,color=&#39;r&#39;,ls=&#39;dashed&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;$I_0$ value&#39;)plt.show()Case (a): dose reduction of 0.0 %Case (b): dose reduction of 0.0 %Partie 3 : Ce quâ€™il faut retenir Le principe ALARA (ALADA) est Ã  lâ€™origine des dÃ©veloppements rÃ©cents en stratÃ©gies AEC Le but est dâ€™atteindre un signal cible au dÃ©tecteur, gage dâ€™un niveau de qualitÃ©, et de moduler lâ€™exposition en consÃ©quence Tirer Ã  techniques fixes avec la valeur moyenne de modulation revient Ã  utiliser la mÃªme dose, mais distribuÃ©e de faÃ§on non optimale (sous-exposition Ã  certains endroits, sur-exposition Ã  dâ€™autres) EOSedge est le premier systÃ¨me dâ€™imagerie RX Ã  balayage intÃ©grant une stratÃ©gie AEC : la Flex DosePartie 4 - DiffusÃ© et qualitÃ© imageEn premiÃ¨re approximation, le rayonnement diffusÃ© peut Ãªtre vu comme un signal additionnel basse frÃ©quence du signal initial (dit primaire). Si $I$ est le rayonnement primaire, et $S$ le rayonnement diffusÃ©, lâ€™intensitÃ© mesurÃ©e au dÃ©tecteur est $I_{s}=I+S$.Questions Quel est lâ€™effet du diffusÃ© $S$ sur lâ€™estimation de la ligne intÃ©grale $p=\\log(I_0)-\\log(I_s)$ ? Quâ€™en dÃ©duisez-vous sur le niveau de gris moyen dans lâ€™image $p$ par rapport Ã  lâ€™image idÃ©ale $p_{\\mathrm{true}} = \\log(I_0)-\\log(I)$ ? A lâ€™aide de la fonction cv2.GaussianBlur, filtrez lâ€™image I avec un noyau isotrope de taille 51, et multipliez-la par 0.1. Appelez cette nouvelle image S : ce sera notre image de diffusÃ©. Ajoutez ce diffusÃ© Ã  lâ€™image primaire I : appelez Iscatter cette nouvelle image. GÃ©nÃ©rez une rÃ©alisation de bruit de Poisson associÃ©e Ã  cette image corrompue par du diffusÃ©. De mÃªme, gÃ©nÃ©rez une rÃ©alisation de bruit de Poisson associÃ©e Ã  lâ€™image non corrompue I. Ecrivez une fonction qui applique la transformation log vue prÃ©cÃ©demment. Transformez lâ€™image Iscatter : quâ€™observez-vous par rapport Ã  la transformation de I ? Supposez que vous connaissez la carte de diffusÃ© (câ€™est le cas ici, puisquâ€™on lâ€™a gÃ©nÃ©rÃ©e) ; soustrayez-la Ã  votre acquisition corrompue : que donne lâ€™image en log par rapport Ã  lâ€™image en log corrompue ? par rapport Ã  lâ€™image en log idÃ©ale ? Comment expliquez-vous ce rÃ©sultat ?fn = Path(root/&quot;I.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))# Question 2S = (...)Iscatter = I+SIscatter = (...) # add noise to IscatterInoScatter = (...) # add noise to If,ax = plt.subplots(1,3,figsize=(18,6))ax[0].imshow(I)ax[0].set_axis_off()ax[0].set_title(&#39;$I$&#39;)ax[1].imshow(S)ax[1].set_axis_off()ax[1].set_title(&#39;$S$&#39;)ax[2].imshow(Iscatter)ax[2].set_axis_off()ax[2].set_title(&#39;$I_s=I+S$&#39;)plt.show()# Question 3def logCompress(img): return (...)# Vous pouvez sÃ©lectionner une sous-rÃ©gion anatomique ou `full` pour voir toute l&#39;imagebrain = slice(100,300),slice(300,500)cervicals = slice(350,600), slice(300,500)teeth = slice(400,600), slice(100,300)full = slice(None,None)# Choisissez la rÃ©gion que vous voulez dans `anat`anat = brain# Questions 3 et 4pTrue = logCompress(InoScatter)pScatter = logCompress(Iscatter)pScatterCorrected = logCompress((...))vmin,vmax = pTrue.min(), pTrue.max()f,ax = plt.subplots(1,3,figsize=(18,6))ax[0].imshow(pTrue[anat],vmin=vmin,vmax=vmax)ax[0].set_axis_off()ax[0].set_title(&#39;True image&#39;)ax[1].imshow(pScatter[anat],vmin=vmin,vmax=vmax)ax[1].set_axis_off()ax[1].set_title(&#39;Scatter-corrupted&#39;)ax[2].imshow(pScatterCorrected[anat],vmin=vmin,vmax=vmax)ax[2].set_axis_off()ax[2].set_title(&#39;Scatter-corrected&#39;)plt.show()Partie 4 : Ce quâ€™il faut retenir Le rayonnement diffusÃ© est une image basse frÃ©quence qui se superpose au rayonnement primaire Le diffusÃ© conduit Ã  une diminution du contraste global de lâ€™image La correction numÃ©rique du diffusÃ© (aprÃ¨s acquisition) permet de restaurer le contraste de lâ€™image, mais conduit aussi Ã  une image plus bruitÃ©e Afin de prÃ©senter une image plus acceptable Ã  lâ€™utilisateur final, il faut prendre en compte ce phÃ©nomÃ¨ne, soit en amont (rÃ©jection du diffusÃ© avant quâ€™il atteigne le dÃ©tecteur) ou en aval (correction de diffusÃ© et dÃ©bruitage)" }, { "title": "TVID: La video numerique en pratique", "url": "/cours/posts/tvid_video_numerique_pratique/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-10 14:00:00 +0100", "snippet": "Lien de la note HackmdFilm et entrelacement Film = 24P, NTSC = 60I Comment passer un film a la tele ? 2:3 pulldown 4 frames, 10 fields A: TFF + RFF B: BFF C: BFF + RFF D: TFF Voila comment on envoie des films a la tele Americaine (tele-cine) Et oui, on repete des films !Desentrelacement Reconstruire les lignes manquantes Plusieurs approches Toutes inexactes Complexite variable En pratique: efficacite / cout Ce nâ€™est pas quâ€™on ne sait pas faire, câ€™est quâ€™on fait pour un budgetDesentrelacer, comment ca marche, combien ca coute ?Methode Ne rien faire Câ€™est indadmissible Weave Lire une frame (a) $$=1:1$ (a) Skip field Lire $2\\times$ le meme field (a) Si field bottom $\\to$ aligner frame (b) AlignementImage entrelacee 4:2:0 MPEG-2On doit upscaler verticalement pour skip fieldUpscaling Definition Agrandir une image source a faible resolution On cree des pixelsUpscaling NN: Nearest Neighbour / Plus proche voisin Repeter le pixel voisin Utiliser dans la Super Nintendo ou la Neo GeoAvantages: Rapide GratuitProbleme: $\\color{red}{\\text{Moche}}$Upscaling BF (Bilinear Filtering) Interpolation lineaire 2D Trois interpolations 1D entre $P_{00}$ et $P_{10}$: $Q_0$ TODOAvantages: Acceptable Pas cherProbleme: Pas pour les gros ratios (SD $\\Rightarrow$ 4K)Upscaling B-Spline Plusieurs polynome Points de passage pour les pixels en 2D B-Spline: Contrainte de continuite entres les polynomesTres souvent: B-Splines cubiquesCâ€™est flou, mais câ€™est acceptable SD $\\to$ 4K: OKProblemes: Cher Risque (ringing)Le resultat est tres inegal. Il nâ€™y a aucune strategie parfaiteLe coup de skip field câ€™est $ $= 1:1(a) + \\text{filtrage}(b) + \\text{upscale}(c)$ Bobbing: Lire chaque field 1/1 (a) Si field bottom $\\to$ aligner frame (b) Upscaler verticalement $\\times 2$ ( c ) Cout $=1:1(a) + \\text{filtrage}(b) + \\text{upscale}(c)$ Blending (Microsoft) Lire une paire de fields (a) Aligner fields bottom (b) Upscaler verticalement $\\times 2$ ( c ) Cout $=2:1(a) + 2\\times \\text{filtrage}(b) + 2\\times\\text{upscale}(c) + \\text{mixage}(d)$ $\\color{red}{\\text{Adaptative (Spatial, MoComp)}}$ Desentrelaceur intelligent Adaptatif spatial pur Plusieur fields: B0, T1, B1 Decoupes en zones de pixels: $Z_i$ Pour chaque $Z_i$ â€œdifferenceâ€ entre $B1$ et $B0$ (parite) $E_i\\sim = Z_i(B1) - Z_i(B0)$ $E_i\\gt$ seuil: $Z_i$ â€œen mouvementâ€ Pixels $Z_i(T1)$ bobbes Sinon $Z_i$ â€œstatiqueâ€ Pixels $Z_i(T1)$ weaves avec $Z_i(B0)$ Avantages Si mouvement: $Z_i(T1)$ desentrelacee Sinon $Z_i(T1)$ pleine resolution Rendu acceptable Inconvenients Certains mouvements indetectables (translation, recouvrements) $ $=3:1+\\text{differenciateur} + \\text{bob} + \\text{multiplexeur}$Amelioration 4 fields $E_i = \\max(Z_i(B1) - Z_i(B0))$, $Z_i(T1) - Z_i(T0)$ Meilleure detection de â€œmouvementâ€ $ $=4:1+2\\times\\text{differenciateur} + \\text{bob} +\\text{multiplexeur}$Adaptatif temporel: Spatial + estimateurs de mouvements convolutifs FIR / Turbo Cuisine secrete brevetee (Faroudja) Plus beau BEAUCOUP PLUS CHERExemplesCadence image US: 1953: NTSC en couleur Interference image/son a 60 ips Solution: changer la frequence image $\\times 1000/1001$ 60 ips $\\Rightarrow$ 59,94 ips 30 ips $\\Rightarrow$ 29,97 ips 24 ips $\\Rightarrow$ 23,978 ips Transparent, economique penible â€œModes TVâ€, â€œModes PCâ€Image animee: quelle frequence choisir ? Cinema Muer: 16 ips Parlant: 24 ips TV Synchro cameras et TVs â€œHorloge communeâ€ ? Frequence secteur ! US, JP: 60 ips EMEA: 50 ips Cadence USUS: $60$ ips $60 \\Rightarrow 30$: sauter 1 image sur 2 $30 \\Rightarrow 60$: repeter 1 image sur 2 $24 \\Rightarrow 30$: repeter 1 image sur 5 $59,97 \\Rightarrow 60$: repeter 1 image sur 1000 $60 \\Rightarrow 59,97$: sauter 1 image sur 1000 $29,97 \\Rightarrow 60$: repeter 1 image sur 2 et 1 fois sur 1000Cadence EUEU: $50$ ips $60 \\Rightarrow 50$: sauter 1 image sur 6 $50 \\Rightarrow 60$: repeter 1 image sur 5 $24\\Rightarrow25$: repeter 1 image sur 24 ? NON! accelerer $25/24$: $+4\\%$ $2m20s/h$ $+1$ demi-ton Mega drive: toute la logique etait conditionnee par lâ€™horloge videoCertains jeux etaient ralentis en Europe pour le passage $60Hz\\to50 Hz$Perte de $20\\%$ de vitesse ! $30 \\Rightarrow 50$: rapport 5/3. Repeter $2\\times$ fois la 3e image ? $1$ $2$ $3$ $\\color{orange}{3}$ $\\color{red}{3}$ Pourquoi on veut pas faire ca ? Parce que câ€™est saccade On fait: $1$ $\\color{orange}{1}$ $2$ $\\color{orange}{2}$ $3$ Plus homogene $\\Rightarrow$ resultat plus fluide Cadences en pratiqueTout est entier: PTS: temps image source STC: temps horloge affichageResolution dâ€™increment: TIR TIR(PTS) = duree dâ€™une seconde dans le flux video TIR(STC) = duree dâ€™une seconde a lâ€™affichageSi TIR(PTS) non $\\%$ TIR(STC) probleme de $\\color{red}{\\text{fraction continue !}}$ExempleTIR PTS = 90000 = 1 secnode La FC fait apparaitre de la gigue, aka JITTER" }, { "title": "TNSI: Traitement numerique du signal", "url": "/cours/posts/tnsi_traitement_num_signal/", "categories": "Image S9, TNSI", "tags": "Image, S9, TNSI", "date": "2021-11-10 09:00:00 +0100", "snippet": "Lien de la note HackmdPresentationParcours: Ingenieur topographe - INSA These en traitement du signal et de lâ€™image - TelecomIngenieur Chercheur a EDF R&amp;amp;D (Saclay) Groupe realite virtuelle et visualisation scientifique (avec Arnaud MAS) Numerisation et apprentissage statistique (image et 3D)Groupe Realite Virtuelle Visualisation Scientifique Aider lâ€™exploitant des sites de production nucleaire a decider lors des phases de preparation et de realisation des arretes de tranche AiderOCR pour les plans techniquesLa reconnaissance de forme dans les imagesSegmentation semantique: deux reseau Segmentation pixelique Segmentation semantique pour classifier les pixels de lâ€™imageLa reconnaissance de forme dans les nuages de points Donnees DP2D FES2Local R250280 millions de pointsActuellement: manuel Segmentation en petit nuage de points + ajustement de formeTraitement numerique du signal Definition Representation de la variation dâ€™un phenomene physique ExemplesEvolution de la temperature ou de la pression dans le temps Definition Transcrire numeriquement (i.e. des donnees) un signal continu (monde reel)On veut passer du monde continu au monde discretComment on fait le passage du continu au discret ? On va faire un echantillonage en temps et en amplitudeQuelle est la precision de cette discretisation ? On utilise le theoreme de ShannonEn resume: on prend notre signal, on compare dans chaque base de fonction a quel point notre signal ressemble et on va pouvoir voir a quel point notre signal est haute frequence et basse frequence. Avec les transformee de Fourier, on veut passer en temporel sans perdre dâ€™informationTheoreme dâ€™interpolation Decoule du theoreme de ShannonOn utilise un sinus cardinalLe theoreme de Shannon nous dit quâ€™on a un signal continu:\\[x(t) = \\sum_{n=-\\infty}^{+\\infty}x[n]\\underbrace{\\frac{\\sin\\biggr(\\frac{\\pi(\\overbrace{t-\\color{red}{nT_e}}^{\\text{translation}})}{\\underbrace{\\color{red}{T_e}}_{\\text{echelle}}}\\biggr)}{\\frac{\\pi(t-nT_e)}{T_e}}}_{\\color{red}{sinc}}\\]Exercice\\[x(t) = \\sin(10t) + 2\\sin(2t) + \\sin(5t) - 3\\sin(\\frac{t}{2})\\\\t = [-2, 2]\\to 400\\] Normaliser et centrer $T_e=0.1$ Interpoler avec $sinc$On reprendre notre figureOn prend des echantillons a intervalles regulireOn va sommer les sinus cardinaux:Ca va nous permettre de reconstruire notre signal:Quel est lâ€™interet du sinus cardinal ? On peut utiliser nâ€™importe quelle interpolation, mais le sinus cardinal est le meilleurQuantification Quantification scalaire: arrondir a lâ€™entier le plus proche $x$: amplitude des valeurs $q(x)$: valeur de quantificationTraitementComment on debruite un signal ? Convolution avec une fonction gaussienne ?Convolution avec une porte ?Non local means ? (câ€™est un flou gaussien ou un flou uniforme)On a un signal avec un flou gaussien: On fait une convolution avec une porteEn resume Comment echantilloner et reconstruire un signal Comment analyser un signal Comment filtrer une partie de lâ€™information dâ€™un signalTransformee de Fourier Rappel rapide Analyser harmonique Decomposition en serie de Fourier Discrete Time Fourier Transform (DTFT) Tf a temps discret Discrete Fourier Transform (DFT) TF discrete Continuous Fourier Transform (CFT) Fast Fourier Transform (FFT) Produit scalaireComment est-ce quâ€™on calcule un produit scalaire ?\\[\\langle x, y\\rangle = \\sum_{n=-\\infty}^{+\\infty}x[n]y[n]^*\\\\\\langle x, y\\rangle = \\int_{-\\infty}^{+\\infty}x(t)y^*(t)dt\\] Avec Fourier, on est en complexes\\[\\Vert x\\Vert^2 = \\langle x,x\\rangle = \\sum_{n=-\\infty}^{+\\infty}\\vert x[n]\\vert\\]Decomposition/reconstructionSoit \\(\\{f_n\\}_{n\\in\\mathbb N}\\to\\) base orthogonale.\\[\\langle f_n,f_p\\rangle = 0\\quad n\\neq p\\]$\\exists$ une suite $\\lambda[n]$ telle que $\\lim_{N\\to+\\infty}\\Vert x-\\sum\\lambda[n]f_n\\Vert = 0$\\[x=\\sum_{n=0}^{+\\infty}\\lambda_n f_n\\quad\\text{avec }\\lambda_n = \\frac{\\langle x,f_n\\rangle}{\\Vert f_n\\Vert^2}\\]Exercice\\[x = \\sin(2\\pi t) + 2\\sin(3\\times 2\\pi t) - 3\\sin(5\\times 2\\pi t) + \\sin(7\\times 2\\pi t)\\\\t = [0,1]\\] Tracer $x$ avec 1000 echantillons Decomposition de $x$ avec \\(\\{\\sin(n\\cdot 2\\pi t)\\}_{n\\in N}\\to\\) $N = [0,â€¦,5]$ ou $N = [0,â€¦,20]$ Verifier lâ€™orthogonalite Tracer les coefficients Reconstruction Si on ajoute une phase au sinus ? Idem " }, { "title": "DLIM: Reseaux neuronaux convolutifs", "url": "/cours/posts/dlim_res_neurones_convolutif/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-08 14:00:00 +0100", "snippet": "Lien de la note HackmdUn reseau de neurones convolutifLe but est dâ€™extraire les caracteristiquesLes formules de convolutionContinue 1D:\\[(f * g)(x) = \\int_{-\\infty}^{+\\infty}f(x-t)g(t)dt = \\int_{-\\infty}^{+\\infty} f(t)g(x-t)dt\\]Discrete 2D:\\[(f*\\omega)(x,y) = \\sum_{dx=-a}^a\\sum_{dy=-b}^b\\omega(a + dx, b + dy)f(x + dx, y+dy)\\]$f$ est lâ€™aimeg, $\\omega$ le noyau, son support est $[-a,a]\\times[-b, b]$Exemple de noyaux $\\omega$ (WP Noyau_(traitement_dâ€™image)):Conv2Dx = kl.Conv2D(filters = 4, kernel_size=(5, 5))(x)Lâ€™image dâ€™entree a 3 canaux -&amp;gt; chaque filtre a $5\\times5\\times 3 + 1$ poidsLâ€™image de sortie a 4 canaux, elle pert 4 pixels dans chaque directionEn details + stride + padding = â€˜sameâ€™Conv2D(filters = 2, kernel_size = (3, 3), stride = (2, 2), padding = &#39;same&#39;) Stride: une facon de reduire la taille dâ€™une image padding = â€˜sameâ€™: la sortie a la meme tailleConvolution a trousEn anglais: atrous convolutionConv2D(32, kernel_size=3, dilatation_rate=(2, 2)) Couvre la meme surface quâ€™un noyau $5\\times 5$, ou que $2$ convolutions $3\\times 3$ a la suite, mais pour un cout moins cher (en poids)Ne reduit pas la taille de lâ€™image (padding = same)Convolution separee spatiale: une conv $2D\\to1$ conv. $1D$ profondeur: $N$ conv $2D$ sur $M$ couches $\\to$ $M$ conv $2D$ puis $N$ conv $1D$Convolution separeee spatialeEn pratique on fait:Conv separee en profondeurkl.SeparableConv2DIci 3 couches: $3$ conv $2D$ + $4$ conv $1D$ $4$ couches en sortieGain de calcul importantperte de representation $\\to$ utiliseMobileNetLa convolution transposee (ou deconvolution) Convolution: concentre en un pixel un bloc de pixel (fois un noyau) Conv transposee: distribue un pixel (fois un noyau) a un bloc de pixelMathematiquement les deux sont des convolutions mais la conv. transposee a pour but de simuler lâ€™operation inverse de la conv\\[\\begin{aligned}\\text{propagation conv transposee} &amp;amp;\\leftrightarrow \\text{retro-propagation conv}\\\\\\text{retro-propagation conv. transposee} &amp;amp;\\leftrightarrow\\text{propagation conv.}\\end{aligned}\\]Trucs dâ€™architecture Pooling kl.MaxPooling2d(pool_size = (2, 2)) Si on veut augmenter le nombre de couches il faut diminuer la taille de lâ€™image sinon BOOM On veut une vision multi-echelle il faut diminuer la taille de lâ€™image + ponts. Lâ€™inverse du pooling est kl Ponts La grande astuce de ResNet qui leur a permis de tout gagner vert $\\to$ rouge $\\leftarrow$ Prog. et retro-prog. Lors de la retropropagation lâ€™erreur prend le pont et les convolutions $\\to$ les premieres couches sont corrigees Dropout ou BatchNormalization Pas besoin de dropout si BatchNormalization Evite que les poids importants en bloquent dâ€™autres Apres convolutionAvant fonction dâ€™activationReduit le besoin de normaliser les donneesTypes de problemes en visionSemantic segmentation Classification Classification + localisation Object detection Instance segmentation Celle quâ€™on va faire U-net (2015)Separation semantique dâ€™images medicalesMulti-echelleNotre projet aujourdâ€™hui !Copy &amp;amp; crops: ce sont des PONTS Ca sert a faire des concatenationsFonctions dâ€™erreur pour la segmentationSi chaque image de sortie represente les pixels appartenant a la classe $k$, alors on peut finir avec un softmax: $y+k = e^{z_k}/\\sum_{i}e^{z_i}$ Erreur quadratique mse: pente douce, pas dâ€™information dâ€™exclusion Entropie croisee: $E=-\\sum_kt\\log y_k+(1-t_k)\\log(1-y_k)$ binary_crossentropy avec $t_k=0$ ou $1$ categorical_crossentropy avec resultats sous la forme $[0,0,..,1,..,0]$ pour indiquer la classe $k$ sparse_categorical_crossentropy avec les classes indiques par des entier y_true = [[1, 2], [0, 2]] #image 2x2 with 3 categoriesy_pred = [[0.05, 0.95, 0], [0.1, .01, 0.8], #proba for each category [0.7, 0.2, 0.1], [0.2, 0.2, 0.6]] #for each pixelloss = keras.losses.SparseCategoricalCrossentropy()loss(y_true, y_pred).numpy() Focal loss\\[E_{FL} = -\\sum_k t_k(1-y_k)^{\\gamma}+(1-t_k)(1-y_k)^{\\gamma}\\log(1-y_k)\\] Comme la pente du log est forte, elle favorise les cas simples a detecter. On peut ecraser la courbe de $(1-\\gamma_k)$ pour aider Ã  trouver les cas difficiles. Augmenter le nombre de donneesSouvent câ€™est bien utile, en particulier lorsquâ€™on manque de donnees.Parfois ca rend la tache plus difficile et ca ne marche pas.ImageDataGenerator" }, { "title": "TVID: Du pixel a l&#39;ecran", "url": "/cours/posts/tvid_pixel_a_image/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-08 10:00:00 +0100", "snippet": "Lien de la note HackmdOn va decouvrir les principes fondamentaux lâ€™audio et la video numerique. 20h dont 6 de TP TPs de 3h On va faire notre propre decodeur et afficheur videoPlusieurs parties: Fondamentaux de ce quâ€™est un pixel Quâ€™est-ce que signifie les resolutions (pourquoi pas des multiples de 10 ? Pourquoi 1080i ? Pourquoi 16/9e ?) Structure dâ€™une image video Cadences Comment on fait pour afficher nâ€™importe quel film a nâ€™importe quelle taille vers nâ€™importe quelle television ? Comment on fait de lâ€™adaptation de cadence ? Entrelacement Ca nous pourri la tete depuis 70 ans Affichage Comment trouver un mode commun dâ€™affichage ? Ce sont les prerequis pour la suiteLa suite: standards de compression videoPixel Câ€™est un element dâ€™une imageMais encore ? Câ€™est un format Profondeur Combien de bits par composants ? espace de couleurPixel aspect ratioMonde PC: PAR = 1:1 Pixels carresMonde video: PAR &amp;gt;= 1 Pixel rectangulairesPourquoi ? On tient ca de lâ€™analogique: pas de resolution Analogique: pas de resolution Numerique: resolutions partout Besoin de correspondance numerique $\\leftrightarrow$ analogique On arrive sur le display aspect ration: la resolution de sortie\\[\\color{red}{\\text{PAR}\\times\\text{DIM} = \\text{DAR}}\\]Est-ce quâ€™on a deja essaye de jouer un fichier VOG dâ€™un DVD tout seul ? Lâ€™image sera plus carree et deformee car on ne lit pas les metadataColor SpaceGenerateurs de graphismes RGB Ordis, smartphones, tablettes On Screen Display (OSDs) On Screen Technique: superposition dâ€™affichage comme lâ€™affichage du numero de la chaine quand on zappe Pourquoi on affiche le nom de la chaine quand on zappe en numerique ? En analogique, quand on zappait câ€™etait instantane car il suffisait de changer que quelques parametres pour changer de frequence sans pre-processingCâ€™est juste pour faire attendre les gens, sinon on nâ€™a quâ€™un ecran noirPourquoi certaines box ont une mosaique avec plusieurs flux videos de differentes chaines ? Car ce nâ€™est pas fait par la box, ce sont des chaines mosaiques pre-composees par lâ€™emetteurOn utilise les metadatas pour choisir une chaine sur les mosaiquesCertaines mosaiques ne permettent pas de selectionner de chaine ARGB, ABGR A est le canal $\\alpha$ (alpha) ABGR est la representation dâ€™Android BGRA, RGBA, â€¦Video: YUV Images et sequences animees Y: luminance U, V: Chrominance (aka Cb, Cr) Raisons historiquesEst-ce que les premiers signaux analogiques pour la tele etaient en couleur ? Bien sur que nonVers les annees 50 on se dit que ca serait bien dâ€™avoir la couleurs On va faire un truc degueulasse pour que ce soit retrocompatible avec les gens ayant une tele en noir et blanc Lâ€™analogique est la reponse de ce quâ€™on fait en numerique.Les US avaient NTC qui on cree un standard video de 480 lignes en noir et blanc qui est passe en couleurs en une nuit (et ca a marche !) Lâ€™heritage de lâ€™analogiqe nous enquiquine encore aujourdâ€™huiExemple RGBQuâ€™est-ce quâ€™on remarque ? Le vert est predominant car il est predominant dans la natureLes humains ont un excellent pouvoir dâ€™observation sur le vert (60-70% de notre champ de vision)On voit moins bien le rouge car câ€™est le sang et le feu (20-30% de notre champ de vision)On voit encore moins bien le bleu car on ne veut pas etre aveugle par le ciel La compression numerique va user et abuser de nos limitations de perceptionExempe YUVQuâ€™est-ce quâ€™on remarque ? Dans le V il y a tres peu de rouge, noye dans du grisSi on etait un algorithme, lesquels de ces images on trouverait plus facile a digerer que les autres ? U et V ont une dynamique faible donc lâ€™encodeur entropique va se regaler On va grignoter tout ce qui est possible pour faire des economiesFormatsFormat lineaire: Toute lâ€™info est dans le pixel Profondeur: 8..16 bits/composantes HDR: 10 bits 8 bpc: â€œTrue Colorâ€ Representation des pixels : ARGB, ARGB, ARGBâ€¦ Exemple: #FF00FF00 Câ€™est du vert alpha opaque et vert a fond Exotiques: high colorsConsiderations systeme: True colorsCombien ca coute ?Que faut-il dans un systeme ? Horloge Systeme CPU RAM Efficacite Bande passante (BW) BUS DMA Direct Memory Access Faire des transferts de donnees enorme sans utiliser un iota du processeur Taille: combien de bytes au max il est capable de copier BW: bande passante (nb bits/s capable de transferer) Modules hardware Carte video (GPU), carte son, etc Autres modules dâ€™affichage CCC Full Hd True Color ? Image fixe RGB $8bcp$ @ $1080p60$ BW afficage: $1920 \\times 1080 \\times 60 \\times 24 = 2,98 Gb/s$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ dâ€™efficacite $\\Rightarrow$ BW RAM $= 200M \\times 32 = 6,4 Gb/s$ ~$3,88\\%$ BW ram ~$46\\%$ BW bus Juste pour afficher ! $\\times 2$: NOK. Pas dâ€™animation possible DMA: $64$ bits / clock (DMA++) $\\Rightarrow$ BW bus $=200M\\times 64 = 12,8 Gb/s$ $\\Rightarrow$~$3,88\\%$ BW RAM $\\Rightarrow$~$23\\%$ BW bus $\\Rightarrow$ Image animee jouable $\\Rightarrow$ Couteux CCC 4K ? Image fixe RGBTODOPixels: formatsFormat paletisse: Palette de couleur predeifinie Pixel = index couleur palette Profondeurs: 1, 2, 4, 8 bits / pixel Tous les OSDs sont paletisesCCC Full HD palettise ? Image paletisee 256 couleursTODOStructure dâ€™une image videoColorspace YUVSampling Mode Sampling Mode: sous-echantillonnage de la chrominanceQuâ€™est-ce que ca veut dire ? On va peut-etre enlever du U ou du V sur certains pixels car nos yeux ne peuvent pas le voir de toute faconLe fameux grignottage Seulement en color space YUV Oeil moins sensible a UVExemple:Sur la 2e image, on a commence a diviser lâ€™echantillonnageQuâ€™est-ce quâ€™on observe ? Il y a des bandes qui apparaissent a chaque bordures de couleursElles se degeulent les unes sur les autresSi on met une video youtube avec du rouge petant on aura le meme effet Ca arrive surtout sur les cas extremes avec des transitions abruptesOn suppose 8 pixels:Ils ont chacun leurs composantes $4:4:4$ Pour 4 pixels consecutifs (pas forcement en ligne mais aussi en carre) il y a 4 $U$ et 4 $V$ $4:2:2$ Pour 4 pixels consecutifs, on nâ€™en a que 2 qui contiennent de la chrominance On a litteralement decime une colonne de chroma sur 2 Ce sont toutes les images JPEG $4:2:0$ MPEG-1 On a 6 composantes sur 8 bits au lieu de 12 Le calculateur fait la moyenne On a beaucoup economise juste en coupant la chroma une ligne sur 2 et un colonne sur 2 $4:2:0$ MPEG-2 $4:1:1$ Utilise par les Etats-UnisPendant notre enfance on avait les camescopes DV, en Europe ils sont en $4:2:2$ et aux US du $4:1:1$ Tous les CODECs aujourdâ€™hui sont bases sur la perception visuelleImage planaire Heritage TV: Y avant UV PC: Images interleavees (ARGB, ARGB, â€¦) Video: Images planaires: Buffers composantes separes Luma: Y, Y, Y Chroma: UV, UV, UV Decouplage hardware / composantes Une image planaire, combien ca coute ?CCC Full HD Planar $4:2:2$ ?$1080p60$ YUV $4:2:2$ $8$ bits Luma: $1920\\times 1080\\times 60\\times 8=\\sim1 Gb/s$ Chroma: $1920\\times 1080\\times 60\\times 16 / 2=\\sim1 Gb/s$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ dâ€™efficacite $\\Rightarrow$ BW RAM $=200M\\times 64\\times 8\\times 0.8 = 81,92 Gb/s$ Deux DMA 2 fois plus petits: $16$ bits / clock $BW = 200 M \\times 16 = 3,2 Gb/s/canal$ $2,5\\%$ BW ram $31\\%$ BW par canal On pas en YUV car câ€™est le seul format qui nous permet de decimer le chroma sans tout casserCCC Full HD Planar $4:2:0$ ?$1080p60$ YUV $4:2:0$ $8$ bits $\\gt90\\%$ des fichiers video (TNT, SAT, YT, Netflix, â€¦) Luma: $1920\\times 1080\\times 60\\times 8=\\sim1 Gb/s$ Chroma $1920\\times1080\\times60\\times16\\times\\color{green}{4 = \\sim 0,5Gb/s}$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ dâ€™efficacite $\\Rightarrow$ BW RAM $=200M\\times 64\\times 8\\times 0.8 = 81,92 Gb/s$ Deux DMA 2 fois plus petits: $16$ bits / clock $BW = 200 M \\times 16 = 3,2 Gb/s/canal$ $2,5\\%$ BW ram $\\sim 31\\%$ BW Y, $15\\%$ BW UV CCC 4K Planar $4:2:0$ 10 bits ?$2160p60$ YUV $4:2:0$ 10 bits: Netflix Deux DMA 64 bits / clock Hardware a 2 px / clock BW = 200M x 64 = 12,8 Gb/s/canal 9% BW ram TODOEntrelacement / Desentrelacement70 ans et toutes ses dentsUn peu dâ€™histoire: les signaux videos ne sont pas tous faits de la meme maniere et ne sont pas fait comme on le pense.Mais nous nâ€™avons pas parle de la structure dâ€™une image.Il y a un peu moins dâ€™un siecle, des ingenieurs se sont dit â€œOn va transmettre de lâ€™image analogique sur des tubes cathodiquesâ€.Le principe dâ€™un ecran cathodique est toujours le meme: on a une surface remplit de photophores qui emet de la lumiere quand elle se prend des electrons, elle met du temps a sâ€™allumer et du temps a sâ€™eteindre.On sâ€™est dit quâ€™on allait utiliser ces ecrans pour afficher des images.Pourquoi ecran cathodique ?Car les electrons sont generes par une cathode, et si on etait un peu trop pres de lâ€™ecran on se prenait des rayons.On ecrit notre image ligne a ligne a lâ€™ecran et on obtient notre image.SAUF QUEOn a remarque de 480 lignes câ€™est bien pour le format dâ€™image. Mais si on envoie 480 lignes par image, 60 images par seconde, on a un signal beaucoup trop large.Des ingenieurs se sont dit â€œMais câ€™est pas un probleme, regardez le temps que prend mon ecran a sâ€™eteindreâ€ (câ€™est une gaussienne). Ces ingenieurs se sont dit â€œJe ne vais envoyer quâ€™une ligne sur 2 de chaque image et alterner entre lignes paires/impairesâ€. Câ€™est ca lâ€™entrelacement On a decime lâ€™image spatialement. On a quasiment la meme qualite dâ€™imageEst-ce quâ€™on a vu que les tubes cathodiques scintillent ? Câ€™est lie du a lâ€™entrelacement et alterner les imagesAujourdâ€™hui on nâ€™a que des ecrans plats avec des pixels avec une bonne reactivite (jusquâ€™a 140 Hz) Mais ca nous pose des ENORMES problemes avec lâ€™entrelacementSur nos ecrans actuels, chaque pixel a chacun sa vie.On a un probleme de taille dâ€™ecran, de pixels, de resolution, etc.Pourquoi garder lâ€™entrelacement ? Car il y a encore des pays qui utilisent des teles cathodiques Si câ€™est moins cher, on va le faire On paye cher apres car câ€™est a creditUn peu dâ€™histoire 1941: standard NTSC 6 MHz de bande passante Dot crawl: information couleur mal filtree 15730 ligne/s 525 ligne/image 15730 / 525 = 30 ips OK pour films (24 ips) NOK pour du direct Une idee simple 1 frame: 2 fields : pair/impair Captures a des instants differentsTFF = Top filter (flag)BFF = Bottom filter (flag)ExemplesUne image entrelacee câ€™est une image avec des dents Tous les flux de la TNT sont entrelaces et ne sont pas en HD On en en 1440i50 Le numerique, câ€™est pas que câ€™est mieux, câ€™est que câ€™est moins cherEntrelacementAvantages: Image fixe: resolution conservee Image mouvante: $2\\times$ plus fluide BW inchangee Parfait pour un tube cathodiqueInconvenients: Resolution horizontales / 2 si mouvement Signaliser lâ€™ordre des fields Scintillement Le futur devra faire avecâ€¦Exemple En bas a droite lâ€™objet bouge mais nâ€™est pas entrelace Ce flux video donne des maux de tete aux ingenieursLe OK ne bouge pas et ne doit pas etre entrelaceLe logo en bas a droite est le logo corporate Il y a plusieurs entrelaceursExemple: VLCOu est le K ? On a pris que les lignes du haut et on a degage les lignes du basCâ€™est desentrelace comme un pied par le GPUPlusieurs facons de desentrelace: Prendre que les lignes du dessus et upscale $\\times 2$ en vertical" }, { "title": "VPOA: Detection et localisation", "url": "/cours/posts/vpoa_detection_localisation/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-05 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionQuâ€™est-ce que la vision ? Percevoir le monde Compose dâ€™objets Structure en 3D Efficacement interprete par lâ€™Homme Receuil dâ€™information Ensemble de points Information sur la lumiere Quantite et contenu spectral Representation du monde reel Les objets nâ€™existent pas sur la retine Processus visuel dâ€™interpretation Vision humaine Extremement complexe Active de nombreuses zones du cerveau Possede des capacites nombreuses et varieesVision par ordinateur Bio inspiree ou non Production dâ€™un modele algorithmique fonctionnellement similaire aux capacites du cerveau humain Reprosudit seulement un sous-ensemble de capacitesQuelques termes Traitement dâ€™images: manipulation dont lâ€™entree et la sortie sont des images Aide lâ€™humain ou la machine a examiner des images Analyse dâ€™images: analyse ou lâ€™entree est une image mais la sortie est une informationTODOProcessus dâ€™integration dans un systemeObjectifs de la seance Trouver/extraire dans lâ€™image des informations pertinentes pour TODODetection Deep-learning On a entraine le modele a detecter des voitures mais ca ne reconnais que lâ€™avant des camionsDetection et trackingGeometrie projectiveCoordonnees homogenes Systeme de coordonnees pour la geometrie projectivePasser des coordonnees cartesiennes aux coordonnees homogenes:\\[\\begin{bmatrix}x\\\\y\\end{bmatrix} \\Rightarrow\\begin{bmatrix}x\\\\y\\\\1\\end{bmatrix}\\]Passer des coordonnees homogenes aux coordonnees cartesiennes:\\[\\begin{bmatrix}u\\\\v\\\\w\\end{bmatrix}=\\begin{bmatrix}u / w\\\\v / w\\\\1\\end{bmatrix} \\Rightarrow\\begin{bmatrix}u / w\\\\v /w\\end{bmatrix} =\\begin{bmatrix}x\\\\y\\end{bmatrix}\\]Propriete homogene: $\\bar x\\sim\\lambda \\bar x, \\forall \\lambda\\in\\mathbb R, \\lambda \\neq =0$Point a lâ€™infini:\\[\\bar x_{inf} = \\begin{bmatrix}x \\\\ y \\\\0 \\end{bmatrix}\\]Modele du plan projectif Le plan projectif $P^2$ represente lâ€™espace 3D sur un planIntrepretation geometrique de lâ€™homographieHomographiesEstimation dâ€™homographieEstimation par Direct Linear Transform Necessite au moins 4 points pour obtenir une solution exacte (2 equations par point et 8 inconnues) Etant donne $n\\ge 4$, correspondances de points 2D, determiner $H$ tel que $\\bar x_iâ€™=H\\bar x_i$Algorithme: Pour chaque correspondance $\\bar x_i\\leftrightarrow \\bar x_iâ€™$ pour claculer $A_i$ Assembler les matrices $A_i$ en une matrice $9\\times 9$: $A$ Calculer le SVD de $A$: $U\\Sigma V$ Solution pour $h$: derniere colonne de $V$ Determiner $H$ a partir de $h$Homographie et plan 3DLe passage de nâ€™importe quel plan vers nâ€™importe quel autre plan (y compris le plan image) est une homographieExtraction de caracteristiques localesRepresentation dâ€™une image$I(x, y)$: valeur dâ€™un pixel Dans $\\mathbb R$ en monochrome Dans $\\mathbb R^3$ en couleursVariations De luminosite globale: $I(x,y)\\to I(x,y)+\\alpha$ De contraste: $I(x,y)\\to\\lambda I(x,y)$ Par translationComparaison de pointsTrouver le point le plus similaireStereo-vision: on suppose que les points similaires sont sur la meme ligneComment trouver des points facilement identifiables ? GradientsContoursEtcKernel Aussi appele noyau ou masque ou matrice de convolution Permet dâ€™appliquer une operation a lâ€™image Convolution:Gradient Va nous permettre dâ€™obtenir une caracteristique de variabilite autour dâ€™un pointEn 1D:En 2D: Filtre de SobelLaplacienDetection de contoursDetection de coins Zones ou le gradient varie dans plusieurs directionsDetecteur de Harris:Changement dâ€™echelleComment reconnaitre un point apres un changement dâ€™echelle ? Avec des descripteurs !Descripteur Moyen de decrire une zone locale de lâ€™image Les â€œfeaturesâ€ sont associees a des points localement distincts dans lâ€™image Les descripteurs sont la signature de ces pointsDifferences de GaussiennesDetection de blobs par differences de Gaussiennes:On soustrait lâ€™image floutee a lâ€™image normaleInvariance par changement dâ€™echelle pour les differences de Gaussiennes:Descripteur SIFT Scale Invariant Feature TransformDetection de blobs par la methode des differences de gaussienneRotationComment reconnaitre un point apres une rotation ?Descripteur SIFTHistogramme dâ€™orientations du gradient Decoupage en $4\\times 4$ fenetres Histogramme sur 8 directionsResume: Identification/Matching des keypointsAutres descripteurs MSER (Maximally Stabel Extremal Regions) SURF (Speeded Up Robust Features) ORB (Oriented FAST and Rotated BRIEF) SIFT et SURF sont brevetes OpenCV a invente ORB comme alternative open-source et gratuite BRIEF FAST KAZE etcExtraction de caracteristiques localesComment valoriser lâ€™information ? Reconaissance/detection dâ€™objets Estimation de la pose/localisation De la projection dâ€™objets 3D sur le plan Image Dâ€™objets 3D dans le monde De la camera dans le monde Estimation du mouvementReconaissance dâ€™objetsObjectifs: Detection dâ€™instances dâ€™objets par points dâ€™interet Transformee de Hough RANSAC Detection de categories dâ€™objets Sac de mots visuels Transformee de HoughA lâ€™origine, detection de lignes droites: Chaque point votre pour â€œtoutesâ€ les lignes qui passent par lui Les votes sont accumules Un maximum local corresponds a des lignes candidatesPossible probleme: trouver le maximum vrai Mean shift Gaussian convolution â€¦Transformee de Hough generalisee Contour/forme arbitraire Choix dâ€™un point de reference our le contour (e.g. le centre) Pour chaque point du contour, se rappeler de sa position par rapport au point de reference Calcul de lâ€™angle RANSACCas de lignes Choix aleatoire de droites Vote base sur le nombre de points proches de la ligne todoAmelioration Elimination de outliers par RANSAC Amelioration de lâ€™estimation de RANSAC TODOComparaisonReconnaissance dâ€™objets 3DBase sur la detection de features 3 features minimum sont necessaires pour la reconnaissanceReconnaissance dâ€™objet 3D base sur la detection dâ€™un modele 3D connuMots visuelsPrincipe: extraction de features locales a partir dâ€™un certain nombre dâ€™images Cartographie des descripteurs vers de mots visuels qui quantifient lâ€™espace des features Le centre des clusters definissent les prototypes de mots Determination de quel mot doit etre assigne a chaque nouvelle region de lâ€™image en trouvant le centre du cluster le plus procheExempleChaque groupe de patch correspond a un meme mot visuel Resumer une image entiere a partir de sa distribution de presence de mots Analogue a un sac de mots souvent utilise pour les documents de texteCreation dâ€™un vocabulaire visuel: Repertorier un ensemble de mots visuels (~ dictionnaire) Differentes strategies Apprentissage supervise Deep learning etc Strategies dâ€™echantillonnage:Arbre de vocabulaire: Remplissage:Probleme: certains mots visuels sont discriminants Dâ€™autres apparaissent dans de nombreuses imagesCalcul dâ€™un poids pour chaque mot visuel Le poid correspond a la quantite dâ€™info esperee Normalisation des histogrammes en fonction de ce poidsEstimation du mouvementObjectifs Detection/ Estimation du mouvement dans la scene Du au mouvement de la cmaera Mouvement des objets Perception du mouvement apparent Champs des vecteurs de deplacement Flux optique Flux optiqueDifficultes de lâ€™estimation du flux optique Ambiguites Premiere image: deplacement de drone, champ de vecteurs = deplacement des pixels Si on aune voiture qui se rapproche de nous, on peut segementer la voiture du reste de lâ€™image a partir de champs de vecteursInterpretation du flux:Vitesse: La camera se deplace a une vitesse $(Xâ€™, Yâ€™, Zâ€™)$ par rapport a la scene Si on derive les equations de perspective on a donc:Interpretation du fluxTranslation pure selon $X$ (ou $Y$)Translation pure selon $Z$:Cas general: Donne la direction du deplacement Mouvement $(Xâ€™, Yâ€™, Zâ€™)$ Soit $[X_0, Y_0, Z_0]^T$ un point de la scene, apres un temps $t$, il est projete sur lâ€™image au point $[u_t, v_t]^t$ avec:Temps avant collision: Mesure de la taille dâ€™â€˜un element $\\lambda = f\\frac{\\Lambda}{z}$Bundle adjustment Nous avons pour lâ€™instant uniquement utilise des paires dâ€™image pour obtenir une information de profondeur Dans le cas general, il est possible dâ€™utiliser $N\\gt 2$ images/cameras Le Bundle (block) adjustment ou ajustement de faisceaux en bloc, est une methode de resolution au sens des moindres carres les coordonnees 3D des points et aligner les images Plusieurs images sont corrigees â€œen blocâ€Principe: Demarrer avec une approximation initiale Projeter les points 3D sur les plans images des cameras Comparaison avec la mesure Ajustement pour minimiser lâ€™erreur Le BA est une approche non-lineaire de resolution par moindres carres: $\\bar x_{ij} + \\hat e_{x_{ij}} = \\lambda_{ij}P_{ij}\\bar X_i$ Avec $\\hat e_{x_{ij}}$ lâ€™erreur de mesure du point $\\bar X_i$ $i lâ€™indice du point, $j$ lâ€™indice de la camera Elimination du facteur dâ€™echelle: $\\bar x_{ij} + \\hat e_{x_{ij}} = \\frac{P_{1:2{ij}}\\bar X_i}{P{3_{ij}}\\bar X_i}$ Resolution par SVDOdometrie Visuelle Estimation du mouvement de la camera par rapport au mondeNecessaire a de nombreuses applications Pas de GPS Genre sur Mars IMU et/ou odometrie des roues insuffisants On va mettre des encodeurs sur les roues et lire de combien sâ€™est deplace la roue Odometrie: Estimation du mouvement base sur le modele cinematique Extansion a la visionTriangulation Permet de connaitre la position 3D dâ€™un point Principe: Trouver des correspondances de points entre 2 images successives: utilisation de descripteurs Si le monde est statique et les points bien apparies alors on peut estimer la transformation $(R,t)$ a partir des parametres extrinseque Probleme de minimisation de lâ€™erreur de reprojection Necessite dâ€™une bonne calibration Peu robuste aux rotations pures On compense ave lâ€™IMU et lâ€™odometrie des roues Pseudo code:Capturer l&#39;image I_kCalculer les correspondannce entre I_k-1 et I_kCalcul de la matrice essentielle E et que p^TEp&#39; = 0Decomposition de E en R_k et t_k par SVDCalcul du modele 3D (coordonnees des points de correspondance)Redimensionnement de t_k pour prendre en compte l&#39;echelle Attention ! p^TEp&#39; = 0 &amp;lt;=&amp;gt; lambda p^TEp&#39;=0k = k + 1SLAM Simultaneous Localization and Mapping Si une carte est fournie, possibilite de se localiser dans cette carte uniquement Si une position est fournie, possibilite de creer une carte de lâ€™environnement Le SLAM est lâ€™estimation conjointe dâ€™une carte de lâ€™environnement et de la position de la camera dans cette carte Necessaire des quâ€™un robot doit explorer un environnement totalement ou partiellement inconnu Amelioration de lâ€™odometrie visuelle On sauvegarde les coordonnees des points 3D extraits et de leurs caracteristiques locales Creation dâ€™une carte de features 3D3 categories principales de methodes pour lâ€™estimation de lâ€™etat: Extended Kalman Filter Particle Filter Least Squares =&amp;gt; Graph-based SLAMGraph-based SLAM Utilisation dâ€™un graphe pour representer les variables et les relations entre ces variables Pose Graph: contient uniquement les positions Factor Graph: contient des facteurs reliant les differentes variablesPose Graph: Chaque noeud represente une pose Les liaisons entre ces noeuds contiennent leur relation spatiale Lâ€™optimisation essaye de trouver la position optimale dâ€™un noeud qui minimise lâ€™erreur introduite dans les liaisonsQuels sont les avantages ? Meilleure estimation des coordonnees 3D des points/features Fermeture de boucles (Loop-closure) Plus robuste face aux rotations pures" }, { "title": "VPOA: Analyse de l&#39;environnement 3D", "url": "/cours/posts/vpoa_analyse_3d/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-04 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionOn sait obtenir de lâ€™info en 3D sous la forme dâ€™un nuage de points (sous forme de nuage de points, carte de disparite).Comment valoriser cette donnee ? On peut se localiserDetection dâ€™objets Visualisation 3D Reconstruction de modele 3D Building Information Modeling Clustering 3D Dimensionnement 3D Detection dâ€™objets 3D Modele numerique de terrain Navigation autonome etcComment passer dâ€™un nuage de points a une donnee a valeur ajoutee ? Analyse 3D Segementation RecalageAnalyse de Surface et Reconstruction 3DSegmentation semantique But: segmenter en temps reel tous les points segmenter toutes les donnees accumulees Utile pour les vehicules autonomesReconstruction 2DExemple de problematique en 2D: Dans la realite, le probleme nâ€™est pas si simple Extraction de la surface Discretisation Octree (1 point par cellule) Calcul dâ€™un champ de vecteurs Calcul de la fonction indicatrice Extraction de lâ€™isosurfaceReconstruction 3D En 3D, ca donne: VoxelisationDifferentes methodes de voxelisationMaillageEnsemble de sommets connectesAnalyse de surfaceCalculs de normales par ACP: On cherche le meilleur plan approche dans le voisinage dâ€™un point $X_{i0}$ Les points du voisinage sont notes $X_i$ Equation dâ€™un plan $n^tX=d, \\Vert n\\Vert =1$ Distance signee dâ€™un point au plan: $d(X_i, P) = n^tX_i-d$Resolution Methode des moindres carres Resolution de lâ€™equation de minimisation pour le planFonction a minimiser: $f(n,d)=\\sum_{i=1}^m(n^tX_i-d)^2$On pose: Barycentre des points $G=\\frac{1}{}$ Matrice de covariance des pointsTODOLe meilleur plan approche est defini par: Normale $n_{min}$ Vecteur propre norme associe a la plus petite valeur propre de $M_{cov}$ NB: indetermine a un changement de sens pres Distance $d_{min}$ $d_{min}=n^tG$ La solution fait appel a lâ€™analyse des directions principales de la matrice de covariance: Analyse en Composantes Principales (ACP)Segmentation 3D Definition Subdiviser (partitionner) le nuage de points 3D en sous-ensembles connexes correspondants a des modeles simples Methodes de segmentationCroissance de surface Principe A partir de â€œsurfaces germesâ€ ou â€œgrainesâ€ (seed surfaces) dans le nuage de point Agregation progressive des points voisins appartenant a la meme surface Remarque: extension de lâ€™algorithme â€œcroissance de regionsâ€ pour les imagesPour chaque point, un calcul de la normale du plan dans un voisinage:Critere dâ€™agregation: Co-normalite: $\\alpha = \\arccos(n_1, n_2)\\le \\alpha_{seuil}$ Normales dans le meme sens Coplanarite: $d=\\max(\\vert r_{12}\\cdot n_1\\vert, \\vert r_{12}\\cdot n_2\\vert) \\le d_{seuil}$ Points sur le meme plan Clustering Definition Regroupement de donnees en paquets homogenes selon des caracteristiques commnunesDBSCAN Câ€™est lâ€™un des algorithme de clustering les plus repandusPrincipe: Choix dâ€™un point graine pour la region Identification des voisins du point Pour chaque point voisin Si la densite locale de points est suffisante, ajout a la region Sinon, labellisation en tant que bruit On continue jusquâ€™a ne plus pouvoir etendre la regionOn peut jouer sur 2 parametres: Le rayon de recherche des voisins La quantite minimale de voisin ou densiteRANSAC RANdom SAmple ConsensusMethode de vote sur des echantillons aleatoires de surfaces Echantillons calcules a partir du nombre minimal de points necessaires pour definir la surface(quorum) Vote: un TODOPrimitives geometriques et quorum de points: Droite: Quorum = 2 points non alignes Plan: Quorum = 3 points $x_i$ non alignes TODO Vote: Nombre de points compris dans un espace a une certaine distance $\\delta$ de la surface calculeeProbabilites: Hypotheses Plusieurs surfaces possibles, points non bruites $N$ points dans le nuage de points $n$ points appartiennet a la surface recherchee $q$ points pour definir la surface (quorum)TODO Nombre de tirages necessaires: Nombre de tirage aleatoires $T_{min}$ necessaires pour avoir une probabilite $p_t$ de trouver une surface dâ€™au moins $n_{min}$ points\\[T_{min} = \\frac{\\log(1-p_t)}{\\log(1-(\\frac{n_{min}}{N})^q)}\\] En supposant $n_{min}\\lt\\lt N:T_{min}\\simeq \\log(\\frac{1}{1-p_t})$ TODOHough 3DPrincipe: Methode de vote dans lâ€™espace dicreTODODetection de droitesTODOProblemeDeep learningRecalage 3DPoint Set Registration, Point Matching: Processus dâ€™alignement de jeux de points TODOIterative Closest Point ICP Determination de la transformation rigide $(R,t)$ entre les deux nuages de pointsPrincipe Appariement des points du nuage a recaler au point le plus proche dans lâ€™autre nuage (approche de â€œnearest neighborâ€) Calcul de la transformation $(R,t)$ qui minimise la distance entre ces pointsCalcul de la transformation $(R,t)$Resolution par la methode des moindres carres:On calcule:\\[f(R,t) = \\sum_{i=1}^n\\Vert p_i-(R\\cdot p_i&#39;+t)\\Vert^2\\\\f:\\begin{cases}SE^3&amp;amp;\\to \\mathbb R^+\\\\(R,t)&amp;amp;\\mapsto f(R,t)\\end{cases}\\]On cherche: $(R,t)$ tel que $(R, t)=\\text{arg}\\min_{R,t}f(R,t)$Solution par decompositionTODOResolution par Singular Value Decomposition (SVD) Entree: jeux de points $(P,Pâ€™)$ sortie: Matrice de rotation $R$, vecteur translation $t$ Algorithme Determiner les barycentres $p_m=\\frac{1}{n}\\sum_{i=1}^n$ et $p_mâ€™$ Calculer la matrice $H$ Decomposer $H$ en valeurs singulieres $\\exists(U, V, \\Sigma)$ TODO Calculer $R=VU^T$ et $t=p_m-p_mâ€™$ Pseudo code ICP:Recalage approximatif P&#39;-&amp;gt;PRepeter: - Association de donnees P&#39; -&amp;gt; P - Calcul de la transformation (R, t) - Application de la transformation au nuage de point P&#39; - Calcul de la distance entre les nuagesTant que: - Distance normalisee &amp;gt; seuil - Et nombre d&#39;iterations &amp;lt; maximum d&#39;iterationsTemps de calcul: Appariement en $O(n_1, n_2)$, le reste en $O(n_1 + n_2)$ Acceptable pour les petits nuages de points, trop lent pour de gros nuages de points Necessite de sous-enchatilloner Possibilite dâ€™acceleration avec ANN (Approximate Nearest Neighbor): $O(n_1\\log(n_2))$Approximate Nearest Neighbor (ANN) Principe Pre-calcul dâ€™un kd-tree pour partitionner lâ€™espace Recherche dichotomique avec distance seuil Variante ICP: Metrique point a plan (point to plane) Echantillonage: regulier, aleatoire, base sur les normales Rejection des outliers â€¦" }, { "title": "VPOA: Perception 3D", "url": "/cours/posts/vpoa_perception_3d/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-03 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionMagellium Observation de la terre Analyse et traitement de donnees satelittes Geo-information Imagerie et Applications Essayer dâ€™extraire de la donnee image Infrastructure logicielleLâ€™entreprise: 248 employes 2 sitesOffres et marcheImagerie &amp;amp; applicationsActivites Image &amp;amp; video Lidar &amp;amp; 3D RobotiqueOffre Transfert de technologies Conception, systeme de perception Dev logicielPositionnement Ce nâ€™est pas de la sous-traitanceTechnos cles Capteurs 2D &amp;amp; 3D Detection et reconnaissance dâ€™objets Localisation et navifation Technos informatiques avanceesSyntheseMetier et projetsResponsable technique Definition des architectures et algos Encadrement technique des equipes Echange clients et/ou partenairesThematiques Computer vision Robotique dâ€™exploration planetaire Robotique orbitaleAutres Labo vision Deep learningProjet H-20 Projets finances par la comission europeenne Autonomous Decision MakingAssemblage de structures en orbite comme des telescopesSuite de ADET0: en moisBeaucoup implique au CNESRobot Simple Fetch Rover (SFR)MMT2 pour ThalesComputer visionComment les eleves decrivent le computer vision ? â€œUn truc de GISTREâ€ DefinitionUn domaine inter-disciplinaire pour permettre a une machine dâ€™analyser, traiter et comprendre une representation de lâ€™environnement obtenue par un systeme dâ€™acquisition. Cette branhe de lâ€™intelligence artificielle implique le developpement dâ€™algorithmes permettant lâ€™automatisation de taches que le systeme visuel humain peut realiser. IntroductionQuâ€™est-ce que la perception ? Une representation de la realiteOn va estimer des choses proprietes geometriques proprietes semantiques Ce qui concerne le sens/la signification Que peut-on obtenir ? Reconstruction 3D Interpretation semantique Interpretation dâ€™imageDe lâ€™objet a lâ€™observationDe lâ€™observation a lâ€™objetCe quâ€™on veut faire en computer visionSystemes dâ€™acquisition 3DTomographie numeriqueRayons X Principe de lâ€™IRM Superposition de coupes 2D successivesTelemetrie par temps de volEnvoi dâ€™une impulsion pulsee Lumineuse classique: camera ToFLidar ToFComment on voit derriere lâ€™objet ? On ne peut pas voir derriere les objetsOn devine en utilisant des donnees autour et on interpoleTelemetrie par decalage de phaseEnvoi dâ€™une impulsion modulee Lumineuse classique: Camera SWIR a modulation de phase Lumineurse Laser: LIDAR Ultrasonore: SONAR Ondes Radio: RADARMesure du decalage de la phase Il faut utiliser des longueurs dâ€™ondes adaptees aux utilisations quâ€™on veut en faire Câ€™est comme ca quâ€™on se fait flasher sur lâ€™autorouteTriangulationPrincipe utilise par les geometres, le GPSâ€¦Triangulation activePointeur laser Un rayon laser est envoye vers lâ€™objet a mesurer La lumiere diffusee est observee par une camera On peut en deduire la profondeur du pointLaser ligne, profilometrie Une image saisie donne une ligne de points Un unique balayage suffit pour assurer la couverture de la surfaceLumiere structuree Projection dâ€™un motif connu Appariement pixels/motifCamerasAvantages: Pas de contact Peu onereux Robuste (~pas de piece mobile, pas dâ€™interferencesâ€¦) Facilite dâ€™acquisition de grandes quantites de donnees Couverture dense Grande variete de distances Possibilite dâ€™obtenir de lâ€™information 2D et 3D Pas besoin dâ€™eclairage specifique Technique passive Informatino geometrique mais aussi semantique, interpretation de lâ€™image Donnee directement interpretable par lâ€™HommeInconvenients: Besoin de lumiere Occlusions Perte dâ€™information Une image est une projection du monde 3D sur un plan 2D Difficulte de lâ€™appariement des pixels Precision relativement faibleMono-vision passive Utilisation dâ€™image 2D pour avoir un rendu 3DStereo-vision Vision dâ€™une meme scene depuis 2 endroits legerements decales lâ€™un par rapport a lâ€™autre Principe de la perception 3D chez lâ€™HommePrecision et etalonnage Les points 3D sont des mesures geometriques obtenues par des principes physique (lumiere, contact, etc.) et mecaniques Les erreurs systematiques de mesure peuvent etre ameliorees par calibrage/etalonnageModelisation de la cameraGeometrie optiquePostulats: La propagation de la lumiere est decrite par des rayons lumineux provenant dâ€™une source de lumiere Un rayon lumineur suis une ligne droite dans un milieu homogene A lâ€™intersection entre 2 milieux homogenes, la lumiere est reflehie ou refractee Le chemin parcouru par un rayon lumineux et reversible Lâ€™intersection de rayons lumineux est sans effetsModelisation de la camera Capteur uniquementComment eviter ca ? On met une lentille :) (Theotime) Pinhole/stenope Câ€™est le modele stenope Distance focaleOuverture Reduction de la taille de lâ€™ouverture Amelioration de la nettete Reduction de la luminosite Problematique du computer vision: choisir la bonne ouvertureLumiere Sans lumiere, pas dâ€™image (pas de bras pas de chocolats) Lâ€™illumination de la scene a une influence importante sur le processus dâ€™acquisition Controler lâ€™illumination est un concept clef GLobalement possible de controler lâ€™illuminatino dans lâ€™industrie Difficile a impossible en milieu exterieur Il faut si possible controle lâ€™illumination Sinon, agir sur les parametres physiques de la camera Vitesse dâ€™obturation Ouverture Petite vitesse dâ€™obturation et/ou grande vitesse de lâ€™objet $\\Rightarrow$ attention au flou de mouvement Logiciel dâ€™auto-exposition Cameras â€œglobal shutterâ€ plutot que â€œrolling shutterâ€Lentilles Utilisation dâ€™une lentille pour concentrer la lumiere sur le plan image Amelioration de la luminosite Amelioration de la nettete Distance focale La distance entre la lentille et le point ou tous les rayons lumineux convergentFocus Les objets sont correctement projetes sur le plan image uniquement lorsquâ€™ils sont a une certaine distance de la lentille/lorsque le capteur est a une certaine distance de la lentilleDistance de focusHyperfocale Definition Distance minimum a laquelle il est possible de faire la mise au point tout en gardant les objets situes a lâ€™infini avec une nettete acceptable Depend de la distance focale et de lâ€™ouverture Validite du modele stenopeOn peut assimilier une camera munie dâ€™une lentille a une camera stenope si: On considere uniquement le rayon lumineux central On suppose que la mise au point est faite On considere que la distance de focus de la camera avec lentille est equivalenete a la distance focale de la camera stenope On neglige ou corrige les distortions induites par la lentille On ajoute un systeme dâ€™ouverture pour limiter les erreursDistortions Probleme des lentilles Distortion radiale Distortion en moustache mais tres rare Distortion tangentielle La distortion est plus importante pour les rayons qui passent pres du bord de la lentille Astigmatisme La distance focale est differente selon lâ€™axe $X$ et lâ€™axe $Y$ car la lentille nâ€™est pas parfaitement circulaire AbberationsProbleme des lentilles Aberration chromatique Aberration comatique Sâ€™observe notemment sur les telescopes Malformation capteurProbleme du capteur Asymetrie des pixels ou â€œskewnessâ€ Souvent negligeable sur les cameras modernesBruitProbleme du capteur Bruit lie a lâ€™electronique Bruit lie a la discretisation des mesures (seulement 255 valeurs possibles)Geometrie optiqueSysteme dâ€™equationCentre optique Le capteur et la lentille ne sont pas parfaitement alignes $\\Rightarrow$ decalage entre le centre optique et le centre de lâ€™imageLe point/pixel de coordonnees $(0,0)$ dans lâ€™image correspond au coin superieur gauche On applique une tranlsation permettant de passer au centre optique $(0,0)$ de lâ€™imageParametres intrinseques Retenir: matrice intrinseque3D vers image 2D:\\[\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}\\sim K\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix}\\quad\\text{Equivalent a un facteur d&#39;echelle pres}\\]\\[\\exists\\lambda\\text{ tq }\\lambda\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix} = K\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix}\\] Les coordonnees du monde ne sont pas necesairement les memes que les coordonnees de la camera Il faut convertir du systeme de cooordonnees du monde vers le system de coorodnnnees de la camera\\[\\begin{bmatrix}X_c\\\\Y_c\\\\Z_c\\end{bmatrix}=R\\cdot\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix} + t\\] $R$ une matrice de rotation $3\\times 3$ $t$ un vecteur translationDu monde a lâ€™imageEstimation de la matrice camera $P$ une matrice $3\\times 4\\Rightarrow 12$ inconnues $P\\sim K\\cdot[R\\vert t]$ On peut decomposer en $P=[\\vert P_1\\vert P_2]$ $P_1=K\\cdot R$ matrice $3times 3$ $P_2=k\\cdot t$ vecteur $3\\times 1$ Resectioning: On estime $P$ a partir de parires $\\bar x$ et $\\bar X$ connues Estimation de la matrice intrinsequePlane-based calibration On realise lâ€™acquisition de multiple images dâ€™une surface plane (e.g. damier) Cela permet de fixer $Z=0$ pour tous les points du plan observeOn a donc:\\[\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}\\sim K\\begin{bmatrix}r_1&amp;amp;r_2&amp;amp;t\\end{bmatrix}\\begin{bmatrix}X\\\\Y\\\\1\\end{bmatrix}=H\\begin{bmatrix}X\\\\Y\\\\1\\end{bmatrix}\\] A lâ€™aide de ces equations et de la conaissance du plan observe, il est possible de determiner $K$ Parametres de distorsion Il est possible dâ€™estimer des aprametres caraterisant les distortions radiales et tangentielles Plusieurs modeles de distorsion existent, notamment le modele polynomial de Brown-ConradyModele completComment realiser une bonne calibration ? La cible doit etre parfaitement plane Les motifs de type cercles asymetrqiues donnent de meilleurs resultats La distance entre les points doit etre mesuree precisement Il faut correctement definir le nombre de lignes/colonnes de la cibleControler lâ€™environnement de calibration Pas de sources de lumiere directe Pas dâ€™autres cible/motifs similaires visible Pas de relets Controle de lâ€™exposition Il faut toujours calibrer sur siteProcedure de calibration Mettre la camera dans une position fixe Acquerir 9 images a la distance de travail la plus proche Recommecer pour la distance de travail moyenne Acquerir 8 images avec des inclinaisons differentes de la cible Acquerir 5 a 10 images supplementaires avec des angles â€œaleatoiresâ€ Essayer dâ€™avoir une distribution homogene des points dans le plan image StereovisionTriangulationGeometrie epipolaireLignes epipolairesMatrice essentielle $E$Matrice fondamentale $F$RectificationLe fait de rendre 2 images â€œparallelesâ€ Rend la triangulation facile Facilite lâ€™appariementAppariement de points Trouver les coordonnees en pixel dâ€™un point 3D dans le plan image des 2 cameras Les points images sont sur la meme ligne lorsque les images sont rectifieesPlans image paralelles DispariteDistance en pixels qui separe la projection dâ€™un meme point sur les images des 2 cameras Calcul de la profondeurImage de disparite/clarte de profondeurCalcul des coordonnees 3DMethodes de correlationComment faire pour trouver les points correspondants ?De facon naive, recherche identique mais on peut avoir des pixels qui ont la meme valeurs et avoir des faux positifs -&amp;gt; selection dâ€™une fenetre pick a window $W$ around $\\bar p = (\\bar u, \\bar v)$ build vector $w$ Slide the window $w$ along $v=\\bar V$ in image 2 and compute $wâ€™(u)$ for each $u$ Compute the dot product $w^Twâ€™(u)$ Câ€™est sensible aux differences dâ€™exposition On fait de la normalized crossed-correlation On peut faire varier la taille de la fenetrePetite fenetre: Plus de details Plus de bruit Problemes de la stero-visionOcclusionsProblemes de la stereo vision Regions homogenes et/ou peu texturees Patterns repetitifsInfluence de la baseline Petite baseline, petit $\\frac{B}{Z}$ Grande baseline, grand $\\frac{B}{Z}$Disparite entiere Le processus de stereo-correlation permet uniquement de calculer des valeurs entieres de disparite Il est necessaire de raliser une interpolation pour lisser les disparite Exemples ans interpolation sous-pixellique: Une fonction dâ€™interpolation sous-pixellique doit etre implementeeLa fonction de disparite est estimee en appliquant une fonction de la forme:\\[d_{subpix} = d_{int} + f(s_{left}, s_{med}, s_{right})\\]avec $s$ les scores de correlationOn peut simpifier la formulation de cette fonction:\\[d_{subpix}=\\begin{cases}d_{int} - 0.5 + f(\\frac{l_d}{r_d}) &amp;amp;\\text{if } l_d\\le r_d\\\\d_{int} + 0.5 + f(\\frac{r_d}{l_d}) &amp;amp;\\text{otherwise}\\end{cases}\\]Lâ€™utilisation dâ€™une fonction dâ€™interpolation sous-pixellique a pour effet dâ€™introduire de petites erreurs sous la forme dâ€™une sinusoideMeme si cet effet est difficilement visible sur la carte de disaprtie, il apparait clairement sur la reprojection 3D:Deep learningReseaux de neurones convolutifs:Etat de lâ€™art" }, { "title": "PRSTA: TD 5", "url": "/cours/posts/prsta_td5/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-29 14:30:00 +0200", "snippet": "Lien de la note HackmdFeuille 3 Exercice 4La variable aleatoire $X$ suit une loi de Pareto de parametre $\\alpha$.A lâ€™aide du theoreme de Wilks, ecrire la zone de rejet du test $H_0 : \\alpha = 2$ contre $H_1 : \\alpha \\gt 2$. Solution Nous nâ€™avons pas de valeur pour $H_1$, mais $\\alpha\\gt 2$. Nous allons donc le remplacer par lâ€™EMV. Pour la loi de Pareto de parametre $\\alpha\\gt 0$ dont la densite est donnee par\\[f(x,\\alpha) = \\alpha x^{-\\alpha-1}\\] pour $x\\gt 1$. Determinons lâ€™EMV. On a:\\[L(x,\\alpha) = \\alpha^{n}\\prod_{i=1}^nx_i^{-\\alpha-1}\\] dâ€™ou\\[\\log L(x,\\alpha) = n\\log \\alpha + \\sum_{i=1}^n(-\\alpha-1)\\log(x_i)\\] et\\[\\frac{\\partial\\log L}{\\partial\\alpha}(x,\\alpha) = \\frac{n}{\\alpha}-\\sum_{i=1}^n\\log(x_i)\\] Ainsi\\[\\frac{\\partial\\log L}{\\partial \\alpha}(x,\\alpha) =0\\] equivaut a\\[\\frac{n}{\\alpha}-\\sum_{i=1}^n\\log(x_i) = 0\\] Nous obtenons la solution $\\hat\\alpha = \\frac{n}{\\sum_{i=1}^n\\log (x_i)}$ Reste a verifier la condition du second ordre:\\[\\frac{\\partial^2\\log L}{\\partial\\alpha^2} = -\\frac{n}{\\alpha^2}\\lt 0\\] Par consequent, $\\hat\\alpha = \\frac{n}{\\sum_{i=1}^n\\log(x_i)}$ est bien lâ€™EMV \\[\\begin{aligned}T&amp;amp;= \\frac{L(X_1,\\dots,X_n,\\hat\\alpha)}{L(X_1,\\dots,X_n,2)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n(\\frac{n}{\\sum_{j=1}^n\\ln(X_j)})X_i^{-(\\frac{n}{\\Sigma \\ln(X_i)+1})}}{\\prod_{i=1}^n2X_i^{-3}}\\\\&amp;amp;= \\biggr(\\frac{n}{2\\Sigma\\ln(X_j)}\\biggr)^n\\prod_{i=1}^nX_i^{-\\frac{n}{\\Sigma\\ln(X_i)+2}}\\end{aligned}\\]\\[\\begin{aligned}R_n&amp;amp;= 2\\ln(T)\\\\&amp;amp;= 2n\\ln(\\frac{n}{2S})+\\sum_{i=1}^n(2-\\frac{n}{S})\\ln(X_i)\\end{aligned}\\\\\\color{red}{S:=\\sum_{j=1}^n\\ln(X_j)}\\\\\\begin{aligned}Rn &amp;amp;= 2n\\ln(\\frac{n}{2S})+(2-\\frac{n}{S})S\\\\&amp;amp;= \\boxed{2n\\ln(\\frac{n}{2S})+2S-n}\\end{aligned}\\] Asymptotiquement, $R_n$ suit asymptotiquement une loi de $\\chi^2$ a $n$ degre de liberte. La zone de rejet est:\\[\\{R_n\\gt\\chi^2_{\\color{red}{1-\\alpha}}\\}\\] ou $\\chi^2_{1-\\alpha}$ designe le quantile de niveau $1-\\alpha$Feuille 3 Exercice 6Considerons $n$ variables aleatoires independantes de densite:\\[f(x,\\theta) = \\theta^2xe^{-\\theta x}ğŸ™_{\\mathbb R_+}(x)\\]ou le parametre $\\theta$ est strictement positif.Nous disponsons de $n$ observations et voulons tester lâ€™hypothese $H_0:\\theta = \\theta_0$ contre lâ€™hypothese $H_1:\\theta = \\theta_1$ avec $\\theta_0\\lt \\theta_1$ Justifier que $f(x,\\theta)$ definit bien une densite pour tout $\\theta\\gt 0$ Calculer $E(X)$ Determiner la statistique de Neyman-Pearson que nous noterons $T_n$ En admettant que $\\theta T_n$ suit une loi $\\Gamma(2n,1)$, determiner une expression de $\\alpha$ et $\\beta$ en fonction du seuil du test Determiner les courbes COR associes a ce test. Solution On saute les 2 premieres questions car fait et refait 3.\\[\\begin{aligned}T &amp;amp;= \\frac{L(X_n,\\dots,X_n,\\theta_1)}{L(X_n,\\dots,X_n,\\theta_0)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n\\theta_1^2X_ie^{-\\theta_1X_i}}{\\prod_{i=1}^n\\theta_0^2X_ie^{-\\theta_0X_i}}\\\\&amp;amp;= \\biggr(\\frac{\\theta_1}{\\theta_0}\\biggr)^{2n}\\times e^{\\sum_{i=1}^n(\\theta_0-\\theta_1)X_i}\\end{aligned}\\] On passe au logarithme:\\[\\begin{aligned}\\ln T&amp;amp;= \\underbrace{2n\\log(\\frac{\\theta_1}{\\theta_0})}_{\\color{green}{a}}+\\underbrace{(\\theta_0-\\theta_1)}_{\\color{green}{b}}\\sum_{i=1}^nX_i\\end{aligned}\\] Lâ€™hypothese $H_0$ est rejetee lorsque:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln T&amp;amp;\\gt\\ln C_{\\alpha}\\\\a+b\\sum_{i=1}^nX_i&amp;amp;\\gt\\ln (C_{\\alpha})\\\\\\underbrace{\\sum_{i=1}^n X_i}_{\\color{red}{T_n}}&amp;amp;\\lt \\underbrace{\\frac{\\ln(C_{\\alpha})-a}{b}}_{\\color{red}{S_{\\alpha}}}\\end{aligned}\\\\\\color{green}{\\text{car } b = \\theta_0-\\theta_1\\lt 0}\\] Donc:\\[T_n\\lt S_{\\alpha}\\] 4.\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{Rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T_n\\lt S_{\\alpha}\\vert \\theta=\\theta_0)\\end{aligned}\\] Sous $H_0$, $\\theta_0 T_n$ suit une loi $\\Gamma(2n, 1)$\\[\\begin{aligned}\\alpha &amp;amp;= P(\\theta_0T_n\\lt\\theta_0 S_{\\alpha})\\\\&amp;amp;= F_n(\\theta_0S_{\\alpha})\\end{aligned}\\] Ou $F_n$ designe la fonction de repartition de la loi $\\Gamma(2n,1)$. Exprimons $S_{\\alpha}$ en fonction de $\\alpha$: \\[\\boxed{S_{\\alpha}=\\frac{F_n^{-1}(\\alpha)}{\\theta_0}}\\] \\[\\begin{aligned}\\beta&amp;amp;= P(\\text{Rejeter }H_1\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(T_n\\ge S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\theta_1T_n\\ge\\theta_1S_{\\alpha}\\vert\\theta=\\theta_1)\\end{aligned}\\] Or sous $H_1$: $\\theta T_n\\sim\\Gamma(2n,1)$ Donc: \\[\\boxed{\\begin{aligned}\\beta&amp;amp;=1-F_n(\\theta,S_{\\alpha})\\\\&amp;amp;=1-F_n(\\frac{\\theta}{\\theta_0}F_n^{-1}(\\alpha))\\end{aligned}}\\] En python: scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.05, 20, scale=1), 20, scale = 1) 0.9184... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.05, 50, scale=1), 50, scale = 1) 0.999702... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.01, 10, scale=1), 10, scale = 1) 0.316165... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.001, 100, scale=1), 100, scale = 1) 0.9999523... On nome $\\Pi$ la probabilite de detection:\\[\\Pi = 1-\\beta\\\\\\boxed{\\Pi = F_n(\\frac{\\theta_1}{\\theta_0}F_n^{-1}(\\alpha))}\\]Feuille 4 Exercice 4Considerons $n$ variables aleatoires independantes $X_i$ suivant la loi de densite:\\[f(x,\\theta) = \\frac{3}{\\theta} x^2e^{-\\frac{x^3}{\\theta}}ğŸ™_{\\mathbb R_+(x)}\\]avec $\\theta\\gt 0$ ou \\(ğŸ™_{\\mathbb R_+}\\) designe la fonction indicatrice de $\\mathbb R_+$Nous souhaitons tester lâ€™hypothese $H_0:\\theta = \\theta_0$ contre $H_1:\\theta = \\theta_1$ avec $\\theta_0\\lt \\theta_1$ a lâ€™aide dâ€™observations $x_i$ issues de lâ€™echantillon precedent (a) Justifier que, pour tout $\\theta\\gt0$, $f(\\cdot,\\theta)$ definit bien une densite sur $\\mathbb R$ (b) Determiner lâ€™EMV $\\hat\\theta$ Determiner la statistique du test de Neyman-Pearson et indiquer la region critique associe a ce test. Verifier que la variable aleatoire $Y_i=\\frac{2}{\\theta}X_i^3$ suit une loin $\\chi^2$ a deux degres de liberte En deduire le seuil du test de Neyman-Pearson en fonction du risque de premiere espece $\\alpha$ Determiner la puissance du test en fonction du test et de $\\theta_1$ Determiner les courbes COR associees a ce test (a) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=2$ et $n=15$ (b) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=5$ et $n=30$ (c) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=2$ et $n=10$ (d) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=5$ et $n=30$ Solution 3. On pose $\\phi(y)=\\frac{2}{\\theta}y^3$. Ainsi:\\[\\phi^{-1}(y) = \\sqrt[3]{\\frac{\\theta y}{2}}\\] Elle est derivable car elle est polynomiale et est bijective car elle est strictement croissante.\\[\\begin{aligned}f_Y(y)&amp;amp;=\\frac{1}{(\\frac{6}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2)}\\times f(\\sqrt[3]{\\frac{\\theta y}{2}})\\\\&amp;amp;= \\frac{1}{\\frac{6}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2}\\times \\frac{3}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2\\times e^{-(\\frac{(\\sqrt[3]{\\frac{\\theta y}{2}})^3}{\\theta})}\\\\&amp;amp;= \\frac{1}{2}\\times e^{-\\frac{y}{2}}\\end{aligned}\\] On peut en deduire que $Y$ suit une loi $\\chi^2(2)$ 4.\\[\\color{green}{\\boxed{T=\\sum_{i=1}^nX_i^3}}\\]\\[\\color{green}{Y_{i} = \\frac{2}{\\theta}X_i^3\\sim X^2(2)}\\]\\[\\Rightarrow \\frac{2}{\\theta} T\\sim \\chi^2(2n)\\]\\[\\begin{aligned}\\alpha &amp;amp;=P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T\\gt S_{\\alpha}\\vert\\theta = \\theta_0)\\\\&amp;amp;= P(\\frac{2}{\\theta_0}T\\gt \\frac{2}{\\theta_0}S_{\\alpha}\\vert \\theta=\\theta_0)\\end{aligned}\\] Sous $(H_0)$, $\\color{red}{\\frac{2}{\\theta_0}T\\sim\\chi^2(2n)}$ $\\color{green}{F_n \\text{ est la fonction de repartition }\\chi^2(2n)}$\\[\\alpha = P(W\\gt \\frac{2}{\\theta_0}S_{\\alpha})\\] \\[\\alpha = 1 -F_n(\\frac{2}{\\theta_0}S_{\\alpha})\\] $\\color{red}{Donc}$\\[1-\\alpha = F_n(\\frac{2}{\\theta_0}S_{\\alpha})\\] \\[S_{\\alpha} = \\frac{\\theta_0}{2}F_n^{-1}(1-\\alpha)\\] \\[\\begin{aligned}\\color{red}{\\beta} &amp;amp;= P(\\text{Rejeter }H_1\\vert H_1\\text{vraie})\\\\&amp;amp;= P(T\\le S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\frac{2}{\\theta_1}T\\le \\frac{2}{\\theta_1}S_{\\alpha}\\vert \\theta = \\theta_1)\\end{aligned}\\]\\[w_1 = \\frac{2}{\\theta_1}T\\sim \\chi^2(2n)\\] \\[\\beta = F_n(\\frac{2}{\\theta_1}S_{\\alpha})\\]\\[\\color{green}{\\beta = F_n\\biggr(\\frac{\\theta_0}{\\theta_1}F_n^{-1}(1-\\alpha)\\biggr)}\\] Passons aux applications numeriques: scipy.stats.chi2.cdf(0.5 * scipy.stats.ppf(0.95, 30), 30) 0.14185880202947254 scipy.stats.chi2.cdf(0.2 * scipy.stats.ppf(0.95, 60), 60) 1.6239064341119149e-09 scipy.stats.chi2.cdf(0.5 * scipy.stats.ppf(0.99, 20), 20) 0.46403880816957155 scipy.stats.chi2.cdf(0.2 * scipy.stats.ppf(0.99, 20), 20) 1.87204631776198e-08 scipy.stats.chi2.cdf(1.0001 * scipy.stats.ppf(0.99, 20), 20) 0.9900104784496678 " }, { "title": "IMED2: Principe physiques de la radiologie numerique", "url": "/cours/posts/principe_radio/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-29 09:00:00 +0200", "snippet": "Lien de la note Hackmd Rappels kVp mA Temps dâ€™expositionAdaptation du faisceau: Filtration uniforme (Cu) Lames de collimationInteractions avec la matiere: Diffusion elastique Diffusion inelastique Effet photoelectriqueLes chaines images selon les modalites Quelques exemplesQuâ€™est-ce quâ€™une â€œbonneâ€ image ?Tout depend de la tacheOn a 3 choses tres importantes: bruit nettete Resolution spatiale contraste Contraste-to-noise ratio Bonne image a rayons X ? Ca depend encore de la tache Differentiation de matieres Pas dâ€™artefacts (e.g., halos pres des contours, lignes, colonnes, mouvement, flouâ€¦) Si on a un halo autout dâ€™un implant, on a un peu de jeu autourIl faut certainement rajouter quelque chose pour reparer caCa peut etre tres dangereux (patient fragile, agee, etc.)Zoom sur la chaine de traitement numerique Lâ€™image quâ€™on voit est loin dâ€™etre lâ€™image quâ€™on mesureSur la premiere image on a une ligne au centreQualite Image et tache clinique Qui est mon patient ? Un gamin Un adulte Une personne agee Pour quel acte vient-il ? Un suivi de scoliose / un bilan general de posture Un depistage de cancer du sein Une ablation de tumeur hepatique Selon les cas, le besoin en qualite image et la tolerance en terme dâ€™irradtion serra differente Un principe historique: ALARA (As Low As Reasonnably Achievable) Un acronyme qui a tendance a etre remplace par ALADA (As Low As Diagnostically Achievable)Du coup il y a des guidelines:Controle automatique de lâ€™exposition AEC: la technologie de tous les appareils modernes dâ€™imagerie RX â€œAutomatic Exposure Control (AEC) is an X-ray exposure termination deviceâ€ Wikipedia Radiographie conventionnelle Une technique aussi vieille que les rayons XOn faisait du stitching, mais on avait des problemes de deformation geometriquesEOS/EOSedge et lâ€™imagerie orthopediqueVideo de presentationPathologies en orthopedie Diagnostic, correction &amp;amp; suivi de scolioses Chirurgie: tiges et vis Implants (hanches, genou) Osteoporose Polyarthrite" }, { "title": "PRSTA: Seance 4", "url": "/cours/posts/prsta_seance4/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-27 17:00:00 +0200", "snippet": "Lien de la note HackmdRappel Proposition Sous des hypotheses techniques, en notant $\\hat\\theta_n$ lâ€™estimateur du maximum de vraisemblance. $\\sqrt{n!(\\theta_0)}(\\hat\\theta_n-\\theta_0)$ converge en loi vers $\\mathcal N(0,1)$ Nous disons que lâ€™estimateur du maximum de vraisemblance est normal asymptotiquement efficace ou NAE (Best asymptotically normal ou BAN)Nous supposerons que les hypotheses techniques evoquees sont verifiees Theoreme de Wilks Sous lâ€™hypothese $(H_0)$, $R_n:=2\\log T_n$ converge en loi ver une loi $\\chi^2(1)$Cas particulier $H_0:\\theta=\\theta_0$ $H_1:\\theta\\neq \\theta_1$Notons $\\hat\\theta$ lâ€™EMV Definition La statistique de Wald est:\\[W_n=\\frac{(\\hat \\theta_n-\\theta_0)^2}{V(\\hat\\theta_n)}\\] Theoreme Sous $H_0$, $W_n$ converge en loi vers un $\\chi^2(1)$ExemplePremier exemple $X\\sim\\mathcal N(m,1)$ $H_0:m=0$ contre $H_1:m\\neq 0$\\[V(\\bar X_n)=V(\\frac{1}{n}\\sum_{i=1}^n X_i)=\\frac{1}{n^2}(\\sum_{i=1}^nX_i)\\\\\\boxed{V(\\bar X_n)=\\frac{1}{n^2}\\times n=\\frac{1}{n}}\\]Second exemple $H_0$: â€œle patient est sainâ€ $H_1$: â€œle patient est maladeâ€ $\\alpha$: probabilite de rejeter $(H_0)$ alors quâ€™elle est vraie i.e. probabilite de fausse alarme $\\beta$: probabiliter de rejeter $(H_1)$ alors quâ€™elle est vraie i.e., probabilite de non detection Ainsi, la puissance $\\pi:=1-\\beta$ est la probabilite de detection Caracteristiques Operationnelles du Recepteur Elles permettent dâ€™analyser les performances dâ€™un test Expression de la puissance comme une fonction de $\\alpha$ $\\beta=f(\\alpha)$" }, { "title": "PRSTA: TD 4", "url": "/cours/posts/prsta_td4/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-27 14:30:00 +0200", "snippet": "Lien de la note HackmdFeuille 4 Exercice 2Partie ALa variable aleatoire $X$ suit une loi de densite:\\[f(x,\\theta)=\\theta x^{\\theta-1}1_{[0;1]}(x)\\]ou le parametre $\\theta$ est strictement positif.En dâ€™autres termes, $f(x, \\theta) = 0$ si $x \\not\\in [0; 1]$ et $f(x, \\theta) = \\theta x^{\\thetaâˆ’1}$ si $x \\in [0; 1]$. Justifier que, pour tout $\\theta \\gt 0$, $f(., \\theta)$ definit bien une densite sur $\\mathbb R$. Calculer $E(X)$ Determiner lâ€™estimateur du maximum de vraisemblance $\\hat\\theta$ du parametre $\\theta$. Considerons maintenant la variable aleatoire $Y := âˆ’ \\ln X$. Pourquoi est-elle bien definie ? Montrer que la variable aleatoire $Y$ suit une loi $\\Gamma(1, \\theta)$. Solution 1. Comme $\\theta\\gt 0$ et $x\\in[0;1]$, $f(x,\\theta)$ est strictement positive.\\[\\begin{aligned}\\int_0^1f(x,\\theta)&amp;amp;=[x^{\\theta}]^1_0\\\\&amp;amp;= 1^{\\theta}-0 =1\\end{aligned}\\] On a donc bien une densite. 2.\\[\\begin{aligned}E(X)&amp;amp;=\\int_0^1xf(x,\\theta)1_{[0;1]}dx\\\\&amp;amp;= \\int_0^1\\theta x^{\\theta}dx\\\\&amp;amp;= \\biggr[\\frac{\\theta x^{\\theta+1}}{\\theta+1}\\biggr]\\\\&amp;amp;= \\frac{\\theta}{theta+1}\\gt0\\end{aligned}\\] 3. Considerons:\\[\\begin{aligned}L(x_1,\\dots,x_n,\\theta) &amp;amp;= \\prod_{i=1}^n\\theta x_i^{\\theta-1}1_{[0;1]}(x_i)\\\\&amp;amp;= \\theta^n\\prod_{i=1}^nx_i^{\\theta-1}\\prod_{i=1}^n1_{[0;1]}(x_i)\\end{aligned}\\] Pourquoi est-ce que les indicatrices ne posent pas de problemes ? Car nos observations sont entre $0$ et $1$ Pour determiner le maximum, nous pouvons nous restreindre au cas: $(x_1,\\dots,x_n)\\in[0;1]$ car les $x_i$ sont des observations. Passons au logarithme:\\[\\ln(L(x_1,\\dots,x_n,\\theta))=n\\ln(\\theta)+(\\theta-1)\\sum_{i=1}^nx_i\\] Calculons la derivee partielle:\\[\\frac{\\partial\\ln(x_1,\\dots,x_n,\\theta)}{\\partial\\theta}=\\frac{n}{\\theta}+\\sum_{i=1}^n\\ln(X_i)\\\\\\begin{aligned}\\frac{\\partial\\ln(x_1,\\dots,x_n)}{\\partial\\theta}&amp;amp;=0\\\\\\Leftrightarrow\\theta&amp;amp;=-\\frac{n}{\\sum_{i=1}^n\\ln(X_i)}\\end{aligned}\\] Verifions la conditions du second ordre:\\[\\frac{\\partial^2\\ln(L(x_1,\\dots,x_n,\\theta))}{\\partial\\theta^2}=-\\frac{n}{\\theta^2}\\lt 0\\quad \\forall \\theta\\gt 0\\] $\\hat\\theta$ est bien lâ€™EMV! 4. Question 1. Elle est bien definie car comme $X\\in[0;1]$, $\\ln(X)\\lt0$ donc $-\\ln(X)\\gt 0$ 2. Pourquoi on parle de loi $\\Gamma$ au lieu de loi exponentielle ? Car câ€™est facile dâ€™additionner les loi $\\Gamma$. \\[\\begin{aligned}y&amp;amp;=-\\ln x\\\\\\ln x&amp;amp;=-y\\\\x&amp;amp;=e^{-y}\\end{aligned}\\] On pose $\\phi(x)=-\\ln(x)$\\[\\phi&#39;(x)=-\\frac{1}{x}\\\\\\phi^{-1}(x)=e^{-x}\\\\\\begin{aligned}f_Y(y)&amp;amp;=\\color{red}{-}\\frac{1}{\\phi&#39;(\\phi^{-1}(y))}\\cdot f(\\phi^{-1}(y))\\quad\\phi&#39;(\\phi^{-1}(y))=\\color{red}{-}\\frac{1}{e^{-x}}\\\\&amp;amp;=e^{-y}\\cdot\\theta\\phi^{-1}(y)^{\\theta-1}\\\\&amp;amp;=e^{-y}\\cdot e^{-y(\\theta-1)}\\\\&amp;amp;=\\theta e^{-\\theta y}\\end{aligned}\\] Donc $Y\\rightsquigarrow \\xi(\\theta)=\\Gamma(1,\\theta)$ \\[\\boxed{\\phi_y(t)=\\frac{\\theta}{\\theta-it}}\\] car fonction caracteristique de la loi exponentielle Quâ€™est-ce quâ€™on a oublie dans notre formule ? La valeur absolue du Jacobien Partie BConsiderons $n$ variables aleatoires independantes $X_i$ suivant la loi de $X$. Nous souhaitons tester lâ€™hypothese $H_0 : \\theta = \\theta_0$ contre $H_1 : \\theta = \\theta_1$ avec $\\theta_0 &amp;lt; \\theta_1$ a lâ€™aide dâ€™observations $x_i$ issues de lâ€™echantillon precedent. Nous noterons, dans la suite de lâ€™exercice, $Y_i = âˆ’ \\ln X_i$. Montrer que la statistique de Neyman-Pearson est: $T_n:=\\sum_{i=1}^nY_i$ Determiner la loi de la variable aleatoire $T_n$ puis celle de la variable aleatoire $U_n:=\\frac{T_n}{\\theta}$ Exprimer les risques de premiere et de seconde espece $\\alpha$ et $\\beta$ en fonction du seuil $S_{\\alpha}$, des parametres $\\theta_0$ et $\\theta_1$ et de la fonction de repartition de la variable aleatoire $U_n$. Solution 1.\\[\\begin{aligned}\\frac{L(X_1,\\dots,X_n\\theta_1)}{L(X_1,\\dots,X_n\\theta_0)}&amp;amp;=\\frac{\\prod_{i=1}^n\\theta_1x_i^{\\theta_1-1}}{\\prod_{i=1}^n\\theta_0x_i^{\\theta_0-1}}\\\\&amp;amp;= \\biggr(\\frac{\\theta_1}{\\theta_2}\\biggr)^n\\prod_{i=1}^nX_i^{\\theta_1-\\theta_0}\\end{aligned}\\] $(H_0)$ est rejetee si:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln(T_n)=n\\ln(\\frac{\\theta_1}{\\theta_0})+(\\theta_n-\\theta_0)\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\gt\\ln(C_{\\alpha})\\\\\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\gt\\underbrace{\\frac{\\ln(C_{\\alpha})-n\\ln(\\frac{\\theta_1}{\\theta_0})}{\\theta_n-\\theta_0}}_{S_{\\alpha}&#39;}\\\\-\\sum\\ln(X_i)&amp;amp;\\lt -S_{\\alpha}&#39;\\\\T_n=-\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\lt S_{\\alpha}\\quad \\text{ou } S_{\\alpha}=-S_{\\alpha}&#39;\\end{aligned}\\] 2. Quel loi suit $T_n$ ? On sait que $X_i\\sim P(1,\\theta)$ Donc $\\phi_X(t)=\\frac{\\theta}{\\theta-it}$\\[T_n=\\sum_{i=1}^n Y_i\\] Donc\\[\\phi_{T_n}=(\\phi_{Y_i}(t))^n\\] car les $Y_i$ sont independants. \\[\\boxed{\\phi_{T_n}=\\biggr(\\frac{\\theta}{\\theta-it}\\biggr)^n}\\] Donc: $T_n\\sim\\Gamma(n, \\theta_0)$ sous $(H_0)$ $T_n\\sim\\Gamma(n, \\theta_1)$ sous $(H_1)$ On va calculer la densite de $U_n$\\[U_n=\\theta T_n\\\\\\phi:]0;+\\infty[\\to]0;+\\infty[\\] $\\phi$ est derivable et bijective:\\[\\phi^{-1}(x)=\\frac{x}{\\theta}\\quad\\text{et}\\quad\\phi&#39;(x)=\\theta\\\\\\begin{aligned}f_{U_n}(u)&amp;amp;=\\frac{1}{\\theta}\\times\\frac{1}{\\Gamma(n)}\\biggr(\\frac{u}{\\theta}\\biggr)^{\\alpha-1}\\theta^{\\alpha}e^{-\\theta\\frac{u}{\\theta}}\\end{aligned}\\] \\[f_{U_n}(u)=\\frac{1}{\\Gamma(n)}u^{\\alpha-1}e^{-u}\\] Donc la loi de $U_n$ ne depend pas de $\\theta$ 3. Notons $H_n$ la fonction de repartition de $U_n$.\\[\\begin{aligned}\\alpha&amp;amp;=P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T_n\\lt S_{\\alpha}\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\theta_0 T_n\\le\\theta_0 S_{\\alpha}\\vert\\theta=\\theta_0)\\\\&amp;amp;= \\color{red}{P}(U_n\\lt\\theta_0 S_{\\alpha})\\quad\\color{red}{\\text{Sous } H_0}\\\\&amp;amp;= H_n(\\theta_0S_{\\alpha})\\end{aligned}\\\\S_{\\alpha}=\\frac{H_n^{-1}(\\alpha)}{\\theta_0}\\] \\[H_n(x)=\\int_0^x\\frac{1}{\\Gamma(n)}t^{\\alpha-1}e^{-t}dt\\] Si $x\\lt y$ alors:\\[H_n(y)-H_n(x)=\\int_x^y\\frac{1}{\\Gamma(n)}t^{\\alpha-1}e^{-t}dt\\gt0\\] Donc $(H_n)$ est strictement croissante sur $[0;+\\infty[$ Par consequence, elle est strictement croissante \\[\\begin{aligned}\\beta &amp;amp;= P(\\text{Rejeter } H_1\\vert H_0\\text{fausse})\\\\&amp;amp;= P(T_n\\ge S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\underbrace{\\theta_1 T_n}_{\\color{green}{U_n}}\\ge S_{\\alpha}\\theta_1\\vert \\theta=\\theta_1)\\\\&amp;amp;= 1-H_n(\\theta_1S_{\\alpha})\\end{aligned}\\] \\[\\boxed{\\beta=1-H_n\\biggr(\\frac{\\theta_1}{\\theta_0}H_n^{-1}(\\color{green}{\\alpha})\\biggr)}\\] " }, { "title": "OCVX2 : Tout ce que vous avez toujours voulu savoir sur les SVMS", "url": "/cours/posts/ocvx2_svm/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-27 11:00:00 +0200", "snippet": "Lien de la note HackmdOn a un probleme de classification binaire: Probleme: donnees dâ€™apprentissage\\[\\{(x_i,y_i)\\}_{i=1}^n\\quad x_i\\in\\mathbb R^p\\quad y_i\\in\\{-1,+1\\}\\] On cherche un hyperplan de $\\mathbb R^p$ qui separe parfaitement les deux classesDans notre exemple, il nâ€™y a pas quâ€™un seul hyperplan separant les 2 classes:Hyperplan Hyperplan: caracterise par un vecteur normal $w\\in\\mathbb R^p$ et un offset $b\\in\\mathbb R$\\[x\\in H\\Leftrightarrow w^Tx+b=0\\]Lequel des hyperplans semble meilleur ? Celui du milieuOn a une infinite de solutions possibles (meme risque empirique), mais toutes les solutions nâ€™ont pas les memes performances en generalisation Geometriquement, on veut celui qui est le plus loin des points (aka la marge de lâ€™hyperplan)On cherche $(w,b)\\in\\mathbb R^p\\times\\mathbb R$ tel que tous les echantillons de la classe $-1/+1$ soient dans le demi espace: positif: $w^Tx_i+b\\ge0$ $y_i=+1$ negatif: $w^Tx_i+b\\le0$ $y_i=-1$ Dans tous les cas:\\[\\boxed{\\forall x_i\\in\\mathbb R^p, y_i(w^Tx_i+b)\\ge 0}\\]Marge Marge: distance de lâ€™hyperplan aux echantillons les plus proches \\(\\begin{aligned}M_H=\\min_{i=1,\\dots,n}\\{d(x_i,H)\\} &amp;amp;= \\min_{i=1,\\dots,n}\\{d(x_i,x),x\\in\\mathbb R^n,w^Tx+b=0\\}\\\\&amp;amp;= d(x_s,H)\\quad\\text{avec } x_s \\text{ vecteur de support}\\end{aligned}\\) On va chercher lâ€™hyperplan qui maximise la marge\\[H^*=\\text{arg}\\max_{(w,b)\\in\\mathbb R^p\\times\\mathbb R}M_H=d(x_s,H)\\]Distance dâ€™un point $x_0$ a un hyperplan:\\[d(x_0,H)=\\Vert y-x_0\\Vert\\]\\[(L)=\\{x_0+tw,t\\in\\mathbb R\\}\\]\\[y\\in(L),\\exists t\\in\\mathbb R, y=x_0+tw\\\\\\begin{aligned}&amp;amp;y\\in(H)w^Ty+b=0\\\\&amp;amp;w^T(x_0+tw)+b=0\\\\&amp;amp;w^Tx_0+\\underbrace{tw^Tw}_{\\Vert w\\Vert^2}+b=0\\\\\\end{aligned}\\\\t=-\\frac{1}{\\Vert w\\vert^2}(w^Tx_0+b)\\]\\[\\begin{aligned}d(x_0,H)=\\Vert y-x_0\\Vert&amp;amp;=\\Vert x_0+tw-x_0\\Vert\\\\&amp;amp;=\\Vert tw\\Vert\\\\&amp;amp;=\\vert t\\vert\\cdot\\Vert w\\Vert\\\\&amp;amp;=\\biggr\\vert-\\frac{1}{\\Vert w\\Vert^2}(w^Tx_0+b)\\biggr\\vert\\times\\Vert w\\Vert\\end{aligned}\\\\\\boxed{d(x_0, H)=\\frac{\\vert w^Tx_0+b}{\\Vert w\\Vert}}\\]\\[\\begin{aligned}M_H&amp;amp;=\\min_i\\{d(x_i,H)\\}\\\\&amp;amp;=\\min_i\\biggr\\{\\frac{\\vert w^Tx_i+b\\vert}{\\Vert w\\Vert}\\biggr\\}\\\\&amp;amp;= \\frac{1}{\\Vert w\\Vert}\\min_i\\{\\vert w^Tx_i+b\\vert\\}\\\\&amp;amp;= \\frac{\\vert w^Tx_s+b\\vert}{\\Vert w\\Vert}\\quad x_s\\text{ vecteur de support}\\end{aligned}\\]On cherche\\[\\text{arg}\\max_{(w,b)}M_H=\\text{arg}\\max_{(w,b)}\\frac{\\vert w^T x_s+b\\vert}{\\Vert w\\Vert}\\] Si $(w,b)$ est une solution, $(kw,kb)$ $k\\gt0$ est aussi solution.On va choisir $(w,b)$ tels que $\\vert w^T x_s+b\\vert =1$Marge normalisee: $\\frac{1}{\\Vert w\\Vert}$SVMOn cherche a:\\[\\begin{aligned}\\text{maximiser}&amp;amp;\\frac{1}{\\Vert w\\Vert}\\\\\\text{maximiser}&amp;amp;\\frac{2}{\\Vert w\\Vert}\\\\\\text{minimiser}&amp;amp;\\frac{1}{2}\\Vert w\\Vert^2\\\\\\end{aligned}\\] SVM:\\[\\boxed{\\text{arg}\\min_{(w,b)\\in\\mathbb R^d\\times\\mathbb R}\\frac{1}{2}\\Vert w\\Vert^2\\\\\\begin{aligned}\\text{tel que } &amp;amp;y_i(w^Tx_i+b)\\ge1\\\\&amp;amp;\\forall i=1,\\dots,n\\end{aligned}}\\]\\[\\frac{1}{2}\\Vert w\\Vert^2=\\frac{1}{2}w^Tw\\\\y_i(w^Tx_i+b)\\ge1\\Leftrightarrow 1 - y_i(w^Tx_i+b)\\le 0\\quad\\forall i\\] Le Lagrangien de (SVM) est:\\[\\begin{aligned}\\mathscr L(w,b,\\lambda)&amp;amp;=\\frac{1}{2}w^Tw+\\sum_{i=1}^n\\lambda_i(1-y_i(w^Tx_i+b))\\quad w\\in\\mathbb R^p, b\\in\\mathbb R,\\lambda\\in\\mathbb R^n\\\\&amp;amp;=\\frac{1}{2}w^Tw-\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)\\end{aligned}\\]Conditions KKTStationnarite du Lagrangien\\[\\begin{aligned}\\nabla_w\\mathscr L(w,b,\\lambda)&amp;amp;=0 \\\\ &amp;amp;=\\underbrace{\\frac{\\partial}{\\partial w} (\\frac{1}{2}w^Tw)}_{w} - \\sum_{i=1}^n\\frac{\\partial}{\\partial w}(\\lambda_i\\underbrace{(y_i(w^T}_{\\lambda_i y_i x_i}x_i+b)-1))\\\\0&amp;amp;= w-\\sum_{i=1}^n\\lambda_iy_ix_i\\\\w&amp;amp;=\\sum_{i=1}^n\\lambda_iy_ix_i\\quad w \\text{ est une combinaison lineaire des } x_i\\end{aligned}\\\\\\nabla_b\\mathscr L(w,b,\\lambda)=\\boxed{0=\\sum_{i=1}^n\\lambda_iy_i}\\]A chaque $x_i$ correspond un $\\lambda_i$ $\\lambda_i\\ge 0\\to\\lambda_i$ est la â€œforceâ€ avec laquelle $x_i$ repousse lâ€™hyperplan $\\sum_{i=1}^n\\lambda_iy_i=0\\to$ lâ€™hyperplan est a lâ€™equilibreComplementarite\\[\\forall i=1,\\dots,n\\quad\\lambda_i(1-y_i(w^Tx_i+b))=0\\quad(\\alpha_i^*g_i(x^*)=0\\quad\\forall i)\\]Soit $\\lambda_i=0$:\\[1-y_i(w^Tx_i+b)\\lt 0\\Leftrightarrow y_i(\\underbrace{w^Tx_i+b}_{x_i \\text{ n&#39;est pas} \\\\ \\text{un vecteur}\\\\ \\text{de support}})\\gt 1\\\\\\lambda_i=0\\begin{cases}x_i\\text{ ne repousse pas l&#39;hyperbole}\\\\\\text{ne contribue pas a la solution } w=\\sum_{i=1}^n\\lambda_iy_ix_i\\\\\\text{la solution ne change pas si on enleve } x_i\\text{ du jeu de donnees}\\end{cases}\\]Soit $\\lambda_i\\gt 0$:\\[1-y_i(w^Tx_i+b)=0\\Leftrightarrow y_i(\\underbrace{w^Tx_i+b}_{x_i \\text{ est un vecteur} \\\\ \\text{de support}})=1\\\\\\lambda_i\\gt 0\\begin{cases}\\text{la solution change si on enleve } x_i \\text{ du jeu de donnees}\\end{cases}\\]Recap\\[w=\\sum_{i=1}^n\\lambda_iy_ix_i\\\\o=\\sum_{i=1}^n\\lambda_iy_i\\\\\\mathscr L(w,b,\\lambda)=\\frac{1}{2}w^Tw-\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)\\\\\\begin{aligned}w^Tw&amp;amp;= (\\sum_{i=1}^n\\lambda_iy_ix_i)^T(\\sum_{j=1}^n\\lambda_jy_jx_j)\\\\&amp;amp;= \\sum_{i=1}^n\\lambda_iy_i(x_i)^T\\sum_{j=1}^n\\lambda_jy_jx_j\\\\&amp;amp;= \\sum_i\\sum_j\\lambda_i\\lambda_jy_iy_jx_i^Tx_j\\end{aligned}\\]\\[\\begin{aligned}\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)=\\sum_{i=1}^n\\underbrace{\\lambda_iy_iw^Tx_i}&amp;amp;+\\underbrace{b\\sum_{i=1}^n\\lambda_iy_i}-\\sum_{i=1}^n\\lambda_i\\\\\\sum_{i}\\lambda_iy_i(\\sum_{j=1}^n\\lambda_jy_jx_j)^Tx_i&amp;amp;=\\sum_i\\sum_j\\lambda_i\\lambda_jy_iy_jx_i^Tx_j\\end{aligned}\\] Probleme dual du SVM\\[\\boxed{\\max_{\\lambda_i\\ge 0 \\\\ \\sum_{i=1}^n\\lambda_iy_i}\\mathscr L=-\\frac{1}{2}\\sum_{i=1}^n\\sum_{j=1}^n\\lambda_i\\lambda_jy_iy_jx_i^Tx_j+\\sum_{i=1}^n\\lambda_i}\\]Sous reserve quâ€™on puisse resoudre le dual: On trouve $\\lambda_i^{*}$ On trouve $w^{*}=\\sum_{i=1}^n\\lambda_i^{*}y_ix_i$ On trouve $b^{*}$ grace aux vecteurs de support $y_i(w^{*t}x_i+b^{*})=1$ Probleme dual du SVM se resout par Sequential Minimal OptimizationPour resoudre" }, { "title": "OCVX2 : Tout ce que vous avez toujours voulu savoir sur l&#39;ACP (ou pas)", "url": "/cours/posts/ocvx2_acp/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-27 10:00:00 +0200", "snippet": "Lien de la note HackmdOn a un nuage de points:On une infinite de directions possibles. On projette sur les axes: On cherche un vecteur $\\vec u$ tel que lâ€™erreur de projection des ${x_i}$ sur lâ€™espace engendre par notre vecteur $\\text{span}(u)$ soit minimale.En formulation mathematiques:\\[\\text{proj}(x_i,\\text{span}(u))=P_u(x_i)=\\langle x_i,u\\rangle = x_i^Tu\\] En lâ€™etat: une infinite de solutions (si $u$ solutions, $ku$ solutions avec $k\\in\\mathbb R^{*}$)On impose $\\Vert u\\Vert=1$\\[P_u(x_i)=\\langle x_i,u\\rangle=x_i^Tu\\to E(x_i,\\underbrace{P_u(x_i)}_{y_i}) = \\Vert x_i-y_i\\Vert^{(2)}\\] On cherche donc:\\[\\text{arg}\\min_{u,\\Vert u\\Vert=1}\\sum_{i=1}^n E(x_i,P_u(x_i))\\]Dâ€™apres Pythagore:\\[\\Vert x_i\\Vert^2=\\Vert y_i\\Vert^2+\\Vert x_i-y_i\\Vert\\\\\\Vert x_i-y_i\\Vert^2=\\Vert x_i\\Vert^2-\\Vert y_i\\Vert^2\\]On peut donc reecrire:\\[\\begin{aligned}\\sum_{i=1}^nE(x_i,P_u(x_i))&amp;amp;=\\sum_{i=1}^n\\Vert x_i-y_i\\Vert^2\\\\&amp;amp;=\\underbrace{\\sum_{i=1}^n\\Vert x_i\\Vert^2}_{\\text{constante}} - \\sum_{i=1}^n\\Vert y_i\\Vert^2\\end{aligned}\\]Donc:\\[\\begin{aligned}\\text{arg}\\min_{u,\\Vert u\\Vert=1}&amp;amp;=\\text{arg}\\min_{u,\\Vert u\\Vert=1}-\\sum_{i=1}^n\\Vert y\\Vert^2\\\\&amp;amp;=\\text{arg}\\max_{u,\\Vert u\\Vert=1}\\sum_{i=1}^n\\Vert y_i\\Vert^2\\\\&amp;amp;=\\text{arg}\\max_{u,\\Vert u\\Vert=1}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n\\Vert y\\Vert^2}\\\\&amp;amp;\\Vert y_i\\Vert^2=y_i^Ty_i\\underbrace{\\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i}_{\\text{var}(P_u(X))}\\end{aligned}\\]On est en train de chercher:\\[\\begin{aligned}\\text{arg}\\min_{u,\\Vert u\\Vert=1}-\\sum_{i=1}^n\\Vert y_i\\Vert^2&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i\\\\&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^n(x_i^Tu)^T(x_i^Tu)\\\\&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^nu^Tx_ix_i^Tu\\\\&amp;amp;= -u^T(\\underbrace{\\frac{1}{n}\\sum_{i=1}^nx_ix_i^T}_{\\Sigma\\text{ matrice de covariance} \\\\ \\text{de } X=\\{x_i\\}^n_{i=1}\\text{ centre}})u\\end{aligned}\\] On cherche: \\(\\boxed{\\text{arg}\\min_{u\\in\\mathbb R^p \\\\ \\Vert u\\Vert =1}-u^T\\underbrace{\\Sigma}_{\\text{matrice de} \\\\ \\text{covariance}}u}\\)\\[\\text{arg}\\max_{\\Vert u\\Vert=1}u^T\\Sigma u = \\text{arg}\\max\\overbrace{\\frac{u^T\\Sigma u}{u^Tu}}^{\\text{Quotien de Rayleigh}}\\]On va reecrire:\\[\\text{arg}\\min_{u\\in\\mathbb R^p}-u^T\\Sigma u\\\\\\begin{aligned}\\Vert u\\Vert =1\\Leftrightarrow &amp;amp;\\Vert u\\Vert^2=1\\\\&amp;amp;\\begin{cases}u^Tu=1 &amp;amp;f(u)-u^T\\Sigma u\\\\u^Tu-1=0&amp;amp;g(u)=u^Tu-1\\end{cases}\\biggr\\}\\text{arg}\\min_{g(u)=0} f(u)\\end{aligned}\\]Le lagrangien de ce probleme est $\\mathscr L(u\\lambda)=f(u)+\\lambda g(u)-u^T\\Sigma u+\\lambda(u^Tu-1)$ Stationnarite de $\\mathscr L:\\nabla_u\\mathscr L(u,\\lambda)=0=\\nabla_u(-u^T\\Sigma u)+\\lambda\\nabla_u(u^Tu-1)$ Rappel: $f(x)=x^TAx$On calcule la differentielle $f(x+h)=f(x)+df_x(h)+O(h)$\\[\\begin{aligned}f(x+h)=(x+h)^TA(x+h)=\\underbrace{x^TAx}_{f(x)}+x^T\\underbrace{AH+h^T}&amp;amp;Ax+\\underbrace{h^TAh}_{O(h)}\\\\x^TAh+(\\underbrace{h^TAx})^T&amp;amp;\\\\\\underbrace{x^TA^Th}&amp;amp;\\\\x^T(A+A^T)h&amp;amp;\\to df_x(h)=x^T(A+A^T)h\\\\(=2x^TAh\\text{ si } &amp;amp;A \\text{ symetrique } A=A^T)\\end{aligned}\\\\\\]\\[df_x(h)=\\langle\\nabla_xf,h\\rangle=\\nabla_xf^Th\\to\\nabla_xf=(A+A^T)x=2Ax\\\\\\begin{aligned}\\nabla_u(-u^T\\Sigma u)=-\\nabla_u(u^T\\Sigma u)=-2\\Sigma u\\\\\\nabla_u(u^Tu)=\\nabla_u(u^TI_du)=2u\\end{aligned}\\biggr\\}-2\\Sigma u+2du=0\\]\\[\\color{red}{\\boxed{\\Sigma u=\\lambda\\mu}}\\] $u$ est un vecteur propre de $\\Sigma$$\\lambda$ est sa vlaeur propreOn se souvient quâ€™on cehrche $u$, $\\Vert u\\Vert=1$ qui maximise:\\[\\begin{aligned}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n\\Vert y_i\\Vert^2}_{\\text{var}(P_u(x))}&amp;amp;= \\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n(x_i^Tu)(x_i^Tu)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nu^Tx_ix_i^Tu\\\\&amp;amp;=u^T(\\frac{1}{n}\\sum_{i=1}^nx_ix_i^T)u\\\\&amp;amp;=u^T\\underbrace{\\Sigma u}_{\\lambda u}\\\\&amp;amp;=\\lambda \\underbrace{u^Tu}_{\\Vert u\\Vert^2 =1}\\\\&amp;amp;=\\lambda\\end{aligned}\\]" }, { "title": "EPIQUANTI : Types de Qubits", "url": "/cours/posts/epiquanti_type_qubit/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-26 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursQuantum anneleaing\\[\\mathcal H_p =\\sum_{i=0}^Nh_i\\sigma_i^Z+\\sum_{i,j=0}^NJ_{ij}\\sigma_i^Z\\sigma_j^Z\\]JargonD WaveSuper conducting quantum annealing15 ans dâ€™avance sur la creation de ses machines Spin up qubit $\\vert\\uparrow\\rangle$ Spin up qubit $\\vert\\downarrow\\rangle$ Quantum annealing and ising model\\[\\mathcal H_p =\\sum_{i=0}^Nh_i\\sigma_i^Z+\\sum_{i\\lt j}^NJ_{ij}\\sigma_i^Z\\sigma_j^Z\\] $\\mathcal H_p$: system hamiltonian $h_i$: energy difference between 2 states of qubits i $v_i$: vertices containing qubit i $J_{ij}$: coupling between vertices $v_i$ et $v_j$ with close i and j $E$: edge, connecting qubitsComputing processStarts with converting the probleme into a Ising model or QUBO (Quadratic Unconstrained Binary Optimization) Initialization of qubits states to $\\vert\\uparrow\\rangle$ or $\\vert\\downarrow\\rangle$ Setting qubits bias levels $h_i$ Slowly growing $J_{ij}$ coupling System converging to minimal $\\mathcal H_p$ Readout $\\vert\\uparrow\\rangle$ or $\\vert\\downarrow\\rangle$ states for all qubits, giving the solution to the problem of finding the energy minimum for $H_p$ Le chimera est la facon dont les qubits sont relies entre eux physiquement dans le processeurAlgorithmsPegasus / Advantage 2020 generation5436 qubitsEach qubits is connected to 15 neighbour qubits through 37440 couplers, from 6 per qubit in previous generations.Qubits are operating at 15,8 mK One order of magnitude improvement in time spent solving problems vs D-Wave 2000Q launched in 2017Pourquoi câ€™est plus dur de rajouter de nouveaux qubits ? Câ€™est plus dur a intriquerSuperconducting qubitsQubits operating temperatures rationalePourquoi est-ce quâ€™on doit les refroidir ces qubits ? On veut eviter la decoherence des qubits mais pas queLes micro-ondes quâ€™on envoie sur les qubits sont conditionnees par le niveau dâ€™energieOn refroidit pour que le bruit ambiant soit inferieur a la puissance des micro-ondes5 Superconducting qubits lab configuraitonIBMRoadmapGoogleGoogleâ€™s 1 million physical qubits plan Câ€™est quoi la consommation energetique ? - TheotimeAlice &amp;amp; Bob French startup created by ThÃ©au Peronnin and RaphaÃ«lLescanne, from ENS with the help from Benjamin Huard (ENS Lyon), ZakiLeghtas (ENS Paris), Mazyar Mirrahmi (Inria), PhilippeCampagne-Ibarcq (Inria) and Emmanuel Flurin (CEA) use cat-qubits based on two photons coupling in a cavity to increase reliability of superconducting qubits qubit information comes from measuring cavity photon number parity without measuring photon number expect to build a logical superconducting qubit with only 30 cat-qubits instead of 10 000 classical superconducting qubits significantly reduce the burden to create a LSQ FTQC (large scale quantum / fault tolerant quantum computer) plan to produce a first processor with logical qubits by 2023Amazon Amazon announced in december 2020 it will build its own quantum computers using cat-qubits superconducting, in a 118 pages theoretical paper it plans to use surface codes QECitâ€™s partnering with Caltech (incl John Preskill), Yale (Devoret/Schoelkopf teams)and other universitiesSummaryElectron spins qubitsDifferent electron spins qubit platformsHow to detect a single charge?How to manipulate a single spin?How to realize a two-qubit gate?State of the art of two qubit gatesplanar systems with a huge number of electrodes to: define the reservoirs - source and drain control the height of the barrier between quantum dots define the depth of the quantum well manipulate the qubits read out the qubitsToward a scalable platformC12 Quantum Electronic french startup created by Matthieu and Pierre Desjardins with the help from Taki Kontos (LPENS) electron spins qubits trapped in carbon nanotubes 5 qubits demonstrator planned for 2021/2022SummaryNV centers qubitsNV centers implementation and controlsQuantum brillance Australian startup ambiant temperature qubits 5 NV centers qubits demonstrated in 2021 they plan to scale &amp;gt; 50 qubits in 2022 fits on a desktop computer form factor qubits NV centersTopologic qubitsThe topological qubit bitChez microsoft: better stability qubits low decoherence noise few errors long coherence time high gate speed nothing demonstrated so far no prototype different algorithms Majorana fermions summaryTrapped ions qubitsIonQ La boite la plus calee et ayant recu le plus de fonds: $$82$M en 2015 Maryland and Duke Universities spin-off launched by Christopher Monroe $\\color{green}{\\text{pros}}$ $\\color{red}{\\text{cons}}$ laser controlled gates slow gates $32$ qubits with a large quantum volume of $2^{22}$ reached in 2020 not easy to scale, planning to network several tiny units (above) long coherence time and good qubits fidelity Â  excellent qubit connectivity thanks to phonons Â  available on Microsoft and Amazon cloud services Â  IPO planned in 2021Honeywell 2D trapped ions announced in march 2020 4 qubits in march 2020 6 qubits in june 2020 10 qubits in septembre 2020 Better scalability projectTrapped ions qubits summaryCold atoms qubitsCold atoms and Rydberg states Etat de Rydberg: etat tres energisantCold atoms qubits summaryPhoton qubitsPhotons qubits types and toolsQubitsInstrumentationQuantum dot photon sourceQuantum dot photon sourceDV and CV photon qubitsPhotons qubits summary" }, { "title": "TVID: 2D Motion Estimation", "url": "/cours/posts/tvid_motion_estimation/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-10-25 10:00:00 +0200", "snippet": "Lien de la note HackmdScalable video recording Scalability referes to the capacity of recovering physically meaningful image or video information from deconding only partial compressed bitstreams Quality scalability: finer to finer quantizations Spatial scalability: different spatial resolutions (Laplacian, Pyramid, â€¦) Temporal scalability: we can jump frames and add the missing ones progressively Frequency scalability: lower frequencies to higher frequencies Combination of basic schemes Granularity: coarse vs fine ones Object-based scalability: different resolutions for different objects2D motion vs optical flowOn a une sphere en train de tourner sans illumination: dans le flux video, il nâ€™y a pas de difference.Prenons ensuite une sphere dont la source lumineuse bouge: lâ€™information visuelle changera. The observed of apparent 2D motion is called optical flowOptical flow equation and ambiguity in motion estimation Imaginons une sequence video $\\psi(x,y,t)$ On image un point $(x,y)$ deplace en $(x+d_x,y+d_y)$ au temps $t+d_t$ Under the constant intensity assumption, the images of the same object point at different times have the same luminance value \\(\\psi(x+d_x,y+d_y,t+d_t)=\\psi(x,y,t)\\)On fait un developpement de Taylor:\\[\\psi(x+d_x,y+d_y,t+d_t)=\\psi(x,y,t)+\\frac{\\partial\\psi}{\\partial x}d_x+\\frac{\\partial\\psi}{\\partial y}d_y+\\frac{\\partial\\psi}{\\partial t}d_t\\]On obtient:\\[\\frac{\\partial\\psi}{\\partial x}d_x+\\frac{\\partial\\psi}{\\partial y}d_y+\\frac{\\partial\\psi}{\\partial t}d_t = 0\\]Definisson $v_x=\\frac{d_x}{d_t}$, $v_y=\\frac{d_y}{d_t}$, $v_t=\\frac{d_xt}{d_t}=1$\\[\\frac{\\partial\\psi}{\\partial x}v_x+\\frac{\\partial\\psi}{\\partial y}v_y+\\frac{\\partial\\psi}{\\partial t} = 0\\]Qui peut etre ecrit:\\[\\nabla\\psi^Tv+\\frac{\\partial\\psi}{\\partial t}=0\\]Avec $\\psi^T$ le gradient spatialThe flow vector $v$ at any point $x$ can be decomposed into 2 orthogonal components:\\[v=v_ne_n+v_te_t\\] As we can observe, when a straight edge moves in the plane, we can only detect the normal $v_n$ of its motion vector !Because $\\nabla\\psi=\\Vert\\nabla\\psi\\Vert e_n$ the optical flow equation can be rewritten as:\\[v_n\\Vert\\nabla\\psi\\Vert+\\frac{\\partial\\psi}{\\partial t}=0\\]Avec $\\Vert\\nabla\\psi\\Vert$ la magnitude du vecteur gradient.Les consequences de ces equations sont: A chaque pixel $x$ We can compute\\[v_n=-\\frac{\\frac{\\partial\\psi}{\\partial t}}{\\Vert\\nabla\\psi\\Vert}\\] This ambuigity in estimationg the motion vector is known as the aperture problem The motion can be estimated uniquely only if the aperture contains at least 2 different gradient directionsGeneral methodologies We consider the ME between 2 given frames, $\\psi(x,y,t_1)$ and $\\psi(x,y,t_2)$ The problem is referred as to as forward motion estimationNotationComment encoder les vecteurs de mouvements ?Ils ne sont pas les memes en fonction de lâ€™espace, il faut les encoder de facon parametrique. Fonction mapping: nouvelle position\\[w(x,a)=x+d(x,a)\\]Avec le parametre $a$ qui encode le mouvement, ca nous donne la nouvelle position.\\[a=[a_1,a_2,\\dots,a_n]^T\\]Motion representationDifferent representations de mouvement.Image b: pixel-based On a un vecteur pour chaque pixel de lâ€™imageImage c: on va la faire en TP On suppose quâ€™on fait un decoupage par bloc On fait un vecteur de mouvement par blocPour le champ de vecteur, comment est-ce quâ€™on parametrise ? TranslationsPolynomial motionsRotationsâ€¦ On estime que lâ€™image est faite de pixel et on fait de la pixel-wise Ca fait 2 millions dâ€™inconnues a trouverOn rajoute de la regularite. En general, on decoupe en regions.On estime dâ€™abord le mouvement ou une region ?Approche par blocsOn decompose lâ€™image en blocs (ex: pour une image $100\\times100$, en $33\\times 33$) On a des blocs qui vont se superposer car le mouvement nâ€™est pas uniforme Et on sâ€™en fout !On a egalement des coins qui ont bouges. Il faut faire de la descente de gradient Les version les plus simples quâ€™on peut imaginer câ€™est en terme de translation Les blocs sont un bon compromis entre la precision et la complexite It can induce warping effectsMotion esimation criteria Displaced Frame Difference (DFD):\\[E_{DFD}(a)=\\sum_{x\\in\\Lambda}\\vert\\psi_2(w(x,a))-\\psi_1(x)\\vert^p\\] where $\\Lambda$ is the domain of all pixels in $\\psi_1$ and $p$ a positive number When $p=1$, the above error is called mean absolute difference (MAD) and when $p=2$ Mean Squared Error (MSE) The error image $e(x,a)=\\psi_2(w(x,a))-\\psi_1(x)$ is usually called displaced frame difference (DFD) image When $a$ is optimal ($p=2$)\\[\\frac{\\partial E_{DFD}}{\\partial a}=2\\sum_{x\\in\\Lambda}(\\psi_2(w(x,a))-\\psi_1(x))\\frac{d(w(x,a))}{da}\\nabla\\psi_2(w(x,a))=0\\]Prenons un cas plus simple\\[\\frac{\\partial\\psi}{\\partial t}d_t=\\psi_2(x)-\\psi_1(x)\\]It is equivalent to minimize:\\[E_{flow}=\\sum_{x\\in\\Lambda}\\vert\\nabla\\psi_1(x)^Td(x,a)+\\psi_2(x)-\\psi_1(x)\\vert^p\\]This solution verifies when $p=2$\\[\\frac{\\partial E_{flow}}{\\partial a}=2\\sum_{x\\in\\Lambda}(\\nabla\\psi_1(x)^Td(x,a)+\\psi_2(x)-\\psi_1(x))\\frac{\\partial d(x,a)}{da}\\nabla\\psi_i(x)\\]We can add a penalty term in our equation to enforce the smoothness of our vector field (i.e. must vary smoothly)\\[E_s=\\sum_{x\\in\\Lambda}\\sum_{y\\in N_x}\\Vert d(x,a)-d(y,a)\\Vert^2\\]We want to minimize:\\[E_{total}=E_{DFD}+w_sE_s\\]with $w$ the weighting coefficient. We have to regularize but not too much (to avoid over-blurring)Minimzation methodsOn va surtout regarder la methode exhaustive La methode de gradient La methode de Newton-Raphson Avec la descente de gradient et le probleme de dimensionnalite, on tombe souvent sur des minimums locaux et non globaux One important search strategy is to use a multi-resolution representation of the motion field and conduct the search in a hierarchical manner The basic idea is to first search the motion parameters in a coarse resolution, propagate this solution into a finer resolution, and then refine the solution in the finer resolution It can combat the slowness of exhaustive search methodsRegularization\\[E=\\sum_{x\\in\\Lambda}(\\frac{\\partial\\psi}{\\partial x}v_x+\\frac{\\partial\\psi}{\\partial y}+\\frac{\\partial\\psi}{\\partial t})^2 + w_s(\\Vert\\nabla v_x\\Vert^2+ \\Vert\\nabla v_y\\Vert^2)\\]Block matching algorithm (BMA) Les blocs peuvent etre de forme polygonale On prend en pratique des carres On suppose quâ€™on fait de la translationThe Exhaustive Search Block Matching Algorithm (EBMA)Under the block-wise translation model\\[w(x;a) = x+d_{m}\\quad x\\in B_m\\]Then the error can be written:\\[E(d_m,\\forall m\\in\\mathcal M)=\\sum_{m\\in\\mathcal M}\\sum_{x\\in B_m}\\vert\\psi_2 (x+d_m)-\\psi_1(x)\\vert^p\\]We can estimate the MV for each block individually\\[E_m(d_m)=\\sum_{x\\in B_m}\\vert\\psi_2 (x+d_m)-\\psi_1(x)\\vert^p\\]Deformable block matching algorithm\\[d_m(x)=\\sum_{k=1}^K\\Phi_{m,k}(x)d_{m,k}\\quad x\\in B_m\\]Le deplacement au bloc $m$ de $x$ est une somme ponderee des deplacements en 4 coinsNode-based motion representation Nodal MVs vs Polynomial coefficients Nodal Stabilite Motion estimation using node-based model\\[a=[d_k;k\\in\\mathcal K]\\]\\[E(a)=\\sum_{x\\in B}(\\psi_2(w(x,a))-\\psi_1(x))^2\\]where:\\[w(x,a)=x+\\sum_{k\\in\\mathcal K}\\phi_k(x)d_k\\]Mesh-based motion estimation Dans le cas des blocs: estime independants et deformes Mesh: maillage sur lâ€™image et on se permet de les deplacer en meme temps Tout est corrole Contrainte a connaitre: on ne veut pas que nos 2 carres sâ€™inversent On a souvent des discontinuetes au niveau des edges Plus on augmente le nombre de noeuds, plus on a une estimation precise Mais la puissance de calcul explose Global motion estimationPlusieurs methodes existentEst-ce quâ€™on est dans le cadre ou pas dâ€™avoir uniquement la camera qui bouge ? Au foot et tennis, une grande partie du decor est stableRegion-based motion estimationEst-ce quâ€™on separe en region ou on estime le mouvement ?3 approches possiblesMulti-resolution motion estimation Various ME approaches can be reduced to solving an error minimization problem Major difficulties Many local minima in the gradient-descent case Not easy to reach the global minimum Computation high Pyramide laplacienne: on decompose lâ€™image en bandes de frequence" }, { "title": "IMED2: X-Ray Imaging", "url": "/cours/posts/imed2_x_ray/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-20 09:00:00 +0200", "snippet": "Basic conceptsExponential BehaviorExponential Decay/Growth:\\[\\frac{\\delta N}{\\delta t} = \\pm\\lambda\\]X-Ray ProductionCoolidge Tube High-voltage Generator for heating ($U_h$) and cathode/anode ($U_a$) Filaments is heated and gives off electrons Electrons are accelerated from cathode to anode Electrons collide with the anode material and accelerate other electrons About $1\\%$ of the energy generated is emitted as X-Rays Tourner lâ€™anode genere de la chaleurInteraction with Anode MaterialBremsstrahlungComplex model depending on: Path of electron in the target Change in direction at each interaction Change of ionization and radiation loss Direction of emission of the bremsstrahlung Attenuation and scattering inside the targetThin to thick target emission model:\\[I(E)=\\underbrace{C}_{\\text{constant}}\\cdot \\underbrace{Z}_{\\text{atomic number}}\\cdot (\\underbrace{E_{max}}_{\\text{energy of the} \\\\ \\text{bombarding} \\\\ \\text{electron}}-E)\\]Emitted SpectraPour un tungstene:X-Ray Interaction with MatterX-Ray photon life span: Photon is transmitted through the matter Photon is absorbed (end of life) Photon is scattered ($E_{new}\\le E$)If $E_{new}\\gt0$, then more 1, 2 or 3Photoelectric AbsorptionInteraction with an electron of the K, L, M, â€¦ atomic shell All energy is absorbed Ejects an photoelectronÂ Â» ionizing radiation Vacancy is filled from a electron of a higher shell Produces either characteristic radiation (fluroescence) or an â€œAuger electronâ€Probability of occurrence (or cross-section):\\[\\sigma_{photon}\\propto \\frac{Z^3}{E\\text{^}3}\\]Compton (Incoherent Scatter)Interaction with free electrons (outer shell): Part of photon energy is transferred to the electron (ionization) Photon is deflected with a certain angle and new energy $E_{new}\\lt E$ Energy loss depends on the scattering angle (energy conservation law) Scatter angle ($\\theta$) decreases with photon energy ($E$)Probability of occurenece (or cross-section) Almost independant of $Z$ &amp;amp; decreases with $E$ Energy conservation\\[\\frac{E}{E_{new}}=\\frac{E}{m_ec^2}(1-\\cos(\\theta))\\] Klein-Nishina coefficient\\[\\sigma_{compton}=f_{K-N}(E,\\theta)\\]Rayleigh (Coherent Scatter)Electromagnetic wave resonance: The incident electric wave makes electrons to oscillate in phase and emit radiation Energy is conserved $E_{new}=E$ Photon is deflected with a certain angle Scatter angle $\\theta$ decreases with photon energy $(E)$Probability of occurence (or cross-section): Mainly for large $Z$ Decreases rapidly with $E$ Atomic Form Factor (AFF)\\[\\sigma_{rayleigh}-f_{AFF}(E,\\theta)\\]Total attenuation\\[\\delta I = -\\sigma\\cdot\\rho\\cdot I_0\\cdot\\Delta T\\]Total Attenuation Cross Section, $\\sigma$ $[cm^2/g]$\\[\\sigma(E)=\\sigma_{photo}(E)+\\sigma_{compton}(E)+\\sigma_{rayleigh}(E)+\\dots\\]Linear Attenuation Coefficient, $\\mu$ $[cm^{-1}]$\\[\\begin{aligned}\\mu(E)=\\sigma(E)\\cdot\\rho &amp;amp;\\text{for a single atom}\\\\(\\frac{\\mu}{\\rho})(E)=\\sum_Z w_z\\cdot(\\frac{\\mu}{\\rho})_Z&amp;amp;\\text{for all atoms}\\end{aligned}\\]X-Ray DetectionPrimary X-ray imagePhotographic Film &amp;amp; Phosphor PlatesSolid State Detectors: Indirect DetectionSummary\\[Signal(i)=\\underbrace{k}_{\\text{Gain}}\\int\\underbrace{\\xi(E)}_{\\text{detector technology}}\\underbrace{\\eta(E)}_{\\text{efficiency}}\\biggr[\\underbrace{G}_{\\text{grid}}\\cdot I_{scatter}(E,i)+I_0(E,i)\\cdot e^{-\\int\\color{red}{\\mu}(E)\\cdot dl}\\biggr]dE\\]OverviewWhat characterizes an Imaging System ? Tube output (spectra, power) Beam geometry (narrow or wide beam) Detector technology (integration, electronics, â€¦) 2D vs 3D imagingWhat system Design vs Imaging Target ? Spatil resolution for specific diagnostic value Radiation dose vs image noisDigital Image FormationProjection ImageDisregarding scatter &amp;amp; non-idealities:\\[\\text{Object signal}(i) = k\\int\\biggr[E\\cdot I_0(E,i)\\cdot e^{-\\int\\mu(E)\\cdot dl}\\biggr]dE\\\\\\text{Air signal}(i)=k\\int E\\cdot I_0(E,i)dE\\]Image formation:\\[\\begin{aligned}\\text{Image}(i)&amp;amp;=-\\color{red}{\\log}(\\frac{\\text{Signal}(i)}{\\text{Air Signal}(i)})\\end{aligned}\\]3D ReconstructionProjection (Mono-E):\\[\\rho(\\beta, t)=\\int_{L_{i-s}}\\mu(x,y)dl\\]If $l=x\\cos(\\beta)+y\\sin(\\beta)$ then we have the Radon tranform Numeric Approximation (Filtered Back Projection, FPB)\\[\\mu(x,y)=\\frac{\\Delta\\beta}{2\\pi}\\sum_{\\beta}\\underbrace{w(\\beta, t)}_{\\text{weight} \\\\ \\text{(e.g. beam geometry)}}\\cdot(\\underbrace{h(t)}_{\\text{high-pass filter} \\\\ \\text{e.g., } H(f)=\\vert f\\vert} * p(\\beta, t))\\] Optimization problem (Iterative Recon)\\[\\text{arg}\\min_{\\mu(x,y)}\\Vert p(\\beta, t)\\underbrace{R}_{\\text{projection matrix with }w(\\beta,t) \\\\ \\text{(e.g. beam geometry)}}\\cdot\\mu(x,y)\\Vert\\]Practical IssuesBeam quantity and qualityBeam HardeningAnti-scatter gridsImage NoiseQuantum noise: Discrete nature of photon production (â€œrain dropsâ€) Visible effects when Nb of particles are small Poisson distribution (Gaussian for large numbers)\\[\\mathcal P\\{k\\}=P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}\\\\SNR=\\frac{\\text{Av. Signal}}{\\text{noise}}=\\frac{N}{\\sqrt{N}}\\]\\[Signal(i)=k\\int E\\cdot\\mathcal P\\{\\eta(E)I(E\\}dE+\\mathcal N(\\sigma)\\]Modulation Transfer Function (MTF)\\[Mt=\\frac{\\text{Modulation of Output Signal}}{\\text{Modulation of Input Signal}} = \\frac{M_o(f)}{M_i(f)} = Fct(f)\\]Imaging System OptimizationNoise Power Spectrum (NPS)System PerformanceImaging Systems &amp;amp; ApplicationsMammographySpectral mammographyOn trouve un rassemblement de beaucoup de vaisseaux montres par lâ€™iode, etant une indication dâ€™un cancer.Chest X-RayComputed TomographyWrap-upX-ray physics X-ray production: Coolidge Tube, Bremsstrahlung, Characterisics X-Rays Interaction with matter: photoelectric, compton, Rayleigh X-ray detectors: films, image intensifiers, solid state detectorsRadiology Image formation Image quality 3D reconstruction Clinical application examples" }, { "title": "PRSTA: TD 3", "url": "/cours/posts/prsta_td3/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-14 14:00:00 +0200", "snippet": "Lien de la note HackmdFeuille 3 Exercice 1La variable aleatoire $X$ suit une loi $N(0, \\sigma^2)$ avec $\\sigma \\gt 0$.Nous etudierons le test $H_0 : \\sigma^2 = \\sigma^2_0$ contre $H_1 : \\sigma^2 = \\sigma_2^1$ avec $0 \\lt \\sigma_0 \\lt \\sigma_1$. Determiner la statistique de Neyman-Pearson que nous noterons $T_n$. Determiner $\\alpha$ en fonction du seuil du test. Determiner $\\beta$ en fonction du seuil du test. Determiner les courbes COR associees a ce test. Solution\\[\\begin{aligned}T&amp;amp;=\\frac{\\Pi_{i=1}^nf(X_i,\\sigma_1)}{\\Pi_{i=1}^nf(X_i,\\sigma_0)}\\\\&amp;amp;= \\frac{\\Pi_{i=1}^n\\frac{1}{\\sigma_1\\sqrt{2\\pi}}\\exp(\\frac{-X_i^2}{2\\sigma_1^2})}{\\Pi_{i=1}^n\\frac{1}{\\sigma_0\\sqrt{2\\pi}}\\exp(\\frac{-X_i^2}{2\\sigma_0^2})}\\\\&amp;amp;=(\\frac{\\sigma_0}{\\sigma_1})^n\\exp(-\\frac{1}{2}\\sum_{i=1}^nX_i^2(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2}))\\end{aligned}\\\\\\begin{aligned}\\ln(T)&amp;amp;=\\underbrace{n\\ln(\\frac{\\sigma_0}{\\sigma_1})}_{\\color{green}{a}}-\\frac{1}{2}\\sum_{i=1}^nX_i^2\\underbrace{(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})}_{\\color{green}{b}}\\\\&amp;amp;= a-\\frac{b}{2}\\sum_{i=1}^nX_i^2\\end{aligned}\\] Dâ€™apres le lemme de Neyman-Pearson: Lâ€™hypothese $H_0$ est rejetee lorsque:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln(T)&amp;amp;\\gt\\ln(C_{\\alpha})\\\\a-\\frac{b}{2}\\sum_{i=1}^nX_i^2&amp;amp;\\gt\\ln(C_{\\alpha})\\\\\\sum_{i=1}^nX_i^2&amp;amp;\\gt-\\frac{2}{b}(\\ln(C_{\\alpha}) - a)\\end{aligned}\\\\\\color{red}{\\boxed{\\sum_{i=1}^nX_i^2\\gt S_{\\alpha}}}\\\\T_n=\\sum_{i=1}^nX_i^2\\] On cherche $\\alpha$ et $\\beta$:\\[\\begin{aligned}\\alpha&amp;amp;= P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;=P(\\sum X_i^2\\gt S_{\\alpha}\\vert\\sigma=\\sigma_0)\\\\&amp;amp;=P(\\frac{T_n}{\\sigma_0^2}\\gt\\frac{S_{\\alpha}}{\\sigma_0^2})\\end{aligned}\\] Les variables aleatoires sont normales centrees et independantes donc\\[W_n:=\\frac{T_n}{\\sigma_0^2}\\sim\\chi_2(n)\\\\\\alpha=P(W_n\\gt\\frac{S_{\\alpha}}{\\sigma_0^2})\\] On prend $\\alpha=0.05$ et $n=33$\\[\\frac{S_{\\alpha}}{\\sigma_0^2}\\simeq 47,40\\] chi2.ppf(0.95, 33)chi2.isf(0.05, 33) s comme survie\\[\\alpha=1-F_N\\biggr(\\frac{S_{\\alpha}}{\\sigma_0^2}\\biggr)\\\\F_N\\biggr(\\frac{S_{\\alpha}}{\\sigma_0^2}\\biggr) = 1-\\alpha\\\\\\frac{S_{\\alpha}}{\\sigma_0^2} = F_N^{-1}(1-\\alpha)\\\\\\color{red}{\\boxed{S_{\\alpha}=\\sigma_0^2F_N^{-1}(1-\\alpha)}}\\]\\[\\begin{aligned}\\beta&amp;amp;=P(\\text{Accepte H_0}\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(T_n\\le S_{\\alpha}\\vert\\sigma^2=\\sigma_1^2)\\end{aligned}\\] Sous lâ€™hypothese $H_1$: $W_nâ€™:=\\frac{T_n}{\\sigma_1^2}\\sim\\chi^2(n)$\\[\\begin{aligned}\\beta &amp;amp;= P(W_n&#39;\\le\\frac{S_{\\alpha}}{\\sigma_1^2})\\\\&amp;amp;= F_n(\\frac{S_{\\alpha}}{\\sigma_1^2})\\\\\\end{aligned}\\\\\\color{red}{\\boxed{\\beta = F_n\\biggr(\\frac{\\sigma_0^2F_n^{-1}(1-\\alpha)}{\\sigma_1^2}\\biggr)}}\\]Feuille 3 Exercice 3La variable aleatoire $X$ suit une loi geometrique de parametre $p$. A lâ€™aide du theoreme de Wilks, ecrire la zone de rejet du test $H_0 : p = 0, 25$ contre $H_1 : p = 0, 5$. Solution Dâ€™apres le theoreme de Wilks,\\[R_n=2\\log(T_n)\\sim\\chi^2(1)\\\\\\{R_n\\gt 3,84\\}\\] Il suffit dâ€™expliciter en $R_n$ Il suffit dâ€™expliciter $R_n$\\[\\begin{aligned}T_n&amp;amp;=\\frac{L(X_1,\\dots,X_n,0.5)}{L(X_1,\\dots,X_n,0.25)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n0.5\\times(1-0.5)^{X_i-1}}{\\prod_{i=1}^n0.25\\times(1-0.25)^{X_i-1}}\\\\&amp;amp;= 2^n\\times\\prod_{i=1}^n\\biggr(\\frac{0.5}{0.75}\\biggr)^{X_i-1}\\\\&amp;amp;= 2^n\\times\\prod_{i=1}^n\\biggr(\\frac{2}{3}\\biggr)\\\\&amp;amp;= 2^n\\times\\biggr(\\frac{2}{3}\\biggr)^{\\sum_{i=1}^n(X_i-1)}\\end{aligned}\\] Passons au logarithme neperien:\\[\\ln(T_n)=n\\ln(2)+\\ln\\biggr(\\frac{2}{3}\\biggr)\\sum_{i=1}^n(X_i-1)\\\\\\begin{aligned}R_n&amp;amp;=2\\ln(T_n)\\\\&amp;amp;= 2(n\\ln(2)+\\ln\\biggr(\\frac{2}{3}\\biggr)\\sum_{i=1}^n(X_i-1))\\end{aligned}\\\\\\alpha = 5\\%\\] Rappel: $R_n$ suit asymptotiquement $\\chi^2(1)$ Zone de rejet:\\[\\{R_n\\gt 3,84\\}\\] On veut resoudre lâ€™equation pour isoler $\\sum_{i=1}^nX_i$\\[\\begin{aligned}2[n\\ln(2)+\\ln(\\frac{2}{3})\\sum_{i=1}^n(X_i-1)]&amp;amp;\\gt3.84\\\\\\ln(\\frac{2}{3})\\sum_{i=1}^n(X_i-1)&amp;amp;\\gt\\frac{3.84}{2}-\\ln(2)\\\\\\sum_{i=1}^nX_i-n&amp;amp;\\lt\\frac{\\frac{3.84}{2}-n\\ln(2)}{ln(\\frac{2}{3})}\\quad\\text{car }\\ln(\\frac{2}{3})\\lt0\\\\\\frac{\\sum_{i=1}^nX_i}{n}&amp;amp;\\lt\\frac{1.92-n\\ln(2)}{n\\ln(\\frac{2}{3})} +1\\\\\\bar X_n&amp;amp;\\lt\\frac{1.92-n\\ln(2)}{n\\ln(\\frac{2}{3})}+1\\end{aligned}\\]" }, { "title": "OCVX2 : Le retour de l&#39;optimisation avec contraintes - Exercices", "url": "/cours/posts/ocvx2_opti_contraintes_retour_exos/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-13 16:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1\\[\\begin{aligned}\\min f(x,y)&amp;amp;=2x+y\\\\\\text{tel que }3x^2+y^2&amp;amp;\\le4\\end{aligned}\\] Solution\\[\\begin{aligned}3x^2+y^2&amp;amp;\\le4\\\\3x^2+y^2-4&amp;amp;\\le0\\\\g(x,y)&amp;amp;=3x^2+y^2-4\\end{aligned}\\\\\\mathscr L(x,y,\\alpha)=2x+y+\\alpha(3x^2+y^2-4)\\\\\\begin{cases}\\frac{\\partial\\mathscr L}{\\partial x}=2+6\\alpha x=0&amp;amp;\\to x=-\\frac{1}{3\\alpha}\\\\\\frac{\\partial \\mathscr L}{\\partial y}=1+2\\alpha y=0&amp;amp;\\to y=-\\frac{1}{2\\alpha}\\end{cases}\\\\\\begin{aligned}\\mathscr L(\\equiv \\theta_D(\\alpha))&amp;amp;=2(-\\frac{1}{3\\alpha})+(-\\frac{1}{2\\alpha}) + \\alpha(3(-\\frac{1}{3\\alpha})^2 + (-\\frac{1}{2\\alpha})^2 - 4)\\\\&amp;amp;= -\\frac{2}{3\\alpha}-\\frac{1}{2\\alpha}+\\alpha(\\frac{1}{3\\alpha^2}+\\frac{1}{4\\alpha^2}-4)\\\\&amp;amp;= -\\frac{1}{3\\alpha}-\\frac{1}{2\\alpha}+\\frac{1}{3\\alpha}+\\frac{1}{4\\alpha}-4\\alpha\\\\&amp;amp;= -\\frac{1}{3\\alpha}-\\frac{1}{4\\alpha}-4\\alpha\\\\&amp;amp;= -\\frac{7}{12\\alpha}-4\\alpha\\end{aligned}\\\\\\begin{aligned}\\nabla_{\\alpha}\\theta_D(\\alpha)&amp;amp;=\\frac{7}{12\\alpha^2}-4=0\\\\&amp;amp;=\\frac{7}{12\\alpha^2}=4\\\\&amp;amp;=\\frac{1}{4}\\frac{7}{12}=\\alpha^2\\\\\\alpha&amp;amp;=\\frac{1}{2}\\sqrt{\\frac{7}{12}}=\\frac{1}{4}\\sqrt{\\frac{7}{3}}\\end{aligned}\\] Autre methode, en utilisant la complementarite:\\[\\begin{aligned}\\alpha^*g(x^*,y^*)&amp;amp;=0\\\\\\alpha^*=(3(-\\frac{1}{3\\alpha^*})+(-\\frac{1}{2\\alpha^*})^2)&amp;amp;=0\\\\\\alpha^*(\\frac{1}{3\\alpha^{*^2}}+\\frac{1}{4\\alpha^{*^2}}-4)&amp;amp;=0\\\\\\frac{1}{3\\alpha^*}+\\frac{1}{4\\alpha^*}-4\\alpha^*&amp;amp;=0\\\\\\frac{7}{12\\alpha^*}&amp;amp;=4\\alpha^*\\\\\\frac{1}{4}\\frac{7}{12}&amp;amp;=\\alpha^{*2}\\\\\\alpha^*&amp;amp;=\\frac{1}{4}\\sqrt{\\frac{7}{3}}\\end{aligned}\\]Exercice 2\\[\\begin{aligned}\\min_{x\\in\\mathbb R^3}&amp;amp;\\frac{1}{2}(x_1^2+x^2_2+x_3^2)\\\\\\text{tel que } &amp;amp;x_1+x_2+2x_3-1=0\\\\&amp;amp;x_1+4x_2+2x_3-3=0\\end{aligned}\\]Sous forme matricielle:\\[\\boxed{\\begin{aligned}\\min &amp;amp;\\frac{1}{2}x^Tx\\\\\\text{tel que } &amp;amp;Ax-b =0\\end{aligned}}\\\\x=\\begin{pmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{pmatrix}\\\\A=\\begin{pmatrix}1&amp;amp;1&amp;amp;2 \\\\ 1&amp;amp;4&amp;amp;2\\end{pmatrix}\\\\b=\\begin{pmatrix}1 \\\\ _3\\end{pmatrix}\\\\\\]Exercice 3$X={S_1,\\dots,S_N}$ avec proba discrete $p_i=\\mathbb P(X=S_i)$ et $\\sum_{i=1}^Np_i=1$. Entropie de Shannon\\[H(\\mathbb P=(p_1,\\dots,p_n))=-\\sum_{i=1}^Np_i\\log_2(p_i)\\\\\\log_2(x)=\\frac{\\ln(x)}{\\ln(2)}\\]La distribution qui maximise lâ€™entropie est la distribution uniforme. Solution On cherche a maximiser\\[H(x)=-\\sum_{i=1}^nx_i\\log_2(x_i)\\quad\\text{pour }x=\\begin{pmatrix}x_1 \\\\ \\vdots \\\\ x_n\\end{pmatrix}\\in\\mathbb R^2\\\\\\text{tel que} \\sum_{i=1}^nx_i=1\\\\\\] On cherche a minimiser\\[-H(x)=\\sum_{i=1}^nx_i\\log_2(x_i)\\\\\\text{tel que }\\sum_{i=1}^nx_i-1=0\\\\\\to h(x)=\\sum_{i=1}^nx_i-1\\quad\\text{affine}\\\\\\begin{aligned}\\mathscr L(x,\\beta)&amp;amp;=-H(x)+\\beta h(x)\\\\&amp;amp;= \\sum_{i=1}^nx_i\\log_2(x_i)+\\beta(\\sum_{i=1}^nx_i-1)\\end{aligned}\\\\\\begin{aligned}\\nabla_x\\mathscr L(x,\\beta)=0&amp;amp;\\Leftrightarrow\\forall i,\\begin{cases}\\frac{\\partial \\mathscr L}{\\partial x_i}=0\\\\\\frac{\\partial\\mathscr L}{\\partial x_i}=\\frac{\\partial}{\\partial x_i}(x_i\\log_2(x_i))+\\beta\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}\\frac{d}{dx}(x\\log_2 x)=\\log_2x+x\\frac{d}{dx}\\log_2x\\\\\\frac{d}{dx}\\log_2x=\\frac{d}{dx}\\frac{\\ln(x)}{\\ln(2)}=\\frac{1}{x\\ln(2)}\\end{cases}\\end{aligned}\\\\\\begin{aligned}\\frac{\\partial \\mathscr L}{\\partial x_i}&amp;amp;=\\frac{\\partial}{\\partial x_i}(x_i\\log_2(x_i))+\\beta\\\\&amp;amp;=\\log_2(x_i)+x_i\\frac{1}{x_i\\ln(2)}+\\beta\\\\&amp;amp;=\\frac{\\ln(x_i)+1}{\\ln(2)}+\\beta=0\\end{aligned}\\\\\\begin{aligned}\\frac{\\ln x_i+1}{\\ln 2}&amp;amp;=-\\beta\\\\\\ln x_i+1&amp;amp;=-\\beta\\ln 2\\\\\\ln x_i &amp;amp;= -\\beta\\ln(2)-1\\\\x_i&amp;amp;=e^{-(\\beta\\ln 2+1)}\\quad\\forall i\\end{aligned}\\] Avec la contrainte:\\[\\begin{aligned}\\sum_{i=1}^nx_i&amp;amp;=1\\\\\\sum_{i=1}e^{-(\\beta\\ln2+1)}&amp;amp;=1\\\\ne^{-(\\beta\\ln 2+1)}&amp;amp;=1\\\\\\underbrace{e^{-(\\beta\\ln 2+1)}}_{x_i}&amp;amp;=\\frac{1}{n}\\end{aligned}\\] La distribution qui maximise lâ€™entropie est donc $x_i=\\frac{1}{n}$ $\\forall i=1\\dots n$ $\\equiv$ distribution uniforme" }, { "title": "IMED2: Introduction", "url": "/cours/posts/imed2_introduction/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-13 16:00:00 +0200", "snippet": "Agenda Introduction to Medical Imaging What is medical imaging ? Roles, Players, Modalities Anatomical vs Functional Imaging Ionizing vs Non-ionizing Radiation Nuclear medicine Basic concepts Tomorrow X-ray Physics Basic concepts X-ray production X-ray interaction with matter X-ray detectors Diagnostic RadiologyGE Healthcare+1800 employees R&amp;amp;D ($35\\%$) Production ($22\\%$) European Center for Maintenance ($16\\%$) Support Functions &amp;amp; Other ($27\\%$)IntroductionA recent history 1895: discory of X-rays, first applications 1958: First gamma camera, Nuclear Medicine 1962: First UV of fetus 1967: First CET head scanner 1972: First head MR scanner 1990: first PET scanner 2000â€™s-2010â€™s: Digital Age IA What is medical imaging ?ProcessRolesPlayersWho are diagnostic imaging customers ? Healthcar systemes, hospitals, and clinics Governmnent officials Pharmaceutical firms Genetics &amp;amp; Bio-science researchersModalities overviewIonizing vs non-ionizing radiationAnatomix vs Functional Imaging ?Contrast Agents Contrast agents are substances used to enhance visibility of internal structures in X-ray or MR-based imaging techniques Iodine-based Injected in the bloodstream to highlight blode vessels Gaolinium-based Vascular ferromagnetic contrast agent visible in MRI Baarium-based orally to help imaging digestive system, including esophagus, stomach and GI tracks Radioisotope Contrast Agents Radioisotope contrast agents are based on atmos with excess nuclear energy, making it unstable. They emit the excess energy to highlight body functions Tc-99m Injected in the bloodstream to study brain, myocardium, thyroid, lungs, liver, gallblader $^{18}$F-FDg Mark the glucose metabolism Nulcear imagingKey componentsNuclear MedicineAnatomical vs Functional ImagingGamma-rays PhysicsBasics ConceptsQuantaAtomic ModelCharacteristic RadiationProduct of electron transistions between 2 electric shells:Two steps: Electrons (or photons) collid with a shell electron, which is removed from orbit Electrons from higher energy shell fills the vacancy and an X-ray photon is emittedExponential BehaviorExponential decay/growth:\\[\\frac{\\Delta N}{\\Delta t}=\\pm\\lambda N\\\\\\text{provided: }\\lambda\\Delta t\\lt\\lt1\\\\\\text{then: } N=N_0e^{\\pm\\lambda\\Delta t}\\]AttenuationZ-ray photon life span: Photon is transmitted through the matter Photon is absorbed (end of life) Photon is scattered ($E_{new}\\le E$)If $E_{new}\\gt0$, then more A, B or CTransmitted photons:\\[I(E)=I_0(E)\\cdot e^{-\\mu(E)\\cdot t}\\quad\\text{Berr-Lambert lawa}\\]Isotopes DecayGlossary: IsotoPes = atoms with the same number of protons (Z) IsotoNes = atoms with the same number of neutrons Nuclides = nuclei with differing numbers of protons and neutrons are called nuclei Radioisotopes = atoms with unstable nuclei Isomeric Transition Nucleus in an excited state returns to the more stable state release of a photon (gamma, $\\sim88\\%$) Sometimes the nucleus energy may eject an electron (ionized radiation $\\sim12\\%$) which deposes radiation dose to the patientExample: $^{99m}{43}Tc\\to^{99}{43}Tc+\\gamma$ Beta-plus decayProton converted to a neutron by releasing positron $(\\beta)+$ and a neutrino Since positron is an antimatter analog Electron captureProton converted to a neutron by capturing an electron and releases a neutrino. It happens in nuclei with too few neutronsSince the electron is removed from the shell, it releases characteristic X-raysSummaryRadiopharmaceuticalsProductionIdeal characteristicsIdeal Characteristics Short-half life (but not too short) Monochromatic Gamma-ray production Gamma-ray energy high enough to easily cross patient body (deposing minimal dose) Gamma-ray energy low enough to be stopped by the detector Have minimal production of other particles (add noise to our measurements) Localize to the organ of interest, non toxic, â€¦ Inexpensive and readily availableTechnetium-99m Close to ideal characteristics Decays with $88\\%$ in emission of 140.5 keV photon $12\\%$ internal conversions (electrons, characteristic x-rays, â€¦)Transport IssuesCommon IsotopesDiagnostic RadiologyInstrumentationGamma Camera Nuclear Imaging $\\Leftrightarrow$ X-ray Imaging Radioctive isotope X-ray tube Collimator Anti-scatter grid Gamma camera X-ray detector Nuclear Medicine detector also measures not only the number of events, but the time and energy of each detected event Ideally imaging is performed from unscattered photons that undergo photoelectric absorption in the detector Scintillator + Electronics must be very fast to detect individual eventsPulse Height Analyzer with Nal CrystalCollimatorsEfficiency Resolution = bar patterns, MTF, FWHM of point source, â€¦ Sensitivity = fraction of gamma rays the pass through the holes (typically $0.01\\%$) Increasing blades/holes length: Res $\\uparrow$, Sen $\\downarrow$ Type (parallel, convergence, â€¦) modulates Res &amp;amp; Sen Increasing blades/holesClinical applicationSingle Photon Emission CTCharacteristics Long decay isotope Single photon emitted and captured by camera Tomography technique generates 3D volume of radioactivity density Multi-head cameras allows for faster acquisitions Poor spatial resolution VS excellent contrast resolution Noise is a major factorReconstruction (same as CT) Filtered Back-Projection Iterative techniquesApplicationsPositron Emission TomographyCharacteristics Positron emitter (F-18) Two 511 kEV annihilation photons $180^o$ apart No collimator neededApplicationWrap-upIsotopes Exponential Decay, half-life Isomeric Transition (Tc-99m), Electronic $\\to$ gamma rays, SPECT Beta-plus (F-18) $\\to$ PET Beta-minus $\\to$ TherapyApplications in medicine Radiopharmaceuticals $\\to$ fission, cyclotron, accelerators, generators Gamma cameras, collimators SPECT, single photon emission (gamma-rays: 70-400 keV) $\\to$ orthopedics PET, positron emission (511 keV) $\\to$ oncology" }, { "title": "OCVX2 : Le retour de l&#39;optimisation avec contraintes", "url": "/cours/posts/ocvx2_opti_contraintes_retour/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-13 14:00:00 +0200", "snippet": "Lien de la note Hackmd But Resoudre:\\[\\begin{matrix}(OPT)&amp;amp;\\text{minimiser } f(x)&amp;amp; \\\\\\text{tel que} &amp;amp;g_i(x)\\le0&amp;amp;i=1,\\dots,m\\\\&amp;amp;h_j(x)=0&amp;amp;j=1,\\dots,p\\end{matrix}\\]Avec $f, g_i$ convexes et $h_j$ affines$p^{*}=$ valeur optimale $=f(x^{*})$ point optimal avec\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto f(x)\\end{aligned}\\]$x$ est admissible ssi il verifie les contraintes Lagrangien de (OPT):\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta)=f(x)+\\sum_{i=1}^n\\alpha_ig_i(x)+\\sum_{j=i}^p\\beta_jh_j(x)\\end{aligned}\\\\\\begin{aligned}\\alpha\\in\\mathbb R^m\\\\\\beta\\in\\mathbb R^p\\end{aligned}\\biggr\\}\\text{variables duales/multiplicateurs de Lagrange}\\]Fonction primale et probleme primalFonction objective primale:\\[\\theta_p(x)=\\max_{\\alpha,\\beta \\\\ \\alpha\\ge0\\Leftrightarrow \\alpha_i\\ge0\\forall i}\\mathscr L(x,\\alpha,\\beta)\\]et probleme primal $(Q)$ \\(\\min_x\\theta_p(x)\\) $x$ est primal admissible ssi $g_i(x)\\le0$ $\\forall i$ $h_j(x)=0$ $\\forall j$ $x^{*}$ primal optimal et $p^{*}=\\theta_p(x^{*})$ valeur optimaleDans le cas ou on a une seule contrainte $g(x)\\le0$ et une seule contrainte $h(x)=0$\\[\\mathscr L(x,\\alpha,\\beta)=f(x)+\\alpha g(x)+\\beta h(x)\\\\\\begin{aligned}\\underbrace{\\theta_p(x)}_{\\text{fonction convexe}}&amp;amp;=\\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0}\\mathscr L(x,\\alpha,\\beta)\\\\&amp;amp;=\\max_{\\alpha, \\beta \\\\ \\alpha\\ge 0}[f(x)+\\alpha g(x)+\\beta h(x)]\\\\&amp;amp;= f(x) + \\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}[\\alpha g(x)+\\beta h(x)]\\end{aligned}\\] $g(x)\\gt0\\to\\alpha=+\\infty$ $h(x)\\neq0, \\beta=signe(h(x))\\infty$ $g(x)\\le0\\to\\alpha=0$ $h(x)=0,$ peu importe $\\beta$ \\[\\theta_p(x)=f(x)+\\begin{cases}0 &amp;amp;\\text{si } g(x)\\le0 \\text{ et } h(x)=0\\\\+\\infty &amp;amp;\\text{sinon}\\end{cases}\\\\\\Leftrightarrow x\\text{ primal admissible}\\]$y=x^2$:\\[\\begin{aligned}\\min f(x)&amp;amp;=\\infty^2\\\\x+1&amp;amp;\\le0\\end{aligned}\\]$\\color{red}{\\boxed{}}$ : lieu des points primaux admissibleFonction duale et probleme dualFonction objective duale \\(\\theta_D(\\alpha,\\beta)=\\min_x\\mathscr L(x,\\alpha,\\beta)\\)et probleme dual \\((D) \\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}\\theta_D(\\alpha,\\beta)\\) $(\\alpha, \\beta)$ dual admissible ssi $\\alpha\\le0$ ($\\alpha_i\\ge0$ $\\forall i$)$(\\alpha^{*}, \\beta^{*})$ dual optimal ssi solution de $(D)$ et $d^{*}=\\theta_D(\\alpha^{*},\\beta^{*})$\\[\\begin{aligned}\\underbrace{\\theta_D(\\alpha,\\beta)}_{\\text{fonction concave}} &amp;amp;=\\min_x\\mathscr L(x,\\alpha,\\beta)\\\\&amp;amp;= \\min_x[\\underbrace{f(x)+\\alpha g(x)+\\beta h(x)}_{\\text{affine (a } x \\text{) fixe relativement a }\\alpha\\text{ et }\\beta\\text{ et }\\min(\\text{fcts concaves}) = \\text{fct concave}}]\\end{aligned}\\] Lemme Si $(\\alpha,\\beta) \\ \\alpha\\ge0$ dual admissible, $\\theta_D(\\alpha,\\beta)\\le p^{*}$Preuve\\[\\begin{aligned}\\theta_D(\\alpha, \\beta) &amp;amp;=\\min_x\\mathscr L(x, \\alpha, \\beta)\\\\&amp;amp;\\le\\mathscr L(x^*,\\alpha,\\beta)=f(x^*)+\\underbrace{\\overbrace{\\alpha}^{\\ge0}\\overbrace{g(x^*)}^{\\le0}}_{\\le0} + \\overbrace{\\beta h(x^*)}^{=0}\\quad\\begin{matrix}\\text{avec }x^*\\text{ primal optimal} \\\\ \\to g(x^*)\\le0\\text{ et } h(x^*)=0\\end{matrix}\\\\&amp;amp;\\le f(x^*)=p^*\\end{aligned}\\] Toutes les valeurs du probleme dual minorent la valeur optimale du probleme primalProbleme dual \\(\\to\\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}\\theta_D(\\alpha,\\beta)=d^*\\le p^*\\to p^*-d^*\\ge0\\) saut de dualite Câ€™est le principe de dualite faible: vrai pour tout probleme primal et dualOn aimerait ici que le saut de dualite $p^*-d^*$ soit egaux a $0\\to p^*=d^*$ On peut resoudre le primal en resolvant le dualOn a cherche les conditions (â€œqualifications de contraintesâ€) pour que $p^*=d^*$.Dans le cas ou tout est convexe: Condition de SlaterLe saut de dualite est nul sâ€™il existe un $\\tilde x$ qui est srictement admissible $(g(\\tilde x)\\lt0)\\Leftrightarrow$ lâ€™ensemble admissible doit avoir un point interieur Lemme (complementarite)Si la dualite forte est verifiee, on a $\\boxed{\\alpha^{*}g(x^{*})=0}$ Si on a plusieurs contraintes, $\\alpha^{*}_ig_i(x^{*})=0$ $\\forall i$ PreuveDualite forte:\\[\\begin{aligned}p^{*}=d^{*}&amp;amp;=\\theta_D(\\alpha^{*},\\beta^{*})\\\\&amp;amp;= \\min_x\\mathscr L(x,\\alpha^{*},\\beta^{*})\\\\&amp;amp;\\le\\mathscr L(x^*,\\alpha^*,\\beta^*)=\\underbrace{f(x^*)}_{p^*}+\\underbrace{\\overbrace{\\alpha^*}^{\\ge0}\\overbrace{g(x^*)}^{\\le0}}_{\\le0}+\\overbrace{\\beta^*\\underbrace{h(x^*)}_{=0}}^{=0}\\end{aligned}\\\\p^*\\le p^*+\\underbrace{\\alpha^*g(x^*)}_{\\le0}\\to\\alpha^*+g(x^*)=0\\\\\\begin{cases}\\alpha^*\\gt0&amp;amp;\\to g(x^*)=0\\\\g(x^*)\\lt0&amp;amp;\\to\\alpha^*=0\\end{cases}\\]Conditions de Karush-Kuhn-Tucker (KKT pour les intimes) Conditions KKT Conditions necessaires pour la resolution de (OPT):\\[\\begin{matrix}(OPT)&amp;amp;\\text{minimiser } f(x)&amp;amp; \\\\\\text{tel que} &amp;amp;g_i(x)\\le0&amp;amp;i=1,\\dots,m\\\\&amp;amp;h_j(x)=0&amp;amp;j=1,\\dots,p\\end{matrix}\\]Soient $x^{*}\\in\\mathbb R^n$, $\\alpha^{*}\\in\\mathbb R^m$ et $\\beta^{*}\\in\\mathbb R^p$ satisfait les conditions: Stationnarite de $\\mathscr L$: \\(\\nabla_x\\mathscr L(x^*,\\alpha^*,\\beta^*)=\\nabla_x f(x^*)+\\sum_{i=1}^n\\alpha_i^*\\nabla_x g_i(x^*)+\\sum_{j=1}^p\\beta_j^*\\nabla_x h_j(x^*)=0\\) Admissibilite primale: $g_i(x^{*})\\le0$ $\\forall i$ et $h_j(x^{*})=0$ $\\forall j$ Admissibilite duale: $\\alpha_i^{*}\\ge0$ $\\forall i$ Complementarite: $\\alpha_i^{*}g_i(x^{*})=0$ $\\forall i$Alors $x^{*}$ est optimal pour le probleme primal, et $(\\alpha^{*}, \\beta^{*})$ optimal pour le dual.Si de plus la dualite forte est verifiee, alors nâ€™importe quelles solutions du primal et du dual verifient $1)-4)$En pratiqueComment on sâ€™en sort ? On ecrit le Lagrangien $\\mathscr L(x,\\alpha,\\beta)$ et on calcule $\\nabla_x\\mathscr L(x,\\alpha,\\beta)$ On utilise la stationnarite $\\nabla_x\\mathscr L(x,\\alpha,\\beta)=0$ pour trouver une relation entre $x$ et $\\alpha/\\beta$ On remplace $x$ par $\\alpha/\\beta$ dans le Lagrangien $\\to$ ecrire la fonction objective duale On resout le dual, eventuellement en se servant de la complementariteExemple\\[\\begin{aligned}\\min_{x\\in\\mathbb R^2}&amp;amp;\\frac{1}{2}(x_1^2+x_2^2)\\\\\\text{tel que }&amp;amp;\\underbrace{x_1-2x_2+2}_{g(x_1,x_2)}\\le0\\end{aligned}\\] \\[\\mathscr L(x,x_2,\\alpha_2)=\\frac{1}{2}(x_1^2+x_2^2)+\\alpha(x_1-2x_2+2)\\] \\[\\begin{aligned}\\nabla_x\\mathscr L = 0 &amp;amp;\\to \\frac{\\partial\\mathscr L}{\\partial x_1}=x_1+\\alpha=0\\to x_1=-\\alpha \\\\ &amp;amp;\\frac{\\partial \\mathscr L}{\\partial x_2} = x_2-2\\alpha=0\\to x_2=2\\alpha\\end{aligned}\\] \\[\\begin{aligned}\\mathscr L(\\alpha)(\\equiv\\theta_D(\\alpha))&amp;amp;=\\frac{1}{2}\\biggr((-\\alpha^2)+(2\\alpha)^2\\biggr) + \\alpha(-\\alpha-4\\alpha+2) \\\\ &amp;amp;= \\frac{5}{2}\\alpha^2-5\\alpha^2+2\\alpha \\\\ &amp;amp;=-\\frac{5}{2}\\alpha^2+2\\alpha\\end{aligned}\\] On resout\\[\\begin{aligned}\\max_{\\alpha\\ge0}\\theta_{D}(\\alpha)\\to\\nabla_{\\alpha}\\theta_D(\\alpha)&amp;amp;=-5\\alpha+2 = 0 \\\\\\alpha^*&amp;amp;=\\frac{2}{5}\\to x_1^*=-\\frac{2}{5}\\text{ et } x_2^*=\\frac{4}{5}\\end{aligned}\\]" }, { "title": "EPIQUANTI : Architecture d&#39;un ordinateur quantique et technologies habilitantes", "url": "/cours/posts/epiquanti_architecture/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-12 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du cours La correction dâ€™erreur â€œnormaleâ€ est tres differente de celle de lâ€™informatique quantiqueQEC ZooEnvoyer un Qubit Principe general Shor 9 error correction codeSurface code QEC QEC adapted to 2D bit architectures like with superconductors from Google Au-dessus de 20 qubits, on a trop dâ€™erreursAlissonBob, Amazon et UCI pretendent pouvoir reduire le nombre de qubits physiques necessaires pour faire des calculs.More on quantum computing speedQuand on fait une operation de portes sur des qubits intriques, câ€™est comme si on faisait cette operation sur plusieurs etats.On va prendre une porte de Hadamard: on a une vingtaine dâ€™operations.Or, dâ€™apres IBM, comme le calcul quantique est probabiliste il faut lâ€™executer plusieurs fois, cad $4000$ fois. $4000\\times20=80 000$ portes executees pour juste une porte de Hadamard ! Et câ€™est un cas simple De meme, pour les autres portes: On veut corriger le taux dâ€™erreur pour utiliser le moins de qubits physiques possibleQubits connectivityIBMRocheser 53 qubits, october 201965 qubits, october 2020GoogleSycamore 53 qubits, october 2019Pourquoi un qubit blanc ? Parce quâ€™il marche pas ptdrIonQ Cas particulier des ions piegesIls sont tous connectes les uns aux autres 11 qubits, 2018â€œRackabilityâ€ examplesPasqualDouble depth racks Model of cold atoms computer with $100-100$ qubits, planned for $2021-2023$QuandelaSingle depth rack PrometheusData center constraintsCombien est-ce que ca consomme dans un data center ? Je sais pas / ca depend[name=Olivier Ezratty] [time=Tue, Oct 12, 2021 4:50 PM] [color=#907bf7]Ca depend du nombre de rackCooling Goal: reduce thermal noise affecting qubitsMicro-waves sources Chaque fils supra-conducteur coute $3000$$Details from a 15 mK cryostatSome companiesDilutions and systems Finland Bluefors IBM Rigetti CEA US: JanisULT Google UK: Oxford instruments Microsoft DWave France: CryoConcept Neel LPENS Netherlands: Leiden Cryogenics IBM Cabling Japan Coax Co. LTD Netherlands Delft Circuits France Radiall Pulse tubes and compressors US Cryomech Japan Sumitomo Available cooling power Cryostat pulse tubes minimum temperature 20mK stage 100 mK stage MC cold plate Bluefors lD250 XLF400 XLD1000 1 2 2 10mk 8 mK 8 mK $12\\mu$ W $12\\mu$ W $34\\mu$ W $250\\mu$ W $450\\mu$ W $1000\\mu$ W IBMGoldeneye fridge designed for 1121 qubits Condor completion planned for 2023.5 and 14 days to cool down.design shown is not fake Cabling paths shows they will use some sort of cryoCMOS using separate pulse tubes to and bottom" }, { "title": "PRSTA: Seance 3", "url": "/cours/posts/prsta_seance3/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-06 14:00:00 +0200", "snippet": "Lien de la note HackmdExemple $H_0:m=m_0$ contre $H_1:m=m_1$ ou $X$ suit une loi $\\mathcal N(m,1)$ et $m_0\\le m_1$ A. N.: $m_0=1$ et $m_1=2$ Calculer $\\alpha$ Calculer $\\beta$ Solution Determiner la statistique de NP\\[\\begin{aligned}\\frac{L(X_1,\\dots,X_n,2)}{L(X_1,\\dots,X_n,1)} &amp;amp;= \\frac{\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(X_i-2)^2}{2}}}{\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(X_i-1)^2}{2}}}\\\\&amp;amp;= e^{\\frac{1}{2}[-\\sum X_i^2-4X_i+4+\\sum X_i^2-2X_i+1]}\\\\&amp;amp;= e^{\\frac{1}{2}\\sum_{i=1}^n(1X_i-3)}\\\\&amp;amp;=e^{\\sum_{i=1}^nX_i}\\times \\underbrace{e^{-\\frac{3n}{2}}}_{\\color{red}{c}}\\end{aligned}\\] Passons au log\\[\\log(T)=\\sum_{i=1}^nX_i+\\log(\\color{red}{c})\\] Lâ€™hypothese $H_0$ est rejetee lorsque\\[\\begin{aligned}T&amp;amp;\\gt S_{\\alpha}\\\\\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\sum X_i+\\log(c)&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\end{aligned}\\\\\\color{red}{\\boxed{\\sum X_i\\gt\\log(S_\\alpha)-\\log(c)}}\\\\\\sum X_i\\gt C_{\\alpha}\\] On veut calculer $\\alpha$:\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\sum X_i\\gt C_{\\alpha}\\vert m=1)\\end{aligned}\\] On veut se ramener a la loi centree-reduite:\\[\\begin{aligned}\\alpha&amp;amp;=P(\\underbrace{\\frac{\\sum X_i}{n}}_{\\color{green}{\\bar X_n}}\\gt\\frac{C_{\\alpha}}{n}\\vert m=1)\\\\&amp;amp;= P(\\bar X_n\\gt\\frac{C_{\\alpha}}{n}\\vert m=1)\\\\&amp;amp;= P(\\sqrt{n}(\\bar X_n-1)\\gt\\frac{\\sqrt{n}(C_{\\alpha}-1)}{n})\\end{aligned}\\] Sous lâ€™hypothese $H_0$: $Z_n=\\sqrt{n}(\\bar X_n-1)\\sim\\mathcal N(0,1)$ Par definition, quâ€™est-ce que ce nombre ? On rejette combien a droite ? Câ€™est un quantile au niveau $1-\\alpha$ \\[\\sqrt{n}(\\frac{C_{\\alpha}}{n}-1)=Z_{1-\\alpha}\\] ou $Z_{1-\\alpha}$ designe le quantile de $\\mathcal N(0,1)$ au niveau $1-\\alpha$. Maintenant on veut exprimer $\\beta$. De quoi on a besoin pour determiner $\\beta$ ?\\[\\begin{aligned}\\beta &amp;amp;= P(\\text{Accepter } H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(\\sum X_i\\le C_{\\alpha}\\vert m=2)\\end{aligned}\\] On veut exprimer $C_{\\alpha}$ en fonction de $Z_{1-\\alpha}$.\\[\\begin{aligned}\\sqrt{n}(\\frac{C_{\\alpha}}{n}-1)&amp;amp;=Z_{1-\\alpha}\\\\\\frac{C_{alpha}}{n}-1&amp;amp;=\\frac{Z_{1-\\alpha}}{\\sqrt{n}}\\\\\\frac{C_{\\alpha}}{n}=\\frac{Z_{1-\\alpha}}{\\sqrt{n}}+1\\\\\\end{aligned}\\\\\\color{red}{\\boxed{C_{\\alpha}=n\\biggr(\\frac{Z_{1-\\alpha}}{\\sqrt{n}}+1\\biggr)=\\sqrt{n}Z_{1-\\alpha}+n}}\\] Avant de continuer, essayons de trouver $C_{\\alpha}$ dans le cas ou $\\alpha=1\\%$ et dans le cas ou $\\alpha=5\\%$ Avant de calculer $\\beta$, on trouve les $C_{\\alpha}$.\\[\\begin{matrix}\\alpha=5\\%&amp;amp;C_{\\alpha}=1,64\\sqrt{n}+n\\\\\\alpha=1\\%&amp;amp;C_{\\alpha}=2,33\\sqrt{n}+n\\end{matrix}\\] Si $n=100$, $\\alpha=1\\%$, alors $C_{\\alpha}=123,3$ et pour $\\alpha=5\\%$, $C_{\\alpha}=116,4$. Maintenant on peut calculer $\\beta$.\\[\\begin{aligned}\\beta&amp;amp;=P(\\text{Ne pas rejeter } H_0\\vert H_0\\vert \\text{ fausse})\\\\&amp;amp;=P(\\sum X_i\\lt C_{\\alpha}\\vert m=2)\\\\&amp;amp;=P(\\bar X_n\\lt\\frac{C_{\\alpha}}{n}\\vert m=2)\\\\&amp;amp;=P(\\sqrt{n}(\\bar X_n-2)\\lt\\sqrt{n}(\\frac{C_{\\alpha}}{n}-2)\\vert m=2)\\\\\\end{aligned}\\] Sous lâ€™hypothese $(H_1)$\\[Z_n=\\sqrt{n}(\\bar X_n-2)\\sim\\mathcal N(0,1)\\\\\\color{red}{\\boxed{\\beta=P(Z_n\\lt\\sqrt{n}(\\frac{C_\\alpha}{n}-2))}}\\] Pour $\\alpha=5\\%$ et $n=100$:\\[\\begin{aligned}\\sqrt{n}(\\frac{C_{\\alpha}}{n}-2)&amp;amp;=10(1,164-2)\\\\&amp;amp;=-8,36\\end{aligned}\\\\\\beta=P(Z_n\\lt-8,36)=3\\times10^{-17}\\] scipy.stats.norm.cdf(-8.36) norm: loi normale cdf: cumulative distribution function Pourquoi $\\beta$ est aussi petit ? Parce que $\\alpha$ est tres grand par rapport a $n$ Faisons la meme chose pour $n=25$ et $\\alpha=1\\%$Test du rapport de vraisemblance generalise (GLR) $H_0:\\theta\\in A$ contre $H_1:\\theta\\in B$ $T=\\frac{L(X_1,\\dots,X_n\\hat\\theta_1^{MV})}{L(X_1,\\dots,X_n\\hat\\theta_0^{MV})}$ $T=\\frac{\\sup_{\\theta\\in B}L(X_1,\\dots,X_n\\theta)}{\\sup_{\\theta\\in A}L(X_1,\\dots,X_n\\theta)}$ Rejet de $(H_0)$ ssi $T\\gt S_{\\alpha}$ ou $S_{\\alpha}$ est un seuil qui depend du niveau de confiance de $\\alpha$ Comment on le traduit ? $H_0:m\\in{0}$$H_1:m\\in\\mathbb R\\setminus{0}$Test de comparaison de 2 moyennes Deux populations Deux echantillons independants suffisamment grand $(X_1,\\dots,X_{n_1})$ et $(Y_1,\\dots,Y_{n_1})$ Statistique\\[Z=\\frac{\\bar X_{n_1}-\\bar Y_{n_2}}{\\sqrt{(\\frac{S^2_{n+1}}{n_1}+\\frac{S^2_{n_2}}{n_2})}}\\] $H_0:m_1=m_2$ contre $H_1:m_1\\neq m_2$ $H_0:m_1=m_2$ contre $H_1:m_1\\gt m_2$ $H_0:m_1=m_2$ contre $H_1:m_1\\lt m_2$Principe de Neyman Pearson Determination dâ€™un model statistique Determination dâ€™hypotheses Determination dâ€™une statistique de test Determination de la forme de la region critique Determination des valeurs critiques Conclusion: rejet ou non de lâ€™hypothese Calcul de la puissance du test Hypotheses simples $H_0:\\theta=\\theta_0$ $H_1:\\theta=\\theta_1$ExemplePremier exempleLa variable aleatoire $X$ suit une loi $\\mathcal N(m,1)$. Nous voulons tester $H_0:m=0$ contre $H_1:m\\neq0$ Solution Quâ€™est-ce que le maximum de vraisemblance ? Câ€™est ce qui maximise la fonction de vraisemblance en fonction de $\\theta$ Maximum de vraisemblance pour une loi normale ?\\[L(x_1,\\dots,x_n,m)=\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x_i-m)^2}{2}}\\] Il nâ€™y a pas de $\\sigma$ car $\\sigma=1$\\[L(x_1,\\dots,x_n,m)=\\Pi_{i=1}^n\\frac{1}{\\color{red}{\\sigma}\\sqrt{2\\pi}}e^{-\\frac{(x_i-m)^2}{2\\color{red}{\\sigma^2}}}\\] On a une fonction $f\\Rightarrow\\log(fâ€™)$? Prenons un exemple:\\[\\begin{aligned}f(x) &amp;amp;= x^2-2x\\\\f&#39;(x)&amp;amp;=2x-2\\\\\\log(f&#39;(x))&amp;amp;=\\log(2x-2)\\\\\\log(f&#39;(x))=0&amp;amp;\\Leftrightarrow2x-2=1\\\\&amp;amp;\\Leftrightarrow \\color{red}{\\boxed{x=\\frac{3}{2}}}\\\\\\end{aligned}\\\\\\begin{aligned}f(x)&amp;amp;=x^2-2x\\\\\\log(f(x))&amp;amp;=\\log(x^2-2x)\\\\(\\log(f(x)))&#39;&amp;amp;=\\frac{2x-2}{x^2-1}\\\\(\\log(f(x)))&#39;=0&amp;amp;\\Leftrightarrow\\color{red}{\\boxed{x=1}}\\end{aligned}\\] Ce nâ€™est pas le meme resultat La formule du maximum de vraisemblance est:\\[T=\\frac{L(X_1,\\dots,X_n,\\hat\\theta)}{L(X_1,\\dots,X_n,\\theta_0)}\\] Avec $\\hat\\theta$ lâ€™estimateur du maximum de vraisemblance de $\\theta$. On cherche $\\bar X$.\\[\\begin{aligned}T&amp;amp;=\\frac{L(X_1,\\dots,X_n,\\bar X)}{L(X_1,\\dots,X_n,0)}\\quad \\text{car }m=0\\\\&amp;amp;= e^{-\\frac{1}{2}[\\sum_{i=1}^n(X_i-\\bar X)^2-\\sum_{i=1}^nX_i^2]}\\\\&amp;amp;=e^{-\\frac{1}{2}[e\\sum_{i=1}^nX_i+n\\bar X^2]}\\\\&amp;amp;=e^{-\\sum_{i=1}^nX_i-\\frac{n}{2}\\bar X^2}\\end{aligned}\\\\\\log(T)=-\\sum X_i-\\frac{n}{2}\\bar X^2\\] $(H_0)$ rejetee $\\color{red}{si}$ $T\\gt S_{\\alpha}$\\[\\begin{aligned}\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\-\\sum X_i-\\frac{n\\bar X^2}{2}&amp;amp;\\gt \\log(S_{\\alpha})\\\\\\sum_{i=1}^nX_i+\\frac{n\\bar X^2}{2}&amp;amp;\\lt\\log(S_{\\alpha})\\end{aligned}\\] PropositionSous des hypotheses techniques, en notant $\\hat\\theta_n$ lâ€™estimateur du maximum de vraisemblance. $\\sqrt{nI(\\theta_0(\\hat\\theta_n\\theta_0))}$ converge en loi vers $\\mathcal N(0,1)$ Nous dirons que lâ€™estimateur du maximum de vraisemblance est normal asymptotiquement efficace ou NAE. Nous supposerons que les hypotheses techniques evoquees sont verifiees. Theoreme de WilksSous lâ€™hypothese $H_0$, $R_n:=2\\log(T_n)$ converge en loi vers une loi $\\chi^2(1)$ En revenant a nos calculs: \\(2\\biggr(\\sum_{i=1}^nX_i+n\\bar X^2\\biggr)\\sim\\chi^2(1)\\)Second exemple La variable aleatoire $X$ suit une loi $\\varepsilon(\\lambda)$ $H_0:\\lambda=1$ contre $H_1:\\lambda\\gt1$" }, { "title": "EPIQUANTI : Partie logiciel", "url": "/cours/posts/epiquanti_logiciel/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-05 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursRegisters n bits register n qubits register $\\color{red}{2^n\\text{ possible states } \\textbf{once at a time}}$ $\\color{green}{ 2^n \\text{possible states }\\textbf{linearly superposed}}$ evaluable partially evaluable independant copies no copies individually erasable non individualy erasable non destructive readout value changed after readout deterministic probabilistic GatesClassical logic gatesIrreversible gates: NAND NOR AND ORQuelle est leur consequence ? Comme on perd un bit, on a une perte dâ€™energieDecouverte par Rolf Landauer Des gens travaillent aujourdâ€™hui pour creer une informatique classique sans perte dâ€™energieQuantum gates Matrix based reversible unitary transformations NOT: rotation $X$ Rotation $Y$\\[\\begin{bmatrix}0&amp;amp;-i\\\\i&amp;amp;0\\end{bmatrix}\\] Pauli-Z: rotation $Z$ Hadamard: superpositionPorte CNOT On va changer la valeur dâ€™un qubit en fonction dâ€™un autre Mathematiquement, a quoi ca ressemble ?\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\end{bmatrix}\\]Si on intrique des qubits a des portes a 2 qubits, est-ce que ca reste ? OuiC2NOT\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\end{bmatrix}\\]SWAP\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1\\end{bmatrix}\\]Fredkin Conditional SWAP\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\]Single qubit operations visualizationCNOT gate effect\\[\\begin{matrix}\\color{blue}{\\text{control qubit}} &amp;amp;&amp;amp;\\color{blue}{\\text{tensor product of control and target qubits before CNOT}}\\\\\\alpha_1\\vert0\\rangle &amp;amp;&amp;amp;\\alpha_1\\alpha_1\\vert00\\rangle+\\alpha_1\\beta_2\\vert01\\rangle + \\alpha_2\\beta_1\\vert10\\rangle+\\beta_1\\beta_2\\vert11\\rangle\\\\\\bigotimes&amp;amp;\\Rightarrow&amp;amp;\\text{CNOT}\\\\\\alpha_2\\vert0\\rangle+\\beta_2\\vert1\\rangle&amp;amp;&amp;amp;\\alpha_1\\alpha_1\\vert00\\rangle+\\alpha_1\\beta_2\\vert01\\rangle + \\alpha_2\\beta_1\\vert11\\rangle+\\beta_1\\beta_2\\vert10\\rangle\\\\\\color{blue}{\\text{target qubit}}&amp;amp;&amp;amp;\\color{blue}{\\text{control and target qubits state after CNOT}}\\\\\\color{blue}{\\text{control qubit is }\\vert0\\rangle}\\\\\\alpha_1=1&amp;amp;&amp;amp;\\alpha_2\\vert00\\rangle+\\beta_2\\vert01\\rangle\\\\&amp;amp;\\Rightarrow&amp;amp;\\text{CNOT}\\\\\\beta_1=0&amp;amp;&amp;amp;\\alpha_2\\vert00\\rangle+\\beta_2\\vert01\\rangle\\\\\\end{matrix}\\] CNOT is not changing the qubitThe EPR pair entanglemet building blockPut control qubit into superposition state, then future gates act on 2 states simultaneously\\[\\frac{\\vert0\\rangle+\\vert1\\rangle}{\\sqrt 2}\\] \\(\\biggr\\}\\frac{\\vert00\\rangle+\\vert11\\rangle}{\\sqrt{2}}\\)Subsenquently, flipping a qubit in an entangled state modifies all of tis componentsControl-U gateOn prend une porte U qui est une porte arbitraire\\[\\begin{bmatrix}1&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots\\\\\\dots&amp;amp;1&amp;amp;\\dots&amp;amp;\\dots\\\\\\dots&amp;amp;\\dots&amp;amp;U_{11}&amp;amp;U_{12}\\\\\\dots&amp;amp;\\dots&amp;amp;U_{21}&amp;amp;U_{22}\\end{bmatrix}\\]Qubit lifecycle Initialization $\\vert0\\rangle$ Hadamard gate $\\frac{\\vert0\\rangle + \\vert1\\rangle}{\\sqrt{2}}$ Other gate aubit vector turning around in Bloch sphere Measurement Measurement returns $\\vert 0\\rangle$ qith a probability $\\alpha^2$ depending on the qubit state, then qubit state becomes $\\vert0\\rangle$ Measurement returns $\\vert1\\rangle$ with a probability $\\beta^2$ Universal gates sets Jeu de portes universelJeu de portes simples quâ€™on peut combiner pour recreer toutes les transformations unitaires Ex: CNOT peut etre recree avec HZHThree CNOT gates: one SWAP gate Universal quantum computing requires a T gate ($\\frac{\\pi}{4}$ rotation)Getting confused with phase rotations One round = $2\\pi$ $S=$ one quarter round $=\\frac{\\pi}{2}$ $T=$ one eight roungSolovay-Kitaev theorem Theorem Any desired gate can be approximated by a sequence of gates from an universal gates set. A quantum circuit of $m$ constant-qubit gates can be approximated to $\\varepsilon$ error by a quantum circuit of $O(m\\log^c(\\frac{m}{\\varepsilon}))$ gates from a desired finite universal gate set with $c=3,97$ For example, creating a $R_{15}$ gate requires $127$ H/Z/T gatesIn other words On veut appliquer a $n$ qubits nâ€™importe quelle operation generique $U$, on enchaine une serie de transformations unitaires.$SU(2^n)$ - Space of unitaries on $n$ qubits Espace contenant toutes les transformationsOn reversibility All quantum gates are mathematically reversible, this is a property of the matrix linear transformations We could theortically run an algorithm and rewinf it entirely to return to the initial state, which could help recover port of the energy spent in the systemOn a practical basis: The gates are not physically and thermodynamically reversible due to some irreversible processes like micro-wave generations and DACs (digital analog converters) The whole digital process taking place before micro-wave generation and after their readout conversion back to digital could be implemented in classical adiabatic\\thermodynamically reversible fashion Currently being investigated at Sandia Labs, Wisconsin University and with SeeQCInputs and outputsProbabilistic or deterministic readouts ? A single qubit measurement is probabilistic, ie: a qubit registered after a Hadamard gate applied to all qubits is a simple random numbers generatorOn a practical basis: the algorithm is executed many times, up to 8000 for IBM Q Experience an average of qubits results is computed, producing a real number the averahed result is theoratically deterministic modulo the error generated by noise and decoherenceBasis, pure and mixed statesExamples Normalement vous avez rien compris[name=Olivier Ezratty] [time=Tue, Oct 5, 2021 3:55 PM] [color=#907bf7] Lâ€™origine aleatoire du photon provient de la physique classique et non quantiqueSingle qubit mixed stateToying with density matricesQubits measurement Measurement is using a collection ${M_m}$ of operators acting on the measured system state space $\\vert\\psi\\rangle$, with probability of $m$ being:\\[p(m)=\\langle\\psi\\vert M_m^âœM+m\\vert\\psi\\rangle\\]System state after measurement becomes:\\[\\frac{M_m\\vert\\psi\\rangle}{\\sqrt{\\langle\\psi\\vert M_m^âœM+m\\vert\\psi\\rangle}}\\]with:\\[\\sum_mM_m^âœM+m=1\\]Various qubits measurement methodsComputing semantics summary5 DiVienzo criteria (IBM, 2000)Main qubit typesFrom lab to packaged computersLes ordinateurs quantiques actuels dâ€™IBM:Lâ€™ordinateur version commerciale: Il y a un cube derriere qui contient lâ€™ordinateurIBM pense atteindre $1000$ qubits dâ€™ici 2 ans, mais ca a pas trop lâ€™air possible car au-dessus de $28$ qubits il y a une enorme perte de qualite.Inside a typical quantum computerEn resume: 4 composantesAvec des atomes froids, on nâ€™aurait pas des compresseurs mais des pompes a ultra-vide.Chez GooglePourquoi les fils tournent ? Pour passer plus de temps dans le froid ? Systeme de dilatation thermique du au changement de temperature hardcore Refroidit: contracte Rechauffement: dilate Pourquoi plusieurs etages ? On est a $300K$ a lâ€™exterieur, on veut minimiser plusieurs pochesChaque etage = une temperatureChaque disque a une taille plus petite en descendant les etages, pour faire passer le moins de chaleur possibleChaque etage est isole de celui au-dessusLes fils sont des attenuateurs de puissance mais ils generent de la chaleur Câ€™est lâ€™isolation thermiqueQuantum computer architecturePhysical layout exampleError correction Each quantum gate and readout generate significant errorsComing form decoherence generated by: flip, phase and leakage error calibration errors thermal noise electric and magnetic noise gravity radioactivty vacuum quantum fluctuations cosmical rays It accumulates with the number of quantum gates and qubitsQEC zoo" }, { "title": "CMKV: Implementation d&#39;algorithme", "url": "/cours/posts/cmkv_algorithme/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-30 09:00:00 +0200", "snippet": "Lien de la note Hackmd\\[T_{t+1}\\leftarrow T_{t+1}\\times\\alpha\\] Evaluation : projetLâ€™algorithmeOn fait une marche alÃ©atoireT_âˆ… &amp;lt;- ?loop i_cond &amp;lt;- ? tirageOn tire un $x_{candidat}$, on preserve tous les $x\\neq x_{candidat}$\\(x=(x_1^{(t)},\\dots,\\color{blue}{x_{candidat}}, x_{candidat+1}^{(t)}, x_{N}^{(t)})\\)Au lieu de changer touT le vecteur, on ne change quâ€™une valeure (le $x_{candidat}$), lâ€™algorithme convergera plus vite\\[\\begin{matrix}&amp;amp;x_{candidat}=(&amp;amp;\\text{idem},&amp;amp;\\boxed{i_{random}},&amp;amp;\\text{idem},&amp;amp;\\boxed{i_{random}},&amp;amp;\\text{idem})\\\\&amp;amp;&amp;amp;\\updownarrow &amp;amp;\\searrow&amp;amp;\\updownarrow&amp;amp;\\swarrow&amp;amp;\\updownarrow\\\\&amp;amp;&amp;amp;&amp;amp;\\nearrow&amp;amp;&amp;amp;\\nwarrow&amp;amp;\\\\&amp;amp;x^{(t)} = (&amp;amp; &amp;amp;\\boxed{} &amp;amp; &amp;amp;\\boxed{} &amp;amp;)\\end{matrix}\\]Comment choisir alpha ? On le prend trÃ¨s proche de 1Algorithme de descente - principe : parcourir toutes les variables Et pour chacunes des variables on parcourt toutes les valeurs possibles et on minimise lâ€™energie (U) : Ca converge forcement mais ca converge vers un minimum local (et câ€™est pas ce quâ€™on cherche)\\[x^{(t+1)}=(\\text{arg}\\min_{\\omega_1\\in\\Omega_1}U(\\omega_1,x_2^{(t)}), x_2^{(t)})\\quad\\text{var #}1\\\\x^{(t+2)}=(x_1^{(t+1)}, \\text{arg}\\min_{\\omega_2\\in\\Omega_2}U(\\omega_2,x_2^{(t+1)}))\\quad\\text{var #}2\\\\\\]Ici, la solution (le x que lâ€™on retient) est le x tel que $U_{courant} = min$ Tour statistique : si jâ€™itere 1million de fois,câ€™est sur que jâ€™ai parcouru toutes mes variablesâˆ loop Umin pour toutes les variables ... descente Ucourant si Ucourant = Umin conv. or sinon Umin = UcourantNotre algo nâ€™est PAS une descente, câ€™est un optimiseur ! (On cherche minimum global, pas local)\\[P_{T_{\\varnothing}}=\\lim_{T\\to\\infty}P_T\\\\\\]Loi alÃ©atoire avec une marche uniforme : câ€™est le CHAOSComment on choisi $T_0$ ?On prend une grande et une petite valeur de temperature et on fait une dichotomie. On mesure le nombre de fois ou on a monte et descendu en energie, ces mesure doivent etre equivalentes.Si on a une temperature trop faible ?Alors ce nâ€™est pas une loi uniforme.$â€”â€“&amp;gt;T$ Plus T Ã©levÃ©e (on va vers la droite) plus on se rapproche dâ€™une loi uniforme\\[\\begin{matrix}T_{min} &amp;amp;T_{cherche} &amp;amp;T_{max}\\\\&amp;amp;\\equiv&amp;amp;\\\\&amp;amp;\\text{uniforme}&amp;amp;\\end{matrix}\\]Si $T_{min}$ et $T_{max}$ loi uniforme alors on est trop a droite. Inversement, on sera trop Ã  gauche. On veut donc : $T_{max}$ grand et $T_{min}$ petit mais pas trop.Comment on fait la dichotomie ?Il ne faut pas uniforme ou pas uniforme, il faut du suffisemment uniforme.RecapOn cherche $T_0$ tq $P(T_0)$ suit une loi suffisemment uniformeIl faut donc prendre un $T_{min}$ et $T_{max}$ avec une loi pas uniforme pour le min et uniforme pour le max.On fait donc une dichotomie qui nous ramenera a 2 lois suffisemment uniforme pour trouver le $T_0$Peu de montÃ©es par rapport aux descentes Ã©nergÃ©tiques $=$ on convergeSi je nâ€™arrive pu Ã  monter alors je suis proche de ma solutionComment on optimise des tirages aleatoires ?Ou\\[i_{\\text{candidat swap }1}\\quad i_{\\text{candidat swap }2}\\] On les precalcule Le precalcul a un biais On va utiliser un tableau circulaire.loop icandidat &amp;lt;- aleatoire Câ€™est pas possible, on aura des valeurs enormesOn a un tableau de valeurs $x_{candidat}$ de longueur $L$: $\\dots$ $a_i$ $\\dots$ Â  Â  Â  $L$ est tres grand et nombre premierOn va faire un damier, $x^{(t)}=$ $1$ $11$ $2$ $12$ $3$ $13$ $4$ $14$ $5$ $15$ $6$ $16$ $7$ Â  $8$ Â  $9$ Â  $10$ Â  Par exemple, $4$ depend des valeurs qui lâ€™entoure: Â  $11\\updownarrow$ Â  $13\\leftrightarrow$ $4$ $\\leftrightarrow14$ Â  $16\\updownarrow$ Â  \\[P_T(X=x)=\\frac{1}{Z_T}e^{-\\frac{U(x)}{\\color{blue}{T}}}\\] Propriete MarkovienneLa probabilite dâ€™avoir $X^i=(x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n) = X\\setminus X_i$\\[P(X_i=x_i\\vert X^i=x^i) = P(X_i=x_i\\vert X_{\\nu_i}=x_{\\nu_i})\\]\\[X_{\\nu_i}=(X_{\\nu_1^i},\\dots,X_{\\nu_w^i})\\] $\\nu_i$: voisinnage de $i$ Le voisinnage dâ€™un graphe complet dâ€™un noeud câ€™est tous les noeuds sauf lui-meme\\[\\to \\overbrace{X_{t-2}\\to \\underbrace{X_{t-1}\\to X_t}_{P(X_t=x_t\\vert X_{t-1}=x_{t-1})}}^{\\color{blue}{P(X_t\\vert X_{t-2})}}\\]La propriÃ©tÃ© Markovienne est Ã©quivalente Ã  celle des chaines de Markov\\[\\mathcal N(e)\\text{ verifie}\\begin{cases}e\\not\\in \\mathcal N(e)\\\\e\\in\\mathcal N(e&#39;)\\Rightarrow e&#39;\\in\\mathcal N(e)\\end{cases}\\] CliqueCâ€™est un ensemble de sommets qui sont voisins soit:\\[E=\\{\\dots e_i\\dots\\}\\begin{cases}E\\neq\\emptyset\\\\\\text{et}\\\\\\forall e,e&#39;\\in E,e\\mathcal N e&#39;\\\\\\text{ou}\\\\\\bar E=1\\end{cases}\\] $e\\mathcal N eâ€™$: $e$ et $eâ€™$ sont voisinsE est un ensemble de sommet 2 Ã  2 voisinsun singleton est une clique, on dit que câ€™est une clique dâ€™ordre 1Une clique dâ€™ordre n câ€™est un ensemble de n sommet 2 a 2 voisins4 ord 14 ord 21 ord 3----9Un graphe complet que lâ€™on reduit aux voisins permet de reduire la dependance des variables.\\[P(X=x)=\\Pi_{\\text{c clique}}\\phi(x_c)\\] $\\phi(x_c)$: fonction potentiel pour la clique $c$Toujours vrai si $\\not\\exists x, P(X=x)=\\varnothing$\\[\\begin{aligned}P(X=x)&amp;amp;=\\frac{1}{Z}e^{-U(x)}\\\\&amp;amp;= \\frac{1}{Z}e^{-\\sum_{c}E_c(x_c)}\\end{aligned}\\] Avec $U_c=\\phi_c$ fonction potentielle pour la clique $c$Modele graphique qui est un champs de Gibbs ? On doit definir les fonctions $U_c$ et $\\phi_c$, avec:\\[U(x)=\\sum_{c}U_c(x_c)\\]$\\bar c$: ordre de la cliqueExempleSur une image en niveau de gris\\[P(X=x\\vert Y=y)=e^{-\\sum_cU_c(x_c,y)}\\]$X_i$ depend de $X_{i+1}$, $X_{i-1}$, $X_{i+nc}$, $X_{i-nc}$ProbabilitÃ© Ã©quiprobable -&amp;gt; U vaut 0on a une vraissemblance quand on melange X et Y\\(L(X=x_i|Y=y_i) \\text{ proportionnelle Ã  } e^{-U_{L}(x_i,y_i)}\\)Avec $U_L(â€¦)$ une clique dâ€™ordre 2\\[U(X_i=\\underbrace{x_i}_{\\text{ordre }1})=\\frac{1}{2}\\\\U_1(\\underbrace{\\text{noir}}_{\\text{dans }x})=\\frac{1}{2}\\\\U_1(\\text{blanc})=\\frac{1}{2}\\quad\\forall\\text{ probabilite}\\]\\[U_2(\\underbrace{x_i,x_j}_{\\text{ordre }2} = 1_{x_i\\neq x_j})\\]Avec $i$ et $j$: voisins independantsDefinissons $U_L$\\[U_L(x_i,y_i) = \\begin{cases}255-y_i&amp;amp;\\text{si } x_i=\\text{blanc et } j\\text{ voisins et inde}\\\\y_i&amp;amp;\\text{sinon}\\end{cases}\\]Tadaaa commande magique :clap: :clap: :cake: :cactus: :call_me_hand: :jack_o_lantern: :cat: :heart:\\[\\begin{aligned}U(x,y)&amp;amp;=\\sum_cU_c(x_c,y)\\\\&amp;amp;=\\sum_iU_1(x_i)+\\overbrace{\\sum_{i,j_{voisins}}U_2(x_i,x_j)}^{\\sum_i\\sum_{j\\in\\mathcal N(i)}U_2(x_i,x_j)}+\\sum_iU_2(x_i,y_i)\\\\&amp;amp;= \\sum_i\\biggr(\\overbrace{U_2(x_i,y_i)}^{\\color{blue}{L(X\\vert Y)}}+\\overbrace{\\underbrace{U_1(x_i)}_{\\text{ordre } 1}+\\underbrace{\\sum_{j\\in\\mathbb N(i)}U_2(x_i,x_i)}_{\\text{ordre } 2}}^{P_{(\\text{a priori})}}\\biggr)\\\\\\Rightarrow U(x,y)&amp;amp;=\\sum_iU_i(x_i,x_{\\nu_i},y_i)\\end{aligned}\\]Les Ã©nergies sont liÃ©es au proba P appriori = P sachant â€¦Produit de P = Somme U (Car exp)" }, { "title": "PRSTA: TD 2", "url": "/cours/posts/prsta_td2/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-29 15:00:00 +0200", "snippet": "Lien de la note HackmdExercice 9On etudie une grandeur suivant une loi normale $\\mathcal N (m, 1)$. Nous disposons de deux observations issues de variables aleatoires independantes $X_1$ et $X_2$ et souhaitons tester $H_0 : m = 0$ contre $H_1 : m = 1$ et prendre une decision avec un risque de premiere espece $\\alpha = 5\\%$. Considerons la regle de de decision : Rejeter $H_0$ si $X_1 + X_2 \\gt k$. Quelle loi suit $X_1 + X_2$ sous lâ€™hypothese $H_0$ ? En deduire la valeur de $k$ sachant que $\\alpha = 5\\%$. Determiner la region critique du test et representer la graphiquement. Calculer le risque de seconde espece $\\beta$ et la puissance du test. Considerons un autre test defini par la regle de decision : Rejeter $H_0$ si $\\min(X_1, X_2) \\gt l$. DÂ´eterminer la valeur l sachant que $\\alpha = 5\\%$. DÂ´eterminer la region critique et representer la graphiquement. Calculer le risque de seconde espece $\\beta$ et la puissance du test. Solution 1. $X_1$ suit $\\mathcal N(m,1)$ et $X_2$ suit $\\mathcal N(m,1)$, on a $X_1$ indÃ©pendant Ã  $X_2$ donc $X_1 + X_2$ suit $\\mathcal N(2m,2)$. 2.\\[\\alpha=P(\\underbrace{\\text{rejeter } H_0}_{\\color{red}{X_1+X_2\\gt k}} \\vert \\underbrace{H_{0} \\text{ vraie}}_{\\color{red}{X_1+X_2\\sim\\mathcal N(2m,2)}})\\\\\\color{red}{\\begin{aligned}V(X_1+X_2) &amp;amp;= E((X_1+X_2)^2)\\\\&amp;amp;= E(X_1^2)+E(X_2^2) + 2E(X_1X_2)\\\\&amp;amp;= \\color{black}{\\boxed{\\color{red}{2}}} + \\underbrace{2E(X_1)E(X_2)}_{\\color{black}{=0}}\\end{aligned}}\\] \\[\\color{red}{\\begin{aligned}\\alpha&amp;amp;= P(\\text{rejeter } H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(X_1+X_2\\gt k\\vert X_1+X_2\\sim\\mathcal N(0,2))\\\\&amp;amp;= P(\\frac{X_1+X_2}{\\sqrt{2}}\\gt\\frac{k}{\\sqrt{2}}\\vert X_1+X_2\\sim\\mathcal N(0,2))\\end{aligned}}\\] Sous lâ€™hypothese $(H_0)$\\[\\frac{X_1+X_2}{\\sqrt{2}}\\sim\\mathcal N(0,1)\\\\0,05 =\\alpha=P(U\\gt\\frac{k}{\\sqrt{2}})\\]\\[\\frac{k}{\\sqrt(2)} = 1.64 \\text{ (par la table normale on cherche 0.95)} \\\\\\text{Donc, } k = 2.32\\] 3. On cherche la rÃ©gion critique tq on rejette $H_0$ soit $X_1 + X_2 \\gt 2.32$\\[\\{(x_1,x_2)\\in\\mathbb R^2\\vert x_1+x_2\\gt 2.32\\}\\] Quâ€™est-ce quâ€™on fait en premier ? On ouvre Geogebra xdd Comme en ocvx, on trace eq1: $x_1 + x_2 - 2.32 = 0$ 4. Rappel : Risque de second espece : $H_1$ soit vrai alors quâ€™on garde $H_0$On veut donc $X_1 + X_2 \\le k = 2.32$ et $X_1$ et $X_2$ suivent $\\mathcal N(m=1,1)$On cherche donc $\\beta = P(\\text{accepter} H_0 | H_1 vraie)$ \\(\\beta = P(X_1+X_2\\le k\\vert m=1)\\\\\\frac{X_1+X_2-2}{\\sqrt{2}}\\sim\\mathcal N(0,1)\\quad\\text{sou l&#39;hypothese } H_1\\)\\(\\begin{aligned}\\beta&amp;amp;=P(U\\le\\frac{k-2}{\\sqrt{2}})\\\\&amp;amp;=P(U\\le0.23)\\\\&amp;amp;=0.59\\end{aligned}\\\\\\color{green}{\\boxed{\\beta\\simeq 0.59}}\\) On a fait une erreur majeure du point de vue modelisation: on a prit un $\\alpha$ trop petit La puissance de test est $1-0.59=\\boxed{0.41}$ 2Ã¨me partie 1.\\(\\begin{aligned}\\alpha&amp;amp;=P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\min(X_1,X_2)\\gt l\\vert m=0)\\\\&amp;amp;= P(\\{X_1\\gt l\\}\\cap\\{X_1\\gt l\\}\\vert m=0)\\\\&amp;amp;= P(U\\gt l)^2 \\quad\\text{ou } U\\sim\\mathcal N(0,1)\\text{ car } X_1 \\text{ et } X_2\\sim\\mathcal N(0,1)\\end{aligned}\\\\\\color{red}{0.05 = P(U\\gt l)^2\\\\P(U\\gt l)=\\sqrt{0.05}\\simeq 0.22}\\) Donc, dâ€™apres la table:\\[l\\simeq0.77\\] 2.\\[\\{(X_1,X_2)\\in\\mathbb R^2\\vert\\min(X_1,X_2)\\gt 0.77\\}\\] 3. On a un probleme: $P(\\min(X_1,X_2)\\le l)$\\[\\begin{aligned}\\beta&amp;amp;= P(\\text{Accepter }H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(\\min(X_1,X_2)\\le l\\vert H_1\\text{ vraie})\\\\&amp;amp;= 1-P(\\min(X_1,X_2)\\gt l\\vert H_1\\text{ vraie})\\end{aligned}\\]\\[color{red}{\\begin{aligned}\\beta&amp;amp;= 1-P(\\{X_1\\gt l\\}\\cap \\{X_2\\gt l\\}\\vert H_1\\text{ vraie})\\\\&amp;amp;= 1-P(X_1\\gt l\\vert H_1\\text{ vraie})^2\\quad X_1\\text{ et } X_2 \\sim\\mathcal N(1,1)\\end{aligned}}\\] Sous $(H_1)$, $X_1$ et $X_2$ suivent une loi $\\mathcal N(1,1)$ Donc $U=X_1-1\\sim\\mathcal N(0,1)$ sous $(H_1)$ \\(\\begin{aligned}\\beta &amp;amp;=1-P(X_1-1\\gt 0.77-1)^2\\\\&amp;amp;= 1-P(U\\gt -0.23)^2\\\\&amp;amp;\\simeq 1-0.59^2\\\\&amp;amp;\\simeq 0.65\\end{aligned}\\)La puissance du test est $1-\\beta = 1 - 0.65 = \\boxed{0.35}$" }, { "title": "PRSTA: Seance 2", "url": "/cours/posts/prsta_seance2/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-29 14:30:00 +0200", "snippet": "Lien de la note Hackmd Regle dâ€™echantillonA partir de nos observations, on decide si on rejette lâ€™hypothese nulle ou nonRetour de la taille des epiteens: on rejette cette hypothese sâ€™il y a un eleve qui fait plus de $1m70$. Risque de premiere espece$H_0$ soit vrai Risque de second espece$H_1$ soit vrai alors quâ€™on garde $H_0$Types de test test parametriqueon-parametrique test dâ€™adequation test de comparaison Si lâ€™hypothese nulle nâ€™est pas rejetee: Elle nâ€™est pas demontree pour autant Elle nâ€™est pas contredite par les faits Test de comparaison dâ€™une proportion Meme principe pour $n$ grand\\[\\sqrt{n}\\frac{\\hat p-p_0}{\\sqrt{p_0(1-p_0)}}\\]Test du rapport de vraisemblance $H_0:\\theta=\\theta_0$ contre $H_1:\\theta=\\theta_1$ $\\theta_0\\lt\\theta_1$Test de vraissemblance qui est le plus puissant\\[T=\\frac{L(X_1,...,X_n, \\theta_1)}{L(X_1,...,X_n, \\theta_0)}\\] Rejet de $(H_0)$ ssi $T\\gt S_{\\alpha}$, ou $S_{\\alpha}$ est un seuil qui depend du niveau de confiance $\\alpha$Example $X_i$ Poisson de parametre $\\lambda$ $H_0:\\lambda=\\lambda_0$ contre $H_1:\\lambda=\\lambda_1$ $\\lambda_0\\le\\lambda_1$Rejet de $H_0$ si\\[\\frac{\\Pi_{i=1}^ne^{-\\lambda_1}\\frac{\\lambda_1^{X_i}}{X_i!}}{\\Pi_{i=1}^ne^{-\\lambda_0}\\frac{\\lambda_0^{X_i}}{X_i!}}\\gt S_{\\alpha}\\\\-n(\\lambda_1-\\lambda_0)+\\sum_{i=1}^nX_i(\\log(\\lambda_1)-\\log(\\lambda_2))\\gt\\log S_{\\alpha}\\\\\\sum_{i=1}^nX_i(\\log(\\lambda_1)-\\log(\\lambda_0))\\gt \\log(S_{\\alpha})+n(\\lambda_1-\\lambda_0)\\\\\\sum_{i=1}^nX_i\\gt\\underbrace{\\frac{\\log(S_{\\alpha})+n(\\lambda_1-\\lambda_0)}{(\\log(\\lambda_1)-\\log(\\lambda_0))}}_{\\color{blue}{n\\alpha}}\\]Rejet de $H_0$ si $\\sum_{i=1}^n{x_i} &amp;gt; \\nu_{\\alpha}$Exemple: $n=2$, $\\lambda_1=1$, $\\lambda_2=2$, $\\alpha=0,05$ Sous $H_0$, $Y=X_1+X_2$ suit une loi $\\mathcal P(2)$ Si $\\mu_{\\alpha}\\in]0;1]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y=0)\\simeq 0.865$Suite de lâ€™exemple precedent Rappel : fonction caractÃ©rique (SAVOIR FAIRE) dâ€™une loi X est $\\phi(t) = E(e^{itX})$ Pour une loi de Poisson, $P(X=k) = \\frac{\\lambda^k}{k!}e^{-\\lambda}$ \\[\\begin{aligned}\\phi_x(t)&amp;amp;=\\sum_{k\\ge0}e^{itk}P(X=k)\\\\&amp;amp;= \\sum_{k\\ge 0}e^{itk}e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k\\ge 0}\\frac{(\\lambda e^{it})^k}{k!} \\text{ : serie}\\\\&amp;amp;=e^{-\\lambda}e^{\\lambda e^{it}}\\end{aligned}\\\\\\color{red}{\\boxed{\\phi_x(t)=e^{\\lambda (e^{it}-1)}}}\\]Loi de $X_1+X_2$ ?\\[\\phi_{X_1+X_2}=\\phi_{X_1}(t)\\phi_{X_2}(t)\\]car $X_1$ et $X_2$ sont independantesOr $X_1$ et $X_2$ mÃªme loi donc mÃªme fonction caractÃ©rique, donc:\\(\\begin{aligned}\\phi_{X_1+X_2}&amp;amp;=\\phi_{X_1}(t)^2\\\\&amp;amp;=e^{(e^{it}-1)^2}\\\\&amp;amp;= e^{2(e^{it}-1)}\\end{aligned}\\) Continuer jusquâ€™a la premiere valeur inferieure a $0.05$ Si $\\mu_{\\alpha}\\in]3;4]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y\\le 3)\\simeq 0.0527$ donc $\\alpha=0.0527$ Si $\\mu_{\\alpha}\\in]4;5]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y\\le 3)\\simeq 0.0166$ donc $\\alpha=0.0166$ Test le plus puissant de risque $\\alpha \\le 0.05$: rejet de $H_0$ si $x_1 + x_2 &amp;gt; 5$Exemple $H_0:m=m_0$ contre $H_1:m=m_1$ ou $X$ suit une loi $\\mathcal N(m,1)$ et $m_0\\le m_1$ A. N.: $m_0=1$ et $m_1=2$ Calculer $\\alpha$ Calculer $\\beta$A RENDRE 1er et 2eme EXO DE REFLEXION (moodle)" }, { "title": "RVAU: Moteur 3D", "url": "/cours/posts/rvau_moteur_3d/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 11:15:00 +0200", "snippet": "Lien de la note HackmdQuâ€™est-ce quâ€™un moteur 3D ? Un logiciel qui permet de modeler un environnement 3DPermet de representer un environnement avec les interactions physiqueMoteur 3D Scene Objets Cameras Lumieres etc Graphe de scene: Pour manipuler les objets 3D de la scene Utilise une API 3D bas niveau ComposantsEditeur Editeur/environnement de developpementImport de modeles 3D Câ€™est la jungle pour les extensions de format 3D Differentiation entre les formats 3D Infographie 3D CAOModelisation CAO Operations parametriques Extrusion Revolution Conge Chanfrein Operations booleennes Geometrie de constructions de solides (CSG) Tesselation Creation dâ€™un maillage: passage dâ€™un modele CAO a un modele trianguleImports de modeles 3D Import de modeles tessellesPour unity: Autodesk FBX .fbx Collada .dae Wavefront .obj Autodesk 3DS .3ds AutoCAD Drawig eXchange Format .dxfExemples de moteurs 3DUnityProjet Assets ProjectSettingsHierarchy Gestion du graphe de sceneGameObject Transform Ensemble de composantsComposant Derive de la classe MonoBehaviourMonobehavior Functions callback Start() Update() FixedUpdate() LateUpdate() OnGUI() Tous les appels dedies a lâ€™interface graphique/affichage Câ€™est du mono-threadDocumentation UnityAssets Store" }, { "title": "RVAU: Collaboration en RV chez EDF", "url": "/cours/posts/rvau_collaboration_edf/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 11:00:00 +0200", "snippet": "Lien de la note HackmdCommuniquer en RVLe but: visualiser une maquette Chaque personne a sa position autour de la table Maquette tournante sur la table Chaque utilisateur puisse le voir sous tout ses angles Un pointeur par utilisateurs Collaboration asymetrique Une personne imergee avec son casque Une personne exterieure sur une tablette Z-space: ecran stereo (3D) Stylet permet dâ€™interagir Position Orientation La personne portant le casque peut voir ce qui est pointe par la personne sur la tabletteIndy: chasse au tresor virtuelle et collaborative dans un batiment reacteurPour former les jeunes embauches, leur apprendre a: se deplacer dans le batiment communiquer avec les autresPrincipes de conception Collaboration Gamification Entrainement a la navigation spatialeCollaborationDeux roles parmis les apprenants: radio chasseursChasse au tresor 1 formateur 12 stagiaires repartis en 4 equipes Le formateur cree la chasse Interface pour selectionner le point de depart Type de chasse Pointage dâ€™un equipement (ex: trouver un equipement particulier) Presence dans une zone (ex: trouver la sortie) Les stagiaires preparent la chasse Ils se regroupent sur le PC du radio La chasse chasseurs immerges et radio a cote POV du radio Plan 2D Possibilite de passer dans la 3D Quand le radio est en 3D, il peut voir lâ€™avatar des autres mais ne peut pas etre vu Il doit etre capable de verbaliser les instructions Le formateur voit les positions de toute le monde Les chasseurs pointent lâ€™objectif Fin de la chasse DebriefingRevue collaborative ne realite augmentee dâ€™une preparation de chantierVisualisation de la maquette: Possibilite de changer lâ€™echelle Position de lâ€™autre utilisateur avec un cube sur sa teteLa Smart Home en RV mobile:::infoAffichage centralise et partage entre plusieur peersonnes dans le cadre de la Smart Home sur smartphone:::Generalisable: Creer, visualiser et partager des annotations contextualisees/geolocalisees comme des signes dâ€™avertissement, communication, historique dâ€™evenementsâ€¦ Pour batiments tertiaires ou industriels pour la conduite et la maintenance ou encore des lieux urbains Utilisation des librairies natives sur smart phone" }, { "title": "RVAU: Collaboration en Realite Virtuelle", "url": "/cours/posts/rvau_collaboration_vr/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 09:00:00 +0200", "snippet": "Lien de la note HackmdCollaborationCe nâ€™est pas necessairement au sens dâ€™un jeu, câ€™est le fait dâ€™etre a plusieurs dans un environnement virtuel.Pourquoi la collaboration ? Nous sommes des animaux sociauxEnvironnement virtuel collaboratif â€œLes environnements virtuel collaboratifs (CVEs) sont des systemes distribues de realite virtuelle qui offrent des univers graphiques numeriques potentiellement infinis. Au sein de ces univers, les utilisateurs peuvent partager des informationsâ€Rappel: projectionIl faut voir ces systemes comme un trompe-lâ€™oeilCollaboration avec projectionCollaboration avec projection ?Du point de vue dâ€™une personne:Du point de vue dâ€™une seconde personne: On souhaite une projection pour chaque personneProjection pour 6 personnes: Possible grace a un affichage 360 Hz 60 Hz par personne Pour notre bus, cela permettrait de ne pas le voir deformeePour une personne exterieur, ca donne ca: On voit 12 images differrents en meme temps Problemes: Collisions Occultations Collaboration avec casques de RVModes de collaboration Collaboration co-localisee Collaboration distante Deux modes differentiables: Mode â€œcoherentâ€ Utilise quand on est sur place Mode â€œindividuelâ€ Chacun a son propre referentiel Collaboration co-localisee â€œcoherenteâ€Exemple: Paint 3D Besion dâ€™un referentiel commun Systeme de tracking Detection de marqueur Collaboration en realite augmentee Soit on importe les personnes physiques dans le monde virtuel, soit on importe les elements virtuels dans le monde physiqueMetaphores dâ€™interactionManipuler un objet a plusieurs ? Si une personne manipule un objet, personne ne peut manipuler cet objetUn objet est trop lourd, il faut quâ€™il soit deplacer par 2 personnesManipulation collaborative Faire la moyenne Manipulation conjointe Separation des degres de liberte Une personne manipule que la rotation Une personne manipule que le deplacement Translation et rotation a partir de la translation de 2 utilisateursNavigation collaborative En general, chacun se deplace separement Une personne dirige tout le groupeCollaboration asymetrique Asymmetry in scale Asymmetry in visualisation Asymmetry in interaction Modele en 5 dimensions pour modeliser ces interactions:Exemples:CommunicationConscience des autres utilisateurs Ou sont-ils ? Qui sont-ils ? Que font-ils ? Que regardent-ils ? Me regardent-ils ? Peuvent-ils voir ce que je leur montre ?PointageAnnotationsExempleVideoTelepresence Ce genre de problemes devient vite compliqueSi une personne est face a nous, on veut quâ€™elle nous regarde et pas a coteCapture de mouvement Communication non verbaleRV socialeFaceDisplayFacebook Social VR Demo" }, { "title": "EPIQUANTI : Qubits", "url": "/cours/posts/epiquanti_qubits/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-09-28 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursGrotrian diagramQuantum vacuum fluctuationsAccording to quantum field theory and Heisenberg principle, vacuum contains harmonic oscillators with zero-point energy\\[E=\\frac{1}{2}hv\\\\\\Delta E\\cdot\\Delta t\\ge\\frac{h}{2}\\]with electrons/positrons spontaneously cretaed and annilihating, creating photons Feynmann diagram Lamb shift (1947)Energy shift observed between 2 levels hyperfine structure in hydrogen atom, explained by quantum vacuum fluctations impacting electronsCasimir effect (1997)Comparing classical and quantum physicsQuantum myths: HistoryEinstein was wrong about quantum mechanics He was a key founder of quantum physics with the photoeletric effect explanation and many other works; he asked the right questions about entanglement in 1935 which are still debatedWerner Heisenberg created his indeterminacy inequality It was created by Earle Hesse Kennard in 1927 and Hermann Weyl in 1928Erwin Schrodingerâ€™s cat is both dead and alive He wanted to explain that the wave-particle duality didnâ€™t work at macro scale, thus the cat canâ€™t be both dead and alive. End of story, but I can elaborate. Itâ€™s a matter of uncertainty origin.Richard Feynmann invented the concept of quantum computing He imagined in 1981 the concept of quantum simulation of quantum physics phenomenon but, before, Yuri Manin invented in 1980 the concept of gate based quantum computing.Youngâ€™s slit experiment was done with electrons in 1927 Peux pas lire ptdrWhat happened during WWII ? La bombe atomiqueLa physique atomique est un champ different de la physique quantique mais on peut expliquer la desintegration du noyau dâ€™uranium par la physique quantique. Les gens faisant de la physique quantique sont passes sur la physique nucleaire, il y a eu un trou dans la phyisque quantiquePost-WWII 1946-1952: Felix Bloc Sphere 1947-1956: William Shockley John Bardeen Walter Brattain Transistors 1957: John Bardeen, Leon Cooper, John RObert Schrieffer Superconductivity 1953 1960: Gordon Gould, Theodore Maiman, Nikolay Basov 1964: Alexander Prokhorov 1964: Charles Hard Townes 1962-1973: Brian Josephson Josephson effect 1964: John Stewart Bell Bell inaqualities and test 1970: Dieter Zeh Quantum decoherence 1980: Yuri Manin Quantum computing 1980: Tommaso Toffoli Toffoli gate 1981: Richard Feynman Quantum simulator 1982: Alain Aspect$1^{st}$ and $2^{nd}$ quantum revolutions Manipulating groups of quantum particles ($1947-*$) Photons, electrons and atoms interactions Transistors Lasers GPS Photovoltaic cell Atom clocks Medical imaging Digital photography LCD TV quantum dots Manipulating superposition and entanglement and/or individual particles ($1982-*$) Quantum computing Quantum telecommunications Quantum cryptography Quantum sensingSecond quantum revolution 1991: Anton Zellinger Neutrons duality 1992: Arthur Ekert QKD 1993: Umesh Vazirani Quantum complexity 1992: Serge Haroche Quantum decoherence Juan Cirac and Peter Zoller Trapped ions qubits Edward Farhi Adiabatic quantum computing David DiVincenzo Criterium 1997: Nicolas Gisin Non locality 1997 &amp;amp; 2002: Daniel Esteve Superconducting qubits 2001: Hans Briegel MBQC 2011: John Preskill Quantum supremacy concept 2012: D-Wave One First quantum annealing commercial computer 2016: IBM Q First cloud based quantum computer Quantum sensing On nâ€™en parlera quasiment pas du tout lasers and frequency combs clocks Spectrographs ultra-sound mikes entengled photons radars ultra-sensing imaging cold atomsCapteurs quantiques Nami Entanglement iXblueClassical computing state of the art and limitationsMooreâ€™s law: dead or alive ?Câ€™est un papier ecrit par Gordon Moore. Il fait en observation empirique: Faire croitre le nombre de transistors dans une puce de maniere exonentielle Ce nâ€™est pas une loi mathematique ou physiqueCela mettait la pression sur les constructeurs comme Intel. Elle est applicable aux: processeurs supercalculateurs espaces de stockage En quoi la loi de Moore sâ€™est arretee ? La puissance dâ€™horloges nâ€™a pas augmente exponentiellement depuis plus de 15 ans Câ€™est lie a la fin de lâ€™echelle de Dennard en 2006 Lâ€™energie utilisee a explose.Pourquoi ? A cause de fuites sur les transistors Ca a fini sur le dark siliconA cause de ce mecanisme, on ne peut pas utiliser toute la surface dâ€™un processeur de serveur sinon il va fondre.Comment on fait pour tout utiliser en entier ? Avec un isolant ?Avec un refroidissement ?CMOS technical challenges Extreme ultra violet (EUV) for $\\le10$ nm density Heat barrier processor clocks Quantum computingPromis and use casesProbleme intractable: probleme dont le temps de calcul va augmenter de maniere exponentielle avec sa taille. PromesseCertains problemes intractables vont etre solvable dans un temps humainement raisonable. Transports et logisitiques Healthcare Energy and materials Finance and insurance DefenseDifference Bits and QubitsFrom quantum physics to qubits wave function describes particles properties probabilities quantization discrete levels of wave functions, like energy, polarity, spin superposition linear combination of quantized states entanglement quantum objects correlated states, consequence of linear superposition of multiple quantum objects wave function &amp;amp; quantization: 2 levels of quantum objectsFrom computing to measurement Quantum gates actions on qubits and their superposed states Computational basis state vector:\\[\\begin{matrix}\\text{complex amplitude} &amp;amp;\\text{of all combinations of } 0 \\text{ and } 1\\\\\\begin{bmatrix}\\alpha_1\\\\\\vdots\\\\\\alpha_2N\\end{bmatrix} &amp;amp;\\begin{matrix}\\vert 00\\dots00\\rangle\\\\\\vdots\\\\\\vert 10\\dots01\\rangle\\\\\\vdots\\\\\\vert 11\\dots11\\rangle\\end{matrix}\\end{matrix}\\] $N$ qubits registers information in $2^N$ superposed state Qubits canâ€™t be independently copied\\[\\sum_{i=1}^{2^N}\\alpha_i^2=1\\]handles $2^{N+1}-1$ real numbers measurement Ends superposition and entanglement outputs $N$ probabilistic classical bits computing has to be run many times and results average Adressing the noise challenge decoherence progressively ends superposition and entanglement coherence times between $100\\mu s$ and a couple seconds errors significant during computing $0.1\\%$ to $8\\%$ error rates per gate and for qubits readouts erros correction requires a very large number of additional qubits $1-100$ to $1-10000$ ratio between logical and physical qubits scalability challenges aulity qubits, cabling, control electronics, cryogenics abd energetics engineering Distributed quantum computing ?Complex numbers and phase $r$: amplitude, modulus, norm $\\theta$: phase angleEuler formula:\\[e^{i\\theta}=\\cos\\theta+\\sin\\theta\\]Phase angles add upqubit Bloch sphere representation Opposite vectors in sphere are mathematically orthogonal$\\alpha$ and $\\beta$ are complex numbers altitudes:\\[\\vert\\Psi\\rangle=\\alpha\\vert0\\rangle+\\beta\\vert1\\rangle\\]Probabilities and Born normalization constraint:\\(\\alpha+\\beta=1\\)Using polar coordinates $\\theta$ and $\\phi$ and no global phase:\\(\\vert\\Psi\\rangle=\\cos\\frac{\\theta}{2}\\vert0\\rangle+\\sin\\frac{\\theta}{2}e^{i\\phi}\\vert1\\rangle\\)Euler formula:\\(e^{i\\phi}=\\cos\\phi+i\\sin\\phi\\)Alternate â€œsymetricâ€ version with a global phase of $e^{-\\frac{i\\phi}{2}}$\\(\\vert\\Psi\\rangle=\\cos\\frac{\\theta}{2}e^{\\frac{-i\\phi}{2}}\\vert0\\rangle+\\sin\\frac{\\theta}{2}e^{\\frac{i\\phi}{2}}\\vert1\\rangle\\)The global phase doenâ€™t change the probabilities $\\vert\\alpha\\vert^2$ and $\\vert\\beta\\vert^2$ for measurementOther representationsPoincareâ€™s sphere:Linear algebra 101\\[f(\\lambda)\\]Vectors Dirac notation:\\[\\vert\\Psi\\rangle = \\begin{bmatrix}\\alpha \\\\ \\beta\\end{bmatrix} \\quad\\Psi\\text{ ket}\\\\\\bar\\alpha =\\alpha*\\quad\\langle\\Psi\\vert=[\\bar\\alpha,\\bar\\beta]\\quad\\psi\\text{ bra}\\]Bra-ket:\\[\\langle\\Psi_1\\vert\\Psi_2\\rangle=[\\bar\\alpha_1,\\beta_1]\\times\\begin{bmatrix}\\alpha_2 \\\\ \\beta_2\\end{bmatrix}\\]How to read that ?\\(\\langle\\Psi\\vert A\\vert\\phi\\rangle\\)Average valye in $\\Psi$ of the value\\[A^{âœ}=(A^T)*\\underbrace{A^*}_{\\text{matrix conjugate}}+\\overbrace{A^T}^{\\text{matrix transpose}}\\Rightarrow \\begin{bmatrix}a &amp;amp;b \\\\ c&amp;amp;d \\end{bmatrix}^âœ\\]\\[\\vert\\Psi\\rangle = \\bigotimes_{n=1}^N\\vert i\\rangle\\]" }, { "title": "OCVX2: Optimisation sous contrainte par la methode des multiplicateurs de Lagrangre et conditions KKT", "url": "/cours/posts/ocvx2_kkt_lagrange/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-27 16:00:00 +0200", "snippet": "Lien de la note Hackmd KKT: Karush-Kuhn-TuckerOn va sâ€™attaquer a des problemes de la forme:\\[\\begin{matrix}&amp;amp;\\text{minimiser } f(x) &amp;amp;f:\\mathbb R^n\\to\\mathbb R &amp;amp;f\\text{ convexe}\\\\&amp;amp;x\\in C &amp;amp;x\\in\\mathbb R^n &amp;amp;C=\\text{ensemble convexe}\\end{matrix}\\]\\[x\\in C\\Leftrightarrow\\begin{cases}g_i(x)\\le 0 &amp;amp;\\forall i=1,\\dots,m&amp;amp;g_i\\text{ convexe}\\\\h_j(x)=0 &amp;amp;\\forall j=1,\\dots,p&amp;amp;h_j\\text{ affine}\\end{cases}\\]$C$ defini lâ€™ensemble des points admissibles.\\[\\boxed{\\begin{matrix}&amp;amp;\\text{minimiser } f(x) &amp;amp;\\text{equivalent a} &amp;amp;\\text{minimiser } f(x), x\\in\\mathbb R^n\\\\&amp;amp;x\\in C &amp;amp; &amp;amp;\\text{tq} \\begin{cases}g_i(x)\\le 0 &amp;amp;\\forall i=1,\\dots,n\\\\h_j(x)=0&amp;amp;\\forall j=1,\\dots,p\\end{cases}\\end{matrix}\\\\\\color{red}{\\text{(OPT)}}}\\] valeur optimale $p^{*}=f(x^{*})$ point optimal $x^{*}\\in\\mathbb R^n$Sans contrainte: $f$ convexe: $x^{*}$ optimal $\\Leftrightarrow\\nabla f(x^{*})=0$ Cette conditions dâ€™optimalite nâ€™est plus vraie des lors que lâ€™on a des contraintes. Dualite de Lagrange LagrangienOn definit le Lagrangien de (OPT) comme la fonction:\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta) = f(x)+\\sum_{i=1}^m\\alpha_ig_i(x)+\\sum_{j=1}^p\\beta_jh_j(x)\\end{aligned}\\\\\\begin{aligned}&amp;amp;\\text{variables duales}\\begin{cases}\\alpha=\\begin{pmatrix}\\alpha_1\\\\\\vdots\\\\\\alpha_m\\end{pmatrix}\\in\\mathbb R^m\\\\\\beta=\\begin{pmatrix}\\beta_1\\\\\\vdots\\\\\\beta_p\\end{pmatrix}\\in\\mathbb R^p\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\text{multiplications de Lagrange}\\\\&amp;amp;\\Leftrightarrow\\text{cout associe a chaque contrainte}\\end{aligned}\\] Lagrangien $\\equiv$ version sans contrainte du probleme (OPT)IntuitionIntuition: pour chaque probleme dâ€™optimisation avec contraintes, il existe un certain parametrage des variables duales tel que le minimum sans contrainte du Lagrangien par rapport a la variable primale $\\equiv x$ (a variables duales fixees) coincide avec la solution du probleme de contraintes.On appelle fonction objective primale\\[\\begin{aligned}\\theta_p:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\end{aligned}\\]On appelle probleme primal le probleme dâ€™optimisation sans contrainte: \\(\\min_{x\\in\\mathbb R^n}\\theta_{p}(x)\\)$x\\in\\mathbb R^n$ est primal admissible ssi\\[\\begin{cases}g_i(x)\\le 0&amp;amp;\\forall i\\\\h_j(x)=0 &amp;amp;\\forall j\\end{cases}\\] On va noter $p^{*}$ la valeur optimale de $(P)$ et $x^{*}$ le point optimal, $p^{*}=\\theta_{p}(x^{*})$On appelle fonction objective duale:\\[\\begin{aligned}\\theta_D:\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(\\alpha,\\beta)&amp;amp;\\mapsto\\min_{x\\in\\mathbb R^n}\\mathscr L(x,\\alpha,\\beta)\\end{aligned}\\]On appelle probleme dual le probleme dâ€™optimisation avec contrainte\\[(D)\\quad \\max_{\\alpha,\\beta \\\\ \\alpha_i\\ge 0}\\theta_D(\\alpha, \\beta) = \\max_{\\alpha, \\beta \\\\ \\alpha_i\\ge 0}\\min_{x}\\mathscr L(x,\\alpha, \\beta)\\]$(\\alpha,\\beta)$ est dual admissible ssi $\\alpha_i\\ge0$ $\\forall i$.On note egalement $(\\alpha^{*}, \\beta^{*})$ la solution de $(D)$ et $d^{*} = \\theta_D(\\alpha^{*}, \\beta^{*})$Interpretation du probleme primalDans le cas ou on a $g(x)\\le0$ convexe et $h(x)=0$ affine.Dans ce cas, le Lagrange est:\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R\\times\\mathbb R&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta)=f(x)+\\alpha g(x)+\\beta h(x)\\end{aligned}\\]On a:\\[\\begin{aligned}\\theta_p:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\end{aligned}\\]Dans ce cas:\\[\\begin{aligned}x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\\\\\theta_{p}(x) &amp;amp;= \\max_{\\alpha, \\beta \\\\ \\alpha\\ge 0}[f(x)+\\alpha g(x)+\\beta h(x)]\\end{aligned}\\] $\\theta_p(x)$ est convexe car la somme ponderee de fonctions convexes est convexe, et le $\\max$ de fonctions convexes est convexe.\\[\\theta_p(x) = f(x)+\\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0}[\\alpha g(x) + \\beta h(x)]\\] Si $g(x)\\gt 0$, le crochet est maximise pour $\\alpha=+\\infty$ et vaut $+\\infty$ Si $g(x)\\le 0$, le crochet est maximise pour $\\alpha=0$ Si $h(x)\\neq 0$, le crochet est maximiser pour $\\beta=(\\text{signe de }h(x))\\infty$ et vaut $+\\infty$ Si $h(x)=0$, le crochet vaut $0$ peu importe la valeur de $\\beta$ Donc si $x$ primal admissible $(g(x) \\le 0$ et $h(x)=0)$, alors le crochet vaut $0$. Si $x$ ne verifie pas les contraintes, alors le crochet vaut $+\\infty$.\\[\\theta_p(x)=f(x)+\\begin{cases}0 &amp;amp;\\text{si } x \\text{ primal admissible}\\\\+\\infty &amp;amp;\\text{si } x \\text{ pas primal admissible}\\end{cases}\\\\\\]\\[\\begin{aligned}(P):\\quad&amp;amp;\\min_{x\\in\\mathbb R^n}\\theta_p(x)\\\\&amp;amp;\\min_{x\\in\\mathbb R^n}f(x)+\\begin{cases}0 &amp;amp;\\text{si } x \\text{ primal admissible}\\\\+\\infty &amp;amp;\\text{si } x \\text{ pas primal admissible}\\end{cases}\\end{aligned}\\]" }, { "title": "OCVX2: Approche lineaire", "url": "/cours/posts/ocvx2_approche_lineaire/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-27 14:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1On considere la fonction differentiable\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto 3x^2+y^2\\end{aligned}\\] Representer les courbes de niveaux 2 et 4 de $f$ dans le plan euclidien A quel lieu correspond la condition $f(x,y)\\le4$ On sâ€™interesse au probleme dâ€™optimisation $(P)$ minimiser $f_0(x,y)=2x+y$ sujet a $3x^2+y^2\\le4$. Representer la courbe de niveau de la fonction objectif qui correspond a la valeur optimale de $(P)$ Comment trouver le point optimal correspondant a $(P)$? Faire le calcul Solution 1.\\[f(x,y)=3x^2+y^2\\\\\\begin{aligned}\\mathcal C_2&amp;amp;=\\{3x^2+y^2=2\\}\\\\&amp;amp;= \\{\\frac{3}{2}x^2+\\frac{1}{2}y^2=1\\}\\end{aligned}\\] Il sâ€™agit de lâ€™equation dâ€™une elipse de: demi grand axe $a$ demi petit axe $b$ \\[\\biggr(\\frac{x}{a}\\biggr)^2+\\biggr(\\frac{y}{b}\\biggr)^2 =1\\] Rappel\\[2\\pi r\\to\\pi(a+b)\\\\\\pi r^2\\to\\pi a b\\] \\[\\mathcal C_2 (f)=\\{3x^2+y^2=2\\}\\] Ellipse de: demi grand axe $\\sqrt{2}$ sur $O_y$ demi petit axe $\\sqrt{\\frac{2}{3}}$ sur $O_x$ \\[\\mathcal C_4 (f)=\\{3x^2+y^2=4\\}\\] Ellipse de: demi grand axe $2$ sur $O_y$ demi petit axe $\\frac{2}{\\sqrt{3}}$ sur $O_y$ Zoli dessin 2. 3.\\[\\begin{aligned}(P) \\quad\\text{min} f_0(x,y)&amp;amp;=2x+y\\\\3x^2+y^2&amp;amp;\\le4\\Leftrightarrow \\mathcal C_{\\le 4}(f)\\end{aligned}\\]\\[\\mathcal C_0 = \\{2x+y=0\\}\\\\\\vec u=\\binom{-1}{2}\\\\\\vec n=\\binom{2}{1}\\] Pour minimiser, on part dans le sens inverse du vecteur normal. Notre point optimal: $p^{*} = (x^{*}, y^{*})$\\[p*\\in\\mathcal C_4(f)\\Leftrightarrow 3x^{*^2}+y^{*^2}=4\\\\p*\\in\\mathcal C_{f_0^*}\\Leftrightarrow 2x^*+y^*=f_0^*\\] Le gradient dâ€™une fonction en un point donne est orthogonal a la courbe de niveau qui passe par ce point la. En $p^{*}$:\\[\\nabla \\vec f(p^*) = \\lambda\\vec n\\\\\\nabla \\vec f(p^*) + \\lambda\\vec n = 0\\quad\\lambda \\gt 0\\]\\[f(x,y)=3x^2+y^2\\\\\\nabla f = (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}) = (6x, 2y)\\\\\\begin{aligned}\\nabla f(p^* = (x^*, y^*)) = (6x^*, 2y^*) = \\lambda\\binom{2}{1}&amp;amp;\\Leftrightarrow \\begin{cases}6 x^* = 2\\lambda\\\\2y^* = \\lambda\\end{cases}\\\\&amp;amp;\\Leftrightarrow 6x^* = 4y^*\\\\&amp;amp;\\Leftrightarrow \\color{green}{\\boxed{y^* = \\frac{3}{2}x^*}}\\end{aligned}\\\\\\begin{aligned}3x^{*^2}+y^{*^2} = 4\\Rightarrow 3x^{*^2}+(\\frac{3}{2}x^*)^2&amp;amp;=4\\\\3x^{*^2}+\\frac{9}{4}x^{*^2}&amp;amp;=4\\\\\\frac{21}{4}x^{*^2}&amp;amp;=4\\\\x^{*^2}&amp;amp;=\\frac{16}{21}\\end{aligned}\\] Donc:\\[x^*=\\frac{4}{\\sqrt{21}}\\quad\\text{ou}\\quad\\color{green}{\\boxed{-\\frac{4}{21}}}\\\\\\text{et}\\quad \\color{green}{\\boxed{y^*=-\\frac{6}{\\sqrt{21}}}}\\]Exercice 2On considere le probleme dâ€™optimisation $(P)$ minimiser $f_0(x,y)=x+y$ sujet a $x+2y\\le3,x\\in B$ avec $B\\in\\mathbb R^2$ lâ€™intersection de lâ€™epigraphe de $x\\mapsto-\\sqrt{x}$. Dessiner le lieu admissible de $(P)$ Representer la courbe de niveau $f_0$ qui realise le minimum de $(P)$ Calculer le point optimal ainsi que la valeur optimale de $(P)$ Solution Rappel: Epigraphe Tout ce quâ€™il y a au-dessus du graphe de la fonction\\[\\text{epi}(f) = \\{(x,t)\\vert t\\ge f(x)\\}\\] 1. \\[x+2y-3=0 \\quad (D)\\\\(3,0)\\in D \\\\ \\vec u=\\binom{-2}{1}\\\\\\vec n =\\binom{1}{2}\\] Avec la courbe $\\mathcal C_0$: Avec $p^{*}=(x^{*}, y^{*})$: 2. Le vecteur normal au graphe va etre colineaire au vecteur normal de notre courbe de niveau. Gradient de quoi ? On est sur le graphe et pas la ligne de niveau Est-ce quâ€™on peut exprimer le graphe comme ligne de niveau ? Toutes les representations parametriques peuvent sâ€™ecrire en representation implicite (lâ€™inverse nâ€™etant pas vrai) Notre graphe de $y\\mapsto-\\sqrt{x}$ est:\\[\\{(x,y) \\text{ tq } y=-\\sqrt{x}\\}\\\\\\{(x,y)\\text{ tq } \\sqrt{x}+y=0\\}\\\\= \\mathcal C_0(g)\\] Avec:\\[\\begin{aligned}g: \\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto \\sqrt{x} + y\\end{aligned}\\] Condition dâ€™optimalite: en $p^{*}=(x^{*}, y^{*})$,\\[\\nabla g(p^*) = \\lambda \\vec n_0\\\\\\begin{aligned}\\nabla g(x,y) &amp;amp;= (\\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y})\\\\&amp;amp;= (\\frac{1}{2\\sqrt{x}}, 1)\\end{aligned}\\] En $p^{*}$:\\[\\begin{aligned}&amp;amp;\\begin{cases}\\frac{1}{2\\sqrt{x^*}} = \\lambda\\\\1 = \\lambda\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}\\lambda =1\\\\\\frac{1}{2\\sqrt{x^*}}=1\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}x^*=\\frac{1}{4}\\\\y^*=-\\frac{1}{2}\\end{cases}\\end{aligned}\\] Valeur optimale:\\[x^* + y^* = \\frac{1}{4}-\\frac{1}{2} = \\color{green}{\\boxed{-\\frac{1}{4}}}\\] " }, { "title": "AN3D: Interpolate position", "url": "/cours/posts/an3d_interpolate_position/", "categories": "Image S9, AN3D", "tags": "Image, S9, AN3D", "date": "2021-09-24 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du profAnimation in Computer Graphics2 main ways to describe animation Kinematics DynamicsWays to genre animation Descriptive animation Motion tracking Procedural generation Physically based simulation Leaning-based synthesisDescriptive Animation The artist/an algorithm fully describes the motion and deformation Pros Cons Full control on the result May introduce un-physical effects History of CG AnimationFirst production of animated films (Disney) Principle Animator in chief: create key frames Assistants: fill the in between (secondary drawings) Principle of Key Framing:Key framing in CG Create manually a set of key frames Interpolate positionsProduction pipeline: Interpolate position Given a set of key positions (pos + time), we want to find an interpolating space-time curve Input: $(p_i, t_i)$Linear Interpolation Pros Cons Simple Non smooth trajectory Constant speed between keyframes Generates straight segments Smooth curve $\\alpha_i$ polynomial basis function of degree $d$Which polynomial/degree choose ?Lagrange polynomial interpolation Interpolate all points at onceDegree of polynomial: $N-1$ Known solution: Lagrange polynomial Comparison En pratique, on nâ€™utilise jamais cette interpolationSpline Idea Define each part a polynomial Smooth junctions between them How to choose the polynomial Sufficiently high degree to be smooth Sufficiently low degree to avoid oscillations In Graphics, cubic polynomials are often used Allow up to $\\mathcal C^2$ junctions Hermite interpolation Cubic curve interpolationg points and derivatives at extermitiesInterpolating curveInitial problem: set of multiple keyframes position+time2 solutions: Set explicitely derivatives for each keyframe - teadious Compute automatically plausible derivatives from surrounding samples - often usedCardinal spline:Set:\\[d_i=\\mu\\frac{p_{i+1}-p_{i-1}}{t_{i+1}-t_{i-1}}\\] $\\mu$ curve tension $\\in[0,2]$ $\\mu = 1$ is commonly used Catmull Rom Spline Wrap-up algorithmCompute $p(t)$ as a cubic spline interpolation Given keyframes $(p_i, t_i)_{i\\in[0,N-1]}$ Given time $t\\in[t_1,t_{N-2}]$ find $i$ such that $t\\in[t_i,t_{i+1}]$ Compute \\(d_i=\\mu\\frac{p_{i+1}-p_{i-1}}{t_{i+1}-t_{i-1}}\\) and \\(d_{i+1}=\\mu\\frac{p_{i+2}-p_{i}}{t_{i+2}-t_{i}}\\) Compute \\(p(t) = (2s^3-3s^2+1)p_i + (s^3-2s^2+s)d_i + (-2s^3+3s^3)p_{i+1} + (s^3-s^2)d_{i+1}\\) with $s=\\frac{t-t_i}{t_{i+1}-t_i}$ Limitation of cubic curve interpolation Only $\\mathcal C^1$, but not $\\mathcal C^2$ at junctions: curvature/acceleration discontinuity Non-constant peed along each polynomialCurve editing Animation software (Maya, 3DSMax, Blender, etc) always come with a curve editor Artists can manually ajust their position, time, and derivatives on curve editor One curve for each scalar parameter position $(x,t,z)$ scaling $(s_x,s_y,s_z)$ rotation/quaternion Can also use a wrapper function $w$ to change time $p(t) = f(w(t))$Usage of keyframes interpolation Interpolate every vertex of multiple meshesMulti-target blendingInterpolate between multiple key poses Interesting for facial animation Per-vertez formulation $p_i(t)=\\sum_{k}^{N_{poses}}$ Blend shapes\\[p_i(t) = b_i^0 + \\sum_k^{N_{poses}}\\omega_k(t)(\\underbrace{b_{ki}-b_i^0})\\]Physically-based simulationWhen physically based simulation is needed Accurate dynamics Teadious to model by hand or procedurally Multiple interacting elements Complex animated geometry Material model Elasticity Purely elastic models donâ€™t loose energy when deformed Plasiticity Ductile material: can allow large amout of plastic deformation without breaking (plastic) Brittle - Opposite (glass) Viscosity Resistance to flow (usually for fluid, ex:honey) In reality Elasto-plastic materials Allow elastic behavior for small deformation, and plastic at larger one Visco-elastic materials Elastic properties with delay Rigid spheresSystem modelingParticles modeling the center of hard spheres Spheres can collide with surrounding obstacles Spheres can collide with each othersSystem: $N$ particles with position $p_i$, speed $v_i$, mass $m_i$, modeling a sphere of radius $r_i$ initial conditions: $p_i(0)=p_i^0,v_i(0)=v_i^0$Forces: $F_i=$\\[v^{k+1} = v^k+hg\\\\p^{k+1}=p^j+hv^{k+1}\\]Collision with a planePlane $\\mathcal P$: parameterized using a point $a$ and its normal $n$\\(\\{p\\in\\mathbb R^3\\in\\mathcal P\\Rightarrow (p-1)\\cdot n =0\\}\\) Sphere above plane: $(p_i-1)\\cdot n\\gt r_i$ Sphere in collision: $(p_i-a)\\cdot n\\le r_i$for (int i = 0; i &amp;lt; N; ++i) { float detection = dot(p[i]-a, n); if (detection &amp;lt;= r[i]) { // ... collision response }}Collision response with planeWhat should we do when a collision is detected ? On peut changer la vitesse On decompose la vitesse selon 2 composantes: la tangente et la normale\\[\\vec v\\begin{cases}v_n\\to &amp;amp;-v_n\\\\&amp;amp;+\\\\v_r\\to &amp;amp;v_t\\end{cases}\\\\\\text{composante normale: } (\\vec v\\cdot\\vec n)=v_n\\\\\\text{composante tangente: }\\vec v-v_n\\vec n\\] Collision response = Update speedResult Applying collision response on speed only Les boules tombent en-dessous du plan Quand notre sphere rebondit, il est possible quâ€™une partie passe au travers du plan, donc on considere en collision, donc on inverse sa vitesse, donc en collision, etcComment on contre ca ? Si ma sphere est dans le sol, on sâ€™arrange pour quâ€™elle ne soit pas dans le solOn la â€œrepousseâ€ pour quâ€™elle soit en contact avec la surfaceCollision response with a plane: positionThree possibilities: Correct position in projecting on the constraint Pros: simple to implement Cons: Physically incorrect position Approximate the correct position Go backward in time to find exact instant of collision Continuouse collision detectino Pros: physically correct Cons: Computationally heavy Result Ca marche !\\[p_i^{new} = p_i+d_n\\]Collision between speheresGiven 1 spheres $(p_1, v_1, r_2, m_2), (p_2, v_2, r_2, m_2)$Collision when\\[\\Vert p_1-p_2\\Vert\\le r_1+r_2\\]What will happen with speeds ? $v_1\\to v_1^{new}, v_2\\to v_2^{new}$Notion of impulseAn impulse $J$ is the integrted force over time\\[J=\\int_{t_1}^{t_2}F(t)dt\\] Result in a sudden change of speed (momentum) in a discrete caseFor a particle with a constant mass\\[\\int_{t_1}^{t_2} F(t)dt=\\int_{t_1}^{t_2} ma(t)dt\\]2 spheres in collision Jâ€™ecris pas ca vous etes fousSummary Detect collision $\\Vert p_1-p_2\\Vert\\le r_1+r_2$ if collision (relative speed$\\gt\\epsilon$) Elastic collision (bouncing) $v_{1/2}=\\alpha v_{1/2}\\pm\\beta \\frac{J}{m_{1/2}}$ If static contact (relative speed $\\le\\epsilon$) Friction $v_{1/2}=\\mu v_{1/2},\\mu\\in[0,1]$ Avoids jittering Correct position (project on contact surface) $p=p+\\frac{d}{2u}$ $d=r_1+r_2-\\Vert p_1-p_2\\Vert$: collision depth For small impacts, can use position based dynamics $v^{new} = \\frac{(p^{new}-p^{prev})}{\\delta t}$ Note on collision stackOptimiser ne pas avoir a simuler les spheres sur le sol et immobiles Faire des graphes des solides et les traiter comme des solides rigidesModeling elastic shapes with particles Spring mass systems Particles: samples on shape Springs: link closed-by particles in the reference shape Spring structureHow to model spring connectivity ? Structutal springs 1-ring neighbors springs ($\\simeq$ mesh edges) Pros: limit elongation/contraction Cons: Allows shearing, and bending Add extra springs connectivity Shearing springs Diagonal links Bending springs 2-ring neighborhood Cloth simulationMass-spring cloth simulation Particles are sampled on a $N\\times N$ grid Each particle has a mass $m$ Set structural, shearing and bending springsForces On each particle: gravity + drag + spring forces\\(F_i(p,v,t)=m_ig-\\underbrace{\\mu v_i(t)}_{\\text{facteur d&#39;attenuation}}+\\sum_{j\\in\\nu_i}K_{ij}(\\Vert p_j(t)-p_i(t)\\Vert-L_{ij}^0)\\frac{p_i(t)-p_i(t)}{\\Vert p_j(t) -p_i(t)\\Vert}\\) $\\nu_i$: neighborhood of particle $i$ $L_{ij}^0$: rest length of spring $ij$Associated ODE\\[\\forall i\\begin{cases}p_i&#39;(t) = v_i(t)\\\\v_i&#39;(t)=F_i(p,v,t)\\end{cases}\\]" }, { "title": "AN3D: Bases du rendu graphique", "url": "/cours/posts/an3d_bases_rendu/", "categories": "Image S9, AN3D", "tags": "Image, S9, AN3D", "date": "2021-09-23 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du profContexteOn a lâ€™habitude de voir des models 3D virtuelsConclusion: il est aise de concevoir et animer ses propres modeles 3D FAUX ! Outils: Blender MayaFormation de 3 a 5 ans dans les ecoles dâ€™infographie. Le cout/temp passe sur la 3D nâ€™a jamais ete aussi elevve Films animations/VFX Cout moyen par sequence VFX ($\\lt10s$): 50k$ Cout animation 3D $\\gt$ cout dessin manuel Jeu videos AAA 100M$ 2 a 4 annees de dev Les outils 3D se sont ameliores Mais restent complexes et tres techniques (3 ans dâ€™etude infographistes) Creation 3DLa quantite et la qualite demande a augmente plus rapidement que les outilsDessins/sculpture a la main restent plus efficace pour le prototypage/designEquipe: Geometric &amp;amp; visual computing Equipe informatique graphique et visionApplicationsDomaine dâ€™applications typiques Loisirs &amp;amp; creations artistiques Modelisation &amp;amp; visualisation en Sciences Naturelles Prototypage et fabricationNotre â€œexpertiseâ€ Methode interactive pour lâ€™aide a la creativite Simulation visuelles Analyses de formes et algorithmiqueAide: stages, emploi, poursuite en Informatique Graphique ?Rem. IG: Domaine technique, R&amp;amp;D avancee Lien fort sujets recherche et entreprise Theses IG - sujets appliques qui interessent les industriesSi le domaine vous interesse: AFIGPlan du cours Introduction et rappels dâ€™Info Graphique Warm-up systeme de particules Animation descriptive Animation physique Animation de personnagesEvaluation Un compte rendu de tp Collision de spheres, tissus, ou personnage articule $\\simeq5$ pages Notre demarche, resultats et analyses Computer graphicsMain subfields Modeling Animation RenderingRepresenting 3D shapes for Graphics Application Computer graphics: mostly focus on representing surfaces Scientific visualization: volume dataSurfacesTwo main rpzRepresentation dâ€™une sphere:Difficulty of surface representation using function Câ€™est impossible, la forme est trop complexeObjective of surface representationMain idea: use piecewise approximationIdeal surface representation Approximate well any surface Require few samples Can be rendered efficiently (GPU) Can be manipulated for modelingExample of models: Mesh-based Triangular meshes, polygonal meshes, subdivision surfaces Polynomial Polynomial: bezier, spline NURBS Implicit grid, skeleton based, RBF, MLS Points sets For projective/rasterization render pipeline: always render triangular meshes at the end Pros Cons Simplest representation Requires large number of saples: complex modeling Fit to GPU Graphics render pipeline Tangential discontinuities at edges Mesh encodingExample of 3D Mesh FileAffine transforms and 4D vectors/matricesPerspective matrixPerspective space: allows perspective projection expressed as a matrix.Common constraints (in OpenGL): Wrap the viewing volume (truncated cone with rectangulare basis called frutsum) ($z_{near},z_{far},\\theta$) to a cube $\\theta: view angle$ $p=(x,y,z,1)\\in$ frutsum $\\Rightarrow pâ€™=(xâ€™,yâ€™,zâ€™,1)\\in[-1,1]^30$ \\[M=\\begin{pmatrix}f&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;f&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;C&amp;amp;D\\\\0&amp;amp;0&amp;amp;-1&amp;amp;0\\end{pmatrix}\\\\f=\\frac{1}{\\tan(\\frac{\\theta}{2})}\\\\L = z_{near}-z_{far}\\\\C= \\frac{z_{far}+z_{near}}{L}\\\\D= \\frac{2z_{far}z_{near}}{L}\\]In practice You must define $z_{near}, z_{far}$ $z_{far}-z_{near}$ should be as small as possible for max depth precsionTo which view space are mapped 3D world space points at $z_{near}, z_{far}$ ?Fractals IdeaRecursively add self-similar details Simple rule $\\to$ complex shape May look like complex natural detailsPerlin noise A widely used noise functionCreer une fonction pseudo-aleatoire continue MAIS deterministeOn prend des echantillons a des valeurs entiere Pour chaque on associe une tangente Utilise une fonction de hash float hash(float n) {return fract(sin(n)*1e4);} Fractal Perlin NoiseOn somme la fonction avec elle-meme en changeant ses parametres\\[g(x)=\\sum_{k=0}^N\\alpha^kf(\\omega^kx)\\] $f$: smooth Perlin noise function $N$: number of Octave $\\alpha$: persistency $\\omega$: frequency gainUsage Material texture Ridge effect Marble effect Animated textures Translation: $f(x,y+t)$ Smooth evolution: $f(x,y,t)$ Moutain-looking terrain $z=f(x,y)$ ApplicationsIn almost any complex shapeExercicePerlin Noise terrain\\[S(u,v)=\\begin{cases}x(u,v)=u\\\\x(u,v)=v\\\\z(u,v)=hg(s(u+o), s(v+o))\\end{cases}\\]The perlin noise\\[g(u,v)=\\sum_{k=0}^N\\alpha^kf(2^ku,2^kv)\\]\\[N=9\\\\\\alpha=0.4\\\\h=0.3\\\\s=1\\\\o=0\\] b: $N$ modifie a: $s$ modifie Les montagnes du fond sont des â€œnouvellesâ€ montagnes on voit plus loin f: $o$ modifie e: $h$ modifieAnimationReference surface function:\\[(u,v)\\in[0,1]^2, f(u,v)=(u,v,0)\\]How to generate the following animations ? HelpDimension of the Perlin noise ?Which parameter $(u,v,t-\\text{time})$ ? a: axe $z$ qui change $f(u,v)=(u,v,p(u+t))$ Faux! $u+t$ nous fait deplacer dans les $t$ negatifs $f(u,v)=(u,v,p(u-t))$ b: $f(u,v)=(u,v,p(u+t, v))$ c: piege ! On a le droit au bruit de Perlin 3D $(u,v,p(u,v,t))$ Quand on a des textures animees a partir de bruit de Perlin, il y a une dimension supplementaire: le temps d: similaire a la c e: $f(u,v)=(u,v,p(u-t)+up(u,v,t))$ Multiplication par $u$ car le bruit est plus important a la fin v: on ne change pas que $z$ cette fois $f(u,v)=(u+p(u,v,t),v+p(u,v,t), p(u,v,t))$ Geometry processing librariesDevelopment libraries LibIGL CGAL GeoGramViewer (+lib) Graphite MeshlabSoftware BlenderUseful CG programming libraryUseful libs Eigen GLM Assimpl DevILMinimalistic GUI ImGui NanoGui AnTweakBarFull framework QtParticle system DefinitionElement at a given position + extra parameters (mass, life time, etc)On appelle un systeme de particules en oppositionL Rigid bodies - Solid objects with static shape Deformable bodies - Continuum material that can deforms Pros Cons Lightweight rpz Simple model from physics point of view Generic flexible model (spatial deformation, no connectivity, etc) Â  Particles systems in HistoryOne of the first animated model in CGExample of particle systemFree fall of sphere under gravity Geometrical rpz of each particle: sphere Equation of motion $p(t)=\\frac{1}{2}gt^2+v_0t+p_0$ Initial position and speed may be placed at random position Each particle may have a different life timeWhat are the parameters used for $p_0$ and $v_0$ in this example ?\\[p_0=(0,0,0)\\\\v_0=(\\sin(), 1,\\cos())\\]Si on a un $\\sin$ du temps, on aurait des particules emises suivant un cercle Genre comme caOr, nos particules ne suivent pas ce cerlce, elles suivent un nombre aleatoire $\\theta$:\\(v_0=(\\sin(\\theta), 1,\\cos(\\theta))\\) Par exemple, $\\theta\\in[-\\pi,\\pi]$Bouncing spheresWhat is the equation of motion (taking into account the bouncing) ? Considere a particle emited at time $t=0$ At what time $t_i$, the particle touch the floor ? What is the new speed after impact ? What is the complete equation of trajectory ?\\[t_i=\\\\p(t)=\\frac{1}{2}gt^2+v_0t\\\\p_g(t_i)=0\\\\\\begin{aligned}\\frac{1}{2}g_yt_i^2+v_{og}t_i=0&amp;amp;\\Rightarrow\\frac{1}{2}g_yt_i=-v_{oy}\\\\&amp;amp;\\Rightarrow=-2\\frac{v_{oy}}{g_y}\\end{aligned}\\\\p(t_i)\\quad v(t_i)\\to\\begin{pmatrix}V_x\\\\-V_y\\\\V_z\\end{pmatrix}\\\\p_2(t)=\\frac{1}{2}g(t-t_i)^2+v&#39;(t_i)(t-t_i)+p(t_i)\\]General motions Motion equation is not restricted to physics-based equations What are the parameters associated to each particle ? What are the corresponding equations of motions ? On dirait que les bulles sortantes bougent en forme de cercle\\[\\text{rand}\\to[0,1]\\\\p_0=(?,0,?)\\]Comment faisons-nous pour recreer le cercle ? On randomise $x$ et $y$ entre $-1$ et $1$Or ca nous fais un carre et on veut un cercleOn tire au hasard 2 rayons $r_1$ et $r_2$\\(\\sqrt{r_1^2+r_2^2}\\gt R\\\\\\begin{cases}R\\cos(\\theta)\\\\R\\sin(\\theta)\\end{cases}\\)Avec: $r_1, r_2\\in[0,R]$ On a donc $p_0,v_0,R,C$ \\(p(t) = p_0+v_0(t-t_0)+\\begin{pmatrix}r\\cos(\\theta t-t_0+\\gamma)\\\\r\\sin(\\theta t-t_0+\\gamma)\\\\0\\end{pmatrix}\\)Avec: $\\gamma$: un offset aleatoire Billboards, impostors, sprites Particle can be displayed as small images/thumbnailsIn practice: Each particle is displayed as a quadrangle A texture is mappe on the quad The texture can contains transparencyUsageLarge use of billboard for complex models vegetation, fire, etc.ExampleUse case in production Le seigneur des anneauxComment on ete fait ces chevaux liquides ? Comment a ete filme la scene ? Il nâ€™y a que des vrais chevaux sur la scenePour lâ€™eau, les chevaux ont ete fait a partir dâ€™emission de particules Zoom sur une chute dâ€™eau La base des tetes de chevaux Couches de particules emisent a partir des tetes Ensemble final La riviere Les vrais chevaux, qui ne meurent pas Faux chevaux et cavaliers modelises pour etre emporte par la riviere" }, { "title": "PRSTA: TD 1", "url": "/cours/posts/prsta_td1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-22 15:00:00 +0200", "snippet": "Exercice 1Une variable aleatoire suit une loi normale de moyenne $m$ et de variance inconnue. Nous voulons tester lâ€™hypothtese $H_0:m=1$ contre $H_1:m\\gt 1$. Determiner la region critique de ce test pour $\\alpha=5\\%$ Solution Sous $(H_0)$:\\[T_n = \\frac{\\sqrt{n}(\\bar X_n-m_0)}{\\sqrt{S_n^2}}\\sim \\mathcal T_{n-1}\\] La zone dâ€™acceptation: on rejette uniquement a droite, on accepte lorsque \\(\\{T_n\\le t_{0.95}\\}\\) Zone de rejet: \\(\\{T_n\\gt t_{0,95}\\}\\)Exercice 6Une variable aleatoire suit une loi de moyenne $2$ et de variance inconnue. Nous voulons tester lâ€™hypothese $H_0:\\sigma^2=2$ contre $H_1:\\sigma^2\\lt2$. Pour ce faire, nous disposons des observations: $1.2$, $2.1$, $1.7$, $2$, $3$, $7$, $0$ et $1$. Determiner la $P_{valeur}$ puis decider avec un risque dâ€™erreur de premiere espece de $1\\%$? Solution On obtient\\[\\begin{aligned}S_{n}^{*} &amp;amp;= \\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2\\\\&amp;amp;= \\frac{1}{8}(-(0.8)^2 + (0.1)^2 + (-0.3)^2 + 0 +1^2+5^2+(-2)^2+(-1)^2)\\\\&amp;amp;=3.9675\\end{aligned}\\] Nous obtenons:\\[nS_n^{*} = 31,74\\\\\\] Donc:\\[\\frac{nS_n^*}{2} = 15,87\\\\\\] On a donc $\\frac{nS_n^{*}}{\\sigma}\\sim\\chi^2_8$\\[P(\\frac{nS_n^*}{2}\\lt 15,87)\\simeq 0.96\\gt 0.01\\] Donc lâ€™hypothese $(H_0)$ nâ€™est pas rejetee. Exercice 8La variable aleatoire $X$ suit une loi exponentielle de parametre $\\lambda$. Determiner la region critique du test $H_0:\\lambda=1$ contre $H_1:\\lambda=2$ pour un risque de premier espece. Solution \\(X\\sim \\varepsilon(\\lambda)\\\\\\) $H_0:\\lambda=1$ $H_1:\\lambda=2$ \\[\\begin{aligned}T&amp;amp;=\\frac{L(X_n,\\dots,X_m,1)}{L(X_1,\\dots,X_m,2)}\\\\&amp;amp;=\\frac{\\Pi_{i=1}^n1e^{-1X_i}}{\\Pi_{i=1}^n2e^{-2X_i}}\\\\\\end{aligned}\\] Quelle formulle appliquons-nous ? Un $\\log$ \\[\\begin{aligned}T&amp;amp;=\\frac{e^{-\\sum X_i}}{2e^{-2ZX_i}}\\\\&amp;amp;=\\frac{1}{2^n}e^{\\sum}\\end{aligned}\\] Rejet de $(H_0)$: ${T\\gt9\\alpha}$ \\[\\begin{aligned}T&amp;amp;\\gt S_{\\alpha}\\\\\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\-n\\log(2)+\\sum_{i=2}^nX_i&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\sum_{i=1}^nX_i&amp;amp;\\gt n\\underbrace{\\log(2)+\\log(S_{\\alpha})}_{\\color{green}{c_{\\alpha}}}\\end{aligned}\\] On a en region critique:\\[\\color{green}{\\{\\sum_{i=1}^nX_i\\gt c_{\\alpha}\\}}\\] Or \\(\\sum_{i=1}^n X_i\\sim\\gamma(n,1)\\)" }, { "title": "PRSTA: Seance 1", "url": "/cours/posts/prsta_seance1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-22 14:30:00 +0200", "snippet": " Point de depart: hypothese formulee sur la population totale Jugement sur echantillon Tests dâ€™hypothese 2 hypotheses: hypothese nulle notee $H_0$ Situation de reference Hypothese soumise au test hypothese alternative notee $H_1$ Objectif: prise de decision a partir des donnees de lâ€™echantillon Ecarts eventuels entre lâ€™echantillon et la population du au hasard de lâ€™echantillonageTypes de tests Test parametrique/non-parametrique Test dâ€™adequation Est-ce que 2 valeurs sont egales ? Test de comparaisonPoint de depart En cas de rejet de lâ€™hypothese nulle Les ecarts sont dits significatifsPlusieurs interpretation: Loi de distribution inadaptee Echantillon non homogene Melange des populations avec des caracteristiques differentes Ecart du a des variations Echantillonnage pas effectue au hasardQue faire ? isoler des echantillons plus homogenes preiciser les facteurs de variation influant sur les observations Si lâ€™hypothese pas nulle nâ€™est pas rejetee Elle nâ€™est pas demontree pour autant Elle nâ€™est pas contredite par les faitsExemple grossier Dans une foret, il y a $20\\%$ de serpents venimeux Francois preleve $100$ serpents et $38$ sont venimeux Intervalle de fluctuation au seuil $0.95$\\[\\biggr[p-\\frac{1}{\\sqrt{n}};p+\\frac{1}{\\sqrt{n}}\\biggr] = [0.10; 0.30]\\] TheoremePour $95\\%$ des echantillons, la proportion $f$ appartient a cet intervalle sous les conditions suivante: $n\\ge30$ $np\\ge5$ $n(1-p)\\ge5$ $f=0.38\\not\\in[0.10;0.30]$ On peut en deduire: Echantillon non representatif Variations pas dues au hasardAssertion sur la foret fausse ?Autre exemple $x_1,\\dots,x_n$ observations provenant dâ€™une loi $\\mathcal N(m,\\sigma^2)$ $\\sigma^2$ suppose connu $n$ quelconque, variables aleatoires normales\\[\\frac{\\sqrt{n}}{\\sigma}(\\bar X-m)\\sim\\mathcal N(0,1)\\\\\\]Quâ€™est-ce quâ€™on doit retenir ? Un truc qui depend de lâ€™echantillon$\\mathcal N(0,1)$ ne depend plus du parametre, on peut sâ€™amuser sans connaitre $m$ La loi ne depend pas du parametreOn va tester: $H_0:m=m_0$ $H_1:m\\neq m_0$Prenons les etudiants dâ€™Epita. Leur taille suit une loi normale de moyenne $1.70m$ et variance $0.05m$ $H_0:m=1.7$ $H_1:m\\neq1.7$Hypothese $(H_0)$\\[\\frac{\\sqrt{n}(\\bar X_n-m_0)}{\\sigma}\\]suit une loi normale centree reduite.Dâ€™apres les cours precedents\\(\\mathbb P(-1,96\\le\\frac{\\sqrt{n}(\\bar X_n-m_0}{\\sigma}\\le1,96)\\simeq0,95\\) Calculons $\\bar x$ sur lâ€™echantillon Si $\\frac{\\sqrt{n}(\\bar x-m_0)}{\\sigma}\\in[-1,96;1,96]$, lâ€™hypothese $H_0$ est rejetee au seuil de signification $\\alpha=5\\%$ Sinon lâ€™hypothese est acceptee Seuil de signification $\\alpha$: Proba de rejeter lâ€™hypothese nulle lorsque celle-ci est vraie Appele risque de premiere espece cf faux negatifs en medecine Test covid negatif en etant malade Le risque de deuxieme espece $\\beta$ est lâ€™inverse Proba dâ€™accepter lâ€™hypothese nulle lorsquâ€™elle est fausse On ne peut pas baisser un risque sans augmenter lâ€™autre Region critiqueCâ€™est la region ou on accepteTest de comparaison dâ€™une proportion Meme principe pour $n$ grand $\\sqrt{n}\\frac{\\hat p-p_0}{\\sqrt{p_0(1-p_0)}}$ suit approximativement une loi normale centree reduite Test bilateral $H_0:m=m_0$ et $H_1:m\\neq m_0$ Test unilateral $H_0:m=m_0$ et $H_1:m\\lt m_0$ Zone de rejet et region critique differentExemplesPremier exemple $X$ suit une loi $\\mathcal N(m,\\sigma^2)$ avec $\\sigma^2$ connu Test bilateral $H_0:m=m_0$ et $H_1:m\\neq m_0$ Statistique $Z_n:=\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sigma}$Sous lâ€™hypothese $(H_0)$, $Z_n$ suit une loi normale centree reduite. Zone de rejet: $]-\\infty;z_{1-\\alpha}[\\cup]z_{1-\\alpha;+\\infty}[$ Region critique\\(\\biggr\\{\\frac{\\sqrt{n}\\vert \\bar X_n-m_0}{\\sigma}\\gt z_{1-\\alpha}\\biggr\\}\\) $z_{1-\\alpha}$: fractile dâ€™ordre $1-\\alpha$ de la loi normale centree reduiteSecond exemple $X$ suit une loi $\\mathcal N(m,\\sigma^2)$ avec $\\sigma^2$ inconnu Test unilateral $H_0:m=m_0$ et $H_1:m\\lt m_0$ Statistique\\[T_n=\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\]Sous lâ€™hypothese $(H_0)$, $\\mathcal T_n$ suit une loi $T_{n-1}$ Zone de rejet: $]-\\infty;-t_{1-\\alpha}[$ Region critique:\\(\\biggr\\{\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\le =t_{1-\\alpha}\\biggr\\}\\) $t_{1-\\alpha}$: fractile dâ€™ordre $1-\\alpha$ de la loi de Student a $n-1$ degre de liberteMethode de la valeur critique Methode due a Neyman et Pearson Approche ensembliste Ensemble des valeurs observees de la stat du test provoquant un rejet Zone de rejet Complementaire de cet ensemble: zone de non-rejet valeur separant ces 2 ensembles valeur critiqueMethode de la proba critique $\\alpha$ est fixe proba critique ou $P_{valeur}$: plus petite valeur du risque dâ€™erreur pour laquelle la decision serait de rejeter $H_0$ Si $P_{value}\\le\\alpha$, $H_0$ est rejetee Si $P_{value}\\gt\\alpha$, pas de raison de rejeter $H_0$ au risque de premiere espece $\\alpha$ExempleDuree de vie des ampoules fabriquees par un industriel $H_0:m=8000$ $H_1:m\\neq8000$ $\\alpha=5\\%$On a un echantillon de $100$ ampoules.\\[Z_n:=\\sqrt n\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\]suit approximativement une loi normale centree reduite $P_{value}=\\mathbb P(Z_n\\lt -1.51)\\simeq0.0655$ $P_{value} \\gt\\alpha$, pas de raison de rejeter lâ€™hypothese $(H_0)$" }, { "title": "RVAU: Realite virtuelle pour la maintenance industrielle", "url": "/cours/posts/rvau_realite_virtuelle_edf/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 11:00:00 +0200", "snippet": "Lien de la note HackmdProjet I-BR (2013-2016)VVProPepa Visite virtuelle du batimenent reacteurPourquoi ? Chez EDF il y a un gros projet de maintenance pour prolonger la duree dâ€™exploitation de nos centrales nucleaires actuelles Pour optimiser les preparations dâ€™interventions en BR pour augmenter le temps metal Numerisation dâ€™un batiment reacteurBorne tactile VVProPrejobTirs radio Pour detecter les problemes de soudure Comme une radio sur un etre humainPlan de balisageVirage: Realite virtuelle et augmenteeKenny: chantier ecole en realite augmenteeVoir les donnees de capteurs de Vercors sur le terrain" }, { "title": "RVAU: Introduction a la Realite Virtuelle", "url": "/cours/posts/rvau_intro/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 10:00:00 +0200", "snippet": "Lien de la note HackmdRealite virtuelleCâ€™est quoi ? Câ€™est toutes les technologies utilisees pour immerser un humain dans un monde virtuel Contrairement au cinema, on est acteurTerme introduit par Jaron Lanier en 1988 Maybe we should go over what Virtual Reality is. We are speaking about a technology that uses computerized clothing to synthesize shared reality.Une definition â€œLa realite virtuelle est un domaine scientifique et technique, exploitant lâ€™informatique et des interfaces comportementales en vue de simuler dans un monde virtuel le comportement dâ€™entite 3D, qui sont en interaction en temps reel entre elles et avec un ou des utilisateurs en immersion pseudo-naturelle par lâ€™intermediaire de canaux sensori-moteursâ€P. Fuchs, Le traite de la realite virtuelle vol. 1 Câ€™est un univers 100% virtuelRealite augmenteeIl faut la distinguer par rapport a la VR Le but est dâ€™incruster sur le monde reel des elements du monde virtuelRealite mixteUn continuu, dâ€™experiences sensoriellesHistorique Stereoscope Premiere forme de la VR dâ€™aujourdâ€™hui Câ€™etait pour les images fixes Sensorama (1962) The ultimate display (1965) Premiere reference a la VR Pas une invention, une vision du futur de lâ€™informatique The sword of Damocles (1968) Le premier casque VR Tellement lourd quâ€™il devait etre accroche au plafond GROPE Haptic display (1967-1988) Simule le toucher Dataglove Vived Combinait lâ€™affichage avec des gants Avec commandes vocales EyePhone (1989) Premier iPhone Coutait 10k$ View (1990) Cave (1992) Dispositif different Immersion avec des projecteurs SPIDAR (1992) Genere un retour de force Genre bague reliee a un fil Flock of Birds (1992) Casque pour le jeu video (90â€™s) Technologie encore balbutiante Annees 2000-2010 Casque de lâ€™ordre de 20k$ Plus grosse resolution: 6 millions de pixels par oeil Par comparaison: 1er occulus, 500k pixels par oeil Cave de Renault 5 faces $2\\times4k$ par face Plusieurs millions dâ€™euros Haption Virtuose 6D (2001) Depuis 2010 Leap motion (2013) Caracteristiques de RVImmersion Mesure selon laquelle le peripherique de RV est capable de remplacer les stimulations sensorielles du monde reel par celui du monde virtuel Pour chacun de nos sens, la simulation est panoramique Un appareil qui peut en simuler un autre est plus immersif que ce dernier Un casque peut simuler un ecran de PC, il est plus immersifPresence Le sentiment dâ€™etre present dans lâ€™environnement virtuel Sur lâ€™image a droite, pour passer de droite a gauche, tout le monde a fait le tour du trou au lieu de passer par-dessus (alors que le sol est en-dessous, il nâ€™allait pas tomber)Affichage pour la realite virtuellePeripherique dâ€™affichage En haut a droite: workbench Ecran 3D avec dispositif dâ€™interactions Possibilite dâ€™interagir avec une maquette Donne une zone de travail Rendu 3D Model au monde: Projection: Pyramide de vue: Near clipping: distance minimale pour voir les objets Far clipping: distance max Z-Buffer Shaders Stereoscopie Bawi on veut de la 3D On a dans notre monde virtuel 2 camerasPlusieurs facons de le faire: Anaglyphe Filtre de couleurs Une couleur par oeil pb: rendu des couleurs fausse Ce nâ€™est pas du tout utilise pour la RV Stereoscopie active Besoin dâ€™electricite Va occulter chaque verre lâ€™un apres lâ€™autre en permanence Pour du 60 fps, on va faire du 120 fps et afficher une fois pour lâ€™oeil droit et une fois pour lâ€™oeil gauche Seteroscopie passive Lunettes beaucoup plus legeres Filtres polarisants 2 projecteurs differents Certains rayons pour lâ€™oeil gauche, dâ€™autre pour lâ€™oeil droit Ecrans auto-stereoscopiques Ce sont des ecrans qui nâ€™ont pas besoin de lunettes pour etre vus en 3DInconvenients: ca reduit la resolution de lâ€™ecran par 2 Il suffit de se deplacer un peu pour que la 3D saute Câ€™est utilise pour la 3DS :0Dans un casque de RV On applique une correction avec les lentilles pour lâ€™effet vignetteCalibration Probleme pour les caves Les images doivent etre coherentes et geometriquement justesInteractions pour la RVPeripheriques dâ€™interactionMetaphores dâ€™interaction Metaphore Au lieu dâ€™exploiter un comportement sensori-moteur et acquis de la personne, nous lui proposons, visuellement en gÃ©nÃ©ral, une image symbolique de lâ€™action ou de la perception souhaitÃ©e Manipuler un objet ? Utiliser une manette, un pointeur, etc. Utiliser une main virtuelle Co-localisation Que la main virtuelle apparaisse a lâ€™endroit de notre main reelle GestesGizmos Des â€œpoigneesâ€ utilisees pour deplacer les objets dans le monde virtuel Rayon Comme un rayon laser, on vise un objet pour interagir avec Portal-gun style TactileControles de lâ€™applicationMetaphores de navigationComment se deplacer dans lâ€™environnement virtuel ? On pointe et on se teleporteUn utilise un joystickUn tapis roulant dans toutes les directionsRoom scale Beaucoup utilise par les casques Utilise par HTC viveDeplacement continuTeleportation libreTeleportation point a pointMateriel dedieMonde en miniatureRedirected walkingOn tourne legerement lâ€™environnement virtuel, pour faire un mouvement courbe IRL en allant tout droit IVLRealite augmenteeLe but est dâ€™incruster des elements virtuel au monde reel.Mais comment ? Vue indirecte (video see-through) Aka pokemon go Vue indirecte (optical see-through) Donne lâ€™impression que lâ€™objet virtuel est reel Projection dans lâ€™environnement Dans le cas dâ€™une voiture Nouveaux peripheriques de realite augmentee Hololens Ces peripheriques peuvent embarquer differents capteurs" }, { "title": "RVAU: Organisation du cours", "url": "/cours/posts/rvau_organisation_du_cours/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 09:00:00 +0200", "snippet": "Lien de la note HackmdParcoursArnaud Mas: chez EDF Ingenieur UTC Master recherche Arts et Metiers ParisTech These CIFRE Renault/Arts et Metiers ParisTech Ingenieur-chercheur en realite virtuelle chez EDFProgramme 22/09 - Introduction a la RV $\\frac{1}{2}$ 29/09 - Introduction a la RV $\\frac{2}{2}$ 06/10 - TP Unity 1 13/10 - Presentations intermediaires projets + TP Unity 2 08/12 - TP Unity 3 15/12 - TP Unity 4 12/01 - Facteurs humains de la RV 02/02 - Presentation projetsProjet Sujet: collaboration en RV Fight face a face, etc. Travail en groupe de 4 13/10: prez intermediaire 02/02: prez finale Pour le 29/09: formation des groupesRendu pour le 02/02 Presentation orale Support avec videoA installer Unity: 2020.3 (LTS) Passer par Unity Hub !" }, { "title": "ALGOREP: What is Model-Checking ? How to build a Model Checker ?", "url": "/cours/posts/algorep_model_checking/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-20 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursSi on a un ping pong, comment on verifie que lâ€™algo marche ? On lance et un espere que ca marche?Non ca câ€™est etre religieux Il faut check toutes les relations et entralecements possibles (effets de bord, etc). Il faut faire des preuves automatiquesOn va prendre des outils capables dâ€™en faire, en utilisant La description $\\neq$ implementation du systeme distribue Sâ€™abstraire des pbs de langage Quâ€™est-ce quâ€™un systeme ?On veut quâ€™une fusee nâ€™explose pas en volWhy is a model required ?On va considerer que TOUS les systemes quâ€™on etudie soit un systeme infini.Le code suivant serveur peut etre considere un systeme:unsigned received_= 0;while (1){ accept_request(); received_ = received_ + 1 ; reply_request();} Avec un modele, on enleve le probleme de received_A more realistic exampleOn a une abstraction des differents comportements de notre systemeOn est capable de construire lâ€™integralite du systeme. On veut faire le produit cartesien de tout le monde.A lâ€™etat initial du systeme, tout le monde est dans lâ€™etat $1$.Pour passer de lâ€™etat $111$ a lâ€™etat $211$, on doit avoir en meme temps un message recu et en transit.Est-ce quâ€™on peut avoir 2 envois simultanement ?Kripke structureOn definit un alphabet, un etat, une transition.Example On utilise des booleens quâ€™on appelle des propositions atomiques On etiquete notre modele pour savoir si on peut atteindre un cheminHow to express finite behavior ?Combien de propositions atomiques ? 3 (rouge, orange, vert)Comment on exprime les comportements a lâ€™infini ? On utilise une logiqueLinear Temporal LogicOn sâ€™interesse aux operateurs: $U$: â€œvrai jusquâ€™a quâ€™autre chose soit vraiâ€ $X$: â€œa la prochaine etape câ€™est vraiâ€GloballyFinallyNextUntilRetour au feu rougeAutomata for model checking Buchi: Transformer une logique dâ€™evenement en automate Express property automatonAutomata approach for model checkingOn a reussi a creer un modele pour Aut. A et Kripke. On fait un produit synchronise Produit synchroniseOn a lâ€™automate de la propriete On a lâ€™automate du systeme. Quand on lit $d_1$ et $r_1$, on doit sâ€™assurer de lire la meme chose dans notre systeme, on supprime les chemins qui font diverger ces valeurs, par le produit cartesien.On regarde cette automate, si on trouve une pastille noir qui sâ€™appelle en boucle, on a un contre-exemple a notre propriete. La reponse est oui" }, { "title": "OCVX2: Programme Lineaires", "url": "/cours/posts/ocvx2_prog_lineaire/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-20 10:00:00 +0200", "snippet": "Lien de la note HackmdOCVX2: Programme LineairesQuelques changements par rapport a ce qui etait prevu OCVX le retourOCVX qui ne va pas se passer comme prevuBashar doit reprendre une partie du boulot de Corinne, pour pas quâ€™il creve il ne fera pas OCVX2 et Guillaume fera tout $\\to$ OCVX2 allege :( On verra les bases Pas de TP Ex: pas de TP sur lâ€™implem dâ€™un SVM Mais on aura tout le reste Evaluation: partiel Essaiera de le caler premiere quinzaine de Novembre Semaine prochaine: pas de cours jusquâ€™a 19h Programme lineaire On cherche a minimiser $f_0(x)$ $x\\in\\mathbb R^n$ tel que $f_i(x)\\le 0$ avec $i=1,\\dots,p$, $f_0, f_i$ $(i=1,\\dots,p)$ fonctions affine. On note ce probleme $P_1$.\\[\\begin{matrix}\\text{minimiser}&amp;amp;f_0(x)&amp;amp;x\\in\\mathbb R^n\\\\\\text{tel que}&amp;amp;f_i(x)\\le 0&amp;amp;f_0,f_i&amp;amp;\\text{fonctions affines}\\\\&amp;amp;i=1,\\dots,p\\end{matrix}\\]Exercice 1Soit $A_u$ le lieu de $\\mathbb R^2$ decrit par les contraintes\\[A_u\\begin{cases}-x+2y&amp;amp;\\le -1\\\\x+y&amp;amp;\\le 1\\end{cases}\\]Et $A_b$ le lieu decrit par les contraintes de $A_u$ auxquelles on ajoute $x-3y\\le 6$On va se donner un espace \\[A_u=\\biggr\\{(x,y)\\in\\mathbb R^2\\text{ tq } \\begin{aligned} -x+2y &amp;amp;\\le 1&amp;amp;(D_1) \\\\ x+y&amp;amp;\\le1&amp;amp;(D_2) \\end{aligned}\\biggr\\}\\] \\[A_b=A_u\\cap\\{(x,y)\\in\\mathbb R^2\\text{ tq } \\underbrace{x-3y\\le 6}_{(D_3)}\\}\\] Etudier le programme lineaire de lieu admissible $A_u$ et minimisant $y$. Que se passe-t-il si on remplace $y$ par $-y$ ? A-t-on toujours une valeur minimale pour un programme lineaire ayant pour lieu admissible $A_b$ ? Etudier le programme lineaire de lieu admissible $A_b$ et minimisant $x+y$. Effectuer cette meme etude pour la fonction objectif $-x-y$ Solution Question 1\\[\\text{min } f_0(x,y)=y\\quad x\\in A_u\\]\\[(D_1): -x+2y+1=0\\] Comment obtenir le vecteur directeur ?\\[ax+by+c=0\\\\\\vec u=\\binom{-b}{a}\\\\\\] Comment obtenir le vecteur normal ?\\[ax+by+c=0\\\\\\vec n=\\binom{a}{b}\\\\\\] Donc:\\((D_1):\\begin{cases}\\vec u_1 = \\binom{-2}{-1}\\\\\\vec n_1 = \\binom{-1}{2}\\end{cases}\\\\(1,0)\\in(D_1)\\) On obtient graphiquement: Maintenant avec le vecteur normal: Dans quel demi-espace sommes nous ? Le demi-espace positif est du cote du vecteur normal et le demi-espace negatif est de lâ€™autre On sâ€™interesse a $-x+2y+1\\le0$ donc on sâ€™interesse au demi-espace negatif car la contrainte est $-x+2y\\le 1\\Rightarrow -x+2y-1\\le 0$. On fait la meme procedure pour $(D_2)$:\\[(D_2):x+y-1=0\\\\\\vec u_2 = \\binom{-1}{1}\\\\\\\\vec n_2 = \\binom{1}{1}\\\\(1,0)\\in(D_2)\\] On cherche notre programme lineaire sur lâ€™intersection de ces 2 contraintes On cherche a minimiser $y$, on part donc â€œvers le basâ€. Notre lieu admissible nâ€™est pas borne vers le bas donc dans ce cas, la valeur optimale est $-\\infty$. \\[(P_2): \\text{min }-y\\\\(x,y)\\in A_u\\] On veut minimiser $-y$ donc on veut maximiser $y$.\\[(x^+,y^+)=(1,0)\\quad\\text{et}\\quad f_0(x^+,y^+)=0\\] Question 2 On va faire exactement pareil en etudiant $(D_3): x-3y-6=0$\\[\\vec u_3=\\binom{3}{1}\\\\\\vec n_3=\\binom{1}{-3}\\\\(0,-2)\\in(D_3)\\] En intersection de ces 3 contraintes: Est-ce quâ€™on programme lineaire a toujours une valeur minimale sur $A_b$ ? Oui car le lieu admissible $A_b$ est borne Question 3 $(P_3)$: minimiser $f_0(x,y)=x+y, (x,y)\\in A_b$ $1^{ere}$ etape: on trace une ligne de niveau Rappel\\[\\mathcal C_0(f_0)=\\{(x,y)\\in\\mathbb R^2, \\begin{aligned} f_0(x,y)&amp;amp;=0 \\\\ x+y&amp;amp;=0 \\end{aligned}\\}\\] \\[\\vec u_0 = \\binom{-1}{1}\\\\\\vec n_0 = \\binom{1}{1}\\\\(0,0)\\in\\mathcal C_0 (f_0)\\] On a defini le gradient de notre fonction, on descend a lâ€™oppose de notre vecteur normal pour trouver la solution. On fait une descente de gradient Graphiquement, la solution est lâ€™intersection de la droite $(D_1)$ et la droite $(D_3)$. Pour determiner les coordonnees de ce point, il doit verifier les equations des 2 droites:\\[\\begin{aligned}&amp;amp;\\begin{cases}-x^*+2y^*+1 = 0\\\\x^*-3y^*-6=0\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}y^*=-5\\\\x^*=-9\\end{cases}\\end{aligned}\\] Point optimal \\[p^{*} = (-9,-5)\\] Valeur optimale: \\(\\begin{aligned} f_0^*&amp;amp;=f_0(x^*,y^*) \\\\ &amp;amp;= x^*+y^* \\\\ &amp;amp;=-14 \\end{aligned}\\) Exercice 2Donnez un exemple de programme lineaire:Non borne Solution\\[\\text{min}_{(x,y)\\in A_u} y\\]De lieu admissible non borne mais de solution finie Solution\\[\\text{max}_{(x,y)\\in A_u} y\\]Ayant une infinite de solutions/points optimaux Solution\\[\\text{max}_{(x,y)\\in A_b} x+y\\]Ayant une unique solution Solution\\[\\text{min}_{(x,y)\\in A_b}\\]Exercice 3On considere le programme lineaire suivant\\[\\begin{matrix}\\text{(P)}&amp;amp;\\text{minimiser}&amp;amp;f_0(x,y)=3x+2y\\\\&amp;amp;\\text{sujet a}&amp;amp;x-y\\le 0\\\\&amp;amp;&amp;amp;4x-y\\ge 1\\\\&amp;amp;&amp;amp;-x-y\\ge-5\\end{matrix}\\] Representer le lieu admissible de $(P)$ dans le plan euclidien Tracer $\\mathcal C_6(f_0)$ la courbe de niveau $6$ de la focntion objectif de $(P)$. Indiquer les demi-espcaes positifs et negatif definis par $\\mathcal C_6(f_0)$. Dans quelle direction translater $\\mathcal C_6(f_0)$ afin de minimiser $f_0$ ? Tracer la courbe de niveau qui realise le minimum de $(P)$ et calculer lâ€™unique point optimal de $(P)$. Quelle est la valeur optimale de $(P)$ ? Methode Lieu admissible Courbe de niveau de $f_0$ Point optimal (geometriquement) Point optimal (analytiquement) Valeur optimale Solution Question 1 Question 2 On cherche a minimiser, on translate dans la direction opposee au vecteur normal. Question 3\\[p^{*}\\in(D_1)\\cap(D_2)\\\\p^{*}=\\biggr(\\frac{1}{3},\\frac{1}{3}\\biggr)\\\\f_0^{*}=f_0(x^*,y^*)=\\color{red}{\\frac{5}{9}}\\] Comment on trouve la courbe de niveau 6 ?\\[\\begin{aligned}C_6(f_0)=\\{(x,y)\\in\\mathbb R^2, f_0(x,y)&amp;amp;=6\\}\\\\3x+2y&amp;amp;=6\\\\3x+2y&amp;amp;=0\\end{aligned}\\]Exercice 4On considere le programme lineaire suivant\\[\\begin{matrix}\\text{(P_2)}&amp;amp;\\text{minimiser}&amp;amp;f_0(x,y)=x+2y\\\\&amp;amp;\\text{sujet a}&amp;amp;-1\\le x\\le 1\\\\&amp;amp;&amp;amp;-1\\le y\\le 1\\\\\\end{matrix}\\]Resoudre $(P_2)$ en suivant la demarche precedente Solution Sujet a\\[\\begin{aligned}\\begin{aligned}x&amp;amp;\\le1\\\\-x&amp;amp;\\le1\\end{aligned}\\Biggr\\} \\vert x\\vert\\le1\\\\\\begin{aligned}y&amp;amp;\\le1\\\\-y&amp;amp;\\le1\\end{aligned}\\Biggr\\}\\vert y\\vert\\le 1\\end{aligned}\\Biggr\\}\\Vert\\binom{x}{y}\\Vert_{\\infty}\\le1\\] \\[p^*=(-1,-1)\\\\f_0^*=-3\\]" }, { "title": "ALGOREP: Raft", "url": "/cours/posts/algorep_raft/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-17 16:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOverview GoalReplicate logs (commands) in a set of servers On va avoir des indexs Des informations quâ€™on va mettre sur chaque index/ligne On veut que tout le monde ait le meme log OverviewOnce all servers agree for a log entry, all server can run it $\\Rightarrow$ All server will then compute the same value (replication) Câ€™est exactement le projetLimitations and restrictions On veut elire un chef a la majoriteComparaison avec Paxos Paxos est de lâ€™approche distribuee Raft non, il y a un leader et tout le monde communique avec le chef Avantage: une machine est chef que pendant un laps de temps Summary Election Operation normal Coherence de lâ€™algo Problemes quâ€™on peut avoirServer state3 roles: Leader Follower CandidateChaque server commence follower:Time divided into Terms On va faire par epoch On veut un chef par epoch En fonction des processus qui meurent et naissent, on peut avoir de lâ€™info obsoleteRaft est un algo pessimiste qui va passer son temps a nettoyer.Heartbeats Leader can send heartbeat to keep authorityLeader changes Chacune des cases est remplie avec des actions Lâ€™info stockee sur $S_1$ a la premiere ligne du log a ete calculee pendant la $1^{ere}$ epoch Ensuite viennent les complicationsLe log est stable sur les 2 premieres colonnesMais apres ? Lâ€™information de $S_4$ nâ€™a pas ete propagee Il faut faire attention a lâ€™information locale et celle connue par tout le monde On ecrit lâ€™information locale quand elle est acceptee par tout le mondeElection basics Increment current term Change to Candidate state Vote for self Send RequestVote RPCs to all other servers, retry until either Receive votes from majority of servers Become leader Send AppendEntries heartbeats to all other servers Receive RPC from valid leader Return to follower state No-one wins election (election timeout elapses) Increment term, start new election Properties of the electionSafety: allow one winner per term Each server gives out only one vote per term 2 different candidates canâ€™t accumulate majorities in same termLiveness: some candidate must eventually winHow to replicate log entries ? On veut un log coherent par rapport aux differents serveursOn a: Des entrees Avec des commandes Le terms Des indexsNormal operationsLâ€™algorithme commence a tourner. Le client envoie une commande au leader Le leader prend la commande et le met dans son log Le leader envoie AppendEntries RPCs aux followers Une fois que lâ€™entree est prise Leader passes command to its state machine, returns result to client I Leader notifies followers of committed entries in subsequent AppendEntries RPCs Followers pass committed commands to their state machines Crashed/slow followers ? â‡’ Leader retries RPCs until they succeedExample 1 $S_4$ et $S_5$ sont en retard Vu quâ€™il sont en retard, si on declenche une nouvelle epoch ils ne peuvent pas etre chefQuel probleme peut-on avoir ? Ca peut accentuer les gens en avance et en retard en fonction des epochsOn va avoir des sous-systemes qui vont se creer avec des logs pas coherentsExample 2On a un truc bizarre, $S_5$ nâ€™a pas dâ€™epoch 2. On a une divergence.Pour lâ€™epoch 5, $S_5$ peut etre elu car il a un log long, mais pas coherent avec celui des autres. Il va donc demander des rollabacks jusquâ€™au dernier point dâ€™intersection.New commitment rulesFor a leader to decide an entry is committed : Must be stored on a majority of servers At least one new entry from leaderâ€™s term must also be stored on majority of serversClient protocol" }, { "title": "ALGOREP: Consensus is possible ! Paxos", "url": "/cours/posts/algorep_paxos/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-17 15:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursA Word on Paxos â€œOn va abandonner les systemes distribues câ€™est trop chiantâ€Lamport: a prouve accidentellement que ca marcheEst-ce que Paxos câ€™est dur ? Ca depend des gens On veut arriver au consensus mais pas gagner Comme si tous les candidats a la presidentielle veulent que quelquâ€™un soit eluIntuitionOn veut aller manger, tout le monde a faim et on a pas de chef. On peut discuter que un a un. Des gens ont une idee initiale et des gens vont suivreQuâ€™est-ce quâ€™il peut arriver ? Soit aucune idee nâ€™est accepteeSoit on arrive pas a avoir une majorite (â€œTu veux manger quoi ?â€ â€œMâ€™en fouâ€)Problem: Split votesConsider 5 processes: P1, P2 accepts $\\color{red}{red}$ P3, P4 accepts $\\color{blue}{blue}$ P5 accepts $\\color{green}{green}$Comment on fait ? P5 rejoint un des groupes et tout le monde rejoint la majorite ?Comment P5 connait lâ€™etat des autres ? On va les faire fight en 1v1 gare du nord On a rouge et noirOn va envoyer un message a tousAvec le delai de propagation des messages, on va dire oui a noir ou oui a rougeSi noir arrive en premier, noir sera choisi, sinon rouge le seraSi on a propose noir et quâ€™on dit oui a rouge, alors on transmet le message comme quoi on propose rouge maintenantExamplePaxosBasic Paxos2 phases On va envoyer des messages Prepare â€œJe vais bloquer toutes les anciennes propositionsâ€ Broadcast accept â€œJâ€™accepte ta valeurâ€ Conceptual Roles in Paxos Proposer Acceptors Learners: learn the outcomeOverviewPhase 1 $[Proposer]$ Choose a proposal number $n$ $[Proposer]$ Broadcast prepare(n) to all servers $[Acceptor]$ Response to prepare(n) if $n\\gt minProposal$ then $minProposal=n$ Return (accepted_proposal, accepted_value) $[Proposer]$ When responses received from majority if any accepted_value returned, replace value by accepted value for highest accepted_proposal Phase 2 $[Proposer]$ Broadcast accept(n, value) to all servers $[Acceptor]$ Response to accept(n, value) if $n \\ge minProposal$ then accepted proposal = min proposal = n, accepted value = value Return (min proposal) $[Proposer]$ When responses received from majority Any objection $(result \\gt n)$ ? restart Otherwise, value is chosen Example 2Example 3Liveness Competing processes can livelock ! Les processus se battent pour avoir le dernier de la majoriteSolutions Randomized delays before restartingMulti-Paxos Create a replicated log" }, { "title": "PBR: Real-time Implementation", "url": "/cours/posts/pbr_real_time_implementation/", "categories": "Image S9, PBR", "tags": "Image, S9, PBR", "date": "2021-09-17 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du coursBefore we startComment on genere une image ? On a vu le raytracing On a vu la rasterization On va se focus sur le temps reel avec de la rasterizationOld TimesLambertOn a tous fait un Lambert model Plus lâ€™angle est eleve entre la normal et la lumiere, moins il nâ€™y a dâ€™energie Il nâ€™y a pas de modele $100\\%$ diffus En une seule operation on a notre BRDF Il existe dâ€™autres modeles mais la difference visuelle nâ€™est pas assez bonne pour etre utilisesPhong Approximation pas tres bonne MAIS precurseur a son epoque ($â€™70s$)Pas de conservation dâ€™energie:PseudocodeLambertvoid main(){ vec3 diffuse = kD * dot(normal, lightDirection) * color; gl_FragColor.rgba = vec4(diffuse, 1.0);}Phongvoid main(){ vec3 r = reflect(- viewDirection, normal); vec3 diffuse = kD * dot(normal, lightDirection) * color; vec3 specular = kS * pow(max(dot(lightDirection, r)), exponent); gl_FragColor.rgba = vec4(diffuse + specular, 1.0);}What and whyIntroduction Non-physical model requires a lot of tweaking Si on a un artiste qui fait une scene en exterieur puis on lui dit quâ€™on doit aller dans un tunnel en voiture, lâ€™artiste pleureIl doit tweaker les materiaux pour que ca ait lâ€™air joli en fonction de la lumiere Câ€™est pour ca quâ€™il y a eu lâ€™avenement du Real Time Rendering vers 2013 Câ€™est dur de definir le PBR Definition: PBRModele mathematiques et approximations que nous allons tous suivre pour decrire les interactions entre la lumiere et la matiereWhat is PBR ?Pourquoi câ€™est populaire ? Decrit le monde plus precisement, donne des rendus realistesTout le monde utilise plus ou moins les memes inputsMoins de tweaking Win-win pour les ingenieurs et artistesMicrofacets Theory Ce modele approxime ce quâ€™il se passe dans la vraie vie On dit que tous les materiaux sont composes de miroirs plus ou moins alignesCâ€™est quoi la difference entre un miroir et un plastique ? Notre premier cas sera un miroirLe second est un materiaux super diffusDielectrics vs ConductorsConductorsLa couleur diffuse serait une approximation du sub-surface scattering Les conducteurs reflete $0-20\\%$ de la lumiere Les metaux nâ€™ont pas de sub-surface scattering Les conducteurs refletent $60-90\\%$ de la lumiere Certains conducteurs ont leur couleur propre due aux longueurs dâ€™ondes absorbeesBRDFBRDF Simplification\\[f_r(p,\\omega_0,\\omega_i)=f_d(p,\\omega_0,\\omega_i) + f_s(p,\\omega_0, \\omega_i)\\] Notre BRDF devient pulg &amp;amp; play On peut remplacer par ce quâ€™on veut du moment que $\\int\\le1$Implementation notes\\[f_r(p,\\omega_0,\\omega_i)=k_df_d(p,\\omega_0,\\omega_i) + k_sf_s(p,\\omega_0, \\omega_i)\\\\k_d+k_d\\le1\\]Diffuse Lobe\\[f_d(p,\\omega_0,\\omega_i) = \\frac{\\rho}{\\pi}\\] $\\rho$: reflectance spectrumSpecular Lobe\\[f_s(p,\\omega_0,\\omega_i)=\\frac{D(\\omega_0,\\omega_i)F(\\omega_0,\\omega_i)G(\\omega_0,\\omega_i)}{4(\\omega_0,\\omega_i)(\\omega_i\\times n)}\\]Specular BRDF\\[D_{GGX}(n,h,a)=\\frac{\\alpha^2}{\\pi((n\\times h)^2(\\alpha^2-1)+1)^2}\\\\\\vec h=\\frac{\\vec v+\\vec L}{\\Vert\\vec v+\\vec L\\Vert}\\] Normal distribution function $D(\\omega_0, \\omega_i)$ Estimates the area of microfacets aligned to give perfect specular As usual, lots of different NDF equationsâ€¦ To be consistent, letâ€™s implement the Trowbridge-Reitz equation Low roughness means few samples contributing a lot to specularShadowing term $G(\\omega_0,\\omega_i)$\\[G(n,v,l,k)=\\underbrace{G_{SchlickGGX}(n,v,k)}_{Obstruction}\\underbrace{G_{Schlik}(n,l,k)}_{Shadowing}\\\\G_{SchlickGGX}(n,v,k)=\\frac{n\\times v}{(n\\times v)(1-k)+k}\\] On va approximer $k=\\alpha$ Approximation de lâ€™occlusion Lâ€™orientation des facettes peut pieger la lumiereEffet Fresnel On a un joli coucher de soleil sur la mer (ou ocean)Lâ€™eau est un miroir modulo les vagues Pour tout materiaux, la reflectance va etre maximale aux angles rasants Lâ€™effet Fresnel câ€™est le poids du specular lobe $k_s$\\[F_{Schlik}(v,h,f_0,f_{90}) = f_0+(f_{90}-f_0)(1-v\\times h)^5\\\\F_{Schlik}(v,h,f_0) = f_0+(1-f_0)(1-v\\times h)^5\\\\F_0(ior)=\\frac{(1-ior)^2}{(ior+1)^2}\\] $f_0$: base reflectivity at normal incidence $f_{90}$: base reflectivity at grazing angle Almost always 1 for conductors Fresnel reflectance for common materials For dialectics, $f_0$ is often approximated with $0.04$ Some materials $f_0$ are tainted (gold, copper) Implementation note: For dielectics, pick $0.04$ $f_0$ For conductors, store $f_0$ in albedo texture Use metallic input to lerp between the 2 Demo !Direct-Lightning pseudocodevec3 radiance = vec3(0.0);for(int i = 0; i &amp;lt; NB_LIGHTS; ++i){ vec3 w_i = lights[i].direction; vec3 kS = FresnelShlick(f0, wi, w_o); vec3 specularBRDFEval = kS * f_s(p, w_i, w_o); vec3 diffuseBRDFEval = (1.0 - kS) * f_d(p, w_i, w_o); radiance += (diffuseBRDFEval + specularBRDFEval) * sampleLight(lights[i], p, w_i) * dot(normal, w_i);}Textures Les artistes font plusieurs texturesTo remember ! Diffuse is an approximation of sub-surface scattering La plupart des moteurs connus vont avoir des metallics workflow Ca simplifie beaucoup la viePonctual lightPoint light Infinitely small Isotropic Describe only by a position Simple to code and fast to sample Power unit should be set using Lumens How to select a proper value ? Not as accurate as Area Light\\[L_i(p,\\omega_i)=\\frac{\\phi}{4\\pi r^2}n\\times\\omega_i\\] Cette lumiere nâ€™existe pas dans la vraie vieNote On ne va pas parler de directionnal light (deja fait) Si on utilise une directionnal light, il faudra tweaker les parametres Ce nâ€™est pas aussi fidele que les Area lightsImage Based Lightning 4 points lights Avec environnement\\[L_0(p,\\omega_0)=\\int_{\\Omega}(f_d(p,\\omega_0,\\omega_i) + f_s(p,\\omega_0,\\omega_i))L_i(p,\\omega_i)n\\times w_i\\\\L_0(p,\\omega_0)=\\int_{\\Omega}f_d(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i+\\int_{\\Omega}f_s(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]IBL Diffuse\\[\\int_{\\Omega}f_d(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]Mais câ€™est juste un flou gaussien ? Câ€™est pas si faux que ca, câ€™est assez proche\\[L_0(p,n)=\\int_{\\Omega}\\frac{\\rho}{\\pi}L_i(p,\\omega_i)n\\times\\omega_id\\omega_i\\\\L_0(p,n)=\\frac{\\rho}{\\pi}\\int_{\\Omega}L_i(p,\\omega_i)n\\times\\omega_id\\omega_i\\]Il faut faire une integration par angle solide, et câ€™est complique. Utilisation des coordonnees spheriques pour lâ€™integration Discretiser lâ€™integrale avec la somme de Riemann Calculer pour chaque texel, avec la direction $N$ du centreIBL Specular\\[\\int_{\\Omega}f_s(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]\\[L_0(p,\\omega_0)=\\int_{\\Omega}L_i(p,\\omega_i)d\\omega_i\\times\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)n\\times\\omega_i d\\omega_i\\] Ca a ete teste et ca marche: câ€™est ca la 3DChanger le niveau de roughness câ€™est faire du downsampling, pourquoi par appliquer la roughness en faisant des images de plus en plus petitesPre-computed BRDF\\[\\begin{aligned}\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)n\\times\\omega_id\\omega_i &amp;amp;= F_0\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)(1-(1-\\omega_0\\times h)^5)n\\times\\omega_id\\omega_i\\\\&amp;amp;+\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)(1-\\omega_0\\times h)^5n\\times\\omega_id\\omega_i\\end{aligned}\\] Obtained bu substituting Fresnel ShlickOnly 2 inputs left: roughness, viewing angleAt runtime: Fetch pre-integrated BRDF texture Fetch convoluted environment Apply the above equation to get the full specular componentSpecular: compisistionc2 brdf = GetIntegratedBRDF(NdotV, roughness);vec3 prefilteredSpecular = GetPrefilteredSpecular((NdotV, roughness);vec3 specular = prefilteredSpecular * (F * brdf.x + brdf.y); F: Fresnel termTo remember Câ€™est juste du pre-filteringColorspace and color precision sRGB vs Linear Monitors apply pow function to luminance Toute lâ€™industrie a du se base sur les ecran qui font ca donc ils ont cree le $sRGB$ Sur photoshop, une image sera encodee en sRGB pour retrouver les couleurs imaginees On va eviter de faire nos calculs en sRGB Soit on fait tout en sRGB Soit on fait tout en lineaire $\\Rightarrow$ OUI On applique a la fin la fonction sRGB pour convertir en lineaire HDR vs LDR HDR: High Dynamic RangeReinhard Tonemapping:\\[color_{final}=\\frac{c}{c+1}\\] HDR has larger range of values Units will create radiance color outside the $0\\dots1$ range Perform computation in HDR, tonemap to LDR is required HDR is required to get correct PBR result Especially important for IBLGoing furtherAdvanced materials Examples: hair, skin, cloud, etc." }, { "title": "PBR: Rendering Theory", "url": "/cours/posts/pbr_rendering_theory/", "categories": "Image S9, PBR", "tags": "Image, S9, PBR", "date": "2021-09-17 09:00:00 +0200", "snippet": "Lien de la note HackmdSlides du coursQui est-ce ? Epita 2018 Chez SiemensTOC Introduction Light-Matter Interactions Radiometry Rendering EquationLight-Matter InteractionsDisclaimer I am not a physicist, and Quantum Mechanics is a really complex topixRappel Champ magnetique et electrique transversal Equation de Maxwell Interactions avec la matiereMacroscopic Level: Interactions Emission In-scattering Out-scattering Absorption onde electromagnetique absorbee Emission Modele de Niels-Bohr Any vibrating charged particle converts energy into electromagnetic radiationAbsorption Lâ€™electron va monter dâ€™un niveau dâ€™energie puis reemettre une emissionScattering On va pouvoir reflechir et transmettre La trajectoire de la lumiere va changer Il va y avoir des interferences Interferences constructives: quand la lumiere va changer de milieu, il y a le principe de Fermat â€œla lumiere suit toujours le chemin le plus courtâ€Final notes Any charged particle can interact on electromagnetic radiation Quantum Theory and Quantum Electrodynamics can go really far I can only advise you to read more about this topic !RadiometryEnergy\\[Q=\\frac{hc}{\\lambda}\\] $h$: constant de Planck $c$: speed of light $\\lambda$: wavelengthRadiant Flux / Power\\[\\phi = \\frac{dQ}{dt}\\]Irradiance\\[E(p)=\\frac{d\\phi(p)}{dA}\\] $d\\phi(p)$: power $dA$: finite surface area\\[E = \\frac{\\phi}{4\\pi r^2}\\]\\[E_1=\\frac{\\phi}{A}E_2=\\frac{\\phi\\cos(\\theta)}{A}\\]Solid angle Area of a projected shape onto the Unit Sphere Radiant intensity\\[I=\\frac{d\\phi}{d\\omega}\\] $\\phi$: power $\\omega$: angleRadiance On va lâ€™utiliser pour faire tout le rendu\\[L(p,w) = \\frac{dE_{\\omega}(p)}{d\\omega}=\\frac{d\\phi(p)}{d_{\\omega}dA^{\\bot}}\\]Rendering equationDisclaimer We assume that Light travels in vacuum We deal only with opaque surfaces Interactions at object surface Definition\\[L_0(p,\\omega_0)=\\int_{\\Omega}\\underbrace{f_r(p, \\omega_0,\\omega_i)}_{\\text{RÃ©flectivitÃ© bidirectionnelle}}L_i(p,\\omega_i)n\\times \\omega_i d\\omega_i\\]BRDF On peut voir ca comme un ratio. Câ€™est la quantite dâ€™energie qui va etre emise en $\\omega_0$ quand elle provient de $\\omega_i$ Câ€™est une grosse approximation de ce quâ€™il se passe Dans la vraie vie il y a de la transmissionCertaines boites utilisent de fonction plus avancees (BTDF, BSSRDF, etc.)Qui design ces BRDF ? Lambert câ€™est une BRDFPhong utilise une BRDFEn general la BRDF câ€™est la propriete des materiaux pour savoir comment câ€™est reflete. On ne veut pas que de lâ€™energie soit cree lors de la reflection Il faut normaliser sinon on a des surprisesFinal notes Rendering equation uses all quantities we have seen The rendering equation is what we solve when generating 3D images" }, { "title": "IMCO: Processing Color", "url": "/cours/posts/imco_processing_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-16 14:00:00 +0200", "snippet": "Lien de la note HackmdHow a camera worksHuman Eye vs a Camera Shutter: how long the camera is opened to let in lightThe imaging flow The camera pipeline for creating nice photos is a secret recipeThe color Imaging Flow SourceOther possible steps: ISO Gain Noise Reduction Etc.Sensor Temporal Mutliplexing Scan 3 times + use 1 sensor 3 real values per pixel Only for static scenes Slow Scan 1 time + Use 3 sensors 3 real values per pixel Costly Space Spatial Multiplexing Scan 1 times + Use 1 sensor Well-mastered technology 1 real value per pixel (interpolation) Loss of light Camera spectral sensitivity SourceSensor (from 110 years ago!)Using temporal multiplexingPreprocessing Dark Current Compensation Signal present even when the length is close, which adds noise How to compensate ? Capture a dark image for the given exposure time\\[C_i(x,y)=R_i(x,y) - D_i(x,y)\\] Vignetting/Lens Shading/Flat Field correction Image tends to darken on the corners/Non-uniform Illumination How to compensate ? You tell me ! Compute average RGB value of 15 White Patches Â  Statistic Red Green Blue Before correction Mean 157.3 159.1 157.5 After correction Mean 249.5 \\ \\ If you are taking RAW images there is a chance your image software already does itColor Constancy Property of the Human Visual Sytem that allows adapting to different scene illuminationsWhite Balance to the rescue The eye cares more about the intrinsic color of the object, not the color of the light leaving the object Easy for our eyes to judge what is white under different illuminants, but not so straightforward to cameraWhite Balance The idea is to make white points the same between scenesWhite point is the $xyY$ (or $XYZ$) value of an ideal â€œwhite referenceâ€ Hence, the camera is able to do the Chromatic AdaptationChromatic Adaptation: How ? $\\color{yellow}{\\text{Source}}$ color $(X_s, Y_s, Z_s)$ with white reference $(X_{WS}, Y_{WS}, Z_{WS})$ $\\color{blue}{Target}$ color $(X_T,Y_T,Z_T)$ with white reference $(X_{WT}, Y_{WT}, Z_{WT})$ Computing $[M]$ Transform $XYZ$ to cone response domain Scale using source/target white references Transform back form cone domain $XYZ$\\[[M] = [MA]^{-1}\\begin{bmatrix}\\frac{\\rho_T}{\\rho_S}&amp;amp;0&amp;amp;0\\\\0&amp;amp;\\frac{\\gamma_T}{\\gamma_S}&amp;amp;0\\\\0&amp;amp;0&amp;amp;\\frac{\\beta_t}{\\beta_s}\\end{bmatrix} [MA]\\]Where $\\rho, \\gamma,\\beta$ are the cone responses for the given source and target colorsExampleWhite balance: automaticWhat if we donâ€™t help the camera ? The camera doesnâ€™t know the illuminantThe camera will try to â€œguessâ€ the white point in the image, and then balance the color automatically. Unlike White Balance, the illuminant is very hard to estimateHow ? Gray world assumption The average of all colors in the image is gray Green channel is taken as â€œgrayâ€ reference White-balanced image is: $k_{r}R,G,k_bB$ $k_r=\\frac{G_{mean}}{R_{mean}}$ $k_b = \\frac{G_{mean}}{B_{mean}}$ White patch algorithm Assumes that highlights = specular reflections of illuminant Maximum $R,G,B$ values are good estimation of white point White balanced image is: $k_{r}R,G,k_bB$ $k_r=\\frac{G_{max}}{R_{max}}$ $k_b = \\frac{G_{max}}{B_{max}}$ How does GIMP does it ? Discards pixels colors at the extremes of $R,G,B$ histograms Thresholds of $0.05\\%$ of total pixel count Do Histogram Stretching of remaining pixel colors, for each channel Plus some smart post-processing Smart Color Balance method Discards â€œblackâ€ and â€œwhiteâ€ pixels Stretch the histogram of the remaining pixels Plus some smart post-processing Those are very basic algorithms.Modern cameras use sophisticated white-balance, based on data-driven solutions One Way Compute features from image Find similar images in databases of images with good white balance Use white balance from image Demosaic Each pixel has a different color filter Bayer Pattern is the most used Color Filter Array (CFA) Why More Green ? Frequency of the G color band is close to the peak of the human luminance frequency response $\\to$ better sharpness Linear interpolation Average of neighors Smoother kernels (bicubic) can also be usedTypical errorTaking a picture of striped pattern $\\to$ color artifact To overcome these problems, most demosaicing methods convert the image to the YCbCrSolution Each pixel has a different color filter Bayer Pattern is the moste used Color Filter Array (CFA) Interpolation methods are patented or proprietary And of course deep learning to the rescueColor Transform $RGB_c\\to RGB_u$Color Correction Cameras are meant to produce pleasing scenes rather than colorimetrically accurate scenes Spectral Sensitivities of the camera are not identical to human color matching functions To obtain colorimetric accuracy, we need to transform the image from the sensorâ€™s color space to the colorimetrics $(XYZ)$ space By default Factory-computed Color Space Transforms (CST) are used When precision is needed, Color Charts are used to obtain a specific transform for the camera and scene We can use ICC color profileColor Correction ChartsColorChecker Digital SG (SG=Semi-gloss) 140 patches (96 uniques colors)Artist Paint TargetColorBuild 300 Patch TargetColor Correction Methods $30+$ years of continous research on how to transform form RGB to XYZ spaces A lot of ways to do it ! Most of them solve the following equation:\\(X=MP\\) $X$: Reference $XYZ$ values $[3\\times m]$ $P$: Camera $RGB$ values $[N\\times m]$ $M$: Correction matrix $[3\\times N]$ $m$: nb of data points $N$: nb of dimensions Â  ColorChecker Classic ColorChecker Digital SG m 24 140 LinearLinear Mapping from $RGB$ to $XYZ$ $N=3$ Not affected by exposure changePolynomial Color CorrectionLinear Mapping From $RGB$ to $XYZ$ + add polynomial components to reduce errors $N=9$, if $2^{nd}$ order polynomial Affected by exposure changes High polynomial degree tends to do overfittingRoot Polynomial Color CorrectionLinear Mapping from $RGB$ to $XYZ$ + add root polynomial components $N=6$, if $2^{nd}$ Order Polynomial Not affected by exposure changeMeasuring with RGB Cameras: Recap Cameras ar not light measurement devices From the moment an image is captured by the sensor, there are a lot of steps which could impact the final color rendition. This processing is proprietaryFuture trends ?White balance: Mixed illumination The white balance fails if 2 illuminants are in the same imageDenoisingBest current solutions use Deep Learning Predict the noise instead of denoising the imageHDR Imaging HDR Imaging is quite mature Some challenges when acquiring moving scenes or shooting a video HDR from a single image using Deep Learning ?Multispectral Imaging Used mostly for quality inspection and classification of materials In principle, it could be used for measuring ReflectanceSpectra from RGB When measuring color with an RGB camera, we measure the ligth response in 3 wavelengths" }, { "title": "IMCO: Measuring Color", "url": "/cours/posts/imco_measuring_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-16 10:00:00 +0200", "snippet": "Lien de la note HackmdVideo timeKonica Minolta SensingHow can we measure colors ? Spectrophotometer Response through the entire visible spectrum Relatively small areas (few $cm^2$) - Resolution is 1 point â€œFalt surfacesâ€ RGB Camera Response in 3 wavelengths (Red, Green Blue) Large areas - High Spatial Resolution ($\\lt50$MPixels) Any kind of surfaces Hyperspectral camera Response throughout the entier visible spectrum (and more) Large areas - Low Spatial Resolution ($\\le2$MPixels) Any kind of surfaces When NOT to Measure color Using instrument to measure color and compute differences objectively is not always needed For example: A company has a corporate color (possible $^{TM}$) Tour de France: Pantone 123C Veuve Cliequot: Pantone 137C Louboutin: Pantone 18.1663TP Products carrying the color are sold; however they are manufactured by different providersJudging by visual assessment Need consistent lightning Need consistent viewing Need to Check for Metamers Use a light booth ! Sufficient when there are few standard samples to be matched Sufficient when tolerance is judged visually by color experts Requires all manufacturers to have a physical copy of the standard, and to have the same hardware Because there are no measurements, we donâ€™t know to adjust color workflow in case we need to match a colorMeasuring with SpectrophotometersRemember Light interaction Spectrometer can measure reflectance and transmittance (specular and/or diffuse) Time for another videoWhat is a Spectrophotometer? Light Reflection vs Material Matte Light is reflected in all directions equally Semiglossy Light is reflected in all direction but a small part is reflected orthogonal to the incident angle Glossy Light is reflected in all directions but a big part is reflected orthogonal to the incident angle Spectrophotometers: In a Nutshell Spectral reflectance The ratio of reflected light ($r$) to the incident light ($i$) under specific geometric conditions \\[R_{\\lambda}=\\frac{\\phi_{\\lambda}^r}{\\phi_{\\lambda}^i}\\] Spectral transmittance The ratio of transmitted light ($t$) to the incident light ($i$) under specific geometric conditions \\[T_{\\lambda} = \\frac{\\phi_{\\lambda}^t}{\\phi_{\\lambda}^i}\\] All measuring instrument need to be calibrated using White Tile made from Spectralon Spectrophotometers: reflectances ?Interlude: fluoresence Fluroescence can create colors we donâ€™t see Use an instrument called a Bispectrometer to measure it Donaldson matrix obtained from a green sample emitting a more satured green lightColorimeter vs Spectrophotometers Colorimeters are used generally to calibrate screens They mimic the way our eyes perceive colorThey measure reflectance in 3 wavelengths (R, G, B)They do not provide a spectral responseSpectrophotometersTypes Bidirectionnal Non-structured and flat surfaces (paper, plastics) Sphere Structured and glossy surfaces (textiles, metallic) SPIN vs SPEX SPIN Specular Included (gloss is accounted for) Color is measured independent of the sampleâ€™s gloss or surface texture SPEX Specular ExcludedSpecifications Example: Automotive interior plaque (items produced using different materials) SPIN: looks at the material independant of surface texture SPEX: values which depend on gloss and surface conditions Different spectro modelsSpecifications Choose depending on what you need Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment geometry $45^o$ a:$0$ (ring illumination) $di:8^o$ $45^o$c:$0$ (circumferential) Light source Gas filled tungsten lamp and UV LED Gas-filled tungsten lamp 3 point circle, 7-LED chip GeometryReflectance of a semi-glossy object $di:8^o$ A high gloss sample with the same pigmentation is visually judged darker by the eye when compared to a matte sample $\\color{orange}{45^o:0}$: measure that color difference $\\color{green}{di:8^o}$ measure the same color in both cases $\\color{orange}{45^o:0^o}$ simulates normal behavior e.g. when we read a magazine Aperture Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment aperture $4.5mm$ $4$ or $8mm$ $2$,$6$ and $8mm$ Small aperture Measures quickly may miss relevant infoLarge aperture more accurate measurement takes longer needs larger sampleConditions Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment conditions M0, M1, M2 N/A M0, M1, M2, M3 M0 legacy measurement (tungsten lamp, no standardization of UV content in illuminat, UV strength changes through time) M1 Spectral distribution of illuminant M2 UV is excluded M3 Polarized light Measurement conditions impact the colorSpectral range Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Spectral range $380-730nm$ $700-400nm$ $380-750nm$ Repeatability Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Short term repeatability $0.1$ $\\Delta E_{94}$ $0.05$ $\\Delta E_{ab}$ $0.05$ $\\Delta E_{00}$ 2 different i1Pro 2 spectro 10 measurements of the same object were taken for each instrument $\\Delta E$ between first and other 9 measurements were computed for each instrument Â  X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Inter-instrument agreement Average $0.4$ $\\Delta E_{94}$ Max $1.0$ $\\Delta E_{94}$ Average $0.4$ $\\Delta E_{ab}$ Max $1.0$ $\\Delta E_{ab}$ Average $0.4$ $\\Delta E_{00}$ Max $1.0$ $\\Delta E_{00}$ Transmittance Measurement When we need transmittance ? Light Filters Printed Ads Food Inspection Inter-instrument agreement Compared measurements of 16 samples used for printingRecap Many different (standardized) methods to measure Reflectance (and Transmittance) Unfortunately, measured Reflectance/Transmittance is not unique as it depends on the instrument you sued to measure it Type of instrument to used depends on what you want to measure, and how frequent you want to measure Only measurements tales under the same conditions can be truly compared. Therefore, it is necessary to note the following information in a color measurement report: Color instrument (geometry, aperture, measurement condition) Illuminant/observer standards, if you give $L\\times a\\times b$ values Future trends: beyond colorVisual appearance of materials Reflection Transmission AbsorbanceBRDF Measurement Bi-directional Reflectance Distribution Function (BRDF) gives a more complete characterization of light interaction with the surface We measure how light reflects in all directions BRDF allows characterizing the surface appearance at a microscopic level (used in Computer Graphics to render objects) Measurable with Goniophotometers How to measure BRDF faster and cheaper ?Sources Les boules Litteralement tout le cours Spectrophotometer Spectral measurment X-RITEMetamerismWhatâ€™s that ? metamerism is a perceived matching of colors with different (nonmatching) spectral power distributions.Most important types Illuminant Metamerism Different spectral characteristic and same color when viewed under one light different color when view under another light Observer Metamersim Different spectral characterisic and same color when viewed by one observer different color when view by another observer Examples:Car industrySourceOtherSourceMetamerism vs Color Inconstancy Color inconstancy: A single object changing color with changes in the color of the illumination Metameric pair: Two objects having color inconstancyRecap Metamerism is an effect we need to consider if a pair of objects will be viewed under more than one type of illuminant In the printing industry, neutral (grayscale) colors are more susceptible to illuminant metamerism as a mix of inks is used In the case of displays, illuminant metamerism is not a problem as they create their own light" }, { "title": "CMKV: Introduction aux Chaines de Markov", "url": "/cours/posts/cmkv_intro_markov/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-15 14:00:00 +0200", "snippet": "Lien de la note Hackmd Savoir echantilloner câ€™est bien mais on veut optimiserRappels Quand on a une loi de proba $P(x)$\\[\\begin{aligned}P(X&amp;amp;=x)\\to P_{\\underbrace{T}_{\\text{temperature}}}(X=x)=\\frac{1}{Z_T}e^{-\\frac{U(x)}{T}}\\\\&amp;amp;\\downarrow\\\\P(X=x)&amp;amp;=\\frac{1}{Z}e^{-U(x)}\\end{aligned}\\]\\[\\color{red}{\\lim_{T\\to+\\infty}P_T=P_{\\text{uniF}}\\\\\\lim_{T\\to0^+} P_T=P_0\\\\P_0(X=x)\\begin{cases}1 &amp;amp;\\text{si } x=x_{\\text{solution}}\\\\\\varnothing &amp;amp;\\text{sinon}\\end{cases}}\\]Marche aleatoire Notre echantillonneur va realiser une marche aleatoireComment on affecte $x^{(t+1)}$ a partir du $x$ courant ? On a un Ã©chantiolloneur Metropolis-Hastings: $x^{(0)}\\leftarrow \\text{alÃ©atoire}$ Boucle: On se trouve un $x_{\\text{candidat}}$ $x^{(t+1)}\\leftarrow$ soit $x^{(t)}$ soit $x_{\\text{candidat}}$ $\\to\\color{red}{\\text{dÃ©pend de }} P_{\\color{blue}{T^{(t)}}}(X=x)$ $\\color{blue}{T^{(t+1)}\\leftarrow\\underbrace{\\alpha}_{\\equiv 1^-} T^{(t)}}$ $t\\leftarrow t+1$ Câ€™est un algo de recuit simulÃ© Alterner entre cycle de refroidissement lent et rÃ©chauffement pour un mÃ©tal Câ€™est quoi un algo brute force ? Câ€™est un algo qui va explorer tout lâ€™espace pour trouver la solution On cherche le minimum energetique $\\color{red}{{2,4}}$ $\\color{red}{{2,3,4}}$ Â  Â  Â  $\\boxed{1}$ $\\boxed{2}$ Â  Â  Â  Â  Â  $\\boxed{3}$ Â  Â  $\\boxed{4}$ Dâ€™apres le dernier cours, si on regarde lâ€™echantilloneur, il y a une possibilite de faire un echantillonneur tres simple mais sous-optimal\\[\\color{red}{\\forall t, u(x^{(t+1)})\\le u(x^{(t)})}\\] loop: $x_{\\text{candidat}}\\leftarrow$ aleatoire si $x_{\\text{candidat}}$ ameliore on le garde comme $x^{(t+1)}$ Combien de temps ca va prendre pour atteindre la solution ? On peut viser la fin de lâ€™univers apres lâ€™extinction des hommes Au final, le tirage aleatoire est moins efficace que le bruteforce Câ€™est con hein ?BacktrackingOn va toujours empiler les boucles. Par exemple: On met $1$ dans la premiere case, sauf que ce nâ€™est pas possible donc on break On met $2$ a la place On fait pareil pour la $2^e$ case, $1$ et $2$ ne sont pas possibles donc on met $3$ On fait pareil pour la $3^e$ case, on met $4$ $\\vdots$ On arrive a un blocage ! $2$ $3$ $4$ $1$ $4$ $\\boxed{1}$ $\\boxed{2}$ $3$ $1$ $2$ $3$ Â  $\\boxed{3}$ Â  Â  $\\boxed{4}$ Mais ou est-ce quâ€™on sâ€™est trompe ?? On backtrack et on change nos valeurs $1$, $2$, $3$ et $4$ ne sont pas possibles donc on supprime la valeur et on revient a la case precedente On change $2$, $3$ câ€™est pas possible donc on met $4$ $2$ $3$ $4$ $1$ $4$ $\\boxed{1}$ $\\boxed{2}$ $3$ $1$ $4$ Â  Â  $\\boxed{3}$ Â  Â  $\\boxed{4}$ Pour resoudre le sudoku, imaginons dâ€™avoir une fonction $U$ a 16 variables:\\[U(\\begin{matrix}\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\end{matrix})\\] ${2, 4}$ Â  Â  Â  Â  $\\boxed{1}$ $\\boxed{2}$ Â  Â  Â  Â  Â  $\\boxed{3}$ Â  Â  $\\boxed{4}$ Ici on reduit lâ€™espace des possibilitesEn premiere iteration:\\(U(\\begin{matrix}\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\end{matrix})\\\\\\vdots\\\\U(\\begin{matrix}\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{2}&amp;amp;\\boxed{1,2,3,4}&amp;amp;\\boxed{1,2,3,4}\\\\\\end{matrix})\\\\\\) On obtient un arbre des possibilites Bruteforce: parcours en largeur Backtrack: parcours en longueur Il y a des problemes ou on ne peut pas backtrackerAutre methodeOn se donne une fonction $U_1(x)$\\[P(X=x)=\\frac{1}{Z}e^{-U(x)}\\\\\\downarrow +T\\\\P_T(X=x)=\\frac{1}{Z_T}e^{-\\underbrace{\\frac{U(x)}{T}}_{\\color{red}{U_T(x)}}}\\] On va chercher le $x$ qui maximismeOn a un espace discret. On chercher le $\\color{green}{P_{\\infty}}$ qui a la meme aire que notre fonction $\\color{blue}{P(X=x)}$ On dessine $\\color{blue}{P(5)}$On dessine $\\color{black}{P(1)}$\\[\\vdots\\]Imaginons quâ€™on a une bille. Il ne faut pas quâ€™elle se fasse coincer dans un minimum local et elle se deplace de proches en proches. La bille aura de plus en plus de mal a â€œremonterâ€ du creux et va se retrouver â€œcoinceeâ€ dans le creux contenant la solutionQuel est le cout pour aller dâ€™une position a une autre ? Dans ce cas la bille doit avoir assez dâ€™energie pour remonter la penteRatio\\[P(X_{t+1}=x_{t+1}\\vert X_t=x_t)=\\text{ratio}\\\\X_t\\color{green}{\\text{ influence }} X_{t+1}\\\\X_{t+1}\\color{red}{\\text{ depend de }} X_t\\] Si on a $P(A=a\\vert B=b,C=c)$, $B$ et $C$ influencent $A$.\\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\]La meteo de GulliEn supposant quâ€™on soit a Paris:\\[\\color{green}{P(X_{t+1}=\\text{pourri}) = 0.6\\\\P(X_{t+1}=\\text{pourri}) = 0.4}\\] $x_{t+1}$ \\ $x_t$ beau pourri total beau $\\color{red}{0.4}$ $\\color{red}{0.2}$ $\\color{green}{0.6}$ pourri $\\color{red}{0.1}$ $\\color{red}{0.3}$ $\\color{green}{0.4}$ \\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\\\\\color{red}{x_{t-2}\\leftarrow x_{t-1}\\overbrace{\\leftarrow}^{\\text{dependance}} x_t\\overbrace{\\leftarrow}^{\\text{dependance}} ?x_{t+1}}\\]Le modele ne semble pas simpliste ? On est influence que par le temps dâ€™avant dâ€™une facon directe Le temps de demain depend du temps quâ€™il fait aujourdâ€™hui mais egalement du temps dâ€™hier Le tableau devient 3DOn a defini:\\[P(X_{t+1}=x_{t+1}\\vert X_{t-1}=x_{t-1}, X_t=x_t)\\]On a decide dâ€™ignorer le temps dâ€™avant avant-hier, et la journee encore avant, etc. Le modele le plus general pour connaitre le temps de demain est:\\[P(X_{t+1}=x_{t+1}\\vert X_t=x_t, X_{t-1}=x_{t-1},\\dots, X_0=x_0)\\quad\\text{(tous les jours)}\\]\\[P(\\underbrace{X_{t+1}}_{\\color{green}{\\text{var. alea}}}=x_{t+1}\\vert X_t=x_t, X_{t-1}=x_{t-1},\\underbrace{\\dots, X_0=x_0}_{\\color{green}{\\text{independante de}}})\\] On a ecrit des dependances indirectes qui ne vont pas etre modelisees\\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\] En vert: dependances indirectes Câ€™est une chaine de MarkovPrenons une chaine de niveau $2$:\\[\\color{green}{\\underbrace{X_{t-4}}_{\\to \\color{black}{X_{t-2}}}\\to \\underbrace{X_{t-3}}}_{\\color{black}{\\to X_t}}\\to \\underbrace{X_{t-2}}_{\\to X_t}\\color{green}{\\to} X_{t-1}\\to X_t\\]Prenons une image en niveaux de gris:\\[X=(X_1,\\dots,X_{\\underbrace{N}_{\\text{pixel}}})\\\\x = (x_1,\\dots,x_N)\\\\U_L(x_i, y_i)=\\begin{cases}y_i &amp;amp;\\text{si } x_i=\\text{noir}\\\\1-y_i&amp;amp;\\text{sinon}\\end{cases}\\]\\[\\begin{aligned}\\color{blue}{U_{\\text{prior}}(x_i,x_{i-l},x_{i-1},x_{i+1},x_{i+l})}&amp;amp;=\\sum_{v}\\vert x_i-x_{iv}\\vert\\\\&amp;amp;=\\sum_{v}\\delta_{x_i\\neq x_{iv}}\\end{aligned}\\] Quâ€™est-ce quâ€™un champ de Markov ?Un modele graphique avec des fleches $A- B$ ($A$ et $B$ sont dependantes mutuellement) On veut que notre graphe soit le plus incomplet possible cad avoir le moins de variables possibles\\[P(X_{t+1}=x_{t+1}\\vert \\{X_u=x_u\\}_{u\\le t})=-(\\{X_u=x_u\\}_{u\\in[t-h,t]})\\\\\\] Propriete Markovienne\\[P(X_i=x_i\\vert \\{X_j=x_j\\}_{[1,N]\\setminus {i}}) = P(X_i=x_i\\vert \\{X_j=x_j\\}_{\\text{ ou } j\\in V(i)})\\]" }, { "title": "EPIQUANTI : Histoire et fondamentaux de la physique quantique", "url": "/cours/posts/epiquanti_histoire/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-09-14 09:00:00 +0200", "snippet": "Lien de la note HackmdSlides de coursAgenda Histoire et fondamentaux de la physique quantique Fondmentaux des qubits avec elements mathematiques Ingenierie du calcul quantique Architecture dâ€™un ordinateur quanitque et technologies habilitantes Differents types de qubits et de calculateurs quantiques Algorithmie quantique - David Herrera-Marti Outils de developpement CAs dâ€™usage metiers et offres clouds - Olivier ezratty avec Georges Usbelger Telecommunications et cryptographie quantique - Eleni Diamanti Questions societales, fausse sciences et fact-checking - Fanny Bouton et Olivier Ezratty Ecosysteme du marche, startup et opportunites - Christophe JurczakEvaluation $50\\%$: QCM a la fin $50\\%$: participation active et exercices avec David Herrera-MartiBackground CentraleSupelec 1982-1985 Sogitec 1985-1989 Informatique applique a lâ€™image (art graphique) Microsoft 1990-2005 Pour lâ€™experience dev A lance des programmes dâ€™accompagnement de startup â€œJe me presente comme un troubadour, un saltimbanqueâ€ Publie depuis 15 ans des livresOn quantum tech Est tombe dans le quantique il y a $\\sim 10$ans Comprendre lâ€™informatique quantique, $3^e$ edition, ebook gratuit de 684 pages septembre 2020 Un peu le syllabus du cours La $4^e$ edition sors dans quelques jours (et en anglais !) Alain Aspect A decouvert lâ€™informatique quantique Podcasts Quantum: podcast de lâ€™actualite quanitque Decode quantum: les entretiens du quantique Dans la science fiction: Yâ€™a plein de mondes paralleles partout :) Dans la physique quantique yâ€™a de la teleportationQuantique ou pas ?Les quantum dots ? Oui ! Alors que ca existe depuis longtempsCâ€™est une technique qui modifie la frequence dâ€™un photon pour en changer sa couleur en couleur primaireFireforx quantum Non câ€™est que le nomSamsung quantum Oui et non (ah ca câ€™est bien quantique)Oui car nâ€™importe quel modele de processeur aujourdâ€™hui a des transistors utilisant des phenomenes quantiquesNon car ca nâ€™utilise par le quantique de $2^e$ generationQubole quantum ? NonFinish quantum max? NonWhat is to be â€œquantumâ€ ? Une forme finie qui ne peut pas etre divisee ?Meh, tu peux pas avoir un demi-bac Câ€™est lie aux proprietes de la matiere Taille et/ou energie inferieure a un certain ?Oui Une propriete importante: la dualite des particules: une bivalence de comportement (onde ET particules)Un peu dâ€™histoireConference de Solvay A eu lieu a Bruxelles, BelgiqueCette photo marque la fin de la periode mettant en place les bases de la physique quantique.Pourquoi Einstein a recu un prix nobel ? Grace a lâ€™effet photoelectrique et NON la theorie de la relativiteCe papier est lâ€™un des fondement de la physique quantique, et lâ€™a fait a 26 ansQui a recu 2 prix Nobel ? Marie Curie, qui est la seule personne a avoir recu $2$ prix nobels dans $2$ domaines differentsPrecursorsUn grand nombre de travaux du $19^e$ siecle ont ete les bases de la physique quantique: Thomas Young William Rowan Hamilton Niels Henrik Abel Charles Hermite James Clerck Maxwell Ludwig Boltzmann Henri Poincare David Hilbert Pieter Zeeman Hendrik LorentzYoungâ€™s slit experiment - 1806Maxwell electro-magnetic waves - 1865Zeeman effect - 1896Founders Max Planck Emmy Noether Albert Einstein etc.Quantum physics beginnings$1^{er}$ date: decouverte - $2^e$ date: prix nobel $1900-1918$: Max Planck black body radiation energy quanta Un four Une etoile etc. Planck constant $1905-1921$: Albert Einstein photoeletric effect $1913-1922$: Niels Bohr hydrogen atom model $1922-1944$: Stern-Gerlach experiment atoms angular momentum experimentaliste On a majoritairement des theoriciens et non exerimentalistes $1924-1929$: Louis de Broglie wave-particle duality $1924-1945$: Wolfgang Pauli exclusion particle $1925$: Uhlenbeck-Goudsmith Electron spin $1926-1933$: Erwin Schrodinger wave function \\(ih\\frac{\\partial \\Psi(x,t)}{\\partial t} = H\\Psi(x,t)\\) $1926-1954$: Max Born quantume probability $1927-1932$: Werner Heisenberg indertemination $1935$ Einstein, Podolski, Rosen: EPR paradox Erwin Schrodinger: C H A T papier sur lâ€™intrication quantique il nâ€™y a que 9 lignes sur le chat $1937$: Etore Majorana fermion: particule sans masse Il manque au moins $50$ personnes dans cette chronologieHow old were they ? Einseiberg: $24$ ans Einstein: $26$ ans Schrodinger: $39$ ans Planck: $42$ ansQuantum physics basicsPhysics domain classification Tout ca forme la theorie du tout Souvent les physicien faisant ca sont mono-maniaquesFrom macro to nano physicsQuantum physics $101$ Quâ€™est-ce qui est quantique ? Quantification Particules massives et non-massives $\\to$ dualite particule/onde Superposition des etats Lâ€™intrication Consequence de la superposition Lâ€™indetermination: \\(\\Delta x\\Delta p\\ge \\frac{h}{4\\pi}\\) La mesure quantique Quand on a nos etats superposes: on mesure et on obtient une des valeurs et non la superposition Lâ€™effet tunnel Non-clonage Theoreme demontre a partir des postulats de la physiques quantique qui peuvent etre faux un jour Ecouter de la musique est une addition dâ€™ondes La teleportation câ€™est mort :( Le theoreme de non-clonage nâ€™est pas invalide par la teleportation de Start TrekQuantification Quantization = discountinued nanoscopic properties of nanoscale amtter and light\\[B(\\lambda, T) = \\frac{2hc^2}{\\lambda^5}\\frac{1}{e^{\\frac{hc}{\\lambda k_BT}}-1}\\quad\\text{Planck law}\\] Rayleigh-Jeans lawâ€œUltraviolet catastropheâ€ spectrum prediction in classical theory\\[B_{\\lambda}(T)=\\frac{2ck_BT}{\\lambda^4}\\]Black Body Radiaton $\\lambda_{max}$: peak wavelength Wienâ€™s displacement law - 1893 \\[\\lambda_{max} = \\frac{2898}{T}\\]Light Spectrum Continous spectrum Sun, black body Absorption spectrum cold gas illuminated from behind by continuous spectrum Emission spectrum by rarified hot gas Quantification atoms et ions electrons autour de leur noyau $n =$ principal $I =$ angulaire $m=$ moment magnetique $s=$ spin photons polarization longueur dâ€™onde phase number photon de meme frequence et onde quantique qui peuvent sâ€™additionner ca creer un GROS photon $\\to$ etat de Fock orbital angular momentum used to create qubits with distincts states and at the particle scale (atoms, electrons, photons)Dualite onde-particule Interference observed with photons photons acting as particle interferences observed with electrons\\[\\text{particle energy}\\to E=h\\nu \\leftarrow \\text{wave frequency}\\\\\\text{particle momentum}\\to p=\\frac{h}{\\lambda}\\begin{aligned}\\leftarrow\\text{Planck constant}\\\\ \\leftarrow\\text{wavelength}\\end{aligned}\\]Young slit experiment detailsSchrodingerâ€™s equation\\[\\begin{aligned}i\\hbar\\overbrace{\\frac{\\partial\\Psi(x,t)}{\\partial t}}^{\\text{total energy}}=-&amp;amp;\\underbrace{\\frac{\\hbar^2}{2m}\\overbrace{\\frac{\\partial^2\\Psi(x,t)}{\\partial x^2}}^{\\text{kinetic energy}}+\\overbrace{V(x)\\Psi(x,t)}^{\\text{potential energy}}}_{}\\\\&amp;amp;\\hat H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial x^2}+V(x)\\quad\\text{Hamiltonian}\\end{aligned}\\] $i$: $i^2=-1$ $m$: particle mass $\\hbar=\\frac{h}{2\\pi}$: constante de Dirac $\\Psi$: lâ€™inconnue de lâ€™equation de Schrodinger Probabilite de trouver une particule massive a un endroit $x$ et un temps $t$ La derivee dans le temps est lâ€™energie de la particule Hamiltonian: function applicable to the particle wave function to evaluate its total energyConstraints\\(z = a+ib\\quad\\vert z\\vert=\\sqrt{a^2+b^2}\\)Complex number module\\(\\vert\\Psi(x,t)\\vert^2\\)Wave function module square\\(\\int^{+\\infty}_{-\\infty} \\vert\\Psi(x,t)\\vert^2 dx =1\\)Integral of the probability to find the particle in any position equals oneIndetermination\\(\\Delta x\\Delta p\\ge\\frac{h}{4\\pi}\\) $\\Delta x$: location precision $\\Delta p$: momentum precision $h$: Planck constantAt a nanoscopic scale, the pseed and position measurement precision are the antinomic, the greater one is, the smaller is the other Heisenberg microscope thought experiment: a photon sent on the electron will hcnage its trajectory and measurement Derivation: at a nanoscopic scale, measurement apparatus impacts measurement output Used in â€œsqueezingâ€ like with photons to increse one precision against the other Quantum sensing to increase measurement precision Also indirectly explains quantum Planck time, distance and massShortest time measurement\\(\\text{Planck time}\\quad t_p=\\sqrt{\\frac{\\hbar G}{c^5}}=\\frac{l_p}{c}\\)Shortest distance measurement\\(\\text{Planck distance}\\quad l_p=\\sqrt{\\frac{\\hbar G}{c^3}}\\)Maximal mass of an elementary particle Sinon ca fait un trou noir\\(\\text{Planck mass}\\quad m_p=\\sqrt{\\frac{\\hbar c}{G}}\\)Quantum physics postulates Quantum state The state of the quantum mechanical system is completely specified by a psi wave function $\\psi(x,y,z,t)$ returning a complex number value that depends on the coordinates of the particle and on time, also denoted a ket: $\\vert\\psi\\rangle$ in Diracâ€™s notation Physical quantities A physical quantity is evaluated with an observable operator acting on the $\\vert\\psi\\rangle$ wave function, the observable is an Hermitian matrix, with real eigenvalues Measurement The only values that can be measured are the eignevalues of the observable, itâ€™s always a real number. When the spectrum of the observable is discrete, the results are quantized Born rule Defnes the expectation values and probabilities for $\\vert\\psi\\rangle$ properties State collapse After measurement, the wave function $\\vert\\psi\\rangle$ becomes the eigenvector corresponding to the eigenvalue obtained, the state of $\\vert\\psi\\rangle$ is irreversibly changed unless Time evolutionState superposition Quantum objects can be in superposed states Consequence wave-particle duality Since the Schrodinger wave equation is linear, any linear combination of solutions is also a solution qubit example: $\\vert\\psi\\rangle=\\alpha\\vert 0\\rangle+\\beta\\vert 1\\rangle$ corresponds to a linear superposition of $\\vert 0\\rangle$ et $\\vert 1\\rangle$ with complex amplitudeIntrication 2 quantum particles, particularly photons, can be prepred in a state that is correlated even at a long distanceSome applications Teleportation Algorithme Cryptographie Communication quantique etc.State reduction and measurement Before measurement, quantums are in a superposed state 2 levelss quantum state $\\vert\\psi\\rangle=\\alpha\\vert0\\rangle+\\beta\\vert1\\rangle$ $\\alpha^2+\\beta^2=1$ Quantum state readout $\\vert\\psi\\rangle=\\vert0\\rangle$ $\\vert\\alpha^2\\vert$ probability to get $\\vert0\\rangle$ $\\vert\\psi\\rangle=\\vert1\\rangle$ $\\vert\\beta\\vert^2$ probability to get $\\vert1\\rangle$ Another measurement will yield the same result $\\frac{1}{\\sqrt{2}}\\vert0\\rangle+\\frac{1}{\\sqrt{2}}\\vert1\\rangle$ $50\\%\\to\\vert0\\rangle\\to$ measurement $100\\%\\to\\vert0\\rangle$ $50\\%\\to\\vert1\\rangle\\to$ measurement $100\\%\\to\\vert1\\rangle$ Also quantum decoherence is progressively disturbing superposition and entanglement, like being a â€œpartial measurementâ€ from the environmnent qubits measurements is done only at the end of computing cannot measure a qubit state in the middle of an algorithm to do some Photons primerOne photon wavelength/frequency right/left polarization = spin angular momentum $+\\hbar$ or $-\\hbar$ vector direction in space massless no electric charge Photon wavenumber\\[k=\\frac{2\\pi}{\\lambda}\\] Photon mode Orhtogonal solutions of the EM wave equations Glauber state\\[\\vert a\\rangle=e^{-\\frac{1}{2}\\vert\\alpha_i\\vert^2}\\sum_{n=0}^{+\\infty}\\frac{\\alpha_i^2}{\\sqrt{n!}}\\vert n_i\\rangle\\] Fock state Tensor product of groups of photons of the modes $k_j$ \\[\\vert n_{k_0}\\rangle\\circ\\dots\\circ\\vert n_{k_n}\\rangle\\]Fourier transforms\\[\\hat f(\\xi) = \\int_{-\\infty}^{+\\infty}f(x)e^{-2\\pi ix\\xi}dx\\quad\\text{Fourier transform}\\\\f(x) = \\int_{-\\infty}^{+\\infty} \\hat f(\\xi)e^{2\\pi ix\\xi}dx\\quad\\text{inversion Fourier transform}\\]Classical, semi-classical and non classical forms of lights and photons Sun and blackbody light single mode laser coherent light gaussian wave packet entangled photons photon squeezed state Photon number Photon number superposition Antibunching non gaussian states Doppler effectSuperconductivitySome materials have 0 resistivity below a threshold temperatureSuperfluidityAt a very low temperature, helium 3 and 4 become superfluid and have no viscosityBose-Einstein condensated" }, { "title": "ALGOREP: Concensus for Asynchronous Systems", "url": "/cours/posts/algorep_consensus_async/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 16:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursEst-ce quâ€™on est capable de creer un consensus asynchrone ? Oui on lâ€™utilise tous les joursUn papier theorique dit non mais si câ€™etait le cas Facebook et machin ne fonctionneraient pasEn tout cas câ€™est impossible dans un mode completement asynchroneFLP Abstract of the paperThe consensus problem involves an asynchronous system ofprocesses,some of which may be unreliable. The problem is for the reliable processes to agree on a binary value. In this paper, it is shown that every protocol for this problem has the possibility of nontermination, even with only one faulty process. Impossibility resultNo completely asynchronous consensus protocol can tolerate even a single unannounced process death.Problem descriptionConfigurations" }, { "title": "ALGOREP: How to build a Failure Detectors", "url": "/cours/posts/algorep_failure_detector/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOn a un ensemble de machine. Comment monitorer pour savoir quâ€™une est morte ? Si quelquâ€™un dans la salle a une machine qui meurt, on va le savoirSupposons quâ€™on a un admin 6, pourquoi câ€™est pas une bonne solution ? Ca se scale pas bienOn centralise dans un seul data center pour un systeme distribueComment on pourrait faire pour detecter les machines qui meurent de maniere auto ?Si on a une mamie agee, coment on sait ? On la rappelle le matin, le midi, a 14hEt si la mamie est tres lente a repondre au telephone ? On appelle une premiere fois, une seconde fois, etc.Au bout de certaines sonneries on la suppose morte On se forge une conviction de si la machine est vivante ou morte On est pas sur a $100\\%$ Desirable properties Completness Accuracy Speed Scale Equal load on each member Network Message Load What real failure detectors prefer ? Success and accuracy Scale &amp;amp; SpeedStrategiesCentralized heartbeatingOn a une machine centrale qui envoie des messages a tout le monde, sauf que la machine ne fait que ca et doit faire dâ€™autre decisions On peut avoir une machine avec superposition de couches Un chef pour les fautes, un chef pour les decisions, etc. On empile les couches jusquâ€™a contrer le theoreme dâ€™impossibiliteRing HeartbeatingOn va regarder nos voisins a gauche et a droite, pour propager le message quâ€™une machine est morte on doit faire le tour de lâ€™anneau.Si notre voisin de droite est mort, comment on fait ? On veut se connecter a son voisin de droiteEt si son voisin de droite est mort aussi ?Soit on est coupe du reseau, soit systeme de cascade de mort de machinesAll-to-all heartbeating A processus heartbeats periodically all its neighbours If heartbeat not received from a process within timeout, mark this process as failedGossiping heartbeatingOn envoie un heartbeat a quelquâ€™un, cette personne dit telle ou telle personne est vivante On prend un pool de personnes random a qui envoyer notre heartbeatConclusion Heartbeat is a fundamental of Failure detection" }, { "title": "ALGOREP: Global Snapshot", "url": "/cours/posts/algorep_global_snapshot/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursProblem statement No global clock No shared memory Unpredictable message delay On est dans un data center, EDF coupe lâ€™electricite $\\Rightarrow$ on est mort.Comment est-ce quâ€™on backup ? Etienne nous dit de backup, il y en a un qui est un peu lent. Il y a un crash et on a loupe le backup On definit un etat stableQuâ€™est-ce quâ€™on fait de lâ€™info entre nous (les messages) ? Si on definit un etat stable ou rien ne transite, sinon câ€™est pas un systeme distrib On doit definir un backup pendant que des messages passent, des apps tournent, etc.Global state and cutsCuts DefinitionA cut in a time diagram is a line joining an arbitrary point on each process line that slices the space-time diagram into a PAST and a FUTURE.Global state DefinitionThe global state of a distributed system is a collection of the local states of the processes and the channels.Consistent cutQuâ€™est-ce quâ€™on pense de cette cut ? Le probleme est quâ€™il ne faut pas quâ€™on soit dans des moment ou il y a un envoie et un evenement qui risque de ne pas etre retrouveElle est mauvaise parce que la coupe se fait avant lâ€™envoie $e_2$ mais aussi aprÃ¨s la rÃ©ception de $g_4$Consistent Global stateOn a des regles: Tout envoi a une reception Une reception implique que lâ€™envoi est dans lâ€™etat globalVoila une coupure coherente:Snapshot for FIFO channelsOn veut envoyer un message puis un deuxieme, comment on fait pour que le premier message arrive avant le premier ? Envoyer un message a tout le monde $\\to$ broadcastArreter ce que font les machines nâ€™est pas une bonne ideeOn flush les canaux grace a la propriete FIFO avec le broadcast $\\to$ plus aucun message en transitProbleme: le leader envoie un message a tout le monde â€œfait la snapshotâ€. Une machine rapide relaie le message a une machine lente qui nâ€™a pas recu le message original, elle va recevoir 2 fois le meme message. Comment on fait ? On essaie de numeroter de maniere unique les snapshotsDans un snapshot, on sâ€™en fiche des messages applicatifs.Prenons lâ€™exemple de $f_3$-$e_4$, a ce moment un message est en transit. Comment on enregistre le message ? Dans ce cas, seul $F$ peut enregistrerOn va stocker dans les messages envoyes depuis notre derniere snapshotChandy-Lamport Algorithm : InformalCorrectness When a process $j$ receives a message $m_{i,j}$Complexity Message complexity$O(e)$ for the record of a single instance of the algorithm, with $e$ the number of edges in the graph Time Complexity$O(d)$ time with $d$ the diameter of the graphRemarks The recorded global state may not correspond to any of the gloal states that occured during the computation\\[\\color{red}{\\text{BUT...}}\\] The recorded global state may not corresponds to any of the global states that occurred during the computation The recorded global state is a valid state in a equivalent executionSnapshot for non-FIFO channelsOn envoie $A$ puis $B$, on suppose quâ€™on peut recevoir $B$ avant $A$Lai Yang AlgorithmOn est tous initialement dâ€™une couleur (ex: blanc). On se met en rouge si on fait une snapshot et on envoie des messages.Quâ€™est-ce qui se passe si on recoit un message rouge ? Quelquâ€™un a fait un snapshot et câ€™est en coursA partir de maintenant jâ€™envoie que des messages rougesComment on sait quels etaient les messages en transit ? Tous les messages blancsLe recepteur va sauvegarder les messages comme etant en transitOn nâ€™est pas capable de: Borner les delais dâ€™un message Avoir une file de messageAu moment de redemarrer le systeme, on ne renvoit pas de message blanc et on peut les integrer au snapshot directement au lieu de simuler leur reception.Pour ne pas faire $\\color{white}{\\text{blanc}}$ $\\color{red}{\\text{rouge}}$ $\\color{white}{\\text{blanc}}$, on fait plutot $\\color{white}{\\text{blanc}}$ $\\color{red}{\\text{rouge}}$ $\\color{purple}{\\text{violet}}$ $\\color{green}{\\text{vert}}$ etc.Si on recoit des messages blanch en snapshot violet, il y a un probleme dans le systeme. Ce nâ€™est pas grave du moment que la couleur de la derniere snapshot est de la meme couleur pour toutes les machines.Matternâ€™s Algorithm Horloge de MatternComment on fait si on veut manger chez Glados jeudi soir ? On envoit un message â€œA 19h je mange chez Gladosâ€On va faire pareil pour cete algoOn se dit â€œRDV a un millionâ€ pour un snapshot (au plus tard). Avant la reception du message a 1 million, les machines doivent faire leurs snapshots" }, { "title": "ALGOREP: Consensus (with failures) in synchronous systems", "url": "/cours/posts/algorep_consensus_sync/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOn vote a la majorite pour pizza vs kebab. Ca suppose: Quâ€™on est impair Chaque voix a le meme poids Que la majorite est dâ€™accordSupposons quâ€™on soit $11$, on ne peut pas arriver a un consensus si quelquâ€™un ne repond pas. Ca suppose: La machine est morte Le lien avec la machine est mortWhat is a consensus ? Defintion: consensusAll process must agree on a value even if inputs can be arbitrary. There is generally a validity condition describing the outputs values that are permitted for each patternsâ€™ input Agreement on wether to commit or abort transaction in a database Agreement on a specific value reading multiple captors (altitude for instance) Classification of a component as faulty On va construire des algos tolerants aux fautes.Link FailuresThe coordinated attack problemOn a un ensemble de generaux qui attaquent une ville. La seule facon quâ€™ils aient de prendre la ville seraient de se coordonner. Ils peuvent communiquer avec des messagers Les messagers peuvent se faire tuer Est-ce que jâ€™attaque ou pas ? Comment faire quand les communications ne sont pas fiables ? On sait quâ€™il faut 10 min pour faire le trajet entre 2 generauxOn demande aux messagers de revenirMais si le messaer a transmis le message mais ne revient pas ? On en renvoit un autreMais sâ€™il se fait tuer aussi ? Lâ€™assassin a un tas de cadavreOn peut decouper les interactions de nos generaux en rounds.Fleche verte: message envoye0/1: ne pas attaquer/attaquerIl y a un moment ou on peut perdre un message ($\\color{green}{\\to}$)Comment faire ? On prend une valeur par defaut si on nâ€™attend pas de consensus (spoiler: non) Supposons quâ€™on supprime un message.Est-ce quâ€™on a un changement pour le processus $P_2$ ? Non, pour lui ca ne change rien Or, pour un algorithme qui marche avec consensus, il faut que tous les processus soient en accord en meme temps.On peut toutefois tres bien dire quâ€™on sâ€™arrete en $D-1$ round et que lâ€™autre message peut etre perdu. On peut se limiter au round precedent, on baisse la complexite de lâ€™algo.On peut donc supprimer le message $P_2\\color{green}{\\to} P_1$ precedent, et de la meme maniere surprimer le message $P_1\\color{green}{\\to} P_2$Comment $P_1$ prend la meme decision que $P_2$ ? On sait quâ€™on a toujours une decision qui doit etre prise au plus tard qu round $D$Or, si on nâ€™a pas envoye de message, la decision etait connue de tout le monde au round $D-1$On repete lâ€™etape pour le round $D-1$ jusquâ€™a arriver aux premiers message On construit un algo sans envoi de messages Un algo commence avec $0$, $0$ est decideUn algo commence avec $1$, $1$ est decideQuelle est lâ€™unique facon de changer de configuration ? De recevoir un message Câ€™est une execution bivalenteRecapOn veut faire un consensus dans tous les systemes distribues. Dans un systeme synchrone, on suppose quâ€™on a des problemes avec des liens, on montre le theoreme de lâ€™impossibilite et quâ€™un message peut etre perdu indefiniment.On se base donc sur un etat pour tout le monde et le seul moyen de changer de configuration est de recevoir un message.Impossibility Result Let $G$ be a graph with 2 nodes connected by a single edge. Then, no algorithm solves the coordinated attack problem on $G$ Proof (by contraction) Suppose a solution exists, given by an algorithm $A$ Let $\\alpha$ be the execution when both processes starts with $1$ and eventually outputs $1$ with all messages delivered. Let $\\alpha_1$ be the same than $\\alpha$ except that all messages are lost after $r$ rounds. In $\\alpha_1$ both processes output $1$. Let $\\alpha_2$ be the same than $\\alpha_1$ except that the last (round $r$) message from process $1$ to process $2$ is not delivered. $\\alpha_1\\sim^1 \\alpha_2$ : $\\alpha_1$ is indistinguishable from Î±2 from process $1$ point of view Since process $1$ outputs $1$ in $\\alpha_1$, then it outputs $1$ in $\\alpha_2$. By termination and agreement, process $2$ outputs $1$ Let $\\alpha_3$ be the same than $\\alpha_2$ except that the last message from process $2$ to process $1$ is not delivered. $\\alpha_2\\sim^1 \\alpha_3$ : $\\alpha_2$ is indistinguishable from $\\alpha_3$ from process $2$ point of view. Since process $2$ outputs $1$ in $\\alpha_2$, then it outputs $1$ in $\\alpha_3$. The same for process $1$ by termination and agreement. IMPOSSIBLE!Process failuresProblem Statement What if communications are reliable, but processes may fail ?2 kinds of failure models: Stopping failures: Processes may stop without warning Byzantine failures $1$ : fautly processes may exhibit completely unconstrained behaviors.FloodsetComment regler ca ? FloodSet: FloodingOn calcule le diametre de notre systemeExampleStopping Algorithm: EIG Etienne : â€œJâ€™explique mal et vous comprenenez malâ€On va se baser sur un EIG treeCet algo va marcher direct pour les fautes byzantines Etienne est vivant, envoie un message et creve.Comme ca on peut deduire a quel round Etienne est mortExampleLe processus $3$ echoue au round $1$ mais a envoye un message au processus $1$ mais pas au processus $2$.Comment $2$ peut etre au courant que $3$ a envoye un message a $1$ ? $1$ doit lui relayer le messageA la dernier ligne, on doit savoir quelle info a ete propagee par le processus $3$, le dernier etage de lâ€™arbre doit etre le meme pour tous les processus corrects. Si on veut supporte $20$ fautes, il faut avoir $20$ lignes Construction On initie le $1^{er}$ etage de lâ€™arbre avec sa propre valeur et on la propage aux autres Au $2^e$ etage on recoit la valeur initiale des autres processus Pour tous les autres rounds, le process $i$ diffuse une pair $(x,v)$ qui va etre un des labels de lâ€™etage precedent Il se construit en se basant sur lâ€™etage precedent et en recevant la valeur des autres elements Why byzantine is more complicated than stopping ? Three processes cannot solve the agreement problem if one of them is faulty !" }, { "title": "IMCO: Describing color", "url": "/cours/posts/imco_des_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-09 14:00:00 +0200", "snippet": "Lien de la note HackmdDescribing a relative color Need of a vocabulary to describe a color 2 (or more) objects may be all blue, but different Need additional descriptions within colors How do we organize colors ?Blue jacket ?All of this is blueThis is navy blueThis is dark navy blue What about colors that are hard to describe ?How ? - Desert Island ExperimentA person with normal color vision is on an island and need to group pebbles Think about colo in terms of common color names (red, blue, green, etc.) How to arrange achromatic samples ? Orders from darker to lighter How to arrange chromatics smaples ? By color (hue) Example: group all red pebbles together How to arrange chromatic samples of the same hue ? order by lightness order by how much color they contain (chroma) We know how to arrange chromatic samples of the same hueColor attributesWe found color attributes Pyschological attributes that describe colors: Hue Lightness Definition: HueAttribute of a visual sensation according to which an area appears to be similar to one of the perceived colors: red, yellow, green, and blue, or to a combination of 2 of them achromatic color: perceived with lacking hue chromatic color: perceived color with hue 11 primitives colors$\\color{white}{\\text{white}}, \\color{gray}{\\text{gray, }}\\color{black}{\\text{black, }} \\color{red}{\\text{red, }}\\color{green}{\\text{green, }} \\color{yellow}{\\text{yellow, }} \\color{blue}{\\text{blue, }} \\color{orange}{\\text{orange, }} \\color{purple}{\\text{purple, }} \\color{pink}{\\text{pink, }} \\color{brown}{\\text{brown}}$Elementary colors: white, black, red, green, yellow, blue unique hues according to opponent color theory Definition: Lightness Brightness: attribute of a visual sensation according to which an area appears to emit, or reflect, more or less light $\\to$ relative Lightness: the brightness of an area judged relative to the brightness of a similarity illuminated area that appears to be white or highly transmitting $\\to$ absolute \\[\\text{Lightness}=\\frac{\\text{Brightness}}{\\text{Brightness(white)}}\\] Definition: Chroma Colorfulness: Attribute of a visual sensation according to which the perceived color of an area appears to be more or less chromatic Chroma: Colorfulness of an area judged as a proportion of the brightness of a similarly illuminated area that appears white or highly transmitting \\[\\text{}Chroma = \\frac{\\text{Colorfulness}}{\\text{Brightness(white)}}\\]Color Order SystemsMunsell Color systemComposition: Hue 10 hues (each divided into 10 subhues) Lightness (called Value) 11 steps (0: ideal black, 10: ideal white) Chroma Range depending on the hue Eyes are all differently sensitiveNotation: H V/C H = Hue, V = Value, C = Chroma e.g. 5Y 7/12 or 5R 1/4 Munsell Color Tree from PantoneHow to communicate color ? Pantone and other organizarionsPantone Color-Naming System Used in the printing/manufactuing industry Swatches are used to specify colors Printed using 14 inks Useful for specifying communicating color Patented ! Need a license to use the listDescribing Relative ColorColor Mixing SystemsAmounts give a specification, not the resulting color RGB value ${100, 20,90}$ in your screen $\\neq$ RGB ${100, 20,90}$ in my screen CMY value ${90, 10,50}$ in your printer $\\neq$ CMY ${90, 10,50}$ on my printer RGB value ${100, 20,90}$ in my screen $\\neq$ CMY ${90, 10,50}$ on my printerHSV/HSL Spaces Hue: color Saturation: measure of chroma Value or Lightness: measure of lightnessHSV/HSL difference: HSL: maximum lightness = white HSV: maximum Value = â€œintenseâ€ colorHSV $\\leftrightarrow$ RGBYCbCr Space Y is Luminance $\\simeq$ Brightness Cb is related to blue Chrominance Cr is related to red Chrominance Used a lot in color compressionDecompositionDivide image in RGBDivide Image in HSVDivide image in YCbCrUse Case - Color Segmentation HSV or YCbCr can be used in Image and Video Processing (e.g., skin segmentation)However, as RGB and CMYK, resulting color is only relative to capture conditionDescribing Standard Color Use an universal way (i.e., numbers) to communicate color instead of using names Need to standardize the color forming conditions Illuminant (viewing lighting) Observer (the human visual response to a given stimulus) Object reflectance ($\\lambda$-dependent spectral measurement) ColorimetryCIE Standard Observers Light sources (primaries): $435.8nm$, $546.1nm$, $700nm$ CIE 1931 Standard Colorimetric Observer $2^o$ visual angle ($2^o$ Observer) $17$ color normal observers CIE 1964 Standard Colorimetric Observer $10^o$ visual angle ($10^o$ Observer) 76 color normal observers CIE Standard Iluminants D: Different types of daylight D50 ($\\color{cyan}{5003K}$) (warm daylight) printing/graphic arts D65 ($\\color{blue}{6504K}$) (natural daylight) art/film/photography A: incandescent lamp ($\\color{orange}{2856K}$) F: Fluorescent light F2 (4230K), F11 (4000K) Color TemperatureTemperature uses as a reference an ideal object called â€œBlack Bodyâ€ Definition: Black BodyAn object that absorbs completely heat and light, and radiates the energy back. It radiates light when heated.CIE Standard Iluminants Warm: $T \\lt 3300K$ Dormitory, Restaurant, Hotel, Coffee Shop Intermediate: $3300K\\lt T\\lt 5300K$ Stores, Shcool, Libraries Cold: $T\\gt 5300K$ Offices, Hospitals Computing XYZ Tristimulus Values $XYZ$ Tistimulus Value $\\to$ amounts of 3 specified stimuli required to match a color\\[\\begin{aligned}X &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar x_{\\lambda}d\\lambda\\\\Y &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar y_{\\lambda}d\\lambda\\\\Z &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar z_{\\lambda}d\\lambda\\\\\\end{aligned} \\quad k =\\]Chromaticity Diagrams: CIE 1931All Hues are perceivable by the standard observer MacAdam EllipsesWhere are the grey ? Brown ? No light info !Uniform color spaces CIE XYZ Space is not perceptually uniform equal perceptual differences between colors $\\neq$ equal distances in the XYZ space CIE recommenced uniform color spaces CIE 1976 $L\\times u\\times v$ CIE 1976 $L\\times a\\times b$ ExampleIn matplotlib:CIE $L\\times a \\times b$ Space\\(L^* = 116f(\\frac{Y}{Y_n})-16\\begin{cases}a^* = 500[f(\\frac{X}{X_n})-f(\\frac{Y}{Y_n})]\\\\b^* = 200[f(\\frac{X}{X_n})-f(\\frac{Y}{Y_n})]\\end{cases}\\)$L\\times C\\times h$Whatâ€™s left ? Modeling cognitive effects or phenomena How to obtain absolute color attributes (brightness and colorfulness) ? Debate about accuracy of $\\bar x, \\bar y, \\bar z$ Color Matching Functionc Representativeness of the population used for the experiments Limitaations of equipment used for the experiments How to understand color perception of â€œcolor anomalousâ€ observers ? " }, { "title": "IMCO: Defining colors", "url": "/cours/posts/imco_def_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-09 10:00:00 +0200", "snippet": "Lien de la note HackmdWho Am I ?Ricardo SAPAICO PhD in Computer Science, Tokyo Institute of Technology 10+ years of expereicneAbout DXO Labs ~18 years 50 people working in FranceProducts DxO PhotoLab LightRoom like DxO PureRaw Smaller version of PhotoLab Editing images quickly EISA award Nik Collection by DxO Plugin for Adobe DxO FilmPackBack to the courseWhy color matters ? Useful for quality inspection Rely on color for a small object Gives shape (shine color light on objects and create shadows) Cultural heritage Paintings If you take a picture of a painting, you want the photo to represents the painting well Same for printing a copy of the painting Printing Computer graphics Even tho not physical, you have to make sure you have the good colrs Photography Sometimes, itâ€™s just a matter of doing the right thing to have a good picture From color to B&amp;amp;W is not easy Style Transfer IA on photography Hyperspectral images Evaluation Attendance Each class attended, you get $+0.5$ Writtent report Exercises using the data we will obtain during the TPs A litlle bit of investigation for solving a typical color-related probleme in cameras Group of 2 people Participation bonus: You can get up to $+2.0$ in your grade if: You ask me technical question by mail You ask technical questions in the IMCO group (Teams) You reply a technical question in the IMCO group (Teams) Defining colors White becomes pink with reflectionWhat is (not) color Color is NOT a property of an object Once in the dark, no more color Someone colorblind will see the color differently Color is NOT a particle Color is a sensation like touch Color is a sensation produced by a physical reality Grass is NOT green and sky is NOT blue,They are perceived as green and blueThey have physical properties that makes them look that way Color is in your HEADHow is color produced ? Sun: light Apple: object Human: sensorElectromagnetic spectrumHow can you see the black if it doesnâ€™t reflect any light ? Because there is a shape (ex: a TV)Black isnâ€™t a color but we can perceive itIf we have a white surface and a red beam of light coming in, it would reflect the red.ObjectSurface and subsurface interaction with light specular absorption diffuse transmittance refraction scattering To know of colors will work on this textile, you can only know it by printing hundreds of colors and extrapolate for the other onesColor is no â€˜partâ€™ of an object Dimension, shape, material (what itâ€™s made of), volume, density, porositySensorHuman vision system ReminderRefractive index:\\[n=\\frac{c}{\\nu}\\] Cornea The most significant image-forming element of the eye Eye problemes, such as nearsightedness, farsightedness, astigmastism, can be attributed to it Lens Serves the function of accomodation It is layered, flexible structure that varies in index of refraction. This feature serves to reduce some of the aberrations Distant object: it becomes â€œflatterâ€ resulting in the decreased optical power Nearby object: it becomes â€œfatterâ€ thus has increased power As we age, we lose flexibility. When we are about 50 years, the lens has completely lost its flexibility Iris + pupil controls the pupil size Pupil is the hole in the middle of the iris through which light passes. The pupil size is largely determined by the overall level of illumination Pigmentation in the iris is what gives us color Retina A thin layer of cells, approximately the thickness of tissue paper Contains the visual systemâ€™s photosensitive cells + initial signal processing and transmission â€œcircuitryâ€ Photoreceptios: Rods and Cones Fovea Area on the retina where we have the best spatial and color vision Optical nerve Transfer info from the retina to the brain 1 million fibers vs 130 million photoreceptors There is a compression of the visual system There are no photoreceptors where the nerve is blind spot Rods and conesCones: useful to perceive colorRods: useful in low-light3 types of cones: Long Medium Short Fun factMost mammals have only blue and green cones, only primates have redColor matching experiment The observer adjusts the intensity of the primary colors until the results matches the testThis test was like 100 years ago Chromaticity diagram Spectrum LocusChromaticity of monochromatic light at specified wavelengthSpatial properties of Color VisionIn JPEG we have an image divided in luminance and chromatic information. Our eyes are less sensitive to chromatic infos, so JPEG subsamples then reconstructs the imageHow to (re)produce color ? Additive process (RGB) Light mixing Substractive process (CMY) Used in printing Paint mixing Color frameworkBonusFacts about animals Most fish, frogs and turtle and 3 to 5 cones Most mammals have retinas where rods predominate Is it because the Earth was dark when first mammals appeared ? Nocturnal mammals like rats and mice have retinas dominated by rods (only 3 to 5% of cones) Snakes can see ultraviolet lightWhy the eyes reflect the light ? In the eyes, there are epithelial cells Epithelial cellsPrevents light from going back to the retina $\\to$ keeps the sharpness and contrastNocturnal animals exchange image quality for image power. Their cells reflects the light back $\\to$ the photoreceptors have a second chance to absorb energy Different than having red eyes !Structural color: IridiscenceUsed for camouflageFacts about humans Red-green color blindness $8\\%$ males (XY chromosome) $0.5\\%$ females (XX chromosome) of northern European descentAround $12\\%$ of the female population could be tetrachromaticTo think over What is fluorescence ? Why a banana stays yellow under 2 different light sources ?" }, { "title": "CMKV: Metropolis-Hastings et recuit simule", "url": "/cours/posts/cmkv_hal_recuit/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-08 14:00:00 +0200", "snippet": "Lien de la note HackmdRappels$P(X=x)$ =&amp;gt; variable aleatoire $x$: ne pas lister toutes les valeurs possibles pour $X$\\[P(X=x\\underbrace{,}_{\\text{et}} Z=z)\\]On le notait $\\cap$ au lycee\\[P(A\\cap B) = P(A).P(B)\\] $X = (X_1,\\dots,X_n)$ est un vecteur aleatoire $x = (x_1,\\dots,x_n)$ est une realisation SudokuIl existe une solution dediee mais on ne la connait pas $\\color{red}{x_1}$ $\\color{red}{x_2}$ Â  Â  $\\color{red}{x_4}$ $2\\color{green}{\\rightarrow y_1}$ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  \\[P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=1\\\\x_4=1\\end{cases}\\]Dans ce cas, on ne regard que 3 realisations et on va les evaluer\\[P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=1\\\\x_4=3\\end{cases}\\\\P(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=3\\\\x_4=4\\end{cases}\\\\P(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =3\\\\x_2=1\\\\x_4=4\\end{cases}\\\\P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\end{vmatrix})\\color{green}{\\lt}P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\end{vmatrix})\\color{green}{\\lt}P(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\end{vmatrix})\\color{green}{=}P(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\end{vmatrix})\\\\\\color{red}{\\boxed{L(X=x\\vert Y=y) = P(Y=y\\vert X=x)}}\\\\\\]On veut reecrire $f(x,y)=\\cos(x)\\sin(\\frac{1}{y})$ en $g(y,x)$\\[g(a,b)=\\cos(b)\\sin(\\frac{1}{a})\\]Retour au sudoku: on sait parler des probas et des vraisemblances On lit les donnees a un espace de recherchePour avoir des vraisemblances:\\[\\begin{aligned}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{=}&amp;amp;L(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\\\&amp;amp;\\overbrace{L(\\begin{vmatrix}2\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})}^{\\downarrow}&amp;amp;\\uparrow&amp;amp;&amp;amp;\\end{aligned}\\] Rappel : Bayes\\(\\begin{aligned}x_{\\text{sol}} = \\text{arg max}_x&amp;amp;\\underbrace{P(X=x\\vert Y=y)}\\\\&amp;amp;=\\color{blue}{\\frac{L(X=\\boxed{x}\\vert Y=y)P(X=\\boxed{x})}{P(Y=y)}}\\end{aligned}\\)La meteo de GulliLe retour de rand()\\[\\begin{cases}P(\\text{beau}) = 0.5 &amp;amp;\\color{red}{\\varnothing}\\\\P(\\text{pourri}) = 0.3 &amp;amp;\\color{red}{1}\\\\P(\\text{couvert}) = 0.2 &amp;amp;\\color{red}{2}\\end{cases} \\leftarrow P(T=t)\\quad t\\in{\\text{\\{beau}}, \\text{pourri}, \\text{couvert\\}}\\] $0 Â  RANDMAX $\\varnothing\\dots\\varnothing$ $1\\vert\\color{red}{1}\\dots1$ $2\\dots2$ Câ€™est pareil pour le sudoku: tout depend de toutOn va voir comment calculer des probas ou les variables ne sont pas independantes\\[\\begin{aligned}y&amp;amp;\\rightarrow\\\\u&amp;amp;\\rightarrow\\end{aligned}\\bigcirc\\rightarrow x_{\\text{sol}} = \\text{arg max}_xP(X=x\\vert Y=y)\\]\\[\\begin{cases}P(\\text{beau}) = 0.4 \\\\P(\\text{pluie}) = 0.1 \\\\P(\\text{couvert}) = 0.2 \\\\P(\\text{orage}) = 0.2 \\\\P(\\text{neige}) = 0.2\\end{cases}\\\\\\color{red}{x_{sol} = beau}\\]On a un echantilloneur:\\[P\\rightarrow \\bigcirc \\rightarrow x\\] Il y a plus de chances que lâ€™echantilloneur ne nous donne pas la bonne solutionHypothese\\[U\\to P?\\\\\\text{hypothese}: \\not\\exists x, P(x)=\\varnothing\\\\P(X=x)=\\boxed{\\color{red}{\\frac{1}{Z}}e^{-U(x\\color{green}{,y})}}\\Rightarrow U(x)=-\\log(Z.\\underbrace{P(X=x)}_{\\color{red}{\\text{ouf}\\neq\\varnothing}})\\\\\\sum_xP(X=x)=1\\Rightarrow Z=\\sum_xe^{-U(x)}\\gt\\varnothing\\text{ une constante}\\]Un algo: Metropolis-HastingsIl a ete invente en meme temps par 2 chercheurs\\[x^{(0)} = \\begin{vmatrix}1&amp;amp;1\\\\1&amp;amp;\\not 2\\end{vmatrix} = \\color{red}{\\begin{pmatrix}1\\\\2\\\\1\\end{pmatrix}}\\\\x^{(1)} = \\begin{vmatrix}2&amp;amp;1\\\\3&amp;amp;\\not 2\\end{vmatrix} = \\color{red}{\\begin{pmatrix}2\\\\1\\\\3\\end{pmatrix}}\\\\\\vdots\\\\x^{(t)}=\\begin{vmatrix}\\bullet&amp;amp;\\bullet\\\\\\bullet&amp;amp; \\bullet\\end{vmatrix}\\] Initialisation: $x^{(0)}$ tire aleatoirement avec loi uniforme $t\\leftarrow\\varnothing$ Repeter jusquâ€™a lâ€™infini (un algoâ€¦ a lâ€™infini) On fait juste un tres grand nombre dâ€™iterations Repeter jusquâ€™a lâ€™infini: \\(x_{\\text{rand}}\\) tire avec loi uniforme \\[P_{\\text{trans}} = \\frac{P(X=x_{\\text{candidat}})}{P(X=x^{(t)})}\\] Si \\(P_{\\text{trans}}\\gt 1\\color{red}{\\Leftrightarrow P(X=x_{\\text{candidat}})\\gt P(X=x^{(t)})}\\) Alors \\(x^{(t+1)}\\leftarrow x_{\\text{candidat}}\\color{green}{\\equiv\\text{ MIEUX = ON GARDE}}\\) Sinon on fait \\(\\color{green}{\\boxed{x^{(t+1)}\\leftarrow x_{\\text{candidat}}}}\\color{red}{\\Leftrightarrow P(x_{\\text{candidat}})\\lt P(x^{(t)})}\\) avec la proba \\(P_{\\text{trans}}\\le 1\\) Sinon $x^{(t+1)}\\leftarrow x^{(t)}$ $t\\leftarrow t+1$ Quel est cet algo ? Câ€™est un algorithme de descenteCet algo est tel que la fonction $P(x^{(t+1)})\\ge P(x^{(t)})$, quand $t$ augmente, $P(x^{(t)})$ augmente aussi. Câ€™est un optimiseur hyper sous-efficace Surtout compare a des algos de descenteExemple $0$ RANDMAX $1\\dots\\color{green}{\\boxed{1}}1$ $0\\dots0$ \\[i_{\\text{trans}} = 0.8 \\times \\text{RANDMAX}\\] Si rand() \\(\\lt P_{\\text{trans}}\\times\\) RANDMAX $x^{(t+1)}\\leftarrow x_{\\text{candidat}}$ Sinon $x^{(t+1)}\\leftarrow x^{(t)}$\\[\\begin{aligned}P(X=x) &amp;amp;= \\frac{1}{Z}e^{-U(x)}\\\\P_{\\text{trans}} &amp;amp;= \\frac{\\not{\\frac{1}{Z}}e^{-U(x_{\\text{candidat}})}}{\\not{\\frac{1}{Z}}e^{-U(x^{(t)})}}\\\\&amp;amp;= e^{-(\\underbrace{U(x_{\\text{candidat}}) - U(x^{(t)})}_{\\color{red}{\\Delta U}})}\\end{aligned}\\]Recuit simuleComme les forgerons qui chauffe la lame dâ€™une epee, qui la mette dans lâ€™eau le temps de manger, la rechauffe en revenant et la laisse refroidir lentement a lâ€™air libre apres avoir ete formee Apres avoir ete dans lâ€™eau, lâ€™epee est cassante On atteint lâ€™etat le plus stable possible en lassant refroidir lentement, lâ€™epee est la plus solide possible Câ€™est un etat de basse energie qui pourrait etre trouve dans la natureAlgorithme Initialisation $T^{(\\varnothing)}\\leftarrow$ elevee On repete: $\\not P\\to P_{T^{(t)}}$ $T^{(t+1)}\\simeq T^{(t)-}$ $t\\leftarrow t+1$ \\[P_{\\color{red}{T}}(X=x) = \\frac{1}{Z_{\\color{red}{T}}}e^{-U(x)}\\\\P(X=x)\\propto e^{-U(x)}\\\\P_{\\color{red}{T}}(X=x)\\propto e^{-\\frac{U(x)}{T}}\\\\U_T(x)=\\frac{U(x)}{T}\\]Exemples dâ€™utilisation On prend une image en niveau de gris quâ€™on stylise On prend une image quâ€™on veut binariser, avec le moins de regions blanchesoires possibles mais les plus grandes possiblesEst-ce quâ€™on a la meilleure solution ? On en a pas la moindre ideeRetour sur lâ€™algo Initialisation: $\\not x^{(0)}$ tire aleatoirement (avec loi uniforme) $t\\leftarrow\\varnothing$ $\\quad\\color{blue}{T^{(0)}\\leftarrow \\text{elevee}}$ Repeter jusquâ€™a lâ€™infini (un algoâ€¦ a lâ€™infini) Repeter jusquâ€™a lâ€™infini: \\(x_{\\text{rand}}\\) tire avec loi uniforme \\[P_{\\text{trans}} = \\frac{P_{\\color{blue}{T}}(X=x_{\\text{candidat}})}{P_{\\color{blue}{T}}(X=x^{(t)})}=e^{\\frac{-(U(x_{\\text{candidat}}-U(x^{(t)})))}{\\color{blue}{T^{(t)}}}}\\] Si \\(P_{\\text{trans}}\\gt 1\\) Alors \\(x^{(t+1)}\\leftarrow x_{\\text{candidat}}\\color{green}{\\equiv\\text{ MIEUX = ON GARDE}}\\) Sinon on fait \\(\\color{green}{\\boxed{x^{(t+1)}\\leftarrow x_{\\text{candidat}}}}\\) avec la proba \\(P_{\\text{trans}}\\le 1\\) Sinon $x^{(t+1)}\\leftarrow x^{(t)}$ $\\color{blue}{T^{(t+1)}\\leftarrow\\propto T^{(t)}\\text{ ou } \\propto=1^{-}}$ $t\\leftarrow t+1$ Si on fait un tirage aleatoire, est-ce que câ€™est intelligent de mettre que des $1$ dans une grille vide dâ€™un sudoku ? Non, câ€™est la meme proba de mettre des $1$ que nâ€™importe quel autre chiffre $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{2}$ $\\color{blue}{2}$ $\\boxed{2}$ $\\boxed{3}$ $\\color{blue}{2}$ $\\color{blue}{3}$ $\\color{blue}{3}$ $\\color{blue}{3}$ $\\boxed{4}$ $\\boxed{1}$ $\\color{blue}{4}$ $\\color{blue}{4}$ $\\color{blue}{4}$ Câ€™est quoi lâ€™interet de ce tirage â€œmoins conâ€? (et pas du tout aleatoire) On peut changer $x^{(t)}$ aleatoirement (en echangeant des cases par exemples) $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{red}{\\boxed{3}}$ $\\color{blue}{2}$ $\\boxed{2}$ $\\boxed{3}$ $\\color{blue}{2}$ $\\color{blue}{3}$ $\\color{red}{\\boxed{2}}$ $\\color{blue}{3}$ $\\boxed{4}$ $\\boxed{1}$ $\\color{blue}{4}$ $\\color{blue}{4}$ $\\color{blue}{4}$ On met de lâ€™intelligence dans cet algo qui a vraiment besoin dâ€™etre aleatoire\\[P_{T\\to+\\infty}(X=x)=\\frac{1}{Z}e^{-\\frac{U(x)}{T}}\\\\\\color{red}{P_{+\\infty}(x) = \\frac{1}{Z}}\\quad\\text{uniforme}\\\\\\color{green}{P_1(x)=P(x)\\\\P_0(x)=\\varnothing\\quad\\forall x}\\] Ce nâ€™est pas une loi de probabilite car la somme des probas $=0$On va determiner la loi de probas autrement, en regardant par exemple un ratio:\\[\\frac{P_T(X=x_{\\text{solution}})}{P_T(X=x)}=e^{\\boxed{\\frac{-(\\overbrace{U(x)-U(x_{\\text{solution}})}^{\\color{red}{\\text{positif}}})}{T\\color{green}{\\to 0^+}}}}_{\\color{blue}{\\to-\\infty}}\\to 0^+\\\\\\frac{P_0(x\\neq x_{\\text{solution}})}{P_0(x_{\\text{solution}})} = \\varnothing\\\\\\begin{cases}\\forall x\\neq x_{\\text{solution}}, P_0(x)=\\varnothing\\\\P_0(x_{\\text{solution}}) = 1\\end{cases}\\]\\[\\downarrow\\\\P_0(x)=\\begin{cases}1&amp;amp;\\text{si } x=x_{\\text{solution}}\\\\\\varnothing &amp;amp;\\text{sinon}\\end{cases}\\]" }, { "title": "ALGOREP: Logical Time", "url": "/cours/posts/algorep_logical_time/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-06 10:30:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursProblem statementDans la classe, qui sâ€™est reveille avant qui ? $1^{ere}$ proposition: on demande lâ€™heure du reveil de tout le mondeProbleme: il faut que tout le monde ait un horloge On ne peut pas faire lâ€™hypothese quâ€™on a une horloge pour tout le monde, sinon on est synchroneLes horloges peuvent avoir des divergences Quelquâ€™un peut dire quâ€™il est debout depuis 5h alors quâ€™en fait il etait 8h $2^{eme}$ proposition: On envoie un message des quâ€™on se leve (ne le fait pas, câ€™est pas bon pour la sante)On ne doit pas avoir de delais de transmission du message Quel evenement a eu lieu avant quel evenement ?Est-ce quâ€™on a vraiment besoin de cette info ? $1^{ere}$ proposition: pour savoir quand est-ce quâ€™une faute est arrivee et on relance le systeme dans un etat precedent $\\Rightarrow$ câ€™est une snapshot On nâ€™a pas de garanti sur le delais des messagesIl faudrait prendre en compte la latence des messages et câ€™est trop complique On va utiliser des horloges logiquesOn va essayer de construire un systeme ou on date les evenements par rapports a des evenements logique $\\Rightarrow$ les envois de messages â€œJâ€™ai vu le message dâ€™Etienne avant de manger ma tartineâ€Consider 3 processes $E$, $F$ et $G$ With some local events: $e_1$, $f_1$, $f_3$, $g_2$, $g_3$ With some send events: $g_1$, $f_2$, $e_2$ With some receive events: $e_3$, $f_4$, $g_4$Ces 2 executions sont impossibles a distinguer On va donner une notion de progresScalar Time: Lamport ClocksDefinitions Rule R1Before executing an event (send, receive, or internal), process pi executes the following\\[C_i:=C_i+d\\quad\\text{with } d\\gt0\\text{, typically 1}\\] Rule R2Each message piggybacks the clock value of its sender at sending time. When a process $p_i$ receives a message with timestamp $C_{msg}$ , it executes the following actions : $C_i := max(C_i, C_{msg} )$ Execute R1 and deliver message Example1.2.3.4.5.6.7.Remarques On peut utiliser lâ€™horloge de Lamport pour lâ€™ordre Il suffit de dire $e_1 \\lt g_1$ Si on incremente toujours de $1$, $h-1$ sera toujours le temps requis pour atteindre le process $e_h$ No Strong ConsistencyProblem The main problem in totally ordering events is that two or more events at different processes may have identical timestamp !Vector Time: Mattern Clocks On va toujours maintenir un compteur On va avoir une horloge local par processus On gere comme une horloge de Lamport On maintient son horloge et celle de tout le mondeComment est-ce quâ€™on peut connaitre lâ€™etat dâ€™un processus ? En envoyant un message On echange avec une $3^e$ personne qui nâ€™a jamais echange avec EtienneOn lui transmet lâ€™avancement dâ€™EtienneSi cette 3e personne envoie un message a Etienne, elle connaitra son avanceePourquoi une personne tierce ? Si on est que 2, on echange des messages quâ€™a 2 et on ne peut pas mettre en avant des horloges complexesEn pratique, comment est-ce quâ€™on fait passer notre compteur local ? Quand on structure un programme distribue, on incremente lâ€™horloge local a des points stables (barre de progression de chargement, etc.)Example On envoie un message a $G$, on veut savoir sâ€™il lâ€™a recu mais il ghostIndirectement, on apprend que $G$ a avance de $5$ elements donc il est vivant, mais est-ce quâ€™il a recu le message ?On sait que $F$ nâ€™avait pas dâ€™information de notre part au departLe $2$ envoye par $E$ a $G$ a ete renvoyee par $F$, sachant que $E$ nâ€™a pas envoye de message a $F$ auparavantOn sait donc que $F$ a recu le message de $E$RemarquesEfficient Implementation of Vector ClocksComment on implemente ca de maniere efficace ? ImplementationOn peut garder les $n$ derniers messages avec nos voisins, on peut juste envoyer le differentiel de la derniere heure envoyer par quelquâ€™un et lâ€™horloge couranteProblem Quâ€™est-ce quâ€™il se passe si jâ€™ai une inversion de messages ?Est-ce quâ€™on est capable de gerer ce cas avec les horloges precedentes ? Non. On va utiliser les ragots $\\Rightarrow$ des matrices dâ€™informations On mâ€™a dit que tu mâ€™as dit queâ€¦\\[\\begin{vmatrix}E&amp;amp;F_E&amp;amp;G_E\\\\E_F&amp;amp;F&amp;amp;G_F\\\\E_G&amp;amp;F_G&amp;amp;G\\end{vmatrix}\\]La machine qui a le plus de communication serait-elle celle qui a le plus de chance dâ€™etre a jour sur la timeline des processus sur chaque machine ? Oui.Virtual Time System DefinitionVirtual time system is an (optimistic) paradigm for organizing and synchronizing distributed systems Relies on Time Warp mechanism, i.e. lookahead-rollback mechanism When a conflict is discovered, the offending processes are rolled back to the time just before the conflict Processes are then executed forward along the revised pathConclusion Different kind of logical time Virtual time system (Jefferson) is a paradigm for organizing and synchronizing distributed systems" }, { "title": "ALGOREP: Leader Election", "url": "/cours/posts/algorep_leader/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-06 09:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursLeader Election in a Synchronous RingProblem statement The netwok digraph is a ring with $n$ nodes All processes are identical Each process can only communicate with clockwise neighbors and counterclockwise neighbors One process outputs â€œIâ€™m the leaderâ€ while the other process output â€œIâ€™m note the leaderâ€Si tu prend 2 robots identiques, ils divergent lors de la connexion au reseauImpossibility Result for Identical Processes TheoremLet $S$ be a system of $n$ processes, $n \\gt 1$, arranged in a bidirectionnal ring. If all the processes are identical then $S$ does not solve the leader-election problem.Sketch of proof Suppose there is a system $S$ that solves this problem Without loss of generality, we can assume that each process of $S$ have a unique initial state. By induction on the number $r$ of rounds, all the processes are in identical states immediately after $r$ rounds. Then if a process reaches a state where it considers to be the leader, all the other processes do so. But this violates the uniqueness requirementProblem Statement $\\color{red}{Revisited}$ The network digraph is a ring with $n$ nodes All processes are identical $\\color{red}{\\text{except for a UID}}$ Each process can only communicate with clockwise neighbour and counterclockwise neighbourPropositions: Envoyer un message disant â€œJe suis peut-etre leaderâ€ Mais beaucoup de messages Anneau unidirectionnelLCR Algorithm Chaque processus envoie son UID Quand il recoit un UID, il le compare avec le sien Si lâ€™UID est plus grand, il lâ€™envoie a son voisin Sinon discard $n$ machines = $n$ roundsComplexity Meilleur cas: $O(n)$ messages Pire cas: $O(n^2)$ messages Quand un noeud est elu, $n$ rounds et $n$ messages sont necessairesHS Algorithm (comparison-based) Bidirectionnal Ring The size of the ring is unknown Comparison-based algo $\\color{red}{\\text{It elects the process with the maximum UID}}$Algorithm On a des phases de process $i$ Dans chaque phase $l$ Process $i$ send out tokens containings its $UID_i$ in both directions Tokens travel distance $2^l$ and return to their origin $i$ When a process $i$ receive a token $t$ containing $UID$ $t_{uid}$ if $t_{uid}$ $\\lt$ $UID_i$ then the token is discarded if $t_{uid}$ $\\gt$ $UID_i$ then the process $i$ relays the token if $t_{uid}$ $=$ $UID_i$ then the process is the leader If both tokens come back safely, process $i$ starts a new phase Otherwise the process considers itself as a non-leader Communication Complexity Phase 0: tout le monde envoie un message a gauche et a droite et recoit un message des 2 cotes On envoit 4 messages par noeud: $4\\times n$ messages Phase $l$: On a survecu a la phase $l-1$, il y a $2^{l-1}+1$ qui sont morts autour de moi, il y a $\\lfloor\\frac{n}{2^{l-1}+1}\\rfloor$ process qui envoient un messgae a cette phase. Le nombre de message est $4\\times 2^l \\lfloor\\frac{n}{2^{n-1}+1}\\rfloor\\le8n$ How many phases are executed before a leader is elected ?\\[1+\\lceil\\log n\\rceil\\] The number of messages is at most $8n(1 + \\lceil\\log n\\rceil)$Time Complexity The time complexity for phase $l$ is $2^{l+1}$ $\\color{red}{\\text{The complexity of all but the final phase is }2\\times2^{\\log n}}$ In the final phase takes $n$ since tokens only travels outbound The final complexity is at most $3n$ (if $n$ is power of $2$) $5n$ otherwise.Summary $O(n)$ $O(n\\log n)$TimeSlice AlgorithmLower Bounds Comparison-basedThe best case is $\\Omega(n \\log n)$ messages. Non-Comparison-based$O(n)$ messages can be reached but only at the cost of large time complexity (Ramsey Theorem).Leader Election in otherFlooding AlgorithmBreadth-First Search We want to build the directed spanning tree for the networkExample Children pointersLeader ElectionMinimum Spanning TreesComment est-ce quâ€™on construit un arbre courant en sequentiel ? â€œOn enfile des noeudsâ€ (mais câ€™est un BFS ca)Problem StatementHow to find the minimum/maximum spanning tree ? A minimum-weight spanning tree minimizes the total cost for any source process to communicate with all the other process in the network$\\color{red}{\\text{Let us assume that } n \\text{ is known}}$Est-ce quâ€™on a besoin dâ€™un leader ? Minorite de oui: on aurait besoin de quelquâ€™un qui synchro tou, mais câ€™est trop sequentielMajorite de non On peut synchroniser avec les process avec les rounds Imaginons que Mael est un process, quâ€™il a un lien avec Etienne et tout le mondeImaginons quâ€™on peut ponderer les liens (Etienne$\\leftrightarrow$Mael $=$ fibre, les autres wifi)Imaginons que quelquâ€™un a une connexion encore plus rapide avec MaelComment est-ce quâ€™on se met dâ€™accord ?$1^{ere}$ suggestion: tableau de booleens pour savoir qui se co a qui $\\Rightarrow$ Mais qui stock le tableau ?$2^{eme}$ suggestion: tout le monde a le tableau de boolens $\\Rightarrow$ infernal de synchro tout le monde Reprenons naivement:2 process sâ€™envoient des messages mutuellement, le composant est creeMaintenant il faut elire un chefSi tous les process sont synchro par 2, maintenant on peut synchroniser 2 pairesOn continue jusquâ€™a synchro tous les composants Avec cette strategie, on aura un temps de propagation plus long pour un message (2 messages au lieu de 1)2 interets: Le BFS est complique a faire, on lancais $n$ BFS Beaucoup de messages sequentiels en parallele Maximiser le fait quâ€™on soit en distribueQuâ€™est-ce quâ€™on va faire apparaitre avec cette methode ? Du $\\log$ car on divise par 2 a chaque foisComment faire pour savoir les liens dâ€™un composant avec le reste du monde ? Quand on creer une paire, les process peuvent echanger leurs listes de voisinsOn peut faire une phase de flooding dans le composantComment ca genere un arbre courant ? 2 process creent un arbre courant entre euxOn rajoute une paire, on a un arbre courant a 4etc.Ou est-ce que lâ€™arbre courant va etre stocke ? Chacun va avoir une vision localeSi jamais un composant a 2 voisins avec le meme degre minimal, comment faire ? Si ce composant ne repond pas a un des 2 voisins dans le temps imparti, câ€™est quâ€™il sâ€™est mis avec lâ€™autre Avec cette methode, on perd les performance de notre systeme On a un composant qui peut faire des aggregations simultanees pour avoir des performances resonnablesComplexity Time: $O(n\\log n)$ Communication: $O((n+\\vert E\\vert)\\times\\log(n))$ $O(n)$ messages sent per level Remarks Non-unique edge weightWe can define a lexicographic order using UID of processes Leader electionWhen building the MST a leader is elected naturally !" }, { "title": "ALGOREP: Introduction", "url": "/cours/posts/algorep_intro/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-03 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursIntroduction to Distributed AlgorithmsSupposons quâ€™on soit tous des machines, avec CPU, GPU, etc.On interroge quelquâ€™un qui repond vite, et un autre qui repond lentement. Si on a pas de reponse, on envoie une 2e message.Comment tu determines la difference entre un etudiant mort et un etudiant lent ?En tant que machine on ne sait pas.Forewords A distributed system is a collection of independant computers that appears to its users as a single coherent systemAndrew S. Tanenbaum A distributed system is one in which the failure of a computer you didnâ€™t even know can rend you computer unusableLeslie LamportMais pourquoi ?Lâ€™utilite: La securite La stabilite Un ordi qui crash $\\neq$ tout qui casse Probleme de matos Google ne peut pas tout stoquer sur un ordi Si une machine apprend quelque chose, on peut la transmettre Si le prof meurt mais nous a transmis ses infos, on peut continuer son cours Câ€™est la replicationWhat is a distributed system ? DefinitionA distributed system is: A collection of autonomous computer connected through a network which enables computers to coordinate their activities so that users perceive the system as a single one Exemple Grid/Cluster computing World Wide Web Network File Server Banking Network Bosser la-dedans pour se faire de la moula Peer-to-peer Network Process Control System Sensors NetworkParallel versus Distributed ?ParallelDistributedPitfalls in Distributed Systems ! The network is reliable The network is secure The network is homogeneous The topology does not change Latency is zero Bandwith is infinite Transport cost is zero There is one administrator pas dâ€™administrateur tout-puissant Challenges distributed systems ? Scalability Avoid Bottlenecks, Good Performances, Physical Ressources Heterogeneity Network, hardware, OS, programming language, implem Concurrency Managing shared ressources Failures Detect, masking, tolerating, recovery, redundancy Communications Synchronous, asynchronous In this class Systeme distrib point de vue theorique et pratique Concepts generaux Passer de programmes complexes a une abstraction algorithmes analyse de complexite presenter les resultats dâ€™impossibilite Practical through a project Un bon gros projet sa mere Groupe de 4 Specs faibles pour appliquer le cours Model Assumptions Modeles IPCs Notion de temps On a pas tous la meme frequence/horloge Modele synchrone Modele asychrone c dur resume a un modele partiellement synchrone Model partiellement synchroneAbstractionsComment avoir une vue dâ€™ensemble ? Il faut monter en abstractionForewords Success really depends on the conception of problems, the design of the system, not on the details of how itâ€™s coatedLeslie LamportMaximal AbstractionOn va se donner un graphe noeud: unite de calcul lien: topologieProcesses (informally) Local event: je calcule fibonnacci Send message: jâ€™ai fini de calculer fibonnacci Receive message: mon voisin a fini de calculer fiboVarious Timing models Synchronising processes is one of the most difficult part of distributed systemAsynchronous model No timing assumption about processes and channels, i.e. no physical assumptions about delays. Each process have local view of time called logical time Any time an event occurs (local or global) at process p, its logical clock is updated: local event increase logical time by one unit global event requires more complex strategies (details in a later lecture). Synchronous modelIl y a un tick La tout le monde est vivant La tout le monde est mortAu moment du tick: evenements locaux envois de messages recevoir des messagesEst-ce que câ€™est realiste ? Dâ€™apres la majorite de la classe, non On est capable de simuler ce tickComplexity in Synchronous ModelQuâ€™est-ce qui nous ralentit ? On peut avoir un algo en tete qui marche hyper bien mais une fois implemente pas du tout, juste a cause de lâ€™envoie de messages DefinitionUn tick sâ€™appelle un round (espace entre 2 pointilles rouges) Pour determiner le tick: Utiliser lâ€™horloge interne Avoir le meme temps envoye aux machines2 measures of complexity are considered for synchronous distributed algorithms Time Complexity: measured in term of number of rounds until all the required outputs are produced. Communicatin Complexity: measured in term of non-null messages that are sent. (We may also sometime consider the number of bits in these messages).Partially Synchronous modelQuand on effectue une tache, on sait par avance le temps quâ€™elle prend. Ca nous permet de faire de la detection de fautes (programme qui a crash, etc.)Process Failures Model Process Failures: Until it fails, a process is supposed to execute the algorithm assigned to it On a une hierarchie de problemes. Quand on parle de tolerance aux fautes, on dit quâ€™on est tolerable jusquâ€™a $n$ fautes. Arbitrary fault (Byzantines) Je peux supporter nâ€™importe quel type de faute, meme les actes de malveillance Omissions On ne va pas recevoir un message Câ€™est un black-out Revenir peut etre dur Lies A process that does not send expected responses Often due to malicious behavior Crashes RecoveryLink failure Crash, Loss, Duplicate can be addressed by some lower level protocol, for instance TCP As long as the network remains connected, link crashes may be masked by routing Link Crashes reveal a lot of impossibility results (see later lectures)Link Abstraction Fair-loss Links Stubborn links Perfect links Le monde ideal Combining AbstractionsClassical combinations Fail Stop Fail Noisy Fail RecoveryAbstracting PropertiesBasic properties of Distributed Systems Safety states that the algorithm should not do anything wrong Liveness On sait quâ€™on va finir par obtenir une certaine ressource states that eventually something good happens Conclusion Lâ€™unique facon de faire des systemes distribues est dâ€™utiliser des abstractions" }, { "title": "CMKV: Introduction", "url": "/cours/posts/cmkv_intro/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-02 14:00:00 +0200", "snippet": "Lien de la note Hackmd DefinitionStatistiques: comptage et representation de donnees DefinitionProbabilite: phenomene dont on extrait un modeleOptimisation combinatoireOn a une grille, on veut la remplir pour que ca devienne un echequier via un algorithme Est-ce que notre algo est deterministe ?Oui, car on a toujours le meme resultat avec la meme entree.Si la couleur dâ€™une case est aleatoire, lâ€™algo nâ€™est plus deterministe. DefinitionUn algo est stochastique si a lâ€™interieur il y a de lâ€™aleatoire # algorand()#algo Lâ€™aleatoire provient de lâ€™entreeIl existe des programmes stochastisques et deterministes.rand() est-il deterministe ? Oui. Câ€™est dingue, hein ?\\[\\Omega=\\{A,B,C,D\\}\\\\\\begin{cases}P(A)\\in[0,1], \\text{idem pour } B,C\\text{ et } D\\\\P(A)+P(B)+P(C)+P(D) = 1\\end{cases}\\]ExempleNous sommes une population, on mesure la probabilite dâ€™avoir 20 ans.\\[\\underbrace{P(20)}_{P(A)}=0.36\\]Maintenant avec la meteo:\\[\\Omega=\\{\\text{beau},\\text{pluie},\\text{couvert}\\}\\\\\\begin{cases}P(\\text{beau}) = 0.51\\\\P(\\text{pluie}) = 0.01\\\\P(\\text{couvert}) = 1 - 0.21 - 0.01\\end{cases}\\]Faire action avec la proba $P$\\[P(\\varnothing)=P(1)=P(2)=...=\\frac{1}{\\text{RANDMAX}}\\]Retour sur la meteo:\\[\\begin{cases}P(\\text{beau}) = 0.3\\\\P(\\text{pluie}) = 0.5\\\\P(\\text{couvert}) = 0.2\\end{cases}\\] Le probleme: certaines variables aleatoires ne sont pas independante (salaire, categorie pro, etc.)SUDOKUOn doit ecrire un programme qui resout le sudoku Â  1 Â  Â  Â  Â  2 Â  Â  Â  3 Â  2 Â  Â  $\\square$ On a \\(4^{12}=16,7M\\) de valeur possibles.On va bruteforce, cad visiter plein de chemins possibles pour remplir. Les $16$ millions de possibilites de remplissage vont baisser mais vont rester elevees. La resolution prend du temps :(Mais, au lieu de faire un algo bete, on fait quoi ? On rentre dans un probleme dâ€™optimisation combinatoire. On enumerait les nombres de remplissage possibleMais pourquoi un probleme dâ€™optimisation ?On obtient un espace a 12 axes, la solution est quelque part dans lâ€™espace On cherche le minimum ou le maximum de la fonction \\(x_{\\text{sol}}=\\text{arg min}_xf(x)\\)Ah et evidemment pas moyen que ce soit une fonction convexe.Pour les gens du fond:Resolution de Sudoku . . . . . 2 3 . 1 . . . . . . 4 \\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\frac{1}{4^{12}}\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\frac{1}{4^{12}}\\] Quand on ne sait pas, on fait de lâ€™equiprobableMais on sait, câ€™est un sudoku:\\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 1\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\varnothing\\]\\[P(x_{\\text{sol}})=1\\\\\\forall x\\neq x_{\\text{sol}}, P(x)=0\\] On peut pas juste ecrire notre solution comme caâ€¦ â€œCertaines solutions sont plus vraies que dâ€™autresâ€Le camarade qui a dit un truc important Par â€œvraiâ€, on veut dire proche de la solution $\\equiv$ peu dâ€™erreur\\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 0.00001\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 0.0\\dots 01\\] La prob est plus elevees que le resteLa meteo de Gulli\\(\\begin{matrix}P(A&amp;amp;\\cap&amp;amp;B)\\\\\\text{beau} &amp;amp;&amp;amp;\\text{Londres}\\\\\\text{temps} = \\{\\text{pourri, ...}\\} &amp;amp;&amp;amp;\\text{lieu} = \\{\\text{Londres, Paris, ...}\\}\\end{matrix}\\) $T$ VA pour rpz le temps $P(T=\\text{beau})=0.6$, $P(T=\\text{pourri})=0.1$, â€¦\\[\\color{red}{\\boxed{P(T=t)}}\\] $V$ vecteur aleatoire, \\(V=(V_1,...,V_n)\\), \\(V_i\\) var aleatoire\\[P(T=t\\color{red}{\\underbrace{,}_{\\text{et}}}L=l)\\color{green}{\\equiv f(t,l)\\in]\\varnothing,1]}\\begin{cases}t\\in\\{\\text{beau, pourri,}\\dots\\}\\\\l\\in\\{\\text{Londres, Paris,}\\dots\\}\\end{cases}\\]\\[P(A\\cap B)=P(A)+P(B)-P(A\\cup B)\\\\\\bar A+\\cap + \\cap + \\bar B-\\bar A-\\cap -\\bar B\\]Exemple$W$ weather, $L$ location, $N$ thune de Xavier NIEL.$P(W=w,L=l)\\equiv$ proba quâ€™il fasse \\(\\color{red}{\\underbrace{\\boxed{\\text{w a l}}}_{\\text{beau a Londres}}}\\)\\[\\begin{aligned}P(A\\cap B)&amp;amp;=P(A\\vert B).P(B) \\\\= P(B\\cap A) &amp;amp;= P(B\\vert A).P(A)\\\\&amp;amp;\\Rightarrow P(A\\vert B)=\\frac{P(A\\cap B)}{P(B)}\\end{aligned}\\]\\[\\begin{aligned}x_{\\text{sol}}=\\text{arg max}_x P(X=x&amp;amp;\\vert Y=y)\\\\&amp;amp;\\downarrow\\end{aligned}\\\\\\frac{\\overbrace{P(Y=y\\vert X=x)}^{\\color{blue}{f(x,y)}}.P(X=x)}{\\underbrace{P(Y=y)}_{\\color{red}{\\text{terme constant}}}}\\\\\\underbrace{L(X=x\\vert Y=y)}_{\\color{green}{\\text{VRAISEMBLANCE}}}.\\underbrace{P(X=x)}_{\\color{green}{\\text{A PRIORI}}})\\]Retour au SUDOKU\\[y=\\begin{matrix}\\begin{vmatrix}y_1 &amp;amp;\\\\&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix} &amp;amp;\\\\2&amp;amp;x_p\\end{vmatrix}\\\\\\begin{vmatrix}3 &amp;amp;\\\\&amp;amp;\\end{vmatrix}&amp;amp;\\begin{vmatrix} &amp;amp;\\\\&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}\\\\y=(0,0,0,0,0,\\color{red}{1},\\color{green}{2},0,\\color{blue}{3},0,0,0,0,0,0,\\color{orange}{4})\\\\y=(y_1,...,y_{15})\\\\y_6=1\\\\x=(x_1,x_2,x_3,x_4,x_6,\\color{red}{0},\\color{green}{0},x_p,\\color{blue}{0},\\dots)\\\\x&#39;=(1,1,1,1,1,\\color{red}{0},\\color{green}{0},1,\\color{blue}{0},\\dots)\\]En solution:\\[\\color{green}{P(}x&#39;\\color{green}{)}= \\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;0\\end{vmatrix}&amp;amp;\\begin{vmatrix}1&amp;amp;1\\\\0&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}0&amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1&amp;amp;1\\\\0&amp;amp;1\\end{vmatrix}\\\\\\end{matrix}\\color{green}{=?}\\\\\\color{green}{P(}x&#39;&#39;\\color{green}{)}= \\begin{matrix}\\begin{vmatrix}1&amp;amp;2\\\\3&amp;amp;0\\end{vmatrix}&amp;amp;\\begin{vmatrix}3&amp;amp;4\\\\0&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}0&amp;amp;1\\\\4&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}4&amp;amp;3\\\\2&amp;amp;0\\end{vmatrix}\\\\\\end{matrix}\\color{green}{=?}\\\\\\]Recap\\[\\color{red}{P_{\\color{pink}{T}}(X=x)=\\frac{1}{Z}e^{\\frac{-U(x)}{\\color{pink}{T}}}\\quad(z=\\sum_xe^{-U(x)})}\\\\\\color{green}{P_{\\color{pink}{T}}(X=x_{\\text{sol}})\\gt P_{\\color{pink}{T}}(X=x)\\quad\\forall x\\neq x_{\\text{sol}}}\\\\\\color{blue}{P(X=x_{\\text{sol}}) = 0.000001\\quad\\text{ECHANTILLONEUR }\\bullet\\to x\\text{ suivant }P(x)}\\\\\\color{pink}{\\lim_{T\\to0^+}P_T=\\begin{cases}\\color{green}{P_{\\color{pink}{0}}(X=x_{\\text{sol}})=1}\\\\\\color{green}{P_{\\color{pink}{0}}(X=x_{\\text{sol}})=\\varnothing}&amp;amp;\\text{sinon}\\end{cases}}\\]" }, { "title": "Kickoff Image", "url": "/cours/posts/kickoff_image_S9/", "categories": "Image S9, Kickoff", "tags": "Image, S9", "date": "2021-09-02 10:00:00 +0200", "snippet": "Lien de la note HackmdIâ€™m a bee Iâ€™m a bee Iâ€™m a bee Iâ€™m a bee Iâ€™m a bee Iâ€™m a bee bee beeRetour sur le S8Câ€™etait long et eprouvantâ€¦ Mais au moins pas de rendu en Septembre, donc plein de rendu en Juin/Juillet.Les notes Toutes les notes ont ete rendues Quelques couac dans le traitement des notes (IML disparu, PRST que les SCIAs ont mais pas nous) Les mono-groupes Pourquoi faire seul un travail a 2 ? Beaucoup plus de temps a corriger pour le prof car plus de groupes Pas OK pour les intervenants exterieurs PLUS DE MONOMES Ne sous-estimez pas AlgoRep en termes de charge de travail Le S9 est plus interessant Beaucoup dâ€™intervenants exterieurs Point de vue industriel et applique Mais le semestre est celui ou on a le plus marre (recherche de stage, fatigueâ€¦) Il faut sâ€™accrocher (à¸‡â€™Ì€-â€˜Ì)à¸‡Presentation du S9 Le PFEE compte pour $2.5$ ECTS 1 ECTS = 30 heures de travail (cours inclu) Ca veut dire 75h de travail pour le PFEE (Presque) Tous les cours sont TP et TD dans les heures (pas que des cours magistraux)Champs de Markov Par Theo En commun avec les SCIAs On fini le cours tot mais le projet vient tard lâ€™an dernier: fini fin Septembre mais projet debut Janvier Notion de proba stats, dâ€™optimisation pour resoudre les problemes ProjetAlgo Rep Par Etienne Demande BEAUCOUP de travail perso Projet mastoc 80h de travail par groupe Le genre de projet infinissable (RIP) Projet qui ne se rush pas on peut utiliser la semaine entreprise pour bien avancer le projet Un peu hors du scope de la majeureIMCO Par Ricardo, intervenant exterieur de DXO Normalement cours du S8 mais Ricardo ne pouvait pas Besoin de matos pour les TPs Presentiel OBLIGATOIRE TP note Ces 3 cours finissent en SeptembreVirtualite Virtuelle et Augmentee Ingenieur de EDF Commence plus tot que prevu (conge partenite de lâ€™intervenant) QUE 7 casques (il faut reserver) NE SURTOUT PAS RESERVER UN CASQUE 48H AVANT LA DEADLINE Projet fun, câ€™est LE projet pour craquer son slipRendu Physique Realiste Sera peut-etre fusionne avec POGL2 Nouveau cours yay! Avec WebGLOCVX2 Guillaume et Bashard Complement dâ€™OCVX1 Optimisation avec contrainte Prob partielProbabilites et Statitisques Avancees Avec Noe PRST2 PartielAnimation 3D Cours et TP Super intervenant exterieur Fin des cours de Septembre ! On passe a OctobreTraitement video Comment le son est traite dans les videos Les 2021 avaient regrettes que les cours ne traitent pas le son La surprise de YvesImagerie Medicale 2 3 intervenants exterieurs Cours en 3 partiesImagerie Satellitaire On sait pas sâ€™il aura lieu Et sâ€™il a lieu, quand il aura lieu Par le directeur de These de Guillaume (wow !) Fin des cours dâ€™Octobre ! Câ€™est lâ€™heure de la semaine bullshit entreprise On passe a NovembreVision par ordinateur Intervenant exterieur OpenCV Ils envoient des robots sur Mars :0Deep Learning pour lâ€™image Joseph - Nicolas - Oliver Rajoute une seance par rapport a lâ€™an dernier Veulent rajouter les GANs cette annee TRES dur dâ€™avoir des cours a jour Les reseaux evoluent vite Câ€™est pas top de donner un cours sur un truc quâ€™on a jamais manipule (temps de formation) Et des fois câ€™est bien de revenir aux reseaux de base :)Traitement Numerique du Signal TERASSE Guillaume de chez EDF PartielAnalyse Temps-Frequence Par Nicolas Domaine du traitement du signal au sens large Pas oublier quâ€™une image câ€™est un signal POGL2 Par Jonathan Pas que OpenGL avance TP sur Blender Cours probable: Mobilisation 3DCelui-la est VRAIMENT pas surPour la fin du semestre Janvier: câ€™est une blague Les partiels peuvent etre avant certains cours Sur le S9 câ€™est complique dâ€™avoir les deadlines autant espacees que le S8Le mois de Janvier sera surtout TPs On essaie de finir tous les cours en DecembrePour les assistants Moins de cours pendant la piscine Mais des cours quand meme G&amp;amp;E ont ete prevenus de pas mettre de cours pendant la piscineâ€¦ jeudi dernier Pas de TPs notes Les cours ne sont pas deplacables Cours communs Image/SCIA Intervenants exterieurs bookes des mois a lâ€™avance Cours enregistres â€œDispensesâ€ de cours On va essayer alterner Image/SRS Peut-etre le mardiâ€¦ au pifâ€¦ parce que câ€™est du tronc commun La seule solution ca serait dâ€™avoir cours le soir et le week-endâ€¦ Et câ€™est non.Commodal/PresentielPas encore fixes Directive de lâ€™ecole: 100% presentiel G&amp;amp;E sont pas giga dâ€™accord Encore un peu tot Anticiper un durcissement des regles Si pb (confinement), avec comodal pas de panique MAIS G&amp;amp;E aimeraient quâ€™on viennent presentiel le plus possible Pas normal de decouvrir de nouveaux noms/visages maintenant Mais G&amp;amp;E comprennent quâ€™il y a certaines contraintes et que certains preferent le comodal Ex: avoir cours a 9h et avoir 1h30 de transport On veut eviter de ravoir 4 eleves avec un intervenant exterieur Le presentiel pourra etre obligatoire On track les absences injustifiees 3/4 jokers Apres ca impact sur la note finale On veut au moins la moitie de la classe en presentielSi cas contact/contaminesSi on est positifs (vaccines ou pas), on reste chez soit.Les stagesQue 5 eleves pour la meilleure soutenance de stage :( On devrait rendre nos slides de soutenance de stage Pour eviter les catastrophes (cf. cette soutenance) Avoir une idee de ce quâ€™on presente Ca sera pour les 2023 pour assister a nos soutenances G&amp;amp;E valident les sujets de stage Ils sont en droit de ne pas valider Le stage doit etre en lien avec la majeureEn dessus de 12, on ne valides pas la soutenance Plus de soutenances confidentiellesRapports de stageSIEMENS a des droits dâ€™auteur sur le rapport de stage Sâ€™y prendre a lâ€™avance pour la soutenance Se renseigner sur le rapport de stage dans une entrepriseLe rapport de stage nâ€™est pas une doc de ce qui a ete faitTrouver un stageLes stages se decantent vers Octobre-Novembre Pas de panique ! Yâ€™a le temps Les entreprises font leurs budget vers Octobre-Novembre Les offres de stage vont commencer a arriverSalaireEntre 1000 et 1200 câ€™est bien, 600 câ€™est le minimum" }, { "title": "DBRE: Masterclass V2", "url": "/cours/posts/dbre_masterclass_v2/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-06-27 20:00:00 +0200", "snippet": "Introduction Le coeur de la protection dâ€™un logiciel se fait via les droits dâ€™auteurs. On nâ€™a aucune solution dont on puisse etre sur a 100%.La solution la plus probable est celle retenue par les juges. Câ€™est pas bon pour la securite juridique mais on ne peut pas faire autrementPropriete intellectuellesPour quâ€™une invention soit brevetable, il faut que lâ€™inventeur ait une activitee inventive, cad trouver une solution pas evidente pour â€œlâ€™homme du metierâ€. Lâ€™inventivite et lâ€™evidence sont subjectifs.On doit aussi avoir un peu de personnalite de lâ€™auteur, que lâ€™oeuvre soit originale $\\rightarrow$ subjectifFair use Le â€œfair useâ€ nâ€™a pas dâ€™equivalents en droit francais.Une autre difficulte vient de la recherche constante du compromis entre â€œaccordons suffisemment de droits pour que les gens creentâ€ mais â€œpas trop pour pas bloquerâ€.Exceptions Dans les proprietes intellectuelles, il y a des tonnes dâ€™exceptions.Le but est de contrebalancer un monopole necessaire pour retablir un equilibre, mais cela cause des incertetitudes juridiques.Exemple Apres le premier sequencage du genome humain, le president des US a precise quâ€™il nâ€™etait pas brevetable car ce sont des genes (de meme avec le genome du COVID-19)Il est tout a fait possible de depose un vaccin libre de droits (mais cela ne se fait pas car pas viable economiquement)Certaines personnes ne deposent pas de brevets car lâ€™invention peuvent vite devenir obsolete ou pour mettre lâ€™invention a disposition de la communaute.Monsanto nâ€™a pas brevete du mais, mais une facon de le cultiverDiffusion dâ€™une oeuvre Selon de la ou une oeuvre est diffusee, ce ne sont pas les memes droits qui sâ€™appliquent $\\rightarrow$ cela ne depend pas de la nationalite de lâ€™auteur.De meme pour le droit du travail.Exemple Nous utilisons teams conformement aux droits dâ€™auteur francais. Si on vend des chaussures sur Internet, quâ€™on sâ€™addresse au public dâ€™un pays, quâ€™on livre la-bas, etc. on est soumis au droit de consommation du pays en questionRecapLe monopole est confere pour favoriser la creation/innovation mais comporte un certain nombre dâ€™exceptions pour ne pas avoir de blocage du marche.Le droit international prevoit une harmonisation pour quâ€™une oeuvre soit utilisee dans plusieurs pays, lâ€™oeuvre depend des regulations de chacune des pays.La condition de protection La condition de protection est etudiee uniquement lorsquâ€™on veut faire valoir ses droits. Pourquoi me reprocher dâ€™avoir copie quelquechose qui nâ€™est pas protege ? Code de la propriete intellectuelle: une oeuvre est protegee si elle est originale. Mais ce nâ€™est pas la seule condition de protection dâ€™une oeuvre ! Est-ce que mon oeuvre est elligible au droit dâ€™auteur ? Quâ€™est-ce qui, dans mon oeuvre, est considere comme protegeable? Ce ne sont pas les mots prits un a un Parmi la liste des oeuvres elligibles, je regardes quels elements sont originaux.$\\Rightarrow$ ce sont les etapes suivies par un juge lors dâ€™un proces en contrefacon. Volet penal: passible dâ€™une peine jusquâ€™a 3 ans de prison Volet civile: demander des dedomagemments ont considÃ©rÃ©s notamment comme oeuvres de lâ€™esprit au sens du prÃ©sent code : 1Â° Les livres, brochures et autres Ã©crits littÃ©raires, artistiques et scientifiques ; 2Â° Les confÃ©rences, allocutions, sermons, plaidoiries et autres oeuvres de mÃªme nature ; 3Â° Les oeuvres dramatiques ou dramatico-musicales ; 4Â° Les oeuvres chorÃ©graphiques, les numÃ©ros et tours de cirque, les pantomimes, dont la mise en oeuvre est fixÃ©e par Ã©crit ou autrement ; 5Â° Les compositions musicales avec ou sans paroles ; 6Â° Les oeuvres cinÃ©matographiques et autres oeuvres consistant dans des sÃ©quences animÃ©es dâ€™images, sonorisÃ©es ou non, dÃ©nommÃ©es ensemble oeuvres audiovisuelles ; 7Â° Les oeuvres de dessin, de peinture, dâ€™architecture, de sculpture, de gravure, de lithographie ; 8Â° Les oeuvres graphiques et typographiques ; 9Â° Les oeuvres photographiques et celles rÃ©alisÃ©es Ã  lâ€™aide de techniques analogues Ã  la photographie ; 10Â° Les oeuvres des arts appliquÃ©s ; 11Â° Les illustrations, les cartes gÃ©ographiques ; 12Â° Les plans, croquis et ouvrages plastiques relatifs Ã  la gÃ©ographie, Ã  la topographie, Ã  lâ€™architecture et aux sciences ; 13Â° Les logiciels, y compris le matÃ©riel de conception prÃ©paratoire ; 14Â° Les crÃ©ations des industries saisonniÃ¨res de lâ€™habillement et de la parure. Sont rÃ©putÃ©es industries saisonniÃ¨res de lâ€™habillement et de la parure les industries qui, en raison des exigences de la mode, renouvellent frÃ©quemment la forme de leurs produits, et notamment la couture, la fourrure, la lingerie, la broderie, la mode, la chaussure, la ganterie, la maroquinerie, la fabrique de tissus de haute nouveautÃ© ou spÃ©ciaux Ã  la haute couture, les productions des paruriers et des bottiers et les fabriques de tissus dâ€™ameublement. Article L112-2 Il nâ€™y a pas de site web, jeux videos, etc. mais dâ€™apres la jurisprudence ils en font partie. La jurisprudence a exclu a plusieurs reprises des textes sans originalite (definitions, lettre de lâ€™alphabet, etc.).Lâ€™originalite quâ€™est-ce que câ€™est ? Câ€™est lâ€™empreinte de la personnalite de lâ€™auteur. Ex: un style (en peinture, litterature, etc.).La titularite2 Hypotheses: Un oeuvre a un auteur unique La pluralite dâ€™auteurs Article L111-1ModifiÃ© par LOI nÂ°2020-1674 du 24 dÃ©cembre 2020 - art. 35 (V) Lâ€™auteur dâ€™une oeuvre de lâ€™esprit jouit sur cette oeuvre, du seul fait de sa crÃ©ation, dâ€™un droit de propriÃ©tÃ© incorporelle exclusif et opposable Ã  tous. Ce droit comporte des attributs dâ€™ordre intellectuel et moral ainsi que des attributs dâ€™ordre patrimonial, qui sont dÃ©terminÃ©s par les livres Ier et III du prÃ©sent code. Lâ€™existence ou la conclusion dâ€™un contrat de louage dâ€™ouvrage ou de service par lâ€™auteur dâ€™une oeuvre de lâ€™esprit nâ€™emporte pas dÃ©rogation Ã  la jouissance du droit reconnu par le premier alinÃ©a, sous rÃ©serve des exceptions prÃ©vues par le prÃ©sent code. Sous les mÃªmes rÃ©serves, il nâ€™est pas non plus dÃ©rogÃ© Ã  la jouissance de ce mÃªme droit lorsque lâ€™auteur de lâ€™oeuvre de lâ€™esprit est un agent de lâ€™Etat, dâ€™une collectivitÃ© territoriale, dâ€™un Ã©tablissement public Ã  caractÃ¨re administratif, dâ€™une autoritÃ© administrative indÃ©pendante dotÃ©e de la personnalitÃ© morale, de la Banque de France, de lâ€™Institut de France, de lâ€™AcadÃ©mie franÃ§aise, de lâ€™AcadÃ©mie des inscriptions et belles-lettres, de lâ€™AcadÃ©mie des sciences, de lâ€™AcadÃ©mie des beaux-arts ou de lâ€™AcadÃ©mie des sciences morales et politique. Les dispositions des articles L. 121-7-1 et L. 131-3-1 Ã  L. 131-3-3 ne sâ€™appliquent pas aux agents auteurs dâ€™oeuvres dont la divulgation nâ€™est soumise, en vertu de leur statut ou des rÃ¨gles qui rÃ©gissent leurs fonctions, Ã  aucun contrÃ´le prÃ©alable de lâ€™autoritÃ© hiÃ©rarchique. Article L111-1 Lâ€™existence ou la conclusion dâ€™un contrat de louage dâ€™ouvrage ou de service par lâ€™auteur dâ€™une oeuvre de lâ€™esprit nâ€™emporte pas dÃ©rogation Ã  la jouissance du droit reconnu par le premier alinÃ©a, sous rÃ©serve des exceptions prÃ©vues par le prÃ©sent code.Il faut imperativement avoir un contrat de cession de droits si on sous-traite la creation dâ€™une oeuvre. (ex: creation dâ€™un jeu video) Le simple fait de commander une oeuvre ne veut pas dire quâ€™on est investi des droits sur lâ€™oeuvre, il faut un transfere de titularite.Il y a une exception: Les droits des salaries appartiennent aux salaries.Ce nâ€™est pas parce quâ€™un salarie est paye pour creer quelque chose que lâ€™oeuvre appartient a lâ€™employeur, il faut une passation de droits.Et si on fait un projet a Epita, a qui appartient les droits ? Lâ€™oeuvre nous appartient car nous nâ€™avons jamais signe de passation de droits MAIS il nous appartient sous reserve quâ€™on lâ€™ai fait entierement seul (cad pas de sujet, encadrement, etc.). Article L131-1CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La cession globale des oeuvres futures est nulle.Pluralite dâ€™auteursCas de la pluralite dâ€™auteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelquâ€™un dâ€™autre, on peut remunerer lâ€™auteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de lâ€™auteur original est proportionnelle aux recettes.Si on utilise lâ€™image de quelquâ€™un dans un manuel de 1000 pages, il est plus rentable de sâ€™acquitter dâ€™un forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation dâ€™une oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de lâ€™oeuvre et qui vont se concerter entre elles. Ex: le developpement dâ€™un logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il nâ€™y a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent lâ€™oeuvre en ayant passe un contrat entre eux Chacun cede ses droits a lâ€™un dâ€™entre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a lâ€™initative dâ€™une personne (physique ou morale).Cette personne est invastie des droits dâ€™auteurs, et va sous son nom: Lâ€™editer La publier La divulguer Ce qui distingue lâ€™oeuvre collective et la collaboration, câ€™est les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise nâ€™arrive pas a prouver les conditions pratiques de la realisation dâ€™un projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue dâ€™un jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention dâ€™un tiers pour harmoniser les apports communs).Duree des droits dâ€™auteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits dâ€™auteurs) aussi lorsque lâ€™auteur meurt jeune Disney: utilisent des â€œrusesâ€ Peut egalement etre raccourcie Si chanson dâ€™un artiste-interprete, retombera plus vite dans le domaine publique Droits dâ€™une oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire quâ€™une oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui nâ€™utiliserai pas son droit moral ne lâ€™a pas perdu et peut le faire valoir a tout moment. Lâ€™auteur ne peut pas ceder de facon generale son droit dâ€™auteur car contraire a un principe dâ€™ordre publique. Attendu que lâ€™inaliÃ©nabilitÃ© du droit au respect de lâ€™oeuvre, principe dâ€™ordre public, sâ€™oppose Ã  ce que lâ€™auteur abandonne au cessionnaire, de faÃ§on prÃ©alable et gÃ©nÃ©rale, lâ€™apprÃ©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait Ã  ce dernier de procÃ©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas dâ€™adaptation, de changement de support ou de genre quâ€™il y a le plus de probleme avec le droit au respect.Representation et reproduction Ce que lâ€™on dit aujourdâ€™hui peut varier dâ€™ici un an ou 2En entreprise, quâ€™on soit auteur, salarie, manageur, etc. il faudra faire attention a la problematique de la titularite des droits.Avec les droits moraux, il y a les droits patrimoniaux. Article L122-1CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 Le droit dâ€™exploitation appartenant Ã  lâ€™auteur comprend le droit de reprÃ©sentation et le droit de reproduction. On distingue les droits pendant sur lâ€™ensemble des oeuvres et ceux lies specifiquement au logiciel (L 122-6 et L122-6-1 du CPI) Article L122-4CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 Toute reprÃ©sentation ou reproduction intÃ©grale ou partielle faite sans le consentement de lâ€™auteur ou de ses ayants droit ou ayants cause est illicite. Il en est de mÃªme pour la traduction, lâ€™adaptation ou la transformation, lâ€™arrangement ou la reproduction par un art ou un procÃ©dÃ© quelconque. Article L122-2CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La reprÃ©sentation consiste dans la communication de lâ€™oeuvre au public par un procÃ©dÃ© quelconque, et notamment: Par rÃ©citation publique, exÃ©cution lyrique, reprÃ©sentation dramatique, prÃ©sentation publique, projection publique et transmission dans un lieu public de lâ€™oeuvre tÃ©lÃ©diffusÃ©e ; Par tÃ©lÃ©diffusion. La tÃ©lÃ©diffusion sâ€™entend de la diffusion par tout procÃ©dÃ© de tÃ©lÃ©communication de sons, dâ€™images, de documents, de donnÃ©es et de messages de toute nature. Est assimilÃ©e Ã  une reprÃ©sentation lâ€™Ã©mission dâ€™une oeuvre vers un satellite.Remarques La reprÃ©sentation consiste dans la communication de lâ€™oeuvre au public par un procÃ©dÃ© quelconque, et notamment dâ€™autres procÃ©dÃ©s qui nâ€™existaient pas lors de la rÃ©daction de cette article On considere quâ€™a chaque fois quâ€™on a touche un public, on represente lâ€™oeuvre Ex: un concert tele-diffuse (la salle de concert + telespectateurs) Si tele-diffuse dans un bar, les clients du bar sont un public Si jâ€™utilise quelque chose qui va me rapporter quelque chose (utiliser lâ€™oeuvre dâ€™un autre), on doit partager avec lâ€™auteurExemple: Diffuser la tele dans un bar Augmenter le chiffre dâ€™affaire Soumis sous autorisation et remuneration Exception (L122-5) Article L122-5ModifiÃ© par LOI nÂ°2018-771 du 5 septembre 2018 - art. 81 Lorsque lâ€™oeuvre a Ã©tÃ© divulguÃ©e, lâ€™auteur ne peut interdire : 1Â° Les reprÃ©sentations privÃ©es et gratuites effectuÃ©es exclusivement dans un cercle de famille ; 2Â° Les copies ou reproductions rÃ©alisÃ©es Ã  partir dâ€™une source licite et strictement rÃ©servÃ©es Ã  lâ€™usage privÃ© du copiste et non destinÃ©es Ã  une utilisation collective, Ã  lâ€™exception des copies des oeuvres dâ€™art destinÃ©es Ã  Ãªtre utilisÃ©es pour des fins identiques Ã  celles pour lesquelles lâ€™oeuvre originale a Ã©tÃ© crÃ©Ã©e et des copies dâ€™un logiciel autres que la copie de sauvegarde Ã©tablie dans les conditions prÃ©vues au II de lâ€™article L. 122-6-1 ainsi que des copies ou des reproductions dâ€™une base de donnÃ©es Ã©lectronique ; 3Â° Sous rÃ©serve que soient indiquÃ©s clairement le nom de lâ€™auteur et la source : a) Les analyses et courtes citations justifiÃ©es par le caractÃ¨re critique, polÃ©mique, pÃ©dagogique, scientifique ou dâ€™information de lâ€™oeuvre Ã  laquelle elles sont incorporÃ©es ; b) Les revues de presse ; c) La diffusion, mÃªme intÃ©grale, par la voie de presse ou de tÃ©lÃ©diffusion, Ã  titre dâ€™information dâ€™actualitÃ©, des discours destinÃ©s au public prononcÃ©s dans les assemblÃ©es politiques, administratives, judiciaires ou acadÃ©miques, ainsi que dans les rÃ©unions publiques dâ€™ordre politique et les cÃ©rÃ©monies officielles ; d) Les reproductions, intÃ©grales ou partielles dâ€™oeuvres dâ€™art graphiques ou plastiques destinÃ©es Ã  figurer dans le catalogue dâ€™une vente judiciaire effectuÃ©e en France pour les exemplaires mis Ã  la disposition du public avant la vente dans le seul but de dÃ©crire les oeuvres dâ€™art mises en vente ; e) La reprÃ©sentation ou la reproduction dâ€™extraits dâ€™oeuvres, sous rÃ©serve des oeuvres conÃ§ues Ã  des fins pÃ©dagogiques et des partitions de musique, Ã  des fins exclusives dâ€™illustration dans le cadre de lâ€™enseignement et de la recherche, y compris pour lâ€™Ã©laboration et la diffusion de sujets dâ€™examens ou de concours organisÃ©s dans la prolongation des enseignements Ã  lâ€™exclusion de toute activitÃ© ludique ou rÃ©crÃ©ative, dÃ¨s lors que cette reprÃ©sentation ou cette reproduction est destinÃ©e, notamment au moyen dâ€™un espace numÃ©rique de travail, Ã  un public composÃ© majoritairement dâ€™Ã©lÃ¨ves, dâ€™Ã©tudiants, dâ€™enseignants ou de chercheurs directement concernÃ©s par lâ€™acte dâ€™enseignement, de formation ou lâ€™activitÃ© de recherche nÃ©cessitant cette reprÃ©sentation ou cette reproduction, quâ€™elle ne fait lâ€™objet dâ€™aucune publication ou diffusion Ã  un tiers au public ainsi constituÃ©, que lâ€™utilisation de cette reprÃ©sentation ou cette reproduction ne donne lieu Ã  aucune exploitation commerciale et quâ€™elle est compensÃ©e par une rÃ©munÃ©ration nÃ©gociÃ©e sur une base forfaitaire sans prÃ©judice de la cession du droit de reproduction par reprographie mentionnÃ©e Ã  lâ€™article L. 122-10 ; 4Â° La parodie, le pastiche et la caricature, compte tenu des lois du genre ; 5Â° Les actes nÃ©cessaires Ã  lâ€™accÃ¨s au contenu dâ€™une base de donnÃ©es Ã©lectronique pour les besoins et dans les limites de lâ€™utilisation prÃ©vue par contrat ; 6Â° La reproduction provisoire prÃ©sentant un caractÃ¨re transitoire ou accessoire, lorsquâ€™elle est une partie intÃ©grante et essentielle dâ€™un procÃ©dÃ© technique et quâ€™elle a pour unique objet de permettre lâ€™utilisation licite de lâ€™oeuvre ou sa transmission entre tiers par la voie dâ€™un rÃ©seau faisant appel Ã  un intermÃ©diaire ; toutefois, cette reproduction provisoire qui ne peut porter que sur des oeuvres autres que les logiciels et les bases de donnÃ©es ne doit pas avoir de valeur Ã©conomique propre ; 7Â° Dans les conditions prÃ©vues aux articles L. 122-5-1 et L. 122-5-2, la reproduction et la reprÃ©sentation par des personnes morales et par les Ã©tablissements ouverts au public, tels que les bibliothÃ¨ques, les archives, les centres de documentation et les espaces culturels multimÃ©dia, en vue dâ€™une consultation strictement personnelle de lâ€™Å“uvre par des personnes atteintes dâ€™une ou de plusieurs dÃ©ficiences des fonctions motrices, physiques, sensorielles, mentales, cognitives ou psychiques et empÃªchÃ©es, du fait de ces dÃ©ficiences, dâ€™accÃ©der Ã  lâ€™Å“uvre dans la forme sous laquelle lâ€™auteur la rend disponible au public ; Ces personnes empÃªchÃ©es peuvent Ã©galement, en vue dâ€™une consultation strictement personnelle de lâ€™Å“uvre, rÃ©aliser, par elles-mÃªmes ou par lâ€™intermÃ©diaire dâ€™une personne physique agissant en leur nom, des actes de reproduction et de reprÃ©sentation ; 8Â° La reproduction dâ€™une Å“uvre et sa reprÃ©sentation effectuÃ©es Ã  des fins de conservation ou destinÃ©es Ã  prÃ©server les conditions de sa consultation Ã  des fins de recherche ou dâ€™Ã©tudes privÃ©es par des particuliers, dans les locaux de lâ€™Ã©tablissement et sur des terminaux dÃ©diÃ©s par des bibliothÃ¨ques accessibles au public, par des musÃ©es ou par des services dâ€™archives, sous rÃ©serve que ceux-ci ne recherchent aucun avantage Ã©conomique ou commercial ; 9Â° La reproduction ou la reprÃ©sentation, intÃ©grale ou partielle, dâ€™une oeuvre dâ€™art graphique, plastique ou architecturale, par voie de presse Ã©crite, audiovisuelle ou en ligne, dans un but exclusif dâ€™information immÃ©diate et en relation directe avec cette derniÃ¨re, sous rÃ©serve dâ€™indiquer clairement le nom de lâ€™auteur. Le premier alinÃ©a du prÃ©sent 9Â° ne sâ€™applique pas aux oeuvres, notamment photographiques ou dâ€™illustration, qui visent elles-mÃªmes Ã  rendre compte de lâ€™information ; 10Â° Les copies ou reproductions numÃ©riques rÃ©alisÃ©es Ã  partir dâ€™une source licite, en vue de lâ€™exploration de textes et de donnÃ©es incluses ou associÃ©es aux Ã©crits scientifiques pour les besoins de la recherche publique, Ã  lâ€™exclusion de toute finalitÃ© commerciale. Un dÃ©cret fixe les conditions dans lesquelles lâ€™exploration des textes et des donnÃ©es est mise en Å“uvre, ainsi que les modalitÃ©s de conservation et de communication des fichiers produits au terme des activitÃ©s de recherche pour lesquelles elles ont Ã©tÃ© produites ; ces fichiers constituent des donnÃ©es de la recherche ; 11Â° Les reproductions et reprÃ©sentations dâ€™Å“uvres architecturales et de sculptures, placÃ©es en permanence sur la voie publique, rÃ©alisÃ©es par des personnes physiques, Ã  lâ€™exclusion de tout usage Ã  caractÃ¨re commercial. Les reproductions ou reprÃ©sentations qui, notamment par leur nombre ou leur format, ne seraient pas en stricte proportion avec le but exclusif dâ€™information immÃ©diate poursuivi ou qui ne seraient pas en relation directe avec cette derniÃ¨re donnent lieu Ã  rÃ©munÃ©ration des auteurs sur la base des accords ou tarifs en vigueur dans les secteurs professionnels concernÃ©s. Les exceptions Ã©numÃ©rÃ©es par le prÃ©sent article ne peuvent porter atteinte Ã  lâ€™exploitation normale de lâ€™oeuvre ni causer un prÃ©judice injustifiÃ© aux intÃ©rÃªts lÃ©gitimes de lâ€™auteur. Les modalitÃ©s dâ€™application du prÃ©sent article, notamment les caractÃ©ristiques et les conditions de distribution des documents mentionnÃ©s au d du 3Â°, sont prÃ©cisÃ©es par dÃ©cret en Conseil dâ€™Etat. Lorsque lâ€™oeuvre a Ã©tÃ© divulguÃ©e, lâ€™auteur ne peut interdire : Les reprÃ©sentations privÃ©es et gratuites effectuÃ©es exclusivement dans un cercle de famille ; Ex: examen de musique avec une musique pas encore dans le domaine public, mais examen peut etre considere comme publiqueDroit de reproduction Article L122-3CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La reproduction consiste dans la fixation matÃ©rielle de lâ€™oeuvre par tous procÃ©dÃ©s qui permettent de la communiquer au public dâ€™une maniÃ¨re indirecte. Elle peut sâ€™effectuer notamment par imprimerie, dessin, gravure, photographie, moulage et tout procÃ©dÃ© des arts graphiques et plastiques, enregistrement mÃ©canique, cinÃ©matographique ou magnÃ©tique. Pour les oeuvres dâ€™architecture, la reproduction consiste Ã©galement dans lâ€™exÃ©cution rÃ©pÃ©tÃ©e dâ€™un plan ou dâ€™un projet type.Quâ€™est-ce que reproduire une oeuvre? Prendre une photo dâ€™â€˜un tableau Enregistrer un cours Ces notes de cours (ptdr) Une reproduction meme partielle est une reproduction. Toute reproduction doit etre autorisee par lâ€™auteur.On a le droit de reproduire lâ€™oeuvre dans un but prive (copie privee). photocopieLa photocopie a apporte de nouvelles difficultes, ca a fait baisser les ventes de certains livres et surtout manuel scolaires. La photocopie apporte des copies de tres bonne qualiteEn France, pour contrer ce probleme, on a instaure une taxe sur les support vierges (copie techniquement interdites mais reellement impossible a interdire). Origine de la taxe pour copie privee legaliser le dispositif anti-copie $\\Rightarrow$ contradiction majeure â€œjâ€™accepte de payer la taxe qui se je peux copierâ€ Epita paye un forfait pour copier un certain nombre de manuelsSi un entreprise achete beaucoup de supports vierges pour stocker ses propres information, elle peut etre exonerer de la taxe. DADVSI aout 2006 (L122-5)3Â° Sous rÃ©serve que soient indiquÃ©s clairement le nom de lâ€™auteur et la source : a) Les analyses et courtes citations justifiÃ©es par le caractÃ¨re critique, polÃ©mique, pÃ©dagogique, scientifique ou dâ€™information de lâ€™oeuvre Ã  laquelle elles sont incorporÃ©es$\\Rightarrow$ c.a.d une revue de presse Ce nâ€™est pas ce que Google fait actuellement (L122-5)4Â° La parodie, le pastiche et la caricature, compte tenu des lois du genre ;Exeptions DANS une exception Les exceptions Ã©numÃ©rÃ©es par le prÃ©sent article ne peuvent porter atteinte Ã  lâ€™exploitation normale de lâ€™oeuvre ni causer un prÃ©judice injustifiÃ© aux intÃ©rÃªts lÃ©gitimes de lâ€™auteur. Article L122-6ModifiÃ© par Loi nÂ°94-361 du 10 mai 1994 - art. 4 () JORF 11 mai 1994 Sous rÃ©serve des dispositions de lâ€™article L. 122-6-1, le droit dâ€™exploitation appartenant Ã  lâ€™auteur dâ€™un logiciel comprend le droit dâ€™effectuer et dâ€™autoriser : 1Â° La reproduction permanente ou provisoire dâ€™un logiciel en tout ou partie par tout moyen et sous toute forme. Dans la mesure oÃ¹ le chargement, lâ€™affichage, lâ€™exÃ©cution, la transmission ou le stockage de ce logiciel nÃ©cessitent une reproduction, ces actes ne sont possibles quâ€™avec lâ€™autorisation de lâ€™auteur ; 2Â° La traduction, lâ€™adaptation, lâ€™arrangement ou toute autre modification dâ€™un logiciel et la reproduction du logiciel en rÃ©sultant ; 3Â° La mise sur le marchÃ© Ã  titre onÃ©reux ou gratuit, y compris la location, du ou des exemplaires dâ€™un logiciel par tout procÃ©dÃ©. Toutefois, la premiÃ¨re vente dâ€™un exemplaire dâ€™un logiciel dans le territoire dâ€™un Etat membre de la CommunautÃ© europÃ©enne ou dâ€™un Etat partie Ã  lâ€™accord sur lâ€™Espace Ã©conomique europÃ©en par lâ€™auteur ou avec son consentement Ã©puise le droit de mise sur le marchÃ© de cet exemplaire dans tous les Etats membres Ã  lâ€™exception du droit dâ€™autoriser la location ultÃ©rieure dâ€™un exemplaire. Article L122-6ModifiÃ© par Loi nÂ°94-361 du 10 mai 1994 - art. 4 () JORF 11 mai 1994 Sous rÃ©serve des dispositions de lâ€™article L. 122-6-1, le droit dâ€™exploitation appartenant Ã  lâ€™auteur dâ€™un logiciel comprend le droit dâ€™effectuer et dâ€™autoriser : 1Â° La reproduction permanente ou provisoire dâ€™un logiciel en tout ou partie par tout moyen et sous toute forme. Dans la mesure oÃ¹ le chargement, lâ€™affichage, lâ€™exÃ©cution, la transmission ou le stockage de ce logiciel nÃ©cessitent une reproduction, ces actes ne sont possibles quâ€™avec lâ€™autorisation de lâ€™auteur ; 2Â° La traduction, lâ€™adaptation, lâ€™arrangement ou toute autre modification dâ€™un logiciel et la reproduction du logiciel en rÃ©sultant ; 3Â° La mise sur le marchÃ© Ã  titre onÃ©reux ou gratuit, y compris la location, du ou des exemplaires dâ€™un logiciel par tout procÃ©dÃ©. Toutefois, la premiÃ¨re vente dâ€™un exemplaire dâ€™un logiciel dans le territoire dâ€™un Etat membre de la CommunautÃ© europÃ©enne ou dâ€™un Etat partie Ã  lâ€™accord sur lâ€™Espace Ã©conomique europÃ©en par lâ€™auteur ou avec son consentement Ã©puise le droit de mise sur le marchÃ© de cet exemplaire dans tous les Etats membres Ã  lâ€™exception du droit dâ€™autoriser la location ultÃ©rieure dâ€™un exemplaire. copie de sauvegarde et copie privÃ©e sont diffÃ©rentesToute stipulation contraire aux dispositions prÃ©vues aux II, III et IV du prÃ©sent article est nulle et non avenue.Regime du droit RÃ©gime du droit des contrats date de 1804ordonnance du 10 fÃ©vrier 2016 Article 1101ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Le contrat est un accord de volontÃ©s entre deux ou plusieurs personnes destinÃ© Ã  crÃ©er, modifier, transmettre ou Ã©teindre des obligations. Le contrat est la Loi des parties au contrat Article 1103ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats lÃ©galement formÃ©s tiennent lieu de loi Ã  ceux qui les ont faits. Force obligatoire du contrat peut saisir le juge pour faire rectifierLa libertÃ© contractuelle ne permet pas de dÃ©roger aux rÃ¨gles qui intÃ©ressent lâ€™ordre public. (Article 1102) Article 1104ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats doivent Ãªtre nÃ©gociÃ©s, formÃ©s et exÃ©cutÃ©s de bonne foi. Cette disposition est dâ€™ordre public. Article 1105ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats, quâ€™ils aient ou non une dÃ©nomination propre, sont soumis Ã  des rÃ¨gles gÃ©nÃ©rales, qui sont lâ€™objet du prÃ©sent sous-titre. Les rÃ¨gles particuliÃ¨res Ã  certains contrats sont Ã©tablies dans les dispositions propres Ã  chacun dâ€™eux. Les rÃ¨gles gÃ©nÃ©rales sâ€™appliquent sous rÃ©serve de ces rÃ¨gles particuliÃ¨res. Les contrats, quâ€™ils aient ou non une dÃ©nomination propre, sont soumis Ã  des rÃ¨gles gÃ©nÃ©rales, qui sont lâ€™objet du prÃ©sent sous-titre.Est-ce quâ€™un mariage est une forme de contrat ?Câ€™est plus une instution quâ€™un contrat Pour quâ€™un contrat soit valable, il faut quâ€™il soit valablement forme.Est-ce que le contrat est valablement forme ? Article 1128ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Sont nÃ©cessaires Ã  la validitÃ© dâ€™un contrat : 1Â° Le consentement des parties ; 2Â° Leur capacitÃ© de contracter ; 3Â° Un contenu licite et certain.Si un contrat nâ€™est pas valablement forme, il peut etre conteste. Un qui a pris lâ€™ascendant sur lâ€™autre Un qui a trompe lâ€™autre etc.Consentement des partiesCe consentement doit Ãªtre juridiquement intact, câ€™est Ã  dire ne pas Ãªtre viciÃ© Quelque chose qui altere le consentement Article 1130ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur, le dol et la violence vicient le consentement lorsquâ€™ils sont de telle nature que, sans eux, lâ€™une des parties nâ€™aurait pas contractÃ© ou aurait contractÃ© Ã  des conditions substantiellement diffÃ©rentes. Leur caractÃ¨re dÃ©terminant sâ€™apprÃ©cie eu Ã©gard aux personnes et aux circonstances dans lesquelles le consentement a Ã©tÃ© donnÃ©. Article 1132ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur de droit ou de fait, Ã  moins quâ€™elle ne soit inexcusable, est une cause de nullitÃ© du contrat lorsquâ€™elle porte sur les qualitÃ©s essentielles de la prestation due ou sur celles du cocontractant. Article 1136ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur sur la valeur par laquelle, sans se tromper sur les qualitÃ©s essentielles de la prestation, un contractant fait seulement de celle-ci une apprÃ©ciation Ã©conomique inexacte, nâ€™est pas une cause de nullitÃ©. Article 1137ModifiÃ© par LOI nÂ°2018-287 du 20 avril 2018 - art. 5 Le dol est le fait pour un contractant dâ€™obtenir le consentement de lâ€™autre par des manÅ“uvres ou des mensonges. Constitue Ã©galement un dol la dissimulation intentionnelle par lâ€™un des contractants dâ€™une information dont il sait le caractÃ¨re dÃ©terminant pour lâ€™autre partie. NÃ©anmoins, ne constitue pas un dol le fait pour une partie de ne pas rÃ©vÃ©ler Ã  son cocontractant son estimation de la valeur de la prestation. Article 1145ModifiÃ© par LOI nÂ°2018-287 du 20 avril 2018 - art. 6 Toute personne physique peut contracter sauf en cas dâ€™incapacitÃ© prÃ©vue par la loi. La capacitÃ© des personnes morales est limitÃ©e par les rÃ¨gles applicables Ã  chacune dâ€™entre elles. Article 1146ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Sont incapables de contracter, dans la mesure dÃ©finie par la loi : 1Â° Les mineurs non Ã©mancipÃ©s ; 2Â° Les majeurs protÃ©gÃ©s au sens de lâ€™article 425. Article 1148ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Toute personne incapable de contracter peut nÃ©anmoins accomplir seule les actes courants autorisÃ©s par la loi ou lâ€™usage, pourvu quâ€™ils soient conclus Ã  des conditions normales. Les incapacitÃ©s protÃ¨gent lâ€™incapable Article 425ModifiÃ© par Loi nÂ°2007-308 du 5 mars 2007 - art. 7 () JORF 7 mars 2007 en vigueur le 1er janvier 2009 Toute personne dans lâ€™impossibilitÃ© de pourvoir seule Ã  ses intÃ©rÃªts en raison dâ€™une altÃ©ration, mÃ©dicalement constatÃ©e, soit de ses facultÃ©s mentales, soit de ses facultÃ©s corporelles de nature Ã  empÃªcher lâ€™expression de sa volontÃ© peut bÃ©nÃ©ficier dâ€™une mesure de protection juridique prÃ©vue au prÃ©sent chapitre. Sâ€™il nâ€™en est disposÃ© autrement, la mesure est destinÃ©e Ã  la protection tant de la personne que des intÃ©rÃªts patrimoniaux de celle-ci. Elle peut toutefois Ãªtre limitÃ©e expressÃ©ment Ã  lâ€™une de ces deux missions. Utiliser un preambule pour definir clairement ce quâ€™on veut faire Description de lâ€™oeuvre et de ce que lâ€™on entend faire en des termes â€œnormauxâ€ Obligation dâ€™un Ã©crit Attention Ã©crit obligatoire pour la preuve et pas pour la validitÃ©Chaque droit cÃ©dÃ© doit faire lâ€™objet dâ€™une mention, ce qui nâ€™est pas mentionnÃ© est sensÃ© Ãªtre conservÃ© par lâ€™auteur.On doit prÃ©ciser Ã©tendue gÃ©ographique, la durÃ©e, lâ€™excluivitÃ©, â€¦,Lâ€™oeuvrePrÃ©ambuleCirconstances de la â€œrencontreâ€Description de lâ€™Å“uvre : tous ses Ã©lÃ©mentsExpliquer ce que lâ€™on va faire : les droits visÃ©s par le contrat (reproduction, adaptation, exÃ©cution, etc), durÃ©e, Ã©tendue gÃ©ographique, Ã©ventuellement le public visÃ© par lâ€™exploitation Description prÃ©cise de lâ€™Å“uvre objet du contrat Article L131-1CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La cession globale des oeuvre Article L131-3CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La transmission des droits de lâ€™auteur est subordonnÃ©e Ã  la condition que chacun des droits cÃ©dÃ©s fasse lâ€™objet dâ€™une mention distincte dans lâ€™acte de cession et que le domaine dâ€™exploitation des droits cÃ©dÃ©s soit dÃ©limitÃ© quant Ã  son Ã©tendue et Ã  sa destination, quant au lieu et quant Ã  la durÃ©e.Lorsque des circonstances spÃ©ciales lâ€™exigent, le contrat peut Ãªtre valablement conclu par Ã©change de tÃ©lÃ©grammes, Ã  condition que le domaine dâ€™exploitation des droits cÃ©dÃ©s soit dÃ©limitÃ© conformÃ©ment aux termes du premier alinÃ©a du prÃ©sent article.Les cessions portant sur les droits dâ€™adaptation audiovisuelle doivent faire lâ€™objet dâ€™un contrat Ã©crit sur un document distinct du contrat relatif Ã  lâ€™Ã©dition proprement dite de lâ€™oeuvre imprimÃ©e.Le bÃ©nÃ©ficiaire de la cession sâ€™engage par ce contrat Ã  rechercher une exploitation du droit cÃ©dÃ© conformÃ©ment aux usages de la profession et Ã  verser Ã  lâ€™auteur, en cas dâ€™adaptation, une rÃ©munÃ©ration proportionnelle aux recettes perÃ§ues. Article L131-2ModifiÃ© par LOI nÂ°2016-925 du 7 juillet 2016 - art. 7ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 6Les contrats de reprÃ©sentation, dâ€™Ã©dition et de production audiovisuelle dÃ©finis au prÃ©sent titre doivent Ãªtre constatÃ©s par Ã©crit. Il en est de mÃªme des autorisations gratuites dâ€™exÃ©cution.Les contrats par lesquels sont transmis des droits dâ€™auteur doivent Ãªtre constatÃ©s par Ã©crit.Dans tous les autres cas, les dispositions des articles 1359 Ã  1362 du code civil sont applicables. Les contrats par lesquels sont transmis des droits dâ€™auteur doivent Ãªtre constatÃ©s par Ã©crit. Article L131-3CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La transmission des droits de lâ€™auteur est subordonnÃ©e Ã  la condition que chacun des droits cÃ©dÃ©s fasse lâ€™objet dâ€™une mention distincte dans lâ€™acte de cession et que le domaine dâ€™exploitation des droits cÃ©dÃ©s soit dÃ©limitÃ© quant Ã  son Ã©tendue et Ã  sa destination, quant au lieu et quant Ã  la durÃ©e.Lorsque des circonstances spÃ©ciales lâ€™exigent, le contrat peut Ãªtre valablement conclu par Ã©change de tÃ©lÃ©grammes, Ã  condition que le domaine dâ€™exploitation des droits cÃ©dÃ©s soit dÃ©limitÃ© conformÃ©ment aux termes du premier alinÃ©a du prÃ©sent article.Les cessions portant sur les droits dâ€™adaptation audiovisuelle doivent faire lâ€™objet dâ€™un contrat Ã©crit sur un document distinct du contrat relatif Ã  lâ€™Ã©dition proprement dite de lâ€™oeuvre imprimÃ©e.Le bÃ©nÃ©ficiaire de la cession sâ€™engage par ce contrat Ã  rechercher une exploitation du droit cÃ©dÃ© conformÃ©ment aux usages de la profession et Ã  verser Ã  lâ€™auteur, en cas dâ€™adaptation, une rÃ©munÃ©ration proportionnelle aux recettes perÃ§ues. Article L131-4ModifiÃ© par Loi nÂ°94-361 du 10 mai 1994 - art. 6 () JORF 11 mai 1994La cession par lâ€™auteur de ses droits sur son oeuvre peut Ãªtre totale ou partielle. Elle doit comporter au profit de lâ€™auteur la participation proportionnelle aux recettes provenant de la vente ou de lâ€™exploitation.Toutefois, la rÃ©munÃ©ration de lâ€™auteur peut Ãªtre Ã©valuÃ©e forfaitairement dans les cas suivants :1Â° La base de calcul de la participation proportionnelle ne peut Ãªtre pratiquement dÃ©terminÃ©e ;2Â° Les moyens de contrÃ´ler lâ€™application de la participation font dÃ©faut ;3Â° Les frais des opÃ©rations de calcul et de contrÃ´le seraient hors de proportion avec les rÃ©sultats Ã  atteindre ;4Â° La nature ou les conditions de lâ€™exploitation rendent impossible lâ€™application de la rÃ¨gle de la rÃ©munÃ©ration proportionnelle, soit que la contribution de lâ€™auteur ne constitue pas lâ€™un des Ã©lÃ©ments essentiels de la crÃ©ation intellectuelle de lâ€™oeuvre, soit que lâ€™utilisation de lâ€™oeuvre ne prÃ©sente quâ€™un caractÃ¨re accessoire par rapport Ã  lâ€™objet exploitÃ© ;5Â° En cas de cession des droits portant sur un logiciel ;6Â° Dans les autres cas prÃ©vus au prÃ©sent code.Est Ã©galement licite la conversion entre les parties, Ã  la demande de lâ€™auteur, des droits provenant des contrats en vigueur en annuitÃ©s forfaitaires pour des durÃ©es Ã  dÃ©terminer entre les parties. La loi pose le principe de la rÃ©munÃ©ration proportionnelleIl faut prevoir les Les modes dâ€™exploitation futurs Garantir que lâ€™on est titulaire des droits Afin dâ€™assouplir la licence GPLv3, il est possible dâ€™insÃ©rer des Â« permissions additionnelles Â» ce sont des termes qui complÃ¨tent les termes de la licence en stipulant des exceptions Ã  lâ€™une ou plusieurs de ses conditions. Ces termes additionnels doivent Ãªtre traitÃ©s comme les termes de la licence et, doivent Ãªtre respectÃ©es sauf sâ€™ils sont contraires Ã  la loi applicable. De plus, lors de la distribution des exemplaires du logiciel, il est possible de supprimer toute permission additionnelle sur cet exemplaire ou sur une partie de celui-ci. Au contraire, des permissions additionnelles peuvent Ãªtre stipulÃ©es, sur une contribution ajoutÃ©e par un contributeur qui dispose des droits pour le faire. Les termes additionnels peuvent porter sur : Le refus de toute garantie ou limiter la responsabilitÃ© diffÃ©remment des termes (exonÃ©ration de garantie et de responsabilitÃ©) dÃ©jÃ  contenu dans la licence.Lâ€™exigence du maintient de certaines mentions spÃ©cifiques.Lâ€™interdiction dâ€™indication dâ€™origine erronÃ©e des contributions.La limitation Ã  des fins publicitaires des noms des concÃ©dants ou des auteurs de la contributions.Refuser dâ€™accorder des droits aux termes du droit des marques pour lâ€™utilisation des noms commerciaux, marques commerciales ou marques de services.Exiger que lâ€™indemnisation des concÃ©dants et des auteurs de cette contribution par quiconque transmettant la contribution (ou des versions modifiÃ©es de celle-ci) avec des acceptations contractuelles de responsabilitÃ© au bÃ©nÃ©fice du rÃ©cipiendaire (bÃ©nÃ©ficiaire), pour toute responsabilitÃ© que ces acceptations contractuelles imposent directement Ã  ces concÃ©dants et auteurs . https://faq.adullact.org/index.php/juridique/31-presentation-de-la-licence-gpl-v3Les bases de donnees, deux niveaux de protection La base Les donnees CrÃ©ation Loi nÂ°98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1999Quâ€™est-ce quâ€™on peut injecter dans la protection des donnees ? Dâ€™ou elle vient Comment elle a ete recuperee Droit de vie privee Droit a lâ€™image Loi Informatique et LibertÃ©s du 6 janvier 1978.Les donnÃ©es peuvent Ãªtre protÃ©gÃ©es aussi par le droit dâ€™auteur ou un autre droit Article L112-3ModifiÃ© par Loi nÂ°98-536 du 1 juillet 1998 - art. 1 () JORF 2 juillet 1998Les auteurs de traductions, dâ€™adaptations, transformations ou arrangements des oeuvres de lâ€™esprit jouissent de la protection instituÃ©e par le prÃ©sent code sans prÃ©judice des droits de lâ€™auteur de lâ€™oeuvre originale. Il en est de mÃªme des auteurs dâ€™anthologies ou de recueils dâ€™oeuvres ou de donnÃ©es diverses, tels que les bases de donnÃ©es, qui, par le choix ou la disposition des matiÃ¨res, constituent des crÃ©ations intellectuelles.On entend par base de donnÃ©es un recueil dâ€™oeuvres, de donnÃ©es ou dâ€™autres Ã©lÃ©ments indÃ©pendants, disposÃ©s de maniÃ¨re systÃ©matique ou mÃ©thodique, et individuellement accessibles par des moyens Ã©lectroniques ou par tout autre moyen. Double systÃ¨me de protection : Droit du producteur de la base de donnÃ©es et le droit dâ€™auteur Droit dâ€™auteur si originale originalitÃ© ne rÃ©side pas dans les donnÃ©es mais dans le choix et/ou lâ€™ordonnancement des donnÃ©es Titre IV : Droits des producteurs de bases de donnÃ©es (Articles L341-1 Ã  L343-7) Article L341-1CrÃ©ation Loi nÂ°98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur dâ€™une base de donnÃ©es, entendu comme la personne qui prend lâ€™initiative et le risque des investissements correspondants, bÃ©nÃ©ficie dâ€™une protection du contenu de la base lorsque la constitution, la vÃ©rification ou la prÃ©sentation de celui-ci atteste dâ€™un investissement financier, matÃ©riel ou humain substantiel.Cette protection est indÃ©pendante et sâ€™exerce sans prÃ©judice de celles rÃ©sultant du droit dâ€™auteur ou dâ€™un autre droit sur la base de donnÃ©es ou un de ses Ã©lÃ©ments constitutifs.Le producteur dâ€™une base de donnÃ©es bÃ©nÃ©ficie dâ€™un protection du contenu SI il atteste dâ€™un investissement financier, matÃ©riel ou humain substantiel. Article L342-1CrÃ©ation Loi nÂ°98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur de bases de donnÃ©es a le droit dâ€™interdire :1Â° Lâ€™extraction, par transfert permanent ou temporaire de la totalitÃ© ou dâ€™une partie qualitativement ou quantitativement substantielle du contenu dâ€™une base de donnÃ©es sur un autre support, par tout moyen et sous toute forme que ce soit ;2Â° La rÃ©utilisation, par la mise Ã  la disposition du public de la totalitÃ© ou dâ€™une partie qualitativement ou quantitativement substantielle du contenu de la base, quelle quâ€™en soit la forme.Ces droits peuvent Ãªtre transmis ou cÃ©dÃ©s ou faire lâ€™objet dâ€™une licence.Le prÃªt public nâ€™est pas un acte dâ€™extraction ou de rÃ©utilisation. Article L342-2CrÃ©ation Loi nÂ°98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur peut Ã©galement interdire lâ€™extraction ou la rÃ©utilisation rÃ©pÃ©tÃ©e et systÃ©matique de parties qualitativement ou quantitativement non substantielles du contenu de la base lorsque ces opÃ©rations excÃ¨dent manifestement les conditions dâ€™utilisation normale de la base de donnÃ©es. Article L342-3ModifiÃ© par LOI nÂ°2016-1321 du 7 octobre 2016 - art. 38Lorsquâ€™une base de donnÃ©es est mise Ã  la disposition du public par le titulaire des droits, celui-ci ne peut interdire :1Â° Lâ€™extraction ou la rÃ©utilisation dâ€™une partie non substantielle, apprÃ©ciÃ©e de faÃ§on qualitative ou quantitative, du contenu de la base, par la personne qui y a licitement accÃ¨s ;2Â° Lâ€™extraction Ã  des fins privÃ©es dâ€™une partie qualitativement ou quantitativement substantielle du contenu dâ€™une base de donnÃ©es non Ã©lectronique sous rÃ©serve du respect des droits dâ€™auteur ou des droits voisins sur les oeuvres ou Ã©lÃ©ments incorporÃ©s dans la base ;3Â° Lâ€™extraction et la rÃ©utilisation dâ€™une base de donnÃ©es dans les conditions dÃ©finies au 7Â° de lâ€™article L. 122-5, au 1Â° de lâ€™article L. 122-5-1 et Ã  lâ€™article L. 122-5-2 ;4Â° Lâ€™extraction et la rÃ©utilisation dâ€™une partie substantielle, apprÃ©ciÃ©e de faÃ§on qualitative ou quantitative, du contenu de la base, sous rÃ©serve des bases de donnÃ©es conÃ§ues Ã  des fins pÃ©dagogiques et des bases de donnÃ©es rÃ©alisÃ©es pour une Ã©dition numÃ©rique de lâ€™Ã©crit, Ã  des fins exclusives dâ€™illustration dans le cadre de lâ€™enseignement et de la recherche, Ã  lâ€™exclusion de toute activitÃ© ludique ou rÃ©crÃ©ative, dÃ¨s lors que le public auquel cette extraction et cette rÃ©utilisation sont destinÃ©es est composÃ© majoritairement dâ€™Ã©lÃ¨ves, dâ€™Ã©tudiants, dâ€™enseignants ou de chercheurs directement concernÃ©s, que la source est indiquÃ©e, que lâ€™utilisation de cette extraction et cette rÃ©utilisation ne donne lieu Ã  aucune exploitation commerciale et quâ€™elle est compensÃ©e par une rÃ©munÃ©ration nÃ©gociÃ©e sur une base forfaitaire ;5Â° Les copies ou reproductions numÃ©riques de la base rÃ©alisÃ©es par une personne qui y a licitement accÃ¨s, en vue de fouilles de textes et de donnÃ©es incluses ou associÃ©es aux Ã©crits scientifiques dans un cadre de recherche, Ã  lâ€™exclusion de toute finalitÃ© commerciale. La conservation et la communication des copies techniques issues des traitements, au terme des activitÃ©s de recherche pour lesquelles elles ont Ã©tÃ© produites, sont assurÃ©es par des organismes dÃ©signÃ©s par dÃ©cret. Les autres copies ou reproductions sont dÃ©truites.Toute clause contraire au 1Â° ci-dessus est nulle.Les exceptions Ã©numÃ©rÃ©es par le prÃ©sent article ne peuvent porter atteinte Ã  lâ€™exploitation normale de la base de donnÃ©es ni causer un prÃ©judice injustifiÃ© aux intÃ©rÃªts lÃ©gitimes du producteur de la base.le droit du producteur de la BDD sâ€™applique mÃªme si la BDD nâ€™est pas protÃ©gÃ©e par un droit dâ€™auteur et mÃªme si les donnÃ©es ne sont pas protÃ©gÃ©es" }, { "title": "MLRF: Lecture 06", "url": "/cours/posts/mlrf_sixth_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-25 10:00:00 +0200", "snippet": "Lien de la note HackmdPractice 5: Take home messages BoVW is linear classification friendly And linear classifier are to be prefered whenever possibleData preparation is tedious An important part of the time is dedicated to data analysis Plus we prepared a lot of things for you in the previsous sesssionsScikit-learn is easy and super powerful Calssifier evaluation in 1 line But there is more: parameter tuning, cross-validation, etc. in 1 or 2 lines Data preprocessing + classification (pipelines) in 1-3 linesSome classifiers â€“ part 2How to build non-linear classifiers ?2 solutions: Preprocess the data - seen last time Ex: explicit embedding, kernel trickâ€¦ Change the input to make it linearly separable Combine multiple linear classifiers into nonlinear classifier - current topic Ex: boosting, neural networksâ€¦ Split the input space into linear subspaces Non-linear classification using combinations of linear classifiersMulti-layer Perceptron Combine features linearly, apply a linear activation function $\\phi$, repeatUniversal approximation theoremWhat if $\\phi$ not linear ? Universal approximation theorem (Cybenko 89, Hornik 91)Decision treeWorks on categorical (like, â€œredâ€, â€œblackâ€) and numerical (both discrete and continuous) random variablesTrain by optimizing classification â€œpurityâ€ at each decision (threshold on a particular dimension in numerical case)Very fast training and testing. Non parametric.No need to preprocess the featuresBUT: very prone to overfitting without strong limits on depthRandom Forests Average the decision of multiple decision treesRandomize in 2 ways: For each tree, pick a bootstrap sample of data For each split, pick random sample of features More trees are always betterEnsemble methodsâ€œBaggingâ€ or â€œbootstrap aggregatingâ€ Underlying idea: part of the variance is due to the specific choice of the training data set Let use create many similar training data sets using bootstrap For each of them, train a new classifier The final function will tbe the average of each function ouptuts If generalization error is decomposed into bias and variance terms then bagging reduces variance (averag of large number of random error $\\simeq 0$)Random forest = a way of bagging treesâ€œBoostingâ€, AdaBoost variantCombinaison of weak classifiers $\\sum_m\\alpha_mG_m(x)$$\\alpha_m$ increases with precision (less errors, bigger $\\alpha_m$)The classifier $G_m$ is trained with increased error cost for the observatins which were misclassified by $G_{m-1}$A quick comparisonMore tricksData augmentationAdd realistic deformations to your input in order to improve domain coverage.For image data, depending on what is possible in productin: rotations, horizontal &amp;amp; vertical dlips, scaling, translation, illumination change, warping, noise, etc.For vector data: intersting problem. Possible approach: train/fit PCA then add random noise in low-energy featuresRejectSeveral options: Improve the model of class boundary In 1-vs-all training, add noise to the â€œothersâ€ samples Adjust the decision function dependinf on your application Look at the prediction probabiblity of your classifier, and threshold it as per your need using a ROC curve Model the noise Add a â€œnoneâ€ class to your classifier, with samples for real life cases of negatives samples More theory on MLWhat is our goal ? Given samples (described by features) and true labels,find a good functionwhich wil correctly predict labelsgiven new data samplesProblems: Which family for our function? What is â€œgoodâ€? How to train / find such function?What are the sources of error ? Noise Your data is not perfect. (or â€œEvery model is wrong.â€) Even if there exist an optimal underlying model, the observations are corrupted by noise (e.g. multiple y for a given x). - Even the optimal solution could be wrong. Bias You need to simplify to generalize. You classifier needs to drop some information about the training set to have generalization power. The set of solutions explored does not contain the optimal solution. Variance You have many ways to explain your training dataset It is hard to find an optimal solution among those many possibilities. If we draw another training set from the same distribution, we would obtain another solution. 2 big issuesUnder-fitting Caused by bias Your model assumptions are too strong for the data, so the model wonâ€™t fill well Over-fitting Caused by variance Your algorithm has memorized the data including the noise, so it canâ€™t generalize. The theoryBias (statistical definition)Let $T$ be a statistic used to estimate a parameter $\\theta$.If $E[T] = \\theta + bias(\\theta)$ then $bias(\\theta)$ is called the bias of the statistic $T$, where $E[T]$ represents the expected value of the statistics $T$.If $bias(\\theta) = 0$, then $E[T] = \\theta$. So, $T$ is an unbiased estimator of the true parameter, say $\\theta$.Expected RiskLet $D_n$ be a training set of examples $z_i$ drawn independently from an unknown distribution $p(z)$We need a set of functions F. Example: linear functions $f(x) = a \\times x + b$We need a loss function $L(z, f)$. Example: $L((x, y), f ) = (f (x) âˆ’ y)^2$ The Expected Risk, i.e. the expected generalization error, is: But we do not know $p(z)$, and we cannot test all $z$!Empirical Risk Because we cannot measure the real Expected Risk, we have to estimate it using the Empirical Risk: $D_n$ is our datasetAnd our training procedure then relies on Empirical Risk Minimization (ERM):And the training error is given by:Does this make sense? The empirical risk is an unbiased estimate of the risk, i.e. the more test samples we have, the more accurate our estimate is, under iid assumption.But the training risk is biasedThe training error is a biased estimate of the risk, i.e. the solution $f^â˜… (D_n)$ found by minimizing the training error is better on $D_n$ than on any other set $Dâ€™_n$ drawn from $p(z)$.However, under certain assumptions, the difference between the expected and the empirical risks can be bounded. This is an important result from the work of VapnikNote that the empirical risk on the test set is an unbiased estimate of the risk.Estimate the Expected Risk with the Empirical RiskFor a given capacity, using more samples to train and evaluate your predictor should make your Empirical Risk converge toward the best possible Expected Risk, if the ERM is consistent for $F$, given your training set $D_n$.The difference between Expected Risk and Empirical Risk is bounded but depends on the capacity of $F$ (set of possible functions).There is an optimal capacity for a given number of training samples $n$.CapacityThe capacity $h(F)$ is a measure of its size, or complexity (or VC dimension)For classification, the capacity of $F$ is defined by Vapnik &amp;amp; Chervonenkis as: the largest $n$ such that there exist a set of examples $D_n$ such that one can always find an $f \\in F$ which gives the correct answer for all examples in $D_{nâ€™}$ for any possible labeling.The Bias-Variance DilemmaIntrinsic dilemma: when the capacity $h(F)$ grows, the bias goes down, but the variance goes up!Decomposing the bias-variance-error for MSEFor a regression problem with a mean square loss, we have the following decomposition. Let $Y = f(X) + \\varepsilon$, with $\\varepsilon \\sim N(0, \\sigma_{\\varepsilon}^2)$ and $f_D(X)$ an estimator of $f(X)$, learned over the training set $D$. The error at a particular point $X = x_0$ is:In practiceEmpirical Risk and Expected Risk Measure train and test errorUse hold-out sets, cross-validations, etc. to get a test error.Train error: Empirical Risk.Can my model learn something (by heart)?Test error: Coarse estimate of the Expected Risk.Can my model generalize to unseen data?Detect under-fitting and over-fittingSome solutions / hintsHow to get started? Get enough data in the right format from your customer (hard) Check and split data (boring but mandatory) Agree on a loss function and minimum performance goal (moderate) Try to overfit a predictor on some samples (train set loss), increase complexity only if needed (capacity check) Fit on more data (more = better) Check for overfitting (val set loss) and add regularization if needed Evaluate performance thoroughly (test set loss) (reports, identify failure cases, etc.) Do some hyper-parameter optimization, try other modelsâ€¦ â€¦Introduction to practice session 6Using classification to segment imagesUntil now 1 image $\\to$ many vectors (instance recognition) 1 image $\\to$ 1 vector (image retrieval, image classification)Today / next practice session : 1 pixel â†’1 vector (pixel classification, image semantic segmentation)Brain Anatomy and ImagingHuman brain = Where human OS is stored and runTo investigate brain malfunction, two options:Magnetic Resonance Imaging (MRI)Everything you always wanted to know about MRIHydrogen atoms are naturally abundant in humans, particularly in water and fat.Pulses of radio waves excite the nuclear spin energy transition, and macroscopic polarization that is detected by antennas.Magnetic field gradients localize the polarization in space. By varying the parameters of the pulse sequence, different contrasts may be generated between tissues based on the relaxation properties of the hydrogen atoms therein.What you actually need to knowMRI is a large family of imaging techniquesThey can produce 3D scans of various appearances in order to emphasize some human tissues versus others.BraTS: Brain Tumor Segmentation CompetitionOriginal segmentation taskGiven a 3D scan (skull-stripped, registered) of a patient with T1, T2, T1C and FLAIR modalities, predict a tumor class for each voxel (the patient suffers from a glioma):Avec: edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core (blue).Original datasetThe 2018 competition we use the data from originally contains 285 brain scans.Your MissionA simplified competitionBecause dealing with 3D and data normalization would take you much time and pain, we: already performed data normalization extracted 2D (axial) slices that you have to processActual taskGiven a $240\\times240$ image with $4$ modalities (already normalized), predict for each pixel whether it belongs to a tumor or nor.Actual datasetTrain set $256$ normalized slices, one per patient, containing $240\\times240$ images with $4$ channels ($1$ for each modality), float32 $256$ target segmentations, one per patient, containing $240\\times240$ images with $1$ channel (indicating tumor or clean region), uint8Test set $29$ normalized slices, one per patient (not in the training set), containing $240\\times240$ images with $4$ channels ($1$ for each modality), float32 Ground truth kept secret for gradingSuggested PipelineData preprocessing We already did this step.Choose and train a classifierThere are several suggestions in the reference notebook: SVM, neural network, etc. Input = 1 vector of 4 components for each pixels Output = 1 for tumor, 0 for â€œnot tumorâ€ Do not use background (â€œblackâ€) pixels for training, they would ruin your classification Deep nets can work but they are harder to train well. And donâ€™t use deep nets, weâ€™ll play with them next semesterValidate your trainingCreate and use a validation set extracted from the full training set.To not train on the samples it contains.sklearn.model_selection.train_test_split may be your friend. Check visually results from both train and val sets!Interpret your resultsAdd some context to each pixelYou can get better results by looking at the neighborhood of a pixel to classify it better: train with vectors of size $N\\times M$ instead of $1\\times M$.Fighting underfitting and overfitting You do not have much data to train onIf you pick a classifier which is too simple, you may underfit: you will get low and similar scores both on the train and test setsChoosing another classifier may be a good idea here.You may also easily overfit your classifier, especially if you use one with a large capacity: you will get excellent scores on the train set, and bad ones on the test set.Regularization may be necessary.Post processingWe suggest in the notebook to â€œclean upâ€ the results by removing very small isolated pixels marked as tumor.You may have many other ideas hereGoing FurtherMany options Data augmentation to increase train set Larger / better neighborhood for each pixel Better ANN structure than the one suggested in the notebook Change the representation space? (Fourier, waveletsâ€¦) As the tumors under consideration may not have â€œholesâ€, improve the post-processing Super heavy classifiers (UNet, Gradient Boosted Treesâ€¦) â€¦ConclusionCourse overview: a very small glimpse of CV/PR/MLWelcome to 2012AlexNet by A. Krizhevsky, I. Sutskever, G. E. Hinton halved error rate on ImageNet competitionDeep learningWill be there for a few years!Is a natural extension of what we saw: feature extraction, encoding, pooling, classification in a single, integrated, globally optimized pipeline.Requires skills you learned: dev, math, data preparation, evaluation.Input data still need to be properly normalized, for instance.Requires a lot of practice: read papers, donâ€™t be impressed by the math, implement them.If not applicable, then pick one of the good old technique we talked about." }, { "title": "TIFO: Cours recalage", "url": "/cours/posts/tifo_recalage/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, recalage", "date": "2021-06-23 10:00:00 +0200", "snippet": "Lien de la note HackmdComment extraire une frequence cardiaque quand on a une oscillation ? Stabiliser lâ€™image Quand on fait du recalage, on fait des estimations donc par moment lâ€™image â€œvibreâ€La video recalee est plus petite car on prend la plus grande translation de chaque cote.ContextAn example Ptit poisson, grozyeuxGeneral principle What is the transformation between 2 frames ?For 2 frames $I_2$ and $I_2$, Find $\\mathcal T$ to minimize \\(\\mathcal V = Variance(I_1,\\mathcal T(I_2))\\) Hyper important de verifier2 frames The reference frame ($I_1$ in our presentation) is the frame we will not modify, considered as the â€œtrueâ€ image The studied frame ($I_2$ in our presentation) is the frame we try to minimize $\\mathcal V$ModelChoixe of the model to have the best estimation: Fourier domain Image Graph Multi-modality Un peu complique Usual transformationsRigid transformation Transfo rigide: on ne change pas la structure (les distances) dans lâ€™imageNon-rigid transformation On ne veut surtout pas faire de transformation non-rigidePourquoi ?On risque de creer des deformations locales (dans notre exemple: corriger le mouvement du coeur)Transformation estimationClassical estimation for the entire image analysis:\\[\\mathcal T = (\\mathcal R, T)\\]with:\\[\\mathcal R=\\begin{pmatrix}\\alpha a &amp;amp;\\alpha b\\\\\\alpha c&amp;amp;\\alpha d\\end{pmatrix} = \\alpha\\mathcal R&#39;\\\\T=(d_x, d_y)\\]Case of $\\mathcal R$:If there is a rotation:\\[\\mathcal R=\\begin{pmatrix}\\alpha \\cos(\\theta) &amp;amp;-\\alpha \\sin(\\theta)\\\\\\alpha \\sin(\\theta)&amp;amp;\\alpha \\cos(\\theta)\\end{pmatrix} = \\alpha\\mathcal R&#39;\\]$\\alpha$ is the scale factor\\[(I_2\\mathcal R+T)-I_1 = min(\\mathcal V)\\\\S = \\mathcal T(I_2)=(I_2\\mathcal R + T)\\\\\\forall (x,y)\\in I_2: S(x,y)=I_2(x&#39;,y&#39;)\\]with the estimated $\\mathcal R$ and $T$, $[xâ€™\\quad yâ€™]=[x\\quad y]\\mathcal R+T$Key-pointsPrinciple Objectives Points which are interesting $I_1$ Find their equivalent in $I_2$ Estimate the transform between the 2 sets of points We want to solve\\[P_2=P_2\\times\\mathcal R+\\mathcal T\\] Where $P_1$ and $P_2$ are the sets of points of the 2 frames we seek to match, $\\mathcal R$ is the â€œrotationâ€ matrix. $\\mathcal T=(d_x, d_y)$ is the translation The solution En fonction de la version dâ€™OpenCV il peut y avoir un soucis avec la matrice $\\mathcal M$ (elle peut etre $3\\times 3$ au lieu de $2\\times 3$)Applications Sequence stabilization Reconstruction Optical flow Similarity Comparison (evolution of a tumor etc.)Recalagekeuwa ?Deux images $S$ et $C$: cherche $T$ tel que $T(S)$ ressemble a $C$ Les notations sont pourries iciApplications Outil fondamental en analyse dâ€™images medicales, mais pas uniquement Ou ailleurs en imagerie ? Creation dâ€™images panoramiques Mosaiques Astronomie On ne cherche pas sur toute lâ€™image les points-cles, on se restreint a une certaine zoneSystemes par mosaiqueCe type dâ€™approche consiste a construire les images panoramiques a partir dâ€™une serie dâ€™images prises avec le meme systeme optique. On peut, par exemple, utiliser une camera en rotation autour de son centre optiqueEvidemment, un nombre arbitraire dâ€™images peut etre utiliseExemples en imagerie medicaleRecalage DefinitionConsiste a trouver une transformation spatiale permettant dâ€™aligner une image (source ou flottante) sur une autre (cible ou reference)En anglais: Image registration Image matchingRecalage monomodal ou multimodal: Monomodal: meme modalites Multimodale: modalites differentesRecalage intra ou inter-sujetsExemplesIntra-patient, mono-modaliteExemple: evolution de lesions (images IRM dâ€™un patient atteint de SEP a quelques mois dâ€™intervalle) Câ€™est flou !Pour trouver quelles sont les zones qui ont evolueIntra-patien, multi-modaliteExemple: fusion dâ€™informations provenant de 2 modalites differentesInter-patient, intra-modaliteExemple: segmentation a partir dâ€™un atlas anatomiqueExtension en 3DRecalage en imagerie medicaleReconstruction dâ€™un volume 3D A partir dâ€™une serie de coupes 2D contigues (microscopie, epaisseur de coupe de 60nm environ)Evolution temporelle Brain-shift Developpement cerebralComparaison entre differents sujets:Fusion de modaliteRecapPrincipe des methodes de recalageCritere de similariteSupposons que lâ€™on se donne un critere de similarite: $Simil(I, J)$ qui mesure la â€œressemblanceâ€ entre 2 images $I$ et $J$On choisit egalement une famille de transformation $\\mathcal F$ Le probleme de recalage sâ€™ecrit alors comme: \\(argmin_{T\\in\\mathcal F} Simil(T(I), J)=?\\)Methode de recalage Structures (primitives) a mettre en correspondance Critere de similarite Transformation OptimisationPrimitives geometriques Structures particulieres dans lâ€™image Points, courbes, surfaces Extraits automatiquement ou manuellement Detection des primitives: ici points de forte courbure Primitives intrinseques Primitives extrinseques Primitives intrinseques Structurent intrinseques au patient Information pertinente presente dans les 2 jeus de donnees Points Courbes (contours) Surfaces segmenteees Volumes Points anatomiques Identifies manuellement par lâ€™operateur Isole automatiquement Primitives extrinsequesReperes externes, visibles dans les 2 modalites fixees au patient ou a la table dâ€™examen Invasifs Cadre stereitaxique Vis dans la boite cranienne Non invasifs Cadre non visse Moule Repere colles a la peau Avantages Permet de recaler des donnees tres differentesInconvenients Les marqueurs doivent etre positionnes avant lâ€™acquisition Le recalage retrospectif nâ€™est pas possibleAutres reperes exterenes, contentionOn fait des moules du patient pour faire des recalagesPrimitives Pas de structures particulieres: tous les voxels de lâ€™image sont utilisesCritere de similariteDependance lineaire ou affineCoefficient de correlationHistogramme conjoint Quand il est parfait, on a le meme nombre de points a la meme valeurA quel histogramme correspond les images ? Conservation de lâ€™intensite - SSDInformation mutuelleExemplesSommaireOptimisationApproches geometriquesEvaluationEvaluation qualitativeEvaluation semi-quantitativeEvaluation quantitative" }, { "title": "MLRF: Lecture 05", "url": "/cours/posts/mlrf_fith_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-18 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda Introduction Image classification overview Some classifiers - part 1 Classifier evaluationSummary of last lectureContent-based image retrieval 2 strategies: keep all local descriptors for all images vs 1 descriptor per image Bag of Visual Words pipeline Focus on encoding Evaluation of image retrieval systems Precision Recall F-Measure mAPTexture descriptors (on les a pas du tout vu) What is a texture ? Fast and classic approaches Descripteurs a lâ€™anciennePractice session 4: Take home messagesBoVW Usually requires some preprocessing of the descriptors: centering, rotation/axes permutation, dimensionality reductionâ€¦ Is based on a quantization step (assign descriptors to clusters) Is just a histogram, like the color histogram of sessino 2 We can compute more advanced statistics to get better results (VLAD, FVs) Best practices: Test arrays shapes and types as soon as possible Make a small change, test, fix, tes, validate, repeat Get a complete, basic pipeline ASAP and improve it until time is over Next practice sessionImplement a simple image classifier: Will be gradedSteps Load resources Train a BoVW model Split the dataset into training and validation sets Compute the BoVW descriptor for each image We will make a small change here (sqrt + L2-norm) Prepare training structures Train a classifier and evaluate its performance Training and evaluating is easy with scikit learn Display some results Test on meme image Compute the results on the test set and export themImage classification overviewInstance recognition vs Class recognitionInstance recognitionRe-recognize a known 2D or 3D rigid object, potentially being viewed from a novel viewpoint, against a cluttered background, and with partial occlusionsEx: practice session 3Class recognitionRecognize any instance of a particular general class such as â€œcatâ€, â€œcarâ€ or â€œbicycleâ€Aka category-level or generic object recognition More challengingThis lecture and next practice sessionPipeline overviewOur image classification pipelineThis is a supervised machine learning task We need a dataset with samples Images will be represented as BoVW vectors of fixed size Targets will be encoded as integers 0: Muffin 1: Chihuahua This is a very usual data representation for a classification problem Classifier inputs = â€œsamplesâ€ with â€œfeaturesâ€Classifier outputs = â€œlabelsâ€Now we just need to select an appropriate method, prepare our data, run some training, test the results, adjust some parameters, compare approaches, display results, â€¦Data preparationNumPy formattingTraining/validation/test separation You cannot estimate the generalization performance of your predictor/estimator/classifier on its training set You need to keep some samples aside for later evaluationOther â€œfunnyâ€ things to do IRL Collect data Clean data Check data Clean again Annotate Check Compute/convert/scale featuresFeature selection Consists in dropping some data columnsCan help later stages: Less data to process Better properties (like decorrelated features, etc.)Which columns ? Hard problem in general Because features may be informative as a group Some simpler and helpful techniques: Remove features with low variances Dimensionality reduction techniques are not exactly feature selection, but can still have a similar effect Some classifiers - part 1Disclaimer What follows is a very limited selectionOnly classifiers suitable for image classification as we present it today input = feature vectoroutput = labelMany other approachesWhat is our goal ? Given samples (described by features) and true lables, find a good function which will correctly predict labels given new data samplesParametric vs Non Parametric ClassifiersParametric examplesLogisitic regression, Linear Discriminant Analysis, naive Bayes, Perceptrion, Simple Neural Networks.. A learning model that summarizes data with a set of parameters of fixed size (independant of the number of training examples) is called a parametric model. No matter how much data you throw in natureNon-parametric examplesk-Neares Neighbors, Decision Trees, SVMs â€œNon-parametric models differ from parametric models int that hte model structure is not specified a priori but is instead determined from data. The term non-parametric is not meant to imply that such models completely lack parameters but that the number and nature of the parameters are flexible and not fixed in advanceâ€Wikipedia â€œNonparametric methods are good when you have a lot of data and no prior knowledgeâ€Dummy classifiersSay you have a dataset with 9 muffins and 1 chihuahua.You have a new sample to classify.Which class should you bet on ?If your class prior probabilities $P(C_1), P(C_2),\\dots$ are not equal, then you should bet on the most frequent class! ($g(x)=argmax_yp(y)$)Without such information, you can just pick at randomWaht is the expected accuracy (true predictions / total predictions) if you have N classes an pick one at random ? Scikit-learn offers a DummyClassifier class which helps testing such a strategyWhatâ€™s the point ? Quickly build and test your complete pipeline with a mockup classifier Quickly get a baseline for the performance (look for obvious bias in the dataset, but you should have cleaned it before !)K Nearest Neighbor (kNN)Keep all training samplesView new samples as quieries over the previously learned / indexed samplesAssign the class of the closest(s) samples\\[f(x) = y_i, i = argmin_j\\Vert x_j-x\\Vert\\]We can check more than one sampleRemember thi bias/variance compromise ?Pros very simple to implement Capacity easily controlled with k Can be tuned to work on large datasets: indexing, data cleaning, etc. Good baseline Non parametric Lazy learnerCons In high dimension, all samples tend to be very close (for Euclidean dimension) Large memory consumption on large datasets Requires a large amount of samples and large k to get best performance Setting K:\\[K\\simeq\\sqrt{\\frac{m}{C}}\\] $\\frac{m}{C}$: average number of training sample/classOther distance-based classifierMinimal euclidean distanceVery basic classifierDistance to the mean $m_i$ of the classIt does not take into account differencesin variance for each classPredicted class for x:\\[g(x) = argmin_iD_i(x)\\]Minimal quadratic distance (Mahalanobis)For each class $i$, the mean $m_i$ and covariance matrix $S_i$ are computed from the set of examplesThe covariance matrix is taken into account when computing the distance from an image to the class $i$The feature vector of the image $x$ is projected over the eigenvectors of the class\\[g(x) = argmin_iD_i(x)\\]A quick introduction to Bayesian Decision TheoryExample - RoboCupGeneral case: maximum a posteriori (MAP) General case: need to tale into consideration $p(y)$ and $p(x)$ $p(x\\vert y)$: class conditional density (here: histograms) $p(y)$: class priors, e.g. for indoor RoboCup $p(floor) = 0.6$, $p(goal) = 0.3$, $p(ball) = 0.1$ $p(x)$: probability of seeing data $x$Optimal decision rule (Bayes classifier): maximum a posteriori (MAP):\\[g(x) = argmax_{y\\in Y}p(y\\vert x)\\]How to compute $p(y\\vert x)$ ?\\[p(y\\vert x) = \\frac{p(x\\vert y)p(y)}{p(x)}\\quad\\text{Bayes&#39; rule}\\]If classes are equiprobables and error cost is the same, then, because $p(x)$ is constant, we get the maximum likelihood estimation:\\[g(x) = \\underbrace{argmax_{y\\in Y}p(y\\vert x)}_{\\text{MAP}}\\simeq\\underbrace{argmax_{y\\in Y}p(x\\vert y)}_{\\text{ML}}\\]Generative, discriminant and â€œdirectâ€ classifiersGenerative Probabilistic ModelsSome classical Generative Probabilistic ModelsTraining data $X={x-1,\\dots,x_n}$, $Y={y_1,\\dots,x_n}$. $X\\times Y\\in\\mathcal X\\times\\mathcal Y$For each $y\\in\\mathcal Y$, build model for $p(x\\vert y)$ of $X_y:={x_i\\in X:y_i=y}$ Histogram: if $x$ can have only a few discrete values Kernel Density Estimator Gaussian Mixture of Gaussians Typically, $\\mathcal Y$ small (few possibles lables), $\\mathcal X$ low dimensionalClass conditional densities and posteriorsNaive Bayes ClassifiersLinear discriminant classifiersGeneral idea for binary classificationLearn w and b you can compute $p(y\\vert x)\\simeq\\hat y$ Problem: how to learn w and b ?Logistic RegressionLinear classifier, $f$ is logistic function\\(\\sigma(x) = \\frac{1}{(1+e^{-x})} = \\frac{e^x}{(1+e^x)}\\) Maps all real $\\to[0,1]$Optimize $\\sigma(w^Tx+b)$ to find best $w$Trained using gradient descent (no closed form solution)Gradient descentFormally:\\[w_{t+1}=w_t-\\eta\\nabla L(w)\\]Where $\\eta$ is step size, how far to step relative to the gradientFrom 2 classes to C classes: 2 strategies\\[\\hat y = argmax_{i\\in Y}w_ix\\]Maximum Margin classificationWhat is the best $w$ for this dataset ?Trade-off:large margin vs few mistakes on training setSupport Vector Machin (SVM)Logistic Regression vs SVMOptimization problems:About the regularizerEffect of cost parameter C (regularization, again)Non-linear discriminant classifiersNon-linear classificationWhat is the best linear classifier for this dataset? None. We need something nonlinear!2 solutions: Preprocess the data (explicit embedding, kernel trickâ€¦) Combine multiple linear classifiers into nonlinear classifier (boosting, neural networksâ€¦)Non-linear classification using linear classifiers with data preprocessingData preprocessing ideaTransform the dataset to enable linear separabilityLinear separation is always possibleThe original input space can always be mapped to some higher-dimensional feature space where the training set is separable.Explicit embeddingCompute $\\phi(x)$ for all $x$ in the dataset.Then train a linear classifier just like before Used to be avoided because of computation issues, but it is a hot topic again.Kernel trickLinear classification requires to compute only dot products $\\phi(x_i),\\phi(x_j)$The function $\\phi(x)$ does not need to be explicit, we can use a kernel function\\[k(x,z)=\\phi(x)\\phi(z)\\]which represents a dot product in a â€œhiddenâ€ feature space. This gives a non-linear boundary in the original feature space.Popular kernel functions in Computer VisionLinear kernelâ€: identical solution as linear SVMâ€œHellinger kernelâ€: less sensitive to extreme value in feature vectorâ€œHistogram intersection kernelâ€: very robustâ€œ$X^2$-distance kernelâ€: good empirical resultsâ€œGaussian kernelâ€: overall most popular kernel in Machine LearningExplicit embedding for the Hellinger kernelUsing simple square root properties, we have:\\[k(x,xâ€™) = \\phi(x)\\phi(xâ€™) = \\sqrt{x} \\sqrt{x&#39;}\\]Tricks for next practice session: given a BoVW vector, L1 normalize it (neutralizes effect of number of descriptors) Take its square root (explicit Hellinger embedding) L2 normalize it (more linear-classifier friendly)MetricsConfusion matrix and AccuracyProblems with AccuracyAll the following classifiers have a 90% accuracyDo all errors have the same cost?Precision, recall, F-scorePlotting a Precision/Recall for classification dataFor binary classificationInstead of $\\hat y = argmax_yp(y\\vert x)$, take all possible thresholds for $p(y\\vert x)$TPR, FPR, ROCROC: â€œReceiver Operating Characteristicâ€Kind of signaloise measure under various tuningsLigne rose: random resultsMore about ROC curves:Adjusting the thresholdhttp://www.navan.name/roc/Class overlapSplit the dataset to assess generalization performanceBootstrapDraw randomly, with replacement samples from the training set.Enables us to estimate the variance of estimators we use in the classification rule.HoldoutJust keep a part of the dataset for later validation/testingCross validationwith meta parameter tuningStratifiedKFold (best)Missing things Cost of misclassification Multiclass classification evaluation â€¦" }, { "title": "ASE3: TD 2", "url": "/cours/posts/ase3_td2-1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, ACP", "date": "2021-06-16 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Soit \\(X=\\begin{pmatrix} 16 &amp;amp; 2 &amp;amp;0 \\\\ 8&amp;amp;12&amp;amp;10 \\\\ 12&amp;amp;16&amp;amp;14 \\\\ 20&amp;amp;8&amp;amp;14 \\\\ 16&amp;amp;4&amp;amp;10 \\\\ 0&amp;amp;6&amp;amp;12 \\end{pmatrix}\\)On donne le meme poids a tous les individus: $p_i=\\frac{1}{6}$ $\\forall i$ et $M=I_3$ Calculer la moyenne des variables et le centre de gravite Donner la matrice $Y$ Calculer la matrice de var-covariance $V$ Diagonaliser sur $MV=V$ Calculer le $\\%$ dâ€™inertie Facteurs principaux Determiner les composantes principales et calculer les coefficients de correlation Solution\\[\\begin{aligned}&amp;amp;\\begin{matrix}X^{(1)}&amp;amp;X^{(2)}&amp;amp;X^{(3)}\\end{matrix}\\\\X=&amp;amp;\\begin{pmatrix} 16 &amp;amp; 2 &amp;amp;0 \\\\ 8&amp;amp;12&amp;amp;10 \\\\ 12&amp;amp;16&amp;amp;14 \\\\ 20&amp;amp;8&amp;amp;14 \\\\ 16&amp;amp;4&amp;amp;10 \\\\ 0&amp;amp;6&amp;amp;12 \\end{pmatrix}\\end{aligned}\\] 1. $p_i=\\frac{1}{6}$ $\\forall i=1,2,4,5,6$ poids de chaque individu et $M=I_3$ metrique La moyenne des variables:\\[\\bar X^{(1)}=\\sum_{i=1}^6p_iX_i^{(1)} = \\frac{1}{6}\\sum_{i=1}^6X_i^{(1)}=\\frac{72}{6}=12\\\\\\bar X^{(2)}=\\frac{1}{6}\\sum_{i=1}^6X_i^{(2)}=\\frac{1}{6}\\bullet 48=8\\\\\\bar X^{(3)}=\\frac{1}{6}\\sum_{i=1}^6X_i^{(3)}=\\frac{60}{6}=10\\] Donc $\\bar X^{(1)}=12$, $X^{(2)}=8$, $X^{(3)}=10$. Le centre de gravite du nuage forme par les 3 individus:\\[g^T=(12, 8, 10)\\] 2. Tableau des donnees centrees $Y$\\[y_i^{(j)}=X_i^{(j)}=\\bar X^{(j)}\\\\Y=\\begin{pmatrix}4&amp;amp;-6&amp;amp;-10\\\\-4&amp;amp;4&amp;amp;0\\\\0&amp;amp;8&amp;amp;4\\\\8&amp;amp;0&amp;amp;4\\\\4&amp;amp;-4&amp;amp;0\\\\-12&amp;amp;-2&amp;amp;2\\end{pmatrix}\\] 3. Matrice de var-covariance $V=Y^TDY$ avec $D=\\frac{1}{6}I_6$\\[\\Rightarrow V=\\frac{1}{6}Y^TY=\\begin{pmatrix}\\frac{128}{3}&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{68}{3}&amp;amp;\\frac{44}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}\\end{pmatrix}\\] 4. Diagonalisation de $MV=V$ $M=I_3$: metriques de lâ€™espaces des individus $P_V(\\lambda)=det(V-\\lambda I_3)$ polynome caracteristiques de $V$\\[\\begin{aligned}P_v(\\lambda)&amp;amp;=\\begin{vmatrix}\\frac{128}{3}-\\lambda&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{68}{3}-\\lambda&amp;amp;\\frac{44}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}-\\lambda\\end{vmatrix}\\\\C_1\\to C_1&amp;amp;+C_2+C_3\\\\P_v(\\lambda)&amp;amp;=(32-\\lambda)\\begin{vmatrix}1&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\1&amp;amp;\\frac{68}{3}-\\lambda&amp;amp;\\frac{44}{3}\\\\1&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}-\\lambda\\end{vmatrix}\\quad\\text{par linearite}\\\\L_2\\to L_2-L_1&amp;amp;\\text{ et }L_3\\to L_3-L_1\\\\P_v(\\lambda)&amp;amp;=(32-\\lambda)\\begin{vmatrix}1&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\0&amp;amp;28-\\lambda&amp;amp;20\\\\0&amp;amp;20&amp;amp;28-\\lambda\\end{vmatrix}\\\\&amp;amp;= (32-\\lambda)((28-\\lambda)^2-(20)^2)\\\\&amp;amp;= (32-\\lambda)(28-\\lambda-20)(28-\\lambda+20)\\end{aligned}\\\\\\color{red}{\\boxed{P_V(\\lambda) = (32-\\lambda)(8-\\lambda)(48-\\lambda)}}\\] Les valeurs propres de $V$: $\\lambda_1=48$, $\\lambda_2=32$, $\\lambda_3=8$ (ordre decroissant) 5. Le $\\%$ dâ€™inertie Le $1^{er}$ axe: $\\frac{\\lambda_1}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{48}{88}=0,54 = 54\\%$ Le $2^{e}$ axe: $\\frac{\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{32}{88}=0,36=36\\%$ Le $3^{e}$ axe: $\\frac{\\lambda_3}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{8}{88}=0,09=9\\%$ Le plan factoriel: $\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{80}{88}=90\\%$ 6. Les facteurs principaux sont les deux vecteurs propres associes aux valeurs propres $\\lambda_1=48$ et $\\lambda_2=32$.\\[E_{48}=Ker(V-48I_3)\\\\\\forall u=\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}\\in E_{48} \\Leftrightarrow (V-48I_3)\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix} = \\vec 0\\\\\\begin{cases}-\\frac{16}{3}x-\\frac{16}{3}y-\\frac{16}{3}z=0\\\\-\\frac{16}{3}x - \\frac{76}{3}y+\\frac{44}{3}z=0\\\\-\\frac{16}{3}x + \\frac{44}{3}-\\frac{76}{3}z=0\\\\\\end{cases}\\Leftrightarrow\\begin{cases}x+y+z=0\\quad(1)\\\\-16x-76y+44z=0\\quad(2)\\\\-16x+44y-76z=0\\quad(3)\\end{cases}\\\\(2)-(3)\\Rightarrow -120y+120z=0\\Rightarrow\\color{green}{\\boxed{y=z}}\\\\(1)\\Rightarrow\\color{green}{\\boxed{x=-2z}}\\\\E_{48}=Vect(\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix})\\quad\\text{Droite vectorielle}\\\\u^{(1)}=\\frac{1}{\\sqrt{4+1+1}}\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}\\\\\\color{red}{u^{(1)}\\text{ est norme}}\\\\\\Biggr\\Vert\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}\\Biggr\\Vert=\\sqrt{4+1+1} = \\sqrt{6}\\\\E_{32}=Ker(V-32I_3)\\\\\\forall u=\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}\\in E_{32}\\Leftrightarrow (V-32I+3)\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}=\\vec 0\\\\\\begin{cases}32x-16y-16z=0\\quad(1)\\\\-16x-28y+44z=0\\quad(2)\\\\-16x+44y-28z=0\\quad(3)\\end{cases}\\\\\\begin{cases}(2)-(3)&amp;amp;\\Rightarrow\\color{green}{\\boxed{y=z}}\\\\(1)&amp;amp;\\Rightarrow\\color{green}{\\boxed{y=x}}\\end{cases}\\\\\\color{red}{\\boxed{E_{32}=Vect\\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix}\\quad\\text{Droite}}}\\\\u^{(2)}=\\frac{1}{\\sqrt{3}}\\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix}\\quad\\text{norme}\\] $(u^{(1)},u^{(2)})$ base orthonormee 7. Composantes principales\\[C^{(i)}=Yu^{(i)}\\quad i=1,2\\] La $1^{ere}$ composante:\\[\\begin{aligned}C^{(1)}&amp;amp;=Yu^{(1)}=\\begin{pmatrix}4&amp;amp;-6&amp;amp;-10\\\\-4&amp;amp;4&amp;amp;0\\\\0&amp;amp;8&amp;amp;4\\\\8&amp;amp;0&amp;amp;4\\\\4&amp;amp;-4&amp;amp;0\\\\-12&amp;amp;-2&amp;amp;2\\end{pmatrix}\\bullet\\frac{1}{\\sqrt{6}}\\begin{pmatrix}2\\\\-1\\\\-1\\end{pmatrix}\\\\&amp;amp;= \\begin{pmatrix}4\\sqrt{6}\\\\-2\\sqrt{6}\\\\-2\\sqrt{6}\\\\2\\sqrt{6}\\\\2\\sqrt{6}\\\\-4\\sqrt{6}\\end{pmatrix}\\quad\\text{variable centree}\\end{aligned}\\]\\[C^{(2)}=Yu^{(2)}=\\begin{pmatrix}-4\\sqrt{3}\\\\0\\\\4\\sqrt{3}\\\\4\\sqrt{3}\\\\0\\\\-4\\sqrt{3}\\end{pmatrix}\\quad\\text{variable centree}\\] RemarqueCes composantes principales contiennent les projections des individus sur les 2 axes factoriels. Calcul des coefficients de correlation:\\[\\rho(X_1^{(1)}, C^{(1)})=\\frac{Cov(X^{(1)},C^{(1)})}{\\sigma_{X^{(1)}}\\sigma_{C^{(1)}}}\\\\Cov(X^{(1)},C^{(1)})=&amp;lt;y^{(1)},C^{(1)}&amp;gt;={y^{(1)}}^TD.C^{(1)}\\quad\\text{produit scalaire de l&#39;espace des variables}\\\\D=\\frac{1}{6}I_6\\quad\\text{Metriques dans l&#39;espace des variables}\\\\\\color{green}{\\boxed{Cov(X^{(1)},C^{(1)}) = \\frac{1}{6}{y^{(1)}}^TC^{(1)}}}\\]\\[\\begin{aligned}Cov(X^{(1)},C^{(1)})&amp;amp;=\\frac{1}{6}(16\\sqrt{6}+8\\sqrt{6}+16\\sqrt{6}+8\\sqrt{6}+48\\sqrt{6})\\\\&amp;amp;= \\frac{96\\sqrt{6}}{6}=\\color{green}{\\boxed{16\\sqrt{6}}}\\end{aligned}\\\\\\sigma_{X^{(1)}} = \\sqrt{V(X^{(1)})} = \\sqrt{\\frac{128}{3}}\\\\\\begin{aligned}\\sigma_{C^{(1)}}=\\Vert C^{(1)}\\Vert&amp;amp;=\\sqrt{&amp;lt;C^{(1)},C^{(1)}&amp;gt;}\\\\&amp;amp;= \\sqrt{\\frac{1}{6}(96+24+24+24+24+96)}\\\\&amp;amp;=\\color{green}{\\boxed{4\\sqrt{3}}}\\end{aligned}\\\\\\rho(X^{(1)}, C^{(1)}) =\\frac{16\\sqrt{6}}{\\sqrt{\\frac{128}{3}}\\bullet 4\\sqrt{3}} = \\color{green}{\\boxed{\\frac{\\sqrt{3}}{2}}}\\] Tableau des correlations: Â  $C^{(1)}$ $C^{(2)}$ $X^{(1)}$ $\\frac{\\sqrt{3}}{2}=0,87$ $\\frac{1}{2}=0,5$ $X^{(2)}$ $-\\sqrt{\\frac{6}{17}}=-0,59$ $\\frac{2\\sqrt{34}}{17}=0,69$ $X^{(3)}$ $-0,59$ $0,69$ Exercice 2\\[X=\\begin{pmatrix}2&amp;amp;2&amp;amp;3\\\\3&amp;amp;1&amp;amp;2\\\\1&amp;amp;0&amp;amp;3\\\\2&amp;amp;1&amp;amp;4\\\\2&amp;amp;1&amp;amp;3\\end{pmatrix}\\] Calculer $\\bar{X^{(1)}}$, $\\bar{X^{(2)}}$, $\\bar{X^{(3)}}$ et le centre de gravite Calculer la matrice $Y$ Calculer $V$ Diagonaliser $V$ et calculer le $\\%$ dâ€™inertie Facteurs principaux et composantes principales Solution 1.\\[P_i=\\frac{1}{5}\\quad\\forall i\\\\\\bar{X^{(1)}}=2, \\bar{X^{(2)}}=1, \\bar{X^{(2)}}=3\\\\g^T=(2,1,3)\\] 2.\\[Y=\\begin{pmatrix}0 &amp;amp;1&amp;amp;0\\\\1&amp;amp;0&amp;amp;-1\\\\-1&amp;amp;-1&amp;amp;0\\\\0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\end{pmatrix}\\] 3.\\[V = Y^TDY\\\\D = \\frac{1}{5}I_5\\\\\\begin{aligned}V &amp;amp;= \\frac{1}{5}Y^TY\\\\&amp;amp;=\\frac{1}{5}\\begin{pmatrix}2&amp;amp;1&amp;amp;-1\\\\1&amp;amp;2&amp;amp;0\\\\-1&amp;amp;0&amp;amp;2\\end{pmatrix}\\end{aligned}\\\\\\begin{aligned}P_{Y^TY}(\\lambda)&amp;amp;=\\begin{vmatrix}2-\\lambda &amp;amp;1&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-1&amp;amp;0&amp;amp;2-\\lambda\\end{vmatrix}\\quad C_2\\to C_2+C_3\\\\&amp;amp;=\\begin{vmatrix}2-\\lambda &amp;amp;0&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-1&amp;amp;2-\\lambda&amp;amp;2-\\lambda\\end{vmatrix}\\quad L_2\\to L_3-L_2\\\\&amp;amp;= \\begin{vmatrix}2-\\lambda &amp;amp;0&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-2&amp;amp;0&amp;amp;2-\\lambda\\end{vmatrix}\\\\&amp;amp;= (2-\\lambda)((2-\\lambda)^2-2)\\\\&amp;amp;=(2-\\lambda)(2-\\lambda-\\sqrt{2})(2-\\lambda+\\sqrt{2})\\\\\\end{aligned}\\\\\\begin{cases}\\Gamma_1 = 2+\\sqrt{2}\\\\\\Gamma_2 = 2\\\\\\Gamma_3=2-\\sqrt{2}\\end{cases}\\Rightarrow\\begin{cases}\\lambda_1=\\frac{2+\\sqrt{2}}{5}\\\\\\lambda_2 = \\frac{2}{5}\\\\\\lambda_3 = \\frac{2-\\sqrt{2}}{5}\\end{cases}\\]\\[\\%\\quad\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3} = ?\\] Facteurs principaux:\\[E_{2+\\sqrt{2}}=Ker(Y^TY-(2+\\sqrt{2})I) = Vect\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\ 1\\end{pmatrix}\\\\\\color{green}{\\boxed{u^{(1)}=\\frac{1}{\\sqrt{4}}\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\1\\end{pmatrix}}}\\\\\\%\\quad\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3} = 90\\%\\quad\\text{(inertie maximale)}\\\\E_2=Ker(Y^TY-2I_3)=Vect\\begin{pmatrix}0 \\\\ 1 \\\\1\\end{pmatrix}\\\\\\color{green}{\\boxed{u^{(2)}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\ 1 \\\\1\\end{pmatrix}}}\\] Composantes principales:\\[C^{(1)}=Yu^{(1)}=\\begin{pmatrix}-\\frac{1}{2}\\\\-\\frac{\\sqrt{2}}{2}-\\frac{1}{2}\\\\\\frac{\\sqrt{2}}{2}+\\frac{1}{2}\\\\\\frac{1}{2}\\\\0\\end{pmatrix}\\quad\\text{centrees}\\\\C^{(2)}=Yu^{(2}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\-\\frac{1}{\\sqrt{2}}\\\\-\\frac{1}{\\sqrt{2}}\\\\\\frac{1}{\\sqrt{2}}\\\\0\\end{pmatrix}\\]" }, { "title": "ASE3: Analyse en composantes principales", "url": "/cours/posts/ase3_composantes_principales/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, ACP", "date": "2021-06-09 09:00:00 +0200", "snippet": "Lien de la note HackmdDonnees et leurs caracteristiquesTableau des donneesLes observations de $p$ variables sur $n$ individus sont regroupes en une matrice $X$ a $n$ lignes et $p$ colonnes\\[X=\\begin{matrix}te_1 \\\\ \\vdots \\\\ te_i \\\\ \\vdots \\\\te_n\\end{matrix}\\begin{pmatrix}X^{(1)} &amp;amp;\\dots &amp;amp;X^{(j)} &amp;amp;\\dots &amp;amp;X^{(p)}\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots\\\\\\dots&amp;amp;\\dots &amp;amp;\\color{red}{X_i^{(j)}} &amp;amp;\\dots &amp;amp;\\dots\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots\\\\\\dots&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots\\end{pmatrix}\\\\te_i=(X_i^{(1)},X_i^{(2)},\\dots,X_i^{(j)},\\dots,X_i^{(p)})\\\\e_i=\\begin{pmatrix}X_i^{(1)} \\\\ \\vdots \\\\ X_i^{(j)} \\\\ \\vdots \\\\ X_i^{(p)}\\end{pmatrix}\\]\\(X_i^{(j)}\\) est la valeur prise par la variable $X$ sur le ieme individu.Matrice des poidsOn associe a chaque individu un poids $p_i\\ge0$ (probabilite de choisir lâ€™individu)\\[\\sum_{i=1}^np_i=1, D=\\begin{pmatrix} p_1 &amp;amp;0&amp;amp;\\dots&amp;amp;0 \\\\ 0 &amp;amp;p_2&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots &amp;amp;\\vdots &amp;amp;\\ddots&amp;amp;\\vdots\\\\ 0 &amp;amp;0 &amp;amp;\\dots &amp;amp;p_n \\end{pmatrix}\\]Si $p_i=\\frac{1}{n}\\Rightarrow D=\\frac{1}{n}I_n$ ou $I_n$ matrice identite \\(\\begin{pmatrix} 1&amp;amp;0&amp;amp;\\dots &amp;amp;0 \\\\ 0&amp;amp;1&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots&amp;amp;\\vdots&amp;amp;\\ddots &amp;amp;\\vdots \\\\ 0 &amp;amp; 0&amp;amp;\\dots&amp;amp;1 \\end{pmatrix}\\) $\\forall i=1,\\dots,n$Centre de graviteLa vecteur $g$ des moyennes arithmetiques de chaque variable $X^{(j)}$ est definie par $g=(\\bar X^{(1)},\\bar X^{(2)},\\dots,\\bar X^{(p)})$\\[\\bar X^{(j)}=\\sum_{i=1}^np_iX_i^{(j)}\\quad\\text{moyenne de } X^{(j)}\\quad\\forall j\\in [1,p]\\] Le tableau des donnees centrees est la matrice Y telle que\\[y_i^{(j)}=X_i^{(j)}-\\bar X^{(j)}\\quad\\forall j\\in[1,p], \\forall i\\in[1, n]\\]Matrice de variance-covariance et matrice de correlation Definition:On appelle matrice de variance-covariance: \\[V=Y^TDY\\] Si on note $D_{\\frac{1}{S}}$ la matrice diagonale des inverses des ecarts-types:\\[D_{\\frac{1}{S}} = \\begin{pmatrix}\\frac{1}{S_1} &amp;amp;\\dots &amp;amp;0\\\\\\vdots &amp;amp;\\ddots &amp;amp;\\vdots \\\\0&amp;amp;\\dots&amp;amp;\\frac{1}{S_p} \\end{pmatrix}\\]ou: $S_j=\\sqrt{V(X^{(j)})}=\\sqrt{\\sum_{i=1}^np_i(X_i^{(j)}-\\bar X^{(j)})^2}$ $V(X^{(j)})$: variance de $X^{(j)}$ $S_j$: ecart-type de $X^{(j)}$On appelle la matrice des donnees centrees et reduite: $Z$ telle que:\\[Z_i^{(j)}=\\frac{y_i^{(j)}}{S_j}\\] Matriciellement:\\[Z=Y\\bullet D_{\\frac{1}{S}}\\]La matrice regroupant les coefficients de correlation lineaire entre les $p$ variables est $R$:\\[R=\\begin{pmatrix}1&amp;amp;\\dots&amp;amp;p_{ij}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\p_{ij}&amp;amp;\\dots&amp;amp;1\\end{pmatrix}\\quad\\text{symetrique}\\\\r_{ij}=\\underbrace{p_{ij}}_{\\text{coefficient de correlation}}=\\frac{Cov(X^{(i)}, X^{(j)})}{S_iS_j}\\]Ou: $Cov(X^{(i)}, X^{(j)})$: covariance\\[Cov(X^{(i)}, X^{(j)})=\\sum_{k=1}^np_k\\underbrace{y_k^{(i)}y_k^{(j)}}_{\\text{produit scalaire des variables centrees}}\\]Remarque:\\[\\begin{aligned}R&amp;amp;=D_{\\frac{1}{S}}VD_{\\frac{1}{S}}\\\\&amp;amp;=D_{\\frac{1}{S}}Y^TDYD_{\\frac{1}{S}}\\\\&amp;amp;\\Leftrightarrow\\color{red}{\\boxed{R=Z^TDZ}}\\end{aligned}\\]Espaces des individusChaque individu etant un vecteur defini par $p$ coordonnees est considere comme un element dâ€™un espace vectoriel $F$ appele lâ€™espace des individus.Les $n$ individus forment alors un nuage de points dans $F$ et $g$ en est le barycentre (ou centre de gravite).On munit lâ€™espace $F$ dâ€™une metrique (distance):\\[\\underbrace{&amp;lt;e_i, e_j&amp;gt;}_{\\text{produit scalaire}}=e_i^TMe_j\\]ou: $M$ est une matrice symetrique et definie positive (S.D.P)Remarque: si $M=I$ (matrice identite), on se retrouve avec le produit scalaire usuel.Si \\(M=D_{\\frac{1}{S^2}}=\\begin{pmatrix}\\frac{1}{S_1^2}&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots &amp;amp;\\ddots &amp;amp;\\vdots \\\\ 0 &amp;amp;\\dots &amp;amp;\\frac{1}{S_p^2} \\end{pmatrix}\\) cela revient a diviser chaque caractere par son ecart-type.Inertie Definition:On appelle inertie totale du nuage de points la moyenne ponderee des carres des distances des points au centre de gravite:\\[\\begin{aligned}I_g&amp;amp;=\\sum_{i=1}^np_i(e_i-g)^TM(e_i-g)\\\\&amp;amp;=\\sum_{i=1}^np_i\\Vert e_i-g\\Vert^2\\end{aligned}\\]Proprietes de lâ€™inertieOn peut montrer que lâ€™inertie du nuage est egale a la trace de la matrice $MV$:\\[I_g=Trace(MV)=Trace(VM)\\]Espace des variablesOn note $E$: lâ€™espace des variables\\[X^{(j)}=\\begin{pmatrix}X_i^{(j)} \\\\ \\vdots \\\\ X_n^{(j)} \\end{pmatrix}\\]On munit $E$ de la metrique $M=D$ avec D la matrice des poids\\[\\underbrace{&amp;lt;X^{(j)}, X^{(k)}&amp;gt;}_{\\text{produit scalaire}}=(X^{(j)})^TDX^{(k)}\\]Si les variables sont centrees:\\[\\begin{aligned}(X^{(j)})^TDX^{(k)}&amp;amp;=\\sum_{i=1}^np_iX^{(j)}_iX^{(k)}_i\\\\&amp;amp;=Cov(X^{(j)}, X^{(k)})\\end{aligned}\\]La norme de $X^{(j)}$ (variable centree)\\[\\begin{aligned}\\Vert X^{(j)}\\Vert^2&amp;amp;=&amp;lt;X^{(j)}, X^{(j)}&amp;gt;\\\\&amp;amp;=\\sum_{i=1}^np_i(X_i^{(j)})^2=S_j^2\\\\\\Rightarrow\\Vert X^{(j)}\\Vert&amp;amp;=S_j\\quad\\text{ecart-type}\\end{aligned}\\]On mesure lâ€™angle entre 2 variables $X^{(j)}$ et $X^{(k)}$ (centrees):\\[\\cos(\\theta_{jk})=\\frac{&amp;lt;X^{(j)}, X^{(k)}&amp;gt;}{\\Vert X^{(j)}\\Vert\\Vert X^{(k)}\\Vert}\\quad\\text{similarite cosinus}\\\\\\color{red}{\\boxed{\\cos(\\theta_{jk}) = \\frac{Cov(X^{(j)}, X^{(k)})}{S_jS_k} = p_{jk}}}\\] On retrouve le coefficient de correlation lineaire.Variables engendree par un tableau des donneesA une variable $X^{(j)}$, on peut associer un axe de lâ€™espace des individus $F$ et un vecteur de lâ€™espace des variable et on peut egalement deduire $X^{(1)}, X^{(2)},\\dots,X^{(j)}, \\dots, X^{(p)}$ de nouvelles variables par combinaison lineaire.Soit $\\triangle$ un axe de $F$. $\\triangle$ est engendre par un vecteur unitaire $a$ \\((a^T\\underbrace{M}_{\\text{metriques}}a=1)\\) et projetons les individus sur $\\triangle$ (projection $M$-orthogonale)\\[\\begin{aligned}c_i=a^TMe_i&amp;amp;=e_i^TMa\\\\&amp;amp;=&amp;lt;e_i,a&amp;gt;\\quad\\text{produit scalaire}\\end{aligned}\\]La liste des coordonnees $c_i$ des individus sur $\\triangle$ forme une nouvelle variable artificielle $C$\\[C=\\begin{pmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n\\end{pmatrix}=X\\underbrace{Ma}_{=u}=Xu\\]On pose $u=Ma$: facteur\\[\\Rightarrow C=Xu=\\sum_{j=1}^pu_jX^{(j)}\\] Donc la nouvelle variable $C$ est une combinaison lineaire des variables initiales.Lâ€™ensemble des variables $C$ que lâ€™on peut engendrer par combinaison lineaire des vecteurs colonnes de $X$ forme un sous-espace vectoriel (s.e.v.) de $E$ de dimension $\\le p$Remarque: Si $M=I\\Rightarrow u=a$On suppose que les variables sont centrees ($X=Y$) pour simplifier Proposition: \\[V(C) = u^TVu\\quad\\text{variance de }C\\] Demonstration:\\(\\begin{aligned}V(C) &amp;amp;=c^TDc\\\\&amp;amp;= (Xu)^TDXu=u^T\\underbrace{X^TDX}_{V}u\\\\&amp;amp;\\Rightarrow V(C)=u^TVu\\end{aligned}\\)Le but de la methode est dâ€™obtenir une representation approchee du nuage des $n$ individus dans un s.e.v de dimension faible. Ceci sâ€™effectue par projectionIl faut deformer le moins possible les distances en projection, ce qui signifie que lâ€™inertie du nuage projete sur le s.e.v. $F_k$ soit maximale.Soit $P$: la projection $M$-orthogonale sur le s.e.v. $F_k$\\[Pe_i=f_i\\\\P^2=P\\quad\\text{et}\\quad P^TM=MP\\]Le nuage projete est associe au tableau: $XP^T$ car:\\[\\underbrace{f_i=Pe_i}_{\\text{vecteur colonne}}\\Rightarrow \\underbrace{f_i^T=e_i^TP^T}_{\\text{vecteur ligne}}\\]On determine la matrice de var-covariance du tableau $XP^T$:\\[(XP^T)^TD(XP^T)\\quad\\text{(les var sont centrees)}\\\\=PX^TDXP^T\\\\=\\color{red}{\\boxed{PVP^T}}\\]On determine lâ€™inertie du nuage projete: $Trace(PVP^TM)$\\[\\begin{aligned}Tr(PVP^TM)&amp;amp;=Tr(PVMP)\\\\&amp;amp;=Tr(VMP^2)\\quad\\text{car }Tr(AB)=Tr(BA)\\\\&amp;amp;=Tr(VMP)\\end{aligned}\\] Donc lâ€™inertie du nuage projete est $Trace(VMP)$Le probleme est donc de trouver $P$: projection $M-$orthogonale de rang $k$ maximisant la trace de $VMP$, ce qui determinera $F_k$ ($\\text{dim } F_k=k$)Theoreme Theoreme:Soit $F_k$ un s.e.v. portant lâ€™inertie maximale, alors le s.e.v. de dimension $k+1$ portant lâ€™inertie maximale est la somme directe de $F_k$ et du s.e.v. de dimension $1$ $M$-orthognal a $F_k$ portant lâ€™inertie maximale. \\[F_{k+1}=F_k+\\underbrace{b\\mathbb R}_{\\text{dimension }1}\\] Pour obtenir $F_k$ on pourra proceder de proche en proche en cherchant dâ€™abord le s.e.v. de dimension $1$ dâ€™inertie maximale puis le s.e.v. de dimension $1$ $M-$orthogonal au premier dâ€™inertie maximale.On chercher la droite de $\\mathbb R^2$ passant par $g$, maximisant lâ€™inertie du nuage projete sur cette droite, On rappelle la projection $M$-orthogonale sur la droite dirigee par $a$:\\[P=a(a^TMa)^{-1}a^TM\\]Inertie du nuage projete sur cette droite:\\[\\begin{aligned}Tr(VMP)&amp;amp;=Tr(VMa(a^TMa)^{-1}a^TM)\\\\&amp;amp;= \\frac{1}{a^TMa}Tr(VMaa^TM)\\\\&amp;amp;= \\frac{1}{a^TMa}Tr(a^TMVMa)\\\\&amp;amp;=\\frac{a^TMVMa}{a^TMa}\\end{aligned}\\\\\\frac{d}{da}(\\frac{a^TMVMa}{a^TMa})=0\\quad\\text{(*)}\\]Rappel\\[\\frac{d}{da}(\\underbrace{a^TAa}_{\\text{forme quadratique}})=Aa+A^Ta\\] Si $A$ est symetrique:\\[\\frac{d}{da}(a^TAa)=2Aa\\]\\[\\begin{aligned}\\text{(*)} &amp;amp;\\Rightarrow \\frac{(a^Tma)2MVMa-(a^TMVMa)2MA}{(a^TMa)^2}=0\\\\&amp;amp;\\Rightarrow MVMa=\\biggr(\\frac{a^TMVMa}{a^TMa}\\biggr)Ma\\\\&amp;amp;\\Rightarrow VMa=\\biggr(\\frac{a^TMVMa}{a^TMa}\\biggr)a\\\\&amp;amp;\\Rightarrow \\color{red}{\\boxed{VMa=\\lambda a}}\\quad\\text{avec }\\lambda=\\frac{a^TMVMa}{a^TMa}\\end{aligned}\\] Donc $a$ est un vecteur propre de $VM$ associe a $\\lambda$ (valeur propre). Il faut que $\\lambda$ soit maximale.Donc le s.e.v. $F_k$ de dimension $k$ est engendre par les $k$ vecteurs propres de $VM$ associes aux $k$ plus grandes valeurs propres. On appelle composantes principales: \\[C^{(i)}=Yu^{(i)}\\quad u^{(i)}\\text{: facteur}\\] Si les variables initiales sont centrees alors $C^{(i)}=Xu^{(i)}$\\[V(C^{(i)}) = \\lambda i\\quad\\forall i\\]Qualites des representations sur les plans principauxLe but de lâ€™A.C.P. etant dâ€™obtenir une representation des individus dans un espace de dimension plus faible que $p$. Le critere le plus utilise est celui du pourcentage dâ€™inertie totale expliquee on mesure la qualite de $F_k$ par:\\[\\frac{\\lambda_1+\\lambda_2+\\dots+\\lambda_k}{\\lambda_1+\\lambda_2+\\dots+\\lambda_p}\\] Inertie totale:\\[\\lambda_1+\\lambda_2+\\dots+\\lambda_p=I_{tot}\\]Si par exemple $\\frac{\\lambda_1+\\lambda_2}{I_{tot}}=90\\%$, on concoit quâ€™une representation du nuage dans le plan des 2 premiers axes principaux sera tres satisfaisante.Correlations entre composantes principales et variables initialesLa methode la plus naturelle pour donner une signification a une composante principale $C^{(i)}$ est de la relier aux variables $X^{(j)}$ (variables intiales) en calculant les coefficients de correlation lineaire\\[\\rho(X^{(j)}, C^{(i)})\\]et en sâ€™interessant aux plus forts coefficients en valeur absolue\\[\\rho(X^{(j)}, C^{(i)})=\\frac{Cov(X^{(j)}, C^{(i)})}{\\sigma_{X^{(j)}}\\sigma_{C^{(i)}}}\\]\\[Cov(X^{(j)}, C^{(i)}) = &amp;lt;y^{(j)}, C^{(i)}&amp;gt;\\quad\\text{ou }y^{(j)}\\text{ : var centree}\\]" }, { "title": "MLRF: Lecture 04", "url": "/cours/posts/mlrf_fourth_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 4 Introduction Content-based image retrievalasl (CBIR) using bags of features Evaluating CBIR / Ranked Retrieval (RR) systems Texture descriptors Character descriptorsSummary of last lecture Descriptor matching 1-way Cross check Ratio test Radius threshold Descriptor indexing Indexing pipeline: train/query Linear matching kD-Trees FLANN/hierarchical k-Means LSH Aproximate NN problem Projective transformations Translation Rotation Scaling â€¦ Projective Homography estimation Least square RANSAC Geometric validationPractice session 3: Take home messagesTwin it!: Extracting descriptors, matching them by hand Detect keypoints and extract surrounding pixels to flat vector Normalize them and compare them using cross correlation ($\\sum_if_i\\bullet g_i$)Augmented Documents: Use an off-the-shelf detector/descriptor: ORBAugmented Documents: Projective transforms and Homography estimation OpenCV provides the solver for machinery: list of matches $to$ $3\\times 3$ matrix Just som coordinate transform (2D $\\to$ 2D transform) Remember the classical matrix forms: translation, rotation, â€¦Next practice session Implement a simple image search engine Will be gradedLocal feature descriptorsIntroductionGiven some keypoints in image 1, what are the more similar ones in image 2 ? This is a nearest neighbor problem in descriptor spaceThis is also a geometrical problem in coordinate space Local feature detectors give use the same feature under several perturbations: perspective, illumination, blurâ€¦Local feature descriptors will associate a vector to each local feature.Such description vector should be: Compact - to enable fast indexing and matching Discriminative - to enable object recognition Robust to perturbations - to tolerate real conditionsWe will focus on 2 widely used descriptors for their pedagogical interest HOG (Histogram of gradients), used im SIFT BRIEF (Binary Robust Independent Elementary Features), used in ORBHistogram of GradientAlgorithm overview (optional) global image normalization Compute the gradient image in $x$ and $y$ Compute gradient hisograms Normalise across blocks Flatten into a feature vector (quantify to integers)Exemple Cette sensation quand tu cogne ton coude au niveau du nerfSummaryPros Very stable over illuminations changes perpectives changes, blurCons Slow to compute Quite large (128 bytes for original SIFT)BRIEFGeneral idea: Sample pairs of points \\(\\{p(x), p(y)\\}\\) in the smoothed (very spiky otherwise, like derivatives) keypoints neighborhood Compute a simple binary test: $p(x)\\lt p(y)$ Accumulate the results of $n_d$ tests to form a binary vector of $n_d$ bits (256 in ref.)Sampling strategies GI: $(x_i, y_i)\\sim$ i.i.d. Uniform($-\\frac{S}{2}$, $+\\frac{S}{2}$) GII: $(x_i, y_i)\\sim$ i.i.d. Gaussian($0$, $\\frac{1}{25}S^2$) GII: $x_i\\sim$ i.i.d. Gaussian($0$, $\\frac{1}{25}S^2$) $y_i\\sim$ i.i.d. Gaussian($x_i$, $\\frac{1}{100}S^2$) GIV: $(x_i, y_i)$ randomly sampled from discrete locations of a coarse polar grid introducing a spatial quantization GV: $x_i=(0,0)$ $y_i$ takes all possible values on a coarse polar grid containing $n_d$ points What is the best approach ? Câ€™est la strategie 2SummaryPros Very fast to compute Very fast to match Very compact to store Cons Less robust than HoG(SIFT), DoH(SURF) on several real casesInvariance checkRotation invariance Add an angle measure Take the main gradient orientation (Take the averga around the keypoints) We now have for each keypoint: Coordinates OrientationDescriptor: computed over normalized patchScale invarianceMulti scale feature detection and computation: Add a keypoint for each relevant scale Possibly several keypoints at the same positionWe now have for each keypoint: Coordinates Orientation ScaleDescriptor: computed on a scaled patchReminder: Gaussian sigma vs window sizeIllumation invarianceSIFT approach: Normalize the vector Solves Affine but what non-linear sources like camera saturation? Cap the vector elements to $20\\%$ (!) and renormalize Now we have some illumination invariance Viewpoint invarianceBetter, but more complex approaches can tolerate extreme viewpoint changeComplete pipelinesSIFT (Scale invariant feature tr.) Construct scale space Take difference of Gaussians Locate DoG Extrema Sub pixel locate potential feature points Filter edge and low contrast responses Assigne keypoints orientations Build keypoint descriptors Matching, etc.ORB (oriented FAST and rotated BRIEF) Use FAST in pyramids to detect stable keypoints Select the strongest features using FAST or Harris response Finds their orientation using first-order moments Computes the descriptors using BRIEF Where the coordinates of random point pairs are rotated according to the measured orientation Conclusion about feature extractionSelection of appropriate features: It is a critical decision Depends on the specific applicationFeatures must: Be invariant to data variations (depending on the application) rotation perpective noise etc. Have low dimensionality for fast training, matching, reasonable storageFeatures determine the type of info to work with: gray-level, binary, color image contours, vectorization, skeletonFeatures also determine the type of classifier / indexerContent based image retrievalTwo strategies using local descriptorsKeep all local descriptorsPros: Enables geometric validation better part detection in theoryCons: Huge memory requirements Like what we did in practice session 3 to match parts of an image (useful to validate geometric constraints and classify an image at the same time)Build a global descriptor using local ones Inspired by text retrieval Compact representation Tricks to embed spatial information Limited memory requirements Like what we did in practice session 2 with the color histogram, at the bubble level Bag of Feature approachPipeline with local descriptors (prev. lecture)Pipeline with bag of features (current lecture)Features extractionSparse vs Dense detection For dense detection, we usually filter regions with low varianceDimensionality reductionOften used before encoding to: limit dictionary sizes facilitate quantizationSeveral techniques: Principal Component Analysis Signualr-Value DecompositionEncodingBag of Visual Words Modern approaches are derived from this one Reuses ideas of text/we search to images From a set of descriptor, build a histogram of quantized descriptors much alike a color histogramQuantization Discretization of some signal - Lossy process! Vectorial formulation: $f:R^d\\to F$, with $F={1,2,â€¦,k}$ Defines a Voronoi diagram, ie a decomposition of a metric space determined by the distances to a discrete set of pointsBag of Visual Words (continued) Cluster centers are determined using k-Means (once for all on a training set) Each descriptor is quantized: store the code of the closest centroid Build a histogram of descriptor count for each cluster The set of cluster centers is called the dictionary, the codebook or also the visual vocabulary We can choose the number of words !Vector sizeThe resulting vector size for a given image is given by:\\[D=\\text{vocabulary size}\\]Usually, the bigger the vocabulary the better the results.Several thousands of words are common.NormalizationPremiere methodeProblem: The values in the histogram are absolute: each bin count the number of occurence of each visual word This make the descriptor sensitive to the variation of number of descriptorsSolution: Normalize the histogramSeconde technique Like for text retrieval, it is common to reweight the BOVW vectors using the TFDIF technique Goal: give more importance to rare words than to frequent ones For each dimension of the histogram, compute a new value $t_i$Variant: Soft BoVWUse soft assignment to clusters, add counts to neighbor binsOther variantsBoVW is only about counting the number of local descriptorsVLAD: vector of locally aggregated descriptorsFisher vectorIR evalutationHow to evaluate a retrieval system ?We need a set of queries for which we know the expected results â€œGround truthâ€, aka â€œtargetsâ€, â€œgold standardâ€Precision and recallUsed to measure the balance between Returning many results, hence a lot of the relevant results present in the database, but also a lot of noise Returning very few results, leading to less noise, but also less relevant results Precision ( P ) is the fraction of retrieved documents that are relevant: Recall ( R ) is the fraction of relevant documents that are retrieved F-measure F-measure is the wighted harmonic mean of precision and recallHow to evaluate a ranked retrieval system ?When results are ordered, more measures are availables.Common useful measure are: Precision-recall ROC graph nd the area under it (AUC)Precision-recall graphMean-average precisionExample: Compute the AP for a given queryFor this query and the followinf results, plot the precision/recall graph 1, 3 et 9 sont pertinents iciIs the first result relevant ?Oui compute current precision: 1 relevant / 1 retrieved = 1 Recall: 1 relevantRepeter pour chaque resultat Construction du graphe en dent de scie Certaines librairies garde les valeurs superieures, câ€™est pas bienCase 2: what if $\\vert e_i\\vert=4$ ? Ce quâ€™on veut câ€™est lâ€™aire sous la courbe" }, { "title": "POGL: Second class", "url": "/cours/posts/pogl_second_course/", "categories": "Image S8, POGL", "tags": "Image, POGL, S8", "date": "2021-06-02 14:00:00 +0200", "snippet": "Lien de la note HackmdFrame buffer objectQuand on veut faire un rendu de lâ€™offscreen rendering:Calcul final au dernier moment Avantage: ce calcul nâ€™est pas faut pour les points qui ne sont pas visiblesOn va faire un rendu par buffer qui nâ€™est pas visible un pour la couleur un pour la profondeur etcEn tout les points du quadrilateres du rendu on a les couleurs, normales, etc. et on peut en deduire les combinaisons pour le calcul effectif de lâ€™illumination Les combinaisons sont calculees une seule fois pour les points visibles sur un quadrilatere Câ€™est utilise dans les jeux videos pour economiser du tempsOff-screen renderingOn a besoin de pouvoir ecrire pour notre premier rendu similutanement la profondeur, couleur, etc. Pour cela on defini plusieurs variables out dans notre shader (Multi-Render target)Depth shadow maps Avant de faire le rendu final, pour savoir quels sont les objets visibles, on fait le rendu depuis la source lumineuse Faire le rendu en tenant compte de parties visibles ou pas depuis la source lumineuseInitialise FBORendu depuis la source lumineuseRendu depuis la cameraVertex shaderFragment shaderResultatsOn a le z-buffer depuis la source lumineuse On sâ€™attendait a un super resultat mais la partie pas a lâ€™ombre a mal renduePourquoi ?Quand on fait le rendu, on discretise la scene: peut-etre que quand on verifie un pixel on est trop a droite ou trop a gauche, donc des pixels sont consideres a lâ€™ombre alors qui ne le sont pas.Solution: ajout dâ€™un biais Ce biais nâ€™est pas facile a fixer car depend de notre scene, sa taille, la taille des objets, etc. Le lapin profite du soleil avant dâ€™avoir trop chaudSecond depth shadow map Faire le rendu de la scene depuis la lumiere en regardant les faces arrieres des objets On inverse le backface culling On nâ€™a plus besoin du biais Le biais est toutefois plus facile a mettreResultats Il nâ€™y a ni anti-aliasing, ni ombres doucesOn nâ€™a plus dâ€™artefacts et on a un rendu temps reel qui fonctionne tres bien.Pour aller plus loin: sampler2DShadow/textureProj() soft shadow map etc.Rendu finalFrame buffer objectsOn a plusieurs images, a t-1, t et t+1 (par exemple) Rendu dâ€™une position dans une texture/un render buffer Accumulation dans une texutre (Type float sinon les valeurs sont clampees) Copies dans lâ€™image finaleNous en train de courir vers le lapin, ca donne : Au lieu de faire un rendu, on en fait 3Post processingOn a un quadrilatere affiche dont on peut modifier la texture comme on souhaite.Rendu dans une textureOn deforme lâ€™image Notre lapin a trouve des champignons, les a mange mais câ€™etait des champignons hallucinogenesOpenGLObject Picking Lâ€™idee: on va faire un rendu intermediaire off-screen, on associe a chaque objet un identificateurs dans les FBOsLe brouillard ObjectifModifier la couleur en fonction de la distance choisir la fonction On retrouve notre lapin perdu dans le brouillardMoteur de particulesSystemes a base de particules Permet de modeliser des elements difficiles a modeliser avec des solides classiques ou des surfaces feu fumee etc Fonctionnement Caracteristiques position couleur taille forme â€¦ Lois creation destruction Regles (Evolution) Modifications des caracteristiques Le feuUtilisation de particules Creation Plusieurs centaines Apparaissent dans une zone precise Avec une couleur proche du blanc Forme Point Sphere Evolution Changement de couleur Deplacement vers le haut avec perturbations Destruction Atteint la couleur noir Evolution: changement de couleurResultat:Si on est flemmards: utilisation dâ€™un billboard Affichage dâ€™un feu en 2DEtinceles/feu dâ€™artifice/explosionResultat:Câ€™est les memes regles que pour le feuOn fait des bulles qui grossissent de plus en plusBillboardUtilisation dâ€™un BillboardConclusionLes effets intermediares quâ€™on peut faire pour le rendu final." }, { "title": "ASE3: TD 1 - 3", "url": "/cours/posts/ase3_td_1_3/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple, loi conjointe, loi marginale", "date": "2021-06-02 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 6Le nombre de clients arrivants dans un magasin est une v.a. $N$ suivant une loi de Poisson $\\mathcal P(\\lambda)$. Les clients se repartissent entre les $m$ caisses du magasin de facon independante et chaque client choisit sa caisse au hasard.$X_1$ v.a.: nombre de clients qui passent a la caisse n$^o1$. Determiner la loi conditionelle de $X_1$ sachant que ($N=n$) Determiner la loi marginale de $X_1$ Solution 1.\\[\\forall 0\\le k\\le n\\quad P(X_1=k/N=n) = \\binom{n}{k}p^k(1-p)^{n-k}\\quad\\text{ou } p=\\frac{1}{m}\\] Donc $X_1/N\\hookrightarrow\\mathcal B(n,p)$ 2.\\[X_1(\\Omega)=\\mathbb N\\\\\\begin{aligned}\\forall k\\in X_1(\\Omega)\\quad P(X_1=k)&amp;amp;=\\sum_{n=0}^{+\\infty}P((X_1=k)\\cap(N=n))\\\\&amp;amp;=\\sum_{n=0}^{+\\infty}P(X_1=k/N=n)P(N=n)\\\\&amp;amp;=\\sum_{n=k}^{+\\infty}P(X_1=k/N=n)P(N=n)\\end{aligned}\\] Rappel: La loi Poisson\\(P(N=n)=e^{-\\lambda}\\frac{\\lambda^n}{n!}\\quad\\forall n\\in\\mathbb N\\) \\[\\begin{aligned}P(X_1=k)&amp;amp;=\\sum_{n=k}^{+\\infty}\\frac{n!}{k!(n-k)!}p^k(1-p)^ke^{-\\lambda}\\frac{\\lambda^n}{n!}\\\\&amp;amp;= \\frac{p^ke^{-\\lambda}}{k!}\\sum_{n=k}^{+\\infty}\\frac{(1-p)^{n-k}\\lambda^n}{(n-k)!}\\end{aligned}\\] Rappel\\[\\sum_{n=0}^{+\\infty}\\frac{x^n}{n!}e^x\\quad\\forall x\\in\\mathbb R\\] \\[P(X_1=k)=\\frac{p^ke^{-\\lambda}\\lambda^k}{k!}\\sum_{n=k}^{+\\infty}\\frac{((1-p)\\lambda)^{n-k}}{(n-k)!}\\] Posons $j=n-k$\\(\\begin{aligned}P(X_1=k)&amp;amp;=\\frac{(\\lambda p)^ke^{-\\lambda}}{k!}\\sum_{j=0}^{+\\infty}\\frac{((1-p)\\lambda)^j}{j!}\\\\&amp;amp;=\\frac{(\\lambda p)^{k}}{k!}e^{-\\lambda}e^{\\lambda(1-p)}\\\\&amp;amp;=\\frac{(\\lambda p)^k}{k!}e^{-\\lambda p}\\end{aligned}\\\\\\forall k\\in\\mathbb N\\quad\\color{green}{P(X_1=k)=\\frac{(\\lambda p)^k}{k!}e^{-\\lambda p}}\\)Exercice 7$a\\in]0,1[$, $b\\in]0,+\\infty[$$X$ et $Y$ 2 v.a. dont la loi conjointe est donnee par:\\[\\begin{cases}P_{ij}=P((X=i)\\cap(Y=j))=\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!} &amp;amp;\\text{si } i\\ge j\\\\P_{ij}=0&amp;amp;\\text{si } i\\lt j\\end{cases}\\\\X(\\Omega)=Y(\\Omega)=\\mathbb N\\] Determiner les lois marginales ainsi que $E(X)$, $V(X)$, $E(Y)$, $V(Y)$ $X$ et $Y$ sont-elles independantes ? Determiner la loi de $Z=X-Y$ $Y$ et $Z$ sont-elles independantes ? Solution 1.\\[\\begin{aligned}\\forall i\\in\\mathbb N\\quad P(X=i)&amp;amp;=\\sum_{j=0}^iP((X=i)\\cap(Y=j))\\\\&amp;amp;=\\sum_{j=0}^i\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=b^ie^{-b}\\sum_{j=0}^i\\frac{a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=\\frac{b^ie^{-\\lambda}}{i!}\\sum_{j=0}^i\\frac{i!}{j!(i-j)!}a^j(1-a)^{i-j}\\\\&amp;amp;=\\frac{b^ie^{-b}}{i!}\\sum_{j=0}^i\\binom{i}{j}a^j(1-a)^{i-j}\\quad\\text{Fomule du binome de Newton}\\\\&amp;amp;=\\frac{b^ie^{-b}}{i!}(a+1-a)^i\\\\\\end{aligned}\\\\\\color{green}{P(X=i)=e^{-b}\\frac{b^i}{i!}}\\quad\\forall i\\in\\mathbb N\\] Donc $X\\hookrightarrow\\mathcal P(b)$ et $E(X)=V(X)=b$ \\[\\begin{aligned}\\forall j\\in\\mathbb N, P(Y=j)&amp;amp;=\\sum_{i=0}^{+\\infty}P((X=i)\\cap(Y=j))\\\\&amp;amp;= \\sum_{i=j}^{+\\infty}\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=\\frac{e^{-b}a^j}{j!}\\sum_{i=j}^{+\\infty}\\frac{b^i(1-a)^{i-j}}{(i-j)!}\\\\&amp;amp;= \\frac{e^{-b}(ab)^j}{j!}\\sum_{i=j}^{+\\infty}\\frac{(b(1-a))^{i-j}}{(i-j)!}\\\\&amp;amp;=e^{-b}\\frac{(ab)^j}{j!}e^{b(1-a)}=\\frac{(ab)^j}{j!}e^{-ab}\\end{aligned}\\\\\\] Donc $Y \\hookrightarrow\\mathcal P(ab)$ et $E(X)=V(X)=ab$ 2.\\[P_{0,1}=P((X=0)\\cap(Y=1))=0\\\\P(X=0)P(Y=1)=e^{-b}e^{-ab}ab\\neq 0\\] Donc $X$ et $Y$ ne sont pas independantes. 3. La loi de $Z=X-Y=g(X,Y)$ $Z(\\Omega)=\\mathbb N$ car $P_{i,j}=0$ si $i\\lt j$\\[\\begin{aligned}\\forall k\\in\\mathbb N\\quad P(Z=k)&amp;amp;=\\sum_{(i,j) \\\\ i-j=k}P((X=i)\\cap(Y=j))\\\\&amp;amp;=\\sum_{i,j \\\\ j=i-k}P((X=i)\\cap(Y=i-k))\\\\&amp;amp;=\\sum_{i=k}^{+\\infty}\\frac{b^ie^{-b}a^{i-k}(1-a)^k}{(i-k)!}\\\\&amp;amp;=\\frac{e^{-b}}{k!}(1-a)^k\\sum_{i=k}^{+\\infty} \\frac{b^ia^{i-k}}{(i-k)!}\\\\&amp;amp;=\\frac{e^{-b}(1-a)^k}{k!}b^k\\sum_{i=k}^{+\\infty}\\frac{(ab)^{i-k}}{(i-h)!}\\\\&amp;amp;= \\frac{e^{-b}(1-a)^k}{k!}b^ke^{ab}\\\\&amp;amp;=\\frac{((1-a)b)^k}{k!}e^{-(1-a)b}\\end{aligned}\\] Donc $Z\\hookrightarrow\\mathcal P((1-a)b)$ 4. Independances entre $Y$ et $Z$\\[\\begin{aligned}P((Y=j)\\cap(Z=k))&amp;amp;=P((Y=j)\\cap(X=k+j))\\\\&amp;amp;=P((Y=j)\\cap(X=k+j))\\\\&amp;amp;=\\frac{b^{j+k}e^{-b}a^j(1-a)^k}{j!k!}\\end{aligned}\\\\\\begin{aligned}P(Y=j)P(Z=k)&amp;amp;=e^{-ab}\\frac{(ab)^j}{j!}e^{-(1-a)b}\\frac{((1-a)b)^k}{k!}\\\\&amp;amp;=\\frac{e^{-b}a^j}{j!k!}b^{j+k}(1-a)^k\\\\&amp;amp;=P((Y=j)\\cap(Z=k))\\end{aligned}\\]" }, { "title": "VTK-ITK: Traitement d&#39;Image avec ITK", "url": "/cours/posts/vtk_first_course/", "categories": "Image S8, VTK", "tags": "Image, VTK, S8", "date": "2021-05-31 10:00:00 +0200", "snippet": "Lien de la note HackmdInsight Toolkit (ITK) Open source Ecrite en C++ Existe depuis 2000 Environ 267 developpeurs Plus de 500k telechargements Investissement de la part du NIH: ~14M Algorithmes de traitement dâ€™image seulement Pas de UI ou visualisation www.itk.org A chaque fois quâ€™on utilise une bibliotheque open source. il faut le mentionner3 grandes famille de modalites: IRM Rapide et non nocif (a notre connaissance) On voit tres bien la matiere blanche/grise du cerveau Scanner CB scanner, radio (rayons X) Attentions aux rayons X On voit tres biens les os Ultrasons Si on attend un enfant par exemple Non nocifs a notre connaissance MAIS besoin de signer pour une echographie une decharge (au cas ou) Visible humanUn condamne a mort aux US a donne son corps a la science A ete scanner en HD avec les rayons X (apres sa mort) Son corps a ete congele et decoupe en tranche Chaque tranche a ete photographiee Vraie tranche dâ€™Humain Projet tres controverseMAIS Tout le monde a acces aux images Tres utile pour la science 500 Go (pour les annees 2000, quantite enorme de donnees)Pourquoi CMAKE a ete cree Utilisation des images ci-dessus par tout le monde Chacun fait son algo dans son coin Gouvernement US a voulu tout centraliser â€œvisible human toolkitâ€ (aujourdâ€™hui ITK) ITKBoite a outils dâ€™algorithmes de traitement dâ€™image Il nâ€™y a pas dâ€™outils de visualisation/interface graphique dans ITKCa reste une boite a outils et câ€™est pour que ce soit portableDeveloppeurs initiaux dâ€™ITKCombinaison industriels/academiqueTraitement dâ€™imageSegmentationAujourdâ€™hui, le traitement dâ€™image sert a ameliorer le traitement dâ€™image.Pourquoi extraire la taille des ventricules ?La taille des ventricules câ€™est important Lie a lâ€™autisme Evolution de la taille des ventricules: predire lâ€™autisme rapidement chez lâ€™enfant Verifier que les ventricules grandissent correctement Plus tot on arrive a diagnostique, plus tot on arrive a traiter Exemple dâ€™une tumeur: permet de detecter la tumeur + pour le traitement pour lâ€™enleverRecalage Le probleme, câ€™est que le patient est vivantIntegrer ITK dans une application On ne va pas fair dâ€™interface graphique pendant le TPGeneric programming ITK utilise beaucoup les template et est tres tres generique Ca le rend un peu dur a utiliser La STL en C++ Abstraction des types et actionsC++ Utilisation de namespaces Utilisaiton de smart pointers Propre pointeurs de ITK Gestion des exceptionsPython TypesIl faut connaitre le type de pixel sur lequel on travailleStreaming ITK permet de traiter des images qui ne rentrent pas en memoireLe streaming dâ€™ITK partitionne notre grille et applique nos filtres Si on a besoin de quelque chose (bordure, etc) coupe par un filtre En maillage: les ghost cells Similaire en ITK Exemple: convolution sur chaque partie partitionnee mais bordure coupee entre 2Quelle taille pour une image dâ€™un scanner ?Entre 10 et 25 Mo (meme decompresse, rentre largement en memoire) Nos donnees nous appartiennent, les hopitaux sont obliges de nous donner nos scanner/IRM etc.Pour le TP On va travailler en TP sur DICOM Pas en 3DGestion de la memoirePipeline de traitementUn filtre prend une image en entree et une autre en sortieOn combine les filtres entre euxEn tant que traiteur dâ€™image, soit: On creer un nouveau filtre On utilise ce qui existe deja et on combine les filtresSegmentationComment segmenter cette tumeur ? La tranche est a lâ€™envers car le patient est sur le dosConfidence ConnectedOn defini un point (un germe) On agrandit le point Croissance de regionQuâ€™est-ce qui est problematique sur ce genre dâ€™algo ?Le seed point a ete mis a la main Pour un point ca va Mais pour + (genre 15) câ€™est plus durConnected Threshold A nous de definir upper bound et lower boundIsolated connectedDemande 2 seeds (un germe a lâ€™exterieur et un a lâ€™interieur) Calcul la moyenneQuelle methode est la meilleure ?Tout depend de notre image, ce que veut le practicien, etc.Watershed concept Algo qui prend en consideration les intensites mais aussi les contours ITK ne gere pas le streaming sur les algos iteratifsShape detectionRecalage Mise en correspondance dâ€™images afin de pouvoir agreger leurs informationsExactement le meme cas pour les scanners La machine a gauche vaut ~60M dâ€™eurosSi on veut combiner des scanners Rayons X et IRM, il faut faire du recalage Sauf dans le scanner PET-CTRecalage dâ€™une eclipse de Lune (fait a la main sur PowerPoint par Julien Jommier)Composants du recalage Transformation Si on a 2 images, comment est-ce quâ€™on transforme une image qui boufe pour lâ€™aligner avec une autre image ? Metrique (de mise en correspondances) Quand est-ce quâ€™on est alignes ou non Optimiseur Descente de gradient Transformation Translations (deplacements) conserve distances et angles orientes 2 parametres Rotations (isometrie) conserve distances et angles Homotheties (similitude) conserve les rapports entre les distances Affinites conserve le parallelisme 6 parametres Non-lineairesTransformationsAffineQuelle tranformation ?Quelle transformation a ete faite sur cette image ?Homothetie avec juste un parametreTransformations Non-Lineaires Transformations elastiques ou non-rigides Exemples: B-Splines (Combinaison lineaire de Spline) Thin-plate splines Metrique Mesures de similarite(s) entre la cible fixe et la source en mouvement Recalage iconique Somme des differences au carre Coefficient de correlation SSD ProblemeLes 2 images doivent avoir la meme intensite (relation lineaire)Cross-Correlation Convolution sans inverser le signal $\\bar f=$ moyenne de $f$ $\\sigma f=$ ecart type de $f$ Relation affine entre les intensitesInformation mutuelle Issue de la theorie de lâ€™information Relation statistique entre les intensites des 2 images Densite conjointe de probabilite des niveaux de gris Calcul dâ€™un histogramme conjoint Mesure dâ€™entropieHistogramme conjoint: EntropieOu est presente lâ€™information dans notre volume Tres serree: peu dâ€™entropie Un peu partout: beaucoup dâ€™entropieOn a 2 images qui ont bouge, lâ€™histogramme commence a etre diffus:Soit $g(x,y)$ la valeur de lâ€™histogramme conjoint au point [x,y]:Si on a 2 images alignees (meme patient):Optimiseur Descente de gradient Gradient conjugue Algo genetiques Powell LBFGSInterpolateur QuizPremiere questionOn a 2 images du meme patientDeuxieme question a) 2.0 b) 1.0 c) 0.5 Toujours reflechir dans le domaine physique, le patient a toujours le meme cerveau" }, { "title": "MLRF: Lecture 03", "url": "/cours/posts/mlrf_third_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-28 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 3 Introduction Finish lecture about local feature detectors Local feature descriptors Descriptor matching and indexing Projective transformations Homography estimationA word about Divise clusteringHAC is bottom-up, divisive clustering is performed top-downClassical approach: Start with all data Apply flat clustering Recursively apply the approach on each cluster until some terminationPros: can have more than 2 sub-treesSummary of last lectureGlobal image descriptors Color histogram Limited descriptive power Which distance function ?Clustering K-means Hierarchical Agglomerative ClusteringLocal feature detectors Image gradients Edge detector: Sobel, Canny Corner detector: Harris Large image gradient in 2 directions Corner detector: FAST Corner detectors: LoG, DoG, DoH Blob detector: MSERNest practice sessionsCompute and match descriptors for max. 1 hour (from practice session 2)Play with ORB keypoint mathcing to implement a simple AR technique (practice session 3)IntroductionHow are panorama pcitures created from multiple pictures? Detect small parts invariant under viewpoint change: keypoints Find pairs of mathcing keypoints using a description of their neighborhood Compute the most likely transformation to blend images togetherLocal feature descriptorsHarris &amp;amp; Stephen conclusionHarris-Stephens trick to avoid computing eigenvalues: Nowadays linear algebra is cheap, so compute the real eigenvalues.Thein filter using $\\min(\\lambda_1, \\lambda_2)\\gt\\lambda$, $\\lambda$ being a threshold This is the Shi-Tomasi variantBuild your own edge/corner detectorWe need the eigenvalues $\\lambda_1$ and $\\lambda_2$ of the structure tensor (hessian matrix with block-wise summing)dst = cv2.cornerEigenValsAndVecs(src, neighborhood_size, sobel_aperture)dst = cv2.cornerMinEigenVal(src, neighborhood_size, sobel_aperture)Harris summaryProsTranslation invariant Large gradients in both directions = stable pointsConsNot so fast Avoid to compute all those derivativesNot scale invariant Detect corners at different scalesCorner detectors, binary tests FASTFeatures from accelerated segment test (FAST)Keypoint detector used by ORB Segment testCompare pixel $P$ intensity $I_p$ with surrounding pixels (circle of 16 pixels) If $n$ contiguous pixels are either: all darker than $I_p-t$ all brighter than $I_p+t$ then $P$ is detected as a cornerTricks Cascading If $n=12$ ($\\frac{3}{4}$ of the circle) Machine learning How to perform non-maximal suppressionFAST summaryProsVery fast 20 times faster than Harris 40 times faster than DoGVery robust to transformations (perspective in particular)ConsVery sensitive to blurCorner detectors at different scales LoG, DoG, DoHLaplacian of Gaussian (LoG) The theoretical, slow way Band-pass filterIt detects objects of a certain sizeLaplacian = second derivativeLike sobel with 1 more derivationTaylor, again:New filter $I_{xx} = \\begin{bmatrix}&amp;amp;1 &amp;amp;-2 &amp;amp;1\\end{bmatrix} \\times I$Laplacian filter $\\nabla^2I(x,y)$Edge detector, like Sobel but with second derivativesLaplacian of Gaussian mexican hatLoG = detector of circular shapes Detector of circular shapes:LoG filter extrema locates â€œblobsâ€ maxima = dark blobs on light background minima = light blobs on dark backgroundDetecting corners/blobsBuild a scale space representation: stack of images (3D) with increasing $\\sigma$Difference of Gaussian (DoG)Fast approximation of LoG (Used by SIFT) LoG can be approximate by a Difference of 2 Gaussians (DoG) at different scales DoG filterIt is a band-pass filter Lâ€™idee est : â€œest-ce que mes bosses sont comprises entre telles ou telles longueurs dâ€™ondeâ€DoG filterIntuition Gaussian (g) is a low pass filterDoG computation in practiceTake an imageBlur itTake the differenceDoG scale generation trick DoG computation use â€œoctavesâ€ â€œOctaveâ€ because frequency doubles/halves between octaves If $\\sigma=\\sqrt{2}$, then $3$ levels per octave Downsample images for next octave (like double sized kernel) Compute the DoG between imagesDoG: Corner selection Throw out weak responses and edgesEstimate gradients Similar to harris, look at nearby responses Not whole image, only a few points! faster Throw out weak responsesFind cornery things Same deal, structure matrix, use dete and trace info (SIFT variant)Determination of Hessian (DoH) Faster approximationLoG vs DoG vs DoH On prefere un â€œLaplacian of Gaussianâ€ pour detecter les petites etoilesLoG, DoG DoH summaryProsVery robust to transformations Perspective BlurAdjustable size detectorConsSlowBlob detectors MSERMaximally Stable Extremal Regions (MSER) Detects regions which are stable over thresholds Create min &amp;amp; max-tree of the image Tree of included components when thresholdinf the image ar each possible level Le cerveau a une tumeur Select most stable regions between $t-\\triangle$ and $t+\\triangle$ $R_{t*}$ is maximally stable iif $q(t)=\\vert R_{t-\\triangle}\\text{\\ } R_{t+\\triangle}\\vert/\\vert R_t\\vert$ as local minimum at $t^{*}$ SummaryProsVery robust to transformations Affine transformations Intensity changesQuite fastConsDoes not support blurLocal fetaure detectors: Conclusion Harris Stephens: can be very stable when combined with DoG Shi-Tomasi: Assumes affine transformation (avoid it with perspective) DoG: slow but very robust (perspective, blur, illumination) DoH: faster than DoG, misses small elements, better with perspective FAST: very fast, robust to perspective change (like DoG), but blur quickly kills it MSER: fast, very stable, good choice when no blurIntroduction Given som keypoints in image 1, what are the more similar ones in image 2 ? This is a nearest neighbor problem in descriptor space This is also a geometrical problem in coordinate spaceMatchingMatching problem Goal: given 2 sets of descriptors, find the best matching pairsNeed a distanceorm: depends on the descriptor Distribution (histogram)? Stats? Data type ? Float, integers: Euclidean, cosine Binary: Hamming 1-way matching For each $x_i$ in the set of descriptors $D_1$, find the closest element $y_i$ in $D_2$ We have a match $m(x_i, y_i)$ for each $x_i$Symmetry test aka cross check aka 2-way matching For each $x_i$ in the set of descriptor $D_1$, find the closest element $y_i$ in $D_2$ such as $x_i$ is also the closest element to $y_i$Ratio test For each $x_i$ in $D_1$, find the 2 closest elements $y_i$ and $y_j$ in $D_2$Calibrate the ratio Adjust it on a training set !For each correct/incorrect match in your annotated database, plot the next to next closest distance PDF.What is a good ratio in D. Loweâ€™s experiment ?Geometric validationSummaryIndexingIndexing pipelineUse case: We have a database of images and we want to find an object from itBruteforce matching aka linear matching Simply scan all data and keep the closest elementsDoes not scale to large databases, but can be faster on small oneskD-Trees binary tree in which every leaf node is a k-dimensional pointFLANN - Efficient indexing Original version: hierarchical k-means Construction: repetitive k-means on data (then inside clusters) until minimum cluster size is reached Lookup: traverse the tree in a best-bin-first manner with backtrack queue, backtrack until enough point are returnedLocally Sensitive Hasing (LSH) Hash items using family of hash function which project similar items in the same bucket with high probability Not cryptographic hashing !En fonction de quel cote notre separatrice se trouve par rapport au point, on met notre bit a 1 ou 0 Approximation de la distance $\\cos$ en binaireLocality Sensitive Hashing (LSH) Fast and efficient with large spaces and lot of data Return a â€œgood matchâ€, maybe not the best one kNN can be costlyWhich indexing ? ExperimentAdvices for practice session:Projective transformationsA linear transformation of pixel coordinatesImage Mappings OverviewMath. foundations &amp;amp; assumptions For planar surfaces, 3D to 2D perspectives projection reduces to a 2D to a 2D transformation This is just a change of coordinate system This transformation is invertibleTranslationScaleRotationNotation: Partitioned matricesAffineProjectiveMore on projective transform Each point in 2D is actually a vector in 3D Equivalent up to scaling factor Have to normalize to get back to 2D Using homogrpahy to project point Multiply $\\tilde x$ by $\\tilde H$SummaryHomography estimation, Geometric validationWe want to recover H from keypoint matchesRecover the parameters of a perspective transformHow many correspondences are needed ?Depends on the type of transform: How many for translation ? For rotation ? â€¦ For general projective transform ? Reminded: we have 2 knowns for each matchLinear systemUse Linear Least Square to solve $Ma=b$Solve the systemHow reliable is the estimate ?Even worseIs our data perfect ?On a pas mal de bruitOvercoming Least Square Limitations We need a robust estimationRANSAC: RANdom SAmple ConsensusAlgorithmRANSAC works well with extreme noises" }, { "title": "ASE3: TD 1 - 2", "url": "/cours/posts/ase3_td_1_2/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-26 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 3On considere $n$ boites numerotees de $1$ a $n$.La boite $n^{o}k$ contient $k$ boules numerotees de $1$ a $k$. On choisi au hasard une boite puis une boule dans cette boite.Soit: $X$ v.a.: numero de la boite $Y$ v.a.: numero de la boule Determiner la loi conjointe de $(X,Y)$ Calculer $P(X=Y)$ Determiner la loi de $Y$ et $E(Y)$ Solution 1. Loi conjointe\\[X(\\Omega) = [[1,n]]\\\\Y(\\Omega) = [[1,n]]\\]\\[\\begin{aligned}\\begin{matrix}\\forall i\\in X(\\Omega)\\\\\\forall j\\in Y(\\Omega)\\end{matrix}\\Biggr\\}P((X=i)\\cap(Y=j))&amp;amp;=P_{(X=i)}(Y=j)P(X=i)\\quad\\text{Loi conditionnelle}\\\\&amp;amp;=\\frac{1}{i}\\times\\frac{1}{n}\\quad\\text{si } j\\le i\\end{aligned}\\\\\\begin{cases}P((X=i)\\cap(Y=j))=\\frac{1}{in} &amp;amp;\\text{si }j\\le i\\\\P((X=i)\\cap(Y=j))=0 &amp;amp;\\text{si } j\\gt i\\end{cases}\\] 2.\\[\\underbrace{(X=Y)}_{\\text{evenement}} = \\cup_{i=1}^n\\biggr((X=i)\\cap(Y=i)\\biggr)\\\\\\begin{aligned}P(X=Y)&amp;amp;=\\sum_{i=1}^nP((X=i)\\cap(Y=i))\\\\&amp;amp;=\\sum_{i=1}^n\\frac{1}{in}=\\color{green}{\\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}}\\end{aligned}\\] 3. Loi marginale de $Y$\\[\\begin{aligned}\\forall j\\in[[1,n]]\\quad P(Y=j)&amp;amp;=\\sum_{i=1}^nP((X=i)\\cap(Y=j))\\\\&amp;amp;= \\sum_{i=j}^n\\frac{1}{in}=\\color{red}{\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}}\\end{aligned}\\]\\[\\begin{aligned}E(Y)&amp;amp;=\\sum_{j=1}^njP(Y=j)\\\\&amp;amp;= \\sum_{j=1}\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\\\&amp;amp;= \\frac{1}{n}\\sum_{j=1}^nj\\sum_{i=j}^n\\frac{1}{i}\\end{aligned}\\] \\(P(Y=j)=\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\quad\\forall j\\in\\mathbb N^*=Y(\\Omega)\\\\\\) \\[\\begin{aligned}E(Y)&amp;amp;=\\sum_{j=1}^njP(Y=j)\\\\&amp;amp;= \\sum_{j=1}^nj\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}\\sum_{j=1}^ij\\quad\\text{inversion des sommes et } i\\ge j\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}\\frac{i(i+1)}{2}\\\\&amp;amp;=\\frac{1}{2n}\\sum_{i=1}^n(i+1)\\\\&amp;amp;=\\frac{1}{2n}\\biggr(\\frac{n(n+1)}{2}+n\\biggr)\\end{aligned}\\] \\(E(Y) = \\frac{1}{4}(n+3)=\\frac{n+3}{4}\\) Exercice 4Une urne contient une boule blanche et une boule noire, les boules etant indiscernables au toucher. On y preleve une boule, chaque boule ayant la meme probabilite dâ€™etre tiree. On note sa couleur et on la remet dans lâ€™urne avec $c$ boules de la meme couleur.On repete cette experience, on realise une succession de $n$ tirages ($n\\ge 2$).Soit $X_i$ la v.a.\\[1\\le i\\le n\\begin{cases} X_i = 1&amp;amp;\\text{si on obtient une boule blanche au }i\\text{-eme tirage}\\\\ X_i=0&amp;amp;\\text{sinon}\\end{cases}\\\\Z_p=\\sum_{i=1}^pX_i\\quad 2\\le p\\le n\\] Determiner la loi du couple $(X_1,X_2)$. En deduire la loi de $X_2$ Determiner la loi de $Z_2$ Determiner $Z_p(\\Omega)$ Soit $p\\le n-1$. Determiner \\(P_{(Z_p=k)}(X_{p+1}=1)\\) $\\forall k\\in Z_p(\\Omega)$ et montrer que $P(X_{p+1}=1)=\\frac{1+cE(Z_p)}{2+pc}$ Montrer que $\\forall p\\in[[1,n]]$, $P(X_p=1)=\\frac{1}{2}=P(X_p=0)$ Solution 1. $X_1$ suit la loi de Bernouilli $\\mathcal B(\\frac{1}{2})$. On cherche $P((X_1=i)\\cap(X_2=j))$.\\[X_1(\\Omega)=[[0,1]]\\\\X_2(\\Omega)=[[0,1]]\\\\\\] $1^{er}$ cas: $i\\neq j$\\[\\begin{aligned}P((X_1=i)\\cap(X_2=j))&amp;amp;=P(X_2=j/X_1=i)P(X_1=i)\\quad P(X_1=i)=\\frac{1}{2}\\\\&amp;amp;=\\frac{1}{2+c}\\times\\frac{1}{2}\\end{aligned}\\] $2^e$ cas: $i=j$\\[\\begin{aligned}P((X_1=i)\\cap(X_2=j))&amp;amp;=P(X_2=j/X_1=i)P(X_1=i)\\\\&amp;amp;= \\biggr(\\frac{1+c}{2+c}\\biggr)\\times\\frac{1}{2}\\end{aligned}\\] $X_2$ \\ $X_1$ $0$ $1$ Loi de $X_1$ $0$ $\\frac{1+c}{2(2+c)}$ $\\frac{1}{2(2+c)}$ $\\frac{1}{2}$ $1$ $\\frac{1}{2(2+c)}$ $\\frac{1+c}{2(2+c)}$ $\\frac{1}{2}$ Loi de $X_2$ $\\frac{1}{2}$ $\\frac{1}{2}$ $1$ Donc $X_2\\to\\mathcal B(\\frac{1}{2})$ 2.\\[Z_2=X_1+X_2\\\\Z_2(\\Omega)=[[0,2]]\\\\\\]\\[\\begin{aligned}P(Z_2=0)&amp;amp;=P((X_1=0)\\cap(X_2=0))\\\\&amp;amp;=\\color{green}{\\frac{1+c}{2(2+c)}}\\\\P(Z_2=1)&amp;amp;=P((X_1=0)\\cap(X_2=1)) + P((X_1=1)\\cap(X_2=0))\\\\&amp;amp;= \\color{green}{\\frac{1}{2+c}}\\\\P(Z_2=2)&amp;amp;=P((X_1=1)\\cap(X_2=1))\\\\&amp;amp;=\\color{green}{\\frac{1+c}{2(2+c)}}\\end{aligned}\\] 3.1.\\[Z_p=\\sum_{i=1}X_i\\\\Z_p(\\Omega)=[[0,p]]\\] 3.2.\\[p\\le n-1\\quad P_{(Z_p=k)}(X_{p+1}=1)= \\quad \\forall k\\in\\mathbb Z_p(\\Omega)\\] Sachant que $(Z_p=k)$ est realise: $k$ boules blanches ont ete tirees au cours des $p$ premiers tirages (donc on a remis $kc$ boules blanches dans lâ€™urne) et $p-k$ boules noires ont ete tirees (donc on a remis $(p-k)c$ boules noires).Donc au total lâ€™urne contient $2+kc+(p-k)c=2+pc$ boules dont $(1+kc)$ boules blanches. \\[P_{(Z_p=k)}(X_{p+1}=1)=\\frac{1+kc}{2+pc}\\] \\[\\begin{aligned}(X_{p+1}=1)&amp;amp;=U_{k=0}^p((X_{p+1}=1)\\cap(Z_p=k))\\\\P(X_{p+1}=1)&amp;amp;=\\sum_{k=0}^pP((X_{p+1}=1)\\cap(Z_p=k))\\\\&amp;amp;=\\sum_{k=0}^pP_{(Z_p=k)}(X_{p+1}=1)P(Z_p=k)\\\\&amp;amp;= \\sum_{k=0}^p\\biggr(\\frac{1+kc}{2+pc}\\biggr)P(Z_p=k)\\\\&amp;amp;= \\frac{1}{2+pc}\\biggr(\\sum_{k=0}^pP(Z_p=k)+c\\sum_{k=0}^pkP(Z_p=k)\\biggr)\\\\&amp;amp;=\\color{green}{\\frac{1}{2+pc}(1+cE(Z_p))}\\end{aligned}\\] 4.\\[\\forall p\\in [[1,n]]\\quad P(X_p=1)=\\frac{1}{2}=P(X_p=c)\\] Matrices resultat par recurrence sur slurp sur $p$: Soit $R(p)$ la propriete: $P(X_p=1)=\\frac{1}{2}$, $R(1)$, $R(2)$ vraies ($1^{ere}$ question) Hypothese: Supposons que $R(1)$, $R(2)$,â€¦, $R(p)$ vraies.\\[\\begin{aligned}P(X_{p+1}) = \\frac{1+cE(Z_p)}{2+pc}\\quad\\text{or } E(Z_p)&amp;amp;=E(\\sum_{i=1}^pX_i) \\\\&amp;amp;= \\sum_{i=1}^pE(X_i)\\\\&amp;amp;=\\sum_{i=1}^p\\frac{1}{2}\\quad\\text{car } X_i\\to\\mathcal B(\\frac{1}{2})\\quad 1\\le i\\le p \\text{ (hypothese)}\\\\&amp;amp;=\\color{red}{p\\times\\frac{1}{2}=\\frac{p}{2}}\\\\\\end{aligned}\\\\\\begin{aligned}P(X_{p+1})&amp;amp;=\\frac{1+cE(Z_p)}{2+pc}\\\\&amp;amp;=\\frac{1+c\\frac{p}{2}}{2+pc}\\\\\\end{aligned}\\] \\[P(X_{p+1}=1)=\\frac{1}{2}\\] Exercice 5$X$ et $Y$ 2 v.a. independantes suivant la meme loi de Bernoulli $\\mathcal B(p)$ ($p\\in]0,1[$).On pose $U=X+Y$, $V=X-Y$. Quelle est la loi conjointe de $(U,V)$ ? Calculer $Cov(U,V)$ U,V sont-elles independantes ? Solution 1. $U(\\Omega)=[[0,2]]$, $V(\\Omega)=[[-1,1]]$\\[P((U=i)\\cap(V=j))\\quad\\begin{cases}&amp;amp;\\forall i\\in[[0,2]]\\\\&amp;amp;\\forall j\\in[[-1,1]]\\end{cases}\\\\\\begin{cases}U=X+Y\\Rightarrow X=\\frac{U+V}{2}\\\\V=X-Y\\Rightarrow Y=\\frac{U-V}{2}\\end{cases}\\\\\\begin{aligned}P((U=i)\\cap(V=j))&amp;amp;=P\\biggr(\\biggr(X=\\frac{i+j}{2}\\biggr)\\cap\\biggr(Y=\\frac{i-j}{2}\\biggr)\\biggr)\\\\&amp;amp;= P\\biggr(X=\\frac{i+j}{2}\\biggr)P\\biggr(Y=\\frac{i-j}{2}\\biggr)\\color{red}{\\text{ car } X\\text{ et }Y\\text{ sont independantes}}\\end{aligned}\\] $U$ / $V$ $-1$ $0$ $1$ Loi de $U$ $0$ $0$ $q^2$ $0$ $q^2$ $1$ $qp$ $0$ $pq$ $2pq$ $2$ $0$ $p^2$ $0$ $p^2$ Loi de $V$ $qp$ $p^2+q^2$ $pq$ $1$ Exemple:\\[\\begin{cases}U\\Rightarrow1=i\\\\V\\Rightarrow-1=j\\end{cases}\\Rightarrow\\begin{cases}\\frac{i+j}{2}=\\frac{1-1}{2}=0\\\\\\frac{i-j}{2}=\\frac{1+1}{2}=1\\\\\\end{cases}\\Rightarrow\\begin{cases}P(X=0)=q\\\\P(Y=1)=p\\end{cases}\\biggr\\}qp\\] 2. RappelLa covariance est une forme bilineaire symetrique definie positive (produit scalaire sur lâ€™espace des v.a.) \\[\\begin{aligned}Cov(U,V)&amp;amp;=Cov(X+Y,X-Y)\\quad\\color{red}{\\text{bilineaire}}\\\\&amp;amp;=Cov(X,X)-\\underbrace{Cov(X,Y) + Cov(Y,X)}_{0 = \\text{ par symetrie}} - Cov(Y,Y)\\\\&amp;amp;= Cov(X,X)-Cov(Y,Y)\\quad\\end{aligned}\\\\\\begin{aligned}\\text{or: } Cov(X,Y)&amp;amp;=E(X.Y)-E(X)E(Y)\\\\\\Rightarrow Cov(X,X)&amp;amp;=E(X.X)-(E(X))^2\\\\&amp;amp;=V(X)\\end{aligned}\\\\\\begin{aligned}Cov(U,V)&amp;amp;=V(X)-V(Y)\\\\&amp;amp;=0\\quad\\color{red}{\\text{car meme loi}}\\end{aligned}\\] Independantes $\\Rightarrow$ $Cov(X,Y)=0$ $Cov(X,Y)\\Rightarrow$ independantes 3. Independance ?\\[P((U=0)\\cap(V=-1))=0\\neq P(U=0)P(V=-1)=q^3p\\] Donc $U$ et $V$ ne sont pas independantes. " }, { "title": "RSE: Deuxieme cours", "url": "/cours/posts/rse_2/", "categories": "tronc commun S8, RSE", "tags": "tronc commun, S8, RSE", "date": "2021-05-25 14:00:00 +0200", "snippet": "Lien de la note HackmdEvaluation - A rendre et a presenter Le 15/06 avant 14h sur MoodleAnalyse de la politique RSE de votre entreprise Consignes: groupes de MAX 4 personnes (1 une entreprise). Citez votre ou vos sources. Format PDF. 10 min de prez Quels sont les principaux enjeux RSE de lâ€™entreprise Reprenez les 7 questions centrales de la RSE Identifiez au moins 2 actions par question centrale dans votre entreprise Identifiez les indicateurs de mesure retenus pour ces actions ? A quel(s) Objectif(s) de Developpement Durable (ODD) ces actions contribuent-elles ? Selon vous, en tant que partie prenante de cette entreprise, quel est le principal dilemme de responsabilite societale auquel elle a a faire faceRSEDefinition de la RSE (ISO 26000)La responsabilite dâ€™une organisation vis-a-vis des impacts de ses decisions et activites sur la societe et lâ€™environnement se traduisant par un comportement tranparent et ethique qui contribue au developpement durable, y compris a la sante et au bien-etre de la societe prend en compte les attentes des parties prenantes respecte les lois en vigueur et est en accord avec les normes internationales de comportement et qui est integre dans lâ€™ensemble de lâ€™organisation et mis en oeuvre dans ses relationsDe quelles reponsabilites parle-t-on ?RSE: De quoi parle-t-on ? â€œContribution volontaire et obligatoireâ€ des organisation aux enjeux du developpement durable Contribution: car lâ€™entreprise ne peut pas a elle seule regler les maxu de notre societe et que le â€œDeveloppement Durableâ€ depend avant tout des Etats Volontaire: parce que la premiere responsabilite dâ€™une entreprise est economique et que lâ€™action RSE ne se decrete pas, quâ€™elle doit respecter les valeurs de lâ€™entreprise, ses ressources et etre pertinente au regard de sa strategie Obligatoire: le droit a operer sur un territoire, lâ€™acces aux marches et a la commande publique, le reporting extra-financierVideo YouTube Câ€™est quoi la RSE ?Progression des enjeux cle de lâ€™entrepriseBut: remplir les casesUn levier de performanceRenforcement du capital financierExemples Depot dâ€™un brevet Capital intellectuel Diminution du poids des emballages et suremballages Capital nature Amelioratoin de lâ€™isolation des locaux Capital physique Rappel immediat dâ€™un produit defectueux Capital image Nomination dâ€™un manager manquant de leadership Capital humain Paiement aux fournisseurs dâ€™un prix inferieur au conditions generales Capital relationnel Le cadre reglementaire en FranceLa loi NRE et la loi Grenelle 22001: loi NRE (Nouvelles Regulations Economiques), article 116 imposait aux societes cotees: la publication, au sein de leur rapport de gestion annuel, des informations sur les consequences sociales et environnementales de leurs activitesArticle 225 de la loi Grenelle 2 de Juillet 2010La transposition de la directive europeenne sur le reporting extra-financierLes entreprise concernees sont: les societes cotees: celles des plus de 500 salaries avec un total de bilan depassant 20M dâ€™eurosLa declaration doit fournir des informations concernant:La loi sur le devoir de vigilance La loi relative au â€œdevoir de vigilance des societes meres et des entreprises donneurses dâ€™ordreâ€, promulguee le 27 mars 2017, permet desormais de responsabiliser les grandes societes meres et entreprises donneuses dâ€™ordre dans lâ€™ensemble de leurs filiales et le long de leur chaine de production 150 a 200 entreprises seraient concernees. Il sâ€™agit de societes, ayant plus de 5 000 salaries et dont le siege est situe en France, ou bien 10 000 salaries et un siege a lâ€™etranger Les â€œplans vigilanceâ€ sont attendus en 2018 et le bilan de leur mise en oeuvre en 2019La loi Pacte Introduire la notion de raison dâ€™etre et dâ€™entreprise a la mission Augmenter le nombre dâ€™administrateurs salaries dans les conseils dâ€™administration (y compris dans les mutuelles, unions et federations)ISO 26000: Lignes directrices de la RSEParties prenantesRelever les interets partagesRSE: le cadre de referenceLe cadre de referenceCadre normatif et regelementairePrincipes et thematiques centrales de la RSEQuestion centrale 1: Gouvernance de lâ€™organisation La gouvernance de lâ€™organisation est le systeme par lequel une organisation prend des decisions et les applique en vue dâ€™atteindre ses objectifsDomaines dâ€™action Principes, vision et valeurs Approche strategique et objectifs Planification de lâ€™integration et du deploiement de la responsabilite societale Deploiement de la responsabilite societale Surveillance des performances Amelioration de lâ€™organisation Application du principe de redevabilite Relation avec les parties prenantes Respect des loisQuestion centrale 2: Droits de lâ€™Homme Les droits de lâ€™Homme sont les droits fondamentauxDomaines dâ€™action DA1: devoir de vigilance DA2: Situations presentant un risque pour les droits de lâ€™Homme DA3: Prevention de la complicite DA4: Remedier aux atteintes aux droits de lâ€™Homme DA5: Discrimination et groupes vulnerable DA6: Droits civils et politiques DA7: Droits economiques, sociaux et culturels DA8: Principes fondamentaux et droits au travailQuestion centrale 4: EnvironnementDomaines dâ€™actions DA1: La prevention de la pollution DA2: Lâ€™utilisation durable des ressources DA3: Attenutation des changements climatiques DA4: Protection de lâ€™environnement et rehabilitation des habitats naturelsQuestion centrale 5: Loyaute des pratiquesDomaines dâ€™actions DA1: Lutte contre la corruption DA2: Engagement politique responsable DA3: Concurrence loyale DA4: Promotion de la responsabilite societale dans la chaine de valeur DA5: Respect des droits de la proprieteQuestion centrale 6: Questions relatives aux consommateursDomaines dâ€™actions DA1: Pratiques loyales en matiere de commercialisation, dâ€™informations et de contrats DA2: Protection de la sante et de la securite des consommateurs DA3: Consommation durable DA4: Servie apres-vente, assistance et resolution des reclamations et litiges pour les consommateurs DA5: Protection des donnees et de la vie privee des consommateurs DA6: Acces aux services essentiels DA7: Education et sensibilisationQuestion centrale 7: Communautes et developpement localDomaines dâ€™actions DA1: Implication aupres des communautes DA2: Education et culture DA3: Creation dâ€™emplois et developpement des competences DA4: Developpement des technologies et acces a la technologie DA5: Creation de richesses et de revenus" }, { "title": "MLRF: Lecture 02", "url": "/cours/posts/mlrf_second_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-21 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 2 Introduction Global image descriptors Clustering Local feature detectorsIntroductionSummary of last lectureMachine learning Machine learning = searching for the best model in a hypothesis space Inductive machine learning, optimization-based Inductive bias, bias/vairance compromise Supervised, reinforcement, unsupervised learning Regression, classification, density estimation Model validation: test generalisation, separate/decorrelate test &amp;amp; training setsTemplate matching Sum of squared differences $(T-I)^2$, or correlation-based methodes ($T\\times I$) Normalization needed for correlation-based methods Tolerates translation and small noise, but not rotation, intensity shift, â€¦Debrief of practice session 1PS1 content Jupyter tricks NumPy reminders Intro to image manipulations Twin it! part 1: template matching (Bonus level: segmentation)Take home messages How annoying was it to manually adjust color thresholds to select the duck ?How could have we automated it ?Results with method SQDIFF_NORMED (lower is better) Strengths and weaknesses of template matching for the Twin It! case ?Effects of normalization ?Next practice sessionTwin it! again, with a slightly more elaborated approach Pre-selected bubbles based on their colors $\\Rightarrow$ color histogramsColor histogram: in details1.1 Color quantization: reduce the colors of the bubbles1.2. Compute the color histogram of each bubble1.3. Compute the distance matrix between each bubble, using its color histogram1.4 Visualize the bubbles in an interesting way using hierarchical clustering2.For the pre-selected bubbles, check their content is similar $\\Rightarrow$ Detect stable points and extract the patches around them Compare (match) those patches Image descriptorsIssues with method based on pixel comparisonWhat is important ? What do they consider? Raw pixels! We want to be able to make use of domain knowledge Like sensitivity to shape, or dominant color information OverviewDifferent sizes and contents Different kinds of descriptorsDifferent problems $\\Rightarrow$ Different choices Computation/memory constraints Which perturbations do we have to tolerate ?Global image descriptorsTwo approachesGlobal image descriptors Compute statistics about the content of the image Produce a single global vector Very attractive because they are very fast to compute and match, butâ€¦Bag of Features techniques (lecture 4) Select regions of interest in the image (may be a variable quantity) Compute descriptors for each region Index each part separately (like a text seach engine which indexes words) It is always possible to build a sing descriptors from multiple onesColor histogramsHigh invariance to many transformation rotation, scaling thanks to normalization, perspectiveBut limited discriminative powerEasy to implement Reduce the colors (opt. when performing backprojection) Compute a reduced color histogram on each image Use a distribution distance to compare the descriptorsSome results on Twin It!Steps by step1: Color reduction use K-Means or any other clustering technique to find N useful colors Project each pixels One possible result on the Twin It! poster2: Histogram computationYou already know it (Normalize it)3: Descriptor comparisonOther global image descriptorMore global descriptorsGIST of a scene: Oliva, Torralba, â€œModeling the shape of the sceneâ€Global descriptorsDrawbackAccordin to F. Perronnin:Highly efficient to compute and to match $\\Rightarrow$ perfect in theory But robusteness vs informativeness tradeoff is hard to set(personal conclusion) Approache based on global image descriptors are confined to near-duplicate detection applications until now Modern search engine uses local representations and leverage themClusteringFinding groups in dataMany techniques: Connectivity models hierarchical clustering,â€¦ clustering = set of neighbors Centroid models: k-means cluster = centroid point Distribution model Gaussian mixtures models est. w. Expection maxim cluster = statistical distribution Density models Graph-based modelsAlways the same goal: Minimise the differences between elements within the same cluster Maximise the differences between elements within different clusterNumber of clusters: Many methods require to choose it beforehand Several techniques to adjust the number of clusters automaticallyOutliers rejection: Some techniques do not assign lonely points to any cluster Focus on HAC and K-Means todayHierarchical Agglomerative ClusteringSome linkage types Single linkage minimizes the distance between the closest observations Maximum or complete linkage Average linkage Centroid linkage Waard criterionDivisive clusteringHAC is bottom-up, divisive clustering is top-downClassical approach: Start with all data Apply flat clustering Recursively apply the approach on each cluster until some terminationPros: can have more than 2 sub-trees, must faster than HACCons: same issues as flat clustering, non-determinismK-meansK-Mean clustering (again) The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion it does not maximizes inter-cluster disantce it puts centers so as to get the best coverage (may not be on a density peak !)AlgorithmInitialization: Randomly selected cluster centers Calculate distance oiunts $\\Leftrightarrow$ centers Assign each point to closest center Update cluster centers: avg of pointsResult: centroid centers local maximax tessellation / Voronoi set over the datasetThe previous algorithm is called â€œBatch K-Meansâ€ or simply â€œK-Meansâ€ because it considers the whole dataset at each iteration.Batcj K-Means is not only sensible to outliers and initialization, it is also very slow to compute on large datasets..It is possible to avoid this speed/memory issue by randomly smapling the dataset at each step. Results are only slightly worse Speed and memory requirements make it usable on bigger datasets This approach is call â€œOnline K-Meansâ€ or â€œMiniBatch K-Meansâ€Application: Color quantizationMany clustering techniques to play with !Evaluation of clusteringNeed some supervision ?By construction, clustering algorithms are optimal as they are expect to find some optimal balance between high intra-cluster similarity and low inter-cluster similarity, on their training set.How do these internal criteria translate into good effectiveness for applications ?A common approach is to rely on labeled data to compute new indicators: Purity: sort of â€œagreementâ€ inside each cluster Normalized Mutual Information (NMI) and Entropu: information measures Rand Index (RI) and F measure: error countsModern density estimation point of viewBut what about if we leave some samples out for testing the generalization ?HAC or K-Means â€œoverfitâ€ the underlying data distribution.It does not alway make sense, but if we are interested in density estimation, then we can assess how well our model estimates the probability $P(x)$ of unseen data. The â€œEâ€ step of the EM algo is based on this idea.Local feature detectorsIntroduction How are panorama pictures created from multiple pictures ? Detect small parts invariant under viewpoint change: â€œKeypointsâ€ Find pairs of amthcing keypoints using a description of their neighborhood Compute the most likely transformation to blend images togetherSome classical detectorsEdge (gradient detectors) Soble CannyEdge detectorsWhatâ€™s an edge ? Image is a function Edges are rapid changes in thi function The derivative of a function exhibits the edges Gris = elevation comme dans le watershedImage derivativesRecall: We donâ€™t have an â€œactualâ€ function, must estimate Possibility: set $h=1$ Apply filter -1 0 +1 to the image ($x$ gradient) We get terribly spiky resultsWe need to interpolate/smooth Gaussian filterWe get a sobel filterSobel filterGradient magnitude with SobelCanny edge detection Extract real lines !Non-maximum suppressionFinalizationCorner detectorsGood featuresGood features are unique! Can find the â€œsameâ€ feature easily Not mistaken for â€œdifferentâ€ featuresGood features are robust under perturbation Can detect them under translation, rotation Intensity shift NoiseHow can we find unique patches ?Sky? Bad! Very little variationEdge? OKCorners? Good!Self-differenceHarris corner detector Naive computation: Bon a partir de maintenant câ€™est que des screens parce que le prof traceThis allows us to â€œsimplifyâ€ the original equationand more important making it faster to compute, thanks to simpler derivatives which can be computed for the whole image.If we developp the equation and write it as usual matrix form, we get:where $A(x,y)$ is the structure tensor:This trick is useful because $I_x$ and $I_y$ can be computed very simply. The need for eigenvaluesIf the edge is rotated, so are the values of $I_x$ and $I_y$.Eigenvalues give us the ellipsis axis lens.Summary" }, { "title": "ASE3: TD 1", "url": "/cours/posts/ase3_td_1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-19 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Soit $X$ et $Y$ deux v.a. telles que $Y=X^2$.La loi de $X$ est donnee par $X_i$ $-2$ $-1$ $0$ $1$ $2$ $P(X=X_i)$ $\\frac{1}{6}$ $\\frac{1}{4}$ $\\frac{1}{6}$ $\\frac{1}{4}$ $\\frac{1}{6}$ Determiner la loi du couple $(X,Y)$ (Loi conjointe) Determiner la loi de $Y$ $X$ et $Y$ sont-elles independantes ? Calculer $Cov(X,Y)$ Solution $Y=X^2$, $Y(\\Omega)={0,1,4}$ 1. $X/Y$ $0$ $1$ $4$ Loi de $X$ $-2$ $0$ $0$ $\\frac{1}{6}$ $\\frac{1}{6}$ $-1$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{6}$ $0$ $0$ $\\frac{1}{6}$ $1$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{4}$ $2$ $0$ $0$ $\\frac{1}{6}$ $\\frac{1}{6}$ Loi de $Y$ $\\frac{1}{6}$ $\\frac{1}{2}$ $\\frac{1}{3}$ $1$ $P((X=i)\\cap(Y=j)) = 0$ si $j\\neq i^2$ Avec $j=i^2$, $P((X=i)\\cap(Y=i^2))=P(X=i)$ car \\(\\underbrace{(X=i)}_{A}\\subset\\underbrace{(Y=i^2)}_{B}\\) $A\\cap B=A$ 2. Loi de $Y$ (Loi marginale) Dâ€™apres le tableau $P(Y=0)=\\frac{1}{6}$, $P(Y=1)=\\frac{1}{2}$ et $P(Y=4)=\\frac{1}{3}$ 3. Independance?\\[P((X=i)\\cap(Y=j))=P(X=i)P(Y=j)\\quad\\forall (i,j)\\]\\[P((X=-2)\\cap(Y=4))=\\frac{1}{6}\\\\P(X=-2)P(Y=4)=\\frac{1}{6}\\times\\frac{1}{3}=\\frac{1}{18}\\neq\\frac{1}{6}\\] $X$ et $Y$ ne sont pas indendantes 4.\\[Cov(X,Y)=E(XY)-E(X)E(Y)\\\\E(XY)=\\sum_{i,j}ijP((X=i)\\cap(Y=j))\\\\\\color{red}{E(XY)=\\sum_{i,j}ijP_{i,j}}\\] $X/Y$ $0$ $1$ $4$ Loi de $X$ $-2$ $0$ ($\\times 0$) $0$ ($\\times -2$) $\\frac{1}{6}$ ($\\times -8$) $\\frac{1}{4}$ $-1$ $0$ ($\\times 0$) $\\frac{1}{4}$ ($\\times -1$) $0$ ($\\times 0$) $\\frac{1}{6}$ $0$ $\\frac{1}{6}$ ($\\times 0$) $0$ ($\\times 0$) $0$ ($\\times 0$) $\\frac{1}{6}$ $1$ $0$ ($\\times 0$) $\\frac{1}{4}$ ($\\times 1$) $0$ ($\\times 4$) $\\frac{1}{4}$ $2$ $0$ ($\\times 0$) $0$ ($\\times 2$) $\\frac{1}{6}$ ($\\times 8$) $\\frac{1}{6}$ Loi de $Y$ $\\frac{1}{6}$ $\\frac{1}{2}$ $\\frac{1}{3}$ $1$ \\(E(X,Y)=-\\frac{8}{6}-\\frac{1}{4}+\\frac{1}{4}+\\frac{8}{6}=0\\)\\(\\begin{aligned}E(X) &amp;amp;=\\sum_ix_iP(X=x_i)\\\\&amp;amp;=-\\frac{2}{6}-\\frac{1}{4}+\\frac{1}{4}+\\frac{2}{6}=0\\end{aligned}\\\\\\Rightarrow \\color{green}{Cov(X,Y)=0}\\)Exercice 2$a\\in\\mathbb R^{*}_+$$X,Y$ un couple de v.a. a valeurs dans $\\mathbb N$\\[\\underbrace{P((X=k)\\cap(Y=j))}_{\\text{Loi conjointe}}=\\frac{a}{2^{k+1}(j!)}\\quad\\forall (k,j)\\in\\mathbb N\\] Determiner $a$ $X$ et $Y$ sont-elles independantes $Cov(X,Y)$ Solution 1.\\[\\sum_{k,j}P_{k,j}=1\\\\\\sum_{k=0}^{+\\infty}\\sum_{j=0}^{+\\infty}\\frac{a}{2^{k+1}(j!)}=1\\\\a\\sum_{k=0}^{+\\infty}\\frac{1}{2^{k+1}}\\sum_{j=0}^{+\\infty}\\frac{1}{j!}=1\\] Rappel \\(e^X=\\sum_{j=0}^{+\\infty}\\frac{x^j}{j!}\\\\X=1\\quad\\color{red}{e=\\sum_{j=0}^{+\\infty}\\frac{1}{j!}}\\\\\\) \\[\\color{red}{ae\\sum_{k=0}^{+\\infty}\\frac{1}{2^{k+1}}=1}\\] Rappel (Serie geometriques) \\(\\color{red}{\\sum_{k=0}^{+\\infty}X^n=\\frac{1}{1-X}\\quad\\vert X\\vert\\lt1}\\) \\[ae\\frac{1}{2}\\sum_{k=0}^{+\\infty}\\biggr(\\frac{1}{2}\\biggr)^k=1\\\\\\begin{aligned}ae\\frac{1}{2}\\frac{1}{\\frac{1}{2}}=1&amp;amp;\\Rightarrow ae=1\\\\&amp;amp;\\Rightarrow \\color{green}{a=\\frac{1}{e}}\\end{aligned}\\] 2. Independance ?\\[P((X=k)\\cap(Y=j))=P(X=k)P(Y=j)\\] Loi marginale de $X$ \\(\\forall k\\in\\mathbb N\\quad P(X=k)=\\sum_{j=0}^{+\\infty}P_{k,j}\\)\\(\\begin{aligned}P(X=k)&amp;amp;=\\sum_{j=0}\\frac{a}{2^{k+1}(j!)}=\\frac{a}{2^{k+1}}\\sum_{j=0}^{+\\infty}\\frac{1}{j!}\\\\&amp;amp;=\\frac{ae}{2^{k+1}}=\\frac{1}{2^{k+1}}\\\\\\end{aligned}\\\\\\color{green}{P(X=k)=\\frac{1}{2^{k+1}}\\quad\\forall k\\in\\mathbb N}\\) Loi marginale de $Y$\\[\\forall j\\in\\mathbb N\\quad\\\\\\begin{aligned}P(Y=j)&amp;amp;=\\sum_{k=0}^{+\\infty}\\frac{a}{2^{k+1}(j!)}\\\\&amp;amp;=\\frac{a}{j!}\\frac{1}{2}\\sum_{k=0}^{+\\infty}\\biggr(\\frac{1}{2}\\biggr)^k=\\frac{a}{j!2}2=\\color{green}{\\frac{1}{ej!}}\\end{aligned}\\] La loi de $Y$:\\[\\forall j\\in\\mathbb N\\quad \\color{green}{P(Y=j)=\\frac{1}{ej!}}\\] Independance ?\\[\\begin{aligned}P(X=k)P(Y=j)=\\frac{1}{2^{k+1}}\\times\\frac{1}{ej!}\\\\P((X=k)\\cap(Y=j))=\\frac{1}{e2^{k+1}j!}\\end{aligned}\\Biggr\\}=\\text{ donc OK}\\] 3. $X$ et $Y$ etant independantes donc $Cov(X,Y)=0$" }, { "title": "ASE3: Couple de variables aleatoires discretes et analyse des donnees - 2", "url": "/cours/posts/ase3_couple_va_1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-19 09:00:00 +0200", "snippet": "Lien de la note HackmdRappels \\(\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma_x\\sigma_y}\\)avec: $\\sigma_X=\\sqrt{V(X)}$ $\\sigma_Y=\\sqrt{V(Y)}$ \\[Cov(X,Y)=\\underbrace{&amp;lt;X-E(X),Y-E(Y)&amp;gt;}_{\\text{produit scalaire}}\\\\\\sigma_X=\\sqrt{V(X)}=\\Vert X-E(X)\\Vert\\\\\\rho(X,Y)=\\frac{&amp;lt;X-E(X), Y-E(Y)&amp;gt;}{\\Vert X-E(X)\\Vert\\Vert Y-E(Y)\\Vert}\\]\\[\\cos(\\theta)=\\frac{&amp;lt;u,v&amp;gt;}{\\Vert u\\Vert\\Vert v\\Vert}\\] \\(\\rho(X,Y) = \\cos(\\theta)\\\\\\vert\\rho\\vert\\le 1\\) Proposition \\(V(X+Y)=V(X)+V(Y)+2Cov(X,Y)\\) Demonstration\\[\\begin{aligned}V(X+Y)&amp;amp;=E((X+Y)^2) - (\\underbrace{E(X+Y)}_{E(X) + E(Y)})^2\\\\&amp;amp;=E(X^2+2XY+Y^2)-E^2(X)-2E(X)E(Y)-E^2(Y)\\\\&amp;amp;= E(X^2)+2E(XY) + E(Y^2)-E^2(X)-2E(X)E(Y)-E^2(Y)\\\\&amp;amp;=V(X) +V(Y)+2(E(XY)-E(X)E(Y))\\\\&amp;amp;=\\color{red}{V(X)+V(Y)+2Cov(X,Y)}\\end{aligned}\\]Remarque: Si $X$ et $Y$ sont independantes $\\Rightarrow$ $Cov(X,Y)=0\\Rightarrow\\color{red}{V(X+Y) = V(X)+V(Y)}$" }, { "title": "MLRF: Lecture 01", "url": "/cours/posts/mlrf_first_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-14 10:00:00 +0200", "snippet": "Lien de la note HackmdScope of this course Apply Machine Learning (ML) techniques to solve some practical Computer Vision (CV) problems About Computer Vision (CV) It should be called CV-ML, ML4CV or soâ€¦We need some definitions: What is Computer Vision ? What is Pattern Recognition ? Shape Recognition ? What is Machine Learning ? How do those concepts relate together ?Agenda for lecture 1 Some definitions and basic notions Course outline Introduction to Twin it ! Pattern MatchingSome definitionsComputer Vision DefinitionThe automation of visual tasks with the goal of producing results directly or indirectly usable by humans Input: image(s) in machine format (image acquisition of a subpart of CV) Output: some piecesExemple How would you process image pixels to get those results ? Les photos de chats sur Internet câ€™est important Some applications are direct (like the insect recognition app): a human reads and uses the output Some applications are indirect (like bank checking reading) The output is fed to a business system Some applications extend what humans can naturally do Either by extending our range Pattern Recognition DefinitionThe field of a pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take action such as classifying the data into different categories Bishop, 2006 IAPR: pattern recognition, computer vision and image processing in a broad senseExamples OCR Computer vision Pedestrian detection Computer Vision Credit fraud detection Not computer vision $\\Rightarrow$ CV$\\cap$PR$\\neq\\emptyset$Pattern Recognition is an inverse problem OCR example - Why Pattern Recognition is hardâ€œShapesâ€ DefinitionA way to designate meaningful visual patterns.Sometimes used to describe â€œvisual perceptsâ€Let S and Sâ€™ be 2 shapes observed in 2 different images which happen to be similar. Some statistics can help us making better decisionsâ€¦ Idea: learn the distance threshold under which shapes can be deemed identicalMachine LearningMany forms of Machine Learning Focus on inductive learning (generalize from examples) We will consider both supervised (a â€œteacherâ€ provides labels for examples) and unsupervised (only samples) Focus on optimization-based learning techniques (examples are represented as numerical vectors)Examples of optimization-based learning techniques Linear classifiers, SVMs Neural networks(â€œStatisticalâ€) Machine Learning Learning means changing in order to be better (according to a given criterion) when a similar situation arrivesLearning IS NOT learning by heartAny computer can learn by heart, the difficulty is to generalize a behavior to a novel situationQuoting S. BengioFrom an engineerâ€™s POV Machin Learning is about building programs with tunable parameters (typicalyy an array of floating point values) that are adjusted automatically so as to improve their behavior by adapting to previously seen data.Machine Learning can be considered a subfield of AI since those algorithms can be seen as building blocks to make computer learnScikit Learn DocumentationWhy is learning difficult ?Given a finite amount of training data, you have to derive a relation for an infinite domain.In fact, there is an infinite number of such relationsWhich relation is the most appropriate ?â€¦ the hidden test pointsâ€¦Learning biasIt is always possible to find a model complex enough to fit all the examplesBut how would this help us with new samples ? It should not generalize well.We need to define a family of acceptable solutions to search from. It forces to learn a â€œsmoothedâ€ representationSo in practice we need Examples (data!) A tunable algorithm (model) A evalutation of the model fitness to examples (risk, loss) A definition of the model search space (not too big, not too small) An optimization strategy The bias/variance compromiseSmall search space: Easier to find the best (available) solution But it may be far from the ideal one Large search space: It is hard to find the best (available) solution 3 kinds of problemsRegression\\[x=\\underbrace{\\begin{pmatrix} \\vdots \\end{pmatrix}}_{\\in\\mathbb R^T}\\\\y=\\underbrace{\\begin{pmatrix} \\vdots \\end{pmatrix}}_{\\in\\mathbb R^5}\\]Classification\\[x=\\mathbb R^5\\\\y=\\mathbb R^T\\]Density estimation\\[x\\in\\mathbb R^5\\\\\\mathbb P(x)\\in[0,1]\\]3 types of learning Supervised learning $(x,y)$ The training contains the desired behavior (desired class, outcome, etc.) Reinforcement learning $(x,\\tilde y)$ The training data contains partial targets (for instance, simply whether the machines did well or not) Unsupervised learning The training data is raw, no class or target is given There is often a hidden goal in that task (compression, maximum likelihood, etc.) Model validationMore on that later You need to test the generalization power of your approach So you need data not seen during the training: a test set For which you know the expected output (â€œground-truthâ€, â€œgold standardâ€, â€œtargetâ€,â€¦)Benefits of MLA duck exampleHow to filter the grass to keep only the duckshape, using threshold domain ?Why using Machine Learning in computer Vision ?To avoid knob turning. Itâ€™s complex. Itâ€™s unsafeBut beware of the Machine Learning MagicActual goals of this course Teach you that you can (and should whenever possible) optimize the parameters of your CV/PR product Show some simple tools to try to do it Address practical problem describe a pattern look for a pattern match a pattern classify a pattern describe a set of patterns (an object/an image) retrieve an object given a query, segment objectsâ€¦ and face the unavoidable work surrounding them Course agenda6 â€œweeksâ€ (Friday to Friday)See the web page for complete agendaWeekly tests + assignments (practice sessions). No final examWeekly wokflow should be: Friday, 09:30-10:00: answer the weekly quiz on Moodle (starting next Friday) Friday, 10:00-12:00: attend the lecture using Teams Friday, 14:00-17:00: Work on the practice session and join the discussion using Teams Before next Friday: Complete the assignement and submit your results using Moodle (for sessions 4, 5 and 6 only)No deep learning ! We need a course about basic techniques There are cases where setting upPratice sessions: setup your dev. env.Basically: Python with: Jupyter Numpy Matplotlin Scikit-image: RGB Scikit-learn OpenCV: BGRWhy I love Scikit-LearnNumpy-friendly3-way documentation: User guide, API ref, ExamplesSuper smart API Decomposition, level of detail, default values, consistency, etcIntroduction to Twin it!OverviewA poster game $X$ bubbles, all different but $Y$ bubbles, which have 1 (and only 1) twinYour goals: Find the pairs Discussion (3 minutes): How can we decompose the problem ? How can we make sure our solution works ? What should we focus on ? Already done: Scan the poster Stitch the tiles Normalize the contrastUndelying problems Isolate each bubble $\\Rightarrow$ Segmentation We provide pre-computed results for this step Compare image pairs $\\Rightarrow$ Matching We will focus on this one We will use Template Matching Identify pairs $\\Rightarrow$ Calibration Template matchingWhy template matching ?A simple method which will be useful to understand Evaluation challenges The ideas behind keypoint detection (next lecture)It can work on the Twin it! case Twice the same texture Textures are the same scale, without rotation nor intensity change Only need to cope with translation (and some small noise)Step by step: Compare 2 images 2 arrays of intensities Take the absolute difference\\[R(x,y) = \\vert I_1(x,y) - I_2(x,y)\\vert\\] Sum the differences\\[S=\\sum_{x,y}(I_1(x,y) - I_2(x,y))^2\\](Opt.) Normalize so the results belongs to $[0,1]$Template Matching: Sliding comparison $I_1$ is a small template $T$ to match against $I_2$ (just $I$ after) We rewrite the preceding formula to compute a map $R$ of the shape of $I$ Each pixel of $R$ will have the value of the SSD when the top-left pixel of $T$ in on the pixel $(x,y)$ of $I$Several approaches $\\Leftrightarrow$ Practice sessionAbout the denominatorCross correlation: 2 things to knowMore robust to intensity shiftIdeal goalFor each bubble, retunr only a mathcin pair, if it exists" }, { "title": "ASE3: Couple de variables aleatoires discretes et analyse des donnees - 1", "url": "/cours/posts/ase3_couple_va/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-12 10:00:00 +0200", "snippet": "Lien de la note HackmdCouple de variables aleatoires reelles et discretesSoient $X$ et $Y$ 2 v.a reelles discretes. On appelle couple $(X,Y)$ lâ€™application de $\\Omega\\to\\mathbb R^2$ definie par $(X,Y)(\\omega)=(X(\\omega), Y(\\omega))$$X$ et $Y$ sont definis sur un meme espace probabilite (\\(\\underbrace{\\Omega}_{\\text{univers}}, \\underbrace{\\mathcal C}_{\\text{tribu}}, \\underbrace{P}_{\\text{probabilite}}\\))La loi dâ€™un couple $(X,Y)$ (Loi conjointe) DefinitionOn appelle loi de $(X,Y)$ lâ€™ensemble des couples $((x_i,y_j), P_{i,j})$ ou $x_i\\in X(\\Omega)$ lâ€™ensemble des valeurs de $X$ $y_j\\in Y(\\Omega)$ lâ€™ensemble des valeurs de $Y$ \\(P_{ij} = \\mathbb P((X=x_i)\\cap(Y=y_j))\\) Si $I = [[1, r]]$ et $J = [[1,s]]$ (ensemble discret, ensemble des indices). Les $P_{i,j}$ sont souvent donnes dans le tableau a double entres. $X /Y$ $y_1$ $\\dots$ $y_j$ $\\dots$ $y_s$ $x_1$ $P_{1,1}$ $\\dots$ $P_{1,j}$ $\\dots$ $P_{1,s}$ $\\vdots$ $\\vdots$ Â  $\\vdots$ Â  $\\vdots$ $x_i$ $P_{i,1}$ $\\dots$ $P_{i,j}$ $\\dots$ $P_{1,s}$ $\\vdots$ $\\vdots$ Â  $\\vdots$ Â  $\\vdots$ $x_r$ $P_{r,1}$ $\\dots$ $P_{r,j}$ $\\dots$ $P_{r,j}$ \\[P_{i,j} \\gt 0 \\quad\\text{et}\\quad\\sum_{i\\in I\\\\ j\\in J}P_{ij} = 1\\]Lois marginales DefinitionLes v.a $X$ et $Y$ sont appelees variables marginales du couple $(X,Y)$. La loi de $X$ (resp. de $Y$) est appelee loi marginale de $X$ (resp. de $Y$)Notation:\\[\\forall i\\in I, P(X=x_i)=P_{i\\circ} \\text{ et } P(X=y_j)=P_{\\circ j} \\\\P_{i\\circ} = P(X=x_i) = \\sum_{j\\in J}P((X=x_i)\\cap(Y=y_j)) = \\sum_{j\\in J}P_{ij}\\\\\\forall j\\in J\\quad P_{\\circ j}=\\sum_{i\\in I}P((X=x_i)\\cap(Y=y_j)) = \\sum_{i\\in I}P_{ij}\\]Exemple$(X,Y)$ un couple de v.a. dont la loi conjointe est donnee par le tableau: $X / Y$ 1 2 3 4 $P_{i\\circ}$ (Loi marginale de $X$) 1 $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 2 0 $\\frac{2}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 3 0 0 $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 4 0 0 0 $\\frac{4}{16}$ $\\frac{1}{4}$ $P_{\\circ j}$ (Loi marginale de $Y$) $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{5}{16}$ $\\frac{7}{16}$ 1 Loi conditionnelles Definition Soit $X$ une v.a reelle sur $(\\Omega, \\mathcal C, P)$\\[X(\\Omega) = \\{x_i\\vert i\\in I\\}, \\text{soit } A\\text{ un evenement }/P(A)\\neq 0\\] La loi conditionnelle de $X$ sachant $A = {(x_i, P_A(X=x_i)), i\\in I}$ \\[P_A(X=x_i) = \\frac{P((X=x_i)\\cap A)}{P(A)}\\] En particulier, $A$: Â«$Y=y_i$Â»\\[P_{(Y=y_i)}(X=x_i)=\\frac{P((X=x_i)\\cap(Y=y_i))}{P(Y=y_j)}=\\frac{P_{i,j}}{P_{\\circ j}}\\]\\[P_{(Y=y_j)}(X=x_i) = \\frac{P_{i,j}}{P_{\\circ j}}\\]ExempleOn reprend lâ€™exemple precedent $X_i$ 1 2 3 4 $P_{(Y=3)}(X=x_i)$ $\\frac{1}{5}$ $\\frac{1}{5}$ $\\frac{3}{5}$ $0$ \\[P_{(Y=3)}(X=1)=\\frac{P((X=1)\\cap(Y=3))}{P(Y=3)}=\\frac{\\frac{1}{16}}{\\frac{5}{16}} = \\frac{1}{5}\\]Independantes Definition$X$ et $Y$ sont 2 v.a. independantes ssi \\[P((X=x)\\cap(Y=y)) = P(X=x)P(Y=y)\\quad\\forall x\\in X(\\omega), \\forall y\\in Y(\\omega)\\\\\\Leftrightarrow P_{ij} = P_{i\\circ} \\circ P_{\\circ j}\\] Soit g une fonction de $\\mathbb R^2\\to\\mathbb R$, definie sur lâ€™ensemble des valeurs prises par $(X,Y)$Soit $Z=g(X,Y)$, $Z_h=g(x_i,y_j)\\in Z(\\Omega)$\\[(Z=Z_k) = \\cup_{(i,j) \\\\ Z_k = g(x_i,y_j)}((X=x_i)\\cap(Y=y_j))\\Rightarrow\\color{red}{P(Z=Z_k)=\\sum_{(i,j) \\\\ Z_k = g(x_i,y_j)}P((X=x_i)\\cap(Y=y_i))}\\]En particulier $Z=X+Y=g(X,Y)$\\[P(Z=z) = \\sum_{(x,y) \\\\ x+y=z}P((X=x)\\cap(Y=y))\\]Si $Z=X.Y=g(X,Y)$\\[P(X.Y=z) = \\sum_{(x,y) \\\\ x.y=z}P((X=x)\\cap(Y=y))\\]Exemple$(X,Y)$ couple defini par $X / Y$ 1 2 3 4 1 $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ 2 0 $\\frac{2}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ 3 0 0 $\\frac{3}{16}$ $\\frac{1}{16}$ 4 0 0 0 $\\frac{4}{16}$ Determiner la loi de $Z=X+Y$ Solution\\[Z=\\{2,3,4,5,6,7,8\\}\\] $Z_k$ 2 3 4 5 6 7 8 $P(Z=Z_k)$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{2}{16}$ $\\frac{4}{16}$ $\\frac{1}{16}$ $\\frac{4}{16}$ \\[\\begin{aligned}P(Z=5) &amp;amp;= P(X+Y=5)\\\\&amp;amp;= P((X=1)\\cap(Y=4)) P((X=2)\\cap(Y=3)) + P((X=3)\\cap(Y=2)) + P((X=4)\\cap(Y=1))\\\\&amp;amp;= \\frac{1}{16} + \\frac{1}{16} + 0 + 0 =\\frac{2}{16} = \\frac{1}{8}\\end{aligned}\\]Determiner la loi de $Z=X.Y$ Solution\\[Z(\\Omega) = \\{1,2,3,4,6,8,9,12,16\\}\\] $Z_k$ 1 2 3 4 6 8 9 12 16 $P(Z=Z_k)$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{4}{16}$ \\[\\begin{aligned}P(Z=4) &amp;amp;= P((X=1)\\cap(Y=4)) + P((X=2)\\cap(Y=2)) + P((X=4)\\cap(Y=1))\\\\&amp;amp;= \\frac{1}{16} + \\frac{2}{16} + 0 = \\color{red}{\\frac{3}{16}}\\end{aligned}\\]Esperance dâ€™une fonction de 2 v.a.r discretes\\[\\begin{aligned}X(\\omega)=\\{x_1,...,x_i\\}\\\\Y(\\omega)=\\{y_1,...,y_j\\}\\end{aligned}\\biggr\\}Z=g(X,Y)\\\\E(Z) = E(g(X,Y)) = \\sum_{i,j}g(x_i,y_j)P((X=x_i)\\cap(Y=y_i))\\]\\[E(Z) = \\sum_{i,j}g(x_i,y_j)P_{i,j}\\]Exemple$g(X,Y) = X,Y$\\[\\begin{aligned}E(X.Y) &amp;amp;= \\sum_{i,j}x_iy_jP((X=x_i)\\cap(Y=y_j)) \\\\&amp;amp;= \\sum_{i,j}x_iy_jP_{i,j}\\end{aligned}\\]Proposition PropositionSi $X$ et $Y$ sont 2 v.a. independantes alors \\[E(X.Y) = E(X)E(Y)\\] Demonstration\\[E(X.Y) = \\sum_{i=1}^r\\sum_{j=1}^sx_iy_jP_{i,j}\\]or $X$ et $Y$ sont independantes $P_{i,j} = P_{i\\circ}\\circ P_{\\circ j}$\\[\\begin{aligned}E(X.Y) &amp;amp;=\\sum_{i=1}^r\\sum_{j=1}^sx_iy_jP_{i\\circ}P_{\\circ j}\\\\&amp;amp;= \\sum_{i=1}^rx_iP_i\\biggr(\\sum_{j=1}^sy_jP_{\\circ j}\\biggr)\\\\&amp;amp;= \\sum_{i=1}^rx_iP_{i\\circ}E(Y)=E(X)E(Y)\\end{aligned}\\]\\[E(X.Y) = E(X)E(Y)\\] La reciproque est fausseContre-exemple$(X,Y)$ couple de loi conjointe $X / Y$ 0 1 2 $P_{i\\circ}$ (Loi de $X$) 0 $\\frac{1}{20}$ $\\frac{1}{4}$ 0 $\\frac{3}{10}$ 1 $\\frac{17}{60}$ $\\frac{1}{4}$ $\\frac{1}{6}$ $\\frac{7}{10}$ $P_{\\circ j}$ (Loi de $Y$) $\\frac{1}{3}$ $\\frac{1}{2}$ $\\frac{1}{6}$ $1$ \\[\\begin{aligned}E(X.Y) &amp;amp;= \\sum_{i=0}^1\\sum_{j=0}^2i.jP_{i,j}\\\\&amp;amp;= 1\\times\\frac{1}{4}+2\\times\\frac{1}{6} = \\frac{1}{4} + \\frac{1}{3} = \\frac{7}{12}\\\\E(X) &amp;amp;= \\sum_{i=0}^1iP_{i\\circ}=\\frac{7}{10}\\\\E(Y) &amp;amp;= \\sum_{j=0}^2jP_{\\circ j} = \\frac{1}{2} + \\frac{2}{6} = \\frac{5}{6}\\\\E(X.Y) &amp;amp;= \\frac{7}{12} = E(X)E(Y)\\end{aligned}\\\\\\]et pourtant $X$ et $Y$ ne sont pas independantes car\\[P((X=0)\\cap(Y=2)) = 0\\\\P(X=0).P(Y=2) = \\frac{3}{10}\\times\\frac{1}{6}=\\frac{1}{20}\\]Covariance et coefficient de correlation lineaire Definition$X$ et $Y$ 2 v.a. discretes.On appelle covariance de $(X,Y)$ le nombre reel \\[Cov(X,Y)=E((X-E(X)(Y-E(Y))))\\] Proposition\\[Cov(X,Y)=E(X.Y) - E(X)E(Y)\\]Demonstration\\[\\begin{aligned}Cov(X,Y) &amp;amp;= E(\\overbrace{(X-E(X))}^{\\text{var centree}}\\overbrace{(Y-E(Y))}^{\\text{var centree}})\\\\&amp;amp;= E(XY-XE(Y) - E(X)Y + E(X)E(Y))\\\\&amp;amp;= E(X.Y) - E(Y)E(X) - E(X)E(Y) + E(X)E(Y)\\end{aligned}\\]Cat $E$ est lineaire\\[Cov(X,Y) = E(XY) - E(X)E(Y)\\]Remarque: Si $X$ et $Y$ sont independantes alors $Cov(X,Y)=0$ DefinitionOn appelle coefficient de correlation lineaire \\[\\mathcal C(X,Y)=\\frac{Cov(X,Y)}{\\sigma_x\\sigma_y}\\] $\\sigma_x=\\sqrt{V(X)}$ $\\sigma_y=\\sqrt{V(Y)}$ " }, { "title": "OCVX: Espaces tangents", "url": "/cours/posts/ocvx_espaces-tangents/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-05-11 09:00:00 +0200", "snippet": "Lien de la note HackmdDedramatiser les espaces tangentsPour une fonction \\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ x&amp;amp;\\mapsto f(x)\\end{aligned}\\)\\[Gr(f) = \\{(x,f(x)), x\\in\\mathbb R\\} \\subseteq \\mathbb R^2\\]Une droite affine est un sous-espace de dimension 1\\[\\begin{aligned}\\color{red}{\\mathcal T_{Gr(f), p}} &amp;amp;= (a,f(a)) + \\color{red}{\\underbrace{\\{\\lambda(1,f&#39;(a)),\\lambda\\in\\mathbb R\\}}_{vect((1,f&#39;(a))) = span((1,f&#39;(a)))}}\\\\&amp;amp;= \\{((a+\\lambda), f(a) + \\lambda f&#39;(a),\\lambda\\mathbb R)\\}\\quad\\text{representation parametrique de } \\mathcal T_{Gr(f), p}\\end{aligned}\\]$Gr(f)$ $\\to$ courbe $y=f(x)\\equiv$ courbe \\(\\underbrace{f(x)-y}_{g(x,y)}=0\\)On va introduire \\(\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto f(x)-y \\end{aligned}\\)$Gr(f)$ $\\to$ courbe $y=f(x)\\equiv$ coubre \\(\\underbrace{f(x)-y}_{g(x,y)}=0 \\equiv\\{(x,y)\\in\\mathbb R^2, g(x,y) = 0\\}=\\mathcal C_0(g)\\) On passe a la courbe de niveau 0Que vaut $\\nabla g(p)$ ?\\[\\nabla g(x,y) = (\\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y}) = (f&#39;(x), -1)\\\\\\nabla g(p=(a,f(a))) = (f&#39;(a), -1)\\]On a trouve precedemment un vecteur directeur de lâ€™espace tangent $(1, fâ€™(a))$. On obtient 2 vecteurs orthogonaux\\[\\nabla g(p=(a,f(a))) = (f&#39;(a), -1) \\to \\vec n\\\\&amp;lt;\\vec n,\\vec u&amp;gt; = 0\\] Le gradient dâ€™une fonction en un point donne est orthogonal aux lignes de niveau de cette fonction.Cas generalDans le cas general $f:\\mathbb R^n\\to\\mathbb R$Notre â€œbolâ€ est:\\[Gr(f) = \\{(x,y,f(x,y)), (x,y)\\in\\mathbb R^2\\} \\subseteq\\mathbb R^3\\]On veut calculer lâ€™espace tangent dans un point donne de lâ€™espaceOn a deux directions de pentes Quâ€™est-ce qui se passe selon $x$ ? Si on se deplace de $1$ en $x$, $\\frac{\\delta f}{\\delta x}(x_0,y_0)$ en $z$ Quâ€™est-ce qui se passe selon $y$ ? Si on se deplace de $1$ en $y$, $\\frac{\\delta f}{\\delta y}(x_0,y_0)$ en $z$ Zoomons au niveau du point $p$:Ces vecteurs generent lâ€™espace tangent\\[\\begin{aligned}\\mathcal T_{Gr(f), p} &amp;amp;= p + vect\\biggr(\\underbrace{(\\overbrace{1,0}^{e_x},\\frac{\\partial f}{\\partial x}(x_0, y_0)}_{\\in\\mathbb R^3}), \\underbrace{(\\overbrace{0,1}^{e_y},\\frac{\\partial f}{\\partial y}(x_0,y_0))}_{\\in\\mathbb R^3}\\biggr)\\\\&amp;amp;= p + vect\\underbrace{((e_x, \\frac{\\partial f}{\\partial x}), (e_y, \\frac{\\partial f}{\\partial y}))}\\\\&amp;amp;\\{\\lambda(e_x, \\frac{\\partial f}{\\partial x}) + \\mu(e_y, \\frac{\\partial f}{\\partial y}),(\\lambda,\\mu\\in\\mathbb R^2)\\}\\end{aligned}\\]Le vrai cas general $f:\\mathbb R^n\\to\\mathbb R$ $n$ pertes $\\frac{\\partial f}{\\partial x}$ selon chaque vecteur de base $e_i=(0,â€¦0,1,â€¦,0)$ $n$ vecteurs de perte \\(\\underbrace{(\\underbrace{e_i}_{\\in\\mathbb R^n},\\frac{\\partial f}{\\partial x_i})}_{\\in\\mathbb R^{n+1}}, i=1,...,n\\)\\[\\mathcal T_{Gr(f)} = vect\\biggr((e,\\frac{\\partial f}{\\partial x_1}),...,(e_n,\\frac{\\partial f}{\\partial x_i})\\biggr)\\quad\\text{sous espace de dim }n\\text{ d&#39;un espace de dimension }n+1\\\\T_{Gr(f),p}=\\{\\lambda(e_1,\\frac{\\partial f}{\\partial x_1}) + ... + \\lambda_n(e_n,\\frac{\\partial f}{\\partial x_n}), (\\lambda_1,...,\\lambda_n)\\in\\mathbb R^n\\}\\]$Gr(f)=$ surface $y=f(x_1,â€¦,x_n)$\\[f(x_1,...,x_n)-y=0 \\equiv \\{(x_1,...,x_n,y)\\text{ tel que } \\underbrace{f(x_1,...,x_n)-y}_{g(x_1,...,x_n,y)}=0\\} = \\mathcal C_0(g)\\\\\\begin{aligned}g:\\mathbb R^{n+1}&amp;amp;\\to\\mathbb R\\\\(x_1,...,x_n,y) &amp;amp;\\mapsto f(x_1,...,x_n)-y\\end{aligned}\\\\\\nabla g(x,y) = (\\frac{\\partial g}{\\partial x_1},...,\\frac{\\partial g}{\\partial x_n},\\frac{\\partial g}{\\partial y}) = (\\frac{\\partial f}{\\partial x_1},...,\\frac{\\partial f}{\\partial x_n},-1)\\]Implicitement: \\(\\mathcal T_{C_0(g),p} = \\{x\\in\\mathbb R^{n+1}, \\nabla g^T x = 0\\}\\)ExerciceSoit \\(\\begin{aligned} f:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto ax^2+by^2 \\quad (a,b)\\in\\mathbb (R_{*}^+)^2 \\end{aligned}\\) Decrire lâ€™espace tangent en tout point du graph de $f$ Decrire lâ€™espace tangent a la courbe de niveau $1$ de $f$ Exo 4.531.En un point $(x,y,f(x,y))\\in Gr(f)$ perte selon $x$: $(1,0,\\frac{\\partial f}{\\partial x}) = \\color{blue}{(1,0,2ax)}$ perte selon $y$: $(0,1,\\frac{\\partial f}{\\partial y}) = \\color{green}{(0,1,2by)}$\\[\\begin{aligned}\\mathcal T_{Gr(f), p} = vect\\biggr(&amp;amp;\\underbrace{(1,0,2ax), (0,1,2by)}_{}\\biggr) + p\\\\\\{\\lambda(1,0,2ax) &amp;amp;+ \\mu(0,1,2by), (\\lambda,\\mu)\\in\\mathbb R^2\\} = {(\\lambda,\\mu,2ax\\lambda + 2by\\mu), (\\lambda, \\mu)\\in\\mathbb R^2}\\end{aligned}\\]2.$\\mathcal C_1(f) = {(x,y)\\in\\mathbb R^2, f(x,y)=ax^2+by^2=1}$On commence par regarder que vaut le gradient de cette fonction::\\[\\nabla f(x,y) = \\begin{pmatrix} 2ax \\\\ 2by \\end{pmatrix}\\]Dans quel sens pointe le gradient ?Quel est lâ€™espace par rapport au gradient ?\\[\\begin{aligned}\\mathcal T_{\\mathcal C_1(f),p} = p + \\{(x,y), \\nabla f(x_0, y_0)^T\\begin{pmatrix}x \\\\ y \\end{pmatrix} &amp;amp;= 0\\}\\\\(2ax_0, 2by_0)\\begin{pmatrix}x \\\\ y \\end{pmatrix} &amp;amp;= 0\\\\2ax_0x + 2by_0y &amp;amp;= 0\\\\y&amp;amp;=-\\frac{ax_0}{by_0}x\\end{aligned}\\\\\\mathcal T_{\\mathcal C_1(f),p} = (x_0, y_0) + \\{(x,y)\\in\\mathbb R^2, \\underbrace{y = -\\frac{ax_0}{by_0}x}_{\\nabla f(x_0, y_0)^T\\begin{pmatrix}x \\\\ y \\end{pmatrix} = 0}\\}\\]3.Ou est le minimum de $f$ ? Quel point minimise $ax^2 + by^2$ ?Câ€™est $(0,0)$.\\[argmin f(x,y) = ax^2 + by^2 = (0,0)\\]Dans quel sens pointe le gradient en tout point de la courbe de niveau par rapport au point minimal? En tout point des courbes de niveau de $f$, $Df$ point a lâ€™oppose du point optimal $(x^+=0, y^+=0)$Caracterisation au premier ordre de la convexiteGraphiquement, quelque soit $x$, $Gr(f)\\ge \\mathcal T_{Grf(x,f(x))}$, le point est toujours au-dessus de la tangente.Si $f$ est convexe, $\\forall x,y$, $f(y) - f(x)\\ge fâ€™(x)(y-x)$ Pour une fonction $f:\\mathbb R^n\\to\\mathbb R$, $f$ convexe $\\Leftrightarrow$ $\\forall x,y\\in\\mathbb R^n$ \\(\\color{red}{f(y)-f(x)\\ge \\nabla \\underbrace{f(x)^T}_{\\in\\mathbb R^n}\\underbrace{(y-x)}_{\\in\\mathbb R^n}}\\)" }, { "title": "OCVX: Hyperplan d&#39;appui", "url": "/cours/posts/ocvx_hyperplan/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-05-07 10:00:00 +0200", "snippet": "Lien de la note HackmdRappels Hyperplan dâ€™appui a une partie $A$ de $\\mathbb R^n$ en un point $p\\in A$, est un hyperplan affine de $\\mathbb R^n$ qui laisse $A$ dans un des deux demi-espaces definis par $H$Etant donne un vecteur normal $\\vec \\nu$ definissant $H\\in\\mathbb R^n$ et $p$ un point dans $H\\cap A$ on a\\[\\forall x\\in A; &amp;lt;\\vec\\nu, x-p&amp;gt;\\le 0\\] On a definit par ailleurs la notion de gradient dâ€™une fonction differentiable $f:\\mathbb R^n \\to \\mathbb R$ en un point $a$, determinee par la relation:\\[\\forall h\\text{ assez petit}\\\\f(a+b) = f(a) + \\nabla f(a)^Th + \\underbrace{\\varepsilon(h)\\Vert h\\Vert}_{\\varepsilon(h) \\to 0 \\\\ h\\to0}\\]Plan du cours Objectif dâ€™aujourdâ€™hui Etendre la notion de droite tangente au graphe dâ€™une fonction $f:\\mathbb R\\to\\mathbb R$ Au cas des fonctions $\\phi:\\mathbb R^n\\to\\mathbb R$ au cas des parties de $\\mathbb R^n$ decrites comme courbes de niveaux de fonctions Utiliser le point 1. pour obtenir une lieuristique, permettant de construire des methodes iteratives dâ€™optimisation Revoir la notion de droite tangente dans le cas $\\mathbb R$ (une dimension) $f:\\mathbb R\\to\\mathbb R$ Graphe On va definir une maniere de generaliser la notion de droite tangente $f:\\mathbb R\\to\\mathbb R$ Graphe On adapte cette definition au cas de courbes de niveaux $g:\\mathbb R^2\\to\\mathbb R$ zeros de $g$ (courbes de niveau de $g$) Conclusion pour le cas general $\\phi:\\mathbb R^n\\to\\mathbb R$ Espace tangentLe gradient en dimension 1 correspond a la notion de derivee, qui permet de definir la notion de droite tangente au graphe dâ€™une fonction en un point. Dans ce contexte, lâ€™interpretation geometrique de la notion de gradient est connue. En particulier le fait que vous soyez croissants ou decroissant vous est donne par le signe de votre gradient; cela vous permet de savoir dans quelle direction aller si vous cherchez des points ou votre fonction a des plus petite ou plus grandes valeurs.Que signifie un nombre positif ou negatif pour un vecteur de $\\mathbb R$ ?Si on est positif (resp. negatif), on est dans la moitie positive(resp. negative) de notre droite reelle.\\(Q: \\min_{x\\in\\mathbb R}f(x)\\)On cherche a minimiser la fonction $f$Dans ce dessin, le signe de la derivee vous dit que si vous voulez chercher des points $x$ avec $f(x)\\le f(a)$, il faut aller dans le sens oppose a $fâ€™(a)$.La droite $D_{f,p}$ est derivee parametriquement par\\[\\begin{aligned}\\mathbb R&amp;amp;\\to^{\\lambda}\\mathbb R^2\\\\t&amp;amp;\\mapsto (a+t, f&#39;(a)t + f(a))\\color{green}{= (a, f(a)) + t(1, f&#39;(a))}\\color{red}{=P}\\end{aligned}\\]On est en train de dire que $D_{f,p}$ est la droite passant par $p$, de direction $Vect\\biggr((1,fâ€™(a))\\biggr)$Cette notion de droite tangente ne semble pas, telle quelle, facilement generalisable au cas de fonctions de $\\mathbb R^n\\to\\mathbb R$ DefinitionSoit $A$ une partie de $\\mathbb R^n$, soit $p\\in A$. On appelle \\(\\color{red}{\\text{germe d&#39;une courbe (derivable) } \\gamma:\\underbrace{]-\\varepsilon,\\varepsilon[}_{\\varepsilon\\gt0}\\to A\\text{ tel que }\\gamma(0)=p}\\), la derivee de $\\gamma$ en $0$Cela correspond au vecteur vitesse en $p$ dâ€™un point materiel passant par $p$ a lâ€™instant 0, si $\\gamma$ decrit la position de ce point en fonction du temps $t$. Lâ€™ensemble des germes de courbes en $p$ definit un sous-espace vectoriel de $\\mathbb R^n$. $\\color{orange}{\\text{On le note }T_{A,p}\\text{, il sâ€™appelle espace tangent a }A\\text{ en }p}$.Que donne $\\color{orange}{T_{A,p}}$ dans le cas du graphe de $f$?Si $A$ est $\\Gamma_f$ (graphe de $f$) toute courbe passant par $p$ $\\gamma:]-\\varepsilon,\\varepsilon[\\to\\Gamma_f$ est de la forme:\\(\\gamma(t) = \\underbrace{(\\psi(t), f(\\psi(t)))}_{\\color{orange}{\\psi(t), \\phi(t)}} \\quad \\text{pour }\\psi:]-\\varepsilon,\\varepsilon[\\to\\mathbb R\\)avec $\\psi(0) = a$Si $\\gamma$ est derivable en 0:\\[\\gamma&#39;(0) = (\\psi&#39;(0),\\psi&#39;(0)f&#39;(a)) = \\psi&#39;(0)(1,f&#39;(a))\\]\\[\\Rightarrow \\gamma&#39;(0)\\in Vect\\biggr((1,f&#39;(a))\\biggr)\\Rightarrow T_{A,p}\\subseteq Vect\\biggr((1,f&#39;(a))\\biggr)\\] Conclusion\\[T_{A,p} = Vect\\biggr((1, f&#39;(a))\\biggr)\\] autrement dit: $D_{f,p} = p + T_{A,p}$ DefinitionEtant donne une partie $A\\subseteq\\mathbb R^n$ et $p\\in A$, on appelle espace tangent a $A$ en $p$ lâ€™espace vectoriel $T_{A,p}$ compose des germes de courbes dans $A$ passant par $p$.Remarque: Geometriquement, on represente souvent $p+T_{A,p}$ et non $T_{A,p}$Notre prochaine etape est de reinterpreter $p+T_{A,p}$ de maniere implicite de facon a faire apparaitre la notion de gradient dâ€™une fonction $\\mathbb R^n\\to\\mathbb R$.On a $D_{f,p}: (a,f(a)) + t(1,fâ€™(a))$ pour $t\\in\\mathbb R$.Comment obtenir une ecriture implicite de $D_{f,p}$ ?Si $(x,y)\\in D_{f,p}$ alors\\[\\begin{cases}x = a + t\\\\y = f(a) + f&#39;(a)t\\end{cases}\\Leftrightarrow f&#39;(a)(x-a) = y - f(a)\\]Questions Comment ecrit-on $\\Gamma_f$ comme zeros dâ€™une fonction ? Quel est le gradient de cette fonction au point $p$ ? Quel est $\\perp$ de ce gradient au point $p$ ?Premiere question$\\Gamma_f$ est zeros de la fonction:\\[\\begin{aligned}\\phi:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y) &amp;amp;\\mapsto f(x)-y\\end{aligned}\\\\\\begin{aligned}z(\\phi) = \\{(x,y)\\vert f(x)-y=0\\} &amp;amp;= \\{(x,y)\\vert f(x)=y\\}\\\\&amp;amp;= \\{(x,f(x))\\vert x\\in\\mathbb R\\}\\\\&amp;amp;= \\Gamma_f\\end{aligned}\\]Deuxieme question\\[\\nabla\\phi((a,f(a))) = \\begin{pmatrix}\\frac{\\partial\\phi}{\\partial x}(a,f(a)) \\\\ \\frac{\\partial\\phi}{\\partial y}(a,f(a)) \\end{pmatrix} = \\begin{pmatrix}f&#39;(a) \\\\ -1\\end{pmatrix}\\\\\\phi(x,y) = f(x) - y\\]Ce qui genere notre droite tangente câ€™est $(1, fâ€™(a))$ et on a obtenu le vecteur $(fâ€™(a), -1)$. On a obtenu un vecteur orthogonal a notre droite tangenteTroisieme questionLâ€™orthogonal a $\\nabla\\phi(p)$ au point $p$:\\[\\nabla\\phi(p)^T\\begin{pmatrix}x - a \\\\ y-f(a)\\end{pmatrix} =\\begin{pmatrix}f&#39;(a) \\\\ -1\\end{pmatrix}\\begin{pmatrix}x - a \\\\ y - f(a)\\end{pmatrix} = f&#39;(a)(x-a)- ( y - f(a))\\] $\\perp\\nabla\\phi(p): fâ€™(a)(x-a) = y-f(a)$ ($\\perp$ passant par $p$)â€œVectorialiseâ€: $fâ€™(a)x = y \\Leftrightarrow\\nabla\\phi(p)^T \\begin{pmatrix}x \\ y\\end{pmatrix} = 0$ $\\nabla\\phi(p)$ nous donne $T_{\\Gamma_{f,p}}$, Autrement dit: \\(D_{f,p}:p + \\underbrace{\\nabla\\phi(p)^{\\perp}}_{\\color{orange}{T_{\\Gamma_{f,p}}}}\\) PropSoit $f:\\mathbb R^n\\to\\mathbb R$ une fonction differentiable en un point $p\\in\\mathcal C_{f,r}$. Lâ€™espace tangent a $\\mathcal C_{f,r}$ au point $p$ est donne par lâ€™hyperplan orthogonal ($\\perp$) a $\\nabla f(p)$.Question: Calculer lâ€™espace tangent au point $(1, 1)$ de $\\mathcal C_{f,r}$ pour \\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\)\\[\\begin{aligned}\\nabla f(x,y) = \\begin{pmatrix}2x \\\\ 2y\\end{pmatrix}; \\quad \\nabla f(1,1)^T\\begin{pmatrix}x \\\\ y\\end{pmatrix} &amp;amp;= 0\\\\\\Leftrightarrow 2x+2y &amp;amp;=0\\\\\\Leftrightarrow x+y&amp;amp;=0\\end{aligned}\\]Apport de la convexiteRappel Une fonction $f:\\mathbb R^n\\to\\mathbb R$, differentiable, est convexe si $\\forall x,y\\in\\mathbb R^n$ \\(f(y)- f(x) \\ge\\nabla f(x)^T(y-x)\\qquad \\text{(E)}\\)Hypothese Hypothese$f:\\mathbb R^n\\to\\mathbb R$ une fonction convexeDans ce cas $\\forall r\\in\\mathbb R$, $\\mathcal C_{f\\le r}$ est convexe $\\subseteq\\mathbb R^n$Ici, \\(\\forall y\\in\\mathcal C_{f_1\\le v}\\), $\\nabla f(x)^T(y-a)\\le0$. Donc $x+\\nabla f(x)^{\\perp}$ est un hyperplan dâ€™appui a \\(\\mathcal C_{f_1\\le v}\\) Convexite: $f(y)-f(x)\\ge\\nabla f(x)^T(y-x)$Donc le demi-espace positif est a exclure si lâ€™on souhaite chercher un point $x^+$ tel que $f(x^+)\\le f(x)$ On vient dâ€™eliminier toute une partie de lâ€™espace de nos recherches.Question: Dans quelle direction chercher ? PropSoit $f:U\\subset\\mathbb R^n\\to\\mathbb R$ une fonction differentiable. Soit $x\\in\\mathcal C_{f,r}$, si $\\nabla f(x)\\neq 0$ $\\exists x^+=x+\\Delta x$ tel que $f(x)\\ge f(x^+)$ detour, par un deplacement $\\Delta x$ a lâ€™oppose de la direction de $\\nabla f(x)$Remarques On ne connait pas a priori lâ€™amplitude par laquelle on doit additioner $\\nabla f(x)$ a $x$, pour obtenir $x^+$ Ce resultat est vrai meme si $f$ nâ€™est pas convexe, on ne garantit plus la recherche dâ€™un minimum globalQuestion: Il se passe quoi si $\\nabla f(x) = 0$ ?Questions des elevesJâ€™ai pas compris la particule a une vitese constante sur x? Comment on dÃ©fini la â€œvitesseâ€? Tu images que la courbe gamma reprÃ©sente le dÃ©placement de la particule le long de la courbe A -&amp;gt; gamma(t) = abscisse de la particule le long de la courbe. Avec en t=0, ta particule qui passe par le point p La vitesse instantanÃ©e = dÃ©rivÃ©e de la position. Vitesse instantanÃ©e de la particule en p = dÃ©rivÃ©e de gamma en 0 Ta particule peut adopter plusieurs profils de vitesse le long de la courbe (accÃ©lÃ©rer, dÃ©cÃ©lÃ©rer, etc), mais elle est contrainte de suivre le profile de la courbe Donc la valeur du vecteur vitesse gammaâ€™(0) peut effectivement varier selon le profil de vitesse Mais la direction de ce vecteur vitesse sera toujours la mÃªme, et câ€™est ce qui dÃ©fini lâ€™espace tangent (en dim 1)Mais du coup on fait tout Ã§a juste pour trouver un vecteur qui appartient a lâ€™espace tangent? En fait cette idÃ©e est trÃ¨s gÃ©nÃ©rale, et indÃ©pendante de la dimension de lâ€™espace dans lequel on travaille.En dim 1, Ã§a peut paraÃ®tre un peu overkill de faire tout Ã§a â€œjusteâ€ pour avoir la direction de la tangente.Mais quand on va passer sur des dimensions supÃ©rieurs (donc des surfaces, etc), lÃ  tu auras plusieurs directions possibles de te balader sur la surface et dâ€™approcher ton point p. Imagine $f(x,y) = x^2 + y^2$, donc une surface en forme de bol. En (0,0), tu as plusieurs directions pour approcher (0,0) en restant sur la surface. Pour chacune de ces courbes possibles, tu vas avoir un vecteur vitesse associÃ©. Et câ€™est lâ€™ensemble de ces vecteurs vitesse (enfin, lâ€™espace gÃ©nÃ©rÃ© par ces vecteurs vitesse) qui va dÃ©finir le plan tangentJâ€™ai encore du mal Ã  voir en quoi câ€™est diffÃ©rent dâ€™une diffÃ©rentielle Il y a effectivement un lien entre les deux notions, mais ce ne sont pas du tout les mÃªmes objets : une diffÃ©rentielle est une application linÃ©aire, un espace tangent est une sous-partie de ton espace de travail." }, { "title": "IRGPU: Patterns for massively parallel programming", "url": "/cours/posts/irgpu_patterns/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-05 14:00:00 +0200", "snippet": "Lien de la note HackmdIRGPU: Patterns for massively parallel programmingProgramming patterns &amp;amp; memory optimizationsThe programming patterns Map Map + Local reduction Reduction ScanThe IP algorithms LUT applications Local features extraction Histogram Integral imagesMap patternMap pattern overview Un pixel en entree et sortie La dependance est nulle Map replicated a function over every element of an index set.The computation of each pixel is independant wrt the othersout(x,y) = f(in(x,y))What do you think about kâ€™s impact of the performance ?Le premier fait threadIdx.x + k et lâ€™autre fait threadIdx.x * k A gauche, le thread numero i est le thread numero i+1: câ€™est continue au niveau des addresses memoire (lineaire) A droite: acces stride (palier) Linear sequential access with offset câ€™est bien Strided access câ€™est po bien Strided access patternSur le kernel numero 2, un grand temps du process est passe pour la gestion memoire (acces memoire mal fait)Memory performanceMemory bandwithWhat you think about memoryReality:Memory access hierarchy Memoire L2: cache intermediaire Memoire sur le chip low-latency Registres Shared memory L1 (meme zone que shared memory) Dire au processeur de gerer la memoire ou la gerer nous-meme Dans ce cas on configure nous meme la shared memory Sers de cache entre le L2 et la shared memory Cached Loads from L1 low-latency2 choses a prendre en compte: acces memoire alignes ou non acces memoire coalesced (stride) ou non2 types of global memory loads: cached or uncachedAligned vs MisalignedA load is aligned if the first address of a memory access in 32 bytes Memory addresses must be type-aligned (typeof(machin)) Otherwise poor perf cudaMalloc = alignement on 256 bits at leastCoalesced vs uncoalescedA load is coalesced if a warp access is non-continuousMisaligned cached loads from L1We need a load strategy: 32 threads of warp access a 32-bit word = 128 bytes 128 bytes = L1 bus (single load - bus utilization = 100%) Access permutation has no (or very low) overheard If data are not 128-bits aligned, 2 loads are requiredAdresses 96-224 required.. but 0-256 loaded If data is accessed stridedPas possible dâ€™augmenter la taille du bus ?Le bus est fixe (hardware)Loads from gloabl (uncached) memorySame idea but memory is split in segments of 32 bytesCoalesced Memory Access (summary)How memory works for real DRAM is organised in 2D Core array Each DRAM core array has about 16M bitsExample A 4x4 memory cell With 4 bits pin interface widthDRAM BurstLa memoire est lente DDR = 1/2 interface speed DDR2 = 1/4 interface speed DDR3 = 1/8 interface speed Solution: BurstingLoad N x interface width of the same rowAu lieu dâ€™avoir 1/4, on renvoit 3 x 1/4Better, but not enough to saturate the memory busSummary Use coalesced (contiguous and aligned) accessed to memoryHow to make coalesced loads with 2D arrays ? Ca correspond au pitchPitch: taille des lignes pour que le debut des lignes correspond a un multiple de 32Using shared memoryTranspositionWhere are non-coalesced access ?Sur un warp, les x sont lineaire (0 - 31). Ici, ce qui est lineaire selon x câ€™est la lecture dans in.32 threads vont ecrire 32 elements non-continus a[x][y]Tiling and memory privatization On decoupe le travaille en sous-block (tuile) Ca marche bien sur les images !For each block: Read the tile from global to private block memory process the block (used shared memory) write the tile from the private (shared) block memory to global memoryCollaborative loading and writing then BLOCKDIM = TILEDIM All threads load one or more data Access must be coalesced Use barrier synch to make sure that all threads are ready to start the phaseEst-ce que ecrire dans la tile câ€™est lineaire ?Pour chaque ligne y, x va varier le plus rapidement possible: câ€™est lineaireTiled transposition in shared memoryLâ€™algorithme pour transposer en utilisant la shared memory commence par copier la taille en shared memory, transpose en shared memory et transpose les acces coalesced en memoire globaleA quel moment on fait des acces aligned dans la shared memory ?On lit de maniere alignee en global, on ecrit en aligne partout sauf la derniere ligne ou câ€™est un acces non-alignePerformance (GB/s on TESLA K40)Speed up de 2 entre la version qui utilise la shared memory et celle qui ne lâ€™utilise pasAbout shared memoryComment on peut combler le gap (encore) entre les GB/s de la TESLA ?DRAM banks Bursting: access multiple locations of a line in the DRAM core array (horizontal parallelism) Permet dâ€™utiliser dâ€™avantage la memoire a sa capacite totaleBank conflits in shared memory If 2 threads try to perform 2 different loads in the same bank $\\to$ Bank conflict Evert bank can provide 64 bits every cycle Only 2 modes: Change after 32 bits Change after 64 bits Demander la meme adresse par 2 threads differents ne pose pas de problemesLes addresses consecutives ne sont pas dans les memes banques.2-way conflicts:On fait 2 loads en shared memory Conflict = serialized access po bienConcrete example for shared memory Bank size: 4B = 4 uint8 32 Banks - Many channels Warp size = 32 threadsPour le premier cas du tableau:Est-ce quâ€™il a des threads qui demandent des addresses differentes dans une meme banque ?NonQuel est le nombre de loads (requetes memoire) quâ€™on va effectuer ?Une seule requete memoire op Items Bank used Conflict Free #Loads load M[tid.x] $[0,1,â€¦,31]$ $[0,1,â€¦,7]$ Oui 1 load M[tid.x % 4] $[0,1,2,3,0,1,2,3â€¦]$ $[0]$ Oui 1 load M[tid.x + 1] $[1,2,3,â€¦32]$ $[0,1,â€¦,8]$ Oui 1 load M[tid.x * 2] $[0,1,2,3,â€¦62]$ $[0,1,â€¦,15]$ Oui 1 load M[tid.x * 8] $[0,8,â€¦248]$ $[0,2,â€¦,30]$ Non (conflits sur toutes les banques) 2 load M[tid.x * 12] $[0,8,â€¦248]$ $[0,1,â€¦,31]$ Oui 1 load M[tid.x * 8]:load M[tid.x * 12]:Bank conflicts in TransposeSi on a 32 banques, on utilisent que 2 banques sur 32 et on a plein de conflits. Reading a column may cause bank conflictSolution to bank conflictsWith padding (to WRAP_SIZE + 1)Comment se passe la lecture des columns ?Avec le padding, on decale la lecture de 1 (on se decale dâ€™une banaque). En lisant la 1ere column, on tombe toujours dans une banque differente, evitant ainsi les conflits.Index mapping functionPerformances (GB/s on TESLA K40)Shared memory (summary) Super fast access (almost as fast as registers) But limited resourcesOccupancyStencil PatternUse case: Dilation/erosion Box (Mean) / Convolution Filters Bilateral Filter Gaussian Filter Sobel Filter Il y a une dependance entre les pixelsNaive Stencil ImplemLocal average with a rectangle of radius $r$ (Ignoring border problems for now)Naive Stencil PerformanceSay we have this GPU: Peak power: 1 500 GFlops and Memory Bandwith: 200 GB/sAll threads access global memory 1 memory access for 1 FP addition Requires 1500 x sizeof(float) = 6 TB/s of data But only 200 GB/x mem bandwith $\\to$ 50 GLFOPS (3% the peak) Problem: too many access to global memory Solution: tiling, copy data in shared memory to global memoryHandling Border Add border to the image to have in-memory access Copy tile + border to shared memoryThe bad wayEach thread copies one value and border threads are then idleThe good wayA thread may copy several pixelsStencil pattern with tiling performanceReduction PatternIntuition for reduction pattern Reduction combines every elemet in a collection into one element using an associative operatorReduction pattern: solution 1Est-ce que câ€™est correct ?Non, on va avoir des acces concurentiels (data race)Data race Plusieurs parties dâ€™un programme qui essaie dâ€™acceder sans ordre predefini a la meme donneeWe need to ensure that each of those read-compute-write sequences are atomic.Atomics reminderAtomics Read, modify, write in 1 operation Cannot be mixed with accesses from other threads On global memory and shared memory Atomic operations to the same address are serializedOperationsReduction Pattern CorrectedAccumulation in global memoryAnalysisTime: 5.619 msCorrect result but high contention on the global atomic variable The execution is actually sequential !Global atomics: is this really parallel ?This version will produce the right result. However, is it really parallel ?How our global atomic instruction is executed: lock memory cell read old value compute new value write new value release the memory cellMemory cell = cache line burstOur kernel generates a lot of collisions on global memoryLeverage Shared MemoryAtomic operations are muchMotivation for output privatizationUsing shared memoryReduction pattern V2: Output privatizationWith syncReduction functions and treesOn peut reduire en parallele plusieurs fragmentsComplexity in steps and operationsThe tree parallel version is: work efficient not resource efficient Average number of thread $((N-1/\\log_2(N))$ Â«Â peak requirement ($N/2$) Proof of number of operationsReduction pattern: tree reduction without atomics Use a local sum without atomics Map reduction tree to compute units (threads) Add to a global atomic once for each blockWhat is happening ?The (naive) tree version is slower than the locally sequential versionSp starvationIn each iteration, 2 control flow paths will be sequentiall traversed for each warp Threads that perform addition and threads that do not Threads that do not perform addition still consume execution resourcesResource efficient versionTous les threads vont etre utilise sauf a la fin. On va avoir que des warps actifs, a chaque iterations on libere la moitie des warps.A quick analysisFor a 1024 thread block No divergence on the first 5 steps 1024, 512, 256, 128, 64, 32 consecutive threads are active in each step All threads in each warp either all active or all inactive The final 5 steps will still have divergence Can use warp-level optimization then (warp suffle) Limit global collisionWhat happens with very large input arrays ?Lot of global atomicsHow to avoid this ?Global array, one cell for each block No more locks But requires a second level of reductionMore work per thread Just fire enough blocks to hide latency Sequential reduction, then tree reduction â€œalgorithm cascadingâ€Algorithm cascadingPerform first reduction during the collaborative loading Warning: kernel launch parameters must be scaled accordingly !Last optimizationsLoop unrolling Unroll tree reduction loop for the last warp (less sync needed) Unroll all tree reduction loops (need to know block size) Unroll the sequential reduction loop (knowing the work per thread)Histogram computationMandelbrot practice sessionDuring the practice session, you will have to compute the cumulated histogram of the image. Compute the histogram $H$ Count the number of occurences of each value Computed the cumulated histogram $C$ Inefficient, non-coalesced memory accessFirst sample codeWhat is the issue ?Ajouter un data arrayParallel algorithm using output privatizationLocal histogramInitializationShared memory must be initializedThis can be done with the â€œcomb-likeâ€ pattern We need synchronization after this stageComputationLike previous code, but with local atomics We need synchronization after this stageCommit to global memoryint n = blockDim.x * threadIdx.y + threadIdx.xSummaryPerformance boosters: Coalesced accesses Output privatizationRequirements: atomics synchronizationScan patternWhat is a scan ? Scan computes all partial reductions of a collectionUsage: Integration (cumulated histogram) Resource allocation (memory to parallel threads, camping spotsâ€¦) Base building block for many algorithms (sorts, strings comparisons)Performance baselinesSequential versionNaive parallel versionHave every thread to add up all x elements needed for the y elementScan pattern at the warp or block levelKogge-Stone Number of steps: $\\log N$ (bien) Ressource efficiency (bien) Work efficiency $\\sim N\\log N$ (pas bien)Brent-Kung Number of steps: $2\\log N$ Ressource efficiency: all warps remain active till the end (pas bien) Work efficiency: $2N$ (bien)Sklansky Number of steps: $\\log N$ Ressource efficiency: bien Work efficiency: $\\frac{N}{2}\\log N$ (bien)Scan Pattern at the Block or Grid LevelThe patterns before can be applied: At the warp level (no sync until Volta) At the block level (thread sync)At the global level: multi-level kernel app in global memory Scan then propagate Reduce then scanScan then propagateReduce then scanSummary" }, { "title": "RSE: Premier cours", "url": "/cours/posts/rse_1/", "categories": "tronc commun S8, RSE", "tags": "tronc commun, S8, RSE", "date": "2021-05-04 14:00:00 +0200", "snippet": "Lien de la note HackmdIntroductionValerie Schneider Conseil et formation pour une performance durable Intervient a lâ€™ISEP, ECE, EPITA, SUP RH RSE, economie circulaire, numerique responsable Startegie, modeles economiques, sensibilisation, projetDu developpement durable a la RSELe developpement durable Le developpement durable est le developpement qui satisfait les besoins de la generation actuelle sans priver les generations futures de la possibilite de satisfiare leurs propres besoinsRapport Brundtland, 1987Une population en augmentationDes ressources limitees Le 22 aout 2020 est, cette annee, le â€œEarth Overshoot Dayâ€ (le jour du depassement) Cela signifie que nous avons deja consomme depuis le debut de lâ€™annee les ressources naturelles que peut fournir la Terre en un anNos reserves de metaux sâ€™epuisentUne consommation de biens en augmentationNous possedons de plus en plus dâ€™objets, des nouvelles technologies apparaissent et nous voulons en profiter.La fabrication de cette multitude dâ€™objets necessite des matieres premieresLa consommation energetique du numeriqueLe changement climatique Le climat se rechauffe et cree un risque pour lâ€™humanite et pour les entreprisesLes principaux gaz â€œa effet de serreâ€:La biodiversite 1 million dâ€™especes menacees dâ€™extinction, et beaucoup pourraient disparaitre â€œdans les prochaines decenniesâ€Les causes de lâ€™erosion de la biodiversite: La destruction et la fragmentation des milieux naturels (urbanisation) La surexploitation dâ€™especes sauvages Les pollutions de lâ€™eau, de lâ€™air, des sols Lâ€™introduction dâ€™especes exotiques envahissantes Le changement climatiqueLa RSE, effet de mode ou reelle vague de fond ?La RSE: des concepts du siecle dernierLâ€™entreprise comme realite societale Lâ€™entreprise influence la societe Elle a une contribution non economique, notamment dans le social Howard R. Bowen Edward Freeman Karl PolyaniHoward R. BowenResponsabilities of the Businessman - 1953 Definition: â€œelle renvoie aux obligations de lâ€™homme dâ€™affaire de poursuivre telles politiques, de prendre telles decisions ou de suivre telles lignes dâ€™action qui sont desirables en fonction des obejctifs et des valeurs de notre societeâ€ 20 ans apres, il juge idealiste lâ€™idee dâ€™uneEdward Freeman Licence to operate - 1970 Satisfaire les attentes des parties prenantes Business Case: il y a tout interet a engager lâ€™entreprise dans des demarches volontaires de RSE, parce que câ€™est lâ€™attente des opinions publiques occidentales et parce que les entreprises qui ne sâ€™y soumettrons pas seront a termes sortie des marchesKarl Polyani (1886 - 1964)Lâ€™entreprise est â€œen marche et en societeâ€ Se developpe dans un environnement sain, viable et fertile Lâ€™entreprise est redevable a la Societe Assumer les consequences et les risques Re-internaliser les couts supportes par la collectiviteSoutenabilite - la prise de conscienceRSE (CSR en anglais)Definition de la Responsabilitie Societale (ISO 26000)La responsabilite dâ€™une organisation vis-a-vis des impacts de ses decisions et activites sur la societe et sur lâ€™environnement se traduisant par un comportement transparent et ethique qui: contribue au developpement durable, y compris a la sante et au bien-etre de la societe prend en compte les lois en vigueur et est en accord avec les normes internationales de comportement qui est integre dans lâ€™ensemble de lâ€™organisation et mis en oeuvre dans ses relations" }, { "title": "IRGPU: Getting started with CUDA", "url": "/cours/posts/irgpu_getting-started/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-03 14:00:00 +0200", "snippet": "Lien de la note HackmdCUDA overviewWhat is CUDA ?A product It enables to use NVidia GPUs for computationA C/C++ variant Mostly C++ 15 compatible, with extensions and also some restrictions !A SDK A set of compilers and toolchains for various architectures Performance analysis toolsA runtime An assembly specification Computation libraries (linear algebra, etc.)A new industry standard Used by every major deep learning framework Replacing OpenCL as Vulka is replacing OpenGLThe CUDA ecosystem (2021)Libraries or Compiler Directives or Programming Language ?CUDA is mostly based on a â€œnewâ€ programming language: CUDA C (or C++, or Fortran) This grants much flexibility and performanceBut is also exposes much of GPU goodness through librariesAn it supports a few compiler directives to facilitate some constructsThe big idea: Kernels instead of loops No more for loop !Arrays of parallel threadsA CUDA kernel is executed by a grid (array) of threads All threads in grid run the same kernel code (Single Program Mutliple Data) Each thread has indexes that is used to compute memory addresses and compute decisionsThreads blocksThreads are grouped into thread blocks Threads witihin a bloc cooperate via shared memory atomic operations barrier synchronization Threads in different blocks do not interactA multidimensional grid of computation threadsEach thread uses indices to decide what data to work on:Each index has $x$, $y$ and $z$ attributesGrid and blocks can have different dimensions, but they usually are 2 levels of the same work decompositionExamplesBlock decomposition enable automatic scalabilityArchitectureProgramming modelingBlockA set of threads that cooperate: Synchronisation Shared memory Block ID = ID in a gridGridArray of blocks executing same kernel Access to global GPU memory Sync. by stop and start a new kernelMapping Programming model to hardwarethe SMsZoom on the SM warp: 32 unites de calcul SM organize blocks into warps 1 warp = group of 32 threadsGTX 920: 128 cores = 4 x 32 cores Quad warp scheduler selects 4 warps (TLP) And 2 independant instructions per warp can be dispatched each cycle (ILP) Ex: 1 (logical) block of 96 threads maps to: 3 (physical) warps of 32 threadsZoom on the CUDA cores A warp executes 32 threads on the 32 CUDA cores The threads executes the same instructions (DLP) All instructions are SIMD (width = 32) instructionsEach core: FLoating point &amp;amp; integer unit Fused multiply-add (FMA) instruction Logic unit Move, compare unit Branch unit The first IF/ID of the pipeline is done by the SM SIMT allows to specify the executionThe SIMT Execution Model on CUDA coresSIMT: on programme comme si on avait un thread qui execute une donnees mais ca se cache derriere des instructions SIMD (a + b devient la somme du vecteur a avec le vecteur b) Chaque thread va executer le meme kernel et instructions Divergent code paths (branching) pile up!If/else: tous les threads vont effectuer en meme temps le if et elseIf/elseWhat is the latency of this code in the best and worst case ? Best case: $a\\gt0$ is false for every thread. For all threads: inst-d Worst case: $a\\gt0$ and $b\\gt0$ is true for some but not all threads. For all threads: inst-a, inst-b, inst-c, inst-dLoopsFinal note about terminologyGPU memory modelComputation cost vs. memory costPower measurements on NVIDIA GT200With the same amount of energy: Load 1 word from external memory (DRAM) Compute 44 flops Must optimize memory firstExternal memory: discrete GPUClassical CPU-GPU model Split memory space Highest bandwith from GPU memory Transfers to main memory are slower Intel i7 4770 / GTX 780External memory: embedded GPUMost GPUs today: Same memory May support memory coherence (GPU can read directly from CPU caches) More contention on external memoryGPU: on-chip memoryCache area in CPU vs GPU:But if we include registers: GPU has many more registers but made of simpler memoryMemory model hierarchyHardwareCache hierarchy: Keep frequently-accessed data Core Reduce throughtput demand on main memoru L1 Managed by hardware (L1, L2) or software (shared memory)On CPU, caches are designed to avoid memory latencyOn GPU, multi-threading deals with memory latencySoftwareBuilding and running a simple programWhat you need to get started NVidia GPU hardware NVidia GPU drivers, properly loaded CUDA runtime libraries CUDA SDK (NVCC compiler in particular)Summary Host vs Device $\\leftrightarrow$ Separate memory GPU are computation units which require explicit usage, as opposed to a CPU Need to load data and fetch result from device Replace loops with kernels Kernel = Function computed in relative isolation on small chunks of data Divide the work Compile and run using CUDA SDKHost view of GPU computationSequential and parallel sections We use the GPU(s) as co-processor(s)CUDA memory primitivesWhy 2D and 3D variants ? Strong alignment requirements in device memory Enables correct loading of memory chunks to SM caches (correct bank alignment) Proper striding management in automated fashionHost $\\leftrightarrow$ Device memory transferAlmost complete codeChecking errorsIn practice check for API errorsIntermission: Can I use memory management functions inside kernels ?No: cudaMalloc(), cudaMemcpy() and cudaFree() shall be called from host onlyHowever, kernels may allocate, use and reclaim memory dynamically using regular malloc()Fix the kernel invocation lineWe want to fix this line:Kernel invocation syntax:How to set gridDim and blockDim properly ?Lvl 0: Naive trial with as many threads as possible Will fail with large vectors Hardware limitation on the maximum number of thread per block (1024 for compute capability 3.0-7.5) Will fail with vectors of size which is not a multiple of warp sizeLvl 1: It works with just enough blocksLvl 2: Tune block size given the kernel requirements and hardware constraintsBut waitâ€¦ This code prints nothing ! Kernel invocation is asynchronous Host code synchronization requires cudaDeviceSynchronize() because kernel invocation is asynchronous from host perspective.On the device, kernel invocations are striclty sequential (unless you schedule them on different streams)Intermission: Can I make kernels inside kernels ?Yes. This is the basic of dynamic parallelismSome restrictions over the stack size apply.Remember that the device runtime is a functional subset of the host runtime, ie you can perform device management, kernel launching, device memcpy, etc. but with some restrictionsThe compiler may inline some of those calls.Conclusion about the host-only viewA host-only view of the computation is sufficient for most of the cases: upload data to the device fire a kernel download output data from the deviceAdvanced CUDA requires to make sure we saturate the SMs, and may imply some kernel study to determine the best: amount of threads per blocks amount of blocks per grid work per thread (if applicable) â€¦This depends on: hardware specifications: maximum gridDim and blockDim, etc. kernel code: amount of register and shared memory used by each threadKernel programmingSeveral API levelsWe now want to program kernelsThere are several APIs available: PTX assembly Driver API (C) Runtime C++ API $\\leftarrow$ letâ€™s use this oneFunction Execution Space Specifiers __global__ defines a kernel function Each __ consists of 2 underscore characters A kernel function must return void It may be called from another kernel for devices of compute capability 3.2 or higher (Dynamic Parallelism support) __device__ and __host__ can be used together __host__ is optional if used aloneBuilt-in Vector TypesThey make it easy to work with data like imagesAlignement mus be respected in all operations They all are structuresThey all come with a constructor function of the form make_&amp;lt;type name&amp;gt;The 1st, 2nd, 3rd and 4th components are accessible through the fields $x$, $y$, $z$ respectivelyBuilt-in variableExampleMemory hierarchyTypes of Memory Registers Used to store parameters, local variables, etc. Very fast Private to each thread Lots of thread $\\Rightarrow$ little memory per threads Shared Used to store temp data Very fast Shared among all threads in a block Constant A special cach for read-only values Global Large and slow Caches Transparent uses LocalSalient features of Device MemoryCost to access memoryVariable Memory Space SpecifiersHow to declaring CUDA variablesRemarks: __device__ is optional when used with __shared__ or __constant__ Automatic variables reside in a registerWhere to declare variables ?Can host access it ? Yes No global and constant, declare outside of any function register and shared, use of declare in the kernel Who can be shared by who ?Possible memory access: Among threads in the same grid (a kernel invocation) Global memory Among threads in the same block Global memory Shared memory Relaxed consistency memory modelThe CUDA programming model assumes a device with a weakly-ordered memory model, that is the order in which a CUDA thread writes data to shared memory or global memory, is not necessarily the order in which the data is observed being written by another CUDA or host threadExamplePossible outcomes for thread 2 ?Memory Fence FunctionsMemory fence functions can be used to enforce some ordering on memory accessesEnsures that: All writes to all memory made by the calling thread before the call to __threadfence_block() All reads from all memorySynch functions Stronger than __threadfence() because it also synchronizes the executionAtomic functions Atomic functions perform a read-modify-write atomic operation on one 32-bit or 64-bit word residing in global or shared memoryMost of the atomic functions are available for all the numerical typeArithmetic functionsDebugging, performance analysis and profilingprintfPossible since Fermi devices (Compute Capability 2.x and higher)Limited amount of lines: circular buffer flushed at particular timesGlobal memory writeTo dump then inspect a larger amount of intermediate dataAnalysis code should be removed for productionExampleCUDA toolsThe complete compilation trajectory" }, { "title": "IRGPU: Introduction", "url": "/cours/posts/irgpu_introduction/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-03 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda GPU and architectures (2h) Programming GPUs with CUDA (2h) TP 00 CUDA (3h) Efficient programming with GPU (2h) TP 01 CUDAGPU and architecturesWhy using GPU ? On veut faire de la programmation rapide.Un programme rapide est un programme qui consomme moins. Câ€™est important de consommer moins Ex: nos smartphones consomment enormement dâ€™energie, avoir des programmes qui consomment le moins possible permet dâ€™economiser la batterieOn est aujourdâ€™hui dans lâ€™ere du big data, on veut traiter rapidement un tres gros volume de donnees. Sinon on aurait jamais ete capable dâ€™avoir des techs comme les reseaux de neurones.On veut que les programmes sâ€™executent dans un temps borne. On est pas des gistresâ€¦ Mais quand memeOn veut pas une reponse dâ€™1h avec des systemes critiques embarques (voitures, fusees, etc.)Power Consumption on SmartphonesCPU is a major source of power in smartphones (even with graphical-oriented app) Une bonne partie de la batterie est consommee par le CPU et GPUAujourdâ€™hui, on essaie de tout transferer sur le GPU car ca consomme moins que le CPUPower Consumption of Some ProcessorsQuâ€™est-ce quâ€™on remarque du prix par Gigaflops ? Le GPU est beaucoup plus rentable que le CPU. Tous les calculs ne sont pas basculables du CPU au GPU.Scientific ComputingA bit of history - The first GPUCe qui a motive la creation des GPU câ€™etait la medecine, etc. (meme si le gaming en a prit lâ€™avantage). Back in 70â€™s GPU were for Image Synthesis First GPU: Ikonas RDS-3000 A lâ€™epoque: tres difficile de programmer en GPU N. England &amp;amp; M. Witton founded Ikonas Graphics SystemsThe first GPGPU General Purpose GPUFirst programmable GPU: Vertex Shaders: programmable vertex transforms, 32-bits float Pipeline graphics Shaders: etapes de la pipeline quâ€™on pouvait remplacer A ouvert la voie vers le scientific computic Data-dependent, configurable texturing + register combinersEnabled early GPGPU results: Hoff (1999): Voronoi diagrams on NVIDIA TNT2 Larsen &amp;amp; MacAllister (2001): first GPU matrix multiplication (8-bit) Rumpf &amp;amp; Strzodka (2001): first GPU PDEsGPGPU for physics simulation on Geforce 3Approximate simulation of natural phenomenonGEFORCE FX (2003): floating pointTrue programmability enabled broader simulation research Ray Tracing Radiosity PDE solvers Physically-base simulation FFT (2003) High-level language: Brook for GPU (2004)GPGPU becomes a trend (2006)2 factors for the massive surge in GPGPU dev: Architecture Nvidia G80 Dedicated computing mode - threads rather than pixels/vertices General, byte-addressable memory architecture Software support C and C++ languages and compilers for GPUs (spoiler.. itâ€™s CUDA) Le graphique a droite veut rien dire (câ€™est du marketing)2010â€™sAccelerating discoveries Without GPUs, supercomputer would like 5x more timesAnd data center gave birth to Deep-Learning Les reseaux de neurones existaient deja dans les annees 80 mais on nâ€™avait pas la puissance de calcul avant 2010â€™sEmbedded systems - The real-time constraintsNeed both of the 2 worlds: Need ultra-performance computing With limited resourcesGPU vs CPU for parallelismHow to get things done quicker Do less work Do some work better (i.e. the one being he more time-consuming) Do some work at the sane time Distribute work between different workers Choose the most adapted algorithms, and avoid re-computing thing Choose the most adapted data structures ParallelismWhy parallelism ? Mooreâ€™s law: processors are not getting twice as powerful every 2 years anymore So the processor is getting smarter Out-of-order execution / dynamic register renaming Speculative execution with branch prediction And the processor is getting super-scalar Executer des choses en meme temps Nos CPUs sont des processeurs super-scalaires Toward data-oritented programmingThe burger factory assembly lineHow to make several sandwiches as fast as possible ? Avoir plusieurs personnes qui travaillent en meme temps sur le meme sandwich et vont executer les taches independantes en meme temps, avoir un worker maitre qui sâ€™occupe dâ€™assembler tout Avoir plusieurs workers qui travaillent en meme temps sur des sandwichs differents Mix entre les 2 strategies precedente: un worker qui peut bosser sur un sandwich ou plusieurs en meme temps Pipeline: un worker fait une etape et passe le sandwich a un autre worker Un worker a plusieurs brasA prendre en compte: La latence Le debitAvec la 1ere strategie:2 cycles optimisation en latence et debit Pas la plus efficace car etape de synchronisationAvec la 2e strategie Optimisation en debit mais pas en latenceAvec la 3e strategie: Tres lourd niveau synchronisationData-oriented programming parallelismFlynnâ€™s Taxonomy SISD: no parallelism SIMD: same instruction on data group (vector) MISD: rare, mostly used for fault tolerant code MIMD: usual parallel mode (multithreading) SPMT: Single Programm Multiple Thread Execute le meme programme Optimize for latency (MIMD with collaborative workers)4 super-workers (4 CPU cores) collaborate to make 1 sandwich Manu gets the bread and wait for the othersTime to make 4 sandwicches: $s$ (400% speed-up)Optimize for throughtput (MIMD Horizontal with multiple jobs)Time to make 4 sandwiches: s (400% speed-up)Optimize for throughput (MIMD Vertical Pipelining)Optimize for throughput (SIMD DLP) Un seul optimise en latenceMore cores is trendyData-oriented design have changed the way we make processors (even CPUs) Lower clock rate Large vector-size, more vector-oriented ISA More cores (processing units) Parallelisme: SIMDDepuis 2005/2006, on a des â€œfauxâ€ coeurs pour faire du multi-threadingCPU vs GPU performanceAnd you see it with HPC apps:Towards Heterogeneous ArchitecturesBut donâ€™t forget, you may need to optimize both latency and throughputWhat is the bounds speedup attainable on a parallel machine with a program which is parallelizable at $P\\%$ (i.e. must run sequentially for $(1-P)$) Utiliser la bonne architecture pour le bon travailGPU vs CPU architecturesItâ€™s all about the dataâ€¦ The CPU: optimized for low-latency access (many memory caches) Control logic for out-of-order and speculative executionItâ€™s all about data.. the GPU:Hiding latency with thread parallelism &amp;amp; pipeliningSoâ€¦ you want to hide the latency of getting data from from global memoryâ€¦ how ?1 CPU Core:1 GPU SMP (Streaming Multiprocessor)CPU: low-latency memory to get data ready each thread context switch has a costGPU: memory latency hidden by pipelining context switch is freeLatency hiding: = do other operations when waiting for data = having a lot of parallelism = having a lot of data will run faster but not faster than the peak what is the peak btw ? Peak: Peak de la memoire Donnee par un nombre Peak du compute Nombre dâ€™instructions quâ€™on peut executer par secondes Itâ€™s all about dataâ€¦ Littleâ€™s lawâ€La latence est typiquement la longueur de la pipelineHiding latencyWith thread parallelism &amp;amp; pipeliningNote that pipeline exists on CPUs (cycle de Von Neumann)More about forms of parallelism (the why!)More about forms of parallelism (the how!)Pourquoi on a un TLP horizontal sur les CPUs ?MulticoeursPourquoi on a un TLP vertical sur les CPUs ?Les hypercoeurs (coeurs logiques). Ce ne sont pas des vrais coeurs mais des threads capables de switch sur les coeurs.Extracting parallelismParallel architectures and parallelism All processors use hardware to turn parallelsim into performance" }, { "title": "PFEE - Sujet 6.1 et 6.2: Smiths group", "url": "/cours/posts/pfee_smiths/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-30 15:00:00 +0200", "snippet": "Lien de la 1ere note HackmdLien de la 2nd note HackmdSujets 6.1IntroductionPresentation psr Clement Fang Ancien Image 2020Serge Maitrejean Responsable de lâ€™innovation Doctorat en physiqueEric Garrido Doctorat en physique nucleaireGroupe Smiths Cote en bourse a Londres 4 divisions Smith detection: scanner et detection Detection de choses illicites ou non-declarees En france: Base a Vitry-sur-Seine A peu pres 200 personnes IA / traitement dâ€™imageâ€¦Les techs au sein de SmithGlobal presenceVehicle, cargo &amp;amp; mobile screeningHigh energy X-ray imagingWhich target / threat we are looking for ?SD Paris Partnerships Epita est cense etre laCigarettes detectionSome big seizures made thanks to our iCmore in the newsiCmore Weapons detectionMore in-depthTruck Radioscopy Imaging with X-Rays but with a scanning principle Pulsed X-ray source: X-Ray pulses (flash) oh three $\\mus$ every 2 or 3 milliseconds One vertical line of detectors/pixels (5 or 20 mm width, 5 mm height): one column of image is recorded for each X-ray pulses Truck speed is limited: &amp;lt; displacement of detector width between 2 pulses (typically 5-7 km/h) Or resolution is bad (large detectors)A new tech: Matrix detector Multicolumn detector (column) Large resolution improvement (Left one line, Right Matrix detector)But noting or nobody is perfect First problem: missing part Easy to solve by slowing down the speed butâ€¦ Superposition: le meme point se voit 2 fois The problem of depth at low speed: rearranging data ? The way of ordering data is depending on the depth where objects are located.. But we donâ€™t know the depth ! Itâ€™s a stereo effectOrdering data is depending on the depth We have to assume where in depth the object are located, if we are wrong strong artifacts appearsTurning a drawback onto an advantage Minimizing the artifacts $\\Leftrightarrow$ Finding the depth of the objects and providing a optimum high resolution imageCurent status Proof of concept has been done using energy minimization technics Work on this approach is pursuing A comprehensive set of data has been acquired from which the â€œexact imagesâ€ can be extracted We want to test another approach, neural networks and deep learning are good candidatesThe work Getting familiarized with the problem (not so easy) Getting familiarized with the current method Initating Matrix Detector Deep Learning process for: Building the best radioscopic planar images Finding the depth where objects are located Sujets 6.2IntroductionPresentation psr Clement Fang Ancien Image 2020Serge Maitrejean Responsable de lâ€™innovation Doctorat en physiqueEric Garrido Doctorat en physique nucleaireGroupe Smiths Cote en bourse a Londres 4 divisions Smith detection: scanner et detection Detection de choses illicites ou non-declarees En france: Base a Vitry-sur-Seine A peu pres 200 personnes IA / traitement dâ€™imageâ€¦High energy discrimination Same principle as an X-ray It looks like and X-ray but with an X-ray we only have grayscale informationPlus un objet et dense et epais, plus il sera noirWork to doImproving the performance of the material discrimination project by: Better management of the overlay problem Creatin better quality of scansOverlay 2 ojects that overlay make the material detection wrong Find a method to segment the objects, then assign their atomic numberImprove scan qualityCreate a neural network to convert acquisition from low device to highAn AI that assigns the atomic number of objectsCreate a color scale image with only the grayscale imageProvided Reference method Database Script to help for you for your tasks" }, { "title": "PFEE - Sujet 2: IMCCE - Caviar", "url": "/cours/posts/pfee_imcce/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-30 15:00:00 +0200", "snippet": "Lien de la note HackmdImages spatialesReduction astrometriqueexemple dune image ISS-CASSINILogiciel CAVIAR (IDL)Preversion Python" }, { "title": "PFEE - Sujet 3: Projet for event", "url": "/cours/posts/pfee_for-event/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-28 14:00:00 +0200", "snippet": "Lien de la note HackmdPFEE - Sujet 3: Projet for eventFiltres graphiques avances pour des team builiding et animations evenementielles Developpe des jeux digitaux dâ€™equipe Team building Sur tablette tactile2 applications:E-comicsE-QUESTLes participantsExemples de rendusObjectifsLa tech actuelle" }, { "title": "PFEE - Sujet 7: DXOMARK - Custom QT Video Player", "url": "/cours/posts/pfee_dxomark/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-26 16:00:00 +0200", "snippet": "Lien de la note HackmdIntroductionLaurent Chanas Product owner Partie creation/suivie des mesuresClaudio Ingenieur traitement dâ€™imageLoris Software developer pour lâ€™equipe Analyzer Integration traitement dâ€™imageA reference for the press and the industry Score DXOMARK de la camera lors de lâ€™annonce dâ€™un nouveau smartphone Grande expertise en traitement dâ€™imageRenowned for camera tests and scores for 12 years, DXOMARK also tests audio and displayAnalyzer, the measurement reference solution The reference for reliable image quality evaluation and optimizationA turn-key and modular solutionAnalyse la photo de lâ€™appareil photo pour trouver des defautsEasy-to-use software Un peu old schoolAnalyzer, a standards compliant solution Important que tous les produits suivent les normesLâ€™equipe Une equipe hardware Une equipe traitement dâ€™image/software Suivi hebdomadaireLe projetContexte du projetAujourdâ€™hui, il y a plusieurs facon de decoder une video. Il faut determiner la librairie qui correspondLâ€™existantInspiration dâ€™un logiciel existant Le logiciel doit utiliser du GPUDescription du projet Les demo seront toujours en Python, en utilisant la partie cree en C++Il faut quâ€™il y ait quelque chose dâ€™aboutit a chaque fin de mois, faire une demonstration de quelque chose de fonctionnelleOrganisation du projetPourquoi utiliser du Python ?Beaucoup de mesures dev en PythonQuestionsLe projet est que pour les etudiants ou il y a une equipe ? Que les etudiantsLes attentes: quelles attentes en terme de temps pour un lecteur en C++? On ne nous demande pas de refaire un decodeur video, on utilisera FFMPEG, bonnes inspirations sur des projets existants." }, { "title": "PFEE - Sujet 5: Breast cancer detection - GE", "url": "/cours/posts/pfee_ge/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-23 14:00:00 +0200", "snippet": "Lien de la note HackmdX-ray breast imaging worldwide breast cancer account for $25.2\\%$ of all female cancers and 16% of cancer deaths in adult women mammography uses low-energy X-ray Il faut detecter des lesions tres petites Certaines lesions sont begninesLesionsArtificial intelligence applications AI tools are becoming a must-have for mammography screening systems They can provide significant speed increase of radiologist workflow and more importantly improve quality of their job Possible applications: Negative Triage AI algorithm triage of negative cases in order to allow radiologist to concentrate on more important points AI CAD Detect cancer at very early stages which can not be identified by radiologist Project description Perform analysis of object detection state-of-the-art methods Define model architecture on the example of public dataset Digital Database for Screening Mammography Implement pipeline for model training Perform training and optimization of the modelQuestionCâ€™est en python ? OuiSi jâ€™ai bien compris le projet est a rÃ©alisÃ© depuis le tt dÃ©but ? Il y a rien de fait ? A deja un prototype, le deep learning se developpe tres vite et veut investiguer des nouvelles propositions" }, { "title": "PFEE - Sujet 1: Mihaly", "url": "/cours/posts/pfee_mihaly/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-23 11:00:00 +0200", "snippet": "Lien de la note HackmdProjet githubAucun travail nâ€™a ete fait encore, le but est de commencer a coder des shaders.PresentationLouis Image 2021 â€œLe mec a cheveux longs et aux lunettesâ€ Le sujet: creer un voxelisateur multi-materiaux Soit Mihaly soit Dassault pour faire du Typescript en stage de fin dâ€™annee A choisi Mihaly Le projet sera notre projet de A a Z, quâ€™on arrive a faire des trucs ou pas Suivi regulier â€œEn soit on attend rienâ€ Questions ?Genre ca ca tourne sur Android ? Google mon poteOn est plus sur la crÃ©ation des matÃ©riaux qui peuvent fonctionner sur des modÃ¨les Ã  imprimer plutÃ´t que de travailler dans le moteur lui-mÃªme si jâ€™ai bien comprit, câ€™est Ã§a? On nous donne une table de materiaux avec des proprietes physiques, le but est de voir comment on peut passer de lâ€™un a lâ€™autreJe ne comprends pas forcÃ©ment lâ€™intÃ©ret de lâ€™automatisation On connait tout un tas de materiaux, on veut savoir si en donnant une liste de proprietes on peut creer le materiel. On voudrait avoir une table exhaustive avec tous nos materiaux et voir si on est capable de dire que tel materiel a telle propriete et etre capable de relier ca avec un materiel quâ€™on a deja et creer un shader.Câ€™est quoi comme genre de materiaux ? Genre des resines qui rendent comme du metal/bois ? Oui, câ€™est que de la resine qui rende comme ils veulent. Le but est de modifier la resine pour quâ€™elle ressemble a tel ou tel materiel.Est-ce quâ€™il peut prÃ©senter lâ€™entreprise? Lâ€™entreprise se porte bien ? Mihaly est une societe qui fait de la numerisation 3D et impression 3D. Ils travaillent aujourdâ€™hui sur de la reproduction et numerisation de tableauxCarte de Paris avec des details 3DTableau avec les traces de spatule, etc.La boite a uniquement 2 ans.Ils arrivent a faire de lâ€™impression sur pleins de materiaux differents (metal, verre, tissu, etc). Ce sont les seuls a faire ca au monde et egalement de lâ€™impression 3D en couleurs directement.La boite se porte plutot biem, elle a recemment gagne un concours de Saclay pour les startups les plus innovantes.Quel type de clientele ? Probleme: le produit est tres jeune, le modele economique est pas encore setup (et la crise du Covid). Les cartes de Paris pour les particuliers (qui peuvent y mettre le prix).Le sujet sera encadre ? Encadre par Louis et Christophe (jusquâ€™a la fin du stage de Louis pour lui)" }, { "title": "PFEE : Presentation Sujet 4 Zeiss/EPITA", "url": "/cours/posts/pfee_zeiss/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-22 14:45:00 +0200", "snippet": "Lien de la note HackmdAvec Daniel Godin, ancien image Simon Franchini, PhD et ingenieurIntroductionAbout Zeiss: Founded in 1849 Leading actor in imaging solutions 30000+ collaborators Represented in 50+ countriesAbout Apeer: Project part of the research for microscopy solutions department Cloud based platform for image analysisEPITA student project ApeerML: automated ML segmentation platform Processed &amp;gt; 100 different use cases in very different domains Constantly improving automation in the development of degmentation algorithmsThe challengeThe taskReduction of memory footprint by separtion and merging within smaller spatial domainProject organization and general setup Project will be divided between Research and Implementation Starts with state-of-the-art review of current solutions Docker image ready with problem statements and Test images Programming language: Python Communication: English Development on private Zeiss Github repo Acces to experts in microscopy and image processing" }, { "title": "Conference IBM: Quantum computing et machine learning", "url": "/cours/posts/conf_IBM/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-22 10:00:00 +0200", "snippet": "Lien de la note HackmdPresentationGeorges Usbelger Advanced Analytics &amp;amp; Quantum Computing Leader Development of Academic / Research RelationsNotre perception de la realite 3 phenomenes importantsSuperposition dâ€™etat: Exemple: on est dans un cinema et avant de choisir une place, on est sur toutes les places en meme temps. (chat de Schrodinger)En passant a lâ€™echelle macroscopique, on perd toutes ces proprietes. (decoherence)Intrication:Si on rapproche 2 particules, elles vont echanger des informations et devenir la particule AB. Si une perturbation arrive sur une des particules, peu importe la distance entre les 2 particules, lâ€™autre particule aura la meme perturbation. (contredit la vitesse max qui est la vitesse de la lumiere)Histoire de lâ€™ordinateur quantiqueA partir de 2016, IBM a pu developper le premier processeur quantique.Information binaireRajouter un Qbits multiplie le nombre de configurations possibles par 2.Dâ€™un point de vue algorithmiqueSi on ecrit un algo capable dâ€™exploiter les capacites quantique, lâ€™algorithme va se â€œdiffuserâ€ le long des chemins possiblesApplications types dâ€™evaluation/decision eligibles avec lâ€™informatique quantiqueApport de lâ€™IA et de lâ€™informatique quantique pour la valeur metierApplications eligibles par industrie R&amp;amp;D Molecular Simulation et Quantum Chemistry Material Sciences Banques Risques (Methode de Monte Carlo) Gestion de portefeuilles Energie/Telecom/Transport Sante Defense &amp;amp; securiteElaboration de molecules de syntheseLe qubit et ses proprietesPrincipales portes quantiquesLe qubit et sa representatin sur la sphere de BlochPort de Hadamard Permet dâ€™engendrer la superposition dâ€™etatPort CNOT Permet dâ€™associer 2 qubitsLe â€œparallelismeâ€ quantique Câ€™est lâ€™association des 2 portes precedentesCriteres de David DiVincenzoTechnologie quantiqueDevelopement Roadmap IBMQuantum volumeIBM is builiding the larger ecosystem to ensure sucessIBM Q experienceIBM Q Quantum ExperienceUne nouvelle ereDu descriptif au prescriptifLa classification non hierarchique de type k-meansLes SVMReseau de neuronesFormations" }, { "title": "Conference Google: Construire des solutions plus intelligentes sans expertise en machine learning", "url": "/cours/posts/conf_google/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-20 14:00:00 +0200", "snippet": "Lien de la note Hackmd Sans expertise en ML != Sans MLIntroWho are we ?Laurent Picard Developer advocate - Google Cloud Ebook pioner Any sufficiently advanced technology is indistiguishable from magic Arthur C. Clarke What is machine learning ?Why is machine learning now possible ?Three ways we can benefit from ML today Ne reiventez pas la roue !Nouveau champ: auto-ML on peut construire nos propres models sans expertiseMachine learning APIReady-to-use modelsVision APIComputer vision before ML:Landmark detection: Capable de determiner ou a ete prise la photo (quel endroit)La photo originale a ete modifiee (symetrie horizontale) Toujours capable de determiner lâ€™origine de la photoObject detection:Face detection:Vue 3D de Gollum donc pas un vrai visage humain (mais marche quand meme !)Text detection:Meme avec une legere rotation, on detecte toujours le texteDetecte egalement lâ€™ecriture manuscrite (quelques erreurs)Web entity detection and image matching:La photo ci-dessus de Tolkien est totalement inedite pour lâ€™API utilisee, capable de reconnaitre Tolkien + determiner que lâ€™origine est un journal espagnolOSS Client librariesLibrairies clientes en open-source sur GitHub dans plusieurs langages.Video Intelligence APIDemo:OSS Client librariesNatural Language APIAnalyze text with a simple requestSyntax analysis:Entity detectionContent classificationSentiment analysis: Le ML se plante totalement sur la detection du sarcasme.Translation API Google Translate par exemple! On peut les ameliorer regulierement en fournissant de plus en plus dâ€™exemples et de contre-exemples.Speech-to-Text APIConvert text to speech in 120 languages with a simple request. Fonctionne en temps reel. Ex: il y a quelques annees repeter a un bot en appelant une banque â€œJe veux un conseillerâ€ en esperant quâ€™il comprenne.Consequence sympa des reseaux neuronaux: aujourdâ€™hui les speech-to-text API sont resistants aux bruits car ils apprennent a partir de vrais echantillon.Speech timestamps:Search for text within your audioOSS Client librariesText-to-speech (TTS) APIGenerate natural speech with a simple requestWaveNet natural voices, par Deepmind Câ€™est le modele le plus avance de tous, qui reproduit le mieux une voix humaine.Demo: â€œQuelle est la temperature a Paris ?â€ avec un accent anglaisTadaaaaaaOSS Client librariesTuto pour generer des voixAutoMLBuild your custom model with no expertiseGeneric results with the Vision APICloud AutoMLDemo:Utilisation de ~250 images en moyennes â€œJusteâ€ 3h de calculs.Auto-generate a custom model from your dataUnified in AI PlatformDemoEvaluationTransfert learningHyperparameter tuningConlusionHow can I build smarter solutions ?Liens utilesâ†’ PrÃ©sentationâ†’ BD Google AIâ†’ ML codelabs" }, { "title": "Conference Talan", "url": "/cours/posts/conf_talan/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-19 14:00:00 +0200", "snippet": "Lien de la note HackmdAnimateurLaurent Cervoni Directeur de la Recherche et de lâ€™Innovation du Group Talan Ingenieur de ESIEE Paris Docteur en informatique (IA)TalanSecteurs Energie Service publique Telecom Finance Assurance Transport Industrie RetailImplantations France InternationalDomaines expertisePiliers technologiqueQuâ€™est-ce que lâ€™IA ? Câ€™est pas magique, câ€™est de lâ€™informatique.$\\to$ Cloner le cerveau humain/animal Apprentissage Apprend au fil du temps et des donnees Perception Interprete la signification des donnees, notamment le texte, la voix et les images Cognition Aboutit a des conclusions decisives, actions voire interactions Machine learning, une des branches de lâ€™IAHistoire de lâ€™IAEn 2012: tournant dans lâ€™IA, ce nâ€™est plus de lâ€™IA mais de lâ€™informatique avancee Les reseaux de neurones reviennent au gout du jourPanorama (subjectif) de lâ€™IAIA numerique: IA actuelle Machine Learning: pas que reseaux de neuronesSeparation IA symbolique et numerique un peu fausse: sâ€™interesectent beaucoupIA et consommation energetiqueQuel est lâ€™impact ecologique de lâ€™IA ? Demande energetique importante Le deep learning ca consomme Tres dur de mesurer lâ€™impact objectif de lâ€™IA dans la conso globaleImpact environnementalIA Inscrire lâ€™IA dans une demarche de developpement durable Depuis 5 ou 6 ans deja, les GAFA essaient de rendre leurs propres installations plus â€œvertesâ€Numerique Penurie de ressources (hors energie fossile) Emission de gaz a effet de serre (rutile, mineral de fer, cobalt) Obsolescence Le vrai sujet = les equipements numeriquesLe numerique en exergue Lâ€™IA ne consomme pas tant que ca par rapport au reste du numeriqueConsommation dans lâ€™IALâ€™IA numerique a une activite polluante directe et indirecteCadrage de projet IA: Prendre en compte lâ€™impact environnemental et socialIA pour optimiser la gestion centralisee des centres commerciauxKlepierre, un acteur majeure de la gestionAugmenter la production dâ€™energie renouvelableOptimiser les reseauxLa data pour lâ€™IAGros volume de donneesLa data-isation du mondeBig data, smart data, small dataExplosion de la capacite a gerer les donneesâ€¦ avec une recherche de reduction de la puissance CPUTransfert learning Apprentissage supervise uniquement sur la couche de sortieLes â€œformesâ€ dâ€™IA sont multiplesSi on â€œmixeâ€ les formes dâ€™IA, on a une meilleure approche niveau consommation.Conclusions Q&amp;amp;ALâ€™IA nâ€™est pas la seule solution Stockage ADN Lâ€™intelligence artificielle represente une part infime de la consommation electrique mondiale et elle peut contribuer a optimiser les depenses energetiques mais elle doit sâ€™appliquer a elle-meme la voie de la frugaliteQuestionsPouvez-vous nous parler de votre entreprise et de lâ€™interÃªt que vous pourriez avoir pour notre Ã©cole ? Cad en termes de stages ou dans quelles branches recruteriez-vous ? Talan travaille avec Epita/Epitech et recrute des doctorants. Talan va essayer dâ€™avoir une participation plus active aux cotes de lâ€™ecole (stage/dev). 4 structures: Talan operation, Talan Labs, Talan Solution (recrute profils de lâ€™Epita)" }, { "title": "IML: Supervised learning", "url": "/cours/posts/iml_supervised_learning/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8", "date": "2021-04-16 14:00:00 +0200", "snippet": "Lien de la note HackmdSupervised learning Supervised learning: process of teaching a model by feeding it input data as well as correct output data. The model will (hopefully) deduce a correct relationship between the input and output An input/output pair is called labeled data All pairs form the training set Once training is completed, the model can infer new outputs if fed with new inputs.Given some training data ${x_i,y_i}^n_{i=1}$, supervised learning aims at finding a model $f$ correctly mapping input data $x_i$ to their respective output The model can predict new outputs The learning mechanism is called regression or classificationManaging data for supervised learningHide some data out during training ($\\simeq20\\%$ data) to further evaluate model performances $\\Rightarrow$ train/test splitUse validation set ($\\simeq15\\%$ data) if parameters are iteratively adjusted $\\Rightarrow$ tain/validation splitStratified sampling For classification purposesCLasses might be imbalanaced $\\Rightarrow$ use stratified sampling to guarantee a fair balance of train/est samples for each classRegression The art of predicting values Regression: the output value to predict $y$ is quantitative (real number)$\\Rightarrow$ How to mathematically model the relationship between predictor variables $x_i$ and their numerical output $y_i$ ?Linear regressionSometimes, thereâ€™s no need for a complicated modelâ€¦Ordinary Least SquaresAnscombesâ€™ quartetFor all 4 datasets ${(x_1,y_1),(x_2,y_2),â€¦,(x_{11},y_{11})}$Le 3e regression a une donnee aberrante, cad une donnee tres eloignee des autres qui risque de fausser la regression (probablement du au capteur qui sâ€™est chie dessus)$\\Rightarrow$ Linear regression line $y=3+0.5x$ and $R^2=0.67$ are the SAME for all 4 datasetsLeast absolute deviationLinear regression by OLS is sensitive to outliers (tj=hank you $L_2$ normâ€¦)Is it a good idea ? $\\beta_{LAD}$ is the MLE estimator of $\\beta$ when noise follows a Laplace distribution No analyticial formula for LAD Harder to find the solution Must use gradient descent approach Solution of LAD may not be unique Toutes les droites dans le cone sont optimalesAdding some regularizationAdd apenalty term to OLS to eforce particular properties to $\\hat\\beta$From regression to classificationLogistic regressionLinear regression predicts a real value $\\hat y$ based on predictor variables $x=(x^{(1)},â€¦,x^(k))$ Does not work is $y$ is boolean $P(y=1)=p$ and $P(y=0)=1-p$ Use logistic regression insteadLinear relationship between predictor variables and logit of event:k-nearest neighborsk-NN classifier simply assigns test data points to the majority class in the neighborood of the test points no real training stepResult:Choosing k small k: simple but noisy decision boundary large k: smoothed boundaries but computationally intensive $k=\\sqrt{n}$ can also serve as a starting heuristic, refined by cross-validation $k$ should be odd for binary classificationk-nearest neighbors for regressionUse the k nearest neighbors (in terms of features only) and average to get predicted valueSupport Vector MachineLinear SVMTraining set: \\(\\{x_i,y_i\\}_{i=1}^n\\) with $x_i\\in\\mathbb R^p$ and $y_i\\in{-1,+1}$Goal: find hyperplane that best divide positive sample and negative samplesQuâ€™est-ce quâ€™on a envie de faire ici ?Une moyenne On cherche la droite qui passe le plus au centre Rappel: produit scalaire de 2 vecteurs colineaires:\\[&amp;lt;\\vec w, \\vec{AB}&amp;gt; = \\Vert \\vec w\\Vert.\\Vert \\vec{AB}\\Vert\\]Soft margin SVMData may not be fully linearly separableKernel SVM Remember the kernel trick ?Kernel trick: map data points into high dimesional space where they would become linearly separable Effortlessly interfaced with the SVM by replacing dot product $&amp;lt;.,.&amp;gt;$ by kernelizes version $k(.,.)$Widely used kernel functions: Polynomial kernel Gaussian RBF kernel Sigmoid kernel Choosing the right kernel with the right hyperparametersKernel $\\Rightarrow$ Try linear first. If does not work, RBF is probably the best kernel choice (unless you have some prior information on the geometry of your dataset)Hyperparameters ($C$ + kernel parameter(s)) $\\Rightarrow$ grid search and cross-validationMutliclass SVMWhat if we have more than 2 classes ?2 possible strategiesone vs all: One SVM model per class $\\to$ separate the class from all other classes Assign new points with winner takes all rule if no outright winner, assign point to the class of closest hyperplane (Platt scaling)One versus one: one SVM model per pair of classes $\\to$ separate 2 classes at a time, ignoring the other data assign new points with majority voting ruleDecision trees Decision trees use recusrive partitioning to create a sequence of decision rules on input features that nested split of data pointsInput features can be numeric (decision $\\le$) or categorical (decision $==$)Decision node $=$ decision rule for one featureClassification tree $\\to$ predict classRegression tree $\\to$ predict real numberOn the current node, try to apply all the possible decision rules for all features and select the decision that best split the dataClassification tree $\\to$ impurity riterionRegression tree $\\to$ variance reductionFinal decision boundaries $\\equiv$ overlapping orthogonal half planesDecision on new data $\\to$ running it down through the branches and assign classesHow to split a nodeWhich split should we choose between La reponse est goche Stop recursive partitionning if node is purePros and cons of decision treesPros Simple decision rules Surprisingly computationally efficient Handle multiclass problems Handle numeric and categorical features at the same timeCons Strongly overfit data Bad predictive accuracy Potential solutionRestrain the growth of the tree by imposing a maximal tree depthRandom forests Bagging several decision treesDecision trees are weak classifiers when considered individually Average the decision of several of them Compensate their respective errors (wisdom of crowds) Useless if all decision trees see the same data introduce some variability with bagging (bootstrap aggregating) Introduce more variability by selecting only $p$ out of $m$ total features for each split in each decision tree (typically $p=\\sqrt{m}$)Final decision is taken by majority voting on all decision tree outputsDecision boundaries comparisonEvaluating regression/classification performancesCross-validation$k$-fold cross validation Divide whole data into $k$ non-overlapping sample blocks Train $k$ models on $(k-1)$ training blocks and test on remaining block Compte perf metrics of each model + avergae &amp;amp; standard deviation of all $k$ modelsConfusion matrix" }, { "title": "OCVX: TD Differentielle", "url": "/cours/posts/ocvx_differentielle_exercices/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-15 10:00:00 +0200", "snippet": "Lien de la note HackmdOCVX: TD Differentielle But de la seance: comprendre les differentiellesRappels Definition premiere de la differentielleUne fonction \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^n \\\\ x=(x_1,...,x_n)&amp;amp;\\mapsto (f_1(x),...,f_n(x))\\end{aligned}\\) est differentiable en un point $x_0$ si on peut ecrire\\[f(x_0+h)=f(x_0)+\\color{red}{d_{x_0}f(h)}+\\Vert h\\Vert\\varepsilon(h)\\] $d_{x_0}f:h\\mapsto d_{x_0}f(h)$ est une application lineaire: $d_{x_0}f(h_1+\\lambda h_2)=d_{x_0}f(h_1)+\\lambda d_{x_0}f(h_2)$Notation: $d_{x_0}f$ / $df_{x_0} / Df(x_0)$$1^{ere}$ maniere de calculer la differentielle$1^{ere}$ maniere de calculer la differentielle en $x_0$ de $f$: ecrire et lineariser \\(f(x_0+h)=f(x_0)+d_{x_0}f(h)+\\underbrace{\\Vert h\\Vert\\varepsilon(h)}_{\\mathcal O_o(h)}\\)$2^{ere}$ maniere de calculer la differentielleSi 1.\\(\\begin{aligned} f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ d_{x_0}f:h&amp;amp;\\mapsto hf&#39;(x_0)\\\\ \\end{aligned}\\)2.\\(\\begin{aligned} f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ d_{x_0}f:h&amp;amp;\\mapsto &amp;lt;\\nabla_{x_0}f, h&amp;gt; = \\nabla_xf^Th\\\\ \\end{aligned}\\\\\\nabla_{x_0}f=\\begin{pmatrix} \\frac{\\partial f}{\\partial x_1}(x_0) \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n}(x_0) \\end{pmatrix}\\)3.\\(\\begin{aligned} f:\\mathbb R^n&amp;amp;\\to\\mathbb R^m \\\\ d_{x_0}f:h&amp;amp;\\mapsto Jac_{x_0}f\\times h\\\\ \\end{aligned}\\\\Jac_{x_0}f=\\text{matrice jacobienne}\\\\[Jac_{x_0}f]_{ij} = \\frac{\\partial f_i}{\\partial x_j}(x_0)\\\\Jac_{x_0}f=\\begin{bmatrix}\\frac{\\partial f_1}{\\partial x_1}(x_0) &amp;amp; \\dots &amp;amp; \\frac{\\partial f_1}{\\partial x_n}(x_0)\\\\\\vdots &amp;amp; \\ddots &amp;amp;\\vdots\\\\\\frac{\\partial f_n}{\\partial x_1}(x_0) &amp;amp; \\dots &amp;amp; \\frac{\\partial f_m}{\\partial x_n}(x_0)\\\\\\end{bmatrix} = \\begin{pmatrix}\\nabla_{x_0}f_i^T \\\\ \\vdots \\\\ \\nabla_{x_0}f_m^T\\end{pmatrix}\\) $f$ differentiable $\\Rightarrow$ existence et continuite des $\\frac{\\partial f}{\\partial x_i}$ Existence et continuite des $\\frac{\\partial f_i}{\\partial x_j}$ $\\Rightarrow$ $f$ differentiableExemple\\[f:(x,y)\\mapsto \\frac{xy}{x^2+y^2}\\quad (x,y)\\neq(0,0); 0\\quad(x,y) = 0\\\\f:(x,y)\\mapsto \\frac{xy}{\\sqrt{x^2+y^2}}\\quad (x,y)\\neq(0,0); 0\\quad(x,y) = 0\\] Fonction ou ca se passe malDifferentielle de 2 fonctions RappelPour des fonctions $f,g:\\mathbb R\\to\\mathbb R$ $(f+\\lambda g)â€™=fâ€™+\\lambda gâ€™$ $(fg)â€™=fâ€™g+gâ€™f$ $(f\\circ g)â€™(x)=fâ€™(g(x))\\times gâ€™(x)$ Pour la differentielle: $d_x(f+\\lambda g)=d_xf+\\lambda d_xg$ $d_x(fg)=g(x)d_xf+f(x)d_xg$ $d_x&amp;lt;f,g&amp;gt;=&amp;lt;d_xf,g(x)&amp;gt; + &amp;lt;f(x),d_xg&amp;gt;$ $\\to$ pas ouf comme ecriture $d_x&amp;lt;f,g&amp;gt;:f\\mapsto &amp;lt;d_xf(h),g(x)&amp;gt; + &amp;lt;f(x),d_xg(h)&amp;gt;$ $d_xg\\circ f=d_{g(x)}f\\circ d_xg$ $\\to$ pas ouf comme ecriture \\[\\begin{aligned} d_xg\\circ f:h&amp;amp;\\mapsto d_{g(x)}f\\circ d_xg(h) \\\\ &amp;amp;=d_{g_x}f(d_xg(h)) \\end{aligned}\\] ExercicesExercice de coursDifferentielle de \\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ x&amp;amp;\\mapsto \\frac{\\sin(x)}{x^2+1}\\end{aligned}\\) en tout point $x$ Solution Rappel \\(\\biggr(\\frac{u(x)}{v(x)}\\biggr)&#39; = \\frac{u&#39;(x)v(x)-u(x)v&#39;(x)}{v^2(x)}\\) Seconde methode: Moyen memo technique si(mple) $\\to$ $\\cos$ co(mplique) $\\to$ $-\\sin$ \\[\\begin{aligned}f&#39;(x) &amp;amp; =\\frac{\\cos(x)(x^2+1)-\\sin(x)2x}{(x^2+1)^2}\\\\&amp;amp;=\\frac{(x^2+1)\\cos(x)-2x\\sin(x)}{(x^2+1)^2}\\end{aligned}\\\\d_xf:h\\mapsto hf&#39;(x)\\] Premiere methode (mode bourrin):\\(f(x+h)=\\frac{\\sin(x+h)}{(x+h)^2+1}=\\frac{\\sin(x)\\cos(h)+\\cos(x)\\sin(h)}{x^2+2xh+h^2+1}\\\\\\underbrace{\\frac{\\sin(x)\\cos(h)}{(x^2+1)(1+\\frac{2x}{x^2+1}h+\\frac{h^2}{x^2+1})}}_{\\text{premier terme}} + \\underbrace{\\frac{\\cos(x)\\sin(h)}{(x^2+1)(1+\\frac{2x}{x^2+1}h+\\underbrace{\\frac{h^2}{x^2+1}}_{\\mathcal o(h)})}}_{\\text{second terme}}\\\\\\begin{aligned}\\text{Second terme }=&amp;amp;\\frac{\\cos(x)\\sin(h)}{x^2+1}\\underbrace{\\frac{1}{(x^2+1)(1+\\frac{2x}{x^2+1}h+o(h))}}_{1-\\frac{2xh}{x^2+1}+o(h)}\\quad\\color{red}{\\frac{1}{1+u}\\sim 1-u+o(u)}\\\\&amp;amp;\\frac{\\cos(x)\\sin(h)}{x^2+1}\\biggr(1-\\frac{2xh}{x^2+1}+o(h)\\biggr)\\quad\\color{red}{\\sin(u)\\sim u+o(u)}\\\\&amp;amp;\\frac{\\cos(x)(h+o(h))}{x^2+1}\\biggr(1-\\frac{2xh}{x^2+1}+o(h)\\biggr)\\\\&amp;amp;= \\frac{\\cos(x)(h+o(h))}{x^2+1}-\\underbrace{\\frac{2xh}{x^2+1}\\frac{\\cos(x)(h+o(h))}{x^2+1}}_{o(h)}+o(h)\\\\&amp;amp;= h\\frac{\\cos(x)}{x^2+1}+o(h)\\end{aligned}\\) Câ€™est que le second terme, on fait pas le premier parce quâ€™on a pas envie de crever.Exercice 2-37 Solution 1.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^m &amp;amp;A\\in\\mathcal M_{m,n}(\\mathbb R)\\\\x&amp;amp;\\mapsto Ax+b &amp;amp;b\\in\\mathbb R^m\\end{aligned}\\\\f(x+h)=A(x+h)+b=\\underbrace{Ax+b}_{f(x)} + \\underbrace{Ah}_{\\text{lineaire en }h}\\\\\\begin{aligned}d_xf:h&amp;amp;\\mapsto Ah\\\\d_xf(h)&amp;amp;=Jac_xf\\times h\\end{aligned}\\biggr\\} Jac_xf=A\\] 2.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\quad A\\in\\mathcal M_{n}(\\mathbb R) \\text{ symetrique}\\\\x&amp;amp;\\mapsto x^TAx\\end{aligned}\\\\\\begin{aligned}f(x+h)&amp;amp;=(x+h)^TA(x+h)\\\\&amp;amp;= \\underbrace{x^TAx}_{f(x)} + \\underbrace{x^TAh}_{\\in\\mathbb R} + \\underbrace{h^TAx}_{\\in\\mathbb R} + \\underbrace{h^TAh}_{= (h^TAx)^T=x^TA^Th=x^TAh}\\\\&amp;amp;= f(x) + \\underbrace{2x^TAh}_{d_xf(h)}+\\underbrace{hTAh}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_xf:h&amp;amp;\\mapsto 2x^TAh\\\\d_xf(h)&amp;amp;=2x^TAh = &amp;lt;\\nabla_xf,h&amp;gt; = \\nabla_xf^Th\\\\&amp;amp;\\to \\nabla_xf^T=2x^TA\\\\&amp;amp;\\to \\nabla_xf = 2A^Tx\\end{aligned}\\\\\\] 3.\\[\\begin{aligned}f:\\mathcal M_n(\\mathbb R)&amp;amp;\\to\\mathbb R\\\\X&amp;amp;\\mapsto tr^2(X)\\end{aligned}\\\\\\begin{aligned}f(X+H) &amp;amp;= tr^2(X+H) = (tr(X+H))^2 = (tr(X)+tr(H))^2\\\\&amp;amp;= \\underbrace{tr^2(X)}_{f(X)} + \\underbrace{2tr(X)tr(H)}_{d_Xf(H)}+\\underbrace{tr^2(H)}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_Xf:H&amp;amp;\\mapsto 2tr(X)tr(H)\\\\d_Xf(H)&amp;amp;=\\nabla_Xf^TH=2tr(X)tr(H)\\end{aligned}\\] 4.\\[\\begin{aligned}f:\\mathcal M_n(\\mathbb R)&amp;amp;\\to M_n(\\mathbb R)\\\\B&amp;amp;\\mapsto tr(AB)B\\end{aligned}\\\\\\begin{aligned}f(B+H)&amp;amp;= tr(A(B+H))(B+H) = tr(AB+AH)(B+H)\\\\&amp;amp;= \\underbrace{tr(AB)B}_{f(B)} + \\underbrace{tr(AB)H + tr(AH)B}_{d_Bf(H)} + \\underbrace{tr(AH)H}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_Bf:H&amp;amp;\\mapsto tr(AB)H + tr(AH)B\\\\d_Bf(H)&amp;amp;=Jac_B(f)\\times H\\end{aligned}\\]Exercice 2-38 Solution\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^n &amp;amp;A\\in\\mathcal M_n(\\mathbb R\\\\X&amp;amp;\\mapsto &amp;lt;\\color{blue}{\\underbrace{AX+b}_{f_1(X)}}, \\color{red}{\\underbrace{tr(A)X}_{f_2(X)}}&amp;gt; &amp;amp;b\\in\\mathbb R^n\\end{aligned}\\] Rappel \\(d_x&amp;lt;f,g&amp;gt;:h\\mapsto&amp;lt;d_xf(h),g(x)&amp;gt; + &amp;lt;f(x),d_xg(h)&amp;gt;\\) \\[d_xf_1:h\\mapsto \\color{green}{Ah}\\\\f_2(x+h) = tr(A)(x+h)=tr(A)x+\\underbrace{tr(A)h}_{d_xf_2:h\\mapsto \\color{orange}{tr(A)h}}\\] Donc:\\[\\begin{aligned}d_xf:h\\mapsto d_x&amp;lt;f_1,f_2&amp;gt;(h)&amp;amp;= &amp;lt;\\color{green}{d_xf_1(h)},\\color{red}{f_2(x)}&amp;gt; + &amp;lt;\\color{blue}{f_1(x)},\\color{orange}{d_xf_2(h)}&amp;gt;\\\\&amp;amp;= &amp;lt;Ah,tr(A)x&amp;gt; + &amp;lt;Ax+b,tr(A)h&amp;gt;\\end{aligned}\\\\d_xf:h\\mapsto &amp;lt;Ah,tr(A)x&amp;gt; + &amp;lt;Ax+b,tr(A)h&amp;gt;\\]Exercice 2-39 Solution 1.\\[\\begin{aligned}g:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\frac{1}{x^Tx+1}\\end{aligned}\\\\\\] Rappel \\(d_xf\\circ g = d_{g(x)}f\\circ d_xg\\\\d_xf\\circ g(h) = d_{g(x)}f(d_xg(h))\\) \\[g(x) = b\\circ a(x)\\\\\\begin{aligned}a:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto x^Tx+1\\\\d_xa:h&amp;amp;\\mapsto 2x^Th \\end{aligned}\\\\\\begin{aligned}b:\\mathbb R&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\frac{1}{x}\\\\d_xb:h&amp;amp;\\mapsto hb&#39;(x) = -\\frac{1}{x^2}h \\end{aligned}\\\\d_xb(h) = -\\frac{1}{x^2}h \\quad d_xa(h)=2x^Th\\\\\\begin{aligned}d_xb\\circ a(h)&amp;amp;=d_{a(x)}b(\\underbrace{d_xa(h)}_{y})\\\\&amp;amp;= d_{a(x)}b(y)\\\\&amp;amp;= -\\frac{1}{(a(x))^2}y\\\\&amp;amp;= -\\frac{1}{(x^Tx+1)^2}y\\\\&amp;amp;= -\\frac{1}{(x^Tx+1)^2}2x^Th\\\\\\to d_xg:h&amp;amp;\\mapsto-\\frac{2x^Th}{(x^tx+1)^2}\\equiv \\biggr(\\frac{1}{u(x)}\\biggr)&#39; = -\\frac{u&#39;(x)}{u(x)}\\end{aligned}\\] 2.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\cos^2(x^TAx)\\end{aligned}\\\\f(x) = b\\circ a(x)\\\\\\begin{aligned}a:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto x^TAx\\\\d_xa:h&amp;amp;\\mapsto 2x^TAh\\\\b:\\mathbb R&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\cos^2(x)\\\\d_xb:h&amp;amp;\\mapsto hb&#39;(x) = -2\\cos(x)\\sin(x)h = -sin(2x)h\\end{aligned}\\\\\\begin{aligned}d_xf(h) = d_xb\\circ a(h) = d_{a(x)}b(\\underbrace{d_xa(h)}_{y}) = d_{a(x)}b(y) &amp;amp;= -\\sin(2a(x))y\\\\&amp;amp;= -\\sin(2x^TAx)y\\\\&amp;amp;= -\\sin(2x^TAx)2x^TAh\\end{aligned}\\]Exercice 3-42On calcule un gradient ou une jacobienne ? Solution Gradient Jacobienne Jacobienne Gradient Gradient Gradient Exercice 3-43$f:\\mathbb R^3\\to\\mathbb R$ differentiable en tout point de $\\mathbb R^3$Soit \\(\\begin{aligned} g:\\mathbb R^3&amp;amp;\\to\\mathbb R \\\\ (x,y,z)&amp;amp;\\mapsto f(x-y,y-z,z-x) \\end{aligned}\\)Montrer que\\[\\frac{\\partial g}{\\partial x}(\\alpha) + \\frac{\\partial g}{\\partial y}(\\alpha) + \\frac{\\partial g}{\\partial z}(\\alpha) = 0 \\quad\\forall \\alpha=(a,b,c)\\in\\mathbb R^3\\] Solution\\[\\begin{aligned}g(x,y,z) &amp;amp;=f(x-y,y-z,z-x)\\\\&amp;amp;=f\\circ u(x,y,z)\\end{aligned}\\] avec \\(\\begin{aligned} u:\\mathbb R^3&amp;amp;\\to\\mathbb R^3 \\\\ (x,y,z)&amp;amp;\\mapsto (x-y,y-z,z-x) \\end{aligned}\\) On vient de voir que\\[d_{\\alpha}g:h\\mapsto d_{\\alpha} f\\circ u(h)=\\underbrace{d_{u(\\alpha)}f(d_{\\alpha}u(h))}_{Jac_{\\alpha}g\\times h=Jac_{u(\\alpha)}f\\times Jac_{\\alpha}u\\times h\\mapsto Jac_{\\alpha}g=Jac_{\\underbrace{u(\\alpha)}_{\\beta\\in\\mathbb R^3=u(\\alpha)}}f\\times Jac_{\\alpha}(u)}\\\\u(x,y,z)=(\\overbrace{x-y}^{u_1}, \\overbrace{y-z}^{u_2}, \\overbrace{z-x}^{u_3})\\\\Jac_{(x,y,z)}u=\\begin{bmatrix} \\frac{\\partial u_i}{\\partial x_j} \\end{bmatrix} = \\begin{bmatrix} 1 &amp;amp;-1&amp;amp;0 \\\\ 0 &amp;amp; 1 &amp;amp;-1 \\\\ -1&amp;amp;0&amp;amp;1 \\end{bmatrix}\\\\\\begin{aligned}Jac_{\\beta}f&amp;amp;=\\nabla_{\\beta}f^T\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x}(\\beta), \\frac{\\partial f}{\\partial y}(\\beta), \\frac{\\partial f}{\\partial z}(\\beta))\\\\Jac_{\\alpha}g&amp;amp;=\\nabla_{\\alpha}g^T \\\\&amp;amp;=(\\frac{\\partial g}{\\partial x}(\\alpha), \\frac{\\partial g}{\\partial y}(\\alpha), \\frac{\\partial g}{\\partial z}(\\alpha))\\\\\\nabla_{\\alpha}g^T&amp;amp;=\\nabla_{\\beta}f^T\\begin{bmatrix}1 &amp;amp;-1 &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp;-1\\\\-1 &amp;amp; 0 &amp;amp; 1\\end{bmatrix}\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z})\\begin{bmatrix}1 &amp;amp;-1 &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp;-1\\\\-1 &amp;amp; 0 &amp;amp; 1\\end{bmatrix}\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x} - \\frac{\\partial f}{\\partial z}, \\frac{\\partial f}{\\partial y} - \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial z}- \\frac{\\partial f}{\\partial y})\\\\&amp;amp;= \\frac{\\partial g}{\\partial x} + \\frac{\\partial g}{\\partial y} + \\frac{\\partial g}{\\partial z} = 0\\end{aligned}\\]" }, { "title": "OCVX: Differentielles (le retour)", "url": "/cours/posts/ocvx_differentielle_le_retour/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-12 10:00:00 +0200", "snippet": "Lien de la note HackmdLa differentielle en TOP-DOWNLa semaine derniere, vous avez cherche a generaliser la notion de derivabilite dâ€™une fonction $\\phi:\\mathbb R\\to\\mathbb R$ a celle de differentiabilite dâ€™une fonction $f:\\mathbb R^n\\to\\mathbb R$.Le point de vue aborde: on sait deriver le long dâ€™un vecteur $v\\in\\mathbb R^n$, cad quâ€™on sait deriver la fonction\\[t\\mapsto f(\\overbrace{a}^{\\text{le pt qu&#39;on} \\\\ \\text{cherche a deriver}}+tv)\\]A partir de la on cherche a construire un objet multidimensional qui va remplacer la derivee dans le cas unidimensionnel.On sait deriver une fonction de $\\mathbb R\\to\\mathbb R$ $\\to$ On sait donc deriver une fonction de $\\mathbb R^n\\to\\mathbb R$ le long dâ€™un vecteur $v$ (en particulier le long des axes).$\\to$ On regroupe les derivees le long des axes dans un objet quâ€™on appelle le gradient$\\to$ Definition de la differentielle en un point Câ€™est la demarche BOTTOM-UPAujourdâ€™huiOn va generaliser la notion de derivabilite dâ€™une fonction de $\\mathbb R\\to\\mathbb R$ a lâ€™aide des normes sur $\\mathbb R^n$$\\to$ Analyser â€œlâ€™objet differentielâ€ quâ€™on obtient et decrire une partie des proprietes quâ€™il a$\\to$ retrouver les derivees partielles comme ecriture en coordonnnees de la differentielle en un point Câ€™est la demarche TOP-DOWNRappel sur $\\mathbb R$ Etant donne une fonction $\\phi:\\mathbb R\\to\\mathbb R$ on dit que $\\phi$ est derivable en $a\\in\\mathbb R$ si \\(\\lim_{h\\to a}\\frac{\\phi(a+h)-\\phi(a)}{h}\\) existe. Dans ce cas cette limite est appelee le nombre derivee de $\\phi$ en $a$ et on le note $\\phiâ€™(a)$De maniere equivalente $\\phi$ est derivable en $a$ sâ€™il existe un nombre reel $\\alpha$ tel que pour $h$ assez petit (h proche de 0)\\[\\phi(a+h)=\\phi(a)+\\alpha h + h\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\] Dans ce cas $\\alpha$ est le nombre derivee de $\\phi$ en $a$ et on le note $\\phiâ€™(a)$ Dans $\\mathbb R$: si $\\phi$ est derivable en $a$ alors \\(\\forall h\\text{ assez petit}\\quad \\phi(a+h)=\\phi(a)+\\phi&#39;(a)h+h\\varepsilon(h)\\)Proposition dâ€™extension au cas dâ€™une fonction $f:\\mathbb R^n\\to\\mathbb R$f est differentiable en $a$ si\\[\\forall \\underbrace{h}_{\\in\\mathbb R^n}\\underbrace{\\text{ assez petit}}_{\\exists\\eta\\gt0\\text{ tq }h\\in\\mathcal B(0,\\eta)}\\quad f(a+h)=f(a) +\\overbrace{\\lambda_a(h)}^{\\text{lineaire en }h}+ \\Vert h\\Vert\\overbrace{\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}}^{\\text{pas lineaire en }h}\\]$h$ varie de tel sorte a ce quâ€™on reste dans la boule $\\mathcal B(0,\\eta)$ Definition: une fonction $f:\\mathbb R^n\\to\\mathbb R$ est differentiable en un point $a\\in\\mathbb R^n$ sâ€™il existe une application lineaire $\\lambda_a:\\mathbb R^n\\to\\mathbb R$ telle que \\(\\forall h\\text{ assez petit}:\\quad f(a+h)=f(a)+\\lambda_a(h)+\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\quad\\color{orange}{(D_1)}\\) On ne precise pas la norme car elles sont equivalentes.Question: Pour $f$ donne, combien y a-t-il dâ€™applications lineaires qui satisfait $\\color{orange}{D_1}$ ?Il nâ€™y a qiâ€™une seule, quâ€™on appelle la differentielle en $a$. Lemme: Si $\\lambda_a$ existe, elle est unique.PreuveOn suppose quâ€™il existe 2 applications lineaires $\\lambda_a$ et $\\mu_a$ qui satisfont $\\color{orange}{(D_1)}$, cad\\[\\begin{aligned}\\forall h\\text{ assez petit}:\\quad f(a+h)&amp;amp;=f(a)+\\lambda_a(h)+\\Vert h\\Vert\\varepsilon_1(h)\\\\-f(a+h)&amp;amp;=f(a)+\\mu_a(h)+\\Vert h\\Vert\\varepsilon_2(h)\\\\\\overbrace{\\underbrace{(\\lambda_a-\\mu_a)}_{\\text{Une app lineaire en }h}}^{\\text{On va montrer que} \\\\ \\text{c&#39;est l&#39;app lineaire nulle}}(h)&amp;amp;=\\Vert h\\Vert(\\underbrace{\\varepsilon_1(h)-\\varepsilon_2(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}})\\end{aligned}\\]On est dans la situation suivante:\\[\\forall h\\in\\mathcal B(0,\\eta)\\text{ pour }\\eta\\gt0\\quad\\underbrace{\\psi}_{\\text{lineaire}}(h)=\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned} \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\]Demonstration: Ma $\\psi$ est nulleOn va prendre un vecteur \\(\\overbrace{v\\in\\mathbb R^n}^{\\Vert v\\Vert=1}\\), soit $t\\in]-\\eta,\\eta[$ (donc $tv\\in\\mathcal B(0,\\eta)$)On a:\\[\\begin{aligned}\\psi(tv)=\\Vert tv\\Vert\\varepsilon(tv)&amp;amp;\\Leftrightarrow t\\psi(v)=\\Vert t\\Vert\\Vert v\\Vert\\varepsilon(tv)\\\\&amp;amp;\\Leftrightarrow signe(t)\\frac{\\psi(v)}{\\Vert v\\Vert}=\\varepsilon(tv)\\end{aligned}\\]Si on se limite a $t\\in[0,\\eta[$, on a $\\frac{\\psi(v)}{\\Vert v\\Vert}=\\varepsilon(tv)$Dans la relation\\[\\forall t\\in[0,\\eta]\\quad \\frac{\\psi(v)}{\\underbrace{\\Vert v\\Vert}_{\\text{constant}}}=\\underbrace{\\varepsilon(tv)}_{\\begin{aligned}\\varepsilon(tv)&amp;amp;\\to0\\\\t&amp;amp;\\mapsto0\\end{aligned}}\\\\\\Rightarrow\\psi(v)=0\\]Etant donne un vecteur $v\\in\\mathbb R^n$, $\\Vert v\\Vert=1$, $\\psi(v)=0$.En particulier, $\\forall i\\in{1,â€¦,n}$; $\\psi(e_i)=0$Donc la matrice de $\\psi$ dans la base canonique est nulle, i.e. $\\psi = 0$ Donc $\\lambda_a=\\mu_a$ Definition: On appelle differentielle de $f:\\mathbb R^n\\to\\mathbb R$ au point $a$, lâ€™unique application lineaire (si elle existe) qui satisfait: \\(\\color{orange}{D_{abs}}: \\quad f(a+h)=f(a)+Df(a)(h)+\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\)Dans ce contexte, $Df(a)$ a une matrice dans la base canonique de taille $(1,n)$Exemple1.On note \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ h&amp;amp;\\to \\underbrace{A}_{A\\text{ est une matrice ligne}}h+n\\end{aligned}\\)\\[\\begin{aligned}f(a+h)&amp;amp;=A(a+h)+b\\\\&amp;amp;= Aa + Ah +b\\\\&amp;amp;=(\\underbrace{Aa+b})+Ah\\\\&amp;amp;=f(a) + \\underbrace{Ah}_{\\text{lineaire en }h} + \\underbrace{o}_{\\Vert h\\Vert\\varepsilon(h) \\\\ \\varepsilon \\text{ est nul la}}\\end{aligned}\\]Dâ€™apres la definition:\\[Df(a)(h) = Ah\\\\Df(a):h\\to Ah\\]2.\\(f:\\mathbb R^n\\to\\mathbb R\\\\x\\to x^Tx\\\\\\begin{aligned}f(a+h)&amp;amp;=(a+h)^T(a+h)\\\\&amp;amp;=aTa+h^Ta+a^Th+\\overbrace{h^Th}^{\\Vert h\\Vert_2\\Vert h\\Vert_2}\\\\&amp;amp;=f(a) +\\underbrace{2a^Th}_{\\text{lineaire en }h} +\\Vert h\\Vert \\varepsilon(h)\\end{aligned}\\\\\\) Definition (rappel): \\(\\Vert h\\Vert_2+\\sqrt{h^Th}\\)Remarque: $h^Ta\\in\\mathbb R$, $(h^Ta)^T=h^Ta\\Rightarrow a^Th^{T^T}=a^Th$ car ce sont des reels. Donc $Df(a):h\\to2a^Th$Dans le cas $n=1$\\[\\begin{aligned}f:x&amp;amp;\\to x^2\\\\D f(a):h&amp;amp;\\mapsto Df(a)(h)\\\\f&#39;(a)&amp;amp;=2a\\end{aligned}\\]Proprietes usuellesLes proprietes usuelles de derivabilites et de calcul des derivees sâ€™etend au cas des fonctions de $\\mathbb R^n\\to\\mathbb R$. Soient $f,g:\\mathbb R^n\\to\\mathbb R$ et $a\\in\\mathbb R^n$, on suppose $f,g$ differentiable en $a$.\\[\\begin{aligned}\\forall h\\text{ AP}\\quad f(a+h)&amp;amp;=f(a)+D f(a)(h)+\\Vert h\\Vert\\varepsilon_1(h)\\\\g(a+h)&amp;amp;=f(a)+D g(a)(h)+\\Vert h\\Vert\\varepsilon_2(h)\\\\(+):(f+g)(a+h)&amp;amp;=(f+g)(a)+(\\underbrace{D f(a)+D g(a)}_{\\text{lineaire en }h})(h)+\\Vert h\\Vert (\\underbrace{\\varepsilon_1(h)+\\varepsilon_2(h)}_{\\varepsilon(h)})\\end{aligned}\\] \\(D(f+g)(a)=D f(a)+D g(a)\\)\\[(\\times):(fg)(a+h)=(fg)(a) + f(a)D g(a)(h)+g(a)D f(a)(h)\\\\+D f(a)(h)D g(a)(h)+\\\\\\Vert h\\Vert\\varepsilon_1(h)D g(a)(h) + \\Vert h\\Vert\\varepsilon_2(h)D f(a)(h) +\\\\\\Vert h\\Vert^2\\varepsilon_1(h)\\varepsilon_2(h) + \\Vert h\\Vert(\\varepsilon_1(h)g(a) + \\varepsilon_2(h)f(a))\\\\\\color{red}{D(fg)(a)=f(a)D g(a)+g(a)D f(a)}\\\\\\color{orange}{D (fg)(a):h\\to f(a)D g(a)(h) + g(a)D f(a)(h)}\\]Matrice ligneLa differentielle de $f:\\mathbb R^n\\to\\mathbb R$ en $a$ quand elle existe est une matrice ligne: comment en decrire les coeffs ? Definition(temporaire): Quand $f$ est differentiable au point $a$ on appelle gradient de $f$ en $a$ le vecteur $v$ (colonne) $\\nabla f(a)$ dont la transposee est la marice de $Df(a)$ dans les bases canoniquesOn a donc: pour tout $h$ assez petit\\[f(a+h)=f(a)+\\nabla f(a)^Th+\\Vert h\\Vert \\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\]On est interesse par calculer $\\nabla f(a)^Te_i$ $\\forall i\\in{1,â€¦,n}$Soit $t\\in\\mathbb R$\\[f(a+t_{e_i})=f(a)+\\nabla f(a)^T(te_i)+\\Vert te_i\\Vert\\varepsilon(te_i)\\\\\\Leftrightarrow f(a+t_{e_i})-f(a)=t\\nabla f(a)^Te_i+\\Vert te_i\\Vert\\varepsilon(te_i)\\\\\\frac{\\Leftrightarrow f(a+t_{e_i})-f(a)}{t}=\\nabla f(a)^Te_i+\\Vert e_i\\Vert\\varepsilon&#39;(te_i)\\quad t\\neq0\\\\\\Leftrightarrow\\nabla f(a)^Te_i=\\underbrace{\\frac{f(a+te_i)}{t}}_{\\to_{t\\to 0}\\delta e_if(a)=\\frac{\\delta}{\\delta x_i}f(a)}-\\underbrace{\\Vert e_i\\Vert\\varepsilon&#39;(te_i)}_{t\\to0 \\\\ \\to 0}\\]En prenant la limite on vient de constater (avec la definition temporaire de $\\nabla f(a)$) que $\\nabla f(a)^Te_i=\\frac{\\delta}{\\delta x_i}f(a)$Cad que la ieme coordonnee de votre gradient câ€™est la derivee partielle par rapport a $x_i$ Defintion: Le gradient dâ€™une fonctino $f$ en un point $a\\in\\mathbb R^n$ câ€™est le vecteur $v$ des derivees partielles:\\[\\nabla f(a)=\\biggr(\\frac{\\delta f}{\\delta x_i}(a)\\biggr)_{1\\le i\\le n}\\] Les definitions â€œtemporaireâ€ et definitives de gradient ne sont pas equivalentes: on peut admettre des derivees partielles sans etre differentiable Prop: Si une fonction $f:\\mathbb R^n\\to\\mathbb R$ admet un gradient en un point $a$, et si $x\\to\\nabla f(x)$ est continue au voisinage de $a$, alors $f$ est differentiable en $a$, cad quâ€™on peut ecrire \\(\\forall h \\text{ assez petit}\\\\f(a+h)=f(a)+\\nabla f(a)^Th+o_a(h)\\)Remarque: si $f$ est differentiable en $a$:\\[\\underbrace{\\delta_v f(a)}_{\\color{red}{\\text{derivee directionnelle de } f\\\\ \\text{en } a \\text{ le long de } v}}=\\nabla f(a)^Tv\\]Derivee dâ€™une composeePour parler de composee on va generaliser un petit peu le cadre avec lequel on a travaille jusque la.On sâ€™interesse donc aux fonctions\\[f:\\mathbb R^n\\to\\mathbb R^n\\]On note $f_1,â€¦,f_n$ les fonctions coordonnees de $f$, $f=(f_1,â€¦,f_n)$Exemple\\[\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R^3\\\\(x,y)&amp;amp;\\mapsto \\begin{pmatrix}\\cos(xy) \\\\ x^2+y \\\\ 2y\\end{pmatrix}\\\\g_1:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto \\cos(xy)\\\\g_2:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y\\\\g_3:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto 2y\\\\\\end{aligned}\\]Une fonction $f:\\mathbb R^n\\to\\mathbb R^m$ va etre dite differentielle si on a une ecriture:\\[f(a+h)=f(a)+\\underbrace{Df(a)}_{\\text{differentielle de } f\\\\ \\text{en } a,\\text{de matrice}\\\\ \\text{dans les bases canoniques}\\\\ \\text{de taille: }(m,n)}(h)+\\underbrace{\\Vert h\\Vert}_{\\text{une norme sur }\\mathbb R^n}\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R^m \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\] La matrice de $\\lambda f(a)$ dans les bases canoniques est appellee la jacobienne de $f$ en $a$. \\(J_f(a)=\\begin{pmatrix}\\frac{\\delta f_1(a)}{\\delta x_1}&amp;amp;\\dots &amp;amp;\\frac{\\delta f_1(a)}{\\delta x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\delta f_m(a)}{\\delta x_1}&amp;amp;\\dots &amp;amp;\\frac{\\delta f_m(a)}{\\delta x_n}\\\\\\end{pmatrix}\\\\=\\begin{pmatrix}\\nabla f_1(a)^T\\\\\\vdots\\\\\\nabla f_m(a)^T\\end{pmatrix}\\\\= (\\nabla f_1(a),...,\\nabla f_m(a))^T\\\\\\)Pour $f:\\mathbb R^n\\to\\mathbb R^m$ si on est differentiable en $a\\in\\mathbb R^n$On a $\\forall h$ AP:\\[f(a+h)=f(a)+J_{f}(a)h+o_a(h)\\]Question:Soit $f,g$, $f:\\mathbb R^n\\to\\mathbb R^m$, $g:\\mathbb R^m\\to\\mathbb R^p$, si $f$ et $g$ sont differentiable respectivement $f$ en $a$ et $g$ en $b=f(a)$ alors\\[D(g\\circ f)(a)=D g(\\color{red}{f(a)})\\circ D f(\\color{red}{a})\\]Matriciellement:\\[J_{g\\circ f}(a) = J_g(f(a))\\times J_f(a)\\]" }, { "title": "IMED: L&#39;imagerie par resonance magnetique (IRM)", "url": "/cours/posts/imed_irm/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-09 14:00:00 +0200", "snippet": "Lien de la note HackmdIMED: Lâ€™imagerie par resonance magnetique (IRM)Les bases de lâ€™IRMOn qualifie la densite du champ magnetique par des Tesla, entre 1,5 et 3 Tesla (par comparaison, le soleil est a moins de 1 Tesla)Principe physique de lâ€™IRM1933: Otto Stern (55 ans) mesure le moment magnetique du protonEntre 1938-1946: on observe les premiers spectres RMN, on decouvre le phenomene de resonnance magnetique interaction entres 2 ondes ayant la meme frequence effet boule de neige Ex: les militaires marchants en pas cadences, qui ne peuvent pas traverser des ponts sous risque de ruptureBeaucoup de prix Nobel associes ! Maisâ€¦ on parle de quoi en fait ?Un proton a un spin, il dessine un cone lors de sa rotation.On a une composante horizontale et verticaleChaque proton est oriente dans un sens propreLa resultante de toutes ces forces = 0Imaginons on applique un champ magnetique $B_0$ Les protons sâ€™alignent dans le sens de $B_0$Certains protons sont paralleles a $B_0$, dâ€™autre anti-paralelles (parallele et dans le sens inverse)Si on applique des ondes de radio frequences (generalement perpendiculaire), tout le monde va se tourner dans le meme sens et tourner en meme temps (tourner en resonance)On a une composante magnetique et une onde radio On mesure les ondes â€œlibereesâ€ et le temps necessaire a nos protons pour revenir a leur etat initial (non-initie)La decouverte 1933: Stern demontre que le proton possede un moment magnetique 1945: les premiers spectres de RMN 1971: Damadian a lâ€™idee dâ€™utiliser la RMN pour realise une image de tissu biologique 1977: Lauterbur reprend les principes de calcul des images du scanner pour creer une image medicale a partir du signal RMN des tissus Le nom dâ€™IRM nâ€™a ete donne que plus tard a la RMN car le terme â€œnucleaireâ€ inquietait le publique Passer une IRM nâ€™est pas nocif, contrairement a un scanner.Lâ€™evolutionImages en coupe multiplanaireImage anatomie: on a decoupe quelquâ€™un en morceaux (oui oui câ€™est pas une blagueâ€¦) Fallait pas etre condamne a mort quand on a commence a faire des dissections/vivisections (le corps finissait souvent decoupe par la science, peu importe les dernieres volontes)Image multiparametriqueParametres de lâ€™IRMLa morphologie du signal emis par des protons depend essentiellement du temps (appele temps de relaxation) que ceux-ci mettent a revenir dans lâ€™axe de lâ€™aimant (temps n$^o$ 1 ou T1) et du temps quâ€™ils mettent a se dephaser de nouveau (temps n$^o$ 2 ou T2)T1: SB blanche, SG grise, LCR en hyposignalT2: lâ€™inverse !Les evolutionsSequences rapides: IRM dynamiqueIg Nobel: prix nobel pour des trucs debilesA droite: kecece ?: on est 9 mois avant un accouchement Il y a 2 colonnes vertebralesAngio-IRM IRM pour les veines et les arteres avec du liquide de contraste On a la difference entre plusieurs TeslaBilan Base sur les proprietes magnetiques des molecules dâ€™eau Champ magnetiqueArtefacts Il y a pas mal de mouvement a lâ€™interieur du corps Susceptibilite magnetique Certaines zones sont plus sensibles que dâ€™autres Varie en fonction des personnes Aliasing/troncature Gibbs Meme problematique que le traitement du signal classique Deplacement chimique Notre sang qui fait son taf par exemple Lâ€™IRM de diffusion Meme pricinpe que lâ€™IRM de baseLâ€™IRM fonctionnelle Visualise les zones du cerveau activees par stimulus Echange de lâ€™oxygene entre le sang et les neurones modifient le signal Rehausse les zones dâ€™activite du cerveau" }, { "title": "IMED: Les Rayons X", "url": "/cours/posts/imed_rayons_x/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-09 10:00:00 +0200", "snippet": "Lien de la note HackmdLes os apparaissent !La decouverteUne nouvelle forme de matiere 1838: Faraday sâ€™interesse aux decharges electriques dans les gaz rarefies Appareil de Faraday: cathode et anodee dans un tube en verre. Quand la cahode recoit de la tension, cela provoque une etincelle Variation de pression dans le gaz: lâ€™etincelle se transforme en emanation violette si la pression diminue Quatrieme etat de la matiere nomme â€œmatiere radianteâ€Les rayons cathodiques $XIX^e$s: experience reprise mais reste incomprise Plucker observe quâ€™une augmentation de la pression dans le tube nâ€™entraine plus quâ€™une fluorescence verte sur certaines parois du tube, en face de la cathode En 1869, son eleve Hittorf decouvre des rayons qui se propagent en ligne droite depuis la cathode (mise en evidence a lâ€™aide dâ€™une crois metallique face a la cathode) Ces rayons sont nommes les rayons cathodiques Crookes perfectionne le tube en verre Thompson decouvre lâ€™electron en 1897Une decouverte due au hasardâ€¦.1895: Wilhelm Rontgen etudie le rayonnement cathodique avec des tubes de Crookes. Le 8 novembre, il decouvre un trucâ€¦ Experience: il met le tube de Crookes dans du carton noir Resultat: une plque de platinocyanure de baryum a cote du tube devient fluo, et reste fluo une fois ecartee.Il intercale des objets entre lâ€™ampoule et la plque, la fluorescence reste Il nomme ce rayonnement les â€œRayons Xâ€ (comme tout bon mathematicien qui a une inconnueâ€¦)Proprietes Faiblement absorbes par la matiere Diffuses par la matiere Origine du rayonnement fluo Impressionnent une plaque photo Dechargent les corps charges electriquement Si on met la main devant, on peut voir les os et les tissus apparait sur la plaque Tout premier cliche en Rayon X On peut voir que les bagues restent La premiere radio dentaire au monde !Lâ€™explosion de la radiographieEn medecineEn medecine de guerreMarie Curie a concu 18 voityres radiologiques et installe 250 postes fixes de radio dans les hopitauxAujourdâ€™hui nos os sont blancs et fond noir, a lâ€™epoque câ€™etait lâ€™inverse. Plus ca traverse, plus câ€™est blanc. Aujourdâ€™hui, nos radios numeriques sont le negatif de nos radios originales.Au douanesA lâ€™epoque on le faisait aussi pour les gens et pas seulement les valises.Dans les grands magasinsEn particulier les magasins de chaussures pour montrer quâ€™elle nous va parfaitement.Ou meme comme spectacle !Les gens se faisait bombarder de Rayons X et radiations, pas fifouâ€¦Effet therapeutiqueOn se disait que ca marchait contre les migraines au bout de 15 min dâ€™exposition (il nâ€™y avait surtout plus beaucoup de tissus vivants mais bonâ€¦)On utilisait quand meme les rayons X contre les cancers, ce quâ€™on fait toujours aujourdâ€™hui (pour bruler la tumeur). Probleme: ca crame tout sur son passage. De nos jours, on fait â€œtournerâ€ les rayons pour quâ€™ils se croisent au niveau de la tumeur. Donc a lâ€™epoque, ils savaient que ca cramait des tumeurs mais pensaient pas que ca cramait le cerveau ? (Oui mes câ€™est des doses differentes, ca paaaassse)Effets biologiqueNovembre 1896: Premier article â€œles mefaits des rayons Xâ€. Le temoi a ete demonstrateur en rayons X pendant lâ€™ete a Londres. On abuse pas des mammographies car ca risque de declencher des cancer (le diagnostic qui cause la maladie, câ€™est balotâ€¦) Si une femme doit absolument passer une radio, on lui met un â€œtablierâ€ en plomb pour eviter au plus les radiatoinsLa fluoroscopieLa radiographie Repose sur lâ€™utilisation de rayons X Les rayons traversent les tissus de maniere plus ou moins important selon leur densite Fonctionne a lâ€™aide dâ€™une source emettrice et dâ€™une plaque de detection La quantite de photons atteignant la plaque â€œdessineâ€ les tissus Pas de champs magnetique Dangereux a haute dose Lâ€™avenir des rayons X, câ€™est dâ€™etre de moins en moins nocifs pour les humains tout en gardant la qualite de lâ€™imageAgiographieInjection dâ€™un liquide de contraste, qui permet de verifier lâ€™ecoulement du sang.Le scanner Ca serait cool de pouvoir faire du 3DLa decouverteLes appareils On a reussi a ameliorer la resolution avec les acquisitions spiralees.Lâ€™evolutionAu gauche: premier scanner cerebralImagerie multiplanaire Il nâ€™y a pas tant de differences entre la matiere grise et la matiere blancheReconstruction tomographiqueBilan Repose sur lâ€™utilisation de rayons X Les rayons traversent les tissus de maniere plus ou moins importante selon leur densite Le capteur et lâ€™emetteur effectuent une rotation autour du corps" }, { "title": "IMED: Histoire et enjeux", "url": "/cours/posts/imed_hisoire_et_enjeux/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-08 14:30:00 +0200", "snippet": "Lien de la note Hackmd Histoire de lâ€™imagerie medicale Formats, problemes et interetHistoire de lâ€™imagerie medicaleQuelle medecine a lâ€™eqoque prehistorique ?Pas dâ€™IRM ou de radio, mais deja des notions de medecine a lâ€™ecole (bah oui, on etait deja malade a lâ€™epoqueâ€¦) Pathologies de lâ€™epoque caries fractures maladies virales et bacterienne migraines etc. Notions de soins par les plantes Usage externe et interne Grosse influence des coyances/spiritualites Role important du Chaman A lâ€™epoque, on avait lâ€™ecorce de saule, cad lâ€™aspirine Lâ€™observation est la premiere source de savoir. Des connaissances plus poussees quâ€™on ne le penseâ€¦ Maitrise de coutures et tests de soins dentaires Maitrise des notions de fractures Ateles en bois et immobilisation du membre Notions de â€œchirurgieâ€ Survie aux trepanations (meme si leur raison reste flou) Trepanations: trou dans le crane Le trou est â€œlisseâ€, cad que la personne est restee en vie assez longtemps pour que ca cicatrise La transmission des savoirs se fait de generations en generationsLa medecine durant lâ€™antiquiteMesopotamie1750 avant JC: texte de loi sur la medecine et la chirurgie: Mise en place de protocole medical dâ€™auscultation en melant medecine et religion (â€œdouleur ? mensonge ?â€ etc.) On sait analyser lâ€™halene, lâ€™urine, prendre le pouls et la temperature On ne sait pas encore le role du coeur Avec lâ€™urine on detecte le diabete Urine sucree (pour certains types de diabete) La creation du Fanta Remedes a la base de prieres et de plantes (sirops, onguent, etc.) On sait soigner les fractures: ateles et chirurgie Partage du savoir avec un bibliotheque regroupant tous les ecrits medicauxPar contre, se faire soigner coute tres cher !EgypteLe papyrus Edwin Smith, 1500 avant JC, est le premier document ecrit parlant de traitement chirurgicaux (fractures, plaies, ecrasements, etc.) Il sâ€™agirait en realite dâ€™une copie Aspect pratique des traumatismes: sans le cote magique !750-332 avant JC, la medecine redevient religieuseMise en place dâ€™un systeme medical complexe avec la hierarchie public et gratuitGreceAu $VII^e$s avant JC, les medecins sont sedentaires, restent dans les cites Leurs statuts varient Certains sont fonctionnaires Visites a domicile ou chez le medecin Pythagoriens: câ€™est le cerveau qui dirige Dissections sur des animaux (interdit sur lâ€™homme) Hippocrate divin $\\neq$ maladie compilation de toutes les informations medicales de lâ€™epoque apport dâ€™une procedure, dâ€™une ethique, de diagnostic theorie des humeurs La lymphe La bile noire Le sang La bile blance Empire RomainA Rome, la medecine est mal consideree jusquâ€™au $II^e$s avant notre ereDeveloppement par la suite: notoriete des medecins, reunions de medecins, corporations, etc. suite a lâ€™arrivee des medecins grecques.Premier proctologues, avec le doux nom de berger de lâ€™anus :) Premiere specialisationsInstitutions militaires = gros developpement de la medecine. Hopitaux autour de jardins medicaux Jardins contenant des plantes medicinales Hygiene: separation des salles Separation salle dâ€™attent/salle de chirurgie/morge/etc. les outils bouillis Galien pose les bases de la medecine occidentaleLe Moyen-AgeMedecine occidentaleLa medecine au Moyen-Age en occident connait un recul en arriere suite a la chute de lâ€™empire romain Pertes de connaissances ecrites Pas de traductions existantes Soigner des gens avec des plantes au Moyen-Age = sorcieres Retour de la medecine mystico-religieuse Melange des traditions et croyances Diktats des textes religieux Les moines sont les garants des textes ecrits, et donc sont les medecins.Les plantes medicinales sont dans les jardins des monastere (et liqueurs de plante aussiâ€¦)Medecine orientale La medecine arabe, elle, est en plein essortâ€¦ Elle se base sur les textes dâ€™Hippocrate et Galien Nombreuses avancees $XI^e$s en occident Traduction des ecrits arabes mais perte dâ€™information jusquâ€™a la fin du $XIII^e$s Ecole de medecine (Salerne) En France, il faudra attendre 2 siecles de plus pour ouvrir une universite de medecine Au $XIV^e$s, la dissection est autorisee dans les ecoles Theories de Galien sont remises en cause au milieu du $XIV^e$sâ€¦La peste au Moyen AgeLa peste, la maladie emblematique des pandemies meurtrieres du Moyen-Age, est restee un mystere pour les gens de lâ€™epoqueMeconnaissance et croyancesChretiens et Musulmans pensent que la peste est une punition divine. processions, prieres, etc. pour tenter dâ€™endiguer lâ€™epidemieCette pandemie est originaire dâ€™un siege Mongol a Constantinople, en catapultant des cadavres morts de la peste sur la ville. Les habitants ont fui et ont propage la peste PARTOUT. Pareil que les parisiens qui se barrent durant le 1er confinement avec le coronaOn accuse les lepreux, les juifs, les etrangers, les sorcieresâ€¦ bref on accuse tout le monde dâ€™etre des vecteurs de la peste (meme si le Pape rejette ces accusations!) Probleme: peu dâ€™incineration car contraire a la religion !Quâ€™est-ce que la peste ?Bacterie: Yersinia pestis, indentifiee en 1894 par Alexandre YersinLes rongeurs sont un reservoir naturel, et les puces sont un vecteur.3 formes: bubonique, pulmonaire et septique.Les medecins ne savent tout simplement pas ce quâ€™est ce fleau. La peste est considere comme un â€œpoisonâ€.Les traitements habituels de lâ€™epoque: saignee, transpiration, incision du bubon, lavements, etc. La seule methode qui semble porter ses fruits pour eviter une propagation estâ€¦ la quarantaine. (ou confinement pour lâ€™actualite)3 niveaux de quarantaine: quarantaine a domicile les malades nâ€™ont pas le droit de sortir de chez eux mais leur famille peuvent lieux dâ€™isolements hopitaux specifiques pour les malades toujours de la contamination car les malades ont touche des trucs chez eux et contamine leur famille expulsion des malades hors des villes Oh bah ca marche ! Remaniement social important: passe du moyen age a lâ€™epoque moderne.La fin du Moyen-Age A partir du $XII^e$ Moines-medecins: uniquement dans les campagnes (sur papier) Creation dâ€™hopitaux Peste noire: 2 courants de pensees helleniste arabisant A partir du $XV^e$ Ecoles dâ€™anatomie De plus en plus de decouvertes Andre Vesale: hors Eglise, grosse liberte Les $XVII^e$ et $XVIII^e$ siecles Vivisection sur des animaux Dissection mais sur des animauxâ€¦ vivants. Decouverte du role du corps par William Harvey en 1628 Theorie de la circulation du sang enseignees dans les ecoles francaises Invention du microscope Debuts de la microbiologie Apparition de la variolisation en Europe Ancetre de la vaccination A injecte la variole de vache dans quelquâ€™un, cette personne a ete immunisee contre la variole humaine Pensait que ca marchait que pour la variole Louis Pasteur fait le lien entre maladie et microorganismesLa medecine au $XIX^e$ siecle Professionnalisation des medecins (internat, diplome) Cours dâ€™anatomie se developpent Evolution chirurgicales importantes Naissance des procedures dâ€™auscultations des patients Les hommes commencent a arriver dans lâ€™obstetrique et la gynecologie Premieres maternites mais mortalite plus importante quâ€™a la maison Meurent toutes a la maternite dâ€™une forme de fievre Un homme meurt de la meme maladie suite a une dissection dans une morgue Decouverte dâ€™un lien entre passer directement de la salle dâ€™accouchement depuis la morgue A commence a se laver les mains entre 2, chute drastique du taux de mortalite des femmes a la maternite La toute premiere image medicale1897: Installation du premier service de radiologieLâ€™evolution de la medecine$XX^e$ siecle Premieres machines de visualisation de lâ€™interieur du corps Connaissances sur les micro organismes, infections, etc. Decouverte de la peniciline Deja connue avant le $XX^e$ siecle avant par les bergers Un berger a decide un jour de se mettre de la moisissures de Rocquefort sur une plaie infectee â€¦ Et ca marche! La moisissure de Rocquefort et la peniciline sont de la meme famille Developpement des medicaments Developpement de toutes les techniques dâ€™imgerie Il serait impossible de commercialiser lâ€™aspirine si elle etait decouverte aujourdâ€™hui car elle cree des tumeurs chez les souris En un siecle, les principales techniques dâ€™imagerie anatomiques ont ete developpees et sont toujours utilisees aujourdâ€™hui (et ameliorees)Une acceleration Echographie 4D: 3D+t (video en 3D) Ne sert techniquement a rien a part faire plaisir aux parents Nâ€™apporte rien medicalement parlant Formats, problemes et interetPrincipe generalTout ce qui est â€œa droiteâ€ de la lumiere visible sont mauvais pour le corps humain (Radiographie, Imagerie Nucleaire). Nâ€™allez pas mettre votre tete dans un micro-onde Pour savoir ce qui est bon ou non, voir ce qui est bon pour les femmes enceintes.Format: Quâ€™est-ce quâ€™une image ? Dâ€™apres les cours de Maxime DescoteauxLe plus important:Formats: Grrâ€¦ Pas de standard et normalement, on insulte tous les dieux quand on sâ€™y met Effort de la communaute mrtrix nibabel (les 2 sont des package python) Un format ? Non.En imagerie medicale, il y a une infinite de formats differentsâ€¦Les plus connus: .dcm DICOM .nii NIFTI .hdr .img Analyze .ima .dim Gis (France) .mnc Minc (Montreal Neurological Institute (MNI)) .nrrd Nrrd (USA) .mhd Beaucoup de soucis en perspectiveâ€¦Des problemes ? Oui. Spoiler: imread(monimage.XXX) ne marche pas!Il faut des bibliotheques speciales pour pouvoir les ouvrir.Quelques bibliotheques python: medpy, nibabelâ€¦A la base, une bonne idee: une image = un header et des donneesâ€¦Mais pourquoi donc ? DICOM Format le plus repandu dans les hopitaux (tous les nouveaux appareils cliniques supportent le format DICOM) Problemeâ€¦ plus quâ€™un format bien defini Boite a fourre-tout Les constructeurs definissent leur â€œtagâ€ ou etiquette maisons Cauchemar pour les traiteurs dâ€™image Pour etre ethique $\\rightarrow$ denormalisation necessaire ! Du coup, câ€™est quoi un DICOM ?Information importante dans lâ€™entete: Taille du voxel Taille de lâ€™image Matrice de transformation Type des donnees Change pour chaque DICOM!Matrice de transformation ?3 plans principaux: axial, coronal et sagittalSauf que des fois, lâ€™acquisition nâ€™est pas si simpleâ€¦Taille du voxel? Rappel: un pixel/voxel a une taille qui correspond a des longueurs physiques ! Plus cette taille est petite, meilleure est la resolution! $x$, $y$ et $z$ peuvent etre identiques (isotrope) ou differents (anisotorpe). En general, câ€™est $z$ qui fait nâ€™importe quoi.Quelles consequences ? Difficile de determiner les contours Pertes dâ€™informations Cela pose des soucis en terme de precision de mesure !En conclusion Medecin: â€œJe veux plus de precision. (sans tuer le patient, câ€™est mieux)â€ Informaticien: â€œJe veux plus de puissance.â€Realite: â€œMollo les gens, ca va pas se passer comme caâ€¦â€Quel type dâ€™imagerie ? Imagerie fonctionnelle Se base sur lâ€™activite dâ€™un organe ou dâ€™une partie On mesure lâ€™activite electrique de lâ€™organe en question Imagerie anatomique Permet de visualiser lâ€™anatomie du corps et des organes Pour faire quoi ?Et pas que !Neuro: encephale" }, { "title": "OCVX: Differentielles", "url": "/cours/posts/ocvx_differentielle/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-08 10:00:00 +0200", "snippet": "Lien de la note HackmdBienvenue dans le merveilleux monde de la differentielle &amp;lt;3 BUT: Etudier les extrema dâ€™une fonction convexeExemple\\[f(x) = ax^2+bx+c\\quad a\\gt 0\\] On derive $f$, $fâ€™(x)=2ax+b$ On cherche $x^{*}$ tel que $fâ€™(x^*)=0$\\[f&#39;(x^*) = 0 = 2ax^*+b\\]Point optimal:\\[x^*=-\\frac{b}{2a}\\]Valeur optimale:\\[\\begin{aligned}f^*=f(x^*)&amp;amp;=a(-\\frac{b}{2a})^2+b(-\\frac{b}{2a})+c\\\\&amp;amp;=\\frac{b^2}{4a}-\\frac{b^2}{2a}+c\\\\&amp;amp;=-\\frac{b^2}{4a}+c\\end{aligned}\\] \\(f^*=\\min_{x\\in\\mathbb R}f(x)\\\\x^*=argmin_{x\\in\\mathbb R}f(x)\\)On a envie de faire pareil pour \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ x=(x_1,x_2,...,x_n)&amp;amp;\\mapsto f(x) \\end{aligned}\\) On a besoin de generaliser la notion de derive pour des fonctions de plusieurs variables.RappelOn dit que $f:\\mathbb R\\to\\mathbb R$ est derivable en $x_0$ ssi \\(\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{x-x_0}\\) existe et est finie.Si câ€™est le cas, \\(f&#39;(x_0)=\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{x-x_0}\\) est le nombre derive de $f$ en $x_0$.$fâ€™(x_0)\\equiv$ pente de la tangente au point $(x_0,f(x_0))$. Equation de la tangente: Elle passe par le point $(x_0,f(x_0))$ et $\\vec u=(1,f(x_0))$ est un vecteur directeur\\[\\rightarrow y=f(x_0)+(x-x_0)f&#39;(x_0)\\] Si $f$ est convexe $\\rightarrow$ le graphe de $f$ est toujours au dessus de la tangente, quelque soit le point ou on trace la tangente\\[\\forall x_0\\in\\mathbb R,\\quad f(x)\\ge f(x_0)+(x-x_0)f&#39;(x_0)\\] Câ€™est la caracterisation a lâ€™ordre 1 de la convexite.On peut reecrire le nombre derive comme \\(f&#39;(x_0)=\\lim_{h\\to 0}\\frac{f(x_0+h)-f(x_0)}{h}\\) en posant $h=x-x_0$ Petit rappel: On dit que $f\\theta_{a}(g)$ sâ€™il existe $\\varepsilon:\\mathbb R\\to\\mathbb R$ avec $\\varepsilon(x)\\to_{x\\to a}0$ et $f(x)=g(x)\\varepsilon(x),x\\in \\mathcal V(a)$\\[\\begin{aligned}\\frac{f(x)}{g(x)}&amp;amp;\\to_{x\\to a}0\\\\\\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)}{h} = f&#39;(x_0) &amp;amp;\\Leftrightarrow \\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)-hf&#39;(x_0)}{h} = 0\\\\&amp;amp;\\Leftrightarrow f(x_0+h)-f(x_0)-hf&#39;(x_0)=\\begin{cases}\\theta_a(h)\\\\h\\varepsilon(h)\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\underbrace{\\color{red}{f(x_0+h)=f(x_0)+\\overbrace{hf&#39;(x_0)}^{h\\to hf&#39;(x_0)\\text{ lineaire en }h}+h\\varepsilon(x)}}_{\\text{DL a l&#39;ordre 1 en 0}}\\end{aligned}\\]Comment generaliser la notion de derivee pour $f:\\mathbb R^n\\to\\mathbb R$ ?En quoi câ€™est faux ?\\[\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{\\underbrace{x-x_0}_{\\in\\mathbb R^n}} = \\lim_{h\\to 0}\\frac{f(x)-f(x_0)}{\\underbrace{x-x_0}_{\\in\\mathbb R^n}}\\] On divise par des vecteurs ! Wait thatâ€™s illegal On pourrait regarder axe par axe (coordonnee par coordonnee) $\\Rightarrow$ derivees partielles Definition: Si la fonction $\\phi:t\\mapsto f(x_1,â€¦,x_k+t,â€¦,x_n)$ est derivable en $0$, on dit que la $k^e$ derivee partielle de $f$ existe en $x=(x_1,â€¦,x_n)$, et $\\phiâ€™(0)=\\frac{\\delta f}{\\delta x_k}(x)$ (se note $\\delta_nf(x)$)\\[\\phi(t) = f(x_1,...,x_k+t,...,x_n) = f(x+t(0,...0,1,0,...0))\\]On regarde ce quâ€™il se passe pour la $k^e$ coordonnee en â€œbloquantâ€ les autres.Pour $f:\\mathbb R\\to\\mathbb R$, $fâ€™(x_0)$ existe $\\Leftrightarrow$ $f$ derivable en $x_0$ $\\Rightarrow$ f continue en $x_0$ Manque de bol, lâ€™existence des derivees partielles en un point donne $\\not\\Rightarrow$ continuite de $f$Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases}\\frac{xy}{x^2+y^2} &amp;amp;(x,y)\\neq(0,0)\\\\0 &amp;amp;(x,y)=(0,0)\\end{cases}\\end{aligned}\\]On va regarder \\(\\begin{aligned}\\phi_x:t&amp;amp;\\to f((0,0)+t(1,0)) \\\\ \\phi_x(t)&amp;amp;=f(t,0)=0\\forall t \\\\ &amp;amp;\\rightarrow\\phi_x&#39;(0)=0\\frac{\\delta f}{\\delta x}(0,0)\\end{aligned}\\)Idem pour $y$\\[\\begin{aligned}\\phi_y:t&amp;amp;\\to f((0,0)+t(0,1)) = f(0,t)=0\\forall t\\\\&amp;amp;\\rightarrow \\phi_y&#39;(0)=0=\\frac{\\delta f}{\\delta y}(0,0)\\end{aligned}\\] $\\frac{\\delta f}{\\delta x}$ et $\\frac{\\delta f}{\\delta y}$ existent en $(0,0)$, mais $f$ nâ€™est pas continueDerivee directionnelle On peut generaliser la notion de derivee en un vecteur$\\rightarrow$ On dit que $f$ est derivable en $x_0$ selon un vecteur $v\\in\\mathbb R^n\\setminus{0}$ si la fonction $\\phi:t\\mapsto f(x_0+tv)$ est derivable en $0$. On note $\\phiâ€™(0)=\\lim_{t\\to0}\\frac{f(x_0+tv)-f(x_0)}{t} = \\color{red}{D_vf(x_0)}$\\[\\frac{\\delta f}{\\delta x_i}(x_0)=D_{e_i}f(x_0)\\]Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\]Que vaut la derivee selon $v=(2,0)$ et $x_0=(1,0)$ ?\\[\\begin{aligned}\\phi:t\\to f(x_0+tv) &amp;amp;= f((1,0)+t(2,0))\\\\&amp;amp;= f(1+2t,0)\\\\&amp;amp;= (1+2t)^2+0^2\\\\&amp;amp;= 4t^2+4t+1\\end{aligned}\\\\\\rightarrow\\phi(t) = 4t^2+4t+1\\rightarrow \\phi&#39;(t)=8t+4\\rightarrow phi&#39;(0)=D_vf(x_0)=4\\\\\\text{Et } D_{e_1}=\\frac{\\delta f}{\\delta x}(x_0) = 2\\\\\\begin{cases} D_{(2,0)}f(x_0)=4\\\\ D_{(1,0)}f(x_0)=\\frac{\\delta f}{\\delta x}(x_0)=2\\end{cases}\\text{D&#39;une maniere generale, } D_{\\alpha v}f(x_0)=\\alpha D_v f(x_0)\\]Si $\\Vert v\\Vert=1\\rightarrow$ derivee en $x_0$ en vecteur $v$ $\\equiv$ derivee directionnelle en $x_0$ selon $v$Est-ce que les derivees directionnelles sont la solution ?Est-ce que lâ€™existence des derivees directionnelles en $x_0$ selon tout vecteur $v\\in\\mathbb R^n\\setminus{0}$ garantit la continuite ? Nope, toujours pas.Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases}\\frac{y^2}{x} &amp;amp;x\\neq0\\\\y &amp;amp;x=0\\end{cases}\\end{aligned}\\]En $(0,0)$ selon $v=(v_1,v_2)\\neq{(0,0)}$\\[\\begin{aligned}\\phi:t&amp;amp;\\to f(x_0+tv)=f((0,0)+t(v_1,v_2)) = f(tv_1,tv_2)\\\\\\phi(t)&amp;amp;=\\begin{cases}\\frac{(tv_2)^2}{tv_1} &amp;amp;v_1\\neq0\\\\tv_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi(t)&amp;amp;=\\begin{cases}t\\frac{v_2^2}{v_1} &amp;amp;v\\neq 0\\\\tv_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi&#39;(t)&amp;amp;=\\begin{cases}\\frac{v_2^2}{v_1} &amp;amp;v_1\\neq0\\\\v_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi&#39;(0)&amp;amp;=\\begin{cases}\\frac{v_2^2}{v_1} &amp;amp;v_1\\neq0\\\\v_2 &amp;amp;v_1=0\\end{cases}\\rightarrow\\text{ existe }\\forall v\\in\\mathbb R^2\\setminus\\{0\\}\\end{aligned}\\] $f$ admet une derivee en $0$ quelque soit le vecteur $v\\in\\mathbb R^2\\setminus{0}$ Pourant, $f$ nâ€™est pas continue en $(0,0)$.Si on regarde le parametrage $\\psi:t\\to(t^2,t)$\\[f\\circ\\psi(t)=f(\\psi(t)) = f(t^2,t)=\\begin{cases}\\frac{t^2}{t^2} &amp;amp;t\\neq0\\\\0 &amp;amp;t=0\\end{cases}\\]$\\rightarrow$ $f\\circ\\psi$ nâ€™est pas continue en $0$$\\rightarrow$ $f$ nâ€™est pas continue en 0Nouvelle approcheOn va changer lâ€™angle dâ€™attaquePour $f:\\mathbb R\\to\\mathbb R$, on a vu: $f$ derivable en $x_0$ \\(\\begin{aligned}&amp;amp;\\Leftrightarrow \\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)}{h} \\\\ &amp;amp;\\Leftrightarrow f(x_0+h)=\\underbrace{f(x_0)}_{\\text{la variable c&#39;est }h}+\\underbrace{hf&#39;(x_0)}_{\\text{fonction lineaire par rapport a }h}+\\underbrace{\\theta_a(h)}_{h\\varepsilon(h)}\\end{aligned}\\) Definition: On dit que $f$ est differentiable en $x_0$ sâ€™il existe une application lineaire \\(\\underbrace{d_{x_0}f}_{\\text{se note aussi }df(x_0), df_{x_0}}:\\mathbb R^n\\to\\mathbb R\\) telle que \\(\\color{red}{f(x_0)+d_{x_0}f(h)+\\underbrace{\\theta_a(\\Vert h\\Vert)}_{\\Vert h\\Vert\\varepsilon(h)}}\\)Pour $f:\\mathbb R\\to\\mathbb R$, $f$ derivable en $x_0$ $\\Leftrightarrow$ \\(f(x_0+h)=f(x_0) + \\underbrace{hf&#39;(x_0)}_{d_{x_0}f\\text{ avec } d_{x_0}f:h\\to hf&#39;(X_0)} + h\\varepsilon(h)\\) $d_{x_0}f$ sâ€™appelle la differentielle de $f$ en $x_0$ differentielle = application lineaire = fonction $\\neq$ $fâ€™(x_0)$ = valeur Proposition: Si $f$ est differentiable en $x_0$, $f$ est continue en $x_0$preuve $\\rightarrow$ admiseExemple\\[\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto x^2\\end{aligned}\\]En $x_0$\\[f(x_0+h)=(x_0)^2=\\underbrace{x_0^2}_{f(x_0)}+\\overbrace{2hx_0}^{\\text{fonction lineaire par rapport a }h \\\\ \\rightarrow d_{x_0}f(h)=2hx_0 \\\\ \\rightarrow d_{x_0}h\\mapsto\\underbrace{2x_0h}_{f(x_0)}}+\\underbrace{h^2}_{\\theta_a(h)\\to\\frac{h^2}{h}=h\\to_{h\\to0}0}\\\\\\]\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto x^Tx\\end{aligned}\\]En $x_0$:\\[\\begin{aligned}f(x_0+h)&amp;amp;=(x_0+h)^T(x_0+h) = x_0^Tx_0+x_0^Th+\\underbrace{h^Tx_0}_{(h^Tx_0)^T=x_0^Th}+h^Th\\\\&amp;amp;= \\underbrace{x_0^Tx_0}_{f(x_0)} + 2x_0^Th+\\underbrace{h^Th}_{\\theta_a(\\Vert h\\Vert)}\\end{aligned}\\\\h^Th=&amp;lt;h,h&amp;gt;=\\Vert h\\Vert^2\\\\\\frac{h^Th}{\\Vert h\\Vert}=\\frac{\\Vert h\\Vert^2}{\\Vert h\\Vert}=\\Vert h\\Vert\\to_{h\\to0}0\\]Et $2x_0^Th$ est lineaire $\\color{red}{(2x_0^T(h_1+\\lambda h_2))=2x_0^Th_1+2\\lambda x_0^Th}$ Propriete: Si $f$ differentielle en $x_0$, alors f admet des derivees selon tout vecteur $h\\in\\mathbb R^n\\setminus{0}$ et $D_hf(x_0)=d_{x_0}f(h)$Lien entre differentielle et vecteur gradientf differentielle en $x_0$, $f$ admet des derivees selon tout vecteur $h\\in\\mathbb R^n\\setminus{0}$, en particulier selon les vecteurs de la base canonique $(e_1,â€¦,e_n)$$\\rightarrow$ toutes les derivees partielles $\\frac{\\delta f}{\\delta x}(x_0)$ existent\\[h\\in\\mathbb R^n\\\\h=\\begin{pmatrix}h_1\\\\\\vdots\\\\h_n\\end{pmatrix}\\quad h=\\sum_{i=1}^nh_ie_i\\\\\\begin{aligned}d_{x_0}f(h) &amp;amp;= d_{x_0}f(\\sum_{i=1}^nh_ie_i) \\begin{cases}h_i\\in\\mathbb R\\forall i\\\\e_i\\in\\mathbb R^n\\end{cases}\\quad f\\text{ lineaire } f(\\lambda x+\\mu y) = \\lambda f(x) + \\mu f(y)\\\\&amp;amp;= \\sum_{i=1}^nh_id_{x_0}f(e_i)\\\\&amp;amp;= \\sum_{i=1}^nh_iD_{e_i}f(x_0) = \\sum_{i=1}^nh_i\\frac{\\delta f}{\\delta x_i}(x_0)\\end{aligned}\\] Definition: On appelle vecteur gradient de $f$ en $x_0$\\[\\nabla_{x_0}f=\\nabla f(x_0)=\\begin{pmatrix}\\frac{\\delta f}{\\delta x_i}(x_0)\\\\\\vdots\\\\\\frac{\\delta f}{\\delta x_n}(x_0)\\end{pmatrix}\\]\\[\\begin{aligned}d_{x_0}f(h) &amp;amp;= \\sum_{i=1}^nh_i\\frac{\\delta f}{\\delta x_i}(x_0) = (\\underbrace{\\frac{\\delta f}{\\delta x_1}(x_0),...,\\frac{\\delta f}{\\delta x_n}(x_0)}_{\\nabla_{x_0}f^T})\\begin{pmatrix} h_1 \\\\ \\vdots \\\\ h_n \\end{pmatrix}\\\\&amp;amp;=\\nabla_{x_0}f^Th=&amp;lt;\\nabla_{x_0},h&amp;gt;\\end{aligned}\\]$f$ differentielle en $x_0$, $d_{x_0}=&amp;lt;\\nabla_{x_0}f,h&amp;gt;=\\nabla_{x_0}f^Th$ La differentielle est donc \\(d_{x_0}f:h\\mapsto&amp;lt;\\nabla_{x_0}f,h&amp;gt;=\\nabla_{x_0}f^Th\\)Comment sâ€™etend la differentielle pour \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^p \\\\ x=(x_1,...,x_n)&amp;amp;\\mapsto f(x) = (f_1(x_1,...,x_n),...,f_p(x_1,...,x_n))\\end{aligned}\\)\\[\\begin{aligned}f:\\mathbb R&amp;amp;\\rightarrow \\mathbb R^3\\\\x&amp;amp;\\mapsto(2x, x^2, 3x+2)\\end{aligned}\\]$f$ differentiable en $x_0$ $\\Leftrightarrow$ $f_1,â€¦,f_p$ sont differentiables en $x_0$\\[\\begin{aligned}f(x_0+h)&amp;amp;=\\begin{pmatrix} f_1(x_0+h) \\\\ \\vdots \\\\ f_p(x_0+h) \\end{pmatrix}\\\\&amp;amp;= \\begin{pmatrix}f_1(x_0) + d_{x_0}f_1(h)+\\theta_a(\\Vert h\\Vert)\\\\\\vdots \\\\f_p(x_0) + d_{x_0}f_p(h)+\\theta_a(\\Vert h\\Vert)\\end{pmatrix}\\\\&amp;amp;= \\underbrace{\\begin{pmatrix}f_1(x_0)\\\\\\vdots\\\\f_p(x_0)\\end{pmatrix}}_{f(x_0)} + \\underbrace{\\begin{pmatrix}d_{x_0}f_1(h)\\\\\\vdots\\\\d_{x_0}f_p(h)\\end{pmatrix}}_{?} + \\underbrace{\\theta(\\Vert h\\Vert)}_{\\in\\mathbb R^p}\\end{aligned}\\]Les $f_i, i = 1,â€¦,p$ sont des fonctions differentiables de $\\mathbb R^n\\to\\mathbb R$\\[d_{x_0}f_i(h) = &amp;lt;\\nabla_{x_0}f_i,h&amp;gt; = \\nabla_{x_0}f_i^Th=\\biggr(\\frac{\\delta f_1}{\\delta x_1}(x_0),...,\\frac{\\delta f_n}{\\delta x_n}(x_0)\\biggr)h\\\\\\begin{pmatrix}d_{x_0}f_1(h) \\\\ \\vdots \\\\ d_{x_0}f_p(h) \\end{pmatrix}_{\\mathbb R^p} = \\begin{pmatrix}\\nabla_{x_0}f_1^Th \\\\ \\vdots \\\\ \\nabla_{x_0}f_p^Th \\end{pmatrix}_{\\mathbb R^p} = \\begin{pmatrix} (\\frac{\\delta f_1}{\\delta x_1},...,\\frac{\\delta f_1}{\\delta x_n})h \\\\ \\vdots \\\\ (\\frac{\\delta f_p}{\\delta x_1},...,\\frac{\\delta f_p}{\\delta x_n})h \\end{pmatrix}_{\\mathbb R^p} = \\underbrace{\\begin{bmatrix} \\frac{\\delta f_1}{\\delta x_1},...,\\frac{\\delta f_1}{\\delta x_n} \\\\ \\vdots \\\\ \\frac{\\delta f_p}{\\delta x_1},...,\\frac{\\delta f_p}{\\delta x_n} \\end{bmatrix}_{\\mathbb R^{p\\times n}}}_{\\text{matrice jacobienne}}h_{\\mathbb R^n}\\] Pour une fonction $f:\\mathbb R^n\\to\\mathbb R^p$, on appelle matrice jacobienne en $x_0$, et on note $Jac_{x_0}f$, la matrice des derivees partielles $[Jac_{x_0}f]_{ij}=\\frac{\\delta f_i}{\\delta x_j}$\\(\\color{red}{d_{x_0}f(h) = Jac_{x_0}f\\times h}\\) La differentielle de $f:\\mathbb R^n\\to\\mathbb R^p$ en $x_0$ est lâ€™application lineaire $d_{x_0}f:h\\mapsto Jac_{x_0}f\\times h$$f$ differentielle en $x_0$, \\(f(x_0+h)=f(x_0)+\\underbrace{d_{x_0}}_{d_{x_0}f\\text{ application lineaire}}+\\theta_a(\\Vert h\\Vert)\\) \\[\\begin{aligned} f:\\mathbb R&amp;amp;\\rightarrow \\mathbb R^3\\\\ d_{x_0}f:h&amp;amp;\\mapsto hf&#39;(x_0) \\end{aligned}\\] \\[\\begin{aligned} f:\\mathbb R^n&amp;amp;\\rightarrow \\mathbb R\\\\ d_{x_0}f:h&amp;amp;\\mapsto &amp;lt;\\nabla_{x_0}f, h&amp;gt;=\\nabla_{x_0}f^Th \\end{aligned}\\] \\[\\begin{aligned} f:\\mathbb R^n&amp;amp;\\rightarrow \\mathbb R^p\\\\ d_{x_0}f:h&amp;amp;\\mapsto Jac_{x_0}f\\times h \\end{aligned}\\] " }, { "title": "COIN: Communication Interpersonnelle", "url": "/cours/posts/coin_coin/", "categories": "tronc commun S8, COIN", "tags": "tronc commun, COIN, S8", "date": "2021-04-07 10:00:00 +0200", "snippet": "Lien de la note HackmdPlan du cours: Temperament Cycle de resolution de problemes LeadershipRappels: les axes Introversion/extroversion $\\rightarrow$ Orientation de lâ€™energie Sensation/intuition $\\rightarrow$ Modes de perception Thinking/feeling $\\rightarrow$ Criteres de decision Judgement/perception $\\rightarrow$ OrganisationLes temperamentsModes dâ€™apprentissageExerciceEn distanciel: exercice discordRapport a lâ€™argent ? Econome/depensier ?Un mot qui nous defini ?Un animal qui nous ressemble ?Methodique - SJ Quoi Organise - Etapes definies Methode eprouvees Exercices structures Pratique Respect du statut Discipline clairePendant lâ€™exercice: Econome Pas depensier On sait se faire plaisir Pas investissement Lea elle aime le bitcoin Curieux/connaissance Le dauphin Parce quâ€™il est curieux :3 La gerboise Petit animal curieux En bref Style de leadership Sens de la hierarchie Ferme Impartial Planificateur Relation du temps Ponctuel Fait des listes Sait jeter Style professionnel Sens des responsabilites Relation a lâ€™argent A lâ€™aise avec lâ€™argent Specificites Ponctualite Precipitation Impatience critique SJ: DEVOIR - Gardiens du temps Risque: surmenage, rigidite/obstination La cigale de la cigale et la fourmiPragmatique - SP Quand et comment Improvise Experimentation pratique Observateur En fonction de lâ€™utilite Discipline souple et continueSP en bref Style de leadership Supporte mal lâ€™autorite Agit en negociateur SP LIBERTE - Artisans Sens pratique Realisme Flexibilite Action Debrouillard Infatigable si plaisir Style decontracte Risque: versatile, insouciant, imprevisible La fourmi de la cygale et la fourmiConceptuel - NT Pourquoi Analyse Lectures personnelles Respect de la competence Discipline selon les objectifsEn bref Style de leadership Supporte autorite de competences Relation du temps Usage rationnel Plannification Style professionnel Logique Accorde une grande importance au travail Relation a lâ€™argent Gere rationnellement Prend des risques Specificites Elabore des modeles Voit lâ€™ensemble Perfectionniste NT SAVOIR - Rationnel Theorie Innovation Competence Concepteur Curieux Rationalite Direct, concis Risque: froid, cynique, critique, blessantNâ€™assure pas lâ€™execution Le gars qui a amene le feu a lâ€™humanite et qui se fait maintenant bouffer les organes a lâ€™infiniRationnel - NF Qui Comprendre Discussion de groupe En fonction du lien personnel Discipline personnaliseeEn bref Style de leadership Charismatique Relation au temps Sensible au besoin des autres Donne de son temps Style pro Communicateur Creatif Transmettre dâ€™idees Relation a lâ€™argent Considere comme un moyen pour une fin Specificites Chaleureux NF DEVENIR - Idealistes Lucidite Idealisme Recherche de sens Empathie Communication Catalyseurs Persuasif Risque: hypersensibilite, dependance, confusion des roles, ignore les problemes pratique Le gars partit tabasser des moulins a ventCycle de resolution de problemesExercice - truc de la NASAOn est dans un bateau qui coule et on doit estimer des objets par ordre de croissance. â€œCe sont les experts hein, pas moiâ€En premier lieu, vous devez rÃ©aliser le classement sur une base individuelle et, dans un second temps, effectuer un classement de groupe. Par la suite, nous vous communiquerons le classement type rÃ©alisÃ© par des experts et vous pourrez comptabiliser les scores obtenusLe but: avoir le score le plus basResultat:La strategie: Se faire reperer La plupart des sauvetages arrives pendant les 36 premieres heures Survivre Le rhum peut servir dâ€™antiseptiqueModele typologiqueUn peu associer chaque pole a chaque etape: Analyse: T Motivation: F Solution: N Diagnostic: S E: chercher a lâ€™exterieur Discuter avec des gens exterieur I: Chercher a lâ€™interieur Trouver la solution par soi-meme P: Passer son temps sur le diagnostic/solutions J: Passer son temps sur la motivation/analyse On a TOUS des etapes quâ€™on court-circuite (qui nous interesse moins que dâ€™autres).Câ€™est quoi les outils pour faire un diagnostic ?Questionnaires et interviews Diagramme de Pareto: 80/20 Exemple: si 80% des clients se plaignent du meme bug, on repare ce bug en priorite, les 20% restants sont moins prioritairesCâ€™est quoi les outils pour chercher des solutions ? Le brainstorming Le tour de table Le benchmark Envoyer un stagiaire faire le faux client dans une autre entreprise Piquer leurs idees Amenager les banques pour acceuillir les â€œclientsâ€ (et non utilisateurs) Se sont benchmarker avec les hotels Matrice combinatoire Melanger 2 objets pour en creer un nouveau Comment on fait de lâ€™analyse ?La matrice multi-criteresMotivation ?Informer, communiquer, formerLe leadership en situationExercice Quelles caracteristiques pour un manager ? Dessinez un manager et son equipe4 Styles de leadershipDirectifDirecteur dâ€™usine : structurer la tache Mode de management precis, detaille, centre sur des resultats. Le manafer decide et controle. Structurant Envahissant PersuasifGuide de haute montage Mode de management centre sur un engagement personnel. Recherche de lâ€™implication de tous, vigilance sur les modes operatoires et les resultats Convaincant Paternaliste Participatif Le manager anime des talents et des initiatives, au sein dâ€™une equipe. Il se contractualise ses rapports avec des collaborateurs Ouvert Manipulateur (dans le cas du â€œfauxâ€ participatif) Animateur Prend du temps Legitime Incertain DeleguatifChef de projet Le manager donne des objectifs et controle dans un cadre contractuel, avec des echeances a moyens terme. Responsabilise Laisse faire Soutient Abandonne Developpe Â  Savoir adapter son style en fonction: Des personnalites en presence De lâ€™autonomie des collaborateurs Autonomie tres faible: style directif Autonomie faible: style persuasif Autonomie moderee: style participatif Autonomie forte: style deleguatif La culture de lâ€™organisation Conditions dâ€™efficacite Autonomie des collaborateursRemarques Lâ€™autonomie varie un peu en fonction des personnes, beaucoup en fonction des situations Le degre dâ€™autonomie change dans le tempsCycle progressif/regressif" }, { "title": "IML: Unsupervised clustering", "url": "/cours/posts/iml_dimensionality_clustering/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8, clustering", "date": "2021-04-02 13:00:00 +0200", "snippet": "Lien de la note HackmdWhy do we care Group the input data into clusters that share some characteristics Find pattern in the data (data mining problem) Visualize the data in a simpler way Infer some properties of a given data point based on how it relates to other data point (satistical learning)Why is it trickyBelongs to unsupervised learning No grounds truth available to learn/evaluate quality of the algorithmHow to assess how much data points are related to each other? Which criteria (features) are the most relevant Which metrics make the most senseHow to assess the soundness of the resulting cluster? Is it relevant ?Families of clustering approaches Distance-based clustering centroid-based approach (k-mean) connectivity-based approaches (based on distance) Density-based clustering set of dense points Distribution-based clustering likelihood of point to belong to the same distribution Fuzzy clustering Relaxed clustering paradigm where a data point can be assigned to multiple clusters with a quantified degree of belongingness metric (fuzzy $c$-means clustering,â€¦). $k-$means clusteringPartition $n$ observations $x_1,â€¦,x_n$ int $k$ clusters $C={C_1,â€¦,C_k}$ where each observations $x_i$ belongs to the cluster $C_{j*}$ whose mean $\\mu_{j*}$ is the closest: $x_i\\in S_{j*}$ with $j^{*}=argmin_j\\Vert x_i-\\mu_j \\Vert_2$La croix represente le centre, on veut la plus petite distance depuis un centre pour ajouter un point dans un cluster: Minimize within-cluster sum of squares (variance) Overall optimization problem: NP-hard problem, no guarantee to find the optimal value Stochastic and very sensitive to initial conditions Sensitive to outliers (thank you $L_2$ norm) Probably the most used clustering algorithm$k-$means and Voronoi tesselation Voronoi tesselationparition of the Euclidean space relatively to discrete points/seeds. Each region/Voronoi cell is composed of all the points in the space that are closer to the cell seed than any other seed $k$-mean provides a way to obtain a Voronoi tesselation of the input space, where seeds are the final cluster means Alternatively, one case use some pre-computer Voronoi tesselation seeds as initial clusters for $k$-meansDetermining the optimal number of clusterCombien de clusters a vue de nez pour cette image ? 2, 3, 4, 14â€¦.Compute explained variance for an increasing number of clusters $k$ Plot and find the bend of the elbow Sometimes it does not work :( Sometimes, $k$-means worksâ€¦But most of the time not as expected. Probably because the $L_2$ norm that $k$-means tries to minimize Sensible of curse of dimensionality Form â€œnormalized Gaussianâ€ clusters Does not adapt to manifold geometry Sensible to class imbalance Sensible to outliersSimple Linear Iterative Clustering A kick-ass image segmentation algorithm using $k$-means SLIC superpixels uses a modified $k$-means clustering in the $Labxy$ space to produce $k$ clusters regurlaly sampled and perceptually coherent from a color point of view.k-medoids clustering Possible extension to $k$-means Cluster centroids are not initial data points $\\Rightarrow$ can be problematic$\\Rightarrow$ Replace centroids by medoid (points with the smallest distance to all other points in the cluster)$\\Rightarrow$ $k$-medoid algorithmOverall objective: find $k$ medoids $m_1, . . . , m_k$ that minimize the partitioning costFuzzy $c$-means clustering $k$-means is a hard clustering method: each data point 100% belongs to the cluster Soft clustering methods allow each data points to belong to several clusters with various degrees of membershipGaussian mixture models $k$-means on steroids$k$-means works for spherical clusters, but fails in any other cases $\\Rightarrow$ try harder Model probability density function $f$ of data as a mixture of multivariate GaussianCette courbe est une superposition de plusieurs Gaussiennes: Il faut pouvoir estimer les facteurs de proportions de ces gaussiennes dans la sommeThe EM algorithmInitialization Select $k$ random points as initial means $\\hat\\mu_1,â€¦,\\hat\\mu_k$ Init all covariance matrices $\\hat\\sum_1,â€¦,\\hat\\sum_k$ as whole data sample covariances matrix $\\hat\\sum$ Set uniform mixture weight $\\hat\\phi_1,â€¦,\\hat\\phi_k=\\frac{1}{k}$Alternate until convergenceExpectation stepCompute membership weight $\\hat\\gamma_{ij}$ of $x_i$ with respect to $j^{th}$ component $\\mathcal N(x\\vert\\mu_j,\\sum_j)$Maximization stepUpdate weights (in that ordre) Tadaaaa $k$-means vs GMM Let the fight begin!Kernel Density Estimation Nonparametric estimation GoalEstimate probability density function $f$ based on observations $x_1,â€¦,x_n$ only, assumed to derive from $f$ otherwise wtf are we doing here The kernel density estimator with bandwith $h$ at given point $x$ is given byExemplesMean shift clustering shift each point to the the local density maximum of its KDE, and assign to the same cluster all points that lead to the same maximum ExemplesOn peut faire la meme chose sur les images en couleurs:DBSCAN Density-base spatial clustering of applications with noise Divide points into 3 categories (core, boundary, outliers) whether there are at least $minPts$ in their $\\epsilon$-neighborhood or not Find the connected component of core points (ignore all non-core points) Assign non-core points to nearby clusters if it is less than $\\epsilon$ away, otherwise assign to noiseSpectral clustering View clustering task as a min-cut operation in a graph Compute similarity graph (but which one?) of data $x_1,â€¦,x_n$ Compute (weighted) adjacency matrix $W$, degree matrix $D$ and Laplacian matrix $L=D-W$ Perform eigendecomposition of $L=(E,\\triangle)$ Fact #10 is and eigenvalue of $L$ with multiplicity $\\sim#$ connected components in graph, its eigenvectors are identity vectors of those connected components Fact #2Eigenvector of smallest non-zero eigenvalue (Fiedler vector) gives the normalized min-cut of graph Performs $k$-means clustering of the $k$ smallest eigenvectors $[e_1,â€¦,e_k]_{n\\times k}$Hierarchical clustering A very natural way of handling data GoalGenerate a sequence of nested clusters and ordre them in a hierarchy, represented by a dendogram Leaves the dendogram = initial data Inner nodes of the dendogram = clustersExempleAgglomerative vs Divise clusteringAgglomerative: merge clusters from fine to coarse (bottom-up approach)Divisive clustering: split clusters (top-down approach) Needs some heuristics to avoid the $O(2^n)$ ways of spitting each clusterâ€¦ Not so used in practiceBestiarityOverall comparison of all methods" }, { "title": "TIFO: Introduction a la morphologie mathematique, exemples", "url": "/cours/posts/tifo_morpho_maths_exemples/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique", "date": "2021-04-02 10:00:00 +0200", "snippet": "Lien de la note HackmdImagerie medicale Parties blanches dans le cerveau: lesionsLa combinaison des modalites avec lâ€™image tophat permet de mettre en evidence ces petits strucuturesSuivi de particulesSequences en 2D+tDans des images en 3D+t (3D video)Avec lâ€™IMCEEOn cherche des satellites qui bougent entre 2 imagesPipeline: Câ€™est moche mais ca marcheOn utilise la loi de Khi-DeuxLa suite Base de donneees alimententee quotidienement par Maya Mise en place dâ€™un algo de classification des imagettes base sur le machine learning 97% a 98% de bonne classifications actuellement" }, { "title": "TIFO: Introduction a la morphologie mathematique, partie 2", "url": "/cours/posts/tifo_morpho_maths_suite/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique, niveau de gris, minima, maxima, watershed", "date": "2021-04-02 09:00:00 +0200", "snippet": "Lien de la note HackmdRappels erosion et dilatation z erosions de taille y = une erosion de taille $z\\times y$ z ouverture de taille y $\\neq$ une ouverture de taille $z\\times y$Niveau de grisOn peut voir lâ€™erosion et la dilatation comme une etude des niveaux de gris presents dans une fenetre glissante representee par lâ€™element structurantOn regarde le ixel de lâ€™origine de lâ€™element structurant. On attribue le min ou max pour les pixels correspondants a lâ€™element structurant de leurs niveaux de grisFiltres alternes sequentiels Une repetetition des compositions (fermeture et ouverture) pour debruiter progressivemenent en perdant le moins dâ€™infos possible alternes: on alterne les filtres sequentiel: on augmente la taille de lâ€™element structurant au fur et a mesureTop hatExemple pas du tout scientifique Jâ€™ai pris Harry et je lâ€™ai ouvertHarry en gris - Harry en gris ouvert = Dindon is that you ??La dinde a un niveau de gris dâ€™ecart avec lâ€™image originaleBilan Le nom â€œmorphologie mathematiquesâ€ a ete choisi dans un bar Morpho = considerer les images commes des paysages Minecraft Non-lineaire: insensible au contraste Erosion et dilatation sont amis pour la vie On peut selectionner des objets grace a leur forme/taille (geometrie) La morpho est tres utile pour le filtrage dâ€™image LES DINDES ONT PRIS LE CONTROLE DU MONDEDe nouveaux outilsRetournons sur Harry et son patronusOn augmente la taille de lâ€™element structurant = tout est plus visible (image incoming)Simple dilatationGradients morphologiquesDinde binaire: La dilatation va â€œaugmenter les bordsâ€ Soustraire les 2 images, câ€™est le gradient externeAvec une erosion: Lâ€™erosion va â€œgrignoter les bordsâ€ Câ€™est le gradient interneEn niveau de gris:Bilan du gradient Ces gradients se ressemblent beaucoup!Il faut choisir le gradient au cas par cas.La squeletisation On va chercher le squelette de notre objet.Lâ€™idee câ€™est de prendre la position des centres des boules max inclues dans lâ€™objet etudie On fait grossir des boules au fur et a mesure (ray marching style) A partir du moment ou lâ€™objet touche le bord, ca fait nâ€™importe quoiCarte des distance Attribuer a chaque pixel de lâ€™ojet concerne sa distance au bordOutil de segmentation: le Watershed Ou ligne de partage des eaux On â€œinondeâ€ les vallees (minima locaux) au fur et a mesure que lâ€™on â€œmonteâ€ en niveau de gris. Quand 2 vallees se recontrent, cela cree une ligne qui est la limitation entre 2 objets. En fonction de lâ€™implem, il faut des marqueurs ou non Toujours lire la doc de la fonction de Watershed quâ€™on utilise Sâ€™il nâ€™y a pas de marqueurs et que lâ€™image a beaucoup de minima locaux, on a une sur-segmentationLes minima/maxima locaux Extrema local: point ou groupe de point dont la valeur est extreme dans un voisinage donneLes maxima locauxOn peut definir des profondeurs de maxima On peut selectionner les maxima qui se â€œdistinguentâ€ vraiment du reste On calcule sa profondeur pour chaque maxima Niveaux de gris necessaire pour quâ€™il nâ€™y a plus de maxima On vide lâ€™eau qui a inonde partout sous la courbe On regarde quand les regions fusionnent Câ€™est lâ€™inverse du WatershedReconstruction geodesique Recuperer uniquement certains objets a lâ€™aide de marqueursImplem: dilatations successives jusquâ€™a idempotenceBouchage de trousRectangle rouge = marqueur du fondElimination dâ€™objets touchant les bords" }, { "title": "TIFO: Introduction a la morphologie mathematique", "url": "/cours/posts/tifo_morpho_maths/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique, dilatation, erosion, ouverture, fermeture, composition, connexe", "date": "2021-04-01 14:00:00 +0200", "snippet": "Lien de la note Hackmd Par Elodie cette fois TP en Python (wouhou!) Evaluation: commun avec IMEDPlan du coursYâ€™en a pasBut du cours Savoir ce quâ€™est la morphologie mathematiques Comprendre son interet Acquerir les bases de la morphologie mathematiques Savoir utiliser les outils de morphologie mathematique pour traiter divers probleme de traitement dâ€™image. On fait mieux que des reseaux de neurones ! (environ)Quâ€™est-ce que câ€™est ?HistoireInvention francaise (cocorico)Nee en 1964 a MINES PariTech (ENSMP a Fontainebleau) par Georges Matheron Le nom morphologie mathematiques est ete choisiâ€¦ dans un bar 1982: publication du livre Serra en Anglais 1987: premiers articles dnas IEEE PAMI faire en sorte que la morphologie mathematiques soit reconnue mondialement Depuis, elle est utilisee dans le monde entier Conference internationale tous les 2 ans Journal specialiseSTOOOPOn va parler dâ€™OpenCV Attention a OpenCV Câ€™est genial et horrible en meme temps Pour importer OpenCV1: import cv Pour importer OpenCV2: import cv2 Pour importer OpenCV3: import cv2 wot RGB devient BGR xyz? non zyxâ€¦Retour a quâ€™est-ce que câ€™estUne image devient une fonction On considere lâ€™image comme un paysage ! (un peu comme Minecraft)En quelques mots La morpho maths fait partie de la categorie de traitement dâ€™image non lineaire Toutes les parties de lâ€™image ne vont pas reagir de la meme maniere a lâ€™application dâ€™outils de morpho maths Permet dâ€™etre beaucoup plus generique et efficace En particulier: on est invariant au contraste La base des basesConcept de base: lâ€™ordreOn doit pouvoir etbalir une relation dâ€™ordre entre chaque element considere (pixels, groupes de pixels,etc.) Le treillisStructure de bases: treillis complet structure ordoneeLa connexite La connexite, câ€™est le voisinage des pixelsTous les voisins quâ€™on considere comme connectes.En 3D: connexite 6, 18, 26 Voir a quoi ca correspond: imaginer un Rubikâ€™s cubeComposante connexe Ensembles de pixels connectesOperateurs en morpho mathsProprietesSoit $\\Omega$ un operateur morpho, $x$ et $y$ deux parties de treillis $x\\le y\\Rightarrow\\Omega(x)\\le\\Omega(y)$ Croissance $x\\le\\Omega(x)$ ou $\\Omega(x)\\le x$ Extensivite ou Anti-Extensivite $\\Omega(\\Omega(x))=\\Omega(x)$ IdempotenceElements structurants On veut comparer ce quâ€™on veut traiter avec un objet de geometrie connue: element structurant forme connue taille connue origineOperateursLâ€™erosion Rappel: on est dans un paysageOn considere une image binaire avec un fond noir et un objet blanc. Lâ€™erosion va venir â€œgrignoterâ€ lâ€™objet blanc!On considere un element structurant $B_z$, avec une origine $z$. Lâ€™erosion est definie par:\\[\\epsilon(X)_B=\\{z/B_z\\in X\\}\\]Une video pour mieux comprendreLa dilatationEn prenant les memes notations et ca devient:\\(\\delta(X)_B=\\{z/B_z\\cap X\\neq\\emptyset \\}\\)Une video pour mieux comprendreBilanErosion: agrandit les trous deconnecte les objets â€œaugment le noirâ€Dilatation: rempli les trous connecte les objets â€œaugment le blancâ€La forme de lâ€™element structurant va â€œselectionnerâ€ les formes quâ€™on garde $\\rightarrow$ on filtre en fonction de la taille/forme La croissance nâ€™est valables que si les elemens structurants sont identiquesAssocier et composerPremiere compositionQue se passe-t-il si on fait une erosion suivi dâ€™une dilatation ?\\[\\gamma(X)=\\delta_B(\\epsilon_B(X))\\] Il sâ€™agit dâ€™une ouvertureDeuxieme compositionQue se passe-t-il si on fait une dilatation suivi dâ€™une erosion ?\\[\\phi(X)=\\epsilon_B(\\delta_B(X))\\] Il sâ€™agit dâ€™une fermetureLâ€™ouverture et la fermetureCe sont des outils tres puissants en morpho Ils permettent de garder les objets plus grands que lâ€™element structurant Ideales dans des problemes de filtrage/debruitage!" }, { "title": "OCVX: Norme", "url": "/cours/posts/ocvx_norme/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-01 10:00:00 +0200", "snippet": "Lien de la note Hackmd Norme: \\(\\begin{aligned}\\Vert.\\Vert.\\mathbb R^n&amp;amp;\\to\\mathbb R^1\\\\x&amp;amp;\\mapsto\\Vert x\\Vert\\end{aligned}\\) separation: $\\Vert x\\Vert=0\\Rightarrow x=0$ homogeneite: $\\Vert\\lambda x\\Vert=\\vert\\lambda\\vert\\Vert x\\Vert$ inegalite triangulaire: $\\forall x,y\\in\\mathbb R^n, \\Vert x+y\\Vert\\le\\Vert x\\Vert+\\Vert y\\Vert$ inegalite triangulaire inversee: $\\forall x,y\\in\\mathbb R^n,\\biggr\\vert\\Vert x\\Vert-\\Vert y\\Vert\\biggr\\vert\\le\\Vert x-y\\Vert$\\[\\Vert x\\Vert=\\Vert x+y-y\\Vert\\le\\Vert x-y\\Vert+\\Vert y\\Vert\\\\\\Leftrightarrow \\Vert x\\Vert-\\Vert y\\Vert\\le\\Vert x-y\\Vert\\\\\\Vert y\\Vert=\\Vert y-x+x\\Vert\\le\\underbrace{\\Vert y-x\\Vert}_{\\Vert x-y\\Vert}+\\Vert x\\Vert=\\Vert x-y\\Vert + \\Vert x\\Vert\\\\\\Leftrightarrow\\Vert y\\Vert -\\Vert x\\Vert\\le\\Vert x-y\\Vert\\\\\\Rightarrow \\biggr\\vert\\Vert x\\Vert-\\Vert y\\Vert\\biggr\\vert\\le\\Vert x-y\\Vert\\] A partir dâ€™une norme, on peut definir une distance \\(d_{\\Vert.\\Vert}=\\Vert x.y\\Vert\\) Tout produit scalaire permet de definir une norme \\(\\Vert x\\Vert=\\sqrt{&amp;lt;x.x&amp;gt;}\\)En particulier: $p=1$, $\\Vert x\\Vert_1=\\sum_{i=1}^n\\vert x_i\\vert$ $p=2$, $\\Vert x\\Vert_2=\\sqrt{\\sum_{i=1}^nx_i^2}$ $p=\\infty$, \\(\\Vert x\\Vert_{\\infty} = \\max_{i=1,...,n}\\vert x\\vert\\)Question 3.30\\(\\begin{aligned}\\Vert x-y\\Vert_1&amp;amp;=\\vert x_1.y_1\\vert+\\vert x_2.y_2\\vert\\\\&amp;amp;= \\vert 1-3\\vert+\\vert2-1\\vert\\\\d_{\\Vert.\\Vert_1}(xy)&amp;amp;=3\\end{aligned}\\)Distance de Manhattan\\[\\begin{aligned}\\Vert x-y\\Vert_2&amp;amp;=\\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\\\\d_{\\Vert.\\Vert_2}&amp;amp;= \\sqrt{4+1}\\\\&amp;amp;=5\\end{aligned}\\]\\[d_{\\Vert.\\Vert_{\\infty}}=\\Vert x-y\\Vert_{\\infty} = \\max(2,1)=2\\]Notion de voisinageNotion de voisinnage/boule ouverte$\\rightarrow$ generalise la notion dâ€™intervallle pour $\\mathbb R^n$, $n\\ge2$Boule ouverte centree sur un point $x_0$ de rayon $r$\\[\\mathcal B_{\\Vert\\Vert}(x_0,\\varepsilon)=\\{y\\in\\mathbb R^n\\vert\\Vert x_0-y\\Vert &amp;lt; \\varepsilon\\} \\text{ boule ouverte}\\\\\\]\\[\\bar{\\mathcal B}_{\\Vert\\Vert}(x_0,\\varepsilon)=\\{y\\in\\mathbb R^n,\\Vert x_0-y\\Vert\\le \\varepsilon\\} \\text{ boule fermee}\\]Voisinnage de $x_0$:\\(\\mathcal V(x_0)\\subseteq\\mathbb R^n \\text{ tq } \\exists\\varepsilon\\gt0\\\\\\mathcal B_{\\Vert\\Vert}(x_0,\\varepsilon)\\in \\mathcal V(x_0)\\)Question 3.31\\[\\mathcal{\\bar B_2}(0,1):\\\\x\\in(\\delta\\mathcal B_2(0,1))\\\\\\{x\\in\\mathbb R^1,\\underbrace{\\Vert x\\Vert_1=1\\}}_{x_1^2+x_2^2=1}\\]\\[\\mathcal{\\bar B_1}(0,1):\\\\x\\in\\delta\\mathcal B_1(0,1)\\\\\\{x\\in\\mathbb R^2,\\underbrace{\\Vert x\\Vert_2=1}_{\\vert x_1\\vert+\\vert x_2\\vert=1}\\}\\]Si $x_1\\gt0$, $x_2\\gt0$, $x_2=1-x_1$\\[\\mathcal{\\bar B_{\\infty}}:\\\\x\\in\\delta\\mathcal B_{infty}(0,1)\\\\\\{x\\in\\mathbb R^2, \\max(\\vert x_1\\vert,\\vert x_2\\vert)=1\\}\\]Nos formes sâ€™emboitent:$0\\lt p\\lt 1?$$\\Vert.\\Vert_p$ est une quasi norme $\\rightarrow$ inegalite triangulaire$p=0?$$\\Vert x\\Vert_0=$ nombre de coordonnees non nulles du vecteur $x$$\\mathcal B_p(0,1)$ convexe ? $A$ convexe: $\\forall x,y\\in A, \\forall t\\in[0,1]$, $tx+(1-ty)\\in A$\\[x,y\\in\\mathbb B_p(0,1)\\Leftrightarrow \\Vert x\\Vert_p-\\Vert y\\Vert_p\\lt1\\\\\\begin{aligned}t\\in[0,1], \\Vert \\underbrace{tx+(1-t)y}_{\\in\\mathbb B_p(0,1)}\\Vert_p &amp;amp;\\le\\Vert tx\\Vert_p + \\Vert(1-t)y\\Vert \\text{ inegalite triangulaire}\\\\&amp;amp;\\le t\\underbrace{\\Vert x\\Vert_p}_{\\le 1} + (1-t)\\underbrace{\\Vert y\\Vert_p}_{\\le 1}\\\\&amp;amp;\\le t + (1-t)\\\\&amp;amp;\\le 1\\end{aligned}\\]$\\mathcal B_p(0,1)=\\mathcal C_{\\lt 1}\\Vert.\\Vert_p=$ lien de sous niveau (strict) 1.Donc si $\\Vert.\\Vert_p:x\\mapsto\\Vert x\\Vert_p$ est une fonction convexe, $\\mathcal B_p(0,1)=\\mathcal C_{\\lt 1}\\Vert.\\Vert_p$ est une partie convexe.$\\rightarrow(1-t)y\\le tf(x)+(1-t)f(y)$Continuite dâ€™une fonction de $\\mathbb R^n\\to\\mathbb R^p$$f$ continue en $a$\\[\\forall\\varepsilon\\gt0,\\exists\\eta\\gt0, \\vert x-a\\vert\\lt\\eta\\Rightarrow\\vert f(x)-f(a)\\vert\\lt\\varepsilon\\]Continuite dâ€™une fonction de $\\overbrace{\\mathbb R^n}^{\\Vert.\\Vert_n}\\to\\overbrace{\\mathbb R^p}^{\\Vert.\\Vert_p}$ $f$ continue en $a$ $\\Leftrightarrow$\\(\\forall\\varepsilon\\gt0,\\exists\\eta\\gt0, \\underbrace{\\Vert x-a\\Vert\\_{\\alpha}lt\\eta}_{x\\in \\mathcal B_{\\alpha}(a,\\eta)}\\Rightarrow\\underbrace{\\Vert f(x)-f(a)\\Vert_{\\beta}\\lt\\varepsilon}_{x\\in \\mathcal B_{\\beta}(f(a),\\varepsilon)}\\)Equation de normes $\\Vert.\\Vert_{\\alpha}$ et $\\Vert.\\Vert_{\\beta}$ sont equivalentes ssi $\\exists A,B\\gt0$ tels que \\(\\forall x\\in\\mathbb R^n, A\\Vert x\\Vert_{\\beta}\\le\\Vert x\\Vert_T\\le B\\Vert x\\Vert_{\\beta}\\) TheoremeToutes les normes sont equivalentes en dimension finie Fonctions lipschitzienne Definition: Fonctions lipschitzienneUne fonction est $K-$lipschitzienne sâ€™il existe $K\\gt0$ tel que\\[\\forall x,y\\in\\mathbb R^n, \\Vert f(x)-f(y)\\Vert\\le K\\Vert x-y\\Vert\\] TheoremeToute fonction lipschitzienne est continue.Exemple\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\x=\\begin{pmatrix}x_1\\\\ x_2\\end{pmatrix}&amp;amp;\\mapsto x_1+x_2\\end{aligned}\\\\\\begin{aligned}\\begin{cases} x\\in\\mathbb R^2\\\\ y\\in\\mathbb R^2\\end{cases}\\quad \\Vert f(x)-f(y)\\Vert&amp;amp;=\\vert(x_1+x_2)-(y_1+y_2)\\vert\\\\&amp;amp;= \\vert(x_1-y_1)+(x_2-y_2)\\vert\\le\\vert x_1-y_1\\vert+\\vert x_2-y_2\\vert\\end{aligned}\\\\\\Vert x- y\\Vert=\\biggr\\Vert\\begin{pmatrix}x_1\\\\ x_2\\end{pmatrix}-\\begin{pmatrix}y_1\\\\ y_2\\end{pmatrix}\\biggr\\Vert=\\biggr\\Vert\\begin{pmatrix}x_1 - y_1\\\\ x_2-y_2\\end{pmatrix}\\biggr\\Vert_1=\\vert x_1-y_1\\vert+\\vert x_2-y_2\\vert\\)Fonctions continues Toutes les fonctions polynomiales sont continues. Toutes les fractions rationnelles $\\frac{f(x)}{g(x)}, x\\in\\mathbb R^n$ sont continues partout ou $g(x)\\neq0$ Si $f:\\mathbb R^n\\to\\mathbb R^p$ continue, $g:\\mathbb R^n\\to\\mathbb R^p$ continue, $\\lambda,\\mu\\in\\mathbb R$ alors $\\lambda f-\\mu g$ continue. Si $p=1$, $fg$ continue, $\\frac{f}{g}$ continue partout ou $g$ ne sâ€™annule pas. Si $f:\\mathbb R^n\\to\\mathbb R^p$ continue, $f:\\mathbb R^p\\to\\mathbb R^n$ continue, alors $g\\circ f:\\mathbb R^n\\to\\mathbb R^m$ continueExemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x+y\\end{aligned}\\]Est-ce que $x\\mapsto f(x,0)$ et $y\\mapsto f(0,y)$ continues $\\Rightarrow$ $f$ continue ?Bah non ca sera trop beau.\\[\\underbrace{x\\mapsto f(x,0)}_{f\\circ g(t)\\text{ avec } g:t\\mapsto(t,0)}\\\\\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases} \\frac{xy}{x^2+y^2} &amp;amp;(x,y)+(0,0)\\\\ 0 &amp;amp;(x,y)=(0,0)\\end{cases}\\end{aligned}\\] Si $g:t\\to(t,0)$, $f\\circ g(t)=0$ $\\forall t\\in\\mathbb R$ Si $g:t\\to(0,t)$, $f\\circ g(t)=0$ $\\forall t\\in\\mathbb R$ Si $g:t\\to(t,t)$,\\[f\\circ g(t)=\\begin{cases}\\frac{1}{2} &amp;amp;t\\neq0\\\\0 &amp;amp;t=0\\end{cases}\\forall t\\in\\mathbb R\\]Exercice 3.34 Rappel\\(\\Vert x\\Vert_1 = \\sum_{i=1}^n\\vert x\\vert\\\\\\Vert x\\Vert_2=\\sqrt{\\sum_{i=1}^nx^2}\\\\\\Vert x\\Vert_{\\infty}=\\max_{i=1,..,n}\\vert x_i\\vert\\)\\[\\Vert x\\Vert_1=\\Vert x\\Vert_{\\infty}+\\sum\\vert\\underbrace{\\text{toutes les valeurs qui ne sont pas le max}}_{\\ge 0}\\vert\\\\\\Vert x\\Vert_{\\infty}\\le \\Vert x\\Vert_1\\le n\\Vert x\\Vert_{\\infty}\\\\\\begin{aligned}\\Vert x\\Vert_2\\le\\Vert x\\Vert_1\\quad \\Vert x\\Vert_2^2&amp;amp;=\\sum_{i=1}^nx_i^2=\\sum_{i=1}^n\\vert x_i\\vert^2\\\\\\Vert x\\Vert_1^2&amp;amp;=(\\sum_{i=1}^n\\vert x_i\\vert)^2= \\sum_{i=1}^n\\vert x_i\\vert^2 + 2\\sum_{1\\le i\\le j\\le n}\\vert x_i\\vert \\vert x_j\\vert\\end{aligned}\\\\\\begin{aligned}\\Vert x\\Vert_{\\infty}&amp;amp;=\\max_i\\vert x_i\\vert=\\vert x_{\\underbrace{j}_{\\text{index ou le max est atteint}}}\\vert\\\\&amp;amp;= \\sqrt{x_j^2}\\\\\\Vert x\\Vert_2 &amp;amp;= \\sqrt{\\sum_{i=1}^nx_i^2}\\\\&amp;amp;=\\sqrt{x_j^2+\\underbrace{\\sum_{i\\neq j}x_i^2}_{\\ge0}}\\\\&amp;amp;\\ge\\sqrt{x_j^2}\\\\&amp;amp;\\ge\\vert x_j\\vert\\\\&amp;amp;\\ge\\Vert x\\Vert_{\\infty}\\end{aligned}\\]\\[\\Vert x\\Vert_{\\infty}\\le\\Vert x\\Vert_2\\le\\Vert x\\Vert_1\\le n\\Vert x\\Vert_{\\infty}\\]" }, { "title": "DBRE: Regime de droit", "url": "/cours/posts/dbre_regime_droits/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-31 12:00:00 +0200", "snippet": "Lien de la note HackmdPartielPoints positifs et negatifs Bonne reponse: $100\\%$ des points Mauvaise reponse: $-0,1$pt a $-0,75$pt En fonction de lâ€™incomprehension de la question Regime du droit RÃ©gime du droit des contrats date de 1804ordonnance du 10 fÃ©vrier 2016 Article 1101ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Le contrat est un accord de volontÃ©s entre deux ou plusieurs personnes destinÃ© Ã  crÃ©er, modifier, transmettre ou Ã©teindre des obligations. Le contrat est la Loi des parties au contrat Article 1103ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats lÃ©galement formÃ©s tiennent lieu de loi Ã  ceux qui les ont faits. Force obligatoire du contrat peut saisir le juge pour faire rectifierLa libertÃ© contractuelle ne permet pas de dÃ©roger aux rÃ¨gles qui intÃ©ressent lâ€™ordre public. (Article 1102) Article 1104ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats doivent Ãªtre nÃ©gociÃ©s, formÃ©s et exÃ©cutÃ©s de bonne foi. Cette disposition est dâ€™ordre public. Article 1105ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Les contrats, quâ€™ils aient ou non une dÃ©nomination propre, sont soumis Ã  des rÃ¨gles gÃ©nÃ©rales, qui sont lâ€™objet du prÃ©sent sous-titre. Les rÃ¨gles particuliÃ¨res Ã  certains contrats sont Ã©tablies dans les dispositions propres Ã  chacun dâ€™eux. Les rÃ¨gles gÃ©nÃ©rales sâ€™appliquent sous rÃ©serve de ces rÃ¨gles particuliÃ¨res. Les contrats, quâ€™ils aient ou non une dÃ©nomination propre, sont soumis Ã  des rÃ¨gles gÃ©nÃ©rales, qui sont lâ€™objet du prÃ©sent sous-titre.Est-ce quâ€™un mariage est une forme de contrat ?Câ€™est plus une instution quâ€™un contrat Pour quâ€™un contrat soit valable, il faut quâ€™il soit valablement forme.Est-ce que le contrat est valablement forme ? Article 1128ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Sont nÃ©cessaires Ã  la validitÃ© dâ€™un contrat : 1Â° Le consentement des parties ; 2Â° Leur capacitÃ© de contracter ; 3Â° Un contenu licite et certain.Si un contrat nâ€™est pas valablement forme, il peut etre conteste. Un qui a pris lâ€™ascendant sur lâ€™autre Un qui a trompe lâ€™autre etc.Consentement des partiesCe consentement doit Ãªtre juridiquement intact, câ€™est Ã  dire ne pas Ãªtre viciÃ© Quelque chose qui altere le consentement Article 1130ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur, le dol et la violence vicient le consentement lorsquâ€™ils sont de telle nature que, sans eux, lâ€™une des parties nâ€™aurait pas contractÃ© ou aurait contractÃ© Ã  des conditions substantiellement diffÃ©rentes. Leur caractÃ¨re dÃ©terminant sâ€™apprÃ©cie eu Ã©gard aux personnes et aux circonstances dans lesquelles le consentement a Ã©tÃ© donnÃ©. Article 1132ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur de droit ou de fait, Ã  moins quâ€™elle ne soit inexcusable, est une cause de nullitÃ© du contrat lorsquâ€™elle porte sur les qualitÃ©s essentielles de la prestation due ou sur celles du cocontractant. Article 1136ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Lâ€™erreur sur la valeur par laquelle, sans se tromper sur les qualitÃ©s essentielles de la prestation, un contractant fait seulement de celle-ci une apprÃ©ciation Ã©conomique inexacte, nâ€™est pas une cause de nullitÃ©. Article 1137ModifiÃ© par LOI nÂ°2018-287 du 20 avril 2018 - art. 5 Le dol est le fait pour un contractant dâ€™obtenir le consentement de lâ€™autre par des manÅ“uvres ou des mensonges. Constitue Ã©galement un dol la dissimulation intentionnelle par lâ€™un des contractants dâ€™une information dont il sait le caractÃ¨re dÃ©terminant pour lâ€™autre partie. NÃ©anmoins, ne constitue pas un dol le fait pour une partie de ne pas rÃ©vÃ©ler Ã  son cocontractant son estimation de la valeur de la prestation. Article 1145ModifiÃ© par LOI nÂ°2018-287 du 20 avril 2018 - art. 6 Toute personne physique peut contracter sauf en cas dâ€™incapacitÃ© prÃ©vue par la loi. La capacitÃ© des personnes morales est limitÃ©e par les rÃ¨gles applicables Ã  chacune dâ€™entre elles. Article 1146ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Sont incapables de contracter, dans la mesure dÃ©finie par la loi : 1Â° Les mineurs non Ã©mancipÃ©s ; 2Â° Les majeurs protÃ©gÃ©s au sens de lâ€™article 425. Article 1148ModifiÃ© par Ordonnance nÂ°2016-131 du 10 fÃ©vrier 2016 - art. 2 Toute personne incapable de contracter peut nÃ©anmoins accomplir seule les actes courants autorisÃ©s par la loi ou lâ€™usage, pourvu quâ€™ils soient conclus Ã  des conditions normales. Les incapacitÃ©s protÃ¨gent lâ€™incapable Article 425ModifiÃ© par Loi nÂ°2007-308 du 5 mars 2007 - art. 7 () JORF 7 mars 2007 en vigueur le 1er janvier 2009 Toute personne dans lâ€™impossibilitÃ© de pourvoir seule Ã  ses intÃ©rÃªts en raison dâ€™une altÃ©ration, mÃ©dicalement constatÃ©e, soit de ses facultÃ©s mentales, soit de ses facultÃ©s corporelles de nature Ã  empÃªcher lâ€™expression de sa volontÃ© peut bÃ©nÃ©ficier dâ€™une mesure de protection juridique prÃ©vue au prÃ©sent chapitre. Sâ€™il nâ€™en est disposÃ© autrement, la mesure est destinÃ©e Ã  la protection tant de la personne que des intÃ©rÃªts patrimoniaux de celle-ci. Elle peut toutefois Ãªtre limitÃ©e expressÃ©ment Ã  lâ€™une de ces deux missions. Utiliser un preambule pour definir clairement ce quâ€™on veut faire Description de lâ€™oeuvre et de ce que lâ€™on entend faire en des termes â€œnormauxâ€ Obligation dâ€™un Ã©crit Attention Ã©crit obligatoire pour la preuve et pas pour la validitÃ©Chaque droit cÃ©dÃ© doit faire lâ€™objet dâ€™une mention, ce qui nâ€™est pas mentionnÃ© est sensÃ© Ãªtre conservÃ© par lâ€™auteur.On doit prÃ©ciser Ã©tendue gÃ©ographique, la durÃ©e, lâ€™excluivitÃ©, â€¦," }, { "title": "ASE2: TD 4", "url": "/cours/posts/ase2_td4/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, estimateur, Fisher, FDCR, maximum de vraisemblance", "date": "2021-03-31 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 16Soit une variable aleatoire $X$ de loi de Poisson de parametre $\\lambda$ ($\\lambda\\gt0$). Le but de cet exercice est de trouver une estimation de $\\theta=e^{-\\lambda}$.$(X_1,X_2,â€¦,X_n)$ un echantillon de $X$ et $Y_1,Y_2,â€¦,Y_n$ des v.a. definies par $Y_i=1$ si $X_i=0$ et $Y_i=0$ sinon, $\\forall i \\in[[1,n]]$.\\[S_n=\\sum_{i=1}^nX_i\\\\\\bar Y_n=\\frac{1}{n}\\sum_{i=1}^nY_i\\\\T_n=\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\] Montrer que $\\bar Y_n$ est un estimateur sans biais et convergent de $\\theta=e^{-\\lambda}$ Montrer que $T_n$ est un estimateur sans biais et convergent de $\\theta$ a) Etuder le sens de variation de $f$ definie sur $\\mathbb R_+$ par $f(t)=ne^{\\frac{t}{n}}-e^{t}-n+1$ et deduire son signe b) En deduire que $T_n$ est un estimateur de $\\bar Y_n$ Solution 1. $Y_i$ suit la loi de Bernoulli, le parametre de $Y_i$ est $P(Y_i=1)=P(X_i=0)=e^{-\\lambda}=\\theta$ donc $Y_i\\sim\\mathcal B(0)$\\[E(\\bar Y_n)=\\frac{1}{n}\\sum_{i=1}^nE(Y_i)=\\frac{1}{n}\\sum_{i=1}^n\\theta=\\frac{n\\theta}{n}=\\theta\\] $\\bar Y_n$ est sans biais.\\[V(\\bar Y_n)=\\frac{1}{n^2}\\sum_{i=1}^nV(Y_i)=\\frac{n\\theta(1-\\theta)}{n^2}=\\frac{\\theta(1-\\theta)}{n}\\to_{n\\to+\\infty}0\\\\V(\\bar Y_n)\\to_{n\\to+\\infty}0\\] En appliquant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert\\bar Y_n-E(\\bar Y_n)\\vert\\ge\\varepsilon)\\le\\frac{V(\\bar Y_n)}{\\varepsilon^2}=\\frac{\\theta(1-\\theta)}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\] Donc $\\bar Y_n\\to_{n\\to+\\infty}^P\\theta$ 2.\\[T_n=\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\\\\\begin{aligned}E(T_n) &amp;amp;= E\\biggr(\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\biggr)\\\\&amp;amp;=\\sum_{k=0}^{+\\infty}\\biggr(\\frac{n-1}{n}\\biggr)^kP(S_n=k) \\text{ (car } E(\\phi(X))=\\sum_k\\phi(k)P(X=k))\\\\&amp;amp;=\\sum_{k=0}^{+\\infty}\\biggr(\\frac{n-1}{n}\\biggr)^ke^{-n\\lambda}\\frac{(n\\lambda)^k}{k!} \\text{ (car } S_n=\\sum_{i=1}^nX_i\\text{ somme independantes de Poisson }\\mathcal P(\\lambda))\\end{aligned}\\] Donc $S_n\\sim\\mathcal P(n\\lambda)$\\[\\begin{aligned}E(T_n)&amp;amp;=e^{-n\\lambda}\\sum_{k=0}^{+\\infty}\\frac{((n-1)\\lambda)^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}e^{(n-1)\\lambda}\\\\&amp;amp;=e^{-\\lambda}=\\theta\\end{aligned}\\] Rappel:\\[\\sum_{0}^{+\\infty}\\frac{x^k}{k!}=e^x\\] $T_n$ est sans biais\\[\\begin{aligned}E(T_n^2)&amp;amp;=E((\\frac{n-1}{n})^{2S_n})\\\\&amp;amp;= \\sum_0^{+\\infty}(\\frac{n-1}{n})^{2k}P(S_n=k)\\\\&amp;amp;= \\sum_0^{+\\infty}(\\frac{n-1}{n})^{2k}e^{-n\\lambda}\\frac{(n\\lambda)^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}\\sum_{k=0}^{+\\infty}\\frac{(\\frac{(n-1)^2\\lambda}{n})^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}e^{(n-1)^2\\frac{\\lambda}{n}}\\\\&amp;amp;= e^{-n\\lambda}e^{(n^2-2n+1)\\frac{\\lambda}{n}}\\\\&amp;amp;= e^{-2\\lambda+\\frac{\\lambda}{n}}=\\theta^2e^{\\frac{\\lambda}{n}}\\end{aligned}\\] Donc\\[E(T_n^2)=\\theta^2e^{\\frac{\\lambda}{n}}\\] \\[\\begin{aligned}V(T_n)&amp;amp;=E(T_n^2)-E^2(T_n)\\\\&amp;amp;= \\theta^2e^{\\frac{\\lambda}{n}}-\\theta^2\\\\&amp;amp;=\\theta^2(e^{\\frac{\\lambda}{n}}-1)\\end{aligned}\\\\\\lim_{n\\to+\\infty}V(T_n)=0\\] En utilisant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-\\theta\\vert\\ge\\varepsilon)\\lt\\frac{V(\\bar Y_n)}{\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\Rightarrow T_n\\to_{n\\to+\\infty}^P\\theta\\] 3.a)\\[f(t)=ne^{\\frac{t}{n}}-e^t-n+1\\quad\\forall t\\in\\mathbb R_+\\\\f&#39;(t)=e^{\\frac{t}{n}}-e^t\\\\\\begin{cases}\\forall n\\ge1\\quad \\frac{t}{n}\\le t\\Rightarrow e^{\\frac{t}{n}}\\le e^t\\Rightarrow f&#39;(t)\\le0 &amp;amp;\\forall t\\in\\mathbb R_+\\\\\\forall t\\gt0\\quad f(t)\\text{ est decroissante et comme } f(0)=0&amp;amp;\\begin{aligned}&amp;amp;\\Rightarrow \\forall t\\ge0, f(t)\\le f(0)=0\\\\&amp;amp;\\Rightarrow\\color{green}{f(t)\\le0\\quad\\forall t\\ge0}\\end{aligned}\\end{cases}\\] b)\\[E(T_n)=\\theta\\\\E(\\bar Y_n)=\\theta\\] Les deux estimateurs sont sans biais. Comparons leurs variances\\[V(\\bar Y_n)=\\frac{\\theta(1-\\theta)}{n}, V(T_n)=\\theta^2(e^{\\frac{\\lambda}{n}}-1)\\\\\\begin{aligned}V(T_n)-V(\\bar Y_n)&amp;amp;=\\theta^2(e^{\\frac{\\lambda}{n}}-1)-\\frac{\\theta(1-\\theta)}{n}\\\\&amp;amp;= \\frac{\\theta^2}{n}(ne^{\\frac{\\lambda}{n}}-n-\\frac{1}{\\theta}+1)\\\\&amp;amp;= \\frac{\\theta^2}{n}(ne^{\\frac{\\lambda}{n}}-n-e^{\\lambda}+1)\\\\&amp;amp;= \\frac{\\theta^2}{n}f(\\lambda)\\\\\\text{Or } f \\text{ est negative}&amp;amp;\\Rightarrow V(T_n)-V(\\bar Y_n)\\le 0\\\\&amp;amp;\\Rightarrow\\color{green}{V(T_n)\\le V(\\bar Y_n)}\\end{aligned}\\] $T_n$ est un meilleur estimateur que $\\bar Y_n$ Exercice 17Soit $X$ une v.a. de loi $\\mathcal B(n,p)$ ou $p$ est inconnu..On veut estimer le parametre $p$.On considere un echantillon de $X$: $(X_1,X_2,â€¦,X_n)$. Determiner la vraisemblance de lâ€™echantillon Determiner lâ€™estimateur de maximum de vraisemblance de $p$ Cet estimateur est-il sans biais ? Est-il convergent ? Montrer que cet estimateur est efficace Solution $X\\sim\\mathcal B(N,p)$, $\\theta=p$ inconnu. 1.\\[L(x_1,x_2,...,x_n,p)=\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}p^{\\sum_{i=1}^nx_i}(1-p)^{nN-\\sum_{i=1}^nx_i}\\] dâ€™apres lâ€™exercice 14. 2. Lâ€™equation de la vraisemblance:\\[\\frac{\\delta \\ln L}{\\delta p}=0\\\\\\ln L(x_1,...,x_n,p)=\\ln\\biggr(\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}\\biggr)+\\sum_{i=1}^nx_i\\ln(p)+(nN-\\sum_{i=1}^nx_i)\\ln(1-p)\\\\\\begin{aligned}\\frac{\\delta \\ln L}{\\delta p}&amp;amp;=\\frac{1}{p}\\sum_{i=1}^nx_i+(nN-\\sum_{i=1}^nx_i)\\frac{-1}{1-p}=0\\\\&amp;amp;\\Leftrightarrow (1-p)\\sum_{i=1}^nx_i-p(nN-\\sum_{i=1}^nx_i)=0\\\\&amp;amp;\\Leftrightarrow \\sum_{i=1}^nx_i-pnN=0\\\\&amp;amp;\\Leftrightarrow \\color{green}{\\hat p=\\frac{1}{nN}\\sum_{i=1}^nx_i} \\text{ estimation ponctuelle de }p\\end{aligned}\\] Lâ€™estimateur de maximum de vraisemblance est\\[T_n=\\frac{1}{nN}\\sum_{i=1}^nX_i\\] 3. $Tn$ sans biais ?\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{nN}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;=\\frac{1}{nN}\\sum_{i=1}^nNp\\\\&amp;amp;= \\frac{nNp}{nN}=\\color{green}{p}\\end{aligned}\\] \\[E(T_n) = p\\] $T_n$ est sans biais. 4. Convergence ? Rappel:\\[V(aX) = a^2\\times V(X)\\] \\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2N^2}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{1}{n^2N^2}\\sum_{i=1}^nNp(1-p)\\\\&amp;amp;= \\frac{nNp(1-p)}{n^2N^2}\\\\&amp;amp;=\\frac{p(1-p)}{nN}\\to_{n\\to+\\infty}0\\end{aligned}\\] Dâ€™apres Tchebychev $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-E(T_n)\\vert\\ge\\varepsilon)\\le\\frac{V(T_n)}{\\varepsilon^2}\\\\\\Rightarrow P(\\vert T_n-p\\vert\\ge\\varepsilon)\\le\\frac{p(1-p)}{nN\\varepsilon^2}\\to_{n\\to+\\infty}0\\] Donc\\[T_n\\to_{n\\to+\\infty}^Pp\\] $T_n$ converge en probabilite vers $p$. 5. Efficacite\\[\\underbrace{I_n(p)}_{\\text{information de Fisher}}=-E(\\frac{\\delta^2\\ln L}{\\delta p^2})\\\\\\frac{\\delta\\ln L}{\\delta p}=\\frac{1}{p}\\sum_{i=1}^nx_i-(nN-\\sum_{i=1}^nx_i)\\frac{1}{1-p}\\\\\\frac{\\delta^2\\ln L}{\\delta p^2}=-\\frac{1}{p^2}\\sum_{i=1}^nx_i+(nN-\\sum_{i=1}^nx_i)\\frac{-1}{(1-p)^2}\\\\\\begin{aligned}E(\\frac{\\delta\\ln L}{\\delta p^2}) &amp;amp;=-\\frac{1}{p^2}\\sum_{i=1}^nE(x_i)+(nN-\\sum_{i=1}^nE(x_i))\\frac{-1}{(1-p)^2}\\\\&amp;amp;=-\\frac{1}{p^2}nNp+\\frac{1}{(1-p)^2}(-nN+nNp)\\\\&amp;amp;= \\frac{-nN}{p}+\\frac{(-nN)}{1-p}\\\\&amp;amp;= \\frac{-nN(1-p)-nNp}{p(1-p)}\\\\&amp;amp;= \\frac{-nN}{p(1-p)}\\end{aligned}\\\\I_n(p) = -E(\\frac{\\delta\\ln L}{\\delta p^2})=\\frac{nN}{p(1-p)}\\] Donc \\(I_n(p)=\\frac{nN}{p(1-p)}\\) information de Fisher. Or:\\[V(T_n)=\\frac{p(1-p)}{nN}\\Rightarrow \\color{green}{V(T_n)=\\frac{1}{I_n(p)}}\\] Conclusion: $T_n$ est efficaceExercice 18Soit $X$ une distribution de Poisson $\\mathcal P(\\theta)$ ou $\\theta$ inconnu.$(X_1,â€¦,X_n)$ un echantillon de $X$. Determiner la vraisemblance Determiner un estimateur de $\\theta$ Est-il sans biais ? Convergent ? Est-il efficace ? Solution $X\\sim\\mathcal P(\\theta)$ Poisson de parametre $\\theta$, $\\theta$: inconnu. 1.La vraisemblance est:\\[\\begin{aligned}L(x_1,x_2,...,x_n)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!} \\text{cf. exercice 14.}\\end{aligned}\\] 2.Methode du maximum de vraisemblance\\[\\frac{\\delta\\ln L}{\\delta\\theta}=0 \\text{ (eq. de la vraisemblance)}\\\\\\ln L(x_1,...,x_m,\\theta)=-n\\theta+\\sum_{i=1}^n\\ln \\theta-\\ln(\\Pi_{i=1}^nx_i!)\\\\\\begin{aligned}\\frac{\\delta\\ln L}{\\delta\\theta}=0&amp;amp;\\Leftrightarrow -n+\\frac{1}{\\theta}\\sum_{i=1}^nx_i=0\\\\&amp;amp;\\Leftrightarrow\\hat \\theta=\\frac{1}{n}\\sum_{i=1}^nx_i\\text{ estimation ponctulle de }\\theta\\end{aligned}\\] Lâ€™estimateur de $\\theta$ est $T_n=\\frac{1}{n}\\sum_{i=1}^nX_i$ 3.$Tn$ sans biais ?\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n\\theta\\\\&amp;amp;= \\frac{n\\theta}{n}=\\color{green}{\\theta}\\end{aligned}\\] \\[E(T_n)=\\theta\\] $T_n$ est sans biais. Convergence?\\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{n\\theta}{n}\\\\&amp;amp;=\\frac{\\theta}{n}\\end{aligned}\\\\V(T_n)=\\frac{\\theta}{n}\\to_{n\\to+\\infty}0\\] Donc en utilisant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-E(T_n)\\vert\\ge\\varepsilon)\\le\\frac{V(T_n)}{\\varepsilon^2}\\\\\\Rightarrow P(\\vert T_n-\\theta\\vert\\ge\\varepsilon)\\le\\frac{\\theta}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\] Donc\\[T_n\\to_{n\\to+\\infty}^P\\theta\\] 4.Efficacite On calcule lâ€™information de Fisher:\\[I_n(\\theta)=-t(\\frac{\\delta^2\\ln L}{\\delta \\theta^2})\\\\\\frac{\\delta \\ln L}{\\delta\\theta}=-n+\\frac{1}{\\theta}\\sum_{i=1}^nx_i\\\\\\begin{aligned}I_n(\\theta)&amp;amp;=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\&amp;amp;=\\frac{1}{\\theta^2}\\sum_{i=1}^nE(x_i)\\\\&amp;amp;=\\frac{n\\theta}{\\theta^2}=\\color{green}{\\frac{n}{\\theta}}\\end{aligned}\\] \\[V(T_n)=\\frac{\\theta}{n}=\\frac{1}{I_n(\\theta)}\\] $T_n$ est efficace. Exercice 19Soit $X$ une v.a. continue de densite\\[f(x)=\\frac{A}{x^{1+\\frac{1}{\\theta}}}\\quad \\forall x\\ge 1, \\theta\\gt0\\] Determiner $A$ en fonction de $\\theta$ Soit $(X_1,X_2,â€¦,X_n)$ un echantillon de $X$, Determiner la vraisemblance de cet echantillon Determiner lâ€™estimateur du maximum de vraisemblance de $\\theta$ Est-il sans biais ? Convergent ? Est-il efficace ? Solution 1.$f$ etant une densite: $\\int_{\\mathbb R}f(x)dx=1$\\[A\\int_{1}^{+\\infty}\\frac{1}{x^{1+\\frac{1}{\\theta}}}dx=1\\\\A\\biggr[\\frac{-\\theta}{x^{\\frac{1}{\\theta}}}\\biggr]\\\\\\Rightarrow A\\theta=1\\Rightarrow\\color{green}{A=\\frac{1}{\\theta}}\\] 2.\\[\\begin{aligned}L(x_1,x_2,...,x_n,\\theta)&amp;amp;=\\Pi_{i=1}^nf(x_i)\\\\&amp;amp;=\\Pi_{i=1}^n\\frac{1}{\\theta}\\frac{1}{x_i^{1+\\frac{1}{\\theta}}}\\\\&amp;amp;=\\frac{1}{\\theta^n}\\frac{1}{\\Pi_{i=1}^nx_i^{1+\\frac{1}{\\theta}}}\\end{aligned}\\] 3.\\[\\ln L(x_1,x_2,...,x_n,\\theta)=-n\\ln\\theta-(1+\\frac{1}{\\theta})\\sum_{i=1}^n\\ln x_i\\] Equation de la vraisemblance:\\[\\frac{\\delta\\ln L}{\\delta\\theta}=0\\] \\[\\begin{aligned}\\frac{\\delta\\ln L}{\\delta\\theta}&amp;amp;=\\frac{-n}{\\theta}+\\frac{1}{\\theta^2}\\sum_{i=1}^n\\ln x_i=0\\\\&amp;amp;\\Rightarrow\\color{green}{\\hat\\theta=\\frac{1}{n}\\sum_{i=1}^n\\ln x_i}\\end{aligned}\\] Lâ€™estimateur de vraisemblance:\\[T_n=\\frac{1}{n}\\sum_{i=1}^n\\ln x_i\\] 4.\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(\\ln x_i)\\\\&amp;amp;=\\frac{nE(\\ln x)}{n}\\\\&amp;amp;=E(\\ln x)\\end{aligned}\\] or:\\[\\begin{aligned}E(\\ln x)&amp;amp;=\\int_{1}^{+\\infty}\\ln xf(x)dx\\\\&amp;amp;=\\int_{1}^{+\\infty}\\frac{\\ln x}{\\theta ^{1+\\frac{1}{\\theta}}}dx\\end{aligned}\\] On integre par parties:\\[\\begin{cases}v=\\ln x &amp;amp;v&#39;=\\frac{1}{x}\\\\u&#39;=\\frac{1}{\\theta}x^{-1-\\frac{1}{\\theta}} &amp;amp;u=-x^{-\\frac{1}{\\theta}}\\end{cases}\\\\\\begin{aligned}E(\\ln x)&amp;amp;=\\underbrace{[-x^{-\\frac{1}{\\theta}}\\ln x]_1^{+\\infty}}_{=0 \\text{ quand }x\\to+\\infty}+\\int_1^{+\\infty}x^{-1-\\frac{1}{\\theta}}dx\\\\&amp;amp;=[-\\theta x^{-\\frac{1}{\\theta}}]_1^{+\\infty}=\\theta\\end{aligned}\\] Donc $E(T_n)=\\theta$ sans biais. Convergence ?\\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2}\\sum_{i=1}^nV(\\ln x_i)\\\\&amp;amp;= \\frac{nV(\\ln X)}{n^2}\\\\&amp;amp;=\\frac{V(\\ln X)}{n}\\end{aligned}\\\\\\begin{aligned}E(\\ln^2x)&amp;amp;=\\int_1^{+\\infty}\\frac{\\ln^2x}{\\theta x^{1+\\frac{1}{\\theta}}}dx\\\\&amp;amp;=\\underbrace{[-x^{-\\frac{1}{\\theta}}\\ln^2x]_1^{+\\infty}}_{=0 \\text{ quand }x\\to+\\infty}+\\int_1^{+\\infty}\\frac{1\\ln x}{x^{1+\\frac{1}{\\theta}}}dx\\end{aligned}\\\\\\begin{cases}v=\\ln^2x &amp;amp;v&#39;=2(\\ln x)\\frac{1}{x}\\\\u&#39;=\\frac{1}{\\theta}x^{-1-\\frac{1}{\\theta}}, &amp;amp;u=-x^{-\\frac{1}{\\theta}}\\end{cases}\\\\\\begin{aligned}E(\\ln^2x)&amp;amp;=1\\theta\\int_1^{+\\infty}\\frac{\\ln xdx}{\\theta x^{1+\\frac{1}{\\theta}}}\\\\&amp;amp;=2\\theta E(\\ln x)\\\\&amp;amp;=2\\theta^2\\end{aligned}\\\\\\begin{aligned}V(T_n)&amp;amp;=\\frac{E(\\ln^2x)-E^2(\\ln x)}{n}\\\\&amp;amp;=\\frac{1}{n}(2\\theta^2-\\theta^2)\\\\&amp;amp;=\\frac{\\theta^2}{n}\\end{aligned}\\\\V(T_n)=\\frac{\\theta^2}{n}\\to_{n\\to+\\infty}0\\] Dâ€™apres Tchebychev $T_n\\to_{n\\to+\\infty}^P\\theta$ 5.Efficacite\\[I_n(\\theta)=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\\\frac{\\delta\\ln L}{\\delta\\theta}=-\\frac{n}{\\theta}+\\frac{1}{\\theta^2}\\sum_{i=1}^n\\ln x-i\\\\\\frac{\\delta^2\\ln L}{\\delta\\theta^2}=\\frac{n}{\\theta^2}-\\frac{2}{\\theta^3}\\sum_{i=1}^n\\ln x_i\\\\\\begin{aligned}I_n(\\theta)&amp;amp;=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\&amp;amp;=-\\frac{n}{\\theta}+\\frac{2}{\\theta^3}\\sum_{i=1}^nE(\\ln x_i)\\\\&amp;amp;=-\\frac{n}{\\theta^2}+\\frac{2}{\\theta^3}nE(\\ln x)\\\\&amp;amp;=-\\frac{n}{\\theta^2}+\\frac{2}{\\theta^3}n\\theta=\\color{green}{\\frac{n}{\\theta^2}}\\end{aligned}\\] Or $V(T_n)=\\frac{\\theta^2}{n}=\\frac{1}{I_n(\\theta)}$ Donc $T_n$ est efficace. " }, { "title": "PRST: Feuille de revisions", "url": "/cours/posts/prst_feuille_revisions/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-29 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Question 10 Cet exercice est aussi present sur la feuille pour le 17/03/2021La loi du demi-cercle de Wigner de parametre $R$ a une densite nulle en dehors de $] âˆ’ R; R[$. Sur $] âˆ’ R; R[$, sa densite est donnee par\\[f(x)=\\frac{2}{\\pi R^2}\\sqrt{R^2-x^2}\\]Nous admettrons que sa variance est donnee par $\\frac{R^2}{4}$.En deduire un estimateur du parametre $R$ par la methode des moments. Solution\\[V(X)=\\frac{R^2}{4}\\\\\\Leftrightarrow R^2=4V(X)\\\\\\Leftrightarrow R=2\\sqrt{V(X)}\\] Donc:\\[\\hat R=2\\sqrt{S^2}\\] \\[S=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X)^2\\] On sait que $E(X)=0$ (symetrie). En effet, $E(X)=\\int_{-R}^Rx\\times\\frac{2}{\\pi R^2}\\sqrt{R^2-x^2}dx=0$. La fonction devient impaire car $\\times x$. On integre une fonction impaire sur lâ€™intervalle $] âˆ’ R; R[$. $V(X)=E(X^2)$ donc $E(X^2)=\\frac{R^2}{4}$\\[R=2\\sqrt{E(X)}\\Rightarrow\\hat R=2\\sqrt{\\frac{1}{n}\\sum_{i=1}^nx_i^2}\\]Question 11Soient $X$ et $Y$ deux variables aleatoires independantes et suivant toutes deux une loi normale centree reduite.Considerons les variables aleatoires $U = X + 2Y$ et $V = X âˆ’ 3Y$ Montrer que le vecteur aleatoire $(U, V )^T$ est un vecteur gaussien. Les variables aleatoires U et V sont-elles independantes ? Solution 1. $X$ et $Y$ sont independants $\\Rightarrow(X,Y)^T$ vecteur gaussien\\[\\begin{pmatrix}U\\\\V\\end{pmatrix}=\\begin{pmatrix}1 &amp;amp; 2\\\\1&amp;amp;-3\\end{pmatrix}\\] $(U,V)^T$ gaussien comme image dâ€™un vecteur gaussien comme application lineaire 2. On calcule la covariance et $Cov(U,V)=0$ \\[\\begin{aligned}Cov(X)&amp;amp;=E(UV)-\\underbrace{E(U)E(V)}_{=0}\\\\&amp;amp;= E((X+2Y)(X-3Y))\\\\&amp;amp;= E(X^2-3XY+2XY-6Y^2)\\\\&amp;amp;= E(X^2)+\\underbrace{E(XY)}_{=0}-6E(Y^2)\\\\&amp;amp;= E(X^2)-6E(Y^2)\\text{ car } V(X)=E(X^2)=1\\\\&amp;amp;=1-6=\\color{green}{5}\\end{aligned}\\] Donc elles ne sont pas independantes. Exercice 5La variable aleatoire $X$ suit une loi uniforme sur $[0;\\theta]$ avec $\\theta$ inconnu.Sa densite est par definition donnee par $f(x,\\theta)=\\frac{1}{\\theta}ğŸ™_{[0;\\theta]}(x)$ i.e. $f(x,\\theta)=1$ si $0\\le x\\le\\theta$ sinon 0. Montrer que sa densite peut etre ecrite $f(x,\\theta)=\\frac{1}{\\theta}ğŸ™_{[0;1]}(\\frac{x}{\\theta})$ En deduire que la fonction de vraisemblance definie sur $[0;+\\infty[\\times]0;+\\infty[$ sâ€™ecrit:\\(L(x_1,...,x_n,\\theta)=\\begin{cases}\\frac{1}{\\theta^n}&amp;amp;\\text{si} \\max x_i\\le\\theta \\\\ 0&amp;amp;\\text{sinon}\\end{cases}\\) ou encore \\(L(x_1,...,x_n,\\theta)=\\frac{1}{\\theta^n}ğŸ™_{[\\max 1\\le i\\le n;+\\infty]}(\\theta)\\) En deduire lâ€™estimateur du maximum de vraisemblance du parametre $\\theta$ Quelle loi suit la v.a. $\\frac{X_1}{\\theta}$ On pose \\(T=\\max_{1\\le i\\le n}\\frac{X_i}{\\theta}\\). Determiner sa fonction de repartition $F_T$ Montrer que $\\mathbb P(\\alpha\\le T\\le1)=1-\\alpha^n$ En deduire un reel $\\alpha$ tel que $\\mathbb P(T\\in[\\alpha;1])=0,95$ Considerons des observations $x_1,â€¦,x_n$. Notons \\(M=\\max_{1\\le i\\le n}x_i\\). Deduire des questions precedentes un intervalle de confiance pour le parametre $\\theta$ de niveau de confiance 0, 95. Solution 1.\\[\\begin{aligned}x\\in[0;\\theta]&amp;amp;\\Leftrightarrow0\\le x\\le\\theta\\\\&amp;amp;\\Leftrightarrow0\\le\\frac{x}{\\theta}\\le1\\\\&amp;amp;\\Leftrightarrow \\frac{x}{\\theta}\\in[0;1]\\end{aligned}\\] Donc \\(ğŸ™_{[0;\\theta]}(x)=ğŸ™_{[0;1]}(\\frac{x}{\\theta})\\) 2.\\[\\begin{aligned}L(x_1,...,x_n,\\theta)&amp;amp;=\\Pi_{i=1}^nf(x_i,\\theta)\\\\&amp;amp;= \\Pi_{i=1}^n\\frac{1}{\\theta}ğŸ™_{[0;\\theta]}(x_i)\\\\&amp;amp;= \\frac{1}{\\theta^n}\\Pi_{i=1}^nğŸ™_{[0;\\theta]}(x_i)\\end{aligned}\\] Pour que ce ne soit pas egale a $0$, $x_i\\in[0;\\theta]$\\[\\begin{aligned}L(x_1,...,x_n,\\theta)&amp;amp;=\\frac{1}{\\theta^n}ğŸ™_{[0;\\theta]}(\\max(x_i))\\\\&amp;amp;= \\frac{1}{\\theta^n}ğŸ™_{[\\max x_i;+\\infty]}(\\theta)\\end{aligned}\\] 3. EMV: $\\hat\\theta=\\max_{1\\le i\\le n}(x_i)$ 4. Loi uniforme sur $[0;1]$\\[F_{\\frac{X}{\\theta}}(x)=P(\\frac{X}{\\theta}\\le x)=P(X\\le\\theta x)\\\\\\color{red}{X\\sim U([0;\\theta])}=\\begin{cases}0 &amp;amp;\\text{si } x\\le0\\\\\\int_0^{\\theta x}\\frac{1}{\\theta}dt=x &amp;amp;\\text{si } \\theta x\\in[0;\\theta]\\color{red}{\\Leftrightarrow x\\in[0;1]}\\\\1 &amp;amp;\\text{si } \\color{red}{\\theta x\\lt\\theta\\text{, i.e. } x\\gt1}\\end{cases}\\\\=F_U(x) \\text{ avec } U=\\frac{X}{\\theta}\\sim U([0;1])\\] 5.\\[\\begin{aligned}F_T(x)&amp;amp;=P(\\max\\frac{X_i}{\\theta}\\le x)\\\\&amp;amp;= P(\\cap_{i=1}^n\\{X_i\\le x\\})=\\Pi_{i=1}^nP(\\frac{X_i}{\\theta}\\le n) \\text{ car les v.a. } x_i \\text{ sont independantes}\\\\&amp;amp;= P(\\frac{X}{\\theta}\\le x)^n\\text{ car les }\\frac{x_i}{\\theta}\\text{ ont les memes lois}\\end{aligned}\\\\F_T(x)=\\begin{cases}0 &amp;amp;x\\lt0\\\\x^n &amp;amp;x\\in[0;1]\\\\1 &amp;amp;x\\gt1\\end{cases}\\] 7. Resolution dâ€™equation:\\[\\begin{aligned}1-\\alpha^n&amp;amp;=0,95\\\\\\alpha^n&amp;amp;=0,05\\\\\\alpha&amp;amp;=\\sqrt[n]{0,05}\\end{aligned}\\\\\\] 8. $T=\\max\\frac{x_i}{\\theta}$, $M=\\max x_i$, donc $T=\\frac{M}{\\theta}$ (car $\\theta\\gt0$)\\[P(\\sqrt[n]{0,05}\\le T\\le1)=095\\Rightarrow P(\\sqrt[n]{0,05}\\le\\frac{M}{\\theta}\\le 1)=0,95\\\\P(1\\le\\frac{\\theta}{M}\\le(0,05)^{-\\frac{1}{n}})=0,95\\Leftrightarrow P(M\\le\\theta\\le M(0,05)^{-\\frac{1}{n}})=0,95\\] \\[I\\subset[M, M(0,05)^{-\\frac{1}{n}}]\\] " }, { "title": "PRST: Feuille 2, suite - Exercices", "url": "/cours/posts/prst_feuille_2_suite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-29 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 14Considerons une variable aleatoire $X$ suivant une normale centree reduite et une variable aleatoire $\\varepsilon$ independante de la variable aleatoire $X$ telle:\\[P(\\varepsilon=-1)=P(\\varepsilon=1)=\\frac{1}{2}\\]Considerons la variable aleatoire $Y := \\varepsilon X$. Montrer que la variable aleatoire $Y$ suit une loi normale centree reduite Calculer $Cov(X,Y)$ Determiner la loi de la v.a. $X+Y$ Si câ€™est trop difficile, calculer $P(X+Y=0)$ En deduire que le vecteur aleatoire $(X,Y)^T$ nâ€™est pas un vecteur gaussien. Bonus: determiner la fonction de repartition de $X+Y$ Solution 1. Pour $Y\\sim\\mathcal N(0,1)$, il faut montrer que $Y$ suit la meme loi que $X$ Soit $a$ et $b$ deux reels tels que $a\\le b$\\[\\begin{aligned}P(Y\\in[a;b]) &amp;amp;= P(\\{Y\\in[a;b]\\}\\cap\\{\\varepsilon=-1\\}) + P(\\{Y\\in[a;b]\\}\\cap\\{\\varepsilon=1\\})\\\\&amp;amp;= P(\\{-X\\in[a;b]\\}\\cap\\{\\varepsilon=-1\\}) + P(\\{X\\in[a;b]\\}\\cap\\{\\varepsilon=1\\})\\end{aligned}\\] Or les v.a. $\\varepsilon$ et $X$ sont independantes\\[\\begin{aligned}P(Y\\in[a;b]) &amp;amp;= P(-X\\in[a;b])\\times P(\\varepsilon=-1) + P(X\\in[a;b])\\times P(\\varepsilon=1)\\\\&amp;amp;= \\frac{1}{2}P(-X\\in[a;b]) + \\frac{1}{2}P(X\\in[a;b])\\\\X&amp;amp;\\sim\\mathcal N(0,1)\\\\\\alpha X&amp;amp;\\sim\\mathcal N(\\alpha m,\\alpha\\sigma^2)\\\\&amp;amp;= \\frac{1}{2}P(X\\in[a;b]) + \\frac{1}{2}P(X\\in[a;b])\\\\&amp;amp;= P(X\\in[a;b])\\end{aligned}\\] Y suit la meme loi que $X$ donc $Y\\sim\\mathcal N(0,1)$ Avec la fonction caracterisitique:\\[\\begin{aligned}\\phi_Y(X) &amp;amp;= E(e^{it\\psi})\\\\&amp;amp;= E(e^{-it\\psi}\\underbrace{ğŸ™_{\\varepsilon=-1}}_{\\text{fonction indicatrice}} + e^{it\\psi}ğŸ™_{\\varepsilon=1})\\\\&amp;amp;= E(e^{-itX}ğŸ™_{\\varepsilon=-1} + e^{itX}ğŸ™_{\\varepsilon=1})\\\\&amp;amp;= E(e^{-itX} ) E(ğŸ™_{\\varepsilon=-1}) + E(e^{itX})E(ğŸ™_{\\varepsilon=1})\\\\\\end{aligned}\\] 2.\\[\\begin{aligned}Cov(X,Y)&amp;amp;=E(XY)-\\underbrace{E(X)}_{=0}\\underbrace{E(Y)}_{=0}\\\\&amp;amp;=E(XY)=E(\\varepsilon X^2)\\end{aligned}\\] Les v.a. $\\varepsilon$ et $X$ sont independnates donc $\\varepsilon$ et $X^2$ aussi.\\[Cov(X,Y)=E(\\varepsilon)E(X^2)\\\\E(\\varepsilon)=\\frac{1}{2}\\times-1+\\frac{1}{2}\\times1 =0\\] 3.\\[P(X+Y=0)=P(X=-Y)=P(\\varepsilon=-1)=\\frac{1}{2}\\\\P(X+Y=2X)=\\color{red}{P(Y=X)}=P(\\varepsilon =1)=\\frac{1}{2}\\] Ecrit â€œsavammentâ€:\\[\\delta_{a}(A)=\\begin{cases}0 &amp;amp;\\text{si } a\\not\\in A\\\\1 &amp;amp;\\text{si } a\\in A\\end{cases}\\] \\[\\mu_Y=\\frac{1}{2}\\delta_0+\\frac{1}{2}\\mu_X\\] Mais câ€™est pas ce qui nous interesse lul 4. Deux types de v.a.: discrete et continue Y nâ€™est pas continue car la probabilite dâ€™etre egale a un certain nombre et toujours egal a $0$. On cherche pas un nombre mais un intervalle. Si $X+Y$ etait gaussienne $P(X+Y=0)=0$ car dans le cas continue la probabilitÃ© dâ€™un Ã©vÃ©nement en particulier vaut toujours 0. Dâ€™apres la question precedente, $P(X+Y=0)=\\frac{1}{2}$ la combinaison lineaire $X+Y$ nâ€™est pas guassienne donc le vecteur nâ€™est pas gaussien Bonus: On pose $Z=X+Y$.\\[\\begin{aligned}P(Z\\le z)&amp;amp;= P(\\{Z\\le z\\}\\cap\\{\\varepsilon=-1\\})+P(\\{Z\\le z\\}\\cap\\{\\varepsilon=1\\})\\\\&amp;amp;= P(\\{0\\le z\\}\\cap\\{\\varepsilon=-1\\})+P(\\{2X\\le z\\}\\cap\\{\\varepsilon=1\\})\\text{ les v.a. sont independantes}\\end{aligned}\\] Si $z=0$, $F_Z(z)=\\frac{1}{2}\\times F_X(\\frac{z}{2})$ Si $z\\ge0$, $F_Z(z)=\\frac{1}{2}+\\frac{1}{2}F_X(\\frac{z}{2})$ \\[F_Z(z)=\\begin{cases}\\frac{1}{2}F_X(\\frac{z}{2}) &amp;amp;\\text{si }z\\lt0\\\\\\frac{1}{2}+\\frac{1}{2}F_X(\\frac{z}{2}) &amp;amp;\\text{si } z\\ge0\\end{cases}\\]" }, { "title": "PRST: Exos pour le 24/03", "url": "/cours/posts/prst_exercice_du_24_03/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-24 15:30:00 +0100", "snippet": "Lien de la note HackmdExercice 1Considerons une variable aleatoire $X$ suivant une loi de Poisson de parametre $0, 2$. Calculer $P(X = 4)$. Calculer $E(X)$ et $V(X)$. Solution $P(X=4) e^{-0,2}\\frac{0,2^4}{4!}=5,45\\times10^{-5}$ $E(X)=0,2$ $V(X)=0,2$Exercice 2La variable aleatoire $U$ suit une loi uniforme sur lâ€™intervalle $[2; 7]$. Calculer $P(U \\in [3; 5])$ puis $E(U)$. Solution $P(U\\in[3,5])=\\frac{5-3}{7-2}=\\frac{2}{5}$ $E(U)=\\frac{a+b}{2}=\\frac{2+7}{2}=4,5$Exercice 3La loi de Skellam est definie sur $N$ comme la difference de deux variables aleatoires independantes suivant des lois de Poisson $\\mathcal P(\\lambda_1)$ et $\\mathcal P(\\lambda_2)$ avec $\\lambda_1 \\ge 0$ et $\\lambda_2 \\ge 0$.Soient $N_1$ et $N_2$ des variables aleatoires independantes suivant respectivement des lois de Poisson $\\mathcal P(\\lambda_1)$ et $\\mathcal P(\\lambda_2)$.Par definition, la variable aleatoire $X := N_1 âˆ’ N_2$ suit une loi de Skellam de parametres $\\lambda_1$ et $\\lambda_2$ Montrer que $E(X) = \\lambda_1 âˆ’ \\lambda_2$ et $V(X) = \\lambda_1 + \\lambda_2$ ConsidÃ©rons un echantillon $(X_1, . . . , X_n)$ de la loi de $X$. Determiner, a lâ€™aide de la methode des moments, des estimateurs des parametres $\\lambda_1$ et $\\lambda_2$. Solution\\[\\begin{aligned}E(X) &amp;amp;= E(N_1-E(N_2))\\\\&amp;amp;= E(N_1)-E(N_2)\\\\&amp;amp;= \\lambda_1-\\lambda_2\\end{aligned}\\]\\[\\begin{aligned}V(X) &amp;amp;= V(N_1-N_2)\\\\&amp;amp;= \\underbrace{V(N_1) + V(-N_2)}_{N_1\\text{ et }N_2\\text{ sont independantes}}\\\\&amp;amp;= \\lambda_1+(-1)^2V(N_2)\\\\&amp;amp;=\\lambda_1+\\lambda_2\\end{aligned}\\] On sait que\\[\\begin{cases}E(X)=\\lambda_1-\\lambda_2\\\\V(X)=\\lambda_1+\\lambda_2\\end{cases}\\\\\\begin{cases}E(X)=\\lambda_1-\\lambda_2\\\\E(X) + V(X)=2\\lambda_1\\end{cases}\\\\\\begin{cases}\\lambda_2=\\lambda_1-E(X)=\\frac{V(X)-E(X)}{2}\\\\\\lambda_1=\\frac{E(X)+V(X)}{2}\\end{cases}\\] Dâ€™ou, par la methode des moments:\\[\\begin{cases}\\hat\\lambda_1=\\frac{\\bar X+S^2}{2}\\\\\\hat\\lambda_2=\\frac{S^2-\\bar X}{2}\\\\\\end{cases}\\]" }, { "title": "PRST: Seance 5 - Intervalle de confiance, suite", "url": "/cours/posts/prst_seance_5_suite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-24 14:30:00 +0100", "snippet": "Lien de la note Hackmd $X_1$ suit une loi normale $S_n^{2*}:=\\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2$ $\\frac{nS_n^{2*}}{\\sigma^2}$ suit une loi $\\mathcal X^2(n)$ A connaitre\\(\\begin{aligned}X_i&amp;amp;\\sim\\mathcal N(m,\\sigma^2)\\\\X_i-m&amp;amp;\\sim\\mathcal N(0,\\sigma^2)\\\\\\frac{X_i-m}{\\sigma}&amp;amp;\\sim\\mathcal N(0,1)\\end{aligned}\\)\\[\\sum_{i=1}^n\\frac{(X_i-m)^2}{\\sigma^2}\\sim\\mathcal X^2(n)\\\\S_n^{2*}=\\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2\\\\\\frac{nS_n^{2*}}{\\sigma^2}\\sim\\mathcal X^2(n)\\\\\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2*}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}\\\\\\frac{1}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}}\\le\\frac{\\sigma^2}{nS_n^{2*}}\\le \\frac{1}{\\mathcal X^2_{\\frac{\\alpha}{2}}}\\\\\\frac{nS_n^{2*}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}}\\le\\sigma^2\\le\\frac{nS_n^{2*}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}\\]\\[P(\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2*}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}) = 1 - \\alpha\\] La loi $\\mathcal X^2$ nâ€™est pas symetrique. Lâ€™intervalle de confiance au niveau $1-\\alpha$ pour la variance $\\sigma^2$ est:\\[[\\frac{nS_n^{2*}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}};\\frac{nS_n^{2*}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}]\\] $X_1$ suit une loi normal $\\bar X_n$ est un estimateur sans biais de $m$ $S_n^2:=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X_n)^2$ $\\frac{(n-1)S_n^2}{\\sigma^2}$ suit une loi $\\mathcal X^2(n-1)$ \\[P(\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}) = 1 - \\alpha\\] Lâ€™intervalle de confiance au niveau $1-\\alpha$ pour la variance $\\sigma^2$ est:\\[[(n-1)\\frac{s_n^{2}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}};(n-1)\\frac{s_n^{2}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}]\\]" }, { "title": "DBRE: Masterclass", "url": "/cours/posts/dbre_masterclass/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-24 12:00:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Cours nÂ°1 (01/10/2019)PrÃ©sentation du cours 12h de module. 4h rajoutÃ©es ou non, pour aller aux prudâ€™hommes. Si on peut aller aux prudâ€™hommes, des questions gÃ©nÃ©rales sur le dÃ©roulement des prudâ€™hommes peuvent apparaÃ®tre dans les exams ou QCM. Les conflits en droit du travail ne seront pas Ã©tudiÃ©s. Focus sur ce quâ€™est un contrat de travail, les clauses importantes et les modes de rupture des contrats de travail, ainsi que leurs consÃ©quences, comment on recourt Ã  un mode plutÃ´t quâ€™un autreâ€¦ LÃ©gifrance : site Ã  jour contenant les lois.Quels sont les textes que lâ€™on va utiliser en droit du travailÂ ?On a dâ€™abord la loi (au sens large) : Tous les droits fondamentaux La convention europÃ©enne des droits de lâ€™homme (aucune loi ne peut aller contre ces libertÃ©s mais elles peuvent Ãªtre contradictoires) par exemple: chacun a le libre exercice de la profession de son choix. Mais il faut sauvegarder les interets de lâ€™entreprise. Ces libertÃ©s fondamentales vont limiter les possibilitÃ©s de lâ€™employeur. On applique aussi les principes fondamentaux du droit des contrats, et donc le code civil.La relation individuelle de travail est un contrat, du coup la thÃ©orie gÃ©nÃ©rale des contrats a vocation Ã  sâ€™appliquer. On applique aussi le code du travail (thanks Sherlock). On va aussi appliquer les conventions collectives. En gros, câ€™est une convention, un contrat, qui est nÃ©gociÃ© au niveau des branches dâ€™activitÃ©s au niveau national entre des reprÃ©sentations syndicales et des reprÃ©sentations des entreprises qui viennent prÃ©ciser le droit du travail sur un secteur spÃ©cifique. Ã€ quelques exceptions prÃ¨s, ces conventions doivent apporter des dispositions qui sont plus favorables aux salariÃ©s que la Loi. Cela sâ€™applique sur un secteur pas un mÃ©tierExemple : Lâ€™enseignement supÃ©rieur privÃ© hors contrat pour EPITA (pour les ACUs par exemple).Lâ€™Etat franÃ§ais a toujours poussÃ© Ã  ce quâ€™il y ait le plus de conventions collectives. Le but Ã©tant que lâ€™Etat nâ€™intervienne pas trop mais laisse ce droit aux collectivitÃ©s. Il ne va Ãªtre impliquÃ© que pour les mÃ©tiers pas encore couverts par des conventions collectives, en Ã©largissant une autre convention collective pour quâ€™elle affecte ce mÃ©tier par exemple.Les conventions trop favorables se sont faites dÃ©noncer. Ironiquement, les conventions sâ€™appliquent sur toutes les personnes dans le secteur dâ€™activitÃ©, quelquâ€™un qui descend dans les mines aura les mÃªmes avantages que lâ€™IngÃ©nieur qui lâ€™a envoyÃ©. Les accords dâ€™entreprise ou de branche qui vont prÃ©ciser dans une entreprise un accord qui fixe des rÃ¨gles diffÃ©rentes qui sont plus favorables que les conventions collectives. Les contrats de travail individuels qui doivent Ãªtre plus favorables que les accords dâ€™entreprise.On va limiter notre Ã©tude au droit du salariÃ©, pas au droit public (pour les fonctionnaires).Un stagiaire nâ€™est pas un salariÃ©, les rÃ¨gles qui sâ€™appliquent ne sont donc pas du tout les mÃªmes. Donc on nâ€™en parlera pas ici (ou au moins pas trop). Salaire &amp;gt; avantage (pour les retraites) et de nombreuses indemnitÃ©s sont calculÃ©es sur les salairesA part quelques exceptions, en droit du travail, lors de contradictions entre deux textes, on applique le texte donnant le plus dâ€™avantages au salariÃ©.Si le droit du travail est si avantageux pour les salariÃ©s, câ€™est quâ€™il y a un lien de subordination, et un Ã©tat de dÃ©pendance Ã©conomique, entre lâ€™employÃ© et lâ€™employeur. Câ€™est donc pour protÃ©ger les employÃ©s que ces lois existent avant tout. Câ€™est beaucoup plus grave dâ€™avoir un employeur qui insulte ses employÃ©s plutÃ´t que lâ€™inverse, car il a dâ€™autres moyens Ã  sa disposition.Ne pas laisser de traces des insultes (Ã©crit, rÃ©pondeur). Il faut plus rÃ©flÃ©chir avant dâ€™Ã©crire quâ€™avant de parler, car il est interdit dâ€™enregistrer une personne Ã  son insu. Bien quâ€™il semble moins â€œviolentâ€ dâ€™insulter par Ã©crit que par oral.Preuves en droit du travailEn droit, la preuve reste un Ã©lÃ©ment dÃ©terminant. Ce qui ne peut pas Ãªtre prouvÃ© de faÃ§on lÃ©gale nâ€™existe pas.Câ€™est Ã  celui qui prÃ©tend quelque chose de le prouver.En droit du travail, le juge ne recherche pas les preuves. Câ€™est aux parties de donner des preuves.Il peut Ã  titre exceptionnel demander une expertise.Pour tout ce qui est prÃ©visible, on demande des preuves Ã©crites (la durÃ©e dâ€™un prÃ©avis, dâ€™une pÃ©riode dâ€™essai).Il faut avoir un souci de traÃ§abilitÃ© que lâ€™on soit employeur ou employÃ© (ne pas partir dans la paranoÃ¯a non plus).Pour tout ce qui est factuel, on va admettre des preuves par tÃ©moins et des preuves plus souples.Un Ã©crit valide est un acte signÃ© et datÃ© par chaque partie. Il doit y avoir autant dâ€™exemplaires que de parties Ã  lâ€™acte.Une promesse unilatÃ©rale nâ€™a besoin que dâ€™un exemplaire datÃ© et signÃ©.Une lettre, un mail, un SMS ne sont pas des Ã©crits au sens du droit mais sont des commencements de preuves, mais ne sont pas des preuves probantes.Avoir des preuves peut permettre dâ€™Ã©viter des procÃ¨s.Pas de preuve, pas de droit. Pas de droitâ€¦ pas de droit.Pas de palaisâ€¦ pas de palais.On peut aussi utiliser des attestations (tÃ©moignages). Constat de huissier : entre 200 et 500 euros. En vrai, Ã§a dÃ©pend de la demande, on est Ã  moins cher dans le cas de lâ€™authentification dâ€™un message tÃ©lÃ©phonique par exemple. Retranscrire un message Ã©lectronique par huissier : 100-150 eurosNe jamais oublier que lâ€™employeur est une personne morale et non une personne physique. La personne physique reprÃ©sentant cette personne morale peut changer (exempleÂ : promesse dâ€™augmentation).RÃ´le de la jurisprudence en droit du travailOn a beau avoir le code du travail le plus Ã©pais du monde (vraiment ?), on a beaucoup de cas qui ne sont pas dÃ©finis dans le code du travail. On laisse alors au juge le soin dâ€™interprÃ©ter. Ce sont les juges qui dÃ©finissent ce quâ€™est une faute grave ou un manquement.La jurisprudence va jouer un rÃ´le important dans la loi du travail. Les juges de la cour de cassation ont de fait un grand pouvoir normatif en loi du travail dÃ» Ã  leurs interprÃ©tations de la loi. Quand la loi doit Ãªtre interprÃ©tÃ©e, câ€™est le rÃ´le de la cour de cassation, pour que tout le monde interprÃ¨te la loi de la mÃªme maniÃ¨re.Sur certains points, pour avoir une rÃ©ponse complÃ¨te Ã  une question, il va falloir regarder la loiÂ ; les conventions collectives et les jurisprudences (toutes les jurisprudences sont disponibles sur LÃ©gifrance).Le droit international du travail adhÃ¨re Ã  certaines conventions mais le droit international fixe oÃ¹ sâ€™applique le droit international franÃ§ais. Tous les contrats sont soumis au droit franÃ§ais sâ€™ils sont exÃ©cutÃ©s sur le territoire franÃ§ais. MÃªme en Ã©tant franÃ§ais, vous ne bÃ©nÃ©ficierez pas du droit du travail franÃ§ais si vous travaillez Ã  lâ€™Ã©tranger.Ca donne lieu parfois Ã  des difficultÃ©s, par exemple pour le tÃ©lÃ©travail. On fait alors appel au droit international pour savoir quel droit appliquer (celui de lâ€™employeur ou celui de lâ€™employÃ©).Quâ€™est quâ€™un contrat de travail ?La qualification du contrat de travail est un vrai sujet dâ€™actualitÃ© pour les juges.Les employeurs cherchent de la souplesse dans le contrat de travail tandis que lâ€™employÃ© cherche de la stabilitÃ©.Lâ€™employeur a autant besoin de souplesse que lâ€™employÃ© de stabilitÃ©.Fillon : est-ce quâ€™il y avait un contrat de travailÂ ?FN : qui Ã©tait lâ€™employeur ?RÃ©cemment, de nombreuses personnes qui nâ€™Ã©taient pas salariÃ©es, les prestataires de services, prÃ©tendent aux droits du travail (Uber, Deliveroo)Dâ€™un point de vue historique, la crÃ©ation de lâ€™auto-entreprenariat a multipliÃ© lâ€™utilisation de la prestation de service. Câ€™Ã©tait un des buts des lois sur lâ€™auto-entreprenariat.Les juges ont dÃ» dÃ©finir ce quâ€™Ã©tait un contrat de travail. Dans un contrat de travail, il y a trois points indispensables : la rÃ©alisation dâ€™une prestation effective (le taff) le versement dâ€™une rÃ©munÃ©ration (le salaire) un lien de subordination (câ€™est qui le patron ?)Le lien de subordination va souvent Ãªtre prouvÃ© Ã  lâ€™aide dâ€™indices. La soumission Ã  des horaires / ordres, le lieu du travail, les consignes reÃ§ues, le pouvoir de sanction.Pour la cour de cassation, câ€™est la relation entre les parties qui va dire si câ€™est un contrat de travail ou pas. Peu importe ce qui est Ã©crit, ce qui compte ce sont les conditions de faits qui dÃ©finissent si câ€™est un contrat de travail ou une prestation (auto-entrepreneur)Des salariÃ©s de boÃ®tes de consulting qui sont envoyÃ©s dans dâ€™autres boÃ®tes ne doivent pas Ãªtre traitÃ©s comme des employÃ©s de lâ€™autre boÃ®te.Câ€™est lâ€™arrÃªt Ãle de la tentation (3 Juin 2009), câ€™est un arrÃªt de la cour de cassation. Les tentateurs ont demandÃ© la requalification de contrat.Il y a eu un lien de subordination (il y avait des ordres, des horaires). Donc il devait y avoir un contrat de travail. Depuis cet arrÃªt, dans les jeux, ils font des contrats de travail.Câ€™est cette jurisprudence qui est trÃ¨s utilisÃ©e pour requalifier le contrat.Cours nÂ°2 (15/10/2019)La qualification que donnent les parties Ã  leur relation importe peu. Câ€™est la vraie relation de fait qui est prise en compte.Effectivement, il y a un caractÃ¨re subjectif, il peut y avoir des conflits parce que cela peut toujours Ãªtre discutÃ©.Câ€™est au juge dâ€™apprÃ©cier.Il y a des faits qui imposent des qualifications juridiques. Quand on essaye de jouer avec les rÃ¨gles pour dÃ©guiser ce que lâ€™on fait, si le juge sâ€™en rend compte, il peut requalifier, voire contre-lettre (&amp;lt;â€“ c koi contre-lettre ?)Lâ€™arrÃªt Ãle de la tentation est toujours citÃ© car les juges utilisent cette mÃªme logique depuis.La preuveLâ€™Ã©crit sert uniquement de preuve supplÃ©mentaire pour prouver les engagements, mais il peut y avoir engagement sans Ã©crit.Le contrat de travail est obligatoire en droit du travail et dÃ©crit le contenu des engagements des parties.En lâ€™absence dâ€™Ã©crit, on se rÃ©fÃ¨re au droit du travail au minimum (et Ã©ventuellement aux accords dâ€™entreprise en vigueur).Cela ne veut surtout pas dire que sans Ã©crit il nâ€™y a pas de contrat. Dans notre situation, un Ã©crit pour un salariÃ© ne reprÃ©sente pas un avantage mais un inconvÃ©nient (sauf pour la rÃ©munÃ©ration).Ce qui est vraiment obligatoire, câ€™est de dÃ©clarer le salariÃ© Ã  lâ€™URSSAF pour la dÃ©claration Ã  lâ€™embauche.De maniÃ¨re plus gÃ©nÃ©rale, en droit du travailÂ : Pas de preuve, pas de droitÂ ! Idem est non esse aut non probari.Il est la mÃªme chose de ne pas Ãªtre, que de ne pas Ãªtre prouvÃ©.En droit civil, pour quâ€™une Ã©coute soit lÃ©gale, il faut prÃ©venir la personne pour lâ€™Ã©couteÂ ; en droit pÃ©nal, il faut que le juge soit prÃ©venu.La lÃ©galitÃ© de la preuve nâ€™est pas la mÃªme en droit pÃ©nal quâ€™en droit civil.En outre, en droit civil, câ€™est aux parties elles-mÃªmes de prouver leurs dires.Toutes relations entre personne privÃ©e (personne physique ou morale), câ€™est aux particuliers de prouver ce quâ€™ils prÃ©tendent. Ce nâ€™est pas au juge.Certaines preuves peuvent trÃ¨s rarement Ãªtre demandÃ©es par le juge, mais câ€™est exceptionnel.ExempleÂ :Un barman vole dans la caisse. Le patron installe une camÃ©ra de vidÃ©osurveillance non dÃ©clarÃ©e et surprend le salariÃ©, et renvoie le barman.Cependant, comme la preuve est illÃ©gale, la cour de justice a considÃ©rÃ© le vol comme non prouvÃ© (donc qui nâ€™existe pas) et a donc considÃ©rÃ© que le licenciement est abusif.Il y a une affaire oÃ¹ un majordome avait fait des Ã©coutes sauvages. Elles nâ€™ont pas Ã©tÃ© utilisÃ©es en civil et il a fallu attendre que dans le pÃ©nal un juge dÃ©cide quâ€™il veuille utiliser la preuve pour quâ€™elles soient utilisÃ©es (et lÃ©gales).Il faut essayer autant que lâ€™on peut de se prÃ©-constituer des preuves. Donc il faut de la traÃ§abilitÃ© dans ce que lâ€™on fait. Il ne faut pas non plus Ãªtre paranoÃ¯aque mais il faut autant que lâ€™on peut en constituer.Une bonne preuve permet souvent de ne pas aller aux prudâ€™hommes. Attention Ã  ne pas se constituer des preuves contre soi.Si vous voulez insulter quelquâ€™un, dites-lui mais ne lâ€™Ã©crivez pas.Ne laissez pas de messages dÃ©biles sur un rÃ©pondeur tÃ©lÃ©phonique, nâ€™envoyez pas des SMS ou des e-mails injurieux, etc.Les modes de preuve (ordre hiÃ©rarchique dâ€™importance / pertinence) : Aveu judiciaireÂ : devant le juge. Reine des preuves, rare en droit du travail. Acte authentique (fait chez un notaire / officier de policeâ€¦). Pas utilisÃ© en droit du travail. Acte sous seing privÃ©. Acte formel signÃ© par les deux parties. Par exemple un contrat de travail. Un Ã©crit. Un acte avec autant dâ€™exemplaires que de parties. Les montants doivent Ãªtre Ã©crits en chiffres et en lettres. ExempleÂ : Convention de stage. Commencement de preuve par Ã©crit. On ne peut prouver quâ€™avec ce quâ€™on reÃ§oit, pas avec ce quâ€™on envoie. Par exemple, un accusÃ© de rÃ©ception de lettre recommandÃ©e prouve quâ€™on a envoyÃ© quelque chose, mais pas son contenu. Pour les preuves dâ€™inventions ou de propriÃ©tÃ© intellectuelle, on peut sâ€™envoyer Ã  soi-mÃªme avec recommandÃ© une lettre scellÃ©e contenant une preuve de la choseÂ ; en cas de jugement, on pourra desceller Ã  lâ€™audience et cela prouvera quâ€™Ã  date du recommandÃ© la chose existait dÃ©jÃ . Le tÃ©moignageÂ : pour les faits oÃ¹ on nâ€™a pas pu se constituer une preuve. Aveu extra-judiciaire : quasiment aucune valeur. Attention, en signant un contrat le pire piÃ¨ge est de signer un contrat sans avoir la signature de lâ€™autre.Pour le demander de maniÃ¨re pas trop frontale, on peut le demander pour la bonne forme.Lâ€™employeur est une personne morale. La personne physique qui le reprÃ©sente ne sâ€™engage pas Ã  raison personnelle.Par exemple, sâ€™il vous promet Ã  lâ€™oral une prime, puis quâ€™il dÃ©missionne ou meurt, vous ne pourrez pas le prouver Ã  son successeur.Un Ã©crit ne peut Ãªtre contredit que par un autre Ã©crit de mÃªme hiÃ©rarchie.Il faut respecter un parallÃ©lisme dans les preuves.Par exemple, si on nous demande par recommandÃ©, on rÃ©pond par recommandÃ©.AttestationÂ : Ã©crit formel servant Ã  prouver la bonne foi dâ€™une partie.Les diffÃ©rentes formes du contrat de travailDeux grandes formes de contrats de travail : Contrat de travail Ã  durÃ©e dÃ©terminÃ©e (CDD) Contrat de travail Ã  durÃ©e indÃ©terminÃ©e (CDI)Il en existe dâ€™autres.Les juges ont une ligne directrice, qui dit que : La forme normale du travail, câ€™est le CDI Ã  temps plein.Câ€™est ce qui va guider les juges dans leur jugement.Tous les textes de lois doivent Ãªtre interprÃ©tÃ©s Ã  la lumiÃ¨re de ce principe.(Personne ne veut dâ€™un CDD ou temps partiel en principe).En consÃ©quence, les cas de recours au CDD doivent Ãªtre exceptionnels.La loi fixe les cas de recours.Un CDD ne doit pas pourvoir un poste durable et permanent.Il y a globalement 3 cas de recours aux CDDÂ : Remplacement de salariÃ©s absents (congÃ© maladie, congÃ© parental, congÃ© sabbatiqueâ€¦). Il faut bien noter la personne que le â€œCDDisteâ€ va remplacer. Accroissement temporaire dâ€™activitÃ© (emplois saisonniers, commande exceptionnelle, besoin de personnel durant une pÃ©riodeâ€¦). Cas autorisÃ©s par la loi (CDD dâ€™usage).Si on a un peu jouÃ© avec la loi et que le CDD est en rÃ©alitÃ© durable et permanent, le CDD peut Ãªtre requalifiÃ© en CDI.Le CDD doit Ãªtre passÃ© par Ã©crit, justement pour prouver quâ€™il sâ€™agit dâ€™un CDD plutÃ´t quâ€™un CDI.Cependant, dans certains cas, lâ€™employeur peut prouver quâ€™il sâ€™agit dâ€™un CDD. ==&amp;gt; quels cas ? : mystÃ¨re et boule de gommeDans le cas normal :A dÃ©faut de contrat signÃ© dans les 48 heures ouvrables, vous Ãªtes rÃ©putÃ© avoir Ã©tÃ© embauchÃ© en CDI Ã  temps plein sans pÃ©riode dâ€™essai.Le temps partielLe temps partiel doit Ãªtre passÃ© par Ã©crit.Le lÃ©gislateur demande Ã  rÃ©partir les horaires pour Ã©viter les interruptions trop longues (de sorte que lâ€™employÃ© soit disponible pour un autre travail Ã  temps partiel).Sâ€™il y a un accroissement dâ€™activitÃ©, lâ€™employÃ© Ã  temps partiel est prioritaire par rapport Ã  un recrutement extÃ©rieur.AstreinteÂ : le salariÃ© reste Ã  son domicile mais doit venir sâ€™il est sollicitÃ©.Sâ€™il nâ€™est pas sollicitÃ© il est rÃ©munÃ©rÃ© pour lâ€™astreinte (donc moins). Sinon il est payÃ© sous un contrat de travail normal avec un salaire normal Ã©galement (revalorisÃ© par rapport Ã  lâ€™indemnitÃ© dâ€™astreinte passive).Cours nÂ°3 (29/10/2019)Contenu du contrat de travailIl y a plusieurs obligations principales pour lâ€™employeur envers le salariÃ© : Obligation de verser un salaire Obligation de fournir un travail Obligation de loyautÃ© â€“&amp;gt; cÃ d ? Obligation dâ€™assurer la sÃ©curitÃ© du salariÃ©Ces obligations ne sont pas toutes dans le droit de travail mais Ã©galement dans le droit gÃ©neral (assurer la sÃ©curitÃ©).Plusieurs obligations principales pour lâ€™employÃ© envers lâ€™employÃ© : Effectuer le travail pour lequel il est rÃ©munÃ©rÃ© Avoir un comportement â€œnormalâ€ (ne pas nuire) ÃŠtre loyal (comme pour tout contrat)Ces obligations sont implicites (elles ne figurent pas dans le contrat de travail).Par exemple : Protection de la vie privÃ©e (imposÃ©e par la loi).Donc la lÃ©gislation du contrat de travail contient des rappels sur le droit gÃ©nÃ©ral et des clauses suplÃ©mentaires sur le droit du contrat de travail.Dans les limites fixÃ©es par la loi, lâ€™employeur et le salariÃ© peuvent ajouter des clauses au contrat.La lÃ©galitÃ© de ces clauses est plus difficile Ã  analyser.Ce cadre est soumis au droit des contrats.Analyse de quelques clauses du contrat de travail Clause de non-concurrence Clause de confidentialitÃ© MobilitÃ© PÃ©riode dâ€™essai Toutes ces clauses doivent Ãªtre Ã©crites dans le contrat de travail pour Ãªtre en vigueur. Seules les clauses bien formÃ©es ont une portÃ©e lÃ©gale.Rappel : Le salariÃ© est en position dâ€™infÃ©rioritÃ© thÃ©orique. Nul ne peut se prÃ©valoir de sa propre turpitude.Si le dommage subi est le fait de ses propres actions illicites ou illÃ©gales, on ne peut pas rÃ©clamer justice.Une clause illÃ©galeÂ : Pour un salariÃ©, il peut ne pas lâ€™appliquer Lâ€™employeur sera sanctionnÃ©La clause figure ou bien au dÃ©but du contrat de travail, ou bien peut Ãªtre rajoutÃ©e (par Ã©crit) au cours du contrat.Toute clause non illÃ©gale et consentie peut Ãªtre ajoutÃ©e au contrat.Clause de non-concurrenceNâ€™a vocation Ã  sâ€™appliquer quâ€™au terme du contrat.Elle ne sâ€™applique pas lors de lâ€™exÃ©cution du contrat de travail (parce quâ€™il faut de toute faÃ§on Ãªtre loyal envers son employeur).La clause de non-concurence sert Ã  empÃªcher un salariÃ© dâ€™exercer une concurrence loyale Ã  son employeur Ã  lâ€™issue du contrat de travail.Elle vise Ã  interdire au salariÃ© de faire quelque chose de lÃ©gal outre mesureÂ : travailler chez les concurrents ou crÃ©er sa propre structure qui fait concurrence Ã  lâ€™entreprise.Il y a des conditions pour que cette clause soit valableÂ : La clause de non-concurrence doit Ãªtre apprÃ©ciÃ©e avec en ligne de fond le libre-exercice de la profession de son choix (libertÃ© fondamentale, mais exceptions pour les professions rÃ©glementÃ©es par des diplÃ´mes ou par des numerus claususÂ : mÃ©decins, juristes, bÃ¢timentâ€¦). Les juges vont Ãªtre sÃ©vÃ¨res sur cette clause car elle peut limiter une libertÃ© fondamentale. Ã€ partir de 2002, la cour de cassation a posÃ© des conditions pour les clauses de non-concurrence Elle doit Ãªtre nÃ©cessaire pour la sauvegarde des intÃ©rÃªts de lâ€™entreprise Seuls les postes qui peuvent menacer les intÃ©rÃªts de lâ€™entreprise peuvent avoir une clause de non-concurrence. Commerce, encadrement, R&amp;amp;D. La clause doit Ãªtre limitÃ©e dans lâ€™espace (au cas par cas, difficile si lâ€™entreprise a un rayonnement national) et dans le temps (maximum 2 ans, selon le temps de renouvellement de la clientÃ¨le). Elle doit Ãªtre assortie dâ€™une contrepartie financiÃ¨re. Depuis le 7 mars 2007, la cour de cassation a prÃ©cisÃ© que cette contrepartie doit Ãªtre versÃ©e au moment oÃ¹ la clause sâ€™applique (donc Ã  partir de la rupture de contrat) Si la clause est versÃ©e durant le contrat, elle dÃ©pend de lâ€™anciennetÃ©. La clause de non-concurrence va gÃªner le salariÃ© lors de la recherche dâ€™emploi (câ€™est quand il a du mal Ã  trouver un emploi quâ€™on peut lui verser la contrepartie). La concurrence dÃ©loyale est interdite, quâ€™il y ait une clause de non-concurrence ou non.Plusieurs questions se sont posÃ©es sur cette clause : Il faut appliquer la clause quelle que soit la cause de la rupture. Peut-il y avoir une renonciation unilatÃ©rale ? Non sauf si elle a Ã©tÃ© prÃ©vue de faÃ§on bilatÃ©rale. Que faire quand la clause est nulle ? La jurisprudence dominante a tendance Ã  laisser le salariÃ© choisir entre accepter la clause ou la refuser. Si la clause est valableÂ ? Le salariÃ© sâ€™expose Ã  de grosses sanctions sâ€™il rompt la clauseÂ : il devra rembourser la contrepartie, voire se faire licencier de son nouveau poste. Si le nouvel employeur Ã©tait complice, il sâ€™expose Ã  des sanctions devant le tribunal de commerce.Il y a des clauses de non-concurrence dÃ©guisÃ©es.Toute clause visant Ã  empÃªcher un salariÃ© de travailler pour un concurrent Ã  lâ€™issue du contrat est une clause de non-concurrence.Par exemple, on la dÃ©guise parfois en clause de confidentialitÃ©.Une clause de confidentialitÃ© est utile en tant que rappel Ã  la loi, bien que juridiquement surabondante.Cette clause est juridiquement surabondante mais utile pour rappeler cette loi qui nâ€™est toujours pas trÃ¨s bien connue par les employÃ©s.Mais le rappel de ces rÃ¨gles ne doit pas empÃªcher le salariÃ© de travailler pour la concurrence. La plupart du temps, les clauses de confidentialitÃ© sont plus dans le BÂ toÂ B.La clause de non-sollicitation du personnel limite la libertÃ© du salariÃ© sans contrepartie salariale.Lâ€™accord de non solliciation croisÃ©e (des opÃ©rateurs dâ€™un oligopole sâ€™accordent pour ne pas embaucher les salariÃ©s des concurrents) est problÃ©matique dâ€™un point de vue lÃ©gal et donc nâ€™apparaÃ®t pas.Clauses de mobilitÃ©Le salariÃ© sâ€™engage Ã  aller partout oÃ¹ lâ€™entreprise veut lâ€™emmener.MobilitÃ©Â : contraindre un salariÃ© Ã  changer de domicile (induit par un changement dâ€™emplacement de lâ€™entreprise).Distincte du dÃ©placement (qui ne nÃ©cessite pas de changer de domicile).Le critÃ¨re pris en compte nâ€™est pas le domicile du salariÃ© mais la distance entre lÃ  oÃ¹ il travaillait et lÃ  oÃ¹ il va travailler.Si le changement du lieu de travail implique un changement de domicile, on considÃ¨re que câ€™est une modification du contrat. Sâ€™il y a une modification du contrat, elle doit Ãªtre prÃ©vue par une clause ou acceptÃ©e par les parties au moment oÃ¹ on lui propose.Si Ã§a nâ€™implique pas de changement de domicile, ce nâ€™est plus une modification du contrat mais un changement des conditions de travail qui est dans les droits de lâ€™employeur.Mais Ã  partir de quand va-t-on considÃ©rer que le changement de lieu de travail implique un changement de domicileÂ ?Quand il y a changement de zone gÃ©ographique.Zone gÃ©ographiqueÂ : alchimie entre distance, temps de trajet, moyens pour effectuer le trajetâ€¦Quand il nâ€™y a pas de clause de mobilitÃ©, on ne peut pas changer un salariÃ© hors de sa zone gÃ©ographique. Si câ€™est dans la mÃªme zone gÃ©ographique, le salariÃ© nâ€™a pas de le droit Domicile â†’ TravailÂ : temps de trajet.Travail â†’ autre endroit pour le travailÂ : dÃ©placement, temps de travailQuand il y a une clause de mobilitÃ©Â : pour que la clause soit valable, il faut que la mobilitÃ© soit indispensable Ã  la sauvegarde des intÃ©rÃªts de lâ€™entreprise (mobilitÃ© due Ã  un caprice du chef dâ€™entreprise = illÃ©gale).Si le salariÃ© (avec une clause de mobilitÃ©) ne veut pas accepter de changer de lieu de travailÂ : pendant des annÃ©es, câ€™Ã©tait un licenciement pour faute. Maintenant considÃ©rÃ© comme un licenciement justifiÃ©.Si câ€™est dans la mÃªme zone gÃ©ographique, Ã§a reste un licenciement pour faute.PÃ©riode dâ€™essaiDepuis 2008, la pÃ©riode dâ€™essai doit Ãªtre une clause dans le contrat. Quand on dÃ©cide de faire une pÃ©riode dâ€™essai. Limite de 1 Ã  4 mois, renouvelable une fois.La pÃ©riode dâ€™essai est une pÃ©riode durant laquelle lâ€™employeur et lâ€™employÃ© peuvent finir le contrat beaucoup plus facilement. Lâ€™employeur peut licencier avec un dÃ©lai de prÃ©venance de 2 semaines tant que ce nâ€™est pas une cause Ã©trangÃ¨re au travail (politique religieuse, santÃ©, grossesseâ€¦).La pÃ©riode dâ€™essai est considÃ©rablement rÃ©duiteÂ : on ne peut pas en faire si on a fait un CDD.Seule influenceÂ : sur les modalitÃ©s de rupture du contrat.Cours nÂ°4 (05/11/2019)Lâ€™assurance chÃ´mage nâ€™est pas une indemnitÃ©.Deux choses Ã  savoir sur le salaire.Salaires = crÃ©ance surprivilÃ©giÃ©e (lors dâ€™une liquidation, ce sont les premiÃ¨res crÃ©ances Ã  Ãªtre remboursÃ©es).Tout employeur (entreprise ou assurance) cÃ´tise sur les salaires et les indemnitÃ©sassurance obligatoire sur la garantie des salaires Les bulletins de salaire sont Ã  garder Ã  vie, pour le droit et pour la retraite.En matiÃ¨re de salaire, la prescription est de trois ans (voire plus dans certains cas particuliers).En cas de rupture de contrat de travailÂ :DiffÃ©rentes causes de ruptureSi nous vivions dans un monde idÃ©al, ce sont les faits qui devraient imposer un mode de rupture.A une situation factuelle correspond une mÃ©thode de rupture spÃ©cifique.Sauf que ce nâ€™est pas le cas dans la rÃ©alitÃ©, une grande partie du contentieux venant de la qualification de la rupture. Si on qualifie mal le contrat, on risque de devoir payer les indemnitÃ©s + les frais dâ€™avocat. Il vaut mieux licencier sans cause que dâ€™inventer une qualification bidon (voire dâ€™antidater des documents).Câ€™est la situation de fait qui impose le mode de rupture.Cette rupture peut Ãªtre Ã  lâ€™initiativeÂ : du salariÃ© de lâ€™employeur dâ€™un commun accord entre les deux partiesLa jurisprudence joue un rÃ´le important dans la qualification de la rupture (car la loi est trop vague) en cherchant dans le code civil plutÃ´t que par le droit du travail.Certains modes de rupture ne sont pas prÃ©vus par le code du travail mais sont mis en place par des juges qui ont interprÃ©tÃ© le code civil et le contrat de travail.Câ€™est donc un domaine dans lequel il y a beaucoup dâ€™Ã©volution dans les interprÃ©tations et une grande part dâ€™alÃ©atoire (car soumis Ã  lâ€™interprÃ©tation des juges).Ã‡a marche aujourdâ€™hui, mais Ã§a ne marchera peut-Ãªtre pas demain.Rupture Ã  lâ€™initiative du salariÃ©La dÃ©missionLe salariÃ© souhaite quitter son emploi pour des raisons qui lui appartiennent et doit Ãªtre non Ã©quivoque. Il doit remettre une lettre en main propre Ã  lâ€™employeur affirmant quâ€™il quitte lâ€™entreprise.En gÃ©nÃ©ral, le salariÃ© dÃ©missionne lorsquâ€™il a trouvÃ© un emploi derriÃ¨re.La prise dâ€™acte de ruptureManquement grave aux obligations de lâ€™employeur remarquÃ© par le salariÃ©. Le salariÃ© prend acte que lâ€™employeur a rompu unilatÃ©ralement le contrat en ne respectant pas le contrat.Le salariÃ© doit saisir le tribunal immÃ©diatement.Si on prouve le manquement grave de lâ€™employeur, le juge en tirera les consÃ©quences dâ€™un licenciement sans cause.Si le salariÃ© ne prouve pas le manquement, la rupture prendra lâ€™effet dâ€™une dÃ©mission.Il faut mieux pour le salariÃ© prendre acte de rupture que de dÃ©missioner et de tenter de requalifier cette dÃ©mission aprÃ¨s.La rupture est assurÃ©eÂ : dÃ¨s quâ€™on en prend acte, le contrat est rompu. Certains salariÃ©s utilisent la prise dâ€™acte durant une procÃ©dure de licenciementÂ : il y a toujours un dÃ©lai, donc le salariÃ© peut prendre acte de la rupture et donc Ã©chapper au licenciement (puisquâ€™on ne peut pas rompre deux fois le mÃªme contrat).DÃ¨s lors, on peut remettre en valeur les manquements de lâ€™employeur plutÃ´t que les manquements du salariÃ©.Exemples de manquements de lâ€™employeur : employeur qui demande Ã  lâ€™employÃ© de faire quelque chose dâ€™illÃ©gal (e.g., produire un faux) employeur qui nâ€™assure pas la sÃ©curitÃ© (physique ou morale) de ses employÃ©s (e.g., employeur ne sanctionne pas suffisament les personnes responsables dâ€™harcÃ¨lementÂ ; si un consultant se fait agresser par un client, alors la responsabilitÃ© de lâ€™employeur est engagÃ©e) non versement des salaires ne fournit plus de travail Ã  ses salariÃ©s On a souvent tendance Ã  demander Ã  des personnes de lâ€™informatique de faire des actions illÃ©gales (RGPD). #BonPlanQuitterSaBoÃ®teSansDÃ©missionerRÃ©solution judiciaireDemande de rÃ©solution judiciaire pour demander la rÃ©siliation du contrat.Initiative communeLa rupture conventionnelle, alias licenciement Ã  lâ€™amiable. Elle date de 2008.On a eu peur que certains employeurs aient une fÃ¢cheuse tendance Ã  lâ€™imposer Ã  leurs salariÃ©s dont ils ne voulaient plus.Le lÃ©gislateur a donc imposÃ© une procÃ©dure avec des dÃ©lais de rÃ©flexion, des entretiens, et lâ€™obligation de transmettre les accords Ã  la direction dÃ©partementale du travail.Cette rupture conventionnelle est rÃ©servÃ©e au cas prÃ©cis oÃ¹ lâ€™employeur et le salariÃ© ne veulent plus continuer ensemble, mais cette volontÃ© de rompre le contrat ne dÃ©pend pas dâ€™une faute.ExempleÂ : les dÃ©sirs / conditions de vie du salariÃ© changent raisons extrÃªmes personnellesContestationsÂ : le salariÃ© arrive parfois Ã  prouver quâ€™on lui a imposÃ© cette rupture (car moins cher quâ€™un licenciement sans cause) et pourra la requalifier.Ã€ lâ€™initiative de lâ€™employeurNÃ©cessairement un licenciement.Beaucoup de rÃ¨gles de forme Ã  respecter, mais câ€™est surtout le fond, les motivations, qui doit Ãªtre respectÃ©. Si les rÃ¨gles de forme ne sont pas respectÃ©es, il nâ€™y aura pas de remise en compte du licenciement, seulement des sanctions.Les procÃ©dures varient selon la cause du licenciement, la taille de lâ€™entreprise, etc.Le salariÃ© va souvent contester le motif de son licenciement.Chaque licenciement est accompagnÃ© dâ€™une lettre, mÃªme plus importante que la procÃ©dure, car elle contient les motifs du licenciement.La lettre fige les litiges. On ne peut pas invoquer autre chose que ce quâ€™il y a dans la lettre comme motif de licenciementLâ€™employeur possÃ¨de une arme absolueÂ : la mise Ã  pied. Il peut rÃ©diger la lettre plus tard.Licenciement pour motif Ã©conomiqueLâ€™entreprise serait en pÃ©ril si elle gardait les salariÃ©s.Cela peut Ãªtre pour des difficultÃ©s Ã©conomiques, ou pour supprimer certains postes et quâ€™on ne peut pas recaser les gens â†’ donne lieu Ã  beaucoup de contestations sous motif que les postes ont Ã©tÃ© renommÃ©s mais pas supprimÃ©s.Autre motif de contestationÂ : artifice comptable entre plusieurs sociÃ©tÃ©s.En France, les juges ont Ã©normÃ©ment de mal Ã  admettre un motif Ã©conomique quand il sâ€™agit dâ€™une rÃ©organisationÂ : culture de prÃ©servation de lâ€™emploi.Le licenciement peut Ãªtre collectif, mais il sâ€™agit dâ€™un ensemble de licenciements individuels donc tous les employÃ©s peuvent contester leur licenciement indivuellement.Licenciement personnel Non-disciplinaireÂ : sans faute DisciplinaireÂ : faute lÃ©gÃ¨re / grave / lourde (les diffÃ©rents dÃ©grÃ©s tendent Ã  disparaÃ®tre)Motif non-disciplinaireRefus dâ€™appliquer une clause de mobilitÃ©.Pendant trÃ¨s longtemps il a Ã©tÃ© considÃ©rÃ© que câ€™Ã©tait une faute grave. Ce nâ€™est plus une faute grave car elle limite des libertÃ©s fondamentales mais Ã§a reste une faute rÃ©elle et sÃ©rieuse justifiant un licenciement.IncapacitÃ© du salariÃ© Ã  sâ€™adapter Ã  de nouvelles mÃ©thodes (ni par mauvaise volontÃ©, ni par bÃªtise).IncompatibilitÃ©s dâ€™humeur entre les personnes (?)Ã‡a ne passe pas forcÃ©ment.Ã€ titre exceptionnel, on admet quâ€™un motif tirÃ© de la vie privÃ©e consistue un licenciement si ce motif a crÃ©Ã© un trouble grave et objectif.Si un conflit dâ€™intÃ©rÃªt vient de la vie privÃ©e des salariÃ©s, il peut Ãªtre trÃ¨s compliquÃ© Ã  justifier le licenciement.GÃ©nÃ©ralement, quand un employeur veut licencier quelquâ€™un pour un motif tirÃ© de la vie privÃ©e en sachant que Ã§a ne fonctionnera pas, il invente des motifs en lui trouvant une faute.Le salariÃ© doit prouver que le motif avancÃ© nâ€™est pas le bon pour faire requalifier son licenciement.Licenciement disciplinaireOn distingue tradionnellement la faute grave et la faute lourdeFaute graveÂ : faute dâ€™une gravitÃ© telle quâ€™elle rend impossible le maintien du salariÃ© dans lâ€™entreprise.Il faut mettre la personne Ã  pied dÃ¨s que la faute a Ã©tÃ© constatÃ©e.TrÃ¨s souvent une faute professionnelle. Peut Ãªtre une accumulation de comportements (pas de double peine, mais une rÃ©pÃ©tition dâ€™une faute peut devenir une grosse faute).Sanction graduÃ©eÂ : avertissement, mise Ã  pied, licenciement.Exemples de fautes graves : faute comportementaleÂ : absence injustifiÃ©e, retards, vol ou escroquerie (falsification de note de frais), comportement vis-Ã -vis des autres salariÃ©s (violences physiques ou morales dont insulter des subordonnÃ©s) faute professionnelleFaute lourdeÂ : faute grave commise avec lâ€™intention de nuire Ã  lâ€™employeur.Tableau rÃ©capitulatif Initiative Mode de rupture Assurance chÃ´mage CongÃ©s payÃ©s PrÃ©avis Licenciement Sans cause SalariÃ© DÃ©mission GÃ©nÃ©ralement non Â  Â  Non Non SalariÃ© Prise dâ€™acte de rupture Non? Â  Â  Non Non SalariÃ© (RÃ©solution judiciaire) Non? Â  Â  Â  Non Commune Rupture conventionnelle ? Â  Â  Â  Non Employeur Licenciement Ã©conomique Oui Oui Oui Oui Non Employeur Licenciement personnel (non disciplinaire) Oui Oui Oui Oui Non Employeur Licenciement personnel (faute grave) Oui Oui Non Oui Non Employeur Licenciement personnel (faute lourde) Oui Autrefois non Non Oui Non Employeur Licenciement personnel (sans cause sÃ©rieuse) Oui Oui Oui Oui Oui Cours nÂ°5 (19/11/2019)Aux prudâ€™hommes, les plaignants veulent la requalification du mode de rupture.Les juges vont seulement regarder si le mode de rupture est le bon.Beaucoup de contentieux au moment de la ruptureÂ : Difficile de sâ€™opposer Ã  son employeur quand on est en poste.Câ€™est lors de la rupture, lorsque lâ€™on nâ€™est plus dans lâ€™entreprise, que lâ€™on peut plus facilement se battre. Les consÃ©quences de la qualification sont trÃ¨s importantes sur le montant des indemnitÃ©s quâ€™on va percevoir au moment de la rupture qui sont trÃ¨s diffÃ©rentes. Le salariÃ© peut avoir besoin psychologiquement que la justice reconnaisse la faute de lâ€™employeur.IndemnitÃ©s en fin de contratAssurance chÃ´mageCette indemnitÃ© est versÃ©e par lâ€™Ã‰tat, pas par lâ€™employeur.Les conditions pour recevoir lâ€™assurance chomage, ne dÃ©pendent pas de la rupture du contrat de travail du moment que la rupture est dÃ©cidÃ©e par lâ€™employeur (y compris pour une faute lourde).La dÃ©mission nâ€™ouvrait pas le droit Ã  lâ€™assurance chÃ´mage, il y a rÃ©cemment eu des rÃ©formes.Les conditions sont fixÃ©es par les ASSEDIC.Lâ€™ASSEDIC ne regarde pas la cause du licenciement.IndemnitÃ© de congÃ©s payÃ©sLorsquâ€™une personne quitte une entreprise et nâ€™a pas Ã©puisÃ© tout son stock de congÃ©s.On acquiert un certain nombre de jours de congÃ©s payÃ©s par mois travaillÃ©, qui peuvent Ãªtre pris dans des conditions spÃ©cifiques.Si le stock de congÃ©s payÃ©s nâ€™est pas Ã©puisÃ©, lâ€™employeur doit indemniser les congÃ©s payÃ©s qui restent.Les congÃ©s qui ne sont pas pris durant une pÃ©riode de rÃ©fÃ©rence sont perdus (sauf si lâ€™employeur accepte de les reporter).Pendant longtemps, lâ€™idemnitÃ© de congÃ©s payÃ©s nâ€™Ã©tait pas indemnisÃ©e pour un licenciement pour faute lourde.La cours de cassation vient de prendre une dÃ©cision. Que le salariÃ© qui nâ€™avait pas pris ses congÃ©s payÃ©s recevait quand mÃªme cette indemnitÃ© en cas de faute lourde.IndemnitÃ© de prÃ©avisLe contrat de travail fixe un prÃ©avisÂ : durÃ©e que lâ€™on doit respecter entre le moment de dÃ©cider de partir de lâ€™entreprise et le moment oÃ¹ on quitte lâ€™entreprise pour de bon.Ce dÃ©lai de prÃ©avis est de 1 Ã  3 mois.Lâ€™entreprise et le salariÃ© peuvent, dâ€™un commun accord, ne pas effectuer le prÃ©avis, Ã  condition que lâ€™employeur indemnise ce prÃ©avis, câ€™est souvent le cas.Lorsque le salariÃ© est licenciÃ© pour faute grave ou lourde, le prÃ©avis ne lui est pas dÃ».Lorsque le salariÃ© licenciÃ© pour faute grave/lourde fait requalifier son licenciement aux prudâ€™hommes, il demande son indemnitÃ© de prÃ©avis (ainsi que son indemnitÃ© aux congÃ©s payÃ©s sur la durÃ©e du prÃ©avis quâ€™il nâ€™a pas effectuÃ©).En outre, un employeur laissant le salariÃ© effectuer son prÃ©avis ne peut pas le licencier pour faute grave ou lourde.Comme les indemnitÃ©s sont calculÃ©es vis-Ã -vis du prÃ©judice subi, les demandes dâ€™indemnitÃ©s sont chiffrÃ©es au centime prÃ¨s.IndemnitÃ© lÃ©gale ou conventionnelle de licenciementCette indemnitÃ© est fixÃ©e par la loi ou par la convention collective.Elle est calculÃ©e en fonction du salaire et du nombre dâ€™annÃ©es dâ€™anciennetÃ© du salariÃ©.Il peut Ãªtre plus judicieux pour lâ€™entreprise de payer la formation continue dâ€™un salariÃ© avec beaucoup dâ€™anciennetÃ© plutÃ´t que de le licencier et de payer sa giga-indemnitÃ© de licenciement.IndemnitÃ© pour licenciement sans cause rÃ©elle et sÃ©rieuseCette indemnitÃ© nâ€™est due quâ€™en cas de licenciement sans cause rÃ©elle et sÃ©rieuse, et sâ€™ajoute Ã  lâ€™indemnitÃ© prÃ©cÃ©dente.Jusquâ€™Ã  la rÃ©forme de 2017, cette idemnitÃ© nâ€™avait pas de barÃ¨me.La seule indication que donnait la loi Ã©tait que dans les entreprises de plus de 11 salariÃ©s pour les salariÃ©s de plus de 6 mois, il y avait une indemnisation de 6 mois de salaireÂ ; le reste Ã©tait choisi par les juges, et variait de prudâ€™hommes Ã  prudâ€™hommes.En 2017, un barÃ¨me a Ã©tÃ© fixÃ© et a imposÃ© un plafond dâ€™indemnisation de 9 mois de salaire.Ce plafond a Ã©tÃ© contestÃ© par les avocats car la tradition franÃ§aise veut que lâ€™entiÃ¨retÃ© du prÃ©judice soit rÃ©parÃ©.Devant les prudâ€™hommes, toutes les pistes vont Ãªtre suivies par les avocats pour que le salariÃ© perÃ§oive le plus dâ€™indemnitÃ©s possibles.Dommages et intÃ©rÃªtsPrÃ©judice moral, non-respect de la procÃ©dure de licenciementâ€¦Le montant de lâ€™indemnitÃ© est arbitraire.IndemnitÃ©s au titre de lâ€™article 700 (le fameux)IndemnitÃ©s pour couvrir les frais de justice (3â€¯000 ~ 10â€¯000Â â‚¬).Traditionnellement, en France, les employeurs sont condamnÃ©s Ã  verser ces indemnitÃ©s sâ€™ils perdent, mais les salariÃ©s nâ€™y sont gÃ©nÃ©ralement pas condamnÃ©s sâ€™ils perdent.Rappels sur les prudâ€™hommesLes conseillers prudâ€™hommaux sont Ã  moitiÃ© des salariÃ©s, Ã  moitiÃ© des employeurs.Ils reÃ§oivent une formation. Ils Ã©taient auparavant Ã©lus, mais maintenant dÃ©signÃ©s (Ã  condition dâ€™en faire la demande). Ils siÃ¨gent quelques jours par mois.Si ce sont des salariÃ©s, ils perÃ§oivent leur salaire et lâ€™Ã‰tat rembourse lâ€™employeur.Si (et seulement si) ils sont retraitÃ©s ou chÃ´meurs, alors ils perÃ§oivent une indemnitÃ© de lâ€™Ã‰tat.Sections Commerce Industrie Encadrement Agriculture et activitÃ©s diversesChaque section est sÃ©parÃ©e en deux bureauxÂ : Bureau de conciliationDeux jugesÂ : un employeur, un salariÃ©.Câ€™est devant ce bureau que la procÃ©dure commence Bureau de jugementLe tribunal, composÃ© dâ€™un greffier, 4 juges (deux employeurs, deux salariÃ©s).Parmi les quatre juges, un est le prÃ©sident (dont le rÃ´le est de mener les dÃ©bats, au prudâ€™homme change tout les 6 mois, une fois salariÃ©, une fois employeur)Mais il nâ€™a pas de voix prÃ©pondÃ©rente, et les dÃ©cisions doivent Ãªtre prises Ã  la majoritÃ©.En cas de partage de voix, on envoie devant le juge dÃ©partiteur qui, lui, siÃ¨ge les audiences de dÃ©partage.Pour saisir les prudâ€™hommes il faut aller au greffeGÃ©nÃ©ralement, lâ€™employeur et le salariÃ© rÃ¨glent leurs diffÃ©rents en privÃ© ou devant le bureau de conciliation.Quand une affaire arrive devant le bureau de jugement, Ã§a veut dire que le diffÃ©rent est trÃ¨s profond et quâ€™il nâ€™est pas simple Ã  trancher.Le conseil des prudâ€™hommes a Ã©tÃ© saisi un an avant le passage devant le bureau de jugement.Formation transverse (de rÃ©fÃ©rÃ©)Â : procÃ©dure dâ€™urgence pour saisir la justice rapidement.Cette dÃ©cision est provisoire et devra Ãªtre suivie dâ€™une autre dÃ©cision.En matiÃ¨re civile, pas pÃ©nale.La procÃ©dure est accusatoireÂ : les deux parties au procÃ¨s (employeur et salariÃ©) sâ€™accusent mutuellement.Le juge ne fait que rÃ©pondre et trancher les questions quâ€™on lui pose (il ne soulÃ¨ve pas de questions de son propre chef).Ce sont les parties qui fixent les contours du procÃ¨s, pas le juge.Le juge ne cherche pas les preuves, sauf pour les preuves qui ne peuvent Ãªtre appelÃ©es que par un juge.Lâ€™avocat de la demande ou de la dÃ©fense a une argumentation Ã  tiroirsÂ : il a une demande Ã  titre principal, et plusieurs demandes subsidiaires si la demande Ã  titre principal est rejetÃ©e.La procÃ©dure est accusatoire et contradictoire (les deux parties doivent partager les piÃ¨ces Ã  conviction).Si le principe contradictoire est violÃ© ou si une des parties ne vient pas, il y a report dâ€™audience.La procÃ©dure est gratuite (sauf frais de justice) et publique.Cependant, il est interdit de photographier ou dâ€™enregistrer un procÃ¨s.Faire gaffe Ã  Ã©teindre son tÃ©lÃ©phone portable et Ã  se lever quand il le faut.Par contre on peut ramener ses meilleurs crayons de couleurs pour dessiner la scÃ¨ne en live #siarrytraumatisme" }, { "title": "DBRE: Representation et reproduction", "url": "/cours/posts/dbre_droits_reproduction/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-24 12:00:00 +0100", "snippet": "Lien de la note HackmdPluralite dâ€™auteursCas de la pluralite dâ€™auteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelquâ€™un dâ€™autre, on peut remunerer lâ€™auteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de lâ€™auteur original est proportionnelle aux recettes.Si on utilise lâ€™image de quelquâ€™un dans un manuel de 1000 pages, il est plus rentable de sâ€™acquitter dâ€™un forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation dâ€™une oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de lâ€™oeuvre et qui vont se concerter entre elles. Ex: le developpement dâ€™un logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il nâ€™y a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent lâ€™oeuvre en ayant passe un contrat entre eux Chacun cede ses droits a lâ€™un dâ€™entre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a lâ€™initative dâ€™une personne (physique ou morale).Cette personne est invastie des droits dâ€™auteurs, et va sous son nom: Lâ€™editer La publier La divulguer Ce qui distingue lâ€™oeuvre collective et la collaboration, câ€™est les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise nâ€™arrive pas a prouver les conditions pratiques de la realisation dâ€™un projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue dâ€™un jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention dâ€™un tiers pour harmoniser les apports communs).Duree des droits dâ€™auteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits dâ€™auteurs) aussi lorsque lâ€™auteur meurt jeune Disney: utilisent des â€œrusesâ€ Peut egalement etre raccourcie Si chanson dâ€™un artiste-interprete, retombera plus vite dans le domaine publique Droits dâ€™une oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire quâ€™une oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui nâ€™utiliserai pas son droit moral ne lâ€™a pas perdu et peut le faire valoir a tout moment. Lâ€™auteur ne peut pas ceder de facon generale son droit dâ€™auteur car contraire a un principe dâ€™ordre publique. Attendu que lâ€™inaliÃ©nabilitÃ© du droit au respect de lâ€™oeuvre, principe dâ€™ordre public, sâ€™oppose Ã  ce que lâ€™auteur abandonne au cessionnaire, de faÃ§on prÃ©alable et gÃ©nÃ©rale, lâ€™apprÃ©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait Ã  ce dernier de procÃ©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas dâ€™adaptation, de changement de support ou de genre quâ€™il y a le plus de probleme avec le droit au respect." }, { "title": "ASE2: TD 3", "url": "/cours/posts/ase2_td3/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, estimateur, Fisher, FDCR, maximum de vraisemblance", "date": "2021-03-24 10:00:00 +0100", "snippet": "Lien de la note HackmdExercice 12$X_1,X_2,â€¦,X_n$ des v.a. independantes de la loi de Poisson $\\mathcal P(\\lambda=1)$.Soit $Y_n=\\sum_{k=1}^nX_k$ Determiner $\\lim_{n\\to+\\infty}P(Y_n\\le n)$ (utiliser le TCL) En deduire un equivalent simple de $\\sum_{k=0}^n\\frac{n^k}{n!}$ quand $n\\to+\\infty$ Quand on additionne des variables de Poisson independantes, on obtient une variable suivant la loi de Poisson avec comme parametre la somme de tous les parametres. Solution 1. $X_1,X_2,â€¦,X_n$ sont des v.a independantes et de meme loi, alors dâ€™apres le TCL: $\\frac{X_1+X_2+â€¦+X_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^{\\mathcal L}\\mathcal N(0,1)$\\[\\begin{cases}Y_n=\\sum_{i=1}^nX_i, E(Y_n)= \\sum_{i=1}^nE(X_i)=\\sum_{i=1}^n1=n\\\\V(Y_n)=\\sum_{i=1}^nV(X_i)=n\\Rightarrow \\sigma=\\sqrt n\\end{cases}\\\\\\frac{Y_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^L\\mathcal N(0,1)\\\\P(Y_n\\le n)=P(\\frac{Y_n-n}{\\sqrt n}\\le 0)=F_n(0)\\] ou $F_n$ est la fonction de repartition de $\\frac{Y_n-n}{\\sqrt n}$or $\\frac{Y_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^L\\mathcal N(0,1)$\\[\\begin{aligned}&amp;amp;\\Rightarrow \\lim_{n\\to+\\infty}P(Y_n\\le n)=\\lim_{n\\to+\\infty}F_n(0)=\\Phi(0) \\text{ f.d.r de } \\mathcal N(0,1)\\\\&amp;amp;\\Rightarrow \\lim_{n\\to+\\infty}P(Y_n\\le n)=\\frac{1}{2}\\end{aligned}\\] 2. La somme de v.a independantes de la loi de Poisson $\\mathcal P(1)$ suit une loi de Poisson $\\mathcal P(n)$\\[Y_n = \\sum_{k=1}^nX_k\\to\\mathcal P(n)\\\\P(Y_n\\le n)=\\sum_{k=0}^ne^{-n}\\frac{n^k}{k!}=e^{-n}\\sum_{k=0}^n\\frac{n^k}{k!}\\] Dâ€™apres la 1. $\\lim_{n\\to+\\infty}e^{-n}\\sum_{k=0}^n\\frac{n^k}{k!}=\\frac{1}{2}$ Donc\\[\\sum_{k=0}^n\\frac{n^k}{k!}\\sim\\frac{1}{2}e^n\\] avec $n$ grand Exercice 13Une entreprise compte 300 employes, chacun dâ€™entre eux telephone en moyenne 6 minutes par heures. Quel est le nombre de lignes que lâ€™entreprise doit installer pour que la probabilite que toutes les lignes soient utilisees au meme instant soit au plus egale a $0,025$. Solution Il faut definir 2 variables $N$: nombre de lignes installees $X$: nombre dâ€™employes telephonant a un instant $t$ Il faut dâ€™abord determiner la loi de $X$. La chance dâ€™avoir un employe telephonant a un instant $t$, on convertit les minutes en heure: $\\frac{6}{60} = \\frac{1}{10}$. $X$ suit donc une loi $\\mathcal B(300,\\frac{1}{10})$ On cherche $N$ la probabilite $P(X\\ge N)\\le 0,025$\\[\\mathcal B(300,\\frac{1}{10})\\simeq N(30,\\sqrt{27}) \\text{ selon le theoreme de Moivre-Laplace}\\\\U=\\frac{X-30}{\\sqrt{27}}\\simeq\\mathcal N(0,1)\\\\\\begin{aligned}P(X\\ge N)\\le0,025&amp;amp;\\Rightarrow P(U\\ge\\frac{N-30}{3\\sqrt{3}})\\le 0,025\\\\&amp;amp;\\Rightarrow1-\\Phi(\\frac{N-30+0,5}{3\\sqrt 3})\\le0,025\\\\&amp;amp;\\Rightarrow\\Phi(\\frac{N-30+0,5}{3\\sqrt 3})\\ge0,975=\\Phi(1,96)\\end{aligned}\\] ou $\\Phi$ est la fonction de repartition de la loi $\\mathcal N(0,1)$.\\[\\begin{aligned}&amp;amp;\\Leftrightarrow \\frac{N-30+0,5}{3\\sqrt 3} \\ge 1,96\\\\&amp;amp;\\Leftrightarrow N\\ge 3\\sqrt 3\\times1,96+29,5\\\\&amp;amp;\\Leftrightarrow N\\gt 40\\end{aligned}\\] Il faut installer au moins 40 lignes. Exercice 14On considere un echantillon $(X_1, X_2,â€¦,X_n)$ dâ€™une v.a. $X$.Determiner la vraisemblance de cet echantillon dans les cas ou $X$ est distribue suivant: une loi binomiale $\\mathcal B(N,p)$ une loi de Poisson $\\mathcal P(\\lambda)$ Une loi exponentielle $\\mathcal E(\\lambda)$ Une loi normale $\\mathcal N(m,\\sigma)$ Solution $(X_1,X_2,â€¦,X_n)$ un echantillon de $X$. 1. $X\\sim\\mathcal B(N,p)$ ($\\theta=p$ parametre).\\[\\begin{aligned}L(x_1,x_2,...,x_n,p)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;=\\Pi_{i=1}^n\\binom{N}{x_i}p^{x_i}(1-p)^{N-x_i}\\\\&amp;amp;= \\Pi_{i=1}^n\\frac{N!}{x_i!(N-x_i)!}p^{x_i}(1-p)^{N-x_i}\\end{aligned}\\] \\[L(x_1,x_2,...,x_n,p)=\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}p^{\\sum_{i=1}^nx_i}(1-p)^{nN-\\sum_{i=1}^nx_i}\\] 2. $X\\sim\\mathcal P(\\lambda)$ ($\\theta=\\lambda$ parametre)\\[\\begin{aligned}L(x_1,x_2,...,x_n,\\lambda)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;= \\Pi_{i=1}^ne^{-\\lambda}\\frac{\\lambda^{x_i}}{x_i!}=e^{-n\\lambda}\\frac{\\lambda^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\end{aligned}\\] \\[L(x_1,x_2,...,x_n,\\lambda)=\\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\] 3. $X\\sim\\mathcal E(\\lambda)$ (exponentielle) (variable continue), $\\theta=\\lambda$ (parametre)\\[L(x_1,x_2,...,x_n,\\lambda)=\\Pi_{i=1}^nf(x_i)=\\Pi_{i=1}^n\\lambda e^{-\\lambda x_i}\\] \\[L(x_1,x_2,...,x_n,\\lambda)=\\lambda^ne^{-\\lambda \\sum_{i=1}^nx_i}\\] 4. $X\\sim\\mathcal N(m,\\sigma)$ (variable continue), parametres $m$ et $\\sigma$\\[L(x_1,x_2,...,x_n,m,\\sigma)=\\Pi_{i=1}^nf(x_i)\\\\\\text{or } f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{X-m}{\\sigma})^2} \\text{ (densite)}\\\\L(x_1,x_2,...,x_n,m,\\sigma)=\\Pi_{i=1}^n\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{X-m}{\\sigma})^2}\\] \\[L(x_1,x_2,...,x_n,m,\\sigma) = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n}e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i-m)^2}\\] Exercice 15Soit $X$ une v.a. qui suit la loi normale centree, de variance $\\sigma^2$ inconnue ($\\sigma\\gt0$). $\\forall n\\ge 2$, on dispose dâ€™une n echantillon $(X_1,X_2,â€¦,X_n)$ des variables independantes et de meme loi que $X$.Soit $S_n=\\frac{1}{n}\\sum_{i=1}^nX_i^2$ Montrer que $S_n$ est un estimateur sans biais de $\\sigma^2$ Montrer que $S_n$ converge en probabilite vers $\\sigma^2$ Solution X v.a. normale centree $X\\to\\mathcal N(0,\\sigma)$, $\\sigma$ inconnu. $(X_1,â€¦,X_n)$ echantillon de $X$.\\[S_n=\\frac{1}{n}\\sum_{i=1}^nX_i^2\\] 1. $\\forall i$, $X_i$ suit la loi $\\mathcal N(0,\\sigma)$: $V(X_i)=E(X_i^2)$ donc\\[\\begin{aligned}E(S_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(X_i^2)=\\frac{1}{n}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n\\sigma^2=\\frac{n\\sigma^2}{n}\\\\&amp;amp;=\\sigma^2 \\text{ (sans biais)}\\end{aligned}\\] 2. Convergence de $Sn$?\\[\\begin{aligned}V(S_n) &amp;amp;= \\frac{1}{n^2}\\sum_{i=1}^nV(X_i^2)=\\frac{n}{n^2}V(X^2)\\\\&amp;amp;= \\frac{V(X^2)}{n}=\\frac{c}{n} \\quad (C=V(X^2))\\\\&amp;amp;\\Rightarrow V(S_n)\\to_{n\\to+\\infty}0\\end{aligned}\\] Dâ€™apres lâ€™inegalite de Tchebychev:\\[\\begin{aligned}\\forall \\varepsilon, &amp;amp;P(\\vert S_n-E(S_n)\\vert\\ge \\varepsilon)\\le\\frac{V(S_n)}{\\varepsilon^2}\\\\\\Rightarrow &amp;amp;P(\\vert S_n-E(S_n)\\vert \\ge\\varepsilon)\\le\\frac{c}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\end{aligned}\\] Donc:\\[S_n\\to_{n\\to+\\infty}^P\\sigma^2\\] " }, { "title": "ASE2: Convergence et estimation - 4", "url": "/cours/posts/ase2_convergence_et_estimation_4/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, poisson, normale", "date": "2021-03-24 09:00:00 +0100", "snippet": "Lien de la note HackmdEstimateurExempleOn considÃ¨re un Ã©chantillon $(X_1, X_2,â€¦,X_n)$ dâ€™une variable de Poisson de parametre $\\theta$ (inconnu)La vraisemblance de cet echantillon est:\\[L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nP(X_i=x_i)\\\\L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^ne^{-\\theta}\\frac{\\theta^{x_i}}{x_i!}=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\] Definition: On appelle quantitÃ© dâ€™information de Fisher $I_n(\\theta)$ apportÃ©e par un Ã©chantillon sur le paramÃ¨tre $\\theta$ la quantitÃ© positive:\\[I_n(\\theta)=E((\\frac{\\delta \\ln L}{\\delta\\theta})^2)\\]Proposition \\(I_n(\\theta)=-E(\\frac{\\delta^2\\ln L(x,\\theta)}{\\delta\\theta^2})\\)Demonstration $L$ etant une densite: $\\int_{\\mathbb R^n}L(x,\\theta)dx=1$ En dÃ©rivant par rapport Ã  $\\theta$: $\\int_{\\mathbb R^n}\\frac{\\delta L(x,\\theta)}{\\delta\\theta}dx=0\\quad (1)$ En remarquant que $\\frac{\\delta\\ln L(x,\\theta)}{\\delta\\theta}=\\frac{\\frac{\\delta L}{\\delta\\theta}(x,\\theta)}{L(x,\\theta)}$ $(1)$ donne $\\int_{\\mathbb R^n}\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}L(x,\\theta)dx=0$Ce qui prouve que la variable alÃ©atoire $\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}$ est centrÃ©e et que $I_n(\\theta)=V(\\frac{\\delta\\ln L}{\\delta \\theta})$DÃ©rivons une deuxiÃ¨me fois par rapport Ã  $\\theta$:\\[\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx+\\int_{\\mathbb R^n}\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}\\frac{L(x,\\theta)}{\\delta\\theta}dx=0\\\\\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx+\\int_{\\mathbb R^n}(\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta})^2L(x,\\theta)dx=0\\]Donc: \\(\\begin{aligned}I_n(\\theta)&amp;amp;=E((\\frac{\\delta \\ln L}{\\delta\\theta})^2)\\\\&amp;amp;=\\int_{\\mathbb R^n}(\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta})^2L(x,\\theta)dx\\\\&amp;amp;=-\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx\\\\&amp;amp;=-E(\\frac{\\delta^2\\ln L(x,\\theta)}{\\delta\\theta^2})\\end{aligned}\\)InÃ©galitÃ© de FRECHET-DARMOIS-CRAMER-RAO(FDCR) On a pour tout estimateur T sans biais de $\\theta$:\\[V(T)\\ge\\frac{1}{I_n(\\theta)}\\] Lâ€™estimateur T sera qualifiÃ© dâ€™efficace si la borne infÃ©rieure est atteinte, câ€™est-Ã -dire\\[V(T)=\\frac{1}{I_n(\\theta)}\\]MÃ©thode du maximum de vraisemblance Cette mÃ©thode consiste, Ã©tant donnÃ©e un Ã©chantillon de valeurs $x_1,x_2,â€¦,x_n$ Ã  prendre comme estimation de $\\theta$ la valeur de $\\theta$ qui rend maximale la vraisemblance $L(x_1,x_2,â€¦,x_n,\\theta)$ On prend comme estimation de $\\theta$ la solution de lâ€™Ã©quation de la vraisemblance\\[\\frac{\\delta \\ln L}{\\delta\\theta} = 0\\]" }, { "title": "IREN: Retropropagation du gradient", "url": "/cours/posts/iren_gradient/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8, rÃ©seaux neuronnaux", "date": "2021-03-23 11:00:00 +0100", "snippet": "Lien de la note HackmdIndex du coursRÃ©tropropagation du gradientFonction logistiqueCalculons lâ€™influence du poids $w_{2,2}^2$ sur lâ€™erreur quadratique $E:\\frac{\\delta E}{\\delta w_{2,2}^2}$La derivee partielle de $y$ par rapport a $z$ est $y(1-y)$ On note t (truth) la vraie valeur avec lâ€™erreur quadratiqueCorrectionQue vaut le gradient de $E :\\nabla E$?Quâ€™est-ce quâ€™on modifie pour arriver au bon resultat ?Les poids, on a 18 poids donc $\\nabla E$ est a dimension 18.\\[\\forall \\text{ layer }l, W^l\\leftarrow W^l-\\eta\\nabla E(W^l)\\]Pourquoi ce titre ?On fait une propagation a lâ€™envers, â€œretropropagationâ€ pour remonter lâ€™erreurLa methode du gradientLe but est de trouver le vecteur $w$ qui minimise notre erreur $E$Avec un $w_0$ choisi, lâ€™algorithme de descente du gradient est:\\[w_{t+1}=w_t-\\eta\\nabla E(W_t)\\]jusuqâ€™a atteindre un seuil choisiRepresentation graphiqueCas simple: lâ€™erreur est une fonction convexe.Si on modifie les cas apres chaque donnees, on risque dâ€™osciller travailler par paquet de donnÃ©es. $\\rightarrow$ Notion de batchLorsque lâ€™elliptiques est allongÃ©e, son gradient est quasiment orthogonal Ã  son axe long ce qui nâ€™est pas du tout la bonne direction vers le minimum. la convergence sera longueTravail sur les donneesJouer sur lâ€™echelle\\[y=w_0i_0+w_1i_1\\\\E=(y-t)^2\\]Soit comme jeux de donnees:\\[\\begin{aligned}&amp;amp;\\begin{matrix}0,1&amp;amp;10&amp;amp;\\rightarrow&amp;amp;2\\\\0,1&amp;amp;-10&amp;amp;\\rightarrow&amp;amp;2\\\\\\end{matrix}&amp;amp;\\begin{matrix}1&amp;amp;1&amp;amp;\\rightarrow&amp;amp;2\\\\1&amp;amp;-1&amp;amp;\\rightarrow&amp;amp;2\\\\\\end{matrix}\\end{aligned}\\]La fonction dâ€™erreur correspondante a la forme suivante: normaliser les donnÃ©es pour Ã©viter des fonctions dâ€™erreur Ã©crasÃ©esTranslation\\[y=w_0i_0+w_1i_1\\\\E=(y-t)^2\\]Soit comme jeux de donnees:\\[\\begin{aligned}&amp;amp;\\begin{matrix}101&amp;amp;101&amp;amp;\\rightarrow&amp;amp;2\\\\101&amp;amp;99&amp;amp;\\rightarrow&amp;amp;0\\\\\\end{matrix}&amp;amp;\\begin{matrix}1&amp;amp;1&amp;amp;\\rightarrow&amp;amp;2\\\\1&amp;amp;-1&amp;amp;\\rightarrow&amp;amp;0\\\\\\end{matrix}\\end{aligned}\\]Lâ€™erreur correspondante aux jeux de donnÃ©es a la forme suivante: centrer les donnÃ©es pour Ã©viter des fonctions dâ€™erreur Ã©crasÃ©es.Les minimums locauxUne fonction dâ€™erreur nâ€™est pas forcement elliptique, il faut sâ€™attendre a avoir des minimums locaux.Le point de convergence dÃ©pend du point de dÃ©part dâ€™oÃ¹ le risque de finirdans un minimum local. Si on lance une bille, en fonction de la ou elle se trouve elle fini dans un minimum localComment sortir dâ€™un minimum local pour rejoindre un minimum global ?Les solveursPour contrer ces differents problemes, on a differents solveursMoment et NesterovOn donne une inertie $\\alpha$ a la methode:On ne calcule pas le gradient au poids des poids, mais aux poids modifies.Nesterov propose de travailler sur les donnÃ©es mise Ã  jour:Ca peut aider a â€œsortirâ€ des trous et reduire les oscillations Si notre bille sâ€™approche dâ€™un trou, on lui dira â€œNon va pas par la, fait demi-tourâ€RMSpropLe coef dâ€™apprentissage $\\eta$ influence beaucoup la convergence.On peux choisir autant de $\\eta_i$ que de parametres existants: $\\eta_i=\\varepsilon\\mu_i\\frac{\\delta E}{\\delta \\omega_i}$Avec:Ca marche mal avec les â€œmini-batchesâ€ $9\\frac{\\delta E}{\\delta \\omega_i}$ de $0,1$ suivi dâ€™une de $-0,9$ devrait faire du surplace, mais pas avec cette methodeOn prefere moyenner les gradients dans le temps, lâ€™algorithme est:AdagradOn cherche le w aui minimise $E$, donc $\\nabla E(w)=0$Au pas de temps $t$, on est au point $w_t$, on cherche $\\delta w$ tel que $\\nabla E(w-t+\\delta w)=0$ donc avec un developpement limite:Avec $\\nabla^2E$ la matrice hessienne de $E$.Lâ€™algorithme iteratif est:Calculer lâ€™inverse de la matrice essienne est trop couteux, on va chercher quelque chose qui lui ressemble, $V_t$ pour Adagrad:Exemple de convergenceRegardons Ã  quelle vitesse convergent diffÃ©rentes mÃ©thodes suivant la formede la fonction dâ€™erreur.An overview of gradient descent optimization algorithmsTrois types de reseaux neuronauxQuelques exemples de reseaux neuronaux: reseau simple pour separer des donnees Qui a le cancer, qui ne lâ€™a pas reseau recursif pour faire des additions reseau de convolution pour comprendre une imageUne idÃ©e pour sÃ©parer les donnÃ©es sur deux cercles?SeparationRelu defini un demi-plan, on va utiliser 6 Relu $(\\nearrow)$ pour faire un cercle grossier et une sigmoide $(\\rightsquigarrow)$ pour separer les 2 cerclesRecursifOn veut calculer $0101011+1001110$, on fait comme un addition a la main On a besoin dâ€™avoir des retenues (si on a $1+1$ par exemple), câ€™est un reseau a memoire.Les cellules grises sont la memoire, cad les retenues, des operations precedentes. Ces reseau sont compliques a faire converger, il faut que la memoire fonctionne correctement.Convolution Les Convolution Neural network sont la grande reussite du deep learning.Le but est de travailler sur des images pour en extraire ses caracteristiquesEn entrÃ©e nous avons une image $N \\times N \\times 3$ (en RGB) dont nous diminuonsla surface Ã  chaque couche du rÃ©seau pour augmenter sa profondeur.Ã€ la fin on peut voir lâ€™image comme un vecteur de caractÃ©ristiques.Ensuite (pas sur le dessin) on peut utiliser un rÃ©seau neuronal classique pour classer lâ€™image.Les convolutions Un filtre est un masque dâ€™une certaine taille dont on a donnÃ© une valeur pour chacune des couchesOn fait la somme de tous les poids $\\times$ toutes les valeurs et on travaille un pixel sur 2. La taille des filtres est le nombre de canaux de lâ€™image de depart.Chacun des 5 filtres aura combien de canal ?2 car lâ€™image dâ€™arrivee a 2 canauxDiminuer la surfaceLâ€™exemple prÃ©cÃ©dent saute un pas (travailler un pixel sur 2), qui rÃ©duit la surface. Si on a pas de saut de plus de filtre $\\rightarrow$ le nombre de donnÃ©es EXPLOSE. pooling: On rÃ©duit la surface de lâ€™image au fur et a mesure quâ€™on augmente sa profondeur.Le choix du maximum est le plus utilisÃ©. On pourrait faire une moyenne mais cela risque de rÃ©duire le contraste de lâ€™image.Le Net 5Le premier CNN, qui a bien fonctionnÃ©, pour lire les codes postaux sur les enveloppes, dÃ©veloppÃ© en 90 par Yann Le CunEvolution des CNNLes reseaux augmentent en prÃ©cision, taille et nombre dâ€™opÃ©rations.De plus en plus compliquÃ©:On rajoute des trucs pour amÃ©liorer les rÃ©sultats (ou converger).Lâ€™idÃ©e est de reprendre des donnÃ©es antÃ©rieures pour ne pas trop oublier. Le saut correspond Ã  lâ€™opÃ©ration:\\[y=F(x,w)+x\\]KaggleLe Kaggle dâ€™Olivier RicouTensor FlowLe Tensor Flow Playground" }, { "title": "OCVX: Optimisation Convexe 2", "url": "/cours/posts/ocvx_kariulele_2/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:20:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Graphe de de $f: \\mathbb R \\rightarrow \\mathbb R$Calculer le pasCalcul du pas optimaltrouver $t^*$ par la minimisation de $f(x + t \\Delta x)$la tangente au graphe de $t \\overset{\\psi}{\\longrightarrow} f(x + t \\Delta x)$ en 0 est donnÃ©e par$\\psi(0) + t\\psiâ€™(0) = f(x) + t$$= f(x) + t\\nabla f(x)^T \\Delta x$On sâ€™arrete des quâ€™on trouve:$t^*$ tq$f(x + t^{*}\\Delta x) \\le f(x) + \\alpha t^{*} \\nabla f(x)^T \\Delta x$La hessienne dâ€™une fonction f en un point definit une fonction quadratique.$X \\longmapsto X^T \\underbrace{\\nabla^2f(a)}_{\\text{matrice carre (hessienne de f en a)}}X$Dire que $a \\mapsto \\nabla^2f(a)$ est majoree sur un lieu $S$ de son domaine de definition est equivalent au fait de dire que les valeurs propres (fonctions en a) de la hessienne sont des fonctions majorees. $\\forall a \\in S$ on a que les valeurs propres de la hessienne de f sont minorees par une meme constante $m &amp;gt; 0$.Strictement convexe: Non Strictement convexe:Generaliser la descente classique$f(x + v) = f(x) + \\nabla f(x)^T v + o(v)$ On remplace $f(x+v)$ par son approximation au 1er ordre; cad $f(x) + \\nabla f(x)^T v$ On cherche la direction (cad les vecteurs de norme 1 ($|.|_2)$) tq $f(x) + \\nabla f(x)^T v$ est minimal. On cherche donc a calculer $v^{*} = argmin({\\nabla f(x)^T v \\vert \\Vert v\\Vert_2 = 1})$Rq: Si $v^{*}$ minimise $\\nabla f(x)^Tv$ ssi $-v^{*}$ maximise $\\nabla f(x)^Tv$ pour $|v|_2 = 1$Rappel: Cauchy Schwarz : $\\vert\\nabla f(x)^Tv\\vert \\le \\Vert\\nabla f(x)\\Vert_2 \\Vert v\\Vert_2$$\\vert\\nabla f(x)^Tv\\vert \\le \\Vert \\nabla f(x)\\Vert_2$En prenant $v = \\frac{\\nabla f(x)}{|\\nabla f(x)|_2}$ (hyp denominateur != 0)\\(\\nabla f(x)^T v^* = \\left(\\nabla f(x)^T \\nabla f(x)\\right) x \\frac{1}{\\|\\nabla f(x)\\|_2}= \\frac{\\|\\nabla f(x)\\|_{2}^{2}}{\\|\\nabla f(x)\\|_2}= \\|\\nabla f(x)\\|_2\\)Donc pour que $v^{*}$ maximise $\\nabla f(x)^Tv^{*}$ pour $|v|_2 = 1$Ainsi $\\frac{-\\nabla f(x)}{|\\nabla f(x)|_2}$ minimise $\\nabla f(x)^Tv$ pour $\\Vert v\\Vert_2 = 1$Au lieu dâ€™utiliser une direction normalisee, pour la mise a jour, on regarde plutot $\\Delta_{x_{sd}} = |\\nabla f(x)|_2$ nsd =&amp;gt; normalized steepest descentPour la norme 1 on sâ€™interesse au calcul de:$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 = 1})$$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 \\le 1})$Ceci est un programme lineaire, ces points optimaux sont des points extremaux du lieu admissibleCes points extremaux sont les points:$\\mathcal F_{e_i}$ pour $i \\in {1,â€¦,n}$$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 \\le 1}) = I e_i$ pour un certain $i \\in {1,â€¦,n}$$\\nabla f(x)^T e_i$ est la projection de $\\nabla f(x)$ sur $e_i$ cad $\\frac{\\partial f(x)}{\\partial x_i}$ Le $e_i$ qui realise lâ€™argmin.$\\Delta x_{sd} =$ la projection de $\\nabla f(x)$ le long de $\\Delta x_{nsd}$$\\Rightarrow \\Delta x_{sd} = - \\frac{\\partial f(x)}{\\partial x_i} e_i$$\\Delta x_N = - (\\nabla^2 f(x))^{-1} (\\nabla f(x))$$f(x) + \\nabla f(x)^Tv + \\frac{1}{2}v^T\\nabla^2f(x)v = \\Psi(v)$$\\Psi$ est minimum ssi $\\nabla \\Psi(v) = 0$\\[\\nabla \\Psi(v) = \\nabla f(x) + \\nabla^2 f(x) v=&amp;gt; \\nabla \\Psi(v) = 0 &amp;lt;=&amp;gt; \\nabla^2 f(x) v = - \\nabla f(x)\\]" }, { "title": "OCVX: Optimisation Convexe 1, suite", "url": "/cours/posts/ocvx_kariulele_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:10:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!) Trouver lâ€™extremum dâ€™une parabole $f(x) = ax^2 + bx +c \\qquad a &amp;gt; 0$$fâ€™(x) = 2ax +b$$x^{*} \\qquad tq fâ€™(x^{*}) = 0$$2ax^{*} + b = 0$$x^{*} = -\\frac {-b}{2a}$\\[\\begin{aligned}f^{*} &amp;amp;= f(x^{*})\\\\&amp;amp;= a \\left(-\\frac{b} {2a}\\right)^2 + b\\left(-\\frac{b}{2a}\\right) + c\\\\&amp;amp;= \\frac{b^2}{4a}- \\frac{b^2}{2a} +c\\\\&amp;amp;= -\\frac{b^2}{4a} + c\\end{aligned}\\]$f: \\mathbb R \\longrightarrow \\mathbb R$f est dÃ©rivable en $x_0$ : $\\underset{h \\rightarrow 0}{lim} \\frac{f(x+h) - f(x)}{h}$ est finie.Et $\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} = fâ€™(x_0)$$\\underset{h \\rightarrow x_0}{lim} \\frac{f(x)-f(x_0)}{x - x_0}$$f = o_{x_0}(g)$ $f$ est nÃ©gligeable par rapport Ã  $g$ en $x_0$.$\\Leftrightarrow$ Il existe une fonction $\\varepsilon : \\mathbb R \\rightarrow R$ avec $\\varepsilon(x) \\underset{x \\rightarrow x_0}{\\longrightarrow} 0$Et $f(x) = \\varepsilon(x)g(x)$ au voisinage de $x_0$.Si $g$ ne sâ€™annule pas au voisinage de $x_0$$f=o_{x_0}(g) \\Leftrightarrow \\underset{x \\rightarrow x_0}{lim} \\frac{f(x)}{g(x)} = 0$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} = fâ€™(x_0)$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} - \\frac{hfâ€™(x_0)}{h} = 0$soit $\\varepsilon : \\mathbb R \\longrightarrow \\mathbb R$tq $\\underset{h \\rightarrow 0}{\\varepsilon (h) \\rightarrow 0}$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0) - hfâ€™(x_0)}{h} = \\underset{h \\rightarrow 0}{lim} \\space\\varepsilon (h) = 0$$\\frac {f(x_0 + h) -f(x_0) - hfâ€™(x_0)}{h} = \\varepsilon(h)$$f(x_0 + h) -f(x_0) - hfâ€™(x_0) = h\\varepsilon(h)$$f(x_0 + h) = f(x_0) + hfâ€™(x_0) + h\\varepsilon(h) = f(x_0) + hfâ€™(x_0) + o_0(h)$$f(x) = f(x) + (x - x_0)fâ€™(x_0) + (x - x_0) \\underbrace{\\varepsilon(x - x_0)}_{o_0(x- x_0)}$$f: \\mathbb R^n \\longrightarrow \\mathbb R$$x = \\begin{pmatrix}x_1 \\ \\vdots \\ x_n \\end{pmatrix} \\longmapsto f(x_1, \\dots, x_n)$$f(x_1, â€¦ , x_n) = x_1 + x_2 + â€¦ + x_n$La $k^{iÃ¨me}$ dÃ©rivÃ©e partielle de f existe en $x_0 \\in \\mathbb R^n$$\\Leftrightarrow$ la fonction $\\underset{t \\rightarrow f(x_0,â€¦,x_n)}{\\varphi :\\ \\mathbb R \\rightarrow \\mathbb R}$ est dÃ©rivable en 0et $\\varphiâ€™(0) = \\frac{\\partial f}{\\partial x_k}(x_0) \\Leftrightarrow \\partial k f(x_0)$$f(x,y) = \\begin{cases}\\frac{xy}{x^2 + y^2} \\space \\text{ si } (x,y) \\ne (0,0) 0 \\qquad \\text{ si } (x,y) = (0,0)\\end{cases}$\\begin{aligned}\\frac{\\partial f}{\\partial x}(x,y) &amp;amp;= \\frac{\\partial}{\\partial x}\\left(\\frac{xy}{x^2 + y^2}\\right) &amp;amp;= y \\frac{\\partial}{\\partial x} \\left( \\frac{x}{x^2 + y^2} \\right) &amp;amp;= y \\frac{x^2 + y^2 -x(2x)}{(x^2 + y^2)^2} &amp;amp;= y \\frac{y^2 - x^2}{(x^2 + y ^2)^2}\\end{aligned}$\\frac{\\partial f}{\\partial x} (t,0) = 0 \\qquad \\frac{\\partial f}{\\partial y}(0,t) = 0$$\\frac{\\partial f}{\\partial x}(x,y) \\Leftrightarrow$ on dÃ©rive selon lâ€™axe $(o_x)$$\\Leftrightarrow$ on dÃ©rive selon le vecteur $e_x = (1,0)$$\\frac{\\partial f}{\\partial y}(x,y) \\Leftrightarrow$ on dÃ©rive selon lâ€™axe $(o_y)$La derivee directionnelleDans le cas de $n$ variables :$f:\\mathbb R^n \\longrightarrow \\mathbb R$$\\frac{\\partial f}{\\partial x_k}(x)$ = on dÃ©rive par rapport Ã  la $k^{iÃ¨me}$ variable$\\Leftrightarrow$ on dÃ©rive selon la $k^{iÃ¨me}$ variable$\\Leftrightarrow$ on dÃ©rive selon le vecteur $ek = (0, \\dots, o, \\underbrace{1}_{k^{iÃ¨me}}, 0, \\dots, 0)$ DÃ©finition : On appelle dÃ©rivÃ©e directionnelle de $f$ en $x_0$ suivant le vecteur $h \\in \\mathbb R^2$ et on note $D_hf(x_0)$ la dÃ©rivÃ©e en 0 de la fonction \\(\\varphi : \\begin{aligned}\\mathbb R &amp;amp; \\longrightarrow \\mathbb R\\\\t &amp;amp;\\longmapsto f(x_0 + th)\\end{aligned}\\)$\\frac{\\partial f}{\\partial x}(x_0) \\equiv$ derivee de\\[\\varphi :\\begin{aligned}\\mathbb R &amp;amp; \\rightarrow \\mathbb R\\\\t &amp;amp;\\longmapsto \\underbrace{f(x_{01} +, \\dots, x_{0k+t}, \\dots, x_{0n})}_{\\begin{pmatrix}x_{01} \\\\ \\vdots\\\\ x_{0n}\\end{pmatrix} + t\\begin{pmatrix}0 \\\\ \\vdots \\\\ 1 \\rightarrow k^e\\\\ \\vdots \\\\ 0\\end{pmatrix}}\\end{aligned}\\]$f: \\mathbb R^2 \\longrightarrow R \\qquad \\space \\qquad x_0=(1,2)$$(x,y) \\longmapsto x^2 - y^2 \\qquad h=(3,5)$$\\varphi : \\mathbb R \\longrightarrow \\mathbb R$$t \\longmapsto f(x_0 + th)$$\\varphi(t) = f\\left(\\begin{pmatrix}1 \\ 2 \\end{pmatrix} + t \\begin{pmatrix}3 \\ 5\\end{pmatrix}\\right)$$= f(1+3t, 2+ 5t)$$= (1 +3t)^2 - (2 + 5t)^2$$= 1 + 6t + 9t^2 -(4 - 20t + 25t^2)$$= -3 - 14t - 16t^2$$\\varphi â€˜(t) = -14 -32t$$\\varphi â€˜(0) = -14 = D_h(x)$$h \\leftrightarrow \\alpha h$$D_{\\alpha h}f(x_0) = \\alpha D_hf(x_0)$On parle de dÃ©rivÃ©e directionnelle selon la direction de $h \\in \\mathbb R^n \\verb++ {0}$ uniquement quand $h$ est unitaire (par opposition Ã  la dÃ©rivÃ©e directionnelle selon le vecteur $h$).Malheureusement, lâ€™existence de derivees directionnelles en $Vn$ point selon tout vecteur nâ€™implique pas la continuitÃ© en ce point.$f(x,y) = \\begin{cases}\\frac {y^2}{x} \\qquad x \\ne 0y \\space\\space\\qquad x = 0\\end{cases}$En $(0,0)$ soit $h = \\begin{pmatrix} h_1 \\ h_2\\end{pmatrix} \\ne (0,0)$\\begin{aligned}\\varphi(t) = f(th) = f(th_1, th_2)&amp;amp;= \\begin{cases} \\frac{(th_2)^2}{th_1} \\qquad\\space\\space h \\neq 0th_2 \\qquad\\quad\\ h = 0\\end{cases}&amp;amp;= \\begin{cases} t\\frac{h_2^2}{h_1} \\qquad\\space\\space h \\neq 0th_2 \\qquad\\quad\\ h = 0\\end{cases}\\end{aligned}$\\varphi â€˜(t) = \\begin{cases} \\frac{h_2^2}{h_1} \\qquad h_1 \\ne 0 h_2 \\qquad h_1 = 0\\end{cases}$ = $\\varphi â€˜(0)$si $g$ est continue en $0$ et $f$ continue en $g(0)$ alors $f \\circ g$ est continue en $0$$g: \\mathbb R \\longrightarrow \\mathbb R^2$$t \\longmapsto (t^2, t)$$f \\circ g : \\mathbb R \\longrightarrow \\mathbb R^2$$t \\longmapsto f \\circ g(t) = f(g(t))$$f(g(t)) = f(t^2, t) = \\begin{cases}\\frac{t^2}{t^2} \\qquad t \\neq 00 \\qquad\\space t = 0\\end{cases}$$f \\circ g(t) = \\begin{cases}1 \\qquad\\space t \\neq 00 \\qquad\\space t = 0\\end{cases}$Donc $f \\circ g$ pas continue en $0$$\\Rightarrow f$ pas continue en $g(0) = (0,0)$$f(x_0 +h) = f(x_0) + hfâ€™(x_0) + \\begin{cases}o_0(h)\\ h \\varepsilon(h) \\text{ avec } \\varepsilon(h) \\qquad \\varepsilon (h) \\underset{h \\rightarrow 0}{ \\longrightarrow} 0\\end{cases}$ DÃ©finition : On dit que $f: \\mathbb R^n \\longrightarrow \\mathbb R$ est differentiable de $x_0$ ssi il existe une application linÃ©aire $d_{x_0}f$ (aussi notÃ© $df_{x_0}$) tq $f(x_0 + h) = f(x_0) + d_{x_0}f(h) + \\underset{||H|| \\varepsilon (h)}{o_0(h)}$$h \\mapsto h fâ€™(x_0)$ est linÃ©raire $\\varepsilon : \\mathbb R^n \\longrightarrow \\mathbb R$$d_{x_0} f:h \\mapsto d_{x_0}f(h) = h \\times fâ€™(x_0)$ PropriÃ©tÃ© : Si $f$ est diffÃ©rentiable en $x_0$ alors $f$ est continue en $x_0$PropriÃ©tÃ© : Si $f$ est diffÃ©rentiable en $x_0$ alors $f$ admet des dÃ©rivÃ©es directionnelles selon tout vecteur $h \\in \\mathbb R^n \\verb++ {0}$, et la dÃ©rivÃ©e directionnelle vaut $D_hf(x_0) = d_{x_0}f(h)$Soit $f$ diffÃ©rentiable en $x_0$.Donc les dÃ©rivÃ©es partielles $\\frac{\\partial f}{\\partial x_k}$ existent en $x_0$Soit $h \\in \\mathbb R^n \\verb++ {0}$ et $(e_1, \\dots , e_n)$ la base$h = \\begin{pmatrix} h_1 \\ \\vdots \\ h_n\\end{pmatrix} = \\sum_{i = 1}^{n} h_i e_i$$D_hf(x_0) = d_{x_0}f(h) = d_{x_0}f(\\overset{n}{\\underset{i=1}{\\sum}} h_ie_i) = \\overset{n}{\\underset{i=1}{\\sum}} h_i d_{x_0}f(e_i)=\\overset{n}{\\underset{i=1}{\\sum}} h_i \\frac{\\partial f}{\\partial x_i}x_0$$d_{x_0}f(h) = \\langle \\nabla f(x_0), h \\rangle$Soit $f:\\mathbb R^n \\rightarrow \\mathbb R$on dÃ©finit le vecteur gradient de $f$ en $x_0$ par$\\nabla f(x_0) = \\begin{pmatrix}\\frac{\\partial f}{\\partial x_1}(x_0) \\vdots \\frac{\\partial f}{\\partial x_n}(x_0)\\end{pmatrix}$Si $f$ diffÃ©rentiable en $x_0$, alors $d_{x_0} f:h \\longmapsto \\langle \\nabla f(x), h \\rangle$$d_{x_0} :h \\longmapsto h f(x_0)$Soit \\(f: \\begin{aligned}\\mathbb R^n &amp;amp;\\longmapsto \\mathbb R^p\\\\x = (x_1, \\ldots, x_n) &amp;amp; \\longmapsto f(x) = (f_1(x), \\ldots, f_p(x))\\end{aligned}\\)Soit $x_0 \\in \\mathbb R^n$ et $f$ diffÃ©rentiable en $x_0$Les $f_1,\\dots, f_p$ sont diffÃ©rentiables en $x_0$Soit $h \\in \\mathbb R^n \\qquad \\overbrace{f(x + h)}^{\\in \\mathbb R^p} = \\overbrace{f(x_0)}^{\\in \\mathbb R^p} + \\overbrace{d_{x_0}f(h)}^{\\in \\mathbb R^P} + o_0(h)$\\[\\begin{pmatrix} f_1(x_0 + h) \\\\ \\vdots \\\\ f_p(x_0 + h)\\end{pmatrix} =\\begin{pmatrix} f_1(x_0) \\\\ \\vdots \\\\ f_p(x_0)\\end{pmatrix} +\\begin{pmatrix}d x_0 f_1( h) \\\\ \\vdots \\\\d x_0 f_p(h)\\end{pmatrix} + o_0(h)\\]\\[f(x_0 +h) = f(x_0) + \\begin{pmatrix} \\langle \\nabla f_1(x_0), h \\rangle\\\\ \\vdots \\\\ \\langle \\nabla f_p(x_0), h \\rangle \\end{pmatrix} + o_0(h)\\]\\[\\langle \\nabla f_i(x_0),h \\rangle = \\nabla f_i(x_0)^T h = \\left(\\frac{\\partial f_i}{\\partial x_1}(x_0), \\ldots, \\frac{\\partial f_i}{\\partial x_n}(x_0)\\right)\\begin{pmatrix}h_1 \\\\ \\vdots \\\\ h_n\\end{pmatrix}\\qquad \\frac{\\partial f_i}{\\partial x_j}(x_0) = \\partial_j f_i(x_0)\\]\\[f(x_0+h) = f(x_0) + \\begin{pmatrix} (\\partial_1 f_1(x_0) \\dots \\dots \\partial_n f_1(x_0))h \\\\ \\vdots \\\\ (\\partial_1 f_p(x_0) \\dots \\dots \\partial_n f_p(x_0))h \\end{pmatrix} + o_0(h)\\]\\[\\text{les p composantes de f :}\\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1}(x_0)&amp;amp; \\dots&amp;amp; \\frac{\\partial f_1}{\\partial x_n}(x_0)\\\\ \\vdots &amp;amp; &amp;amp; \\vdots \\\\\\frac{\\partial f_p}{\\partial x_1}(x_0)&amp;amp; \\dots&amp;amp; \\frac{\\partial f_p}{\\partial x_n}(x_0)\\end{pmatrix} \\begin{pmatrix} h_1 \\\\ \\vdots \\\\ h_n\\end{pmatrix}\\]On appelle jacobienne de $f$ en $x_0 = (u_1, \\ldots, u_n)\\begin{pmatrix}v_1 \\ \\vdots \\ v_n\\end{pmatrix}$ la matrice :\\(\\mathcal J_{x_0}f = \\left[\\frac{\\partial f_i}{\\partial x_j}(x_0)\\right]_{\\begin{aligned}i &amp;amp;= 1, \\ldots, p\\\\ j &amp;amp;= 1, \\ldots, n\\end{aligned}}\\)Telle que \\(\\underbrace{f(x_0 + h)}_{\\in \\mathbb R^p} = \\underbrace{(x_0)}_{\\in \\mathbb R^p} + \\underbrace{\\underbrace{\\mathcal J_ {x_0}f}_ {\\in \\mathbb M_{p,n}(\\mathbb R)} \\times\\underbrace{h}_ {\\in \\mathbb R^p}}_{\\in \\mathbb R^p} + o_0(h)\\)$d_{x_0}f: h \\longmapsto \\mathcal J_{x_0}f \\times h$ est bien linÃ©aireSoit $f:\\mathbb R^n \\rightarrow \\mathbb R^p$ differentiable en $x_0 \\in \\mathbb R^n$Soit $g:\\mathbb R^p \\rightarrow \\mathbb R^n$ differentiable en $f(x_0) \\in \\mathbb R^p$Alors la composee $g \\circ f = d_{f(x_0)} g \\circ d_{x_0} f$Avec les jacobiennes $\\mathcal J_{x_0} g \\circ f = \\mathcal J_{f(x_0)} g {\\times}^{\\text{produit matriciel}} \\mathcal J_{x_0}f$$(g \\circ f)â€™ = fâ€™ \\times (gâ€™ \\circ f)$$(g \\circ f)(x) = g(f(x))$$(g \\circ fâ€™)(x) = fâ€™(x) \\times gâ€™(f(x))$InterprÃ©tation gÃ©omÃ©trique du gradientOn se limite dÃ©sormais au cas des fonctions convexes.Quand les resultats Ã©noncÃ©s sâ€™appliquent Ã  un cadre plus gÃ©nÃ©ral que lâ€™on spÃ©cifiera. Les questions auxquelles on nâ€™a pas encore de rÃ©ponses gÃ©nÃ©rales : â€œDirectionâ€ de minimisation dâ€™une fonction objectif Trouver des hyperplans dâ€™appui au lieu admissible dâ€™un problÃ¨me dâ€™optimisation Câ€™est la proposition suivante qui permet dâ€™apport une rÃ©ponse Ã  ces 2 questions : Proposition :Soit $f:U \\subset \\mathbb R^N \\longrightarrow \\mathbb R$ fonction convexe et diffÃ©rentiable en $a \\in U$. $\\nabla f(a)$ dÃ©finit un hyperplan dâ€™appui Ã  $\\mathcal C_{\\le r}(f) (r = f(a))$ [Q 4-33]On cherche Ã  rÃ©soudre le problÃ¨me de minimisation : $\\min f_0(x,y)= 2x + y$sujet Ã  : $3x^2 + y^2 \\leqslant 4$Pour minimiser $f_0$ on part vers la â€œgaucheâ€ du dessin ; vers la direction opposÃ©e au gradient de $f_0$.La position â€œlimiteâ€ de ces courbes de niveaux (la courbe de niveau qui rÃ©alise la valeur optimale) correspond Ã  un hyperplan dâ€™appui.$\\mathbb{A}$ est le sous-niveau de niveau 4 de $f_1(x, y) = 3x^2+y^2$\\(\\nabla f_1(x, y) = \\begin{pmatrix}6x \\\\ 2y\\end{pmatrix}\\)On cherche donc un point (x, y) tel que :\\(\\nabla f_1(x, y) + \\lambda \\nabla f_0(x, y) = 0 \\qquad \\text{avec } \\lambda \\geqslant 0\\)Pour trouver (x,y) on cherche a resoudre: $\\begin{cases}\\begin{pmatrix} 6x\\ 2y\\end{pmatrix} = -\\lambda \\begin{pmatrix} 2\\ 1\\end{pmatrix} 3x^2 +y^2 =4 \\end{cases}$Des deux premiÃ¨res Ã©quations on obtient:\\(x=-\\frac{\\lambda}{3}, y=-\\frac{\\lambda}{2}\\)En rÃ©injectant dans la deuxiÃ¨me Ã©quation :\\(x=-\\frac{1}{\\sqrt{21}}, y=-2\\sqrt{\\frac{3}{7}}\\) DÃ©finition :Avec les notations de la proposition on appelle espace tangeant Ã  $\\mathcal C_{r}(f)$ en a lâ€™espace affine.\\begin{aligned}T_a(f) &amp;amp;= a + \\nabla f(a)^\\bot&amp;amp;= a+ {x | \\nabla f(a)^\\top x = 0}\\end{aligned}La proposition donne, telle quelle, la rÃ©ponse Ã  la question 2. posÃ©e ci-dessus. Elle suggÃ¨re Ã©galement une direction vers laquelle minimiser la valeur objectif de f. On suppose que $\\nabla f(a)\\neq 0$, on regarde $-t\\nabla f(a)$ avec $t &amp;gt; 0$.Pour $t$ proche de 0,\\(f(u | \\nabla f(a))-f(a)=\\nabla f(a)^\\top(-t\\nabla f(a)) + ||t\\nabla f(a)||\\epsilon(\\nabla f(a))\\)le $O_o(t)$ est nÃ©gligable devant $-t\\nabla f(a)^\\top \\nabla f(a)=-t||\\nabla f(a)||^2_2$Lâ€™expression $f(a-t\\nabla f(a))=f(a)$ est du signe de $-t||\\nabla f(a)||^2_2$. Pour $t$ assez pertit\\(f(a -t\\nabla f(a)) \\leqslant f(a)\\) Remarque : Lâ€™Ã©tude prÃ©cÃ©dente est contrainte par le fait â€œ$t$ assez petitâ€. Ca donne une idÃ©e de direction du min, pas une garantie. Lâ€™Ã©tude ci-dessus ne nÃ©cessite pas de convexitÃ©. Caracteristique du premier ordre de la convexite :$f: T \\subset \\mathbb R^b \\longmapsto \\mathbb R$ est convexe si: $U$ est convexe $\\forall x,y \\in U, f(y) - f(x) \\geqslant \\nabla f(x)^T(y - x)$En supposant cette caracterisation VRAIE :Soit $y \\in \\mathcal C_{\\le r}(f);$ on veut montrer $\\nabla f(x)^T(y -x) \\le 0$Or comme f est convexe on a :\\(\\nabla f(x)^T(y-x) \\leqslant \\underbrace{f(y)}_{\\le r}\\underbrace{(fx)}_{=r}\\)dâ€™ ou $\\nabla f(x)^T (y-x) \\leqslant 0$Preuve de la caractÃ©risation de convexitÃ©Convexe $\\Leftrightarrow$ ($\\nabla$ convexe)Soient $x,y \\in U, t \\in [0,1]$On regarde la fonction\\(g(t) = f((1-t)x + ty)\\)La definition de convexite de f :\\[\\begin{matrix} &amp;amp; f((1-t) x + t(y)) &amp;amp; \\leqslant &amp;amp; (1-t)f(x) + tf(y)\\\\\\Leftrightarrow &amp;amp; g(t) &amp;amp; \\leqslant &amp;amp; (1-t)g(0) + g(1)\\\\\\Leftrightarrow &amp;amp; g(t) - g(0) &amp;amp; \\leqslant &amp;amp; t(g(1) - g(0))\\\\\\Leftrightarrow &amp;amp; \\frac{g(t) - g(0)}{t} &amp;amp; \\leqslant &amp;amp; g(1) - g(0)\\\\\\Rightarrow &amp;amp; g(0) &amp;amp; \\leqslant &amp;amp; f(y) - f(x)\\end{matrix}\\]Or $g(0) \\nabla f(x)^T(y -x)$Dâ€™ou $\\color{green}{\\boxed{\\nabla f(x)â€™(y-x) \\leqslant f(y) - f(x)}}$($\\nabla$ convexe) et $U$ convexe $\\Rightarrow$ convexeSoient $x,y \\in U \\qquad z_t = (1 - t)x + ty$\\[\\begin{aligned}t \\times [f(y)- f(z_t)] &amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)^\\top(y -z_t)\\\\(1-t) \\times [f(x) - f(z_t) &amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)(x-z_t)]\\\\tf(y) + (1-t)f(x) + tf(z_t) - (1 -t)f(z_t)&amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)(t(y -z_t) + (1-t)(x - z_t)) \\color{orange}{(D)}\\end{aligned}\\]$\\color{orange}{(D)}$ :$\\nabla f(z_t)(ty + (Lt)x -z_t) = 0$$(D) = 0$$(G):$\\begin{aligned}&amp;amp;tf(y) + (1-t)f(x) + f(z_t)&amp;amp;= tf(y) + (1-t)f(x) + f(ty + (1-t)x)\\end{aligned} Exercice :Trouver les points sur le paraboloÃ¯de $z = 4x^2 + y^2$ oÃ¹ le plan tangent est parallÃ¨le au plan $x + 2y + z = 6$.De mÃªme pour le plan $3x + 5y - 2z = 5$ProblÃ¨mes dâ€™optimisationCatÃ©gorie des problÃ¨mes convexes Convention :pour simplifier la notation on note $f : \\mathbb R^n \\longrightarrow \\mathbb R$ une fonction qui nâ€™est pas nÃ©cessairement, dÃ©finie sur $\\mathbb R^n$ DÃ©finition :Un problÃ¨me dâ€™optimisation convexe est un problÃ¨me qui sâ€™exprime sous la forme $\\min f_0(x)$, sujet Ã :\\(f_i(x) \\leqslant 0 \\: \\forall i \\in \\{1,\\dots,m\\}\\\\f_j(x) = 0 \\: \\forall j \\in \\{1,\\dots, p\\}\\) OÃ¹ $f_0, f_i, h_j : \\mathbb R^n \\longrightarrow \\mathbb R$ sont convexes et de plus les $h_j$ sont affines.On peut en particulier rÃ©Ã©crire $(P)$ sous la forme: $\\min f_0(x)$ sujet Ã  :\\(\\begin{aligned}f_i(x) &amp;amp;\\leqslant 0 \\: \\forall i \\in \\{1,...,m\\}\\\\A x &amp;amp;= b\\end{aligned}\\)oÃ¹ $\\mathcal A \\in M_{p,n}(\\mathbb R); b \\in M_{p,1}(\\mathbb R)$On dit quâ€™un point $x$ est admissible sâ€™il satisfait les contraintes dÃ©finies par $(P)$. Le lieu admissible $\\mathcal A$ de $(P)$ correspond aux points admissibles de $(P)$. On fait remarquer que sous nos hypotheses, $\\mathcal A$ est convexe. On note $p^{*}$ la valeur optimale de $(P)$:\\(p^{*} = \\underset{x \\in \\mathcal A}{inf}\\{f_0(x)\\}\\)Par convention si $\\mathcal A = \\emptyset; p^{*} = +\\infty$. Dans le cas sur $p^{*} = - \\infty$ on dit que ($P$) est non bornÃ©.On appelle enfin point optimal $x^{*}$ de $(P)$ tout point tq $f_0(x^{*}) = p^{*}$. Un tel point nâ€™existe pas toujours; par exemple câ€™est le cas $\\underset{x \\in \\mathbb{R}_+^{*}}{min} \\frac{1}{x}$. De plus, il nâ€™existe pas en gÃ©nÃ©ral quâ€™un seul point optimal (quand il y en a); prendre par exemple le problÃ¨me:\\(\\underset{x \\in \\mathbb{R}}{min} 10\\)Lâ€™Ã©criture de ($P$) dans la dÃ©finition est appelÃ©e standard dâ€™un problÃ¨me dâ€™optimisation. Il existe une notion thÃ©orique dâ€™Ã©quivalence de problÃ¨me dâ€™optimisation, On ne rentrera pas dans le dÃ©tail, sachez quâ€™elle consiste Ã  rÃ©exprimer un problÃ¨me dâ€™optimisation de faÃ§on Ã  le rÃ©soudre plus facilement. Exemple :$\\min |x|$ sujet Ã :\\(\\begin{aligned}x - 2 &amp;amp;\\leqslant 0 \\qquad (P_1)\\\\-x -2 &amp;amp;\\leqslant 0\\end{aligned}\\)$P_1$ est Ã©quivalent Ã : $\\min -x^2$ sujet Ã :\\(\\begin{aligned}x - 2 &amp;amp;\\leqslant 0\\\\-x -2 &amp;amp;\\leqslant 0\\end{aligned}\\)Pourquoi la convexitÃ© ?unicitÃ© du minimumSoit $f: \\mathbb R^n \\longrightarrow \\mathbb R$ une fonction convexe, alors $f$ : nâ€™admet pas de maximum locaux strictes. Admet au plus un minimum local stricte.Essayons de justifier le premier point. Supposons quâ€™il existe un voisinage $\\mathcal{B}(x, \\varepsilon)$ pour $\\varepsilon &amp;gt;0$ tq :\\(\\forall y \\in \\mathcal{B}(x, \\varepsilon), y \\neq x f(y) &amp;lt; f(x)\\)Soient $y_1,y_2 \\in \\mathcal{B}(x, \\varepsilon) \\backslash {x}$$\\forall t \\in [0,1]$(conv):$f(ty_1 + (1-t)y_2) \\leqslant tf(y_1) + (1-t) f(y_2)$Donc $tf(y_1) + (1 -t)f(y_2) \\leqslant f(x)$car $f(y_1) \\leqslant f(x)$ et $f(y_2) \\leqslant f(x)$La condition prÃ©cÃ©dente exprime le fait que la sÃ©cante au graphe de f sur $\\mathcal{B}(x, \\epsilon)$ est en dessous de celui ci, donc pas dans lâ€™Ã©pigraphe de f. Dans ce cas f nâ€™est pas convexe.Pour le second point:si $y_1, y_2$ sont 2 minimaux locaux et diffÃ©rents, on retrouve la situation qui contredit la convexitÃ©.Condition dâ€™existance dâ€™un minimum sous contraintesSi on est dans la situation suivante PropriÃ©tÃ© :Un point $x \\in \\mathcal A$ est optimal si:\\[\\nabla f(x^{*} )^\\top(y.x) \\geqslant 0\\] $-\\nabla f_0(x^{*})^\\top(y-x) \\leqslant 0$$-\\nabla f_0(x^{*})$ dÃ©finit un hyperplan dâ€™appui en $x^{*}$ Ã  $\\mathcal A$. Preuve :Supposons $x^{*}$ satisfait $(op)$.Dâ€™aprÃ¨s les inÃ©galitÃ©s de convexitÃ© sur $f_0$ on a:\\(\\forall y \\in \\mathcal A; \\nabla f_0(x^{*})^\\top(y-x^{*}) \\leqslant f(y) - f(x)\\)Dâ€™aprÃ¨s $(op)$:\\(f(y) - f(x^{*}) \\geqslant 0 \\Leftrightarrow f(y) \\geqslant f(x^{*})\\)La rÃ©ciproque se fait par contraposition. On la laisse de cÃ´tÃ© pour cette fois.Est-ce que lâ€™hypothÃ¨se de convexitÃ© de $(P)$ sur tout son domaine de dÃ©finition est important ? $\\rightarrow$ Matheux dans sa tÃªte : OUI$\\rightarrow$ Informaticien (matheux qui fait calculer) : BAH â€¦ CON vexe ?Cas sans contrainteOn sâ€™intÃ©resse en un premier temps au problÃ¨me dâ€™optimisation de la forme:\\(\\underset{x \\in \\mathbb R^n}{\\min} f_0(x)\\)avec $f_0$ diffÃ©rentiable PropriÃ©tÃ© :Si $x^{*}$ est un point optimal de $f_0$ alors:\\(\\nabla f_0(x^{*}) = \\underline{0}\\) Preuve :On se place sur un voisinage $\\mathcal B(x^{*}, \\varepsilon)$ pour $\\varepsilon \\gt 0$ oÃ¹ $\\forall y \\in \\mathcal B(x^{*}, \\varepsilon); f_0(y) \\geqslant f_0 (x^{*})$ En particulier pour le h assez proche de 0: \\(\\begin{aligned}&amp;amp;f_0(x^{*} + h) -f_0(x^{*}) &amp;amp;\\geqslant 0\\\\\\Rightarrow &amp;amp;\\nabla f_0(x^{*})^T h + \\theta_0 &amp;amp;\\geqslant 0\\end{aligned}\\)Ainsi $\\forall h \\in \\mathcal{B}(\\underline{0}, \\eta)$ pour $\\eta &amp;gt; 0$ \\(\\nabla f_0(x^{*})^T \\geqslant 0\\)La seule application linÃ©aire qui est possible sur un voisinage $\\mathcal B(\\underline{0}, \\eta)$ est lâ€™application nulle.Dans le cas $f_0$ convexe, lâ€™annulation du gradient en un point va nous limiter Ã  un sous-lieu de points optimaux Ã  Ã©tudier. En rÃ©alitÃ©, on a en gÃ©nÃ©ral la situation suivante: Les points critiques dâ€™une fonction $f_0$ quelconque sont de lâ€™une des trois formes suivantes: Minimum locaux. Maximums locaux. Points selles. Dans le cas convexe on a que des points du premier type. Dans ce cas lâ€™Ã©tude des points critiques se confond avec celle des points minimaux.ProblÃ¨me du dualSoit P le problÃ¨me dâ€™optimisation: \\(\\min f_0(x)\\)sujet Ã \\(f_i(x) \\leqslant 0\\\\h_j(x) = 0\\)Si on voulait ramener lâ€™Ã©tude de $(P)$ Ã  la minimisaion dâ€™une seule fonction on pourrait Ã©tudier:\\(\\Phi(x) = f_0(x) + \\sum_{i=1}^n I_+(f_i(x)) + \\sum_{j=0}^pI_0(f_j(x))\\)oÃ¹\\(\\begin{aligned}I_+ (x) &amp;amp;= \\begin{cases}0 \\text{ si } x \\leqslant 0\\\\+\\infty \\text{ sinon}\\end{cases}\\\\I_0 (x) &amp;amp;= \\begin{cases}0 \\text{ si } x = 0\\\\+\\infty \\text{ sinon}\\end{cases}\\end{aligned}\\)ProblÃ¨me dâ€™optimisation Ã©quivalent Ã  $(P)$ mais inutilisable DÃ©finition :On appelle Lagrangien du problÃ¨me ($P$) la fonction: \\(\\mathcal L_P (\\underset{\\in \\mathbb R^n}{x}, \\underset{\\in \\mathbb R^m}{\\lambda},\\underset{\\in \\mathbb R^p}{\\nu}) = f_0(x) + \\sum_{i=1}^n \\lambda_i f_i(x) + \\sum_{j=0}^p \\nu_j f_j(x)\\)On dÃ©finit le problÃ¨me dual $(\\check{P})$ de $(P)$ comme suit: on note:\\[g(\\lambda, \\nu ) = \\underset{x \\in \\mathbb R^n}{inf} \\mathcal L(x,\\lambda, \\nu)\\]avec cette notation:\\[\\underset{\\lambda, \\nu}{max} g(\\lambda, \\nu) \\qquad (\\check P)\\\\\\text{sujet Ã } \\quad \\lambda \\geqslant 0\\]Remarque: $g(\\lambda, \\nu)$ pour $\\lambda \\geqslant 0$ est lâ€™$inf$ dâ€™une fonction concave. (affines en les $\\lambda$ et $\\nu$) câ€™est donc concave (exo bribes de gÃ©ometries)Donc $(\\check{P})$ est toujours un problÃ¨me convexe. PropriÃ©tÃ© :\\(\\forall \\lambda \\geqslant 0 \\text{; on a : } g(\\lambda, \\nu) \\leqslant p^{*}\\) Preuve :Soit $x$ un point admissible de ($P$). on a donc $f_i \\leqslant 0$ et $h_j(x) = 0$.Donc \\(\\sum_{i= 1}^m d_if_i(x) + \\sum_{j = 1}^P \\nu_jh_j(x) \\leqslant 0 \\: \\forall \\qquad \\lambda \\geqslant 0\\)Dâ€™oÃ¹:\\(\\begin{aligned}&amp;amp;\\mathcal L_p(x, \\lambda_1 \\nu) &amp;amp;=&amp;amp; f_0(x) + \\sum_{i=1}^n \\lambda_i f_i(x) + \\sum_{j=0}^p \\nu_j f_j(x)&amp;amp;\\leqslant&amp;amp; f_0(x)\\\\\\Rightarrow &amp;amp;\\underset{x}{inf} \\mathcal{L}(x, \\lambda, \\nu)&amp;amp;=&amp;amp; g(\\lambda, \\nu) &amp;amp;\\leqslant&amp;amp; f_0(x)\\\\\\Rightarrow &amp;amp;g(\\lambda, \\nu) &amp;amp;\\leqslant&amp;amp; p^{*}\\end{aligned}\\)Corollaire :Si on note $d^{*}$ la valeur optimale du dual on a : $d^{*} \\leqslant p^{*}$Question : Est ce quâ€™on a lâ€™Ã©galitÃ© ?Dans la situation dâ€™Ã©galitÃ© on dit quâ€™on a une dualitÃ© forte entre (P) et $(\\check{P})$Condition de Slater : Si $(P)$ est convexe et il existe un pt dans lâ€™intÃ¨rieur relatif du domaine de dÃ©finition de $(P)$ tq :$f_i(x)&amp;lt;0$$A x=b$alors $(P)$ et $(\\check{P})$ sont en dualitÃ© forte: DÃ©finition :On dit quâ€™un couple $(\\lambda, \\nu)$ est de $t$ dual admissible si $\\lambda \\geqslant 0$ et $g(\\lambda, \\nu) \\gt -\\infty$. Les points $(\\lambda^{*},\\nu^{*})$ optimaux pour $\\check{\\mathcal P}$ sont parfois appelÃ©s multiplicateurs de Lagrange.Les conditions KKT (Karush-Kuhn-Tucker)Supposons que les valeurs optimales, primale et duale, soient atteintes et egales, en particulier on a une dualite forte. On designe par $x^{*}$ (respectivement $(\\lambda^{*},\\nu^{*})$) un point optimal de $\\mathcal P$ (respectivement $\\check{\\mathcal P}$)On a :\\(\\begin{aligned}f_0(x^{*})&amp;amp;=g(\\lambda^{*}, \\nu^{*})\\\\&amp;amp;=\\inf(\\mathcal L_p (x, \\lambda^{*}, \\nu^{*}))\\\\&amp;amp;\\leq \\mathcal L_p(x^{*}, \\lambda^{*}, \\nu^{*})\\\\&amp;amp;=f_0(x^{*}) + \\sum_{i=1}^m \\lambda_i^{*} f_i(x^{*}) + \\sum_{j=1}^p \\nu_j^{*} h_j(x^{*})\\\\&amp;amp;\\leq f_0(x^{*})\\end{aligned}\\)Toutes les inÃ©galitÃ©s qui apparaissent prÃ©cÃ©demment sont donc des Ã©galitÃ©s. On en dÃ©duit :1) $x^{*}$ minimise $\\mathcal L_p(x, \\lambda^{*},\\nu^{*})$2) $\\displaystyle \\sum_{i=1}^m \\underbrace{ \\lambda_i^{*} f_i(x^{*})}_{\\le 0} = 0$$\\Rightarrow \\forall i \\in {1,â€¦,m}; \\lambda_i^{*}f_i(x^{*}) = 0$La fonction $x \\longmapsto \\mathcal L_p(x, \\lambda^{*}, \\nu^{*})$ est convexe des que $(P)$ lâ€™est. Dire que $x^{*}$ minimise $x \\longmapsto \\mathcal L_p(x, \\lambda^{*}, \\nu^{*})$ est equivalent a dire que$\\nabla_x \\mathcal L_p (x^{*},\\lambda^{*},\\nu^{*}) = 0$$\\Leftrightarrow \\nabla f_0(x^{*}) + \\displaystyle \\sum_{i=1}^m \\lambda_i^{*} \\nabla f_i(x^{*}) + \\displaystyle \\sum_{j = 1}^{p} \\nabla j^{*} \\nabla hj(x^{*}) = 0$Pour resumer $(x^{*},\\lambda^{*}, \\nu^{*})$ verifient les contraintes :$f_i(x^{*}) \\leqslant 0 \\qquad \\forall i \\in {1,â€¦,m}$$h_j(x^{*}) = 0 \\qquad \\forall j \\in {1,â€¦,p}$$\\lambda_i^{*} \\geqslant 0 \\qquad \\forall i \\in {1,â€¦,m}$ (KKT)$\\lambda_i^{*} f_i(x^{*}) = 0 \\qquad \\forall i \\in {1,â€¦,m}$$\\nabla f_0(x^{*}) + \\displaystyle \\sum_{i =1}^m \\lambda_i^{*} \\nabla f_i(x^{*}) + \\displaystyle \\sum_{j = 1}^{p} \\nu_j^{*} \\nabla h_j(x^{*}) = 0$ PropriÃ©tÃ© : Quand $(P)$ est un problÃ¨me convexe et dans le cas de forte dualitÃ©, (condition de Slater satisfaite, par exemple) les conditions KKT sont nÃ©cessaires et suffisantes pour avoir une pair primal-dual optimale.Exercices :RÃ©soudre en utilisant les conditions KKT1\\(min_{x \\in \\mathbb R^2} \\quad \\frac{1}{2}({x_1}^2 + {x_2}^2) \\qquad tq \\quad x_1 - 2x_2 \\leqslant -2\\) Correction :\\(f_0(x_1, x_2) = \\frac{1}{2}(x_1^2 + x_2^2)\\)\\(\\begin{aligned} \\mathcal L(x_1,x_2, \\lambda) &amp;amp;= f_0(x_1, x_2) + \\lambda f_1(x_1, x_2)\\\\ &amp;amp;= \\frac{1}{2}\\left(x_1^2 + x_2^2\\right) + \\lambda (x_1 - 2x_2 + 2) \\end{aligned}\\) Pour que:$(x_1^{*}, x_2^{*})$ soit optimal, il faut que:\\(\\begin{aligned}&amp;amp;\\nabla_x \\mathcal L(x^{*}, \\lambda) = 0 \\\\&amp;amp;\\nabla_x \\mathcal L(x, \\lambda) = 0 \\Leftrightarrow \\begin{cases} \\frac{\\partial \\mathcal L}{\\partial x_1} = 0 \\\\\\frac{\\partial \\mathcal L}{\\partial x_2} = 0 \\end{cases} \\\\&amp;amp;\\begin{cases}\\frac{\\partial \\mathcal L}{\\partial x_1} = x_1 + \\lambda = 0\\\\\\frac{\\partial \\mathcal L}{\\partial x_1} = x_2 - 2\\lambda = 0\\end{cases}\\Leftrightarrow\\begin{cases}x_1 = -\\lambda\\\\x_2 = 2 \\lambda\\end{cases}\\end{aligned}\\)La fonction objective duale est:\\(\\begin{aligned}g(\\lambda, \\nu) &amp;amp;= \\underset{x \\in \\mathbb R^n}{inf} \\mathcal L(x, \\lambda, \\nu)\\\\g(\\lambda) &amp;amp;= \\frac{1}{2}((-\\lambda)^2 + (2\\lambda)^2) + \\lambda(-\\lambda - 4 \\lambda + 2)\\\\ &amp;amp;= \\frac{1}{2}(\\lambda^2 + 4\\lambda^2) - \\lambda^2 - 4\\lambda^2 + 2\\lambda\\\\ &amp;amp;= \\frac{5}{2}\\lambda^2 -5\\lambda^2 + 2\\lambda\\\\ &amp;amp;= -\\frac{5}{2}\\lambda^2 + 2\\lambda\\end{aligned}\\)ProblÃ¨me dual $p^2$\\(\\underset{\\lambda \\geqslant 0}{max} \\qquad g(\\lambda, \\nu)\\)On cherche $\\underset{\\lambda \\geqslant 0}{max}(\\underbrace{-\\frac{5}{2}\\lambda^2 + 2\\lambda}_{g(\\lambda)})$On cherche \\(\\lambda^{*} \\quad tq \\quad \\begin{cases}\\nabla g(\\lambda^{*}) &amp;amp;= 0\\\\\\lambda^{*} &amp;amp;\\geqslant 0\\end{cases}\\)2)\\(\\begin{aligned}&amp;amp;\\nabla g(\\lambda) &amp;amp;=&amp;amp; -5\\lambda + 2\\\\&amp;amp;\\nabla g(\\lambda^{*}) &amp;amp;=&amp;amp; 0 \\\\\\Leftrightarrow&amp;amp; -5\\lambda^{*} + 2 &amp;amp;=&amp;amp; 0\\\\\\Leftrightarrow&amp;amp; \\lambda^{*} &amp;amp;=&amp;amp; \\frac{2}{5} \\geqslant 0\\end{aligned}\\)et $\\displaystyle x^{} = (x_1^{}, x_2^{*}) = \\left(-\\frac{2}{5}, \\frac{4}{5}\\right)$2 â€¦ Apres avoir mis sous forme matricielle\\(min_{x \\in \\mathbb R^3} \\quad \\frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \\qquad tq \\quad \\begin{aligned} x_1 + x_2 + 2x_3 = 1 \\\\ x_1 + 4x_2 + 2x_3 = 3 \\end{aligned}\\) Correction ://FIXME" }, { "title": "OCVX: Optimisation Convexe 1", "url": "/cours/posts/ocvx_verjus_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:00:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Basharâ€™s Github bashar.dudin@epita.frguillaume.tochon@lrde.epita.frÃ€ voir : Descente de gradientIntroductionEn rentrant dans lâ€™Ã¨re industrielle, il a fallu optimiser les coÃ»ts, minimiser les risques, etc.Des mathematiciens ont commencÃ© Ã  se poser des questions.ex: gestion dâ€™un stock, optimiser la construction de produits en usine. Algebre linÃ©aire Calcul diffÃ©rentiel GÃ©ometrie Examples: Chercher le plus cours chemnin entre deux coordonnÃ©es GPS. DÃ©cider des meilleurs routes aÃ©riennes qui minimisent le prix dâ€™approvisionnement en kÃ©rosÃ¨ne. Identifier des images dâ€™IRM qui correspondent Ã  des malformations du cerveau. Chercher des patterns dans la population dâ€™Ã©tudiants intÃ©grants EPITA. ProblÃ¨mes dâ€™optimisationDÃ©finition formelleMinimiser $f_0(x)$sujet Ã  : $f_i(x) \\leq 0, \\forall i \\in {1,\\dots,p}$ $h_j(x) \\leq 0, \\forall j \\in {1,\\dots,m}$oÃ¹ $f_0$, les $f_i$ et les $h_i$ sont des applications de $\\mathbb{R}^n$ vers $\\mathbb{R}$. La fonction $f_0$ est dite fonction objectif; suivant le contexte ce sera une fonction de coÃ»t ou dâ€™erreur.Un problÃ¨me dâ€™optimisation du type de $(P)$ : diffÃ©rentiable si toutes les fonctions en jeu le sont. non-contraint sâ€™il nâ€™a aucune contrainte dâ€™inÃ©galitÃ©s ou dâ€™Ã©galitÃ©s. convexe si lâ€™ensemble des fonctions en jeu sont convexes, les contraintes dâ€™Ã©galitÃ©s Ã©tant de plus affines.LexiqueÃ‰tant donnÃ©e un problÃ¨me dâ€™optimisation $(P)$ on appelle : point admissible de $(P)$ tout point de $\\mathbb{R}^n$ satisfaisant toutes les contraintes. Lâ€™ensemble de tous les points admissibles est appelÃ© lieu admissible de $(P)$. valeur objectif dâ€™un point admissible la valeur que prend la fonction objectif en celui-ci. valeur optimale de $(P)$ la meilleure borne infÃ©rieure sur la fonction objectif. point optimale de $(P)$ tout point admissible dont la valeur objectif est la valeur optimale.PremiÃ¨res remarques qualitatives Y a-t-il au moins une solution ? Sâ€™il y a au moins une solution, combien ? Peut-on toujours dÃ©crire lâ€™ensemble des solutions? Y a-t-il moyen dâ€™approcher des solutions?MLMap fittingProblÃ¨me dâ€™optimisation dit de map fitting DÃ©finition :Une famille diffÃ©rentiable dâ€™applications $f_\\alpha:\\mathbb{R}^n\\longmapsto\\mathbb{R}$ indÃ©xeÅ› par $\\alpha \\in \\mathbb{R}^k$ est une famille de fonctions pour laquelle lâ€™application $\\varphi:\\mathbb{R}^k\\times\\mathbb{R}^n\\longmapsto\\mathbb{R}$ qui envoie $(\\alpha,x)$ sur $f_\\alpha(x)$ est diffÃ©rentiable. Map Fitting :On considÃ¨re un ensemble de couples $(X_i, y_i)\\in\\mathbb{R}^n\\times\\mathbb{R}$ pour $i \\in { 1,â€¦,p }$ et une famille diffÃ©rentiable dâ€™applications \\(\\{ f_\\alpha \\}_{\\alpha\\in\\mathbb{R}^k}\\). Le problÃ¨me de map fitting relatif aux donnÃ©es prÃ©cÃ©dentes consiste Ã  trouver les meilleurs paramÃ¨tres $\\alpha^{*}$ tels que $f_{\\alpha^{*}}$ approche au mieux les $(X_i, y_i)$.RÃ©gression linÃ©aireLe plus simple des problÃ¨mes de map fitting est celui de la rÃ©gression linÃ©aire. La famille diffÃ©rentiable Ã  laquelle on sâ€™intÃ©resse est indexÃ©s par $\\mathbb{R}^2$: $f_\\alpha(x)=\\alpha_1x+\\alpha_0$ pour $\\alpha=(\\alpha_0,\\alpha_1)$ La mÃ©trique standard utilisÃ©e est le MSE (Mean Square Error) donnÃ©e pour un $f_\\alpha$ par\\(\\mathcal{E}(\\alpha)=\\sum_{i=1}^p\\frac{1}{p}(f_\\alpha (X_j)-y_i)^2\\)Le but est de trouver un paramÃ¨tre $\\alpha = (\\alpha_0,\\alpha_1)$ tel que $\\mathscr{E}(\\alpha)$ est minimal, autrement dit de rÃ©oudre le problÃ¨me dâ€™optimisation sans contraintesContour du cours La premiÃ¨re partie est notÃ© par un TD et un partiel La seconde partie est notÃ© par une analyse Ã  faire (projet?)Classification Comment sÃ©parer la classe1 de la classe2 ? On fait un traitâ€¦Produit scalaire$x = \\begin{pmatrix}x_1 \\ \\vdots \\ x_n\\end{pmatrix} \\qquad y = \\begin{pmatrix}y_1 \\ \\vdots \\ y_n\\end{pmatrix}$\\[\\begin{aligned}\\langle:\\rangle : \\mathbb{R}^n &amp;amp;\\longrightarrow \\mathbb{R}\\\\(x,y) &amp;amp;\\longmapsto \\langle x,y \\rangle\\end{aligned}\\]$\\langle x,y \\rangle =\\displaystyle\\sum_{i=1}^{n}x_iy_i$$\\Vert x\\Vert =\\sqrt{\\langle x,x \\rangle}$On veut : $x_1, x_2$ en fonction de $\\Vert x\\Vert $ et $\\varphi$ $y_1, y_2$ en fonction de $\\Vert y\\Vert $ et $\\psi$ $x_1 = \\Vert x\\Vert \\cos{\\varphi} \\qquad x_2 = \\Vert x\\Vert \\sin{\\varphi}$ $y_1 = \\Vert y\\Vert \\cos{\\psi} \\qquad y_2 = \\Vert y\\Vert \\sin{\\psi}$ $\\langle \\vec{x}, \\vec{y}\\rangle = x_1 y_1 + x_2 y_2 = \\Vert x\\Vert .\\Vert y\\Vert .(\\underbrace{\\cos{\\varphi}\\cos{\\psi} + \\sin{\\varphi}\\sin{\\psi}}_{\\cos{(\\psi - \\varphi)} = \\cos{\\theta}}) =\\Vert x\\Vert .\\Vert y\\Vert .\\cos{\\theta}$ En dimension n :\\(\\theta(x,y)=arccos\\left(\\frac{\\langle x,y \\rangle}{\\Vert x\\Vert .\\Vert y\\Vert }\\right)\\) Formules usuelles trigonometriques :\\(\\sin \\left(s+t\\right)=\\sin \\left(s\\right)\\cos \\left(t\\right)+\\cos \\left(s\\right)\\sin \\left(t\\right)\\\\\\sin \\left(s-t\\right)=\\sin \\left(s\\right)\\cos \\left(t\\right)-\\cos \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s+t\\right)=\\cos \\left(s\\right)\\cos \\left(t\\right)-\\sin \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s-t\\right)=\\cos \\left(s\\right)\\cos \\left(t\\right)+\\sin \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s\\right)\\cos \\left(t\\right)=\\frac{\\cos \\left(s-t\\right)+\\cos \\left(s+t\\right)}{2}\\\\\\sin \\left(s\\right)\\sin \\left(t\\right)=\\frac{\\cos \\left(s-t\\right)-\\cos \\left(s+t\\right)}{2}\\\\\\sin \\left(s\\right)\\cos \\left(t\\right)=\\frac{\\sin \\left(s+t\\right)+\\sin \\left(s-t\\right)}{2}\\\\\\cos \\left(s\\right)\\sin \\left(t\\right)=\\frac{\\sin \\left(s+t\\right)-\\sin \\left(s-t\\right)}{2}\\\\\\)On peut reprÃ©senter une droite avec : 2 points 1 point et un vecteur directeur ou normal.$x=\\begin{pmatrix} x_1 \\ x_2 \\end{pmatrix} \\in D \\Leftrightarrow \\langle \\vec{Ox},\\vec{n} \\rangle = 0 \\Leftrightarrow \\underbrace{x^{\\top}n=0}_{\\langle x,n \\rangle}$$\\rightarrow$ Equation dâ€™un hyperplan de vecteur normal $\\vec{n}$Soit une droite $ax_1 +bx_2 + c = 0$ : Son vecteur normal : $\\vec{n} = \\begin{pmatrix}a\\ b\\end{pmatrix}$ Son vecteur directeur : $\\vec{u} = \\begin{pmatrix}-b\\ a\\end{pmatrix}$ Exercice :Dessiner le lieu de $\\mathbb{R}^2$ donnÃ© par la relation\\(\\begin{pmatrix}1 &amp;amp; 2 \\\\-1 &amp;amp; 1\\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2\\end{pmatrix} \\leq \\begin{pmatrix}0\\\\0\\end{pmatrix}\\) $x_1 + 2x_2 \\leq 0$$-x_1 + x_2 \\leq 0$ On remplace lâ€™inÃ©galitÃ© par une Ã©galitÃ© :$x_1 + 2x_2 = 0 \\qquad \\vec{n_1} = \\begin{pmatrix}1\\ 2\\end{pmatrix} \\qquad \\vec{u_1} = \\begin{pmatrix}-2\\ 1\\end{pmatrix}$$-x_1 + x_2 = 0 \\qquad \\vec{n_2} = \\begin{pmatrix}-1\\ 1\\end{pmatrix} \\qquad \\vec{u_2} = \\begin{pmatrix}-1\\ -1\\end{pmatrix}$ On a les vecteurs normaux on peut donc reprÃ©senter graphiquement le lieu. Exercice :Trouver le lieu de $\\mathbb{R}^3$ tq $\\underbrace{x_1 + x_2 + x_3}_{(1 1 1)\\begin{pmatrix}x1\\ x_2\\ x_3\\end{pmatrix}} \\geq 0$ $\\vec{n} = \\begin{pmatrix}1\\ 1\\ 1\\end{pmatrix}$$\\langle n, x \\rangle \\geq 0$ Espace affine$A = {(1,t) \\in \\mathbb{R}^2 \\vert t \\in \\mathbb{R}} = (1, 0) + \\underbrace{{(0,t) \\in \\mathbb{R}^2 \\vert t \\in \\mathbb{R}}}_{F}$ On note quâ€™on pouvait utiliser un autre point $(1,42)$ au lieu de $(1,0)$ donne le mÃªme rÃ©sultat.$P={(t, 3t + u, -u) \\setminus (t, u) \\in \\mathbb{R}^2}$ $O \\in P$ $A = \\begin{pmatrix}1\\ 3\\ 0\\end{pmatrix} \\in P$ $B = \\begin{pmatrix}0\\ 1\\ -1\\end{pmatrix} \\in P$$\\vec{n} = \\vec{OA} \\times \\vec{OB}$ Produit vectoriel : WikipÃ©dia Exercice :Ecrire paramÃ©triquement la droite $D$ de $\\mathbb{R}^2$ de vecteur directeur $\\vec{u}=\\begin{pmatrix}1\\ -1\\end{pmatrix}$ et passant par $(2,3)$ Soit $M \\in D \\Leftrightarrow \\exists ~\\alpha \\in \\mathbb{R}$ tq \\(\\vec{AM} = \\alpha \\vec{u} \\\\ \\Leftrightarrow \\begin{pmatrix}x_1 - 2\\\\ x_2 - 3\\end{pmatrix} = \\alpha \\begin{pmatrix}1\\\\ -1\\end{pmatrix}\\\\\\Leftrightarrow \\begin{cases} x_1 -2 = \\alpha \\\\ x_2 - 3 = -\\alpha\\end{cases} \\\\\\Leftrightarrow \\begin{cases}x_1 = \\alpha + 2\\\\ x_2 = 3 - \\alpha\\end{cases}\\) Donc $(D) = {(\\alpha +2, 3-\\alpha) \\vert \\alpha \\in \\mathbb{R}}$ Exercice :Dessiner le lien de $\\mathbb{R}^2$ decrit par les contraintes :$\\begin{pmatrix}-1 &amp;amp; 2 1 &amp;amp; 1\\ \\end{pmatrix} = \\begin{pmatrix}x \\ y \\end{pmatrix} \\le \\begin{pmatrix} -1 \\ 1\\end{pmatrix}$$ax + by = 0$$ax + by +c = 0$$\\overrightarrow{n} \\begin{pmatrix}a \\ b \\end{pmatrix} \\overrightarrow{u} \\begin{pmatrix}-b \\ a \\end{pmatrix}$${ (x,y) \\in \\mathbb{R}^2 , -x + 2y \\le -1 \\text{ et } x+y \\le 1 }$$(D_1) = -x + 2y + 1 = 0$$(0, \\frac{-1}{2} \\in D_1)$$\\overrightarrow{n_1} = \\begin{pmatrix} -1 \\ 2\\end{pmatrix}$$\\overrightarrow{u_1} = \\begin{pmatrix} -2 \\ -1\\end{pmatrix}$\\[\\underbrace{Ax = r}_{\\text{Ã©criture implicite}} \\qquad \\text{ avec } \\begin{cases}\\text{A matrice } m \\times n\\\\A = [a_{i,j}]_{mn}\\\\x \\in \\mathbb R^n ~ r \\in \\mathbb R^m \\end{cases}\\]\\[\\begin{cases}a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n}xn = r_1\\\\\\vdots \\\\a_{m1}x_1 + a_{m2}x_2 + \\dots + a_{mn}x_n = r_m\\end{cases}\\] Hyperplan: Un plan de dimension $n-1$.Exemples: En 2D, câ€™est une droite. En 3D, câ€™est un planâ€¦Notre description affine ne suffit pas dans le cas gÃ©nÃ©ral. Description dâ€™un cercle :$x^2 + y^2 = r^2x^2+y^2-r^2=0$$\\boxed{f(x,y) = x^2 + y^2 - r^2}$ Ligne / Courbe de niveau dâ€™une fonction f :\\(\\mathscr{C}_r=\\{x\\in \\mathbb{R}^n | f(x)=r\\}\\) Lieu de sous niveau dâ€™une fonction f :\\(\\mathscr{C}_{\\leqslant r}=\\{ x\\ \\in \\mathbb{R}^n \\ f(x) \\leqslant r \\}\\) Les coniques : Ce sont les paraboles, hyperboles, elipsesâ€¦ Exercice :Courbes de niveau 0,1,2 $f(x,y)=x^2+y^2$ $\\mathscr{C}_0$: seul $(0,0)$$\\mathscr{C}_1$: cercle de rayon 1 centrÃ© en 0$\\mathscr{C}_2$: cercle de rayon 2 centrÃ© en 0 $g(x,y)=x^2+4y^2$$\\mathscr{C}_0$: seul $(0,0)$ $\\mathscr{C}_1$: ellipse demi-grand axe 1, demi-petit axe $\\frac{1}{2}$, centrÃ© en 0$\\mathscr{C}_2$: ellipse demi-grand axe $\\sqrt{2}$, demi-petit axe $\\frac{\\sqrt{2}}{2}$, centrÃ© en 0 Ã‰quation dâ€™une Ã©llipse\\(\\bigg(\\frac xa\\bigg)^2 + \\bigg(\\frac yb\\bigg)^2=1\\)a : demi-grand axeb : demi-petit axe Epigraphe dâ€™une fonction $f.\\mathbb R^n \\rightarrow \\mathbb R$ $Epi(f) = {(x,t) ~\\vert~ f(x) \\leq t}$ Exercice :Dessiner lâ€™intersection de lâ€™Ã©pigraphe de $f(x)=-\\sqrt{x}$ (sur $\\mathbb R^+$)avec la partie ${(x, y) | y \\leq \\sqrt x}$ Une partie de $A\\subset \\mathbb{R}^n$ est convexe ssi $\\forall x,y\\in A, \\forall t\\in [0,1]$ alors \\(tx+(1-t)y \\in A\\) Lâ€™adhÃ©rence dâ€™une partie est sa frontiere.$A \\cup \\partial{A} = \\underbrace{\\bar{A}}_{adhÃ©rence}$ Exemple :$A = [1,2[$$\\partial A = {{1} {2}}$$\\bar A = [1,2]$ Quoi ? Hyper parapluie ??? [name=multun] Un hyperplan dâ€™appui dâ€™une partie $A$ est un hyperplan de $A$ qui possÃ©de un Ã©lÃ©ment du bord de $A$ Une fonction convexe admet des hyperplans dâ€™appui en chacun des points de sa frontiÃ¨re. $f$ convexe $\\Leftrightarrow f(tx+(1-t)y) \\leq tf(x)+ (1-t)f(y)$Exemple de fonctions convexes : $f(x) = ax^2 +bx +c , a \\ge 0$ $f(x) = bx+ c$ $e^{ax} \\quad \\forall a$ $f(x) = -\\log(x)$ $f(x) = \\sqrt(x)$ $f(x) = \\vert x\\vert$ $f(x) = x^{2p}, p \\in \\mathbb{N}^*$ Exercice :Est ce que la somme de fonctions convexes est convexe ? $f = \\sum_{i=1}^{N}w_if_i$ la somme de fonctions convexes \\(\\begin{aligned}f(tx + (1-tg)) &amp;amp;= \\sum_{i=1}^N f_i (tx+(1-t)y) \\\\ &amp;amp;\\leq tf_i(x)+(1-t)f_i(y) \\\\ &amp;amp;\\leq \\sum_{i=1}^N w_i(tf_i(x)+(1-t)f_i(y)) \\\\ &amp;amp;\\leq \\sum_{i=1}^N tw_if_i(x) + \\sum_{i=1}^N(1-t)w_if_i(y) \\\\ &amp;amp;\\leq t\\underbrace{\\sum_{i=1}^N w_if_i(x)}_{f(x)} + (1-t) \\underbrace{\\sum_{i=1}^N w_if_i(y)}_{f(y)}\\end{aligned}\\)Donc câ€™est bien convexe !Soit $f(x,y) = x^2 + y^2$La fonction Hessienne de $f$:\\(H(x,y) = \\begin{pmatrix}\\frac{\\partial^2f(x,y)}{\\partial x^2}&amp;amp;\\frac{\\partial^2f(x,y)}{\\partial y \\, \\partial x} \\\\ \\frac{\\partial^2f(x,y)}{\\partial y \\, \\partial x}&amp;amp; \\frac{\\partial^2f(x,y)}{\\partial y^2}\\end{pmatrix}\\)Programme linÃ©aire Exercice 1: $\\mathcal A_u : \\begin{cases}-x+2y \\leq 1x + y \\leq 1\\end{cases}$ $\\mathcal A_b = \\mathcal A_u \\cup {(x,y) \\in \\mathbb R^2, x-3y \\leq 6}$ $(D_1)$: $-x + 2y + 1 = 0 \\qquad (0, -\\frac 12) \\in (D_1) \\qquad \\vec{n_1}\\begin{pmatrix}-1\\ 2\\end{pmatrix} \\qquad \\vec{u_1}\\begin{pmatrix}-2\\ -1\\end{pmatrix}$ $(D_2)$: $x + y - 1 = 0 \\qquad (0,1) \\in (D_2) \\qquad \\overrightarrow{n_2}\\begin{pmatrix} 1 \\ 1\\end{pmatrix}\\qquad \\overrightarrow{u_2}\\begin{pmatrix} -1 \\ 1\\end{pmatrix}$ $(D_3)$: $x - 3y - 6 = 0 \\qquad (0,-2) \\in (D_3) \\qquad \\overrightarrow{n_3}\\begin{pmatrix} 1 \\ -3\\end{pmatrix}\\qquad \\overrightarrow{u_3}\\begin{pmatrix} 3 \\ 1\\end{pmatrix}$ \\(\\underbrace{\\min f_0(x,y) = y = -\\infty}_{(x,y) \\in \\mathcal{A}_u}\\)\\(\\underbrace{\\min f_0(x,y) = -y = 0}_{(x,y) \\in \\mathcal{A}_u}\\) Exercice 2: $f(x,y) = 3x^2 + y^2$\\(\\mathcal{C}_2(f)\\mathcal{C}_4(f)\\)?\\(\\mathcal{C}_{\\le 4}(f)\\)?\\(\\min f_0(x,y) = 2x + y\\)sujet Ã  $3x^2 +y^2 \\le 4$\\[\\begin{aligned}\\mathcal{C}_2(f) : &amp;amp; 3x^2 + y^2 = 2 \\\\\\Leftrightarrow &amp;amp;\\frac{3}{2}x^2 \\frac{1}{2}y^2 = 1\\\\\\Leftrightarrow &amp;amp;\\begin{pmatrix}\\frac{x}{\\frac{\\sqrt{2}}{\\sqrt{3}}}\\end{pmatrix}^2 + \\begin{pmatrix}\\frac{y}{\\sqrt{2}}\\end{pmatrix}^2\\\\\\end{aligned}\\begin{aligned}\\mathcal{C}_4(f) : &amp;amp; 3x^2 + y^2 = 4 \\\\\\Leftrightarrow &amp;amp;\\frac{3}{4}x^2 \\frac{1}{4}y^2 = 1\\\\\\Leftrightarrow &amp;amp;\\begin{pmatrix}\\frac{x}{\\frac{2}{\\sqrt{3}}}\\end{pmatrix}^2 + \\begin{pmatrix}\\frac{y}{2}\\end{pmatrix}^2\\\\\\end{aligned}\\begin{aligned}\\mathcal{C}_0(f_0) : &amp;amp; 2x + y = 0 \\\\&amp;amp; (0,0) \\in \\mathcal{C}_0(f_0)\\\\&amp;amp; \\overrightarrow{n}\\begin{pmatrix} 2\\\\ 1\\end{pmatrix} \\overrightarrow{u}\\begin{pmatrix} -1\\\\ 2\\end{pmatrix}\\end{aligned}\\] \\(\\min(f_0(xy)) = f_0^*$ pour $(x,y) = (x^*,y^*)\\)\\(3x^{*2} +y^{*2} = 4$ $(x^*,y^*) \\in \\mathcal{C}_4(f)\\)\\(2x^{*} + y^* = f_0^*$ $(x^*,y^*) \\in \\mathcal{C}_{f_0^*}(f_0)\\) \\(\\begin{aligned}\\Delta f(x^*, y^*) = \\begin{pmatrix} 6x^* \\\\ 2y^*\\end{pmatrix}\\\\\\langle \\Delta f(x^*,y^*), \\overrightarrow{u} \\rangle = 0\\\\\\begin{pmatrix} 6x^* &amp;amp; 2y^* \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = 0 \\end{aligned}\\) \\(\\begin{aligned}3x^{*2} + y^{*2} &amp;amp;= 4\\\\-6x^* + 4y^* &amp;amp;= 0 \\rightarrow y^* &amp;amp;= \\frac{6}{4} x^*\\\\&amp;amp; &amp;amp; = \\frac{3}{2}x^*\\\\&amp;amp; &amp;amp;= \\frac{6}{\\sqrt{21}}\\end{aligned}\\)$y^* = \\frac{6}{\\sqrt{21}}$ \\(3x^{*2} + (\\frac{3}{2}x^{\\*})^2 = 4\\)\\(3x^{*2} + \\frac{9}{4}x^{\\*2} = 4\\)\\(\\frac{21}{4}x^{\\*2} = 4\\)\\(x^{*2} = \\frac{16}{21}\\)\\(x^* = \\frac{4}{\\sqrt{21}}$ ou $-\\frac{4}{\\sqrt{21}}\\)GÃ©ometrie diffÃ©rentielle pour les petitsAvec ce quâ€™on a vu Ã  ce jour on peut chercher Ã  rÃ©soudre un problÃ¨me dâ€™optimisation de la forme suivante\\(\\begin{aligned}\\text{min}\\qquad &amp;amp; \\overbrace{-x_1-2x_2}^{f_o(x_1,x_2)} \\\\\\text{sujet Ã } \\qquad &amp;amp;x_1+x_2 \\leqslant 5 \\\\&amp;amp; -2x_1+x_2 \\leqslant 3 \\\\&amp;amp; x_1, x_2 \\geqslant 0\\end{aligned}\\) Sur la rouge non plus, cf (0.5, 1)Tu dÃ©passe a gauche$\\color{red}{\\text{Le lieu admissible}}$$\\color{green}{\\mathscr{C}_0}:$ Courbe de niveau de $f_0$ passant par $(0,0)$Afin dâ€™amÃ©liorer la valeur objectif du point courant, on cherche un point Ã  la fois dans le lieu admissible et dans le demi-espace, quâ€™on determine Ã  partir de lâ€™Ã©quation de la fonction objectif.La courbe de niveau de la fonction objectif au point optimal isole le lieu admissible dans la partie + des demi-espaces defini par la courbe de niveau de la fonction objectif en ce point. le demi-espace est un hyperplan dâ€™appui au lieu admissible. Exercice : \\(\\begin{aligned}\\text{min}\\qquad &amp;amp; x+y \\\\\\text{sujet Ã } \\qquad &amp;amp;x^2+y^2 \\leqslant 1\\end{aligned}\\)Comment trouver les hyperplans dâ€™appui au lieu admissible? point optimal en $(\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$je propose$\\color{blue}{\\text{Point optimal B}}$Quand on cherche Ã  minimiser une fonction objectif affine contrainte par un lieu admissible qui est une ellipse de $\\mathbb R^2$, on se retrouve Ã  rechercher des hyperplans dâ€™appui de celui-ci .Cette notion nous ramene Ã  lâ€™Ã©tude des dÃ©rivÃ©es de fonction numÃ©riques dont les graphes dÃ©crivent des morceaux du bord du lieu admissible. Pour gÃ©nÃ©raliser cette approche, on a besoin de gÃ©nÃ©raliser la notion de dÃ©rivÃ©e sur plusieurs variables.Normes sur $\\mathbb R^2$Une norme sur $\\mathbb R-ev$ est une maniÃ¨re de mesurer la longueur dâ€™un vecteur, tout en prÃ©servant un minimum la structure dâ€™ev. Elle permet en particulier de mesurer la distance entre deux points pour la longueur du vecteur qui les relie. DÃ©finition :Une norme sur $\\mathbb R^n$ est une application $\\Vert \\cdot\\Vert : \\mathbb{R}^n \\longmapsto \\mathbb{R}$ telle que 1) $\\Vert x\\Vert = 0 \\Longleftrightarrow x = 0$2) $\\forall \\lambda \\in \\mathbb R , \\forall x \\in \\mathbb R^n: \\Vert \\lambda x\\Vert = |\\lambda|\\cdot\\Vert x\\Vert \\qquad \\quad$ (relation dâ€™homogÃ©initÃ©)3) $\\forall x, y \\in \\mathbb{R}^n$, $\\Vert x+y\\Vert \\leqslant \\Vert x\\Vert + \\Vert y\\Vert \\qquad \\qquad$ (inÃ©galitÃ© triangulaire) Exercice : sur $\\mathbb R^n$ \\[\\Vert x\\Vert _1 = \\displaystyle\\sum_{i=1}^{n}\\vert x_i\\vert\\] \\[\\Vert x\\Vert _2 = \\bigg(\\displaystyle\\sum_{i=1}^{n}(x_i)^2\\bigg)^{\\frac 1 2}=\\sqrt{x^Tx}\\] $\\Vert x\\Vert _\\infty = \\underset{i\\in {1,\\dots,n}}{\\max}{\\vert x_i\\vert }$ Pour $p \\geqslant 1$, \\(\\Vert x\\Vert _p = \\bigg(\\displaystyle\\sum_{i=1}^{n}\\vert x_i\\vert ^p\\bigg)^{\\frac 1 p} \\qquad \\qquad\\) (la norme p) ($p \\ge 1$) Ã€ partir dâ€™une norme sur $\\mathbb R^n$, on va pouvoir dÃ©finir : Une distance : $\\forall x, y \\in \\mathbb R^n, d(x, y) = \\Vert x-y\\Vert $ Une notion de voisinage dâ€™un point Quand on fait de lâ€™analyse, on sâ€™intÃ©resse Ã  ce qui se passe autour dâ€™un point donnÃ© $\\varepsilon$-prÃ¨s. Par example, pour montrer quâ€™une suite numÃ©rique $(u_n)_{n\\in \\mathbb{N}}$ converge vers $l\\in \\mathbb{R}$, on vÃ©rifie: \\(\\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb{N}, n \\ge N \\Longrightarrow \\underbrace{|u_n - l| &amp;lt; \\varepsilon}_{u_n\\in ] l-\\varepsilon, l+\\varepsilon [}\\) La notion de norme sur $\\mathbb R^n$ permet de gÃ©nÃ©raliser cette notion Ã  toute dimension. Par exemple si $(u_n)_{n \\in \\mathbb{N}}$ une suite Ã  valeurs dans $\\mathbb R^n$ et $l = (l_1, .., l_n) \\in \\mathbb{R}^n$.On dit que (u_n) converge vers l au sens de la norme $\\Vert .\\Vert $ si :\\((E) \\qquad \\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb{N}, n \\ge N \\Longrightarrow \\Vert u_n - l\\Vert &amp;lt; \\varepsilon\\)On note$\\begin{aligned}B_{\\Vert \\cdot\\Vert }(l,\\varepsilon)={x\\in \\mathbb{R}^n | \\Vert x-l\\Vert &amp;lt;\\varepsilon} \\ \\bar{B}_{\\Vert \\cdot\\Vert }(l,\\varepsilon)={x\\in \\mathbb{R}^n | \\Vert x-\\Vert |&amp;lt;\\varepsilon} \\end{aligned}$Dans ce cas, $(E)$ sâ€™Ã©crit : \\(\\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb N , b \\ge N \\Rightarrow \\mathcal U_n \\in B_{\\Vert .\\Vert }(l,\\varepsilon)\\)Dans le cas de $\\mathbb R^2$ on represente $\\overline{B_{\\Vert \\cdot\\Vert }}(\\underbrace{\\underline{0}}_{\\text{lâ€™origine}},1)$ Remarque: les boules dâ€™une norme sont convexes. du coup, les boules de Noel aussi #loul Comme on a pu le voir pour la cas de la convergence dâ€™une suite se donner une norme sur $\\mathbb{R}^n$ va nous permettre de transposer les notons de continuitÃ© dâ€™une fonction ou de comparaison de fonctions en un point $(o, \\theta, \\text{~} )$ Exercice :On se donne une norme $\\Vert .\\Vert $ sur$\\mathbb R^n$.continuite): Soit $f:(E, \\Vert .\\Vert _E)\\rightarrow (F, \\Vert .\\Vert _F)$on dit que f est continue en $a \\in E$ si $f$ est dÃ©fini au voisinage de $a$ \\(\\forall \\varepsilon &amp;gt; 0, \\exists \\mu &amp;gt; 0 tq\\Vert x-a\\Vert &amp;lt; \\mu \\Rightarrow \\Vert f(x) - f(a)\\Vert &amp;lt; \\varepsilon\\) $(\\theta)$ Une fonction f est un $\\theta_1(g)$ en a $\\in$ E sâ€™il existe $\\varepsilon$ :(E,$\\Vert \\cdot\\Vert _E$) $\\rightarrow \\mathbb R$ telle que $f=\\varepsilon g$ $\\varepsilon \\xrightarrow[a]{} 0$ Quand g nâ€™est pas identiquement nulle au voisinage de a, la condition prÃ©cÃ©dente est Ã©quivalente Ã  $\\frac{\\Vert f\\Vert _F}{\\Vert g\\Vert _F} \\xrightarrow[a]{} 0$Il semble Ã  ce stade que la dÃ©finition de continuitÃ© ou celle de convergence dÃ©pende de la norme choisie. DÃ©finition :Les normes $\\Vert \\cdot\\Vert_\\alpha$ et $\\Vert \\cdot\\Vert_\\beta$ sur $\\mathbb{R}^n$ sont dites Ã©quivalentes sâ€™il existe $c, C \\in \\mathbb{R}_+^{*}$ telle que\\(\\forall x \\in \\mathbb{R}^n, c\\Vert x\\Vert _\\alpha \\leqslant \\Vert x\\Vert _\\beta \\leqslant C\\Vert x\\Vert _\\alpha\\)Si 2 normes sont Ã©quivalentes alors elles dÃ©finissent les mÃªmes fonctions continues, les mÃªmes o, $\\theta$, ~ ou encore les mÃªmes suites convergentes. ThÃ©orÃ¨me :Sur $\\mathbb R^n$ toutes les normes sont Ã©quivalentes.Normes sur $\\mathbb R^n$ Les normes usuelles: \\[\\Vert .\\Vert _2 : \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _2 = (\\sum_{x=1}^n x_i^2)^{\\frac 12}=\\sqrt{x^Tx}\\] \\[\\Vert .\\Vert _1: \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _1 = \\sum_{i=1}^n\\vert x_i\\vert\\] \\[\\Vert .\\Vert _\\infty: \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _\\infty = \\underset{i \\in \\{1,\\dots,n\\}}{max} \\vert X_i\\vert\\] PropriÃ©tÃ©:\\(\\forall p \\geq 1:\\\\\\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _p = (\\sum(x_i)^p)^{\\frac 1p}\\)Ã€ partir dâ€™une norme, on dÃ©finit : Une distance : $d_{\\Vert .\\Vert }$(x,y) = \\Vert x-y\\Vert $ Des boules : Ouvertes : $B_{\\Vert .\\Vert }(x, \\varepsilon) = {y\\vert d_{\\Vert .\\Vert }(x,y) &amp;lt; \\varepsilon}$ FermÃ©es : \\(\\bar{B}_{\\Vert .\\Vert }(x, \\varepsilon) = \\{y\\vert d_{\\Vert .\\Vert }(x,y) \\leq \\varepsilon\\}\\) Objectif : Montrer que les boules ouvertes pour une norme $\\Vert .\\Vert $ sur $\\mathbb R^n$ sont convexes. DÃ©finition :Une fonction $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ est dite convexe si\\(\\forall x, y \\in \\mathbb{R}^n, \\forall t \\in [0, 1]; \\\\f(tx + (1 - t)y) \\le tf(x)+(1-t)f(y)\\) Lâ€™inÃ©galitÃ© de convexitÃ© se traduit gÃ©omÃ©triquement par le fait que les secantes entre deux points du graphe de $f$ sont au-dessus de salves prises par $f$ entre les abscisses de ces points. Soient $f: (\\mathbb R^2, \\Vert .\\Vert ) \\rightarrow (\\mathbb R, \\Vert .\\Vert )$ et $(0,0) \\in \\mathbb R^2$ $f$ est continue en $(0,0) \\in \\mathbb R^2$ si $\\forall \\varepsilon &amp;gt; 0, \\exists ~ q &amp;gt; 0, \\quad \\Vert (x,y)\\Vert &amp;lt; q \\implies \\Vert f(x,y)-f(0,0)\\Vert &amp;lt; \\varepsilon$ DiffÃ©rentiabilitÃ© et diffÃ©rentiellePour rappel on avait conclu Ã  la sÃ©ance prÃ©cÃ©dente quâ€™il nous fallait Ã©tendre la notion de dÃ©rivÃ©e dâ€™une fonction numÃ©rique au cas des fonctions Ã  plusieurs variables.On se donne une $f: \\mathbb R \\rightarrow \\mathbb R$ au voisinage $a \\in \\mathbb R$Dire que $f$ est derivable en $a \\in \\mathbb R$ câ€™est a dire que la limite:$lim_{h \\rightarrow 0, h \\ne 0} \\frac{f(a +h) - f(a)}{h} \\quad (D)$ existe ; cÃ d est un nombre rÃ©Ã©l $l\\in\\mathbb{R}$Lâ€™objectif est dÃ©tendre la notion de dÃ©rivabiliÃ© au cas dâ€™une fonction : $g: \\mathbb R^n \\mapsto \\mathbb R^m (n&amp;gt;1)$ en $a\\in\\mathbb{R}^n$ On ne peut pas faire : $\\frac{g(a+h)-g(a)}{\\underbrace{h}_{\\text{Un vecteur}}}$Diviser par un vecteur nâ€™a pas de sensâ€¦Lâ€™approche $(D)$ nâ€™est pas celle qui sâ€™Ã©tend le plus facilement vers le cas multivariÃ©. On doit voir les choses autrement.Si $f$ est derivable en $a$:$f(a +h) = \\boxed{f(a)} + \\underbrace{fâ€™(a)h}_{*} + \\boxed{o_0(h)}$$*$ Est la partie linÃ©aire de lâ€™approximation affine de $f$ en a; \\(\\begin{aligned}&amp;amp;h \\mapsto f&#39;(a).h\\\\ &amp;amp; \\mathbb R \\rightarrow \\mathbb R \\end{aligned}\\) Remarque: CaractÃ©riser les applications linÃ©aires de $\\mathbb R$ dans lui-mÃªme. Soit $\\mathcal L: \\mathbb R \\rightarrow \\mathbb R$ une application linÃ©aire$\\forall x \\in \\mathbb R; \\mathcal L(x) = \\mathcal L(x.1) = x.\\mathcal L(1)$ Si $\\mathcal L$ est un endomorphisme de $\\mathbb R$ alors $\\mathcal L$ est de la forme $x \\mapsto \\lambda x; \\lambda \\in \\mathbb R$.PropriÃ©tÃ©: Soit $f: \\mathbb R \\rightarrow \\mathbb R$ une application dÃ©finie au voisinage de $a\\in\\mathbb R$, $f$ est dÃ©rivable en $a$ ssi il existe $\\lambda_a\\in\\mathcal{L}(\\mathbb{R,R})$ telle que $\\forall h \\text{ proche de } 0,\\;f(a +h) = f(a) + fâ€™(a)h + o_0(h)$ $(**)$Preuve: $(\\Rightarrow)$: câ€™est ce que lâ€™on vient de dire $(\\Leftarrow)$: On suppose quâ€™on a une Ã©criture du type $(**)$On regarde pour h assez proche de 0, $h \\neq 0$\\[\\begin{aligned}\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\frac{\\lambda_n(h) + o_0(h)}{h}\\\\&amp;amp;= \\frac 1h \\lambda_n(h) + \\frac 1h o_0(h)\\\\\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\lambda_a(1) + o_0 (1)\\\\\\Rightarrow \\underset{h \\rightarrow 0\\\\ h \\neq 0}{lim}\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\lambda_a(1) \\in \\mathbb R\\end{aligned}\\]Donc $f$ est derivable en a et $fâ€™(a)=\\lambda_a(1)$ DÃ©finition de la diffÃ©rentiabilitÃ©: On suppose $\\mathbb R^n, \\mathbb R^m$ munies de normes quâ€™on note indiffÃ©rentiablement $\\Vert \\cdot\\Vert $. Dans la suite les Ã©noncÃ©s quâ€™on fait ne dÃ©pendent pas des normes choisies.On appelle ouvert de $\\mathbb{R}^n$ pour $\\Vert \\cdot\\Vert $ toute partie de $\\mathbb{R}^n$ qui contient des voisinages de chacun de ses points.Ex: $]a,b[ \\subset \\mathbb R$ $B_{\\Vert \\cdot\\Vert }(x,R); R &amp;gt; 0$DÃ©finition: Soit $f : u \\subset \\mathbb R^n \\rightarrow \\mathbb R^n$ une fonction dÃ©finie en $a \\in u$, $f$ est diffÃ©rentiable en $a$ sâ€™il existe $\\lambda_u \\in \\mathcal L(\\mathbb R^n, \\mathbb R^n)$ telle que$\\forall h$ assez proche de $\\underline{0}$:$f(u+h)=f(a) + \\lambda_a(h) + o_\\underline{0}(h)$ $\\underline{0} = (0, â€¦, 0) \\in \\mathbb R^n$PropriÃ©tÃ©: Quand elle existe lâ€™application linÃ©aire $\\lambda a$ est unique.Preuve: Supposons quâ€™il existe pour h assez proche de 0,2 $\\lambda_n,\\mu_n \\in \\mathcal(\\mathbb R^n, \\mathbb R^m)$ telles que:$f(a+h) = f(a) + \\lambda_n(h) + o_\\underline{0}(h)$$= f(a) + \\mu_a(h) + o_\\underline{0}(h)$$\\forall h$ assez proche de $\\underline{0}$:$(\\lambda_a - \\mu_a)(h) = o_\\underline{0}(h)$Soit $v_1, \\ldots ,v_n$ une base de $\\mathbb R^n$.Pour $t$ au voisinage de $0 \\in \\mathbb R; t \\ne 0$$\\forall i \\in {1,\\ldots, n}$$(\\lambda_a - \\mu_a)(tv_1) = o_\\underline{0}(t\\overbrace{n}^{\\in \\mathbb R^n})$Dâ€™ou $(\\frac{\\lambda_a - \\mu_a)(tv_1)}{t} = o_\\underline{0}(v)$$\\Leftrightarrow (\\lambda_a -\\mu_a)(v_i) = o_\\underline{0}(v)$$\\Rightarrow (\\lambda_a -\\mu_a)(v_i) = 0 \\qquad t \\rightarrow 0$Comme $\\lambda_a - \\mu_a$ est une application linÃ©aire nulle sur tout Ã©lÃ©ment de la base $v_1,\\ldots,v_n$ elle est nulle. Donc $\\lambda_a = \\mu_a$.Definition: Soit $f: u \\rightarrow \\mathbb R^n$ definie sur un ouvert $u \\subset \\mathbb R^n$ Si $f$ est diffÃ©rentiable, lâ€™unique application lineaire $Df(u) \\in \\mathcal L (\\mathbb R^n, \\mathbb R^n)$, telle que pour h assez proche de \\underline{0}.$f(a+h) = f(a) + Df(a)(h) + o_\\underline{0}(h)$$Df(a)$ est appelÃ©e dans le ce cas la diffÃ©Ã©Ã©rentielle de $f$ en $a$. PropriÃ©tÃ©: Si $f$ est diffÃ©rentiable en un point $a \\in u$ alors elle est continue en $a \\in u$ PropriÃ©tÃ©s: Soient $f,g$ 2 fonctions \\(\\begin{aligned}&amp;amp;u \\\\ &amp;amp;\\mathbb R^n \\rightarrow \\mathbb R\\end{aligned}\\) diffÃ©rentiables en $a \\in u$ alors $\\forall \\lambda \\in \\mathbb R, \\lambda f$ est diffÃ©rentiables en a et $D(\\lambda f(a)) = \\lambda Df(a)$ $f+g$ est diffÃ©rentiable en $a$ et $D(f+g)(a)=Df(a) + Dg(a)$ $\\langle f,g \\rangle$ est diffÃ©rentiable en a et $D(\\langle f, g\\rangle)(a) = \\langle f(a), Dg(a)\\rangle + \\langle Df(a), g(a) \\rangle$ Prop: Soient f, g des fonctions diffÃ©rentiables respectivement en $a$ et $b = f(a)$ Alors $g \\circ f$ est diffÃ©rentiable en a et $D(g \\circ f)(a) = Dg(f(n))\\circ Df(a)$$\\mathbb R^n \\overset{f}{\\longmapsto}\\mathbb R^m \\overset{g}{\\longmapsto}\\mathbb R^k$$a \\rightarrow f(a)$$\\mathbb R^n \\overset{Df(a)}{\\longmapsto}\\mathbb R^m \\overset{dg(f(a))}{\\longmapsto}\\mathbb R^k$ Ex:1) $\\mathbb R^n \\overset{f}{\\rightarrow} \\mathbb R$$X \\rightarrow \\langle X,X \\rangle = X^TX$ 2) $\\mathbb R^n \\overset{g}{\\rightarrow} \\mathbb R$$X \\rightarrow e^{X^TX}$ f(X + h) = (X + h)^T(X+h)$= (X^T +h^T)(X +h)$$f(X) = X^TX + h^TX + X^Th + h^Th$$\\mu_q h^Th = \\theta_\\underline{0}(h)$$h \\ne 0, \\frac{|h^Th|}{\\Vert h\\Vert _2} = \\frac{|h^Th|}{\\sqrt{h^Th}}$$= \\sqrt{hTh} = \\Vert h\\Vert _2 \\rightarrow 0; h \\rightarrow \\underline{0}$ Rappel normes, voir plus haut.$\\Vert x\\Vert _0 =$ # dâ€™elements non nuls de x. (ce nâ€™est pas une norme)InÃ©galitÃ© triangulaire inversÃ©e: $|: \\Vert x\\Vert -\\Vert y\\Vert : | \\le \\Vert x - y\\Vert $A partir dâ€™une norme \\Vert .\\Vert on dÃ©finit la notion distance: $d: E \\times E \\rightarrow \\mathbb R^+$$(x,y) \\rightarrow \\langle x,y \\rangle$alors $\\sqrt{ \\langle x,x \\rangle}$ est une norme pour x.Voisinage de aBoule centrÃ©e en a et de rayon r.$\\rightarrow$â€Tout ce qui se passe Ã  une $\\underbrace{\\text{distance}}_{\\text{besoin dâ€™une norme}} r$ de $a \\in \\mathbb R^n$$\\rightarrow B_{\\Vert .\\Vert }(a,r) = {x \\in \\mathbb R, d(x,a) \\lt r}$Ceci est une boule ouverte$B_{\\Vert .\\Vert }(a,r) = {x \\in \\mathbb R^n, d(x,a) \\le r}$Ceci est une boule fermÃ©e$\\overline{B_{\\Vert .\\Vert }} = B_{\\Vert .\\Vert } \\cup B_{\\Vert .\\Vert }$Les fonctions norme sont des fonctions convexes.\\(p = \\frac 12 \\qquad x = \\begin{pmatrix} x_1 \\\\ x_2\\end{pmatrix} \\qquad \\Vert x\\Vert _{\\frac12} = (\\sqrt{\\vert x_1\\vert } + \\sqrt{\\vert x_2\\vert })^2\\)\\(B_{\\Vert .\\Vert \\frac12}(0,1) = \\{(x_1,x_2) \\in \\mathbb R^2, (\\sqrt{\\vert x_1\\vert } + \\sqrt{\\vert x_2\\vert } \\le 1\\}\\)Dans le cadre ou $x_1 \\ge 0, x_2 \\ge 0$$(\\sqrt{x_1} + \\sqrt{x_2})^2 &amp;lt; 1$$\\sqrt{x_1} + \\sqrt{x_2} &amp;lt;1$$x_2 &amp;lt; (1 - \\sqrt{x_1})^2$$f:(\\mathbb R^n, \\Vert .\\Vert _{\\alpha} \\rightarrow (\\mathbb R^p, \\Vert .\\Vert _p)$$x = (x_1, â€¦, x_n) \\rightarrow (f_1(x_1,â€¦,x_n),â€¦f_p(x_1,â€¦,x_n))$$a \\in \\mathbb R^n f$ est continue en $a \\in \\mathbb R^n$$\\forall \\varepsilon &amp;gt; 0, \\exists \\mu &amp;gt; 0, \\forall x \\in \\mathbb R^n, \\Vert x - a\\Vert _{\\alpha} &amp;lt; \\mu \\Rightarrow \\Vert f(x) - f(a)\\Vert _{\\beta} &amp;lt; \\varepsilon$Deux normes $\\Vert .\\Vert _\\alpha$ et $\\Vert .\\Vert _{\\beta}$ sont equivalentes ssi$\\exists c \\ge 0, C \\ge 0, \\forall x \\in E, c\\Vert x\\Vert _\\beta \\le \\Vert x\\Vert _\\alpha \\le C\\Vert x\\Vert _\\beta$dans un espace vectoriel de dimension finie, toutes les normes sont Ã©quivalentes.$x \\in \\mathbb R^n, x = \\begin{pmatrix} x_1 \\ .\\ .\\ .\\ x_n\\end{pmatrix}$\\(\\Vert x\\Vert_1 = \\sum_{i = 1}^n \\vert x_i\\vert \\qquad \\Vert x\\Vert _\\infty = max_{i = 1,...,n}\\vert x_i\\vert\\)â€¦Fonction LipschitzienneUne fonction est dite Lipschitzienne ssi: $\\exists K &amp;gt; 0$ tq $\\Vert f(x) - f(y)\\Vert \\le K \\Vert x - y\\Vert $$\\forall x,y \\in D_y$Si f est Lipschitzienne, f est continue. $f: \\mathbb R^2 \\rightarrow \\mathbb R$$(x_1,x_2) \\rightarrow x_1 + x_2$$x = \\begin{pmatrix}x_1\\ x_2\\end{pmatrix} y = \\begin{pmatrix}y_1\\ y_2\\end{pmatrix}$$\\Vert x - y\\Vert = \\Vert \\begin{pmatrix}x_1 - y_1\\ x_2 - y_2\\end{pmatrix}\\Vert _1 = |x_1-y_1| + |x_2 - y_2|$$\\Vert f(x) - f(y)\\Vert _1 = \\Vert x_1 + x_2 - (y_1 +y_2)\\Vert _1$$= \\Vert (x_1 - y_1)+ (x_2 -y_2)\\Vert _1$$= |(x_1 - y_1) + (x_2 - y_2)|$$\\le|x_1 - y_1| + |x_2 - y_2|$Lâ€™ensemble des fonctions continues est un espace vectoriel. Si f,g sont continues $\\lambda f + \\mu g$ est continue $\\forall(\\lambda,\\mu) \\in \\mathbb R^2 \\rightarrow$ structure dâ€™espace vectoriel Si p =1, f*g est continue, $\\frac fg$ est continu partout ou g ne sâ€™annule pas. Si $h:\\mathbb R^p \\rightarrow \\mathbb R^n$ qui est continue, alors $h\\circ f: \\mathbb R^n \\rightarrow \\mathbb R^n, x\\rightarrow h(f(x))$ est continue.Toutes les fonctions de type polynome sont continues.et $\\frac{f(x,y)}{g(x,y)}$ avec f et g polynomiales, est continue partout ou g ne sâ€™annule pas. (fonction rationelle)$\\begin{cases} \\frac{xy}{x^2 +y^2} \\text{ si } (x,y) \\ne (0,0)0 \\text{ sinon}\\end{cases}$$f(x,0) = 0 \\rightarrow$ continu en 0$f(0,y) = 0 \\rightarrow$ continu en 0 exempleSoient $g:t \\rightarrow (t,t)$$f \\circ g(t) = f(g(t)) =f(t,t) = \\frac{t^2}{t^2 + t^2} = \\frac{t^2}{2t^2} = \\frac12$ si $t \\ne 0$ Donc $f \\circ g$ nâ€™est pas continue. Exercice:1)$\\mathbb R \\overset{f}\\longmapsto \\mathbb R\\ X \\longmapsto X^T X$On cherche Ã  determiner la diffierenciablitÃ© de $f$ en tout point $a \\in \\mathbb{R}^n$\\(\\begin{aligned}f(a+h)&amp;amp;=(a+h)^T(a+h) \\\\ &amp;amp;=a^Ta+h^Ta+a^Th+h^Th \\\\ &amp;amp;=f(a)+\\underbrace{2a^Th}_{h \\rightarrow 2a^Th \\\\\\text{ est linÃ©aire}}+h^Th\\end{aligned}\\)$\\Vert h\\Vert _2^2=\\Vert h\\Vert _2\\Vert h\\Vert _2=\\Vert h\\Vert \\varepsilon(h)$On a $f(a+h)=f(a)+\\text{ lim en h }+o_0(h)$. $f$ est diffÃ©rentiable en a et $\\Delta f(a)h=2a^Th$2)$\\mathbb R^n$ $\\overset{g}{\\rightarrow} \\mathbb R$$X \\rightarrow e^{X^TX}$$g: \\mathbb R^n \\overset{f}{\\rightarrow} \\mathbb R \\overset{exp}{\\rightarrow} \\mathbb R$$X \\rightarrow X^TX \\rightarrow e^{X^TX}$On sâ€™intÃ©resse Ã  la diffÃ©renciabilitÃ© de g en $a\\in\\mathbb{R}^n$. La fonction g est composÃ©e de fonctions diffÃ©rentiables, elle est donc diffÃ©rentiable en tout point.En $a \\in \\mathbb{R}^n, \\Delta g(aâ€™)h=\\Delta \\exp (a^Ta)(\\Delta f(a)f(h))$Dans le cours: $\\Delta g(a)=\\Delta(exp\\circ f)(a)=\\Delta \\exp (f(a))\\circ \\Delta f(a)$\\(\\forall h \\in \\mathbb{R}^n, \\Delta g(a)(h)=\\Delta \\exp (a^Ta)(\\underbrace{\\Delta f(a)f(h)}_{\\in \\mathbb{R}})\\) $\\Delta f(a)(h)=2aTh \\qquad h \\in \\mathbb R$ $\\Delta exp(y)(k) = expâ€™(y)\\cdot k = e^yk$$\\implies \\Delta g(a)(h) = e^{a^Ta} \\times 2a^Th \\qquad h \\in \\mathbb R^n\\space a^T \\in \\mathbb R^n, e^{a^Ta} \\in \\mathbb R$ Gradient et dÃ©rivÃ©es partiellesSoit $f:U \\underline{\\subset} \\mathbb R^n \\rightarrow \\mathbb{R}^m$ une application diffÃ©rentiable en $a \\in U$. On peut donc Ã©crire, pour h assez proche de 0:$f(a+ h) = f(a) + Df(a)(h) + \\underset{l \\rightarrow 0}{o_0(h)}$$(f(a+h) = f(a) + \\Delta f(a)f(h) + \\Vert h\\Vert \\varepsilon(h))$Lâ€™application $\\Delta f(a)\\in \\mathscr{L}(\\mathbb{R}^n, \\mathbb{R}^m)$ oÃ¹ $\\mathscr{L}(\\mathbb{R}^n,\\mathbb{R}^m)$ est lâ€™ensemble des applications linÃ©aires de $\\mathbb{R}^n$ dans $\\mathbb{R}^m$, est caractÃ©risÃ©e par sa matrice dans des bases donnÃ©es. DÃ©finition:On appelle jacobienne de $f$ en $a \\in U$ la matrice de $Df(a)$ dans les bases canoniques de $\\mathbb{R}^n$ et $\\mathbb{R}^m$ Dans cette section,on Ã©tudie comment trouver les coefficients de la matrice jacobienne de $f$ en $a$Notation:La jacobienne de $f$ en $a$ sâ€™Ã©crit $\\mathcal J_f(a) \\in M_{m,n}(\\mathbb{R})$On a $f(a+ h) = f(a) + \\mathcal J_f(a) \\cdot h + o_0(h)$On se pose en premier temps la question de savoir comment dÃ©terminer les lignes, puis en un second temps, les colonnes.$\\color{purple}{\\text{Pour les lignes}}$On Ã©crit $f = (f_1, -, f_m)$oÃ¹ $f_i:u \\rightarrow \\mathbb R$ est la composante de $f$ suivant la $i_{eme}$ coordonnÃ©e.Exemple:$\\mathbb R^3 \\overset{f}{\\rightarrow} \\mathbb R^4$$\\begin{pmatrix}x \\ y \\ z \\end{pmatrix} \\rightarrow \\begin{pmatrix}xy^2 \\ x+y+z \\ xyz \\ z\\end{pmatrix}$En notant,$f_1\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = xy^2$$f_2\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = x+y+z$$f_3\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = xyz$$f_4\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = z$on a $f = (f_1, f_2, f_3, f_4)$En $a \\in U$, on a pour chaque $f$:$f_1(a+h) = f_i(a) + \\mathcal J_{f_i}(a)h + \\Vert h\\Vert \\varepsilon(h)$On peut donc Ã©crire:\\[\\begin{aligned}f(a+h) &amp;amp;= \\begin{pmatrix} f_1(a+h) \\\\ \\vdots \\\\ f_m(a+h) \\end{pmatrix} \\\\ &amp;amp;=\\begin{pmatrix} f_1(a) + \\mathcal J_{f_1}(a)h + \\Vert h\\Vert \\varepsilon (h)\\\\ \\vdots \\\\ f_m(a) + \\mathcal J_{f_m}(a)h + \\Vert h\\Vert \\varepsilon (h) \\end{pmatrix} \\\\ &amp;amp;= \\begin{pmatrix} f_1(a) \\\\ \\vdots \\\\f_m(a)\\end{pmatrix} + \\begin{pmatrix} \\mathcal J_{f_1}(a)h \\\\ \\vdots \\\\\\mathcal J_{f_m}(a)h\\end{pmatrix} + \\Vert |\\varepsilon(h) \\\\&amp;amp;= f(a) + \\begin{pmatrix} \\mathcal J_{f_1}(n) \\\\ \\vdots \\\\ \\mathcal J_{f_m}(n)\\end{pmatrix}h + \\Vert h\\Vert \\varepsilon(h)\\end{aligned}\\]$(\\mathcal J_{f_i}(n) \\in \\mathbb M_{m,n}(\\mathbb R))$â€$\\varepsilon(h)$â€ est une quantitÃ© nÃ©gligeable sous forme de vecteurPar unicitÃ© de la diffÃ©rentielle, on a : $\\mathcal J_f(a) = \\begin{pmatrix} \\mathcal J_{f_1}(a) \\ \\vdots \\ \\mathcal J_{f_m}(a)\\end{pmatrix}$Autrement dit, $\\mathcal{J}f(a)$ est la concatÃ©nation des $\\mathcal{J}{f_i}(a)$ verticalement (en colonnes).$\\color{purple}{\\text{Pour les colonnes}}$Il nous reste Ã  comprendre comment constuire la jacobienne en un point dâ€™une fonction de $\\mathbb{R}^n$ dans $\\mathbb{R}$.Soit $g:U\\subset\\mathbb{R}^n\\longmapsto \\mathbb{R}$ une fonction diffÃ©rentiable en $a\\in U$.Pour h assez proche de $\\underline{0}$, $g(a+h)+g(a)+\\mathcal{\\mathcal J}_{g}h+\\Vert h\\Vert \\varepsilon(h)$Soit $v\\in \\mathbb{R}^n$ et $t\\in \\mathbb{R}$, pour t assez proche de 0, \\(g(a+tv)=g(a)+\\mathcal{J}_g(a)tv+\\Vert tv\\Vert \\varepsilon(tv)\\)\\(g(a+tv)=g(a)+t\\mathcal{J}_g(a)v+\\Vert tv\\Vert \\varepsilon(tv)\\)Si $t \\neq 0$:\\(\\frac{g(a+tv)-g(a)}{t}=\\mathcal{J}_g(a)v+\\varepsilon(tv)\\)Quand $t\\longmapsto 0$ on a\\(\\mathcal{J}_g(a)v=\\displaystyle\\lim_{t\\rightarrow0}\\frac{g(a+tv)-g(a)}{t}\\)La valeur de la $\\mathcal{J}_g(a)$ en un vecteur v est dÃ©crite par la dÃ©rivÃ©e de la direction de g Ã  la droite a+tv.$g_v:t \\rightarrow g(a +tv)$$\\mathbb R : \\frac{g(a + tv)-g(a)}{t} = \\frac{g_v(t) - g_v(0)}{t}$ DÃ©finition:On appelle dÃ©rivÃ©e directionelle de g en a le long de v, la limite, quand elle existe, \\(\\partial_v(g(a))=\\lim_{t\\rightarrow0}\\frac{g(a+tv)-g(a)}{t}\\)Notation:Dans le cas v, câ€™est un vecteur de la base canonique, $v=ej$ on note\\(\\partial_{e_j}g(a)=\\frac{\\partial g}{\\partial x_j}(a)\\) Remarque:On vient de voir que si $g$ est diffÃ©rentiable en $a$ alors $g$ admet des dÃ©rivÃ©es directionnelles en $a$ le long de tout vecteur. La rÃ©ciproque est fausse.On peut avoir des directionnelles en tout point mais ne pas Ãªtre diffÃ©rentiable.\\[\\begin{cases} \\frac{x^2 y}{x^4 + x^2} &amp;amp; \\text{si} (x, y) \\neq (0, 0) \\\\ 0 \\qquad &amp;amp; \\text{sinon}\\end{cases}\\] PropriÃ©tÃ©: Si les dÃ©rivÃ©es partielles de g sont des fonctions continues alors g est diffÃ©rentiable en tout point de fonction diffÃ©rentielle $x \\longmapsto Df(x)$ continue. DÃ©sormais si g est diffÃ©rentiable en un point a alors\\(\\mathcal Jg(a) = (\\underbrace{\\frac{\\delta g(a)}{\\delta x_1}}_{\\mathcal Jg(a)e_1} \\dots \\underbrace{\\frac{\\delta g(a)}{\\delta x_n}}_{\\mathcal Jg(a)e_n})\\) Pour h assez proche de 0\\(g(a+h) = g(a) + \\underbrace{\\mathcal J_g(a)h}_{\\mathcal M_{1,n}(\\mathbb R)} + \\Vert h\\Vert \\varepsilon(h)\\) DÃ©finition: [gradient]On appelle gradient de g en a\\(\\nabla g(a)=\\mathcal{J}_g(a)^T\\)On lit $\\nabla$ â€œnablaâ€ Ex:Calculer:1) $\\nabla g(x,y)$ pour $\\mathbb R^2 \\rightarrow \\mathbb R$$(x,y) \\rightarrow xy^2 + y$2) $\\mathcal J_f(x,y)$ pour$\\mathbb R^2 \\rightarrow \\mathbb R^3$$(x,y) \\rightarrow (xy, y^2, \\sin(xy))$ 1) $\\frac{\\partial g (x,y)}{\\partial x} = y^2$ $\\frac{\\partial g (x,y)}{\\partial y} = 2yx + 1$$\\Rightarrow \\nabla g(x,y) = \\begin{pmatrix}y^2 \\ 2yx + 1\\end{pmatrix}$ 2)$\\mathcal Jf(x, y)= \\begin{pmatrix}y &amp;amp; x \\ ycos(xy) &amp;amp; xcos(xy)\\end{pmatrix}$ " }, { "title": "PRST: Feuille 4 - Exercices", "url": "/cours/posts/prst_feuille_4/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-22 11:00:00 +0100", "snippet": "Lien de la note HackmdExercice de coursProposer un intervalle de confiance asymptotique au niveau $0,90$ pour la moyenne $m$ dâ€™une variable alÃ©atoire. Solution Astuce: mettre $0,05$ de chaque cote de la courbe, on cherche donc $95\\%$ sur notre table de loi normale centree reduite On a donc $1,96$ dans la table. Cf. cours.Exercice de coursFranÃ§ois prÃ©lÃ¨ve 300 serpents dans une forÃªt et constate que 70 dâ€™entre eux sont venimeux.DÃ©terminer un intervalle de confiance asymptotique pour la proportion de serpents venimeux dans cette forÃªt au niveau de confiance 0, 95. Solution $\\hat p = \\frac{70}{300}\\simeq0,23, n = 300$ Conditions dâ€™applications du resultat: $n\\ge 30$ $n\\hat p \\ge5$ $n(1-p)\\ge5$ \\[\\hat p -1,96\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\simeq 0,18\\\\\\hat p +1,96\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\simeq 0,28\\] On a donc $[0,18;0,28]$Exercice 1Proposer un intervalle de confiance au niveau $0,90$ pour la moyenne $m$ pour une variable aleatoire gaussienne de variance $2$ dont nous connaissons les observations suivantes : $3,1 ; 2,4 ; 5 ; 7$ et $2,8$. Solution \\[\\sigma = 2\\\\V(X) = \\sqrt 2\\\\\\bar X_n \\simeq 4,06\\\\\\] On obtient $[3,023;5,09]$ Exercice 6 Soit $U_n$ une variable aleatoire suivant une loi $\\mathcal X^2(n)$, $(n\\ge1)$. Admettons que $\\phi_{U_n}(t)=\\frac{1}{(1-2it)^{\\frac{n}{2}}}$ est sa fonction caracteristique. (a) Montrer que $E(U_n)=n$ (b) Montrer que $V(U_n)=2n$ Soient $X$ et $Y$ deux variables aleatoires independantes suivant respectivement des lois $\\mathcal X^2(m)$ et $\\mathcal X^2(n)$. Montrer que la variable aleatoire $X+Y$ suit une loi $\\mathcal X^2(m+n)$ Solution\\[E(X) = \\frac{\\phi&#39;(0)}{i} \\text{(cf chapitre 1 complement)}\\\\\\phi_{U_n}&#39;(t)= \\frac{ni}{(1-2it)^{\\frac{n}{2}+1}}\\\\E(X) = \\frac{\\phi_{U_n}&#39;}{i}=n\\\\\\] \\((\\frac{1}{u^n})&#39;=-\\frac{ku&#39;}{u^{k+1}}\\) \\[\\phi_{U_n}&#39;&#39;(t)=\\frac{-(n+2)n}{(1+2it)^{\\frac{n}{2}+2}}\\\\E(X^2)=-\\phi^{(2)}(0) = n(n+2)\\\\V(X) = E(X^2)-E(X)^2=n(n+2-n)=2n\\] $X\\sim\\mathcal X^2(m)$, $Y\\sim\\mathcal X^2(n)$\\[\\begin{aligned}\\phi_{X+Y}&amp;amp;=\\phi_X(t)\\phi_Y(t)\\\\&amp;amp;= \\frac{1}{(1-2it)^{\\frac{m}{2}}}\\times\\frac{1}{(1-2it)^{\\frac{n}{2}}}\\\\&amp;amp;=\\frac{1}{(1-2it)^{\\frac{m+n}{2}}} \\text{ , cqfd.}\\end{aligned}\\]" }, { "title": "PRST: Seance 4 - Intervalle de confiance", "url": "/cours/posts/prst_seance_4/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, Student, Khi-deux, intervalle, confiance", "date": "2021-03-22 10:00:00 +0100", "snippet": "Lien de la note Hackmd Il y a 2 types dâ€™estimation: estimation ponctuelle (les estimateurs) estimation par intervalle Deux resultats probabilistes: loi forte des grand nombre theoreme central limiteIntervalle de confiance pour la moyenne $m$Point de depart $(X_1,â€¦, X_n)$ echantillon i.i.d de taille $n$ $(x_1,â€¦,x_n)$ rÃ©alisations de cet Ã©chantillon $\\bar x_n = \\frac{1}{n}\\sum_{i=1}^nx_i$ estimation ponctuelle de la moyenne (espÃ©rance) $m$ $S_n^2=\\frac{1}{1-n}\\sum_{i=1}^n(x_i-\\bar x_n)^2$ estimation ponctuelle de la variance $\\sigma^2$ Dans la majorite des cas, on ne connait pas la loi de probabilite dâ€™un experience aleatoireDans le modele de Bernoulli avec un echantillon i.i.d de la $\\mathcal B$, un intervalle de confiance au niveau $0,95$ est:\\[[f-\\frac{1}{\\sqrt{n}};f+\\frac{1}{\\sqrt{n}}]\\]Câ€™est un encadrement de la valeur reelle de $p$ TheroemeLa proportion $p$ appartient a cet intervalle, pour $95\\%$ des echantillons, sous les conditions: $n\\ge30$ $nf\\ge5$ $n(1-f)\\ge5$ Deux cas: $n$ quelconque: v.a. normales $n$ grand et utilisation du TCLTheoreme central limiteSoit $(X_i)$ une suite de v.a. i.i.d telle que $E(X_1^2)\\le+\\infty$. Noton $m:=E(X_i)$ et $\\theta^2=V(X_i)$\\[\\frac{\\sqrt{n}(\\bar X_n-m)}{\\theta}\\]converge en loi vers une loi normale centrÃ©e rÃ©duiteLoi normale centree reduite $\\mathcal P(X\\le0)=P(X\\ge0)=0,5$ $\\mathcal P(X\\le a)=\\mathcal P(X\\ge a)$ $\\mathcal P(-1,96\\le X\\le1,96)\\simeq 0,95$ et $\\mathcal P(-2,58\\le X\\le2,58)\\simeq 0,99$\\[m\\in\\biggr[\\bar X_n-1,96\\frac{\\sigma}{\\sqrt n};\\bar X_n+1,96\\frac{\\sigma}{\\sqrt n}\\biggr]\\]au niveau de confiance $0,95$Cas gaussien$X_1$ suit une loi normal, $\\forall n\\ge 1$, $\\frac{\\sqrt n(\\bar X_n-m)}{\\sigma}$ suit une loi normale centree reduite et\\[\\mathbb P(-1,96\\le \\frac{\\sqrt n(\\bar X_n-m)}{\\sigma}\\le1,96)\\simeq 0,95\\]Cas general\\[m\\in\\biggr[\\bar X_n-1,96\\frac{\\sigma}{\\sqrt n};\\bar X_n+1,96\\frac{\\sigma}{\\sqrt n}\\biggr]\\]au niveau de confiance $0,95$ La forme generale de lâ€™intervalle de confiance asymptotique general pour $1-\\alpha$ pour la moyenne $m$ est :\\[\\biggr[\\bar X_n-z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt n};\\bar X_n+z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt n}\\biggr]\\] Avec: $z_{1-\\frac{\\alpha}{2}}$: fractile dâ€™ordre $1-\\frac{\\alpha}{2}$ de la loi $\\mathcal N(0,1)$ Cas particulier du modele de Bernoulli Intervalle de confiance pour la proportion dâ€™un echantillon dans une population donnee variance inconnue approximation pour la loi normale possible grace au theoreme suivant: Theoreme de Moivre-Laplace$X_n$ v.a $\\sim\\mathcal B(n,p)$. Soit $q:=1-p$\\[\\forall x\\in\\mathbb R\\\\\\lim_{n\\to+\\infty}\\mathbb P(\\frac{X-n-np}{\\sqrt{npq}}\\le x)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^xe^{-\\frac{t^2}{2}}dt=F(X)\\]Intervalle de confiance de la proportion $p$ Lâ€™intervalle de confiance asymptotique au niveau $1-\\alpha$ pour la proportion $p$ est:\\[\\biggr[\\hat p - z_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}; \\hat p + z_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\biggr]\\]Loi du Khi-deux$(X_1,â€¦,X_n)$ $n$ v.a. independantes normales centrees reduite. La v.a. $U_n:=\\sum_{i=1}^nx_i^2$ suit une loi du Khi-deix a $n$ degres de liberte notee $\\mathcal X^2(n)$ $f_{U_n}=\\frac{1}{2^{\\frac{n}{2}}}e^{-\\frac{x}{2}}x^{\\frac{x}{2} - 1}$ pour $x\\ge 0$ $E(U_n) = n$ $V(U_n) = 2n$ $\\phi_{U_n}(t)=\\frac{1}{(1-2it)^{\\frac{n}{2}}}$ Theoreme$X$ et $Y$ deux v.a. independantes suivant respectivement $\\mathcal X^2(m)$ et $\\mathcal X^2(n)$ alors la v.a $X+Y$ suit une loi $\\mathcal X^2(m+n)$Loi de Student$X$ et $Y$ deux v.a aleatoires independantes suivant les lois $\\mathcal N(0,1)$ et $\\mathcal X^2(n)$.\\[T_n=\\frac{X}{\\sqrt{\\frac{Y}{n}}}\\]suit une loi de Student $\\mathcal T_n$ a $n$ degre de libertePropriete $E(T_n) = 0$ (symetrie) $V(T_n)=\\frac{n}{n-2}$ pour $n\\gt2$ Theoreme$T_n$ converge en loi vers $\\mathcal N(0,1)$ lorsque $n$ tend vers $+\\infty$.Cas gaussien $X_1$ suit une loi normale $Tn:=\\frac{\\sqrt n(\\bar X_n-m)}{\\sqrt{S_n^2}}$ suit une loi de Student a $n-1$ degrÃ©s de libertÃ©. Lâ€™intervall de confiance au niveau $1-\\alpha$ pour la moyenne $m$ est:\\[\\biggr[\\bar X_n-t_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{S_n^2}}{\\sqrt n};\\bar X_n+t_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{S_n^2}}{\\sqrt n}\\biggr]\\] Avec: $t_{1-\\frac{\\alpha}{2}}$ fractile dâ€™ordre $1-\\frac{\\alpha}{2}$ de la loi de Student $n-1$ degrÃ©s de libertÃ©. " }, { "title": "IML: Dimensionality reduction", "url": "/cours/posts/iml_dimensionality_reduction/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8, principal component analysis", "date": "2021-03-19 13:00:00 +0100", "snippet": "Lien de la note HackmdWhy do we care ?We have at hand $n$ points $x1,â€¦, xn$ lying in some N-dimensional space, $x_i \\in\\mathbb R^n , \\forall i = 1, . . . , n,$ compactly written as a $n Ã— N$ matrix $X$ One row of $X$ = one sample One column of $X$ = a given feature value for all samplesExample of real high-dimensional data Real world data is very often high-dimensionalMNIST image classification: Sample $x$:image with 28x28 pixels Data set: 60000 samples Dimensionality: $x \\in\\mathbb R^{28Ã—28=784}$MUSE hyperspectral image analysis: Sample $x$: pixel with 3600 spectral bands Data set: image with 300x300 pixels Dimensionality: $x \\in \\mathbb R^{3600}$ Pour discriminer les galaxies câ€™est raciste ca monsieurThe curse of dimensionality High-dimensional spaces suck donkey ballz suffer from the curse of dimensionality (also called Hughesâ€™ phenomenon)Sur $\\mathbb R$Sur $\\mathbb R^2$Revenir a la meme densite dâ€™echantillonage:Sur $\\mathbb R^3$Revenir a la meme densite dâ€™echantillonage:\\[\\frac{\\nu(\\mathbb S^n)}{\\nu([-1;1]^n)}=\\frac{\\pi^{\\frac{n}{2}}}{2\\Gamma(\\frac{n}{2}+1)}\\to_{n\\to+\\infty}0\\] Points uniformly distributed in a $n$âˆ’cube of side 2 mostly fall outside of the unit sphere! Why is it tricky? We naturally cannot picture anything that is more than 3D in our mind Picturing something 3D in a 2D flat screen can already be misleading Real data naturally lives in (complex) high-dimensional space Real data is often strongly correlated And somehow, we want to have a good look to our data before feeding it to some machine learning algorithm (can I use the inherent structure of my data to pimp my machine learning performances?)How ? Dimensionality reduction: transform data set $X$ with dimensionality $N$ into a new data set $Y$ ($n \\times M$ matrix) with dimensionality $M \\lt N$ (hopefully $M \\lt\\le N$) such that as few information as possible is lost in the process. $y_i$ ($i$th row of $Y$) is the low-dimensional counterpart (the projection) of $x_i$.INFORMATION ???Linear approachesSomehow trying to find a low-dimensional subspace in which the projected data would not be too much distorted after projection. Johnson-Lindenstrauss lemma Classical scaling (The one and only) Principal Component Analysis And much moreâ€¦Johnson-Lindenstrauss lemmaItâ€™s not because you can that you will Let $0\\lt\\varepsilon\\lt1$ and let $x_1,â€¦,x_n$ be $n$ points in $\\mathbb R^N$. Then there exists a linear map $f:\\mathbb R^N\\to\\mathbb R^M$ such that for every points $x_i$ and $x_j$\\[(1-\\varepsilon)\\Vert x_i-x_j \\Vert^2\\le \\Vert f(x_i)-f(x_j) \\Vert^2\\le(1+\\varepsilon)\\Vert x_i-x_j \\Vert^2\\] With $M=\\frac{4\\log(n)}{(\\frac{\\varepsilon^2}{2} âˆ’ \\frac{\\varepsilon^3}{3}).}$ Johnson, W. B., &amp;amp; Lindenstrauss, J. (1984). Extensions of Lipschitz mappings into a Hilbert space. Contemporary mathematics. La douille: il faut trouver la matrice $M$.Classical scalingAlso called Principal Coordinates Analysis (PCoA) Lots of formula here, but you just need to retain the overall idea PCoA: project data points $X$ onto $Y$ with a linear mapping $M$ such that $Y = XM$ such that all pairwise distances between points do not change too much before/after projectionIf $D$ is the $n \\times n$ Euclidean distance matrix with entries $d_{ij} = \\Vert x_i âˆ’ xj\\Vert_2$ and $D^{(2)} = [d_{ij}^2]$, PCoA seeks the linear mapping $M$ that minimizes\\[\\phi(Y)=\\sum_{i,j}(d_{ij}^2-\\Vert y_i-y_j\\Vert^2)\\]with $y_i = x_iM$ and $\\Vert m_i\\Vert^2=1\\forall i$ Solution: eigendecomposition (=diagonalisation) of the Gram matrix $K = XX^T = E\\Delta E$$K$ can be obtained by double centering $D^{(2)}:K=-\\frac{1}{2}C_nD^{(2)}C_n$ with centering matrix $C_n=I_n-\\frac{1}{n}ones(n,n)$Optimal projection onto the first $M$ dimensions $Y=\\Delta_M^{\\frac{1}{2}}E_M^T$ with $E_M$ matrix of the $M$ largest eigenvectors of $E$.Principal component analysis Also known as the Karhunen-Loeve transformClosely related to PCoA, but operates on the covariance matrix $X_c^T X_c$ PCA seeks the linear mapping $M$ that maximizes the projection variance $tr(M^T cov(X)M)$ with $\\Vert mi\\Vert^2 = 1 \\forall i$.\\[X=\\begin{bmatrix}\\overbrace{x_{11}}^{u_1=\\text{moyenne}} &amp;amp; \\overbrace{x_{12}}^{u_2}\\\\\\vdots &amp;amp; \\vdots\\\\x_{n1}&amp;amp;x_{n2}\\end{bmatrix} \\Rightarrow \\text{centrage des donnees}\\]\\[X_c=\\begin{bmatrix}x_{11}-u_1 &amp;amp; x_{12}-u_2\\\\\\vdots &amp;amp; \\vdots\\\\x_{n1}1-u_1&amp;amp;x_{n2}-u_2\\end{bmatrix}\\] Center the data $X_c = C_nX$ 1.b (opt) Reduce the data Compute covariance matrix $\\sum=\\frac{1}{n-1}X_c^TX_c$ Perform eigendecomposition $(E,\\Delta)$ of $\\sum$ Project on the first $M$ principal axes $Y=XE_M$Data after projection is uncorrelated, but haslost some interpretabilityMajor challenges related to PCAPCA is probably the most popular and used unsupervised linear dimensionality reduction technique, but it comes with a bunch of operability questions, the 2 principles being: How to automatically select the right number of dimensions to project? How to project a new data point on a learned projection subspace? See you in lab session for the answer Non-linear approachesWhen it is assumed that the data does not livein an Euclidean subspace (why would it anyway?),some more advanced techniques must be reliedon. Isomap Locally linear embedding Kernel Principal Component Analysis (aka PCA on steroids) Multilayer autoencoders And much moreâ€¦Isomap Geodesic distance rocksIsometric feature mapping: same idea as classical scaling, but using geodesic distance instead of Euclidean distance. Compute k-nearest neighbor graph of data $x_1,â€¦,x_n$ Compute all pairwise geodesic distances Apply classical scalingExempleIsomap applied to some images of the digit 2 in MNIST dataLocally linear embeddingLocally linear embedding: the manifold can be locally considered EuclideanFor each point $x_i$: get its k-nearest neighbors $x_j$, $j=1,â€¦,k$ Get weights $w_{ij}$ that best linearly reconstruct $x_i$ with $x_j$: minimize $\\sum_{i=1}^n\\Vert x_i-\\sum w_{ij}x_j\\Vert$ with constraints $\\sum w_{ij}=1$ (closed-form solution) Low-dimensional embedding $\\to$ reconstruct $y_i$ with $y_j$ and same weights $w_{ij}$:minimize \\(\\sum_{i=1}^n\\Vert y_i-\\sum w_{ij}y_j\\Vert\\)with constraints $\\frac{1}{n}\\sum_iy_iy_i^T$ and $\\sum_iy_i=0$ (eigendecomposition of a Gram matrix)The kernel trick When one actually wants to increase the dimensionBase idea: map $n$ non linearly separable points to a (possibly infinite) space where they would be with a function $\\phi$ How should we define $\\phi$ ? Do we really want to compute stuff in a (possibly infinite) feature space? Mercer theorem: we do not need to know the mapping $\\phi$ explicitly as long as we have a positive semi-definite kernel/Gram matrix $K=[\\mathcal k(x_i,x_j)]=[&amp;lt;\\phi(x_i),\\phi(x_j)&amp;gt;]$Widely used kernel functions: Polynomial kernel: $\\mathcal k(x_i,x_j)=(x_i^Tx_j+1)^d$ Gaussian RBF kernel: $\\mathcal k(x_i,x_j)=e^{-\\gamma\\Vert x_i-x_j\\Vert^2}$ Sigmoid kernel: $\\mathcal k(x_i,x_j)=\\tanh(bx_i^Tx_j+c)$Kernel PCA PCA on steroidsThe maths behind are quite hard, but the following scikit-learn recipe works fine: Compute kernel matrix $k=[\\mathcal k(x_i,x_j)]=[&amp;lt;\\phi(x_i),\\phi(x_j)&amp;gt;]$ and double-center it $K_c=C_nKC_n$ Eigendecomposition of $K_c$ is strongly related to this of the (intractable) covariance matrix in the feature space $\\to$ get eigenvectors $V$ and corresponding eigenvalues $\\Delta$ of $K_c$. Keep the first $M$ columns of $\\sqrt{\\Delta V}$ to get the coordinates of projected data points in the low $M$-dimensional space. But things get nasty when one wants to project a new data point $x$ that was not known when constructing the kernelâ€¦Non-linear PCA Also known as autoencoderOverall idea: train an autoencoder (neural network with an autoassociative architecture) to perform an identity mapping. use the output of the bottleneck layer as low-dimensional code.Bottleneck code is a non-linear combination of entries (thanks to activation functions on the encoder layers) $\\to$ learned mapping is a non-linear PCA.Principal components are generalized from straight lines to curves: the projection subspace which is described by all nonlinear components is also curved.Letâ€™s recapHigh-dimensional data set $X$ is a $n \\times N$ matrix, with $n =$ number of samples and $N =$ dimensionality of underlying space. Parametric $\\equiv$ explicit embedding from high-dimensional space to low-dimensional one For LLE: $p$ is the ratio of non-zero elements in a sparse matrix to the total number of elements For NL-PCA: $i$ is the number of iterations and w is the number of weights in the neural networkt-Distributed Stochastic Neighbor Embeddingt-SNE is a popular method to see in 2D or 3D wtf is going on in a high-dimensional spaces. Construct a probability distribution $p$ over pairs of points in the high-dim space: the more similar (the closer) the two points, the higher the probability Define a second probability distribution $q$ over the points in the low-dim space, and dispatch the points such that the distance between p and q in minimized (for the KullbackLeibler divergence) t-SNE is excellent in visualizing the well-separated clusters, but fails to preserve the global geometry of the data. t-SNE depends on a perplexity parameter, which reflects the scale of search for close points.Independant component analysisICA aims to provide a solution to the so-called cocktail party: retrieving independent sources that got mixed-up together with unknown scaling coefficients.Goal: estimate source $s$ and mixing matrix $A$ from observation $x = As$. Ill-posed $\\Rightarrow$ enforce independence on source components Work on higher order statistics (PCA limits to order-2 statistics) Unkown source must not be Gaussian-distributedContrarily to PCA vectors, ICA vectors are not orthogonal and not ranked by importance,but they are mutually independents." }, { "title": "OCVX: Parties de R et convexite", "url": "/cours/posts/ocvx_partie_r_convexite_/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-18 10:00:00 +0100", "snippet": "Lien de la note HackmdRappels de la seance precedente description des sous espaces affine de $\\mathbb R^n$ sous espaces vectoriels de $\\mathbb R^n$ $E\\subset\\mathbb R^n$ $0_{\\mathbb R^n}\\in E$ Sous espace affine $A=x_0+E$, $E$ sous espace vectoriel et $x\\in\\mathbb R^n$ Un sous-espace affine nâ€™est pas un sous-espace vectoriel.Un sous-espace vectoriel est un sous-espace affine.\\[\\begin{aligned}(D) &amp;amp;= \\{x\\in\\mathbb R^n, X_0+\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= X_0+\\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\rightarrow\\text{description parametrique}\\end{aligned}\\]Description implicite Description implicite: ensemble des points qui verifient une certaine equation\\[\\begin{aligned}(D)=dx \\text{ tel que } &amp;lt;&amp;amp;x,n&amp;gt;=0\\\\&amp;amp;x^Tn=0\\end{aligned}\\]\\(\\{x\\text{ tel que } &amp;lt;x,n&amp;gt;=b\\}\\\\\\text{si je sais que } x_0\\in(D), &amp;lt;x_0,n&amp;gt;=b\\\\\\begin{aligned}\\{x \\text{ tel que }&amp;lt;x,n&amp;gt;=b=&amp;lt;x_0,n&amp;gt;&amp;amp;\\}\\\\&amp;lt;x,n&amp;gt;-&amp;lt;x_0,n&amp;gt;=0&amp;amp;\\}\\\\&amp;lt;x-x_0,n&amp;gt; = 0&amp;amp;\\}\\end{aligned}\\)Description de parties de $\\mathbb R^n$Ecriture impliciteOn se donne une fonction \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x=\\begin{pmatrix}x_1\\\\\\vdots\\\\x_n\\end{pmatrix}&amp;amp;\\mapsto f(x)\\end{aligned}\\\\\\begin{aligned}&amp;amp;\\mathcal C_0=\\{x\\in\\mathbb R^n\\vert f(x)=0\\}\\\\&amp;amp;\\mathcal C_x=\\{x\\in\\mathbb R^n\\vert \\underbrace{f(x)=x}_{g(x)=f(x)-r, \\mathcal C_r(f)=\\mathcal C_0(g)}\\}\\text{ courbe de niveau }x\\end{aligned}\\)Lieu de sous niveau\\(\\mathcal C_{\\le r}(f)=\\{x\\in\\mathbb R^n\\vert f(x)\\le r\\}\\)Exemple\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\)Question 3-10\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\\\\\begin{aligned}\\mathcal C_0(f)&amp;amp;=\\{(0,0)\\}\\\\\\mathcal C_1(f)&amp;amp;=\\{(x,y)\\in\\mathbb R^2 \\text{ tel que } x^2+y^2=1\\}\\Rightarrow\\text{ cercle de rayon } 1\\\\\\mathcal C_2(f)&amp;amp;=\\text{ cercle de rayon }\\sqrt{2}\\end{aligned}\\)\\[\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+4y^2\\end{aligned}\\\\\\] Equation dâ€™une ellipse de demi grand axe $a$ et demi petit axe $b$ \\(\\{(x,y)\\in\\mathbb R^2\\text{ tel que } (\\frac{x}{a})^2+(\\frac{y}{b})^2=1\\}\\)\\[a=b=r\\\\(\\frac{x}{a})^2+(\\frac{y}{b})^2=1\\Leftrightarrow x^2+y^2=r^2\\]\\(\\begin{aligned}\\mathcal C_0(g)&amp;amp;=\\{(0,0)\\}\\\\\\mathcal C_1(g)&amp;amp;=\\{(x,y)\\in\\mathbb R^2 \\text{ tel que } \\underbrace{x^2+4y^2=1}_{(\\frac{x}{1})^2+(\\frac{y}{\\frac{1}{2}})^2=1}\\}\\\\\\mathcal C_2(g)&amp;amp;=\\text{ de meme que }\\mathcal C_1\\end{aligned}\\)Question 3-11Surface definie apr les 2 branches dâ€™une hyperbole $y\\mapsto\\frac{1}{x}$\\[\\{(x,y)\\in\\mathbb R^2, \\underbrace{y=\\frac{1}{x}}_{xy=1}\\}\\\\\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto xy\\end{aligned}\\\\y\\le\\frac{1}{x}\\Leftrightarrow yx\\le1\\] Donc pour la decrire: \\(\\{(x,y)\\in\\mathbb R^2, xy\\le1\\}=\\mathcal C_{\\le1}(g)\\)Ecriture parametriqueExemples\\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R\\\\t&amp;amp;\\mapsto f(t)\\end{aligned}\\\\graph(f)\\subset\\mathbb R^2\\\\\\{(t,f(t)),t\\in\\mathbb R\\}\\rightarrow\\text{ ecriture parametrique}\\)\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\\\graph(f)=\\{(x,y),f(x,y)),(x,y)\\in\\mathbb R^2\\}\\]Definition Soit\\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\t&amp;amp;\\mapsto f(t)\\end{aligned}\\\\graph(f)=\\{(t,f(t)),t\\in\\mathbb R^n\\}\\)Avec une ecriture parametrique, on peut se ramener a une ecriture implicite\\[y=f(x)\\Leftrightarrow f(x)-y=0\\\\graph(f)=\\{(x,f(t)),x\\in\\mathbb R\\}\\\\\\begin{aligned}graph(f) &amp;amp;= \\{(x,y),x\\in\\mathbb R,y=f(x)\\}\\\\&amp;amp;= \\{(x,y), x\\in\\mathbb R\\,\\underbrace{f(x)-y}_{g(x,y)}=0\\}\\\\&amp;amp;=\\{(x,y), g(x,y)=0\\}=\\mathcal C_0(g)\\end{aligned}\\]Epigraphe (au-dessus du graphe) dâ€™une fonction $f$\\(Epi(f) = \\{(x,t),t\\ge f(x)\\}\\)Convexite dans $\\mathbb R^n$Parties convexes de $\\mathbb R^n$ On va dessiner des patates et des haricotsQuelle forme est convexe ? Si on prend 2 points quelconque de $A$ et quâ€™on trace ce segment, alors le segment est inclut dans $A$ $A$ est convexe et $B$ ne lâ€™est pas.Pour un segment entre $x$ et $y$, nâ€™importe quel point de ce segments est une proportion du segment\\(tx+(1-t)y, t\\in[0;1]\\\\\\begin{aligned}t&amp;amp;=0\\to y\\\\t&amp;amp;=1\\to x\\\\t&amp;amp;= \\frac{1}{2}\\to\\text{milieu de } [x,y]\\end{aligned}\\) A CONNAITRE Definition: Une partie $A\\subseteq\\mathbb R^n$ est convexe si, et seulement si\\(\\forall x,y\\in A\\\\\\forall t\\in[0;1]\\\\tx+(1-t)y\\in A\\) Proprietes tout intervall de $\\mathbb R$ est convexe les sous espaces affines/les demi espaces sont convexesOn a $A$ et $B$ convexes $A\\cap B\\to$ convexe $A\\cup B\\to$ en general pas convexeEnveloppe convexe dâ€™une partie $A\\subseteq\\mathbb R^n$Si on a une forme non-convexe, on â€œbouche les trousâ€ pour rendre la forme convexe et on obtient $conv(A)$ Intersection de tous les convexes qui $\\supseteq$ $A$. plus petit convexe qui $\\supseteq$ $A$ Soit $A$ une partie de $\\mathbb R^n$$x$ un point du bord si $\\forall\\varepsilon\\gt0, B(x,\\varepsilon)\\cap A\\neq \\emptyset$ $\\to$ bord/frontiere $\\delta A$ On appelle: adherence de $A$, $\\bar A=A\\cup \\delta A$ interieur de $A$, $\\dot A=A \\setminus\\delta A$ \\[A=[0;1[\\to\\begin{cases} \\delta A = \\{\\{0\\};\\{1\\}\\}\\\\ \\bar A = [0;1]\\\\ \\dot A = ]0;1[\\end{cases}\\]Hyperplan dâ€™appui $A$ admet un hyperplan dâ€™appui en $x\\in\\delta A$Si on peut definir un hyperplan qui separe lâ€™espace en deux demi espaces tels que $A$ tombe integralement dans lâ€™un des deux. $A$ admet un hyperplan dâ€™appui de normale $\\vec n$ en $x\\in\\delta A$ si, et seulement si,\\(\\forall y\\in A, &amp;lt;y-x,n&amp;gt;\\le0\\) Question 3-20 Nâ€™ayant pas dâ€™hyperplan dâ€™appui en un point donnÃ© de son bord:Haricots $\\to$ pas dâ€™hyperplan dâ€™appui en certains points de son bord. Ayant plus dâ€™un hyperplan dâ€™appui en un mÃªme point: il faut un anglePoint anguleux $\\to$ plusieurs hyperplan dâ€™appuis en ce point la Nâ€™ayant aucun hyperplan dâ€™appui:Pas dâ€™hyperplan dâ€™appui pour tous les points de bord. Ayant un hyperplan dâ€™appui en tous les points de son bord:Pour tous les convexes Une partie est convexe ssi on peut definir un hyperplan dâ€™appui en tout point de son bord.Fonction convexes A CONNAITRE Une fonction $f:\\mathbb R^n\\to\\mathbb R$ est convexe ssi: $Dom f$ est convexe $\\forall x,y\\in Dom f$, $\\forall t\\in[0;1]$ $f(tx+(1-t)y)\\le tf(x)+(1-t)f(y)$ $f$ concave si $-f$ convexe.Les droites affines sont les seules fonctions concaves ET convexesPetit bestiaire de fonctions convexes: $ax+b$ $e^{\\alpha x}, \\forall\\alpha\\in\\mathbb R$ $ax^2+bx+c$, $a\\ge0$ $-\\log(x)=\\log(\\frac{1}{x})$ $\\sqrt{x}$ $x^n$, $n$ pair La somme ponderee positivement de fonctions convexes est une fonction convexe \\(f_{i_{i\\ge 0}},i=1,...,N\\text{convexes}\\\\f=\\sum_{i=1}^N\\omega_if_i\\\\\\)Demonstration\\(Dom f=\\cap Dom f_i\\to\\text{ convexe}\\)Soit $x,y\\in Dom f$ et $t\\in[0;1]$\\(\\begin{aligned}f(tx+(1-t)y)&amp;amp;=\\sum_{i=1}^N\\omega_i\\underbrace{f_i(tx+(1-t)y)}_{\\le tf_i(x)+(1-t)f_i(y)\\text{ car } f \\text{ convexe}}\\\\&amp;amp;\\le \\sum_{i=1}^N\\omega_itf_i(x) + \\sum_{i=1}^N\\omega_i(1-t)f_i(y)\\\\&amp;amp;\\le t\\underbrace{\\sum_{i=1}^N\\omega_if_i(x)}_{f(x)} + (1-t)\\underbrace{\\sum_{i=1}^N\\omega_if_i(y)}_{f(y)}\\\\f(tx+(1-t)y)&amp;amp;\\le tf(x)+(1-t)f(y)\\end{aligned}\\) $f=\\max_{i=1,â€¦,n}f_i$ est convexe la composition dâ€™une fonction convexe $f$ avec $g$ affine croissant $g\\circ f$ est convexeLien entre partie convexe et fonction convexe: Lâ€™epigraphe dâ€™une fonction convexe est une partie convexe Tous les lieux de sous niveaux dâ€™une fonction convexe sont des parties convexesEn dimension 1:" }, { "title": "PRST: Exercices de cours du 17/03", "url": "/cours/posts/prst_exercises_17_03/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, Fisher, EMV", "date": "2021-03-17 14:30:00 +0100", "snippet": "Lien de la note Hackmd Les exos sont fait dans le meme ordre que pendant le coursExercice - loi normale loi normale de paramÃ¨tres $m$ et $\\sigma$ avec $\\sigma=1$ densite $f(x,m)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x-m)^2}{2}}$ pour $x\\in\\mathbb R$ et $m\\in\\mathbb R$ DÃ©terminer lâ€™EMV. Solution\\[\\begin{aligned}L(x_1,...,x_n)&amp;amp;=\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x_i+m)^2}{2}}\\\\&amp;amp;= \\biggr(\\frac{1}{\\sqrt{2\\pi}}\\biggr)^ne^{-\\sum_{i=1}^n\\frac{(x_i-m)}{2}}\\end{aligned}\\] Passons au logarithme. Est-ce que la fonction est paire ?Oui car $\\log$ est defini sur $\\mathbb R^{+*}$.\\[\\log(L(x_1,...,x_n,m))=-n\\log(\\sqrt{2\\pi})-\\sum_{i=1}^n\\frac{(x_i-m)^2}{2}\\] Derivons par rapport a m:\\[\\begin{aligned}\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m} &amp;amp;= -\\sum_{i=1}^n\\biggr[(-x_i)+m\\biggr]\\\\&amp;amp;= \\sum_{i=1}^nx_i-nm\\\\\\end{aligned}\\\\\\begin{aligned}\\\\\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m}=0&amp;amp;\\Leftrightarrow\\sum_{i=1}^nx_i-mn=0\\\\&amp;amp;\\Leftrightarrow\\frac{1}{n}\\sum_{i=1}^nx_i=m\\end{aligned}\\] Verifions la condition du second ordre:\\[\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m}=-n\\lt0\\] Donc la condition suffisante est verifiee. $\\hat m = \\bar X$ est lâ€™EMV du parametre $m$.Exercice - loi geometrique loi gÃ©omÃ©trique de paramÃ¨tre $p$ $P(X=x)=p(1-p)^{x-1}$ pour $x\\gt1$ et $p\\in]0;1[$ DÃ©terminer lâ€™EMV. Solution Soit $(x_1,â€¦,x_n)\\in\\mathbb N^n_*$.\\[\\begin{aligned}L(x_1,...,x_n,p)&amp;amp;=\\Pi_{i=1}^np(1-p)^{x_i-n}\\\\&amp;amp;=p^n(1-p)^{\\sum_{i=1}^n(x_i-1)}\\end{aligned}\\\\\\log(L(x_1,...,x_n,p))=n\\log(p)+\\sum_{i=1}^n(x_i-1)\\log(1-p)\\\\\\frac{\\delta\\log(L(x_1,...,x_n,p))}{\\delta p}=\\frac{n}{p}-\\sum_{i=1}^n\\frac{x_1-1}{1-p}\\] \\[(\\log u)&#39;=\\frac{u&#39;}{u}\\\\\\Leftrightarrow \\log (1-p) = -\\frac{1}{1-p}\\] \\[\\frac{\\delta\\log(L(x_1,...,x_n,p))}{\\delta p} = 0\\\\\\begin{aligned}\\frac{n}{p}=\\sum_{i=1}^n\\frac{x_1-1}{1-p}&amp;amp;\\Leftrightarrow n(n-p)=p\\sum_{i=1}^n(x_i-1)\\\\&amp;amp;\\Leftrightarrow n-np=p\\sum_{i=1}^nx_i - np\\\\&amp;amp;\\Leftrightarrow p = \\frac{n}{\\sum_{i=1}^nx_i} = \\frac{1}{\\frac{n}{\\sum_{i=1}^nx_i}} = \\frac{1}{\\bar X}\\end{aligned}\\\\\\] \\[(\\frac{1}{u})&#39; = -\\frac{u&#39;}{u^2}\\] \\[(\\frac{1}{1-p})&#39;=-\\frac{(-1)}{(1-p)^2}=\\frac{1}{(1-p)^2}\\] \\[\\frac{\\delta^2\\log(L(x_1,...,x_n,p))}{\\delta p^2}=-\\frac{n}{p^2}-\\frac{\\sum_{i=1}^n(x_i-1)}{(1-p)^2}\\lt0\\] Donc la condition suffisante est verifiee. $\\hat p =\\frac{1}{\\bar X}$ est lâ€™EMV du parametre $p$.Exercice - information de FisherDÃ©terminer lâ€™information de Fisher pour la loi de Poisson de paramÃ¨tre $\\lambda$. Solution\\[\\log f(x,\\lambda)=-\\lambda+x\\log(\\lambda)-\\log(x!)\\\\\\frac{\\delta\\log f(x,\\lambda)}{\\delta\\lambda} = -1+\\frac{x}{\\lambda}\\\\\\frac{\\delta^2\\log f(x,\\lambda)}{\\delta\\lambda^2}=-\\frac{x}{\\lambda^2}\\\\\\begin{aligned}E_n\\biggr(\\frac{\\delta^2\\log f(X,\\lambda)}{\\delta\\lambda^2}\\biggr)&amp;amp;=-E(\\frac{X}{\\lambda^2})\\\\&amp;amp;=-\\frac{1}{\\lambda^2}\\times\\lambda=-\\frac{1}{\\lambda}\\end{aligned}\\\\I(\\lambda)=-E\\biggr(\\frac{\\delta^2\\log f(x,\\lambda)}{\\delta\\lambda^2}\\biggr)=\\frac{1}{\\lambda}\\]" }, { "title": "IML: Introduction", "url": "/cours/posts/iml_introduction/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8", "date": "2021-03-17 11:00:00 +0100", "snippet": "Lien de la note HackmdMotivationWhat is learning ?Itâ€™s all about evolving DefinitionLearning: Improver over experience to perform better in new situations. Quoting S. BengioLearning is not learning by heart.Any computer can learn by heart.The difficulty is to generalize a behavior to a novel situation.Can machines learn ?A new science with a goal and an object. How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes ? Tom Mitchel, 2006 What is it good for ?According to Peter NorvigThe 3 main reasons why you may want to use Machine Learning: Avoid coding numerous complex rules by hand lower cost, more effective, faster reaction to changing problem Optimize the parameteres of your system given a dataset of yours Better accuracy Create systems for which you do not know the rules conscioulsy (e.g. recognize a face) Greater potential AI vs Machine Learning AI is a very fuzzy concept, much like â€œany computer program doing something usefulâ€ Think â€œif-thenâ€ rules ML can be considered a subfield of AI since those algorithms can be seen as building blocks to make computers learn to behave more intelligently by somehow generalizing rather that just storing and retrieving data items like a database system would do Engineering point of view: ML is about builiding programs with turnable parameters (typically an array of floating point values) that are adjusted automatically so as to improve their behavior by adapting to previously seen dataMachine Learning vs Deep LearningTraditional Machine LearningDeep LearningAI vs ML vs DLDL $\\subset$ ML $\\subset$ AIExerciseMachine Learning ExamplesCan you list examples of projects or products involving Machine Learning ? Google LensMachine Learning ProblemWhy is learning difficult ?Generalization is an ambiguous process.Given a finite amount of training data, you have to derive a relation for an infinite domain.In fact, there is an infinite number of such relations.How should we draw the relation?Which relation is the most appropriate?â€¦the hidden test points (seen after the training)â€¦Learning biasHow to guide generalization It is always possible to find a model complex enough to fit all the examples Example: polynomial with very high degree But how would this help us with new samples? It should not generalize well. We need to define a family of acceptable solutions to search from It forces to learn a â€œsmoothedâ€ representation. â€¦ but it should not smooth the representation too much! Occamâ€™s Principle of Parsimony (14th century)One should not increase, beyond what is necessary, the number of entities required to explain anything.When many solutions are available for a given problem, we should select the simplest one.But what do we mean by simple?We will use prior knowledge of the problem to solve to define what is a simple solution. Example of a prior: smoothnessLearning as a search problemHypothesis space / initial, compatible (with train set), optimal, and ideal solutionsWhat are the sources of error ?Noise, intrinsic errorYour data is not perfect (can have noisy or erroneous labels). (or â€œEvery model is wrong.â€) Even if there exist an optimal underlying model, the observations are corrupted by noise.(Inductive) bias, approximation errorWe are exploring a restricted subset of all possible solutions. Your classifier needs to drop some information about the training set to have generalization power (simplify to generalize).Variance, estimation errorYou have many ways to explain your training dataset. It is hard to find an optimal solution among those many possibilities. Our exploration is not very accurate, we are limited by data we see during training.Bias / variance compromise Low bias $\\Leftrightarrow$ high variance: large search set, can capture many useless details overfitting High bias $\\Leftrightarrow$ low variance: small search set, limited exploration, solution too simple underfitting. Solutions: regularization (penalize solutions which are too complex), early stopping (stop when no more progress)â€¦Parameters of a ML problemMany variations for each element Protocol: supervision? feedback? how many samples for each â€œexperienceâ€? Measure of success: error cost? convergence? â€¦ Inputs (representation space): quality (noise, distribution) and nature (numerical, symbolical, mixed) Solutions (space hypothesis/functions to explore): many approachesThree kinds of ML problemsAccording to Samy BengioRegressionRegression input: samples described by several input variables (correlated)Regression output: a quantitative variable (scalar)Regression, classificationClassification input: samples described by several input variables (correlated)Classification output: a qualitative variable (class, category)Regression, classification, density estimationDensity estimation input: samples described by several input variables (correlated)Density estimation output: estimate of the probability distribution function overthe feature spaceThree kinds of supervision/trainingsAccording to Lecun, S. Bengio Supervised learning: Training data contains the desired behavior â€” desired class, outcome, etc Medium feedback Reinforcement learning: Training data contains partial targets â€” Did the system do well or not? Is some object present in the image (without knowing is position)? Weak feedback Unsupervised/Self-supervised learning: Training data is raw, no class or target is given. There is often a hidden goal in the task: compression, maximum likelihood, predict parts from other parts (BERT-like)â€¦ Lot of feedback Forms of Machine LearningAccording to Cornuejols and Miclet Exploration-based: Generalization or specialization of rules Examples: Grammatical inference, heuristic discovery for SAT solversâ€¦ Optimization-based: Topic of this course. Examples: linear separators and SVMs, neural networks, decision trees, Bayesian networks, HMMsâ€¦ Approximation-based: Data compression, analogy. Examples: KNN, embedding spaces Machine Learning EngineeringML from an engineer point of viewSolve problems using the right toolSome taxonomySimplified view of pre-2010 Machine LearningChoosing the right toolWhy we love scikit-learnRepresenting dataWhy we love scikit-learnRelated domainAt the cross-roads of numerous fields Signal processing Databses, information retrieval Statistics Pattern Recognition Optimization Data science, data mining" }, { "title": "ASE2: TD 2", "url": "/cours/posts/ase2_td2/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, poisson, normale", "date": "2021-03-17 10:00:00 +0100", "snippet": "Lien de la note Hackmd Avec Poisson: approximation en serie, mieux de passer par la Gaussienne (loi binomiale) car moins de calculsExercice 9Une usine fabrique des pieces, dont $3\\%$ ont des defauts On preleve 1000 pieces au hasard Quelle est la probabilite dâ€™avoir plus de $50$ pieces defectueuses ? Quelles est la probabilite dâ€™avoir entre $20$ et $40$ pieces defectueuses ? On veut $1950$ pieces sans defaut. Par prudence, on en preleve $2000$ au hasard. Quelle est la probabilite dâ€™avoir sufffisamment de pieces en bon etat ? Solution Soit $X$ la v.a.: nombre de pieces defectueurse parmi 1000. $X$ suit la loi $\\mathcal B(n,p)$ avec $n=1000$ et $p=0,03$\\[\\mathcal B(n,p)\\simeq \\mathcal N(np,\\sqrt{npq})\\\\\\text{Donc } \\frac{X-np}{\\sqrt{npq}}\\to^{\\mathcal L}\\mathcal N(0,1)\\text{ (theoreme Moivre-Laplace)}\\\\\\begin{cases} np=30\\\\ npq=29,1\\end{cases}\\\\\\sqrt{npq}=\\sqrt{29,1}=5,4\\] 1.1.\\[\\begin{aligned}P(X\\gt50)&amp;amp;=1-P(X\\le50)\\\\&amp;amp;\\simeq 1-P(U\\le\\frac{50-30+0.5}{5,4})\\end{aligned}\\] avec $U=\\frac{X-30}{5,4}\\sim \\mathcal N(0,1)$\\[\\begin{aligned}P(X\\gt50)&amp;amp;\\simeq 1-P(U\\le3,8)\\\\&amp;amp;\\simeq 1-F(3,8)=1,0-0,9999... = 0\\end{aligned}\\] 1.2.\\[P(20\\le X\\le40)\\simeq P(\\frac{20-30-0,5}{5,4}\\le U\\le\\frac{40-30+0,5}{5,4})\\] avec $U=\\frac{X-30}{5,4}\\sim \\mathcal N(0,1)$\\[\\begin{aligned}P(20\\le X\\le40)&amp;amp;= P(-1,94\\le U\\le 1,94)\\\\&amp;amp;= F(1,94)-F(-1,94) \\text{ } F \\text{ fonction de repartition de }\\mathcal N(0,1)\\\\&amp;amp;= F(1,94)-(1-F(1,94))\\\\&amp;amp;= 2F(1,94)-1 = 2\\times 0,9738 \\text{ (Table de } \\mathcal N(0,1)\\text{)}\\\\&amp;amp;= 0,9476\\end{aligned}\\] 2.\\[X\\to\\mathcal B(2000,p=0,03), n=2000\\\\np=60,npq=58,2,\\sqrt{npq}=7,63\\\\\\mathcal B(2000;0,03)\\simeq\\mathcal N(60;7,63)\\] On veut $1950$ pieces en bon etat, donc:\\[P(X\\le50)=P(\\frac{X-60}{7,6}\\le\\frac{50-60+0,5}{7,63})\\\\U=\\frac{X-60}{7,63}\\to\\mathcal N(0,1)\\] Donc:\\[\\begin{aligned}P(X\\le50)&amp;amp;=P(U\\le-1,25)\\\\&amp;amp;= F(-1,25)\\\\&amp;amp;= 1-F(1,25)\\\\&amp;amp;= 1-0,8944=0,1056\\end{aligned}\\]Exercice 10Le nombre de pannes, par mois, sur une certaines machine, suit une loi de Poisson de moyenne egale a $3$. Un atelier fonctionne avec $12$ machines de ce type, independantes.En un mois, quelle est la probabilite de constater dans cet atelier: Plus de $42$ pannes ? entre $36$ et $45$ pannes ? Solution Soit $X_i$ v.a.: nombre de pannes, en un mois de la machine $n^oi$, $X_i\\to\\mathcal P(3)$.Soit $S_{12}=X_1+X_2+â€¦+X_{12}$, $S_{12}$: nombre de pannes dans lâ€™atelier$(X_i)$ sont independantes donc: $S_{12}=\\sum_{i=1}^{12}\\to\\mathcal P(12\\times 3)=\\mathcal P(36)$.\\[S_{12}\\to\\mathcal P(36), \\lambda=36\\gt20\\] On peut approximer cette loi par la loi normale:\\[\\frac{S_{12}-36}{\\sqrt{36}}\\simeq\\mathcal N(0,1)\\] 1. On cherche $P(S_{12}\\gt42)$\\[\\begin{aligned}P(S_{12}\\gt42)&amp;amp;=P(\\frac{S_{12}-36}{6}\\gt\\frac{42-36}{6})\\\\&amp;amp;= P(\\frac{S_{12}-36}{6}\\gt1)\\\\&amp;amp;=1-P(U&amp;lt;1)\\text{ avec } U=\\frac{S_{12}-36}{6}\\\\&amp;amp;=1-F(1)\\\\&amp;amp;=1-0,8413=0,1587\\end{aligned}\\] 2.\\[\\begin{aligned}P(36\\lt S_{12} \\lt45) &amp;amp;=P(0\\lt\\frac{S_{12}-36}{6}\\lt\\frac{3}{2})\\\\&amp;amp;=F(1,5)-F(0)\\\\&amp;amp;= 0,9332-0,5=0,4332\\end{aligned}\\]Exercice 11On jette $600$ fois un de equilibre a $6$ faces. On note $X$ le nombre dâ€™apparitions de lâ€™as (face marquee 1). Quelle est la loi de $X$ ? Calculer $E(X)$ et $V(X)$ Calculer $P(X\\gt 110)$ Determiner un intervale $[a;b]$ centre sur $E(X)$ tel que $P(a\\le X\\le b)=0,95$ Solution 1.\\[X\\to\\mathcal B(n,p)=\\begin{cases}n=600\\\\p=\\frac{1}{6}\\end{cases}\\] 2.\\[E(X) = np = 100,\\sigma(X)=\\sqrt{100\\times\\frac{5}{6}\\times\\frac{1}{6}} = 9,13\\] 3.\\[\\begin{aligned}P(X\\gt110) &amp;amp;= P(\\frac{X-100}{9,13}\\gt\\frac{110-100}{9,13})\\\\&amp;amp;= P(U\\gt\\frac{110-100}{9,13})\\\\&amp;amp;= P(U\\gt1,15)\\text{ avec } U=\\frac{X-100}{9,13}\\to\\mathcal N(0,1)\\\\&amp;amp;= 1-F(1,15)\\end{aligned}\\] Donc $P(X\\gt110)=1-0,8749=0,13$ \\[P(X\\gt110)=0,13\\] 4. Soit $r$: rayon de lâ€™intervalle\\[\\begin{cases}a=E(X)-r\\\\b=E(X)+r\\end{cases}\\] On cherche $r$ tel que\\[P(\\vert X-100\\vert\\le r)=0,95\\] Posons $U=\\frac{X-100}{9,13}$\\[\\begin{aligned}P(\\vert X-100\\vert\\le r)=P(\\vert U\\vert\\le\\frac{r+0,5}{9,13})&amp;amp;=0,95\\\\P(\\frac{-r-0,5}{9,13}\\le U\\le\\frac{r+0,5}{9,13})&amp;amp;=0,95\\\\F(\\frac{r+0,5}{9,13})-F(\\frac{-r-0,5}{9,13})&amp;amp;=0,95\\\\2F(\\frac{r+0,5}{9,13})-1&amp;amp;=0,95\\\\\\end{aligned}\\\\F(\\frac{r+0,5}{9,13}) = \\frac{1,95}{2} = 0,975\\\\\\text{D&#39;apres la table: } \\frac{r+0,5}{9,13}=1,96\\\\\\Rightarrow r= 1,96\\times 9,13-0,5=17,39\\\\\\text{Donc: } \\begin{cases}a=100-17,39=82,61\\\\b=100+17,39=117,39\\end{cases}\\] \\[I=[82,61;117,39]\\] " }, { "title": "ASE2: Convergence et estimation - 3", "url": "/cours/posts/ase2_estimation_3/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, estimation", "date": "2021-03-17 09:00:00 +0100", "snippet": "Lien de la note Hackmd$\\bar X$ est un exemple dâ€™estimateur de la moyenne $m=E(X)$ (sert a approximer la moyenne de la population globale) Utile quand on a un parametre inconnu. Definition:On appelle variance empirique, la statistique :\\[S^2=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar X)^2\\]Proposition\\[S^2 = \\frac{1}{n}\\sum_{i=1}^nX_i^2-(\\bar X)^2\\]Demo\\[\\begin{aligned}S^2&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar X) = \\frac{1}{n}\\sum_{i=1}^n(X_i^2 - X_i\\bar X+\\bar X^2)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nX_i^2-2\\bar X\\sum_{i=1}^nX_i+\\frac{n}{n}\\bar X^2\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nX_i^2-2\\bar X^2+\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i^-(\\bar X)\\end{aligned}\\]Montrons que $S^2\\to^P\\sigma^2$ lorsque $n\\to+\\infty$Dâ€™aprÃ¨s la loi des grands nombres, on a:$\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\to^Pm=E(X)$ quand $n\\to+\\infty$et $\\frac{1}{n}\\sum_{i=1}^nX_i^2\\to^PE(X^2)$ quand $n\\to+\\infty$Donc $S^2=\\frac{1}{n}\\sum_{i=1}^nX_i^2-(\\bar X)^2\\to^PE(X^2)-E^2(X)=\\sigma^2=V(X)$ $S^2$ est un estimateur de la variance. DefinitionOn considÃ¨re une population $X$, distribuÃ©e suivant une loi de probabilitÃ© qui dÃ©pend dâ€™un paramÃ¨tre $\\theta$ inconnu. On prÃ©lÃ¨ve un Ã©chantillon $(X_1,X_2,â€¦,X_n)$ de $X$, on appelle estimateur de $\\theta$, toute variable alÃ©atoire $T_n$ fonction de lâ€™Ã©chantillon:\\[T_n=f(X_1,X_2,...X_n)\\]On appelle biais de lâ€™estimateur la quantitÃ© $b(T_n)=E(T_n)-\\theta$ On dit que lâ€™estimateur est sans biais si $b(T_n)=0\\Leftrightarrow E(T_n)=\\theta$.Comme exemple $\\bar X$ est un estimateur sans biais de $m=E(X)$ puisque $E(\\bar X) = m$ DefinitionOn dit quâ€™une suite $(T_n)$ dâ€™estimateurs de $\\theta$ est asymptotiquement (cad au voisinage de $+\\infty$) sans biais et si\\[lim_{n\\to+\\infty}(E(T_n))=\\theta\\]On appelle risque quadratique de $T_n$ ou erreur quadratique: \\(R(T_n)=E((T_n-\\theta)^2)\\)PropositiomLe risque quadratique est :\\[R(T_n) = V(T_n)+(E(T_n)-\\theta)^2\\]DÃ©monstration\\[(T_n-\\theta)^2=(T_n-E(T_n)+E(T_n)-\\theta)^2\\\\\\begin{aligned}E((T_n-\\theta)^2)&amp;amp;=E((T_n-E(T_n))^2)+2E((T_n-E(T_n))(E(T_n)-\\theta))+E((E(T_n)-\\theta)^2)\\\\&amp;amp;= V(T_n)+2(E(T_n)-\\theta)(E(T_n)-E(T_n))+(E(T_n)-\\theta)^2\\\\\\end{aligned}\\\\\\text{Donc } R(T_n) = V(T_n)+(E(T_n)=\\theta)^2\\]RemarqueSi lâ€™estimateur est sans biais $b(T_n)=E(T_n)-\\theta=0$Alors $R(T_n)=V(T_n)$Donc si on a deux estimateurs sans biais du paramÃ¨tre $\\theta$, le plus prÃ©cis est celui de variance minimale. DefinitionOn dit que lâ€™estimateur $T_n$ est convergent si cet estimateur converge en probabilitÃ© vers le paramÃ¨tre $\\theta$.On ecrira $T_n\\to^P\\theta$ lorsque $n\\to+\\infty$ DefinitionOn appelle vraisemblance de $\\theta$, la densitÃ© de lâ€™Ã©chantillon $(X_1,X_2,â€¦,X_n)$:\\[\\begin{cases}L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nP(X_i=x_i) &amp;amp;\\text{(dans le cas discret)}\\\\L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nf(x_i) &amp;amp;\\text{(dans le cas continu)}\\end{cases}\\]" }, { "title": "IREN: Introduction aux rÃ©seaux neuronnaux ", "url": "/cours/posts/iren_introduction/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8, rÃ©seaux neuronnaux", "date": "2021-03-16 11:00:00 +0100", "snippet": "Lien de la note HackmdIndex du coursUn neurone On reflechis selon les impulsions electriques dans notre cerveau Il y a des seuils pour les impulsions electriques Poid: $w_0$ Energie de la part du voisin: $x_0$ Si on a une mauvaise â€œconnexionâ€, on recoit pas ou peu les informations des voisins On a une fonction dâ€™activation $f$ (seuil) pour savoir si on ressort du neurone A la sortie on a une combinaison lineaire de lâ€™entree de base La fonction dâ€™activation casse la linearite Les problemes ne se reglent pas lineairement a chaque fois Les maths dâ€™un neurone $z=b+\\sum_iw_ix_i$ $y=\\sigma(z)$avec les $i$ entrees $x_i$ $b$ le biais $w_i$ les poids $\\sigma$ la fonction dâ€™activation ReLU: cancer ? $2,5$ en reponse Logistique (sigmoide) vrai ou faux Tangente hyperbolique Varie de $-1$ a $1$ Choisi entre vrai ou faux Un premier reseau neuronalÃ‰valuer les couples dâ€™entrÃ©e $(1,1)$, $(0,1)$, $(1,0)$ et $(0,0)$ avec $\\sigma$ une logistique $(0,0) = 0$Construction dâ€™un reseau neuronalPour construire un rÃ©seau neuronal par apprentissage supervisÃ© il faut : un grand jeu de donnÃ©es Ã©tiquetÃ©es par la sortie voulue dÃ©finir lâ€™architecture du rÃ©seau avec le nombre de couches les types de couches le nombre de nÅ“uds par couche les fonctions dâ€™activations les connexions inter-couches toutes astuces qui fonctionnent une fonction dâ€™erreur pour guider la correction sur les poids une mÃ©thode pour faire converger le rÃ©seau (trouver les bons poids) En cas de problÃ¨me, on sacrifie un poulet.Les donneesLes donnÃ©es doivent Ãªtre trÃ¨s nombreuses (assez pour dÃ©finir toutes les inconnues du rÃ©seau) de bonne qualitÃ© (pour ne pas tromper le rÃ©seau)On appronfondira avec des exemples et lâ€™utilisation de Pandas pour nettoyer les donnÃ©es.Est-ce un champignon ? PrÃ©cision suivant la qualitÃ© des Ã©tiquettes.Lâ€™architecture du rÃ©seauCâ€™est la partie tactique et artistique.Lâ€™Ã©tude des diffÃ©rents rÃ©seaux nâ€™entre pas dans le cadre de ce cours dâ€™introduction. On se limitera Ã  quelques rÃ©seaux lors des TP.La fonction dâ€™erreurLa fonction dâ€™erreur indique de combien le rÃ©seau sâ€™est trompÃ© par rapport Ã la vÃ©ritÃ© terrain ($y$ vs $t$). Elle doit Ãªtre dÃ©rivable correspondre au problÃ¨me traitÃ©Cette fonction est aussi appelÃ©e fonction de coÃ»t (cost function ou loss function en anglais).Exemple Lâ€™erreur quadratique $E = (y âˆ’ t)^2$ $E = \\log(\\cosh(y âˆ’ t))$ quadratique puis linÃ©aire lorsque lâ€™Ã©cart croÃ®t Lâ€™entropie croisÃ©e pour des probabilitÃ©s (valeurs entre $0$ et $1$)\\[E=-\\sum_kt_k\\log(y_k)+(1-t_k)\\log(1-y_k)\\]Une mÃ©thode pour trouver les bons poidsComment lâ€™erreur nous guide pour trouver les poids ?ExempleVous Ãªtes le directeur et tous les jours vous invitez votre Ã©quipe Ã  dÃ©jeuner. Il y a le choix entre le plat A, B ou C. Vous payez chaque jour lâ€™addition.Avec les donnÃ©es $[(5,3,2), 114]$, $[(6,2,2), 108]$, $[(3,4,5), 147]$ qui correspondent aux quantitÃ©s de chaque plat et au prix global, dÃ©duire le prix de chaque plat par une mÃ©thode dâ€™apprentissageQue proposez-vous ?Câ€™est une equations a 3 inconnues mais on veut faire apprendre au reseau de neurones.Supposons quâ€™on met tous les prix a 10euros et quâ€™au lieu de payer 100euros pour 10 plats, on paye 114euros.Reflechir comme un reseau neuronal: On augmente tous les prix On augment les poids en fonction du nombre de fois ou un plat a ete prit On fait un pourcentage $\\rightarrow$ $50%$ La somme de tous les $i$ divise par $i_0$ Utilisons lâ€™erreur pour corriger les poidsLâ€™algorithme consiste Ã  trouver les $w_i$ qui minimisent lâ€™erreur : On initialise les poids Ã  une valeur probable (disons 10 pour tous) On corrige les poids au prorata de leur part dans lâ€™erreur $E = y âˆ’ t$ :\\(w_j = w_j âˆ’ \\eta d_j\\) $d_j = \\frac{E\\times i_j}{\\sum_ki_k}$ $\\eta$ petit pour Ã©viter de sur-corrigerDÃ©roulons lâ€™algorithme avec $\\eta = \\frac{1}{10}$: $[(5,3,2), 114]$ Notre prix estimÃ© est de 100. $d_0=\\frac{(y-t)\\times i_0}{10} = -7.0$ donc $w_0=10+0.70=10.7$ $d_1=\\frac{(y-t)\\times i_1}{10} = -4.2$ donc $w_0=10+0.42=10.42$ $d_2=\\frac{(y-t)\\times i_2}{10} = -2.8$ donc $w_0=10+0.28=10.28$ $[(6,2,2), 108]$ Notre prix estimÃ© est de 105.6 et on obtient $w_0=10.84$, $w_1=10.46$ et $w_2=10.33$ $[(3,4,5), 147]$ Notre prix estimÃ© est de 126.04 et on obtient $w_0=11.37$, $w_1=11.16$ et $w_2=11.20$ On peut rejouer les donnÃ©es jusquâ€™Ã  converger la convergence peut Ãªtre longue avec un petit $\\eta$ cela peut diverger avec un trop grand $\\eta$ \\(\\frac{E\\times i_j}{\\sum_k i_k} = \\alpha\\frac{\\delta(y-t)^2}{\\delta w_j}\\)derivee partielle par rapport a $w_j$RÃ©tropropagation du gradientFonction logistiqueCalculons lâ€™influence du poids $w_{2,2}^2$ sur lâ€™erreur quadratique $E:\\frac{\\delta E}{\\delta w_{2,2}^2}$La derivee partielle de $y$ par rapport a $z$ est $y(1-y)$ Câ€™est $e^x$ qui se balade. Il croise $2$ tout panique qui lui dit â€œDerivee me court apres!â€ et part en courant pendant que $e^x$ se marre. Ensuite $e^x$ tombe sur un gars qui cherche quelquâ€™un, et le gars lui demande â€œTâ€™as pas peur de moi ?â€, $e^x$ repond â€œBah non pourquoi?â€, le gars lui repond â€œBah parce que je suis $\\frac{d}{dy}$â€Que vaut le gradient de $E :\\nabla E$?Pourquoi ce titre ?" }, { "title": "IREN: Tour d&#39;horizon", "url": "/cours/posts/iren_horizon/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8", "date": "2021-03-16 10:00:00 +0100", "snippet": "Lien de la note HackmdNote: projet en binomeIndex du coursCas dâ€™utilisation Pub ciblee Recommendations (Netflix) Description (dâ€™une image pour les personnes malvoyantes) Securite Diagnostique (traitement dâ€™image medicale) Ex: creation dâ€™une IA qui detecte le cancer et a commence a detecter le cancer chez des personnes ou les medecins nâ€™avaient rien trouve et les medecins ont decouvert des nouveaux marqueurs du cancer Jeux (bot pour les echecs) Jeu de go: trop complexe pour tester toutes les possibilites IA developpee qui sâ€™est averee tres creative Majordome (Alexa, Google Home) Le telephoneHistorique Lâ€™IA nâ€™est pas lâ€™oeufLes hivers ont bloque lâ€™IA avant quâ€™elle redemarreLes hiversLa renaissance est dues au triptique donnÃ©es, hardware, thÃ©orie.Aujourdâ€™hui: 3$^{\\text{eme}}$ phase: lâ€™espoir lâ€™IA va regler tous les problemes du monde Lâ€™IA est une copie du cerveau humain (au moins le principe de base)Quand un enfant apprend, il a un flux de donnees continu (vue, ouie, etc.) Les GPUs ont evolues, developpe un parallelisme de choses a faire La theorie: comprehension globale et trucs locaux qui permet de tout faire marcher On nâ€™a PAS de base robuste Ca marche mais on sait pas pourquoi Plus gros câ€™est mieuxBesoin de calculs pour lâ€™entrainement et taille des rÃ©seaux Plus notre reseau est gros, plus on a besoin de donneesOn peut reduire les reseaux de neurones, si une connection entre 2 neurones est trop faible on la supprime.Exemple dâ€™une voiture autonomeResNEt-50 a besoin de $7,72$ G operations pour traiter une image $255\\times 255$ $230$ Gops pour $30$ fps $9,4$ Tops pour du HD $338$ Topes pour $12$ cameras et $3$ couleurs par cameraNvidia A100 Peak rates = GPU boost clock Effective using Sparsity Tensor core: extensions de Nvidia pour gerer Tensorflow (par supposition du prof)Les leadersLes leaders les plusvisible sont Google (Tensorflow, Keras, DeepMind) Facebook (Torch, PyTorch) Microsoft (CNTK) IBM (Watson) Baiduet bien sÃ»r le principal fabriquant : NVidia (Cuda, CuDNN) Ce quâ€™on voit moinsA cotÃ© de ceux qui participent activement Ã  la recherche et audÃ©veloppement des outils, il y a ceux qui lâ€™utilisent en interne. Amazon (Alexa, Amaxon Go) Apple Les constructeurs automobiles (Tesla, Uber, t o u s) tout ceux qui font du conseil (Netflix, Expediaâ€¦), de la pub (Criteo) plein de startups Types dâ€™apprentissageApprentissage supervise On a un jeu dâ€™image et on sait que lâ€™image 4 câ€™est une forme On montre lâ€™image au reseau (qui sortira une reponse au pif vu quâ€™il ne sait rien pour lâ€™instant) On corrige le reseaux en donnant la reponse Le reseaux changent les poids des connexions pour sâ€™adpaterExemple: le spamOn recoit un nouveau mail et le reseau de neurones determine si câ€™est un spam ou non, on le corrige sâ€™il a faux Regression Classification Moindres carres SVM Regression polynomiale Regression logistique, arbre de decisions Reseau neuronal Reseau neuronal La revolution vient des reseaux neuronaux: Mur Demande des quantites enormes de donnees etiquettees Pas toujours simple Ã  faire marcher De plus en plus complexe Produit des rÃ©sultats remarquables en traitement dâ€™image traitement de la parole Apprentissage non supervise classer des classes quâ€™on ne connait pas $\\rightarrow$ clustering $K$-moyennes, ACP, des reseaux de neurones Difficile dâ€™en mesurer lâ€™efficacite (besoin de juges humains) Usage limite mais en progres Probleme: ne sait pas si ce quâ€™il a fait est ok ou non Ex; sâ€™il classe par couluer au lieu de forme Besoin dâ€™humains pour juger Apprentissage par renforcementLie aux jeux videos Rules of the fame are unknown Learn directly from interactive game-play Le jeu informe si on gagne ou perd Pick actions on joystick, see pixels and scoresPoints clefs du renforcement Pas de superviseur qui connait la solution, seulement une note Le retour dâ€™information est decale (pas immediat) La notion de temps est importante $\\rightarrow$ Systeme dynamique Lâ€™agent qui note a un impact sur la suite des donnees quâ€™on va recevoirTestQuel type dâ€™apprentissage ? Comparaison de CNN pour la vision sur route - 2018 Apprentissage renforce (et pas supervise) Appel au tÃ©lÃ©phone - Google â€“ 2018 Un â€œmajordomeâ€ prend RDV Plusieurs techniques en meme temps Essentiellement du supervisÃ© DeepMind StarCraft II combat et explications - 2019 Lâ€™IA Deepmind Starcraft joue et controles ses persos (les bleus) contre un humain (les rouges) Lâ€™IA ne joue pas plus vite que lâ€™humain (elle a une limite) Apprentissage renforce Helicopter - Stanford Univ. â€“ 2008 Apprentissage renforcÃ© On fait un dessin dans le ciel et on dit a lâ€™IA de suivre le dessin le mieux possible MÃ©lodie travaillÃ©e - Music VAE - 2018 Non supervisÃ© Capable dâ€™extraire des carateristiques Creer un vecteur de la musique initiale et finale Creer des etapes intermediaires en â€œinterpolantâ€ Re-genere des vecteurs Recommence depuis la creation de vecteurs DÃ©bat : Lâ€™Ã‰tat doit-il financer les Ã©coles pre-maternelle ? (3 Ã  4 ans) Non â€“ Harish Natarajan Oui â€“ IBM Debater IA IBM (en vente) Comme Google Essentiellement du supervisÃ© Techniques en plus pour la comprehension de texte Un duo et lâ€™artiste cachÃ© (2019 pour la mÃ©thode) Non supervisÃ© On decompose en vecteurs le visage de Macron et celui de lâ€™artiste original Les mouvements de lâ€™artistes original se font sur le visage de Macron Classifie les sourcils, la bouche, etc. De AlphaGo a MuZeroBonus: Film sur AlphaGo A massacre des professionnels Câ€™est comme si nous on voyait le jeu en 2D et AlphaGo en 3D, on est aveugle en comparaison MuZero: Ne donne plus rien (pas de regles, donnees, etc.) Seulement si gagner ou perduUsage futur des differents types dâ€™apprentissageLe monde acadÃ©mique/internet et industriel sont diffÃ©rents.Transfer MLOn prend un reseau qui fonctionne deja dans un cas et on lâ€™adapte pour fonctionner dans un autre cas Effacer les dernieres couches Detecter des objets/formes complexes (ex: une petite fille joue au balon) Garder les premieres couches Detecter des formes de bases Ainsi il est tout Ã  fait possible dâ€™utiliser un rÃ©seau neuronal entrainÃ© pour une tÃ¢che A pour initier lâ€™entrainement du rÃ©seau dâ€™une tÃ¢che B proche.IBM IA pour lâ€™industrie IBM Watson Recruitement une aide a lâ€™embauche pour les entreprises Watson solution pour la vente Watson Assistant pour le marketing Watson Decision Plateform pour lâ€™agriculture IBM Equipement Maintenance Assistant pour amÃ©liorer la qualitÃ© et rÃ©duire la maintenance IBM Watson Supply Chain InsightsSite IBM AI For Industries" }, { "title": "OCVX: TD 1", "url": "/cours/posts/ocvx_td_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8, dimension, lieu, plan", "date": "2021-03-15 14:00:00 +0100", "snippet": "Lien de la note Hackmd Analyse en composante principale: algo data mining et reduction de dimensionsPour la reduction de dimension, on garde que les $n$ premieres.Ca se formule comme un probleme dâ€™optimisationProjection de vecteur sur un autre vecteur : produit scalaire.Pour chercher quelles donnees se dispersent le plus, on va chercher un vecteur $w$ telle que la projection ($X.w$) de mes $x$ soit maximale et soit une matrice\\(X=\\begin{bmatrix} x_{11} &amp;amp; x_{12}\\\\ \\vdots &amp;amp; \\vdots\\\\ x_{i1} &amp;amp; x_{i2}\\\\ \\vdots &amp;amp; \\vdots\\\\ x_{n1} &amp;amp; x_{n2}\\end{bmatrix}\\) On cherche a maximiser $Var(X.w)$ sous contrainte que $\\Vert w\\Vert=1$Exemple perceptron (1 neurone)On cherche les parametres du vecteurs normalOn a un probleme qui prend comme origine quelque chose de geometriqueOn cherche a discriminer les ronds rouges des points verts, on a la marge en plus de la separation. On cherche a maximiser la marge telle que tous les echantillons dâ€™une meme classe vont dâ€™un cote ou de lâ€™autre dâ€™une separatrice.Question 1-1On se place en un premier temps dans le cas de dimension 2, celui du plan euclidien. Soient $x$ et $y$ deux vecteurs de $\\mathbb R^2$, on dÃ©signe par $\\theta$ lâ€™angle orientÃ© (dans le sens direct) entre $x$ et $y$ et par $\\phi$ (resp. $\\psi$) celui entre $x$ (resp. $y$) et la partie positive de lâ€™axe des abscisses. ReprÃ©senter la description prÃ©cÃ©dente par un dessin Exprimer les coordonnÃ©es de $x$ et $y$ en fonction de leurs normes respectives et des angles $\\phi$ et $\\psi$ En dÃ©duire une expression du produit scalaire de $&amp;lt;x, y&amp;gt;$ en fonction de $\\theta$ et des normes de $x$ et $y$\\[x,y\\in\\mathbb R^4, &amp;lt;x,y&amp;gt;=x^Ty=\\sum_{i=1}^nx_iy_i\\\\\\Vert x\\Vert=\\sqrt{&amp;lt;x,x&amp;gt;}=\\sqrt{x^Tx}\\\\d(x,y)=\\Vert x-y\\Vert\\\\\\theta(x,y)=\\arccos(\\frac{&amp;lt;x,y&amp;gt;}{\\Vert x\\Vert\\Vert y\\Vert})\\\\\\begin{aligned}&amp;lt;x,y&amp;gt;&amp;amp;=x_1y_1+x_2y_2=\\sum_ix_iy_i\\\\&amp;amp;= \\Vert x\\Vert\\Vert y\\Vert\\cos(\\theta(x,y))\\end{aligned}\\] $\\theta(x,y)=\\arccos(\\frac{&amp;lt;x,y&amp;gt;}{\\Vert x\\Vert\\Vert y\\Vert})$: cette formule est vraie quelque soit la nature de $x$ et $y$.Question 1-2DÃ©crire le lieu de $\\mathbb R^2$ donnÃ© par la relation matricielle :\\[\\begin{pmatrix} 1&amp;amp;2\\\\ -1&amp;amp;1\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\end{pmatrix}\\le\\begin{pmatrix} 0\\\\ 0\\end{pmatrix}\\] ensemble des vecteurs tels que \\(\\{x\\in\\mathbb R\\vert&amp;lt;x.y&amp;gt;\\ge0\\}\\)$y\\neq0$ et \\(\\{y\\}=\\{x\\in\\mathbb R^2\\vert&amp;lt;x.y&amp;gt;=0\\}\\)\\[\\begin{cases}x+2y\\le0\\\\-x+y\\le0\\end{cases}\\]Prenons la premiere equation et changeons $\\le$ en $=$ pour la resoudre. $x+2y=0$ est de la forme $ax+by=0$. Pour une equation de la forme $ax+by=0$: \\(\\vec n=\\begin{pmatrix} a\\\\ b\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u=\\begin{pmatrix} -b\\\\ a\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)On peut donc en deduire:\\(\\vec n_1=\\begin{pmatrix} 1\\\\ 2\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u_1=\\begin{pmatrix} -2\\\\ 1\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)On cherche le demi-plan oriente negativement par rapport a:\\(&amp;lt;\\vec n_1,\\begin{pmatrix} x\\\\ y\\end{pmatrix}&amp;gt;\\le0\\)Prenons la seconde equation et faisons de meme\\(-x+y=0\\\\\\vec n_2=\\begin{pmatrix} -1\\\\ 1\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u_2=\\begin{pmatrix} -1\\\\ -1\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)Lâ€™intersection des 2 espaces verifie les 2 inegalites.Question 1-3ReprÃ©senter le lieu de $\\mathbb R^3$ dÃ©crit par la relations $x_1 +x_2 +x_3 \\ge 0$.On cherche:\\(\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}\\in\\mathbb R^3\\\\\\)tel que $x_1 +x_2 +x_3 \\ge 0$\\(&amp;lt;\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix},\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}&amp;gt;\\ge0\\)On va chercher le lieu de $\\mathbb R^3$ ou $&amp;lt;\\vec n.\\vec x&amp;gt;=\\vec n^T\\vec x=0$. On prend les point apres et dans le plan.Question 2-6Ã‰crire paramÃ©triquement : la droite de $\\mathbb R^2$ de vecteur directeur $(1,âˆ’1)$ et passant par $(2,3)$; le plan de $\\mathbb R^3$ donnÃ© par lâ€™Ã©quation $x_1 +x_2 +x_3 = 2$.\\[\\begin{aligned}(D)&amp;amp;=\\{x\\in\\mathbb R^2,x=\\lambda u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\} \\text{ representation parametrique}\\\\&amp;amp;= \\{\\vec x\\in\\mathbb R^2,&amp;lt;\\vec n,\\vec x&amp;gt;=0\\}\\\\&amp;amp;=\\{n^Tx=0\\}\\\\&amp;amp;=\\{n_1x_1+n_2x_2=0\\} = \\text{ representation implicite}\\\\\\end{aligned}\\\\n=\\begin{pmatrix} n_1\\\\ n_2\\\\\\end{pmatrix}\\\\x=\\begin{pmatrix} x_1\\\\ x_2\\\\\\end{pmatrix}\\]$(A)=x+(0,1)$ la droite qui passe par $(0,1)$ et de vecteur directeur $\\vec u$\\[\\begin{aligned}(A)&amp;amp;=(0,1)+(D) = (0,1)+\\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\} \\text{ avec } \\vec u=\\begin{pmatrix} u_1\\\\ u_2\\\\\\end{pmatrix}\\\\&amp;amp;= (0,1)+\\{(\\lambda u_1,\\lambda u_2),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(0,1)+(\\lambda u_1,\\lambda u_2),\\lambda\\in\\mathbb R\\}=\\{(\\lambda u_1, 1+\\lambda u_2),\\lambda\\in\\mathbb R\\}\\end{aligned}\\]\\[\\vec n^{\\perp}x=c\\Rightarrow n_1x+n_2y=c\\\\\\Rightarrow ax+by+c=0\\]On obtient lâ€™equation implicite dâ€™une droite affine.\\(\\rightarrow \\vec n = \\begin{pmatrix} a\\\\ b\\\\\\end{pmatrix} \\text{ et }\\vec u = \\begin{pmatrix} -b\\\\ a\\\\\\end{pmatrix} \\text{ et passant par } (0,-\\frac{c}{b})\\)Ecriture parametrique de: la droite de $\\mathbb R^2$ de vecteur directeur $\\vec u= (1,-1)$ et passant par $(2,3)$ $(A)$\\[\\begin{aligned}(A) &amp;amp;= (2,3)+\\{\\vec x\\in\\mathbb R^2, \\vec x=\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= (2,3) + \\{(\\lambda,-\\lambda),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(2,3)+(\\lambda,-\\lambda),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(2+\\lambda,3-\\lambda),\\lambda\\in\\mathbb R\\}\\end{aligned}\\] le plan de $\\mathbb R^3$ donne par $x_1+x_2+x_3=2$ $(P)$. les points de $(P)$ sont les zeros de lâ€™equation $x_1+x_2+x_3-2=0$ \\[x_1+x_2+x_3=2\\\\&amp;lt;\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}, \\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}&amp;gt;=2\\Leftrightarrow&amp;lt;n,x&amp;gt;=2 \\text{ avec } \\vec n=\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}\\text{ et }\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}\\]$(A)=(2,0,0)\\in(P)$, $B=(0,2,0)$, $C=(0,0,2)\\in(P)$$\\vec{AB}$ et $\\vec{AC}$, $\\vec{AB}=(-2,2,0)$, $\\vec{AC}=(-2,0,2)$\\[\\begin{aligned}(P) &amp;amp;= (2,0,0)+\\lambda_1\\vec{AB}+\\lambda_2\\vec{AC}, (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\\\&amp;amp;= (2,0,0)+\\{\\vec{x}\\in\\mathbb R^3,\\vec{x}=\\lambda_1\\vec{AB}+\\lambda_2\\vec{AC},(\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= (2,0,0)+\\{\\lambda_1(-2,2,0)+\\lambda_2(-2,0,2),(\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= (2,0,0)+\\{(-2\\lambda_1-2\\lambda_2,2\\lambda_1,2\\lambda_2), (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= \\{(2-2\\lambda_1-2\\lambda_2,2\\lambda_1,\\lambda_2) (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\end{aligned}\\]Question 2-7Dessiner le lieu de $\\mathbb R^2$ dÃ©crit par les contraintes\\[\\begin{pmatrix} -1 &amp;amp; 2\\\\ 1 &amp;amp; 1\\\\\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\\\\\end{pmatrix}\\le\\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\] DÃ©crire chacun des composants du lieu gÃ©omÃ©trique prÃ©cÃ©dent paramÃ©triquement Que change le fait de rajouter la contrainte $xâˆ’3y \\le 6$ ? Quel lieu correspond Ã  la situation oÃ¹ lâ€™on change le sens de toutes les inÃ©galitÃ©s ?On cherche le lieu de $\\mathbb R^2$ definit par\\[\\begin{pmatrix} -1 &amp;amp; 2\\\\ 1 &amp;amp; 1\\\\\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\\\\\end{pmatrix}\\le\\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\\\\\begin{cases} -x+2y=-1\\\\ x+y=1\\end{cases}\\\\(D1)=-x+2y=-1\\Leftrightarrow \\underbrace{-x+2y+1}_{ax+by+c=0}=0\\\\\\vec{n_1} = \\begin{pmatrix} -1\\\\ 2\\\\\\end{pmatrix} \\text{ et }\\vec{u_1} = \\begin{pmatrix} -2\\\\ -1\\\\\\end{pmatrix}\\]On a le point particulier $(0;-\\frac{1}{2})$\\[(D_2)= x+y-1=0\\\\\\vec{n_2} = \\begin{pmatrix} 1\\\\ 1\\\\\\end{pmatrix} \\text{ et }\\vec{u_2} = \\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\]On a le point particulier $(0;1)$" }, { "title": "TIFO: Implementation", "url": "/cours/posts/tifo_implementation/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, max tree, FFT", "date": "2021-03-11 17:00:00 +0100", "snippet": "Lien de la note HackmdFASTER-FASTER-FASTER!!!Introduction Efficacite Taille des images Contrainte sur le temps de reponse Contrainte sur le materiel (telephoneâ€¦) Solution Bien penser ses algorithmes (et ss structures de donnes) Revoir son implementation sur CPU Eventuellemnt envisager une implementation sur GPU Bien penser ses algorithmes Representation des images â€¦Repenser les algorithmes FFT (Fast Fourier Transform) â€¦Representation des imagesComment representer une image Matrice Vecteur Arbre/grpah Max Tree, Min Tree Tree of Shapesâ€¦ â€¦Matrice, vecteur: bien respecter le cache de la amchine !Max Tree:Image:Max-Tree CorrespondantRacine de lâ€™arbre: image entiere On part du $\\min$ de lâ€™image Des que le $\\min$ separe 2 regions, on a 2 branches dans notre arbre Une branche de lâ€™arbre, câ€™est une region de lâ€™image. Un noeud correspond a tous les pixels Les feuilles, si elles sont petites et nombreuses elles sont peut-etre que du bruitExempleCalcul de lâ€™ouverture ultime Long dans le cas general Solution: utilisation du max-tree On enleve les petites regions et on fait la difference entre lâ€™image dâ€™origine et lâ€™image obtenue. On continue sur les zones plus grosses et on regarde chaque fois le contraste obtenu.On peut estimer quel est le motif le plus contraste et le garder.On a des residus en coupant les branches.On parcours lâ€™image en profondeur avec le niveau de contraste:UO(noe, parent_leve, max_contrast) { node.r=max(parent_level-node.level, max_contrasy) for all child c UO(c, node_level.r)}Resultats: Format Nb of pixels Time (ms) 128x128 16384 0,18 256x256 65536 2,39 512x512 262144 12,01 1024x1024 1048576 52,04 2048x2048 4194304 235,53 Un probleme difficile a la base est rendu plus simple et plus rapide en changeant le codage de lâ€™imageOn calcule lâ€™ouverture ultime et on recupere tous les objets saillantsPour recuperer le texte, on relance lâ€™ouverture ultime sur une partie de lâ€™image Repenser les algorithmes Exemple FFT Implementation des filtres Lâ€™image integrable Calcul rapide FFT (1965 - Cooley et Tukey) (Gauss 1805??) The DFT:\\[x(l)=\\sum_{k=0}^{N-1}x(k)e^{-\\frac{2j\\pi kl}{N}}, l=0,...,N-1\\]avec $N$ complexe mults, $N-a$ complexe add pour chaque $I$ $O(N^2)$Exploiter la symetrie:\\[\\begin{aligned}W_N&amp;amp;=e^{-\\frac{2j\\pi}{N}}\\\\W_N^{k(N-n)}&amp;amp;=W_n^{-kn}=(W_N^{kn})^* &amp;amp;(W_N^{kN}=1)\\\\W_N^{k(n)}&amp;amp;=W_N^{k(N+n)}=W_N^{(k+N)n}\\end{aligned}\\]On suppose que $N=2^m$\\[\\begin{aligned}X(l)&amp;amp;=\\sum_{k\\text{ pair}}x(k)W_N^{lk}+\\sum_{k\\text{ impair}}x(k)W_N^{lk}\\\\&amp;amp;=\\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi2kl}{N}} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi2(k+1)l}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)W_n^{2kl} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)W_N^{(2k+1)l}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)(W_n^2)^{kl}+W_n^l\\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)(W_N^2)^{kl} &amp;amp;W_n^2=W_{\\frac{N}{2}}\\end{aligned}\\] $\\frac{N}{2}$ DFT des echantillons pairs, $\\frac{N}{2}$ DFT des echantilons imapairs\\[X(l)=X_p(l)+W_N^lX_i(l)\\] Somme de 2 DFTs de $\\frac{N}{2}$ echantillons $2\\frac{N}{2}^2+N$ mutliplications Passe de $O(N^2)$ a $O(N\\log N)$Lâ€™image integraleSouvent besoin de calculer des moyennes/ecart-types dans une imageOn passe un masque sur une imageLa valeur obtenue est la sommes des pixelsSi on veut calculer lâ€™aire dâ€™un rectangle aligne sur les axes:\\[Aire(ABCD)=C-B-D+A\\]Implementation des filtres Decomposition des convolutions (filtres separables) $N\\times N\\to N+N$ La taille du filtre a un impact sur la vitesse dâ€™execution Prise en compte des bordures?Implementation sur CPU Utilisation du parallelisme Utilisation des instruction SIMD Auto-vectorisation Intrinsics SIMD Boost::simd â€¦CPUSIMD Single instruction multiple data MMX, SSE, AVX, NEONâ€¦ Registres sous formes de vecteurs Bien adapte a lâ€™imageSIMD: un peu dâ€™histoire 1997 jeu dâ€™instruction MMX sur P166 (intel) Lâ€™ordinateur multimedia - Regsitre 64bits paratages avec le FPU 1997 jeu dâ€™instrucutin - 3DNow ! (AMD) 1999 jeu dâ€™instruction SSE - Registres 128bits SSE2, SSE3, SSE4 - Registres 128bits AVX - Registres 512 256bits AVX512 - Registres 512bits Neon sur ARMSIMD Usage Par le compilateur: Active sur GGC avec lâ€™option -ftree-vectorize (par defaut active avec -O3) Renseigner lâ€™option -march=(corei7,native...) On peut avoir plus dâ€™info avec les options -fopt-info-vec-* (-fopt-info-vec-optimized -fopt-info-vec-missed) Sorties: knn.cpp.229: note: LOOP VECTORIZED (attention: plusieurs passes) Auto-vectorisationfor (std::size_t x = 0; x &amp;lt; l; ++x) { output_image[x] = input_image1[x] + input_image2[x];} // en complet desaccord avec notre coding styleEntrees: -Wall -O3 -g -Wextra -Werror -m64 -march=native -ftree-vectorize -std=c++11 -fopt-info-vec-optimized #-fopt-info-vec-missedSorties: Par le compilateur (auto-vectorisation) Pas toujours facile sâ€™assure que les donnees soient alignees (quasi impossible en cpp :-( ) __attribute__((aligned(TL_IMAGE_ALIGNEMENT))) std::align Alignas(.) aligned_alloc __restrict__ assume dans ICC Bonnes pratiques: Utiliser des indices plutot que des pointeurs Array of Structures vs Structure of Arrays Ne pas interrompre une boucle for (k = 0 ; k &amp;lt; size_vect; k++) { double t = v_example[k] - data[k_data++]; res += t * t; // if (res &amp;gt; tresh) { // breaks; // }}res *= -g;return exp(res) SIMD - intrinsics Possible de les utiliser en c/c++ Exemple:for (std::size_t x = 0; x &amp;lt; l; x+=16) { __m128i v_input_image1 = _mm_loadu_si128((const __m128i*)(input_image1 + x)); __m128i v_input_image2 = _mm_loadu_si128((const __m128i*)(input_image2 + x)); __m128i v_output1 = _mm_add_epi8(v_input_image1, v_input_image2); _mm_store_si128((__m128i*)(output_image+x), v_output1);} Probleme dâ€™alignement des donnees aligned_alloc Difficilement portable Function Multiversioning (GCC 4.8) Utile pour la portabilite du programme __attribute((target(&quot;default&quot;)))int foo() { // The default version of foo}__attribute((target(&quot;sse4.2&quot;)))int foo() { // foo version for SSE4.2}__attribute((target(&quot;arch=atom&quot;)))int foo() { // foo version for the Intel ATOM processor}Boost::simd Permet dâ€™ecrire de maniere agnostique vis-a-vis de la vectorisation Le code devient portable Vectorisation vers certains processeurs gratuite et pour dâ€™autres nonImplementation sur GPUUne fois quâ€™on a pousse nos algos a fond sur CPUâ€¦ Implementation sur GPU Cuda OpenCL Compute Shaders â€¦ Compute Shaders Glsl â€œportableâ€ ou autreOn a plein de threads dans chaque work groupConclusion Pas de points â€œincontournablesâ€ Reflechir a notre implem pour quâ€™elle soit la plus efficace possible" }, { "title": "TIFO: Le bruit", "url": "/cours/posts/tifo_bruit/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, bruit", "date": "2021-03-11 16:00:00 +0100", "snippet": "Lien de la note HackmdModelisationAmelioration vs restauration: Amelioration: on ne sait pas ou on va Restauration: on a un modele que lâ€™on souhaite atteindreModele de degradatation (dans le domaine spatial) $I_{\\text{deg}}=h*I_{\\text{ori}} + n$ $h\\to$ la degradation (optique, flouâ€¦) $n\\to$ le bruit Le bruit \\(I_{\\text{deg}} = h*I_{\\text{ori}} + n\\)On regarde $n$.Genant pour le cote esthetique que pour les traitements $\\Rightarrow$ Il faut donc reduire ce bruit Reduction de bruit Estimation ? Connaissances a priori ou pas Reduction Sans degrader le signalâ€¦ Bruit additifOn considere souvent ici le bruit additifFonction de repartition peut varier: Gaussienne, (impulsion) periodiqueEstimationSoit le capteur est connu: Photos dâ€™une zone bien homogene dans de bonnes conditions dâ€™eclairementSoit le capteur pas connu: Analyse de quelques zonesExempleOn cherche dans les zones les plus homogenes lâ€™ecart-type des valeurs.ReductionRevisite des filtres classiques Mean filter Arithmetic mean Geometric mean Harmonic mean â€¦ Median + variantes Midpoint, alpha-trimmed Adaptative Gaussien selectif â€¦ Approche par ondelette lâ€™image $f(n)$ est bruite par $q(n)$ $g(n)=f(n)+q(n)$ Lâ€™estimation de la correction $F_c=W^{-1}T_{\\lambda}Wg$ $T_{\\lambda}p(y)=p(y)$ si $\\vert p(y)\\vert\\gt\\lambda$, $0$ sinon $T_{\\lambda}p(y)=p(\\lambda)\\pm\\lambda$ si $\\vert p(y)\\vert \\gt \\lambda$, $0$ sinon Resultat: ToS (Tree of Shape) Bruit = feuilles dans lâ€™arbre Couper les feuilles de lâ€™arbre pour affiner le resultat NLMeans Au lieu de faire la moyenne sur un voisinage, on cherche des patchs ressemblants Resultats:On a une image a laquelle on rajoute du bruit et quâ€™on debruite avec NLMeansDegradation periodiques Moi devant les cours de TIFO quand je me dit que je reviserai plus tardSpectre (eclairci):On a des taches aux coins qui apparaissent.Definition du filtre dans le domaine frequentiel:On fait un rejecteur (on met a 0 des frequences precises dans le spectre) Fait un peu grossierementOn multiplie le spectre et lâ€™image obtenue par le filtre, supprimant theoriquement lâ€™origine des degradations periodiques:Resultat:Si on fait la difference entre lâ€™image dâ€™origine et debruitee:La partie convolutionnelle Le bruit: $I_{\\text{deg}} = h*I_{\\text{ori}} + n$ On regarde $h$ Degradations convolutionnelles comme du flou de bouge Reduction $\\Leftrightarrow$ deconvolution Blind deconvolution: Seul $I_{\\text{deg}}$ connu Non-Blind deconvolution: $I_{\\text{deg}}$ et $h$ sont connnus Degradation: $g=h*f+n$Passage en frequentiel: $G(u,v)=H(u,v)F(u,v)+N(u,v)$ $h\\to$ point spread function (PSF) Estimation de $F$ (lâ€™image non bruitee) On a envie de dire: $g=h*f$ dâ€™ou une solution â€œfacileâ€ $F_e(u,v)=\\frac{G(u,v)}{H(u,v)}$ Toutefois, il y a le bruit additif $F_e(u,v)=F(u,v)+\\frac{N(u,v)}{H(u,v)}$ Quand $H\\to0$, $\\frac{N}{H}\\to+\\infty$ $\\Rightarrow$ limiter le support Solution:\\[F_e(u,v)=F(u,v)+\\frac{N(u,v)}{H(u,v)}\\] $h/H$ connu ou pas?Filtre de Wiener Mean square error entre $f$ et $f_e$: $e=E[(f-f_e)^2]$ On cherche $W$ tel que: $\\frac{1}{NM}E[\\vert F-F_e\\vert^2]$ soit $\\min$ $F_e=WG=WHF+WN$ $F-F_e=(1-WH)F-WN$ $e=\\frac{1}{NM}\\sum\\sum\\vert (1-WH)F-WN\\vert^2$ Expression en frequentiel de $f_e$ (en fonction de $H$) en derivant e en fonction de $W$\\[F_e = \\biggr[\\frac{1}{H}\\frac{\\vert H\\vert^2}{\\vert H\\vert^2+\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}}\\biggr]G\\] Filtre de Wiener:\\[w = \\biggr[\\frac{H^c}{\\vert H\\vert^2+\\underbrace{\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}}}_{=K}\\biggr]\\]Probleme: $\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}$ pas connu $\\rightarrow$ mais considere constant $K$Degradation Comment determiner $H$ ? Faire une image dâ€™une impulsion $\\to$ determine entierement $H$ Analyser une image et essayer de determiner sur des frontieres ou des impulsions la reponse $H$ Modeliser la degradation (flou de bougerâ€¦) $\\to$ Tres difficile la plupart du tempsQuantification des resultats Rapport signal sur bruit SNR $\\sum\\vert F(u,v)\\vert^2\\sum\\vert N(u,v)\\vert^2$ Mean Square Error MSE entre lâ€™image et lâ€™estimation $\\frac{1}{N}\\sum (f(x,y)-f_e(x,y))^2$ Note: SNR=$\\sum\\frac{(fe(x,y)^2)}{MSE}$ Conclusion Restauration, amelioration Difficile dans le cas general " }, { "title": "TIFO: Filtrage, partie 2", "url": "/cours/posts/tifo_filtrage_partie_2/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, signal, Fourier, convolution", "date": "2021-03-11 15:00:00 +0100", "snippet": "Lien de la note HackmdSignal Representation Mathematiques dâ€™un phenomene physiqueTraitement du signal Elaboration, detection et interpretation des signauxClassification des signaux Morphologique: continu/discret Spectrale: Bande de frequence BF/HF Energie: Energie finie/Puissance moyenne finie Typologie: deterministe/aleatoire Periodicite: non peridique/$x(t)=x(t+T)$Energie Energie $w_x$ dâ€™un signal $x$\\[W_x=\\int_{-\\infty}^{+\\infty}\\vert x(t)\\vert^2dt\\] Les signaux a energie finie verifient la condition:\\[W_x=\\int_{-\\infty}^{+\\infty}\\vert x(t)\\vert^2\\lt+\\infty\\] Les signaux a support borne (cad duree limitee) sont a ernegie finiePuissance Puissance moyenne $P$ du signal $x$\\[P_x=\\lim_{T\\to+\\infty}\\frac{1}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}} \\vert x(t\\vert^2dt)\\] Energie finie $\\Rightarrow$ puissance moyenne nulle\\[W_x\\lt+\\infty\\Rightarrow P_x=0\\] Puissance moyenne finie $\\Rightarrow$ energie infinie\\[0\\lt P_x\\lt+\\infty\\Rightarrow W_x\\to+\\infty\\] Ex: les signaux periodiquesSignaux classiquesPorte\\[\\Pi_{\\frac{T}{2}}=\\begin{cases} 1 &amp;amp;\\text{si } t\\in[-\\frac{T}{2};\\frac{T}{2}]\\\\ 0 &amp;amp;\\text{ailleurs}\\end{cases}\\]Echelon dâ€™Heavyside\\[u(t)=\\begin{cases} 0 &amp;amp;\\text{si } t\\lt0\\\\ 1 &amp;amp;\\text{si } t\\ge0\\end{cases}\\]Signe\\[sgn(t) =\\begin{cases} -1 &amp;amp;\\text{si } t\\lt0\\\\ 0 &amp;amp;\\text{si } t=0\\\\ 1 &amp;amp;\\text{si } t\\gt0\\end{cases}\\]Triangulaire\\[\\triangle_T(t)=\\begin{cases} \\frac{1-\\vert T\\vert}{T} &amp;amp;\\text{si } \\vert t\\vert T\\\\ 0 &amp;amp;\\text{ailleurs}\\end{cases}\\]Gaussienne\\[g(t) = \\frac{1}{\\delta\\sqrt{2\\pi}}e^{-\\frac{t^2}{2\\delta^2}}\\]Sinus cardinal\\[sinc(t) = \\frac{sin(t)}{t}\\]Series de Fourier On consider les fonctions $g_n(t)$\\[g_n(t) = e^{2j\\pi\\frac{nt}{T}}\\] Que vaut\\[&amp;lt;g_n(t),g_m(t)&amp;gt; = \\frac{1}{T}\\int_Tg_n(t)g_m^*(t)dt=\\begin{cases} 0 &amp;amp;\\text{si } n\\neq m\\\\ 1 &amp;amp;\\text{si } n= m\\end{cases}\\]avec $g_m^*$ le conjugue dans les complexe Soit $f(t)$ periodique de periode $T(T\\gt 0)$. Un signal 1D periodique peut etre vu comme une somme de sinusoides\\[f(t) = \\sum_{n=-\\infty}^{+\\infty}C_ng_n(t)\\]Comment trouver $C_i$ ?\\[\\begin{aligned}\\frac{1}{T}\\int f(t)g_i^*(t)dt &amp;amp;= \\frac{1}{T}\\int(\\sum C_ng_n(t))\\int g_i^*(t)dt\\\\&amp;amp;= \\frac{1}{T}\\int(...+C_{i-1}g_{i-1}(t)+C_{i}g_{i}(t)+C_{i+1}g_{i+1}(t)+...)g_i^*(t)dt\\\\&amp;amp;= \\frac{1}{T}\\int(...+C_{i-1}g_{i-1}(t)g_i^*(t)+C_{i}g_{i}(t)g_i^*(t)+C_{i+1}g_{i+1}(t)g_i^*(t)+...)dt\\\\&amp;amp;=...+\\frac{1}{T}\\int C_{i-1}g_{i-1}(t)g_i^*(t)dt + \\frac{1}{T}\\int C_{i}g_{i}(t)g_i^*(t) + \\\\ &amp;amp;\\frac{1}{T}\\int C_{i-1}g_{i-1}(t)g_i^*(t)dt+...\\\\&amp;amp;=...+C_{i-1}\\underbrace{\\frac{1}{T}\\int g_{i-1}(t)g_i^*(t)}_{=0 \\text{ car } i-1\\neq i}+ C_i\\underbrace{\\frac{1}{T}\\int g_{i}(t)g_i^*(t)}_{=1} + C_{i+1}\\underbrace{\\frac{1}{T}\\int g_{i+1}(t)g_i^*(t)}_{=0 \\text{ car } i+1\\neq i}\\\\&amp;amp;= C_i\\end{aligned}\\]Harmoniques$C_n$: harmoniques On les sommes pour obtenir la sinusoides resultat $C_0$: frequence continue $C_1$: frequence fondamentale â€¦ $C_n$: $n^{ieme}$ harmonique f reel $\\Rightarrow$ $C_n=C_{-n}^(f(t)=f^(t))$Frequences Basses frequences Lentes variations Zones presque uniformes Hautes frequences Variations rapides Contours/coins Se retrouve dans les images Quand des details apparaissent, on monte dans les frequencesSeries et transformees de FourierSpectre Dâ€™amplitude: $\\vert C_n\\vert$ De phase $Arg(C_n)=arctg(-\\frac{b_n}{a_n})$ De puissance $\\vert C_n\\vert^2$ $f(t)$ reel $\\Rightarrow$ spectre dâ€™amplitude symetrique Relation de PARSEVAL: Il y a conservation de la puissance de la representation temporelle a la representation frequentielle.On ne perde pas dâ€™information lorsquâ€™on passe de lâ€™un a lâ€™autre.SignauxOn considere jusquâ€™a present des signaux periodiques On peut generaliser en prenant $T\\to+\\infty$On defini $TF{x(t)}$\\[X(f) = \\int_{-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}dt\\]On defini $TF^{-1}{x(t)}$\\[x(t)=\\int_{-\\infty}^{+\\infty}X(f)e^{+2j\\pi ft}df\\] Toutes les infos contenues dans le signal sont contenues dans le spectreTransformee usuellesPorteTransformee de Fourier: Sinus cardinalConstanteTransformee de Fourier: FondamentalePeigne de DiracTransformee de Fourier: un autre Peigne de DiracExistence de la transformee de $f(t)$ $f(t)$ bornee Integrale de $f(t)dt$ existe Les discontinuires de $f(t)$ sont en nombre limite On sâ€™autorisera systematiquement a faire la transformee de Fourier de lâ€™imageProprietes Linearite\\[Kf(t)+g(t) \\Leftrightarrow KF(t)+G(t) \\text{ } K\\text{ complexe}\\] Similitude: Une dilatation dans le domaine temporel correspond a une contraction dans le domaine frequentiel $f(at)\\Leftrightarrow\\frac{1}{\\vert a\\vert}F(\\frac{f}{a})$ (a reel) Derivee: $\\frac{dx(t)}{dt}\\Leftrightarrow 2i\\Pi fX(f)$ $\\frac{dx(f)}{df}\\Leftrightarrow -2i\\Pi fX(t)$ Dans notre cas: Signal borne et echantilloneSoit le pic de Dirac $\\delta(t)$:Soit le pic de Dirac $\\delta(t_0)$:\\[\\delta(t_0)=\\delta(t-t_0)\\\\f(t)\\delta(t_0)=f(t_0)\\]Soit le peigne de Dirac $Ğ¨(t)$:\\[\\sum_{n=-\\infty}^{+\\infty}\\delta(t-nT)\\]$f(t).Ğ¨(t_0)=$ Une fonction echantillonee, câ€™est une fonction multipliee par un peigne de Dirac.Transformee de FourierDans notre cas: Signal discret (echnatillonne) + support borne Transformee de Fourier Discrete \\(\\begin{aligned}&amp;amp;X(f)=\\int_{-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}dt &amp;amp;X(f)=\\sum_{t=-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}\\end{aligned}\\)\\(X(l)=\\sum_{k=0}^{N-1}x(kT_e)e^{-2j\\pi lf_ekT_e}\\) \\begin{aligned}&amp;amp;X(l)=\\sum_{k=0}^{N-1}x(t)e^{\\frac{-2j\\pi}{N} kl} &amp;amp;X(k)=\\sum_{k=0}^{N-1}x(t)e^{\\frac{2j\\pi}{N} lk} \\end{aligned}Notes$F_e$ frequence dâ€™echantillonnage $X(0)\\to-2F_e(/0)$ $X(N-1)\\to +2F_e(/+4F_e)$ Pas en frequence: $F_e/N$Calcul rapide de la TFDFast Fourier Transform (1965 - Cooley et Tukey\\[\\begin{aligned}X(l)&amp;amp;=\\sum_{k=0}^{N-1}x(k)e^{-\\frac{2j\\pi kl}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi 2kl}{N}} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi 2(k+1)l}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi 2kl}{N}} + e^{-\\frac{2j\\pi l}{N}}\\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi2kl}{N}}\\end{aligned}\\] Pour calculer la TFD sur un signal de taille $N$, on calcul la transformee de Fourier sur les coeeficients pairs $(\\frac{N}{2})$ et la transformee de Fourier sur les coefficients impairs $(\\frac{N}{2})$â€¦ et recursivementDans notre cas (Image) Signal 2D: TF2D (Transformee de Fourier a 2 dimensions)Visualisation du spectre:On peut aller de $-2F_e$ a $2F_e$ Representation pas pratique car le max dâ€™information se retrouve dispatche aux differents angles.On interverti les cadrants. Les basses frequences se retrouvent au centreResultat:La convolutionReponse impulsionnelle ?Reponse a une impulsion $\\delta(t)$, cad envoyer un pic de Dirac unitqire et recupere la reponse impulsionnelle du filtre h(t). Cela caracterise le filtre.On peut en deduire pour nâ€™importe quel signal la sortie du filtre.La reponse du filtre est donnee par un produit de convolution\\[y(t)=x(t)\\times h(t)=\\int_{-\\infty}^{+\\infty}x(u)h(t-u)du\\]Reponse impulsionnelleSi le signal est une serie dâ€™impulsions ? On calcule la reponse du filtre a la 1$^{ere}$ impulsion On calcule la reponse de la seconde impulsion De meme pour la 3$^{eme}$ Par le principe de supperposition, les reponses sâ€™additionnent Câ€™est ce quâ€™on fait lors du produit de convolution.Proprietes Commutative: $f(t)* g(t)=g(t)* f(t)$ Distributive: $(x(t)+y(t)) * g(t) = x(t) * g(t)+y(t) * g(t)$ Associative: $(x(t)* y(t))* z(t)=x(t)* (y(t)* z(t))$Theoreme de Plancherel Temps Frequences Convolution $*$ Multiplication $.$ Multiplication $.$ Convolution $*$ Autre propriete\\(f&#39;*g=f*g&#39;=(f*g)&#39;\\)Consequences du lien convolution $\\leftrightarrow$ multiplication Spectre dâ€™un signal echantillonee Revisite du filtrage Passe haut Passe bas Passe Bande Rejecteur DeconvolutionAutres consequences: DoG - Difference de gaussiennes LoG - Laplacien dâ€™une gaussienneSpectre dâ€™un signal echantillonne:$f(t)Ğ¨(t_0)=$Dans le domaine frequentiel: La TF du peigne de Dirac est un autre peigne de Dirac plus espace Le signal se repete a lâ€™infini, on nâ€™a besoin de connaitre quâ€™un espaceRevisite du filtragePasse haut / Passe Bas/ Passe Bande / Rejecteur On a un signal quâ€™on veut filtrer pour enlever le bruit On passe en frequenciel et on a le spectre du signal Les hautes frequences sont du bruit On defini un signal pour les enlever 1 sur toutes les basses frequences 0 partout ailleurs On multiplie les 2 On obtient le spectre supprime de toutes les bases frequences On fait lâ€™inverse de la TF et on obtient le signal sans les hautes frequencesEn pratique, est-ce quâ€™on fait tout ca ?Non.On peut faire lâ€™inverse Prendre le filtre defini Faire lâ€™inverse et de le passer en temporel en temporel, la porte devient un sinus cardinal Convoluer le filtre avec le signal On obtient notre signal filtreAutre consequenceConvolution $fâ€™=f*h\\Rightarrow F\\times H = Fâ€™$Deconvolution $\\frac{Fâ€™}{H} = F\\to$ domaine temporel Tres difficile si on ne connait pas le filtre initial Probleme des 0 (ou des valeurs tres petites dans $H$) Si on floute le visage de quelquâ€™un pour anonymat avec un filtre gaussien, on peut arriver a deconvoluer et retrouver le visage dâ€™origine (tres difficile en pratique) Il faudrait mettre un gros carre noir et non flouter le visageDetection de bord ($f$ gauss)â€™$\\to f$guassâ€™ (la derivee de la gaussien est connue formellement) Realise a la fois le lissage et la derivee LoG Laplacient dâ€™une gaussienneDog Difference de gaussienneFiltrage Passe Bas Description Coef central superieur ou egal aux autres Autres coefs positifs Effet Pixel central devient une moyenne ponderee des voisins Les regions homogenes sont peut changees Les frontieres sont etalees Reduit le bruit Passe Haut Description Coef central positif et eleve Autres coefs petits, negatifs ou nuls La somme des coefficients est nulle Effet Zones homogenes: perte de la notion dâ€™intensite Frontieres sont renforcees Proprietes de la TF2DLe module de lâ€™image ne change pasLe module change mais la phase est invariante a la rotationImpact du flou Cela veut dire que les hautes frequences sont reduites/degradees.Si on bouge, on a un flou directionnel, cad on a preserve lâ€™information dans un sens et perdu dans lâ€™autre.Skew estimationApplication:On a un document qui passe dans un scanner, il nâ€™est pas forcement droit et on veut corriger lâ€™orientation.On voit la rotation dans le spectre et on refait une transformee de Fourier.On peut estimer lâ€™orientation du fichier dâ€™origine.Autres transformations Short Term Fourier Transform Discret Cosinus Transform Ondelettes Radon Wigner Hilbert â€¦Transformee en cosinus discreteOn fait la transformee de Fourier sur une base de sinusoide reel (utilise en JPEG)Probleme definiton varie dâ€™un ouvrage a un autre Pour le JPEG, lâ€™encodeur et le decodeur peuvent utiliser une transformee differenteShort Term Fourier Transform probleme: FT: soit le temps, soit la frequence Solution: ne considerer que des petits intervalles\\[X(f,t&#39;)=\\int_{-\\infty}^{+\\infty}x(t)w^c(t-t&#39;)e^{-2j\\pi t}dt\\] Impact de la taille de w W etroit $\\Rightarrow$ localisation temporelle correcte mais mauvaise resolution frequentielle W large $\\Rightarrow$ localisation temporelle imprecise mais bonne resolution frequentielle Transformee en ondelettes Avantages: FT: soit le temps, soit la frequence STFT: diffculte de regler la taille de w et taille fixee une fois pour toutes Transformee en ondelette: Representation temps-frequence la frequence avec sa position spatiale Adaptation de la resolution en fonction de la frequence Basses frequence $\\to$ Privilegie la resolution frequentielle Hautes frequence $\\to$ Privilegie la resolution temporelle analyse des signaux non stationnaires Definition:\\[\\Psi_x^\\psi(\\tau,s)=\\frac{1}{\\sqrt{\\vert s\\vert}}\\int x(t)\\psi^c\\biggr(\\frac{t-\\tau}{s}\\biggr)dt\\\\\\Psi_x^\\psi(\\tau,s)=\\int x(t\\psi_{\\tau, s}^c)(t)dt\\\\\\psi_{(\\tau,s)}=\\frac{1}{\\sqrt{\\vert s\\vert}}\\psi\\biggr(\\frac{t-\\tau}{s}\\biggr)\\]Exemples Haar Mexican Hat MorletUsage Compression Filtrage Approximation â€¦" }, { "title": "TIFO: Filtrage, partie 1", "url": "/cours/posts/tifo_filtrage_partie_1/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, lissage, debruitage, laplacien, convolution, bords", "date": "2021-03-11 14:00:00 +0100", "snippet": "Lien de la note HackmdFiltrage Domaines spatial et frequentiel Lissage, elimination du bruit Detection de bords/coinsQuelques filtres classiques On sâ€™appuie souvent sur le produit de convolution Matrice avec des coefficients On va recalculer la valeur dâ€™un pixel en fonction de son voisinage Combinaison lineaire de tous les pixels voisins Lissage, debruitageComment eliminer le bruit dans une image ? Filtre moyenneur Objectif: lisser lâ€™image Donne une impression de flou Fonctionnement: on remplace la valeur dâ€™un pixel par la moyenne des valeurs des pixels du voisinage Noyau de convolution: \\[\\frac{1}{9}\\begin{bmatrix} 1 &amp;amp; 1 &amp;amp; 1\\\\ 1 &amp;amp; 1 &amp;amp; 1\\\\ 1 &amp;amp; 1 &amp;amp; 1\\\\\\end{bmatrix}\\]Comment choisir la taille/forme du voisinage ?On reste generalement sur des voisinages carres par soucis de performanceResultats:Un leger flou apparait.Si on continue et quâ€™on augmente la taille du masque:Le lissage est un peu trop fort et on perd des details.Implementation Comment implementer un tel filtre ? Double boucle Que faire sur la bordure On ne traite pas les bords Recalculer sur la bordure avec des coeffs differents Dupliquer les dernieres et premieres lignes/colonne Image periodique: chercher les valeurs sur une autre periode $\\Rightarrow$ il nâ€™y a pas de bonnes reponses Amelioration? Au lieu de faire contribuer tous les pixels egalement, on peut privilegier les pixels proches du centre Filtre Gaussien Filtre Gaussien Objectif: lisser lâ€™image Fonctionnement: on remplace la valeur dâ€™un pixel par la moyenne ponderee des valeurs des pixels du voisinage Noyau de convolution: gaussienne Parametre/Taille du noyau ?ResultatComparaison ave le filtre moyenneur Avantages/inconvenients ? moins lâ€™impression de flou bonne amelioration Filtre Median Objectif: debruitage Fonctionnement: trier lâ€™ensemble des valeurs des intensites des pixels sur un voisinage puis remplacer la valeur du pixel considere par la valeur mediane sur le voisinageResultat Supprime facilement le bruit impulsionnel Preserve lâ€™information de contour Est un peu lourd (tri) Je suis pas du tout narcissiqueOn a completement enleve le bruit â€œpoivre et selâ€ de la 2$^{\\text{nde}}$ imageLissage Lissage (gaussien, moyenneâ€¦) Degrade les frontieres Solutions ? Faire contribuer principalement les pixels qui ont une couleur proche de la couleur du pixel considere ou ponderer leur apport en fonction de leur couleur Filtre de Nagao â€¦ Filtre gaussien, resultats:Gaussien selectif: seuil pour faire contribuer les pixel (si câ€™est inferieur, on les fait contribuer, sinon on les oublie). Permet de preserver les contours Seuil a fixer Sâ€™il est trop tolerant: tend vers le gaussien normal Pas assez tolerant: reste sur lâ€™image originale Nagao Filtre de Nagao Tenir compte des regions? Faire un median mais dans la region de variance faible Au lieu de prendre un masque centre sur le pixel, on va regarder sur differents voisinagesOn calcule la variance a chaque zones rouges On calcule la moyenne sur le voisinage avec la variance la plus faible On ne veut pas faire une moyenne a cheval sur un contour ResultatsNagao: on a fortement lisse lâ€™image mais on a garde les contoursDetection de bords Comment se caracterise un contour ? Comment trouver les contours ? Pourquoi trouver les contours ? Definir la notion de bord/contour Transition brutale (echelon) En â€œescalierâ€ Dans la vraie vie, jamais aussi brutale Quelle operation realiser pour detecter ce type de motif? Calcul de la derivee ?\\[\\lim_{x_0\\to x}\\frac{f(x_0)-f(x)}{x_0-x}\\] Si lâ€™accroissement est plus fort en $y$ que en $x$, on calcul le coefficient directeur. Quand la porte est tres fort, on a un contour.\\[\\frac{\\delta f(x,y)}{\\delta x} =\\]\\[\\frac{\\delta f(x,y)}{\\delta y} =\\] Vecteur directeur en tout point de la courbeCalcul de la deriveeEn continu on a $\\lim_{h\\to 0}\\frac{f(x + h) - f(x)}{h}$ et on veut calculer ca correctement en dirscret.Profil:Derivee: recherche de maxima locaux ?Calcul de la derivee en 1 point x En continu: $\\lim_{h\\to 0}\\frac{f(x + h) - f(x)}{h}$ En discret on a du mal a aller vers 0 En discret on a $\\frac{f(x+1)-f(x)}{1}$ Dans notre cas (discret) $fâ€™(x)=(f(x+1)-f(x))$ ou $\\frac{1}{2}\\times (f(x+1)-f(x-1))$ Masques: $[-1;1]$, $\\frac{1}{2}[-1;0;1]$ Attention signal 2D Roberts Filtre de Roberts\\[r(x,y) = \\sqrt{(i(x,y)-i(x-1,y-1))^2} + \\sqrt{(i(x,y-1)-i(x-1,y))^2}\\\\r(x,y) = \\vert i(x,y)-i(x-1,y-1)\\vert + \\vert i(x,y-1)-i(x-1,y)\\vert\\] Contours pas forcement netsSobel, PrewittFiltres beaucoup plus communs.Sobel:Prewitt:Pourquoi ces coefficients ? On inclut le lissageLa difference: lisser par un filtre moyenneur / Sobel lisser par un filtre Gaussien / PrewittResultatsSobelPrewitt\\[\\frac{\\delta f(x,y)}{\\delta x}\\\\\\frac{\\delta f(x,y)}{\\delta y}\\]On peut combiner les derivees: calculer amplitude du gradient calculer lâ€™angle\\[\\sqrt{sx^2+sy^2}\\\\tan^{-1}(\\frac{sy}{sx})\\]Informations sur lâ€™orientation du gradientComment recuperer les contours a partir de lâ€™image du gradient ?On peut combiner les 2 images Le vecteur gradient est orthogonal aux lignes de niveaux plus sa norme est grande plus la transition est forte On cherche une transition maximaleDifferentes strategies pour recuperrer les contours: Seuillage Seuillage par hysteresis On cherche un seuil pour un profil On garde tout au dessus du seuil et on jette tout en dessous On inclut le motif a droite quâ€™on ne veut pas garder Pour regler ce probleme on utilise 2 seuils un seuil haut un seuil bas On a une 1$^{ere}$ binarisation avec le seuil haut On perd de lâ€™info On enleve le motif quâ€™on veut pas Le seuil tolerant garde beaucoup plus dâ€™infos Hysteresis: on garde tous les resultats des seuils tolerant qui ont un contact avec le seuil haut Recherche de lignes de crete Probleme: Contour ferme/contour ouvert ? Kirsch, RobinsonKirsch and Robinson Compass Masks (Filtres de compas): On fait â€œtournerâ€ le filtre. â€œSobel que lâ€™on fait tournerâ€Lâ€™amplitude est donnee par la plus forte reponse.Lâ€™orientation est deduite du masque qui a donne la plus forte reponse.Frei-ChenPermet de trouver les gradients et dâ€™autres motifs (lignes croises, point, etc.) Edge Line Â  1.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;\\sqrt2&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\-1&amp;amp;-\\sqrt 2&amp;amp;-1\\end{bmatrix}\\) 5.\\(\\frac{1}{2}\\begin{bmatrix}0&amp;amp;1&amp;amp;0\\\\-1&amp;amp;0&amp;amp;-1\\\\0&amp;amp;1&amp;amp;0\\end{bmatrix}\\) 9.\\(\\frac{1}{3}\\begin{bmatrix}1&amp;amp;1&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\end{bmatrix}\\) 2.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;0&amp;amp;-1\\\\\\sqrt 2&amp;amp;0&amp;amp;-\\sqrt 2\\\\1&amp;amp;0&amp;amp;-1\\end{bmatrix}\\) 6.\\(\\frac{1}{2}\\begin{bmatrix}-1&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\1&amp;amp;0&amp;amp;-1\\end{bmatrix}\\) Â  3.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}0&amp;amp;-1&amp;amp;\\sqrt 2\\\\1&amp;amp;0&amp;amp;-1\\\\-\\sqrt 2&amp;amp;1&amp;amp;0\\end{bmatrix}\\) 7.\\(\\frac{1}{2}\\begin{bmatrix}1&amp;amp;-2&amp;amp;1\\\\-2&amp;amp;4&amp;amp;-2\\\\1&amp;amp;-2&amp;amp;1\\end{bmatrix}\\) Â  4.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}-\\sqrt 2&amp;amp;-1&amp;amp;0\\\\-1&amp;amp;0&amp;amp;1\\\\0&amp;amp;1&amp;amp;-\\sqrt 2\\end{bmatrix}\\) 8.\\(\\frac{1}{2}\\begin{bmatrix}-2&amp;amp;1&amp;amp;-2\\\\1&amp;amp;4&amp;amp;1\\\\-2&amp;amp;1&amp;amp;-2\\end{bmatrix}\\) Â  9 masquent qui forment une base Chaque sous-famille est capable de detecter un motif localement La detectection se fait seulement avec:\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;\\sqrt2&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\-1&amp;amp;-\\sqrt 2&amp;amp;-1\\end{bmatrix}\\text{ +rotations a }90^o\\\\\\theta=\\arccos\\biggr(\\sqrt{\\frac{\\sum_{k=1}^4(W_k\\times I)^2}{\\sum_{k=1}^9(W_k\\times I)^2}}\\biggr)\\) Plus $\\theta$ est grand, moins la bordure est marquee ($\\theta$ est entre 0 et $\\pi$).Avantages: Plus robuste a differents niveaux dâ€™illumination Plus robuste car elimine les motifs lignes, points, etc. de la detection Peut etre utilise pour detecter les lignes en utilisant les masques 5 a 8 a la place des masques 1 a 4Le laplacienUtilisation de la derivee seconde Un point de contour est un passage a zero de la derivee secondeDerivee seconde:$f$: $fâ€™$: $fâ€™â€™$: Un point de contour nâ€™est rien dâ€™autre quâ€™un passage de la derivee seconde par 0. Calcul du laplacien $fâ€™(x)=f(x+1)-f(x)$ $\\frac{f(x+1)-f(x)}{1}$ $fâ€™â€˜(x) = (x+1)-fâ€™(x)$ $fâ€™â€˜(x = f(x+2)-f(x+1)-f(x+1)+f(x)$ On obtient un masque simple:\\[f&#39;&#39;(X) = f(X+1)-2\\times f(X)+f(X-1)\\] Si on veut detecter les contours, il faut chercher les passage par 0 du resultat:On a somme le masque horizontal et vertical Les contours sont reperes par un changement de signeOn va plutot chercher un changement de signe (de forte amplitude)Si $E\\gt0$ il faut un des $A,B,C$ ou $D\\lt0$ et inversement si $E\\lt 0$ La calcul des derivees est approche au moyen de filtres Simple et rapide Inconvenients: approximation, sensibilite au bruit, en particulier le Laplacien $\\rightarrow$ necessite de lisser le signal avant ou lors de la derivation Impact du lissage Robustess au bruit Delocalisation des points de contour Le Laplacien est sensible au bruit $\\to$ sur-segmentationEvaluation de la qualite de detection de contours: Bonne detection Bonne localisation Reponse unique Cf filtre de Canny/DericheDetection de points dâ€™interet Detection de coins Comment se caracterise un coin ? Comment trouver les coins ? Pourquoi trouver les coins ? Coin = gradient fort dans 2 directionsMoravecPour chaque point: On fait la somme $S$ des differences des intensites entre un voisinage centre sur le point et le voisinage decale On reitere le calcul avec des decalages dans toutes les directions Pour chaque point, on garde, parmi tous les decalages $i$ le resultat de $S_i$ qui a donne la plus faible valeurMoravec: Calcul dâ€™un critere sur toute lâ€™image\\[c_{d_x,d_y}(x,y) = \\sum_{i=-s...+s}\\sum_{j=-s...+s}(I(x+i, y+j)-I(x+i+d_x,y+j+d_y))^2\\] On calcul un critere pour chaque point\\[c(x,y)=\\min_{d_x,d_y}(c_{d_x,d_y}(x,y))\\] Un coin est un maximum local de $c(x,y)$Desavantages: Sensible au bruit (des petites imperfections peuvent etre prises pour des coins) Contours de certaines directions peuvent etre pris pour des coins (anisotrope car on considere que quelques directions)HarrisRevision du critere pour etre plus robuste\\[c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)(I(x+i,y+j)-I(x+i+d_x,y+j+d))^2\\\\I(x+d_x,y+d_y)\\simeq I(x,y)+d_x\\biggr(\\frac{\\delta I(x,y)}{\\delta x}\\biggr)+d_y\\biggr(\\frac{\\delta I(x,y)}{\\delta y}\\biggr)+...\\\\c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)\\biggr(d_x\\biggr(\\frac{\\delta I(x+i,y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)\\biggr)^2\\]Critere:\\(c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2\\\\\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2\\)\\[\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2 = (d_x,d_y)\\begin{pmatrix} (\\frac{\\delta I}{\\delta x})^2 &amp;amp;(\\frac{\\delta I}{\\delta x\\delta y})\\\\ (\\frac{\\delta I}{\\delta x\\delta y}) &amp;amp; (\\frac{\\delta I}{\\delta y})^2\\end{pmatrix}\\begin{pmatrix}d_x\\\\d_y\\end{pmatrix}\\]Ce qui donne:\\[Ad+x^2+2Cd_xd_y+Bd_y^2\\\\M=\\begin{pmatrix} A&amp;amp;C\\\\ C&amp;amp;B\\end{pmatrix}=\\begin{pmatrix} (\\frac{\\delta I}{\\delta x})^2 &amp;amp;(\\frac{\\delta I}{\\delta x\\delta y})\\\\ (\\frac{\\delta I}{\\delta x\\delta y}) &amp;amp; (\\frac{\\delta I}{\\delta y})^2\\end{pmatrix}\\] Avec $w$ une gaussienneNouveau critere H $H=det(M)-\\alpha$ trace $(M)^2$ $\\lambda_1$ $\\lambda_2$ les deux valeurs propres $det(M)=\\lambda_1\\lambda_2$ et $trace(M)=\\lambda_1+\\lambda_2$ $H=\\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$ $H\\lt0$ contour $H\\to0$ ras $H\\gt\\gt0$ coin $\\alpha$ grand $\\Rightarrow$ $H$ diminue et le detecteur est moins sensible $\\alpha$ petit $\\Rightarrow$ $H$ diminue et le detecteur est plus sensibleAchard, Bigorgne, Devars Detection basee sur le produit vectoriel Pres dâ€™un coin, la norme du produit vectoriel entre 2 vecteur gradient est grande Dans une zone homogene elle est faible La norme des vecteurs gradients est petite Sur un contour elle est faibke aussi Lâ€™angle frome entre 2 vecteurs gradients proches est petit Pour chaque point $i$, avec un voisinage $V_i$, on determine un critere $k$: \\(k=\\sum_{j\\in V_i}\\Vert\\overrightarrow{grad(P_i)}\\Vert^2\\Vert\\overrightarrow{grad(P_j)}\\Vert^2\\sin^2(\\widehat{grad(P_i),grad(P_j)})\\)\\(\\begin{aligned}&amp;amp;I_x=\\biggr(\\frac{\\delta I}{\\delta x}\\biggr) &amp;amp;\\Vert\\overrightarrow{grad(P)}\\Vert^2=I_x^2+I_y^2\\\\&amp;amp;\\widehat{\\sin(ox,grad(P)})=\\frac{I_y}{\\sqrt{I_x^2+I_y^2}} &amp;amp;\\widehat{\\cos(ox,grad(P)})=\\frac{I_y}{\\sqrt{I_x^2+I_y^2}}\\\\&amp;amp;k=I_x^2&amp;lt;I_y^2&amp;gt;+I_y^2&amp;lt;I_x^2&amp;gt;-2I_xI_y&amp;lt;I_xI_y&amp;gt; &amp;amp;&amp;lt;I&amp;gt;I\\times\\begin{pmatrix}1&amp;amp;1&amp;amp;1\\\\1&amp;amp;0&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\end{pmatrix}\\end{aligned}\\)ResultatsArchardAmelioration de la netteteLaplacien Retour sur la derivee seconde (Laplacien)$f$: $fâ€™$: $fâ€™â€™$: \\[f&#39;&#39;(X) = f(X+1)-2\\times f(X)+f(X-1)\\]Renforcement de la nettete$-fâ€™â€™$: Ce quâ€™on ainerai câ€™est combine $f$ et $-fâ€™â€™$ pour ecarter les amplitudes des extremums avant et apresOn prend $f$ et lui on lui retranche $k$ fois la derivee seconde pour accroitre le contraste locale$f$: $-kfâ€™â€™$: $f-kfâ€™â€™$: Masque pour le Laplacien Rajouter $+1$ au centre câ€™est comme rajouter lâ€™image completeResultats Augmente la nettete Renforce le bruitCâ€™est lâ€™inverse de ce quâ€™on a fait au debutConclusion Tout ce quâ€™on a fait jusquâ€™a present est faux car on a pas pris en compte la correction gamma." }, { "title": "OCVX: Introduction", "url": "/cours/posts/ocvx_introduction/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-11 13:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionLâ€™optimisation fait partie des missions historiques de lâ€™ingÃ©nierie. Elle naÃ®t avec lâ€™Ã¨re industrielle: une fois un concept Ã©laborÃ© il sâ€™agit de rÃ©duire les coups, minimiser les risques de dÃ©fauts de livraisons ou Ã©tendre le scope dâ€™action â€¦Les techniques mathÃ©matiques qui permettent de rÃ©soudre une partie de ces problÃ¨mes dâ€™optimisation balayent un large spectre des thÃ©matiques mathÃ©matiques que vous avez pu aborder jusque lÃ ; lâ€™algÃ¨bre linÃ©aire, le calcul diffÃ©rentielle et un peu de gÃ©omÃ©trie. Le cours dâ€™OCVX a pour objectif de vous donner le bon degrÃ© de confort pour manipuler ces techniques.De quoi on parle ?Voici quelques exemples quâ€™on pourrait croiser lorsquâ€™on sâ€™intÃ©resse Ã  lâ€™optimisation. Chercher le plus court/rapide chemin entre deux coordonnÃ©es GPS. DÃ©cider des meilleures routes aÃ©riennes qui minimisent le prix dâ€™approvisionnement en kÃ©rosÃ¨ne. Identifier des images dâ€™IRM qui correspondent Ã  des malformations du cerveau. Chercher des patterns dans la population dâ€™Ã©tudiants intÃ©grants Epita DÃ©cider dâ€™achat/vente dâ€™assets prenant en compte lâ€™historique disponible.Probleme dâ€™optimisationDefinition formelleOn Ã©crit en gÃ©nÃ©ral un problÃ¨me dâ€™optimisation $(P)$ sous la forme standard\\[\\begin{aligned}&amp;amp;\\text{minimiser} &amp;amp;f_0(x) &amp;amp;\\\\&amp;amp;\\text{sujet a } &amp;amp;f_i(x)\\le0, &amp;amp;\\forall i\\in\\{1,...,p\\}\\\\&amp;amp; &amp;amp;h_j(x)=0, &amp;amp;\\forall i\\in\\{1,...,m\\}\\end{aligned}\\]oÃ¹ $f_0$, les $f_i$ et les $h_j$ sont des applications de $\\mathbb R^n$ vers R. La fonction $f_0$ est dite fonction objectif ; suivant le contexte ce sera une fonction de coÃ»t ou dâ€™erreur. Les inÃ©galitÃ©s sont qualifiÃ©es de contraintes dâ€™inÃ©galitÃ©s et les Ã©galitÃ©s de contraintes dâ€™Ã©galitÃ©s. TentativeVous pouvez chercher Ã  formuler les problÃ¨mes Ã©numÃ©rÃ©s sous forme dâ€™un problÃ¨me dâ€™optimisation, ce nâ€™est pas toujours Ã©vident.Un probleme dâ€™optimisation du type de $(P)$ est dit differentiable si toutes les fonctions en jeux le sont; non-contraint sâ€™il nâ€™a aucune contraintes dâ€™inegalites ou egalites convexe si lâ€™ensemble des fonctions en jeu sont convexes, les contraintes dâ€™egalites etant de plus affinesSous la premiÃ¨re hypothÃ¨se on a une sÃ©rie dâ€™outils mathÃ©matiques qui nous permettront dâ€™apporter un Ã©clairage riche sur $(P)$. Si lâ€™on rajoute la seconde on est en mesure de construire des procÃ©dÃ©s itÃ©ratifs efficaces en Ã©tat de rÃ©soudre ces problÃ¨mes. La derniÃ¨re nous garantie de trouver la solution optimale. Fake newsLes Ã©lÃ©ments en italiques sont lÃ  pour marquer le fait que nos assertions Ã  ce stade sont encore un peu fausses. Lâ€™image est un peu moins idyllique.LexiqueÃ‰tant donnÃ© un problÃ¨me dâ€™optimisation $(P)$ on appelle: point admissible de $(P)$ tout point de $R^n$ satisfaisant toutes les contraintes. Lâ€™ensemble de tous les points admissibles est appelÃ© lieu admissible de $(P)$. valeur objectif dâ€™un point admissible la valeur que prend la fonction objectif en celui-ci. valeur optimale de $(P)$ la meilleure borne infÃ©rieure sur la fonction objectif. point optimal de $(P)$ tout point admissible dont la valeur objectif est la valeur optimale.Premieres remarques qualitativesComme est le cas de tout systÃ¨me dâ€™Ã©quations, il est utile de se poser le type de questions suivantes: y a-t-il au moins une solution? sâ€™il y a au moins une solution combien? peut-on toujours dÃ©crire lâ€™ensemble des solutions? y a-t-il moyen dâ€™approcher des solutions? QuestionChercher un problÃ¨me dâ€™optimisation qui: a un lieu admissible est vide; a plus dâ€™un seul point optimal; nâ€™a pas de valeur optimale mais a un lieu admissible non vide \\; a une valeur optimale mais pas de point optimal. Cadre de la premiere UE dâ€™OCVXContours du coursOn se limite au cours du premier semestre de majeure au cas des problÃ¨mes dâ€™optimisations sans contraintes. Câ€™est un cadre suffisant pour les premiÃ¨res applications des techniques dâ€™optimisations Ã  un premier niveau de ML ; il recouvre le cas des diffÃ©rentes rÃ©gressions, de lâ€™entraÃ®nement dâ€™un rÃ©seau de neurones ainsi que les cas des algos de classification standards Il reprÃ©sente un premier niveau Ã  atteindre qui permet de fixer votre attitude vis-Ã -vis dâ€™un problÃ¨me dâ€™optimisation, sans sâ€™encombrer de concepts plus abstraits Ã  concevoir. Il ne recouvre pas le cas des Support Vector MachinesRegression mon amieMap Fitting Une famille diffÃ©rentiable dâ€™applications $f_{\\alpha} : \\mathbb R^n \\to \\mathbb R$ indexÃ©es par $\\alpha\\in \\mathbb R^k$ est une famille de fonctions pour laquelle lâ€™application $\\phi : \\mathbb R^k \\times\\mathbb R^n â†’ \\mathbb R$ qui envoie $(\\alpha, x)$ sur $f_{\\alpha}(x)$ est diffÃ©rentiable. On considÃ¨re un ensemble de couples $(X_i, y_i) \\in\\mathbb R^n \\times\\mathbb R$ pour $i \\in {1, . . . , p}$ et une famille diffÃ©rentiable dâ€™applications ${f_{\\alpha}},\\alpha\\in\\mathbb R^k$ . Le problÃ¨me de map fitting relatif aux donnÃ©es prÃ©cÃ©dentes consiste Ã  trouver les meilleurs paramÃ¨tres $\\alpha^$ tels que $f_{\\alpha^}$ approche au mieux (pour une mÃ©trique prÃ©-choisie) a les $(X_i, y_i)$.La regression lineaireLe plus simple des problÃ¨mes de map fitting est celui de la rÃ©gression linÃ©aire. Dans le cas de dimension 1 (on cherche Ã  approcher une fonction de $\\mathbb R$ dans $\\mathbb R$) il se dÃ©cline comme ceci: la famille diffÃ©rentiable Ã  laquelle on sâ€™intÃ©resse est indexÃ©es par $\\mathbb R^2$: $f_{\\alpha}(x)=\\alpha_1x+\\alpha_0$ pour $\\alpha=(\\alpha_0,\\alpha_1)$ la mÃ©trique standard utilisÃ©e est la MSE pour Mean Square Error donnÃ©e pour un $f_{\\alpha}$ par\\[\\mathcal E(\\alpha) = \\sum_{i=1}^p\\frac{1}{p}(f_{\\alpha}(x_i)-y_i)^2\\]câ€™est une estimation moyenne de la variance des prÃ©dictions de $f_{\\alpha}$ Le but est de trouver un paramÃ¨tre $\\alpha=(\\alpha_0,\\alpha_1)$ tel que $\\mathcal E(\\alpha)$ est minimal, autrement dit de rÃ©soudre le problÃ¨me dâ€™optimisation sans contraintes minimiser $\\mathcal E(\\alpha)$.Le problÃ¨me de rÃ©gression linÃ©aire a une solution analytique; cÃ d une solution donnÃ©e par une expression explicite en fonction des entrÃ©es.Cette solution implique cependant lâ€™inversion dâ€™une matrice de taille Ã©quivalent Ã  celle des donnÃ©es en entrÃ©e. Chose particuliÃ¨rement coÃ»teuse.Empathie machineApproximation sÃ©quentielleIl est rare quâ€™un problÃ¨me dâ€™optimisation ait une solution analytique. MÃªme quand cela est le cas il est souvent plus efficace de chercher une solution approchÃ©e.Un processus itÃ©ratif qui rÃ©sout un problÃ¨me dâ€™optimisation $(P)$ est un choix initial dâ€™un point de dÃ©part (de prÃ©fÃ©rence) admissible $x_0$ ; un processus itÃ©ratif qui construit un point admissible $x_{n+1}$ Ã  partir de $x_n$ et de donnÃ©es locales ayant une valeur objectif plus petite que celle de $x_n$.Cette dÃ©marche ne nous offre en gÃ©nÃ©ral quâ€™une approximation dâ€™une solution. Elle a cependant lâ€™avantage de pouvoir se dÃ©rouler en temps raisonnable. Il faut par ailleurs prendre en compte que lâ€™implÃ©mentation des flottants en machines nous contraint dÃ©jÃ  Ã  approcher les grandeurs quâ€™on manipule.Acquis dâ€™apprentissages vises (AAVs) Savoirs Identifier les Ã©lÃ©ments composants un problÃ¨me dâ€™optimisation et des Ã©lÃ©ments nÃ©cessaires Ã  son Ã©tude qualitative Cartographier les outils Ã  disposition pour rÃ©soudre un problÃ¨me dâ€™optimisation et les hyperparamÃ¨tres qui dÃ©clinent et gouvernent ceux-ci. DÃ©crire le domaine de validitÃ© dâ€™un algorithme. Savoir-faire ImplÃ©menter des algorithmes standards dâ€™optimisation sans contraintes Effectuer des analyses comparatives entre des diffÃ©rentes algorithmes dâ€™optimisation sans contraintes ReconnaÃ®tre les problÃ¨mes liÃ©s aux approximations numÃ©riques qui apparaissent dans toute implÃ©mentation. Attitude - Analyse de risque Vivre par le moto : Un test nâ€™est pas une statistique et une statistique ne vient pas sans variabilitÃ©. Contenus notionnels PrÃ©-requis techniques Des Ã©lÃ©ments de gÃ©omÃ©tries InterprÃ©tation gÃ©omÃ©trique du produit scalaire Courbes de niveau et epigraphes de fonctions. Parties et fonctions convexese en dimension finie. Des Ã©lÃ©ments de topologie Comment calculer des distances et dÃ©finir des voisinanges dans $\\mathbb R^n$ Approcher et comparer des fonctions Ã  plusieurs variables. Des Ã©lÃ©ments de calcul diffÃ©rentiel Approcher localement une fonction multivariÃ©es par une fonction affine. Ã‰criture en base ; jacobienne et gradient. InterprÃ©tation gÃ©omÃ©trique du gradient Approximation locale de second ordre : la hessienne Ã‰tude qualitative des problÃ¨mes dâ€™optimisation. Le lieu critique dâ€™une fonction objectif. Apport de la convexitÃ© au contexte de lâ€™optimisation. Ã‰tudes du cas quadratique. MÃ©thodes de rÃ©solutions itÃ©ratives. Descentes de gradients et MÃ©thodes de Newton EvaluationDeux modes dâ€™Ã©valuations vont intÃ©ragir dans le cadre de ce cours Des Ã©valuations formatives via moodle, ce qui est suffisant pour garantir le fait que vous consacrez suffisamment de temps Ã  comprendre les Ã©lÃ©ments de cours et lâ€™assimiler. Une Ã©valuation formative est notÃ©e de maniÃ¨re binaire : 0% de la note si lâ€™Ã©tudiant nâ€™y participe pas sÃ©rieusement et 100% sinon. Des Ã©valuations sommatives comptabilisÃ©es de maniÃ¨re classique. Elle seront composÃ©es dâ€™une Ã©valuation intermÃ©diaire qui prendra la forme dâ€™un devoir sur table, celui-ci vise Ã  garantir votre capacitÃ© Ã  formuler un raisonnement gÃ©omÃ©trique / diffÃ©rentiel concernant les problÃ©matiques dâ€™optimisation dâ€™une Ã©valuation TP afin dâ€™avoir un regard sur lâ€™ensemble des Ã©lÃ©ments que vous aurez pu mobiliser pour atteindre les objectifs de cours. Les Ã©valuations formatives comptent pour 20% de la note finale. On attend de vous de faire preuve dâ€™autonomie lors du suivi de ce cours.MoodleLâ€™ensemble des contenus de cours, dâ€™annonces, de bibliographies de travail Ã  rendre et des tests dâ€™Ã©valuation seront disponibles sur un cours moodle auquels vous serez inscrit bientÃ´t." }, { "title": "ISIM: La modelisation", "url": "/cours/posts/isim_modelisation/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, maillage, surface, polygone, animation", "date": "2021-03-11 09:00:00 +0100", "snippet": "Lien de la note HackmdModelisation Rendu temps reel Mailages/polygones Rendu photorealiste (algorithme type raytracing) Maillages/polygones Mathematiques Animation Modeles physiques Chaque objet est decrit par une formule mathematiques Tres compact et bien adapte pour les algorithmes type raytracing Formule compliquee ou impossible a determiner pour la plupart des objetsFormes de bases - primitives 2D/3D Sphere Cylindre Cube Plan Tore â€¦MaillageConstruction dâ€™objets par assemblage de polygones Bonne modelisation des objets avec peu de courbes (architectureâ€¦) Peu compacte mais facile manipulerRepresentation Polygone utilise: Majoritairement le triangle Facilite le traitement (remplissageâ€¦) Representation en interne Liste de coordonnees de sommets par polygone Duplication des sommets communs a plusieurs polygones Pas de connaissance de la topologie Liste de sommets puis liste dâ€™indice par polygone Gain de place Reduction de la quantite dâ€™information Pas de connaissance de la topologie Triangulation de Delauny Cas pour quand le maillage nâ€™est pas en triangle.Diagramme de Voronoi $vor(p) = {x\\in E;\\forall qd(x,p)\\le d(x,q)}$Mesh Refinement On veut appauvrir le maillage quand il est loin et lâ€™enrichir quand il est pres.Adaptive mesh refinement Depth taggingModelisation surfaciqueSurfaces de BezierBezier (1960 - Renault) Courbes de Bezier Surfaces de Bezier Ces courbes ont ete mises en place pour representer les carosseries de voituresCourbes de Bezier Courbes de Bezier: definir une courbe passant par 2 points: Lissage lineaire $P_1t+P_2(1-t)$ avec $0\\le t\\le1$ Si plus de points: continu par morceau Lissage polynomial $x(t) = Q(t) = a_3t^3+a_2t^2+a_1t+a_0$ $y(t) = R(t) = b_3t^3+b_2t^2+b_1t+b_0$ Pour garder la derivabilite en $P_1$ et $P_2$: $Qâ€™(t) = 3a_3t^3+2a_2t+a_1$ Idem pour $y(t)$ Il faut trouver les $a_i$ et les $b_i$ On va utiliser: $x(0)=xP_1$ $x(1)=xP_2$ $xâ€™(0) = xâ€™P_1$ $xâ€™(1)=xâ€™P_2$ Ce qui donne: $x(t)=(2t^3-3t^2+1)xP_1+(-2t^3+3^2)xP_2+(t^3-2t^2+1)xâ€™P_1+(t^3-t^2)xâ€™P_2$ Idem pour $y(t)$ Comment avoir les $xâ€™(0)=xâ€™P_1$ $xâ€™(1)=xâ€™P_2$ Ajout de points de controles $D_n$ pour determiner la derivee localement. Les vecteurs tangents sont deduits par $3(D_1-P_1)$ Cela donne:\\[xP_1(1-t)^3+xD_1(3t(1-t)^2)+xD_23t^2(1-t)+xP_2t^3\\] On peut chainer et rajouter des morceaux pour agrandir la courbe.Resultats: La texture est dâ€™ailleurs proceduralePour definir une courbe plus complexe: Augementer le degre La modification dâ€™un point de controle perturbe toute la courbe Joindre plusieurs courbes de BezierPour appliquer des transformations affines: Applique les transformations affines aux points de controleSurfaces de BezierPar extension: surfaces de Bezier 4 points de controle en 2D, 16 points de controle en 3D Joindre plusieurs surfaces de BezierLissage de polygonesSurface de subdivisionDifferents algorithmes: Algorithme de catmull-Clark, Doo-sabin.Un exemple en 2D: Diviser chaque segment en 3 parties egales joindre les divisions successives Recommencer jusquâ€™au niveau lissage desire A faire en 3DAlgorithme de Catmull-ClarkExemple: Est-ce quâ€™on peut dire que câ€™est faitâ€¦ a la main ?Modelisation par assemblageC.S.G. C.S.G.: Constructive Solid GeometryCombiner des briques de base (solides) par des operations: Union Intersection DifferenceUnion:Intersection:Difference:Representation sous forme dâ€™arbre: Fonction implicite dâ€™un solide: $F(x,y,z)$ $F(x,y,z)\\lt0$ interieur $F(x,y,z)=0$ surface $F(x,y,z)\\gt0$ exterieur Pour le calcul des C.S.G.: $-1;0;1$ $F_{A\\cap B}(p) = \\max(F_A(p),F_B(p))$ $F_{A\\cup B}(p) = \\min(F_A(p),F_B(p))$ $F_{A-B}(p) = \\max(F_A(p),-F_B(p))$ Modelisation par revolution Lâ€™objet est construit par la rotation dâ€™une forme autour dâ€™un axe de revolution Fonction dâ€™un angle Fonction dâ€™un pas dâ€™echantillonnage Trace du contour:Lâ€™axe de revolution se situe au centre (axe vert et axe rouge) On se rend compte que le Graal nâ€™est rien dâ€™autre quâ€™une fulte a champagneAutres exemples: La boule de bowling presente des C.S.G.Modelisation par extrusion Lâ€™objet est construit par une surface suivant une trajectoire Le chemin peut etre plus ou moins complique Câ€™est peut-etre une etoile de mer mais je la fait sortir de terreRetour a la main de tout a lâ€™heure:Cartes dâ€™altitudesPermet generalement de representer les terrains: Construction: Iterative â€¦ Exemple: Is this minecraftBlobs/Metaballs Representation dâ€™un objet par iosurfaceImaginons quâ€™on met une source dâ€™energie qui chauffe:Quâ€™est-ce qui se passe si on a 2 points dâ€™energie qui se rapprochent ?On obtient une courbe car les valeurs se somment. On peut utiliser cette courbe pour modeliser des formes arrondies.En 2D:En 3D: Jâ€™ai fait un petit objet, je sais pas ce que câ€™est.Hand-spinner?On peut faire des gouttes de mercure qui sâ€™attachent ensemble. Le point dâ€™energie nâ€™est pas forcement ponctuel, ca peut un un plan, un cylindre, etc. On un un pâ€™tit.. pâ€™tit cheval Rendu En raytracing, evaluation le lonf du rayon Algorithme des â€œmarching cubesâ€ Particules Attention au calcul des normales Modelisation Eau â€¦ Modelisation de la vegetationGraftalesModelisation desplantes L-Systems (Lindenmayer, 1968) Similaire a une grammaire souvent utilise pour modeliser la vegetation (mais pas seulement) Yâ€™a un super cours de theorie des langages donne par Jonathan FabrizioOn par de lâ€™axiome et on applique la regle de production On divise le 1$^{er}$ segment en 3 sous-segments On rajoute 2 segments inclines On repete a chaque etape On a besoin de differentes regles dâ€™evolutions (branches, couleurs, etc.). Le plus dur câ€™est de definir la grammaire de base.Acquisition Comment font-ils pour faire des modeles aussi beau ?Scan 3DPour le monde de Nemo:On a un vrai artiste qui fait un vrai modeleSuite au scan 3D du modelePour Avatar: Cette pratique est assez courante.Dâ€™autres artistes scultent directement le modele numerique.Sculpture 3D:Codage des Formes/Maillages Aretes aillees B-rep Array of vertex Enregistrer tous les sommets et leurs proprietes Pas tres compact Array of indexes Lister les sommets et leur caracteristiques Tablea dâ€™addressage indexe Dans cette exemple: le sommet 1 est enregistre plusieurs fois, on a pas a enregistrer ses caracteristiques a chaque fois, on fait un addressage indexe. Ne mache pas toujours, les proprietes peuvent varier dâ€™un meme sommet en fonction du polygone auquel il est rattache.Aretes aillesUne arete: une orientation Sommet de depart et dâ€™arrivee On les memorise selon un ordre deux faces deux sommets quatre aretes Le sommet actuel y est toujours lie si elles existent Boundary Representation B-Rep Un solide est modelise par les elements exterieurs. Cela donne une surface fermee Ensemble de : Faces, aretes et sommets + relations topologiques Les faces ne doivent pas sâ€™intersecter ailleurs que sur des aretes explicites (de la B-REP) Les afces doivent separer lâ€™interieur de lâ€™exterieur du solide Redondance des donnees $\\to$ risque dâ€™incoherenceModelisation dâ€™une sceneDeformation/Mouvements/Objets articules Representation hierarchique Systeme de pile de matrices Deformations libresOn veut contorsionner un objet mais ses morceaux doivent restes coherents. Une solution: faire un volume de Bezier et modifier les points de controle Solution simple Pas la plus efficace Animation Generation de toutes les images qui composent lâ€™animations Il faut donc modeliser les transformations Deplacements Deformations Changement de couleur â€¦ Equation de mouvement Definitions des positions et orientations - trajectoire a suivre Position cle et interpolation Specification que de quelques positions puis interpolation automatique pour generer les positions intermediaires (pas facile de respecter toutes les contraintes) Modele physique Donne du realisme au mouvement Lâ€™ordinateur calcul les positions intermediaires Lâ€™animateur fait les images â€œclesâ€ de lâ€™animationPositions cles Celle de droite câ€™est quand Fabrizio va voir mon raytracerVitesse du mouvementIl faut gere lâ€™acceleration du mouvement entre 2 positions cles Un mouvement lineaire nâ€™est pas realiste Il y a du travail sur lâ€™expression du visageLe monde de NemoFilmer des poissons reels pendant tres longtemps et reproduire le mouvementAnimations difficilesAnimation de personnages Definition de lâ€™animation complete du personnage Difficile et consommation memoire trop elevee Definition dâ€™un â€œsqueletteâ€ et dâ€™une â€œpeauâ€ Le mouvement est specifie uniquement pour le squelette Gain de place Retournons sur la main:On a rajoute un squelette, si on veut bouger la main, on bouge le squelette. Le squelette de la main est anatomiquement faux Definition dâ€™un â€œsqueletteâ€ Le corps humain comporte environ 200 os Environ une centaine dâ€™articulations assemblage de segments rigides Structure arborescente hierarchique Rotation avec ajout de contraintes Cinematique inverse Trouver la bonne position Le deplacement des os entraine le deplacement de la peau La peau Cylindres Maillages ou surfaces (Splinesâ€¦) Attachement de chaque point a un os Ponderation de lâ€™attachement dâ€™un point aux os voisins Modeles de muscles Modelisation par blobs et surfaces implicites Dans lâ€™ensemble ce type de modeles nâ€™est plus trop utilise Modelisation des muscles par des ressorts Modelisation par particules hierarchiques Noyau: lie au reste du modele Derme: deformation delâ€™objet Epiderme: cohesion et surface + interaction et collisions avec le rest du monde $\\to$ Diminution de la complexite Interaction uniquement avec la couche voisine Interaction avec lâ€™exterieur geree au niveau de lâ€™epiderme diminution du nombre de particules diminution de la quantite de calculs Problemes de jointures Augmentation du maillage aux jointures Ajout dâ€™os dans lâ€™articulation Ajout de contraintes: section minimal autour de chaque os.. Lissage des ponderations des contributions des os sur lâ€™enrobage Animation de visagesQuelques positions modelisees Normal, souriatn.. Calcul automartique des transitions (morphing)Temps reel: Blend shape Position neutre Codage des deltas pour arriver a une position particuliereMotion capture Realisme important Des acteurs vont jouer la scene Jouent dans un hangar dans lequel ils sont geolocalises Ils auraient pu se peindre le visage en bleu mais ils ont pas oses Au moins ils ont des pâ€™tites oreilles Camera: geolocaliseeMapping: Câ€™est pendant lâ€™entrainement, pas le hangarMouvement du visage:Une grosse bete va manger des chevaux:On va caller des modeles 3D de chevaux qui se feront mangerFonctionne de la meme facon que le motion capture avec les humains: Pas tous les filmes utilisent le motion capture, comme RatatouilleTissus et vetementsModeles masses-ressorts Maillage de Provot On met des â€œmassesâ€ Ajout de ressorts pour le cisaillement et la courbure Indique les contraintes physiques entre chacune des masses Collisions et autocollisions Beaucoup de calculs division de lâ€™espace et volumes englobants Autocollisions Eviter que le tissus passe au travers de lui-meme en se repliant Conclusions Modelisatione et animation" }, { "title": "PRST: Feuille 3 - Exercice", "url": "/cours/posts/prst_third_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, estimateur, poisson, normale, geometrique, pareto, uniforme", "date": "2021-03-10 14:30:00 +0100", "snippet": "Lien de la note HackmdExercice du coursDÃ©terminer les estimateurs des paramÃ¨tres $m$ et $\\sigma$ 2 donnÃ©s par la mÃ©thode des moments pour une loi normale $N (m, \\sigma^2)$. Solution \\(E(\\lambda) = \\frac{1}{\\lambda}\\\\\\lambda = \\frac{1}{E(X)}\\\\\\hat\\lambda=\\frac{1}{\\bar X_n}\\) $X_n\\to^{P.S} \\frac{1}{\\lambda}$ loi forte des grand normbres\\[f:x\\mapsto\\frac{1}{x}, \\mathcal C^{\\gamma}\\\\]0;+\\infty[\\to\\mathbb R\\]Exercice 1Determiner un estimateur convergent et sans biais du parametre $\\lambda$ pour la loi de Poisson. Solution On sait que:\\[E(Y) = \\lambda\\] Donc lâ€™estimateur dâ€™ordre 1 de parametre $\\lambda$ est:\\[\\hat\\lambda = \\bar X_n = \\frac{1}{n}\\sum_{i=1}^nX_i\\] Lâ€™estimateur est sans biais et il est fortement convergent par la loi forte des grand nombres.Exercice 2Determiner un estimateur du parametre $\\alpha$ pour la loi de Pareto par la methode des momets (cf. feuille1). Solution On sait que $E(X) = \\frac{\\alpha}{\\alpha -1}$\\[\\alpha -1E(X) = \\alpha\\\\\\alpha(E(X)-1) = E(X)\\\\\\alpha=\\frac{E(X)}{E(X) - 1}\\\\\\bar\\alpha\\frac{\\bar X}{\\bar X -1}\\]Exercice 3Determiner un estimateur du parametre $p$ pour une loi geometrique. Solution\\[X\\sim\\mathcal E(p)\\\\E(X) = \\frac{1}{p}\\\\\\text{donc } p = \\frac{1}{E(X)}\\\\\\bar p = \\frac{1}{X}\\]Exercice du cours loi de Pareto de parametre $\\alpha$ densite $f(x,\\alpha)=\\alpha x^{-\\alpha-1}$ pour $x\\gt1$ et $\\alpha\\gt0$ Determiner lâ€™EMV Solution\\[\\begin{aligned}L(x_1,...,x_n,\\alpha)&amp;amp;=\\Pi_{k=1}^nf(x_k,\\alpha)\\\\&amp;amp;= \\Pi_{k=1}^n\\alpha x^{-\\alpha-1}\\\\&amp;amp;= \\alpha^n\\Pi_{k=1}^nx^{-\\alpha-1}\\\\\\log(L(x_1,...,x_n,\\alpha)) &amp;amp;= n\\log(\\alpha)+\\sum_{k=1}^n\\log(xk^{-\\alpha-1})\\\\&amp;amp;= n\\log\\alpha-(\\alpha-1)\\sum_{k=1}^n\\log(xk)\\\\\\frac{\\delta L}{\\delta\\alpha} &amp;amp;= \\frac{n}{\\alpha}-\\sum_{k=1}^n\\log(x_k)\\\\\\frac{\\delta L}{\\delta\\alpha} = 0 &amp;amp;\\Leftrightarrow \\frac{n}{\\alpha}-\\sum_{k=1}^n\\log(x_k)=0\\\\&amp;amp;\\Leftrightarrow \\alpha=\\frac{n}{\\sum_{k=1}^n\\log(x_k)}\\\\&amp;amp;\\Leftrightarrow \\alpha=\\frac{1}{\\frac{1}{n}\\sum_{k=1}^n\\log(x_k)}\\\\\\frac{\\delta^2L}{\\delta\\alpha^2}&amp;amp;=-\\frac{n}{\\alpha^2}\\lt0\\\\\\hat\\alpha &amp;amp;= \\frac{1}{\\frac{1}{n}\\sum_{k=1}^n\\log(x_k)} \\Rightarrow\\text{ EMV}\\end{aligned}\\]Exercice 6Soit $X$ une varibale aleatoire suivant une loi uniforme sur $[0,\\theta]$. Quelle est la densite de la variable aleatoire $X$ ? Quelle est son esperance ? En deduire un estimateur du parametre $\\theta$ par la methode des moments Solution 1.\\[f(x,\\theta)=\\begin{cases} \\frac{1}{\\theta} &amp;amp;\\text{si } x\\in[0,\\theta]\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\] 2.\\[E(X) = 0 + \\frac{\\theta}{2} = \\frac{\\theta}{2} \\Rightarrow \\theta=2\\times E(X)\\] 3.\\[\\hat\\theta=2\\bar X\\]" }, { "title": "PRST: Seance 3, Convergences", "url": "/cours/posts/prst_convergences/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, convergence, central limite, estimateur, moment, maximum de vraisemblance, exponentielle", "date": "2021-03-10 14:30:00 +0100", "snippet": "Lien de la note HackmdModes de convergenceConvergence presque sure (p.s.) $(X_i)$ suite de v.a definies sur le mÃªme espace $\\Omega$ et $X$ une variable alÃ©atoire Ã©galement dÃ©finie $\\Omega$. convergence ponctuelle implique tous les autres.Convergence en probabilite Meme cadre que precedemment $\\forall\\varepsilon\\gt0, \\lim_{n\\to+\\infty}P(\\vert X_n-X\\vert\\ge\\varepsilon)=0$Convergence $L^2$ aussi appelee convergence en moyenne quadratique $\\lim_{n\\to+\\infty}E(\\vert X_n-X\\vert)=0$ nâ€™a de sens que pour les variables alÃ©atoires telles que $E(X^2)\\lt+\\infty$ implique la convergence en probabilitÃ©, nâ€™a pas de lien avec la convergence presque sÃ»re.ThÃ©orÃ¨me Central LimiteThÃ©orÃ¨me 4 (Loi forte des grands nombres)Soit $(Xi)$ une suite de variables alÃ©atoires i.i.d. (indÃ©pendantes et identiquement distribuÃ©es) telle que $E(\\vert X_1\\vert) &amp;lt; +\\infty$.Notons $m := E(X_1)$.\\[\\lim_{n\\to+\\infty}\\bar X_n = m\\]au sens de la convergence p.s. oÃ¹ $\\bar X_n := \\frac{X_1+â€¦+X_n}{n}$ThÃ©orÃ¨me 5 (T.C.L. cas unidimensionnel) Soit $(X_i)$ une suite v.a. i.i.d. Notons $m := E(X_i)$ et $\\sigma^2 = V(Xi)$ $\\frac{\\sqrt{n}(\\bar X_n - m)}{\\sigma}$ converge en loi vers une loi normale centrÃ©e rÃ©duite.Cas multidimentionnel Soit $(X_i)$ une suite de vecteurs aleatoires de $\\mathbb R^p$ i.i.d. Notons $m:=E(X_i)\\in\\mathbb R^p$ et $\\Sigma$ la matrice de variances-covariances $\\sqrt{n}\\biggr(\\frac{1}{n}\\sum_{i=1}^nX_i-m\\biggr)$ converge en loi vers une loi normale multidimensionnelle $\\mathcal N(0, \\Sigma)$Premieres notions de statistiqueEchantillon de taille $n$ Point de depart: v.a. $X$ dont lâ€™ensemble des valeurs est note $\\mathcal H$ Donnee $n$ variables aleatoires i.i.d. A parti de lâ€™echantillon, nous voudrons inferer la valeur dâ€™un parametre (fini-dimensionnel) en estimation parametrique ou prendre une decision en decision statistiqueModele statistique $\\theta\\in\\mathbb R^d$ $\\Theta\\subset\\mathbb R^d$ ensemble des parametres $\\mathcal P:={\\mathbb P_{\\theta}\\vert\\theta\\in\\Theta}$ famille de lois indexees par $\\Theta$ But: estimer la valeur $\\theta_0$ ou de $g(\\theta_0)$ Estimateur: fonction (mesurable) $\\hat\\theta:\\mathcal H^n\\to\\mathbb R^d$ Exemple pour le parametre $\\lambda$ dâ€™une loi $\\mathcal P(\\lambda)$ $\\Theta=]0;+\\infty[$ $\\mathcal H=\\mathbb N$RappelEstimateur propose $\\hat\\lambda:\\mathcal H^n\\to]0;+\\infty[$ $\\hat\\lambda(x_1, â€¦, x_i):=\\frac{1}{n}\\sum_{i=1}^nx_i$ $\\hat\\lambda$ moyenne empiriqueEstimateur sans biais $b(\\hat\\theta_n):=E(\\hat\\theta_n)-\\theta$ dans lâ€™exemple: $\\hat\\lambda_n$ est sans biaisPourquoi lâ€™estimateur est-il sans biais ?Pour tout $i\\in{1,â€¦,n}$, $X_i\\sim\\mathcal P(\\lambda)$.\\[\\begin{aligned}E(X_i) &amp;amp;= \\lambda\\\\E(\\hat \\lambda) &amp;amp;= E(\\frac{1}{n}\\sum_{i=1}^nY_i)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\lambda\\\\&amp;amp;= \\frac{1}{n}\\times n\\lambda = \\lambda\\end{aligned}\\]Estimateur convergent $\\hat\\theta_n$ convergent si $\\hat\\theta_n$ converge en probabilitÃ© vers $\\theta$ $\\hat\\theta_n$ fortement convergent si $\\hat\\theta_n$ converge presque sÃ»rement vers $\\theta$Estimateurs de lâ€™esperance et de la variance: cas general Pour lâ€™esperance: $\\bar X_n:=\\frac{1}{n}\\sum_{i=1}^nx_i$ a moyenne empirique Pour la variance: $S_nâ€™^2:=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar x_n)^2$ qui est aussi Ã©gale Ã  $\\frac{1}{n}\\sum_{i=1}^nx_i^2-\\bar x_n^2$ la variance empirique $\\bar X_n$ sans biais par contre $S_nâ€™^2$ biaisÃ© $S_nâ€™^2$ parfois remplacÃ© par $S_n^2=\\frac{n}{n-1}S_nâ€™^2$ qui est sans biais tous trois fortement convergents dâ€™aprÃ¨s la loi forte des grands nombres.Methode des moments Exploiter les moyennes et variances empiriques moyennes et variances sont remplaces par leurs contreparties empiriques fournit (en gÃ©nÃ©ral) des estimateurs convergents du fait de la convergence des moyennes et variances empiriques Exemple de la loi exponentielle: $E(X)=\\frac{1}{\\lambda}$ donc $\\lambda=\\frac{1}{E(X)}$ estimateur de $\\lambda$ donnÃ© par la mÃ©thode des moments: $\\hat\\lambda=\\frac{1}{\\bar X_n}$ $E(X^2)$ peut Ãªtre remplacÃ© par $\\frac{1}{n}\\sum_{i=1}^nx_i^2$ suivant le mÃªme principe les moments et moments centrÃ©s dâ€™ordre supÃ©rieur peuvent Ãªtre utilisÃ©s suivant le mÃªme principe DÃ©terminer un autre estimateur donnÃ© par la mÃ©thode des moments pour la loi de Poisson.Methode du maximum de vraisemblancePrincipe Rechercher la valeur de $\\theta$ en fonction des observations $x_1,â€¦,x_n$ assurant la plus grande probabilitÃ© dâ€™obtenir ces observations.Fonction de vraisemblance $\\mathcal H$ ensemble des valeurs que peut prendre la variable alÃ©atoire $X$ pour la loi normale $\\mathcal H=\\mathbb R$ pour la loi normale $\\mathcal H=\\mathbb N$ loi depend de $\\theta$ donc la densite associee aussi que nous noterons $f(x,\\theta)$ Fonction de vraisembalnce \\[L(x_1,...x_n,\\theta):=\\Pi_{i=1}^nf(x_i,\\theta)\\]Maximum de vraisemblance fonction $\\hat \\theta$ de $x_1,â€¦,x_n$ Qui maximise $L$ i.e. telle que $L(x,\\hat\\theta)\\ge L(x,\\theta)$ pour tout $\\theta\\in\\Theta$ oÃ¹ $\\Theta$ est lâ€™espace des paramÃ¨tresCas unidimensionnel Si $L$ est de classe $\\mathcal C^2$ (i.e. deux fois derivable par rapport $\\theta$ et de derivee seconde continue), $\\hat\\theta$ est solution du systeme \\(\\begin{cases} \\frac{\\delta L}{\\delta \\theta} &amp;amp;= 0\\\\ \\frac{\\delta^2 L}{\\delta \\theta^2} &amp;amp;\\lt 0\\\\\\end{cases} (1)\\) La condition 1 est nÃ©cessaire et la condition 2 est sufisante. La condition 1 sâ€™appelle lâ€™Ã©quation de vraisemblance Pour simplifier les calculs, on peut remplacer la vraisemblance par la log-vraisemblance car la fonction logarithme est de classe $\\mathcal C^2$ et strictement croissante sur $]0; +\\infty[$. Ainsi $\\hat\\theta$ est solution du systeme: \\(\\begin{cases} \\frac{\\delta \\log L}{\\delta \\theta} &amp;amp;= 0\\\\ \\frac{\\delta^2 \\log L}{\\delta \\theta^2} &amp;amp;\\lt 0\\\\\\end{cases} (2)\\) La condition 1 est nÃ©cessaire et la condition 2 est sufisante.Logarithme Particulierement utile car: $\\log(ab) = \\log(a) + \\log(b)$ $\\log(\\frac{a}{b}) = \\log(a) - \\log(b)$ $\\log(a^x) = x\\log(a)$Exemple de la loi exponentielle $L(x,\\lambda)=\\Pi_{k=1}^n\\lambda e^{-\\lambda x_k} = \\lambda^ne^{-\\lambda}\\sum_{k=1}^nx_k$ $\\log(L(x,\\lambda)) = n\\log(\\lambda) - \\lambda\\sum_{k=1}^nx_k$ $\\log(\\frac{\\theta L}{\\theta\\lambda}(x,\\lambda)) = \\frac{n}{\\lambda}-\\sum_{k=1}x_k$ Condition nÃ©cessaire : $\\hat\\lambda(x)$ solution de :\\[\\frac{n}{\\lambda}-\\sum_{k=1}x_k = 0\\\\\\hat\\lambda(x) = \\frac{n}{\\sum_{k=1}^nx_k}\\] Condition sufisante: $\\frac{\\delta^2\\log L}{\\delta\\lambda^2}=-\\frac{n}{\\lambda^2}\\lt0$ La condition sufisante est satisfaite donc $\\hat\\lambda(x)$ est bien le maximum de vraisemblance. Estimateur du maximum de vraisemblance $\\hat\\lambda_n = \\frac{n}{\\sum_{k=1}^n} = \\frac{1}{\\bar X_n}$ Il est fortement convergent dâ€™apres la loi fort des grands nombres" }, { "title": "DBRE: Titularite des droits d&#39;auteurs", "url": "/cours/posts/dbre_droits_auteur/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-10 12:00:00 +0100", "snippet": "Lien de la note HackmdPluralite dâ€™auteursCas de la pluralite dâ€™auteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelquâ€™un dâ€™autre, on peut remunerer lâ€™auteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de lâ€™auteur original est proportionnelle aux recettes.Si on utilise lâ€™image de quelquâ€™un dans un manuel de 1000 pages, il est plus rentable de sâ€™acquitter dâ€™un forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation dâ€™une oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de lâ€™oeuvre et qui vont se concerter entre elles. Ex: le developpement dâ€™un logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il nâ€™y a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent lâ€™oeuvre en ayant passe un contrat entre eux Chacun cede ses droits a lâ€™un dâ€™entre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a lâ€™initative dâ€™une personne (physique ou morale).Cette personne est invastie des droits dâ€™auteurs, et va sous son nom: Lâ€™editer La publier La divulguer Ce qui distingue lâ€™oeuvre collective et la collaboration, câ€™est les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise nâ€™arrive pas a prouver les conditions pratiques de la realisation dâ€™un projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue dâ€™un jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention dâ€™un tiers pour harmoniser les apports communs).Duree des droits dâ€™auteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits dâ€™auteurs) aussi lorsque lâ€™auteur meurt jeune Disney: utilisent des â€œrusesâ€ Peut egalement etre raccourcie Si chanson dâ€™un artiste-interprete, retombera plus vite dans le domaine publique Droits dâ€™une oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire quâ€™une oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui nâ€™utiliserai pas son droit moral ne lâ€™a pas perdu et peut le faire valoir a tout moment. Lâ€™auteur ne peut pas ceder de facon generale son droit dâ€™auteur car contraire a un principe dâ€™ordre publique. Attendu que lâ€™inaliÃ©nabilitÃ© du droit au respect de lâ€™oeuvre, principe dâ€™ordre public, sâ€™oppose Ã  ce que lâ€™auteur abandonne au cessionnaire, de faÃ§on prÃ©alable et gÃ©nÃ©rale, lâ€™apprÃ©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait Ã  ce dernier de procÃ©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas dâ€™adaptation, de changement de support ou de genre quâ€™il y a le plus de probleme avec le droit au respect." }, { "title": "ASE2: Convergence et estimation - 2", "url": "/cours/posts/ase2_convergence_et_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, convergence, normale, gamma, poisson, loi, Mac-Laurin, Moivre-Laplace, central limite", "date": "2021-03-10 09:30:00 +0100", "snippet": "Lien de la note HackmdIntroductionLe problÃ¨me central de lâ€™estimation en statistique est le suivant : disposant dâ€™observations sur un Ã©chantillon de taille $n$ on souhaite en dÃ©duire les propriÃ©tÃ©s de la population dont il est issu.On cherchera Ã  estimer, par exemple, la moyenne dâ€™une population Ã  partir de la moyenne dâ€™un Ã©chantillon. Le mode de tirage le plus important est lâ€™Ã©chantillonnage alÃ©atoire simple correspondant Ã  des tirages Ã©quiprobables et indÃ©pendants les uns des autres.Lâ€™une des premiÃ¨res qualitÃ©s dâ€™un estimateur est dâ€™Ãªtre convergent en probabilitÃ© vers le paramÃ¨tre Ã  estimer. Un Ã©chantillon de $X$ est une suite de variables alÃ©atoires $(X_1,X_2,â€¦,X_n)$ indÃ©pendantes et de mÃªme loi que $X$. Un estimateur dâ€™un paramÃ¨tre $\\theta$ inconnu est une fonction qui dÃ©pend de lâ€™Ã©chantillon et donc doit converger en probabilitÃ© vers le paramÃ¨tre $\\theta$. La prÃ©cision dâ€™un estimateur sera mesurÃ© par sa variance.Rappels de la loi Gamma et la loi Normale On dit quâ€™une variable alÃ©atoire positive $X$ suit une loi gamma de paramÃ¨tre $r$, notÃ©e $\\gamma_r$ si sa densitÃ© est donnÃ©e par :\\[f(x) = \\frac{1}{\\Gamma(r)}e^{-x}x^{r -1}\\] Avec $\\Gamma(x) = \\int_0^{+\\infty}e^{-t}t^{x-1}dt$ (fonction Gamma) definie pour $x\\gt0$PropriÃ©tÃ©s de la fonction Gamma $\\Gamma(x+1)=x\\Gamma(x)$ (intÃ©gration par partie) $\\Gamma(1) = 1$ $\\Gamma(n+1)=n!$ $\\Gamma(k+\\frac{1}{2})=\\frac{1.3.5â€¦..(2k-1)}{2^k}\\Gamma(\\frac{1}{2})$ $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$EspÃ©rance de la loi $\\gamma_r$ : Soit $X$ une variable alÃ©atoire suivant la loi gamma de paramÃ¨tre $r$.\\(E(X)=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}te^{-t}t^{r-1}dt=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^{r}e^{-t}dt=\\frac{\\Gamma(r+1)}{\\Gamma(r)}=r\\)Variance de la loi $\\gamma_r$ : $V(X) = E(X^2)-E^2(X)$\\[E(X^2)=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^2e^{-t}t^{r-1}=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^{r+1}e^{-t}dt = \\frac{\\Gamma(r+2)}{\\Gamma(r)} = r(r+1)\\]Donc $V(X) = r(r+1)-r^2 =r$.Loi Normale de paramÃ¨tres$(m,\\sigma)$ On dit quâ€™une variable alÃ©atoire $X$ suit la loi normale notÃ©e $\\mathcal N(m,\\sigma)$ si sa densitÃ© est\\[f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-m}{\\sigma})^2}\\] oÃ¹: $m = E(X)$ $\\sigma = \\sqrt{V(X)}$ (Ã©cart type) Avec le changement de variable $U=\\frac{X-m}{\\sigma}$ (variable normale centrÃ©e rÃ©duite), la densitÃ© de $U$ est:\\[f(u) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}u^2}\\]DemonstrationMontrons que $V(U) = 1$.On a:\\(V(U) = E(U^2) = \\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}}u^2e^{-\\frac{1}{2}u^2}du = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}u^2e^{-\\frac{1}{2}u^2}du\\)Posons $t=\\frac{u^2}{2}$, $dt = udu$\\(V(U) = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}2te^{-t}\\frac{dt}{\\sqrt{2t}} = \\frac{2}{\\sqrt{\\pi}}\\Gamma(\\frac{3}{2})=\\frac{2}{\\sqrt{\\pi}}\\frac{1}{2}\\Gamma(\\frac{1}{2})\\)Donc $V(U) = \\frac{1}{\\sqrt{\\pi}}\\sqrt{\\pi}=1$Moments de la loi normale centrÃ©e rÃ©duiteSoit $U$ une variable normale centrÃ©e rÃ©duite, on appelle moment dâ€™ordre $k$ de $U$ : $u_k=E(U^k)$ Si $k=2p+1$ alors $u_{2p+1} = 0$ (car fonction impaire) Si $k=2p$ alors $u_{2p} = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}u^{2p}e^{-\\frac{1}{2}u^2}du = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}u^{2p}e^{\\frac{1}{2}u^2}du$Posons $t=\\frac{u^2}{2}$, $dt=udu$\\[u_{2p} = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}(2t)^pe^{-t}\\frac{dt}{\\sqrt{2t}}=\\frac{2^p}{\\sqrt{\\pi}}\\int_0^{+\\infty}t^{p-\\frac{1}{2}}e^{-t}dt = \\frac{2^p}{\\sqrt{\\pi}}\\Gamma(p+\\frac{1}{2})\\\\\\text{Or } \\Gamma(p+\\frac{1}{2}) = \\frac{1.3.5...(2p-1)}{2^p}\\Gamma(\\frac{1}{2}) \\text{ et } \\Gamma(\\frac{1}{2})=\\sqrt{\\pi}\\\\\\text{Donc } u_{2p}=1.3.5....(2p-1)=\\frac{(2p)!}{2^pp!}\\]Fonctions caractÃ©ristiques Definition: la fonction caractÃ©ristique dâ€™une variable alÃ©atoire rÃ©elle $X$ est la transformÃ©e de Fourier de sa loi de probabilitÃ©. Elle est notÃ©e $\\phi_X(t)$ et on a:\\[\\phi_X(t)=E(e^{itX}) \\text{ (} i \\text{ complexe)}\\]Si $X$ est une variable Ã  densitÃ© ($X$ est une v.a continue de densitÃ© $f$) alors :\\[\\phi_X(t) = \\int_{\\mathbb R}e^{itx}f(x)dx\\]Si $X$ est une variable discrÃ¨te alors sa fonction caractÃ©ristique est :\\[\\phi_X(t)=\\sum_ke^{itk}P(X=k)\\]PropriÃ©tÃ©s $\\phi_{\\lambda x} = \\phi_X(\\lambda t)$, $\\forall\\lambda$ un scalaire $\\phi_{X+a}(t)=e^{ita}\\phi_X(t)$, $\\forall a$ un scalaire Si $X$ est une variable alÃ©atoire dâ€™espÃ©rance $m$ et dâ€™Ã©cart type $\\sigma$ et $U = \\frac{X-m}{\\sigma}$\\[\\phi_{\\frac{X-m}{\\sigma}} = \\phi_U(t) = e^{-\\frac{itm}{\\sigma}}\\phi_X(\\frac{t}{\\sigma})\\]RemarqueLa fonction caractÃ©ristique se prÃªte bien aux additions de variables alÃ©atoires indÃ©pendantes.Si $X$ et $Y$ sont deux variables alÃ©atoires indÃ©pendantes alors \\(\\phi_{X+Y}(t) = \\phi_X(t)\\phi_Y(t)\\\\\\text{En effet } \\phi_{X+Y}(t) = E(e^{it(X+Y)})=E(e^{itX}e^{itY})\\\\\\text{Or } X \\text{ et } Y \\text{ sont indÃ©pendantes } E(e^{itX}e^{itY}) = E(e^{itX})E(e^{itY})\\\\\\text{Donc } \\phi_{X+Y}(t)=\\phi_X(t)+\\phi_Y(t)\\)PropositionSoit $X$ une variable alÃ©atoire de fonction de rÃ©partition $\\phi_X(t)$.On a $\\phi_x(0)=1$ et $\\frac{d^k\\phi_X}{dt^k}(0)=\\phi_X^{(k)}(0)=i^kE(X^k)$DÃ©moSupposons que $X$ est une variable continue de densitÃ© $f$On a:\\[\\phi_X(t)=\\int_{\\mathbb R}e^{itx}f(x)dx\\Rightarrow\\phi_X(0)=\\int_{\\mathbb R}f(x)dx=1 \\text{ (car f est une densitÃ©)}\\\\\\text{En dÃ©rivant } \\phi_X(t) \\text{ par rapport Ã  t: } \\phi_X&#39;(t)=i\\int_{\\mathbb R}xe^{itx}f(x)dx\\\\\\text{Si } t=0: \\phi_X&#39;(t)i\\int_{\\mathbb R}xf(x)dx=iE(x)\\\\\\text{Si on dÃ©rive 2 fois, } \\phi_X^{(2)}(t)=\\int_{\\mathbb R}(itx)^2e^{itx}f(x)dx\\\\\\text{En dÃ©rivant k fois par rapport Ã  t: }\\phi_X(t)^{k}(t)=\\int_{\\mathbb R}(ix)^ke^{itx}f(x)dx\\\\\\text{Donc } \\phi_x^{(k)}(0)=(i^k)\\int_{\\mathbb R}x^kf(x)dx=i^kE(X^k),\\forall k\\in\\mathbb N\\]Formule de Mac-LaurinSi $\\phi_X(t)$ est indÃ©finiment dÃ©rivable on a:\\[\\phi_X(t)=\\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}\\phi_X^{(k)}(0)=\\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}i^kE(X^k)\\]Exemple 1Soit X une variable alÃ©atoire continue de densitÃ©:\\[f(x)=\\begin{cases} e^{-x} &amp;amp;\\text{si } x\\gt0\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\]DÃ©terminer la fonction caractÃ©ristique de $X$ Solution\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\int_{\\mathbb R}e^{itx}f(x)dx=\\int_{-\\infty}^{+\\infty}e^{itx}e^{-x}dx=\\int_{0}^{+\\infty}e^{-(1-it)x}dx\\\\&amp;amp;= \\int_{0}^{+\\infty}e^{-(1-it)x}dx=\\biggr[\\frac{-e^{-(1-it)x}}{1-it}\\biggr]_0^{+\\infty}=\\frac{1}{1-it}\\end{aligned}\\] Car $-e^{-(1-it)x}=e^{-x}e^{itx}\\to0$ lorsque $x\\to+\\infty$. Puisque $e^{itx}$ est bornÃ©e de module 1 et $e^{-x}\\to0$ quand $x\\to+\\infty$Exemple 2DÃ©terminer la fonction caractÃ©ristique de la loi de Bernoulli de paramÃ¨tre $p$ Solution Soit $X$ une variable de Bernoulli\\[\\begin{cases}X=1 &amp;amp;\\text{avec la probabilitÃ© }p\\\\X=0 &amp;amp;\\text{avec la probabilitÃ© }1-p\\end{cases}\\] X Ã©tant discrÃ¨te, donc sa fonction caractÃ©ristique est:\\[\\begin{aligned}\\phi_X(t)&amp;amp;=\\sum_ke^{itk}P(X=k)=\\sum_{k=0}^1e^{itk}P(X=k)=P(X=0)+e^{it}P(X=1)\\\\&amp;amp;= 1-p+pe^{it}=q+pe^{it} \\text{ avec } q=1-p\\end{aligned}\\]Convergences des suites de variables alÃ©atoiresUne suite $(X_n)$ de variables alÃ©atoires Ã©tant une suite de fonctions il existe diverses faÃ§ons de dÃ©finir la convergence de $(X_n)$ dont certaines jouent un grand rÃ´le en statistiques.Convergence en probabilitÃ© DefinitionLa suite $(X_n)$ converge en probabilitÃ© vers une variable alÃ©atoire $X$ si $\\forall\\varepsilon\\gt0, \\eta\\gt0$ (arbitrairement petits) il existe un entier $n_0$ tel que $\\forall n\\gt n_0\\Rightarrow P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$, câ€™est-Ã -dire $P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$. On notera $(X_n)\\to^PX$.InÃ©galitÃ© de BienaymÃ©-Tchebychev\\[P(\\vert X_n-E(X)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2},\\forall\\varepsilon\\gt0\\]RemarqueLorsque $E(X_n)\\to_{n\\to+\\infty}a$, il suffit de montrer que $V(X_n)\\to_{n\\to+\\infty}0$ pour Ã©tablir la convergence en probabilitÃ© de la suite $(X_n)$ vers $a$.En effet dâ€™aprÃ¨s Tchebychev: $P(\\vert X_n-E(X_n)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2}\\to0$Donc en passant Ã  la limite $\\lim_{n\\to+\\infty}P(\\vert X_n-a\\vert\\gt\\varepsilon)=0,\\forall\\varepsilon\\gt0$Convergence en moyenne quadratiqueOn suppose que $E(\\vert X_n-X\\vert^2)$ existe DefinitionOn dit quâ€™une suite de variables alÃ©atoires $(X_n)$ converge en moyenne quadratique vers une variable $X$ si $E(\\vert X_n-X\\vert^2)\\to_{n\\to+\\infty}0$ On notera $(X_n)\\to^{m.q}X$Convergence en loi DefinitionLa suite $(X_n)$ converge en loi vers la variable $X$ de fonction de rÃ©partition $F$ si en tout point de continuitÃ© de $F$ la suite $(X_n)$ des fonctions de rÃ©partition des $(X_n)$ converge vers $F$. Câ€™est-Ã -dire $\\lim_{n\\to+\\infty}F_n(x)=F(x)$ pour tout $x$ point de continuitÃ© de $F$. On notera $(X_n)\\to^LX$RemarquePour les variables discrÃ¨tes, la convergence en loi est Ã©quivalente Ã \\[\\lim_{n\\to+\\infty}P(X_n=k)=P(X=k)\\]ThÃ©orÃ¨me Si la suite des fonctions caractÃ©ristiques $\\phi_{X_n}(t)$ converge vers $\\phi_X(t)$ alors $(X_n)\\to^LX$Applications: Convergence en loi de la binomiale vers la loi NormaleThÃ©orÃ¨me (Moivre-Laplace) Soit $(X_n)$ une suite de variables binomiales $\\mathcal B(n,p)$ alors\\[\\frac{X_n-np}{\\sqrt{npq}}\\to^L\\mathcal N(0,1) \\text{ lorsque } n\\to+\\infty\\]DÃ©monstrationLa fonction caractÃ©ristique de la loi $\\mathcal B(n,p)$ est:\\[\\phi_{X_n}(t)=(pe^{it}+1-p)^n \\text{ donc celle de } Y_n=\\frac{X_n-np}{\\sqrt{npq}} \\text{ est:}\\\\\\phi_{Y_n}(t) = (pe^{\\frac{it}{\\sqrt{npq}}}+1-p)^ne^{\\frac{-itnp}{\\sqrt{npq}}}\\\\\\ln(\\phi_{Y_n}(t))=nLn(p(e^{\\frac{it}{\\sqrt{npq}}}-1)+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle le dÃ©veloppement limitÃ© de lâ€™exponentielle Ã  lâ€™ordre 2\\[e^x\\simeq1+x+\\frac{x^2}{2} \\text{(au voisinage de 0)}\\\\\\ln(\\phi_{Y_n}(t))\\simeq n\\ln(p(\\frac{it}{\\sqrt{npq}}-\\frac{t^2}{2npq})+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle $\\ln(1+x)\\simeq x-\\frac{x^2}{2}$ (au voisinage de 0)Donc:\\(\\begin{aligned}\\ln(\\phi_{Y_n}(t))&amp;amp;\\simeq n\\biggr[\\frac{pit}{\\sqrt{npq}}-\\frac{pt^2}{2npq}+\\frac{p^2t^2}{2npq}\\biggr]-\\frac{itnp}{\\sqrt{npq}}\\\\&amp;amp;\\simeq-\\frac{t^2}{2q}+\\frac{pt^2}{2q}=\\frac{t^2}{2q}(p-1)=-\\frac{t^2}{2}\\end{aligned}\\)En composant par lâ€™exponentielle:\\[\\phi_{Y_n}(t)\\simeq e^{-\\frac{t^2}{2}}\\] fonction caractÃ©ristique de la loi normale $\\mathcal N(0,1)$Conclusion $\\frac{X_n-np}{\\sqrt{npq}}\\to^L\\mathcal N(0,1)$Remarquelorsque n est assez grand on peut donc approximer la loi Binomiale par la loi normale. On donne gÃ©nÃ©ralement comme condition $np$ et $nq\\gt5$.Il convient cependant dâ€™effectuer la correction de continuitÃ© : on obtient donc une valeur approchÃ©e de $P(X=x)$ par la surface sous la courbe de densitÃ© de la loi normale $\\mathcal N(np,\\sqrt{npq})$ comprise entre les droites dâ€™abscisse $x-\\frac{1}{2}$ et $x+\\frac{1}{2}$\\[P(X=x)\\simeq P(x-\\frac{1}{2}\\lt X\\lt x+\\frac{1}{2})=P\\biggr(\\frac{x-\\frac{1}{2}-np}{\\sqrt{npq}}\\lt \\frac{X-np}{\\sqrt{npq}}\\lt \\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}}\\biggr)\\\\\\text{Et } P(X\\lt x)\\simeq P\\biggr(\\frac{X-np}{\\sqrt{npq}}\\lt \\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}}\\biggr)\\]ExempleSoit X une variable binomiale $\\mathcal B(n=40; p=0,3)$.La valeur exacte pour $P(X=11)$ est $0,1319$.La formule dâ€™approximation : \\(P(X=11)\\simeq P\\biggr(\\frac{11-\\frac{1}{2}-12}{\\sqrt{8,4}}\\lt \\frac{X-12}{\\sqrt{8,4}}\\lt \\frac{11+\\frac{1}{2}-12}{\\sqrt{8,4}}\\biggr)=P(-0,52\\lt U\\le-0,17)=0,131\\)Avec $np=12$ et $npq=8,4$Donc lâ€™erreur est de moins de $1\\%$Convergence en loi de la loi de Poisson vers la loi normale TheoremeSoit $(X_{\\lambda})$ une suite de variables de Poisson de paramÃ¨tre $\\lambda$. Si $\\lambda\\to+\\infty$, $\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}}\\to^L\\mathcal N(0,1)$DÃ©monstrationon rappelle la fonction caractÃ©ristique de la loi de Poisson:\\[\\phi_{X_i}(t)=e^{\\lambda e^{it}-\\lambda}\\]On rappelle aussi la formule $\\phi_{\\frac{X-m}{\\sigma}}=e^{-\\frac{it\\lambda}{\\sqrt{\\lambda}}+\\lambda+\\frac{\\lambda it}{\\sqrt{\\lambda}}-\\frac{t^2}{2}-\\lambda}=e^{-\\frac{t^2}{2}}$ On retrouve la fonction caractÃ©ristique de la loi normale centrÃ©e et rÃ©duite.Conclusion $\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}}\\to^L\\mathcal N(0,1)$ThÃ©orÃ¨me (Central-limite) Soit $(X_n)$ une suite de variables alÃ©atoires, indÃ©pendantes et de mÃªme loi dâ€™espÃ©rance $m$ et dâ€™Ã©cart-type $\\sigma$ alors :\\[\\frac{X_1+X_2+....+X_n-nm}{\\sigma\\sqrt n}\\to\\mathcal N(0,1)\\]DÃ©monstration\\[\\frac{X_1+X_2+....+X_n-nm}{\\sigma\\sqrt n}\\to\\mathcal N(0,1) = \\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt n}\\]Posons $Y_n=\\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt n}$\\[E(\\frac{X_i-m}{\\sigma\\sqrt n})=\\frac{E(X_i)-m}{\\sigma\\sqrt {n}}=0 \\\\\\text{et}\\\\V(\\frac{X_i-m}{\\sigma\\sqrt n})=\\frac{1}{\\sigma^2 n}V(X_i)=\\frac{\\sigma^2}{n\\sigma^2}=\\frac{1}{n}\\]La fonction caractÃ©ristique de $Y_n=\\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt{n}}$ est:\\[\\phi_{Y_n}(t) = \\Pi_{i=1}^n\\phi_{\\frac{X_i-m}{\\sigma\\sqrt{n}}}(t)=\\phi_{\\frac{X_i-m}{\\sigma\\sqrt{n}}}(t)^n=(1-\\frac{t^2}{2n}+o(\\frac{1}{n^2}))^n\\]On rappelle que $(1+\\frac{x}{n})^n\\to e^{x}$Car $(1+\\frac{x}{n})^n=e^{n\\ln(1+\\frac{x}{n})}\\simeq e^{n\\frac{x}{n}}=e^x$Donc $\\phi_{Y_n}(t)=(1-\\frac{t^2}{2n}+o(\\frac{1}{n^2}))^n\\to e^{-\\frac{t^2}{2}}$ lorsque $n\\to+\\infty$Estimateurs DÃ©finitionSoit $(X_1,X_2,â€¦,X_n)$ un Ã©chantillon de $X$, câ€™est-Ã -dire une suite de variables alÃ©atoires indÃ©pendantes et de mÃªme loi que $X$. La statistique $\\bar X$ ou moyenne empirique de lâ€™Ã©chantillon est:\\[\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\]\\[E(\\bar X)=\\frac{1}{n}\\sum_{i=1}^n E(X_i)=\\frac{nm}{n}=m \\text{ oÃ¹ } m=E(X)\\\\V(\\bar X)=\\frac{1}{n^2}\\sum_{i=1}^n V(X_i)=\\frac{n\\sigma^2}{n^2}=\\frac{\\sigma^2}{n}\\to 0 \\text{ lorsque } n\\to+\\infty\\]Donc dâ€™aprÃ¨s Tchebychev $\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\to^Pm=E(X)$ quand $n\\to+\\infty$ Câ€™est la loi des grands nombres." }, { "title": "ASE2: Rappels sur les lois", "url": "/cours/posts/ase2_rappels/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, normale, poisson, exponentielle, geometrique", "date": "2021-03-10 09:00:00 +0100", "snippet": "Lien de la note HackmdLoi normale centree reduite $E(X) = 0$ $V(X) = 1$ $f(X) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{t^2}{2}}$ $F(X) = \\frac{1}{\\sqrt{2\\pi}}\\int_0^Xe^{-\\frac{t^2}{2}}$Loi Poisson $P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$ (avec $\\lambda = \\frac{1}{n}$)\\[P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!} \\text{ (avec } \\lambda = \\frac{1}{n}\\text{)}\\\\P(X_n = k)= e^{-\\frac{1}{n}}\\frac{1}{n^kk!}, \\forall k\\in\\mathbb N\\] Si $k=0$, $P(X_n = 0) = e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ Si $k\\ge1$, $P(X_n=k)=\\frac{1}{n^kk!}e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ car $\\frac{1}{n^k}\\to_{n\\to+\\infty}0$Loi exponentielle $E(X) = \\frac{1}{\\lambda}$ $V(X) = \\frac{1}{\\lambda^2}$ DensitÃ© de probabilitÃ©:\\[\\begin{cases} f(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\ f(t)=\\frac{1}{E(X)}e^{-\\frac{t}{E(X)}} &amp;amp;\\forall t\\ge0\\end{cases}\\\\\\Leftrightarrow \\begin{cases} f(t)=\\lambda e^{-\\lambda t} &amp;amp;\\text{si } t\\ge0\\\\ f(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\\\end{cases}\\] Fonction de rÃ©partition:\\[\\begin{cases} F(t)=1 - e^{-\\lambda t} &amp;amp;\\text{si } t\\ge0\\\\ F(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\\\end{cases}\\]Loi geometrique $E(X)=\\frac{1}{p}$ $V(X) = \\frac{1-p}{p^2}$$(X_n), n\\gt0$ une suite de v.a. geometrique $G(\\frac{1}{n})$ avec $p=\\frac{1}{n}$ parametre.\\[\\begin{aligned}P(X_n = k) &amp;amp;= (1-p)^{k-1}p, \\forall k\\ge1\\\\&amp;amp;= (1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\end{aligned}\\]" }, { "title": "ASE2: TD 1, suite (encore)", "url": "/cours/posts/ase2_exercices_convergence_estimation_suite/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, convergence, normale, loi", "date": "2021-03-10 09:00:00 +0100", "snippet": "Lien de la note HackmdExercice 5Soit $X$ une v.a. normale centree et reduite $X\\to\\mathcal N(0,1)$.Montrer que $\\forall x\\in\\mathbb R^*_+$\\[\\int_0^x e^{-\\frac{t^2}{2}}dt\\ge\\sqrt{\\frac{\\pi}{2}}(1-\\frac{1}{x^2})\\] Utiliser Tchebychev. Solution Soit $X\\to\\mathcal N(0,1)$ (Loi normale centree reduite). Dâ€™apres lâ€™inegalite de Techbychev:\\[\\begin{aligned}\\forall\\varepsilon\\gt0, &amp;amp;P(\\vert X-E(X)\\vert\\ge\\varepsilon)\\le\\frac{V(X)}{\\varepsilon^2}\\\\\\text{or: } &amp;amp;E(X) = 0 \\text{ et } V(X) = 1\\\\&amp;amp;P(\\vert X\\vert\\ge\\varepsilon)\\le\\frac{1}{\\varepsilon^2}\\\\\\text{et} &amp;amp;P(\\vert X\\vert\\ge\\varepsilon)=1-P(\\vert X\\vert\\le\\varepsilon)\\\\\\text{Ca permet d&#39;ecrire: } &amp;amp;P(\\vert X\\vert\\lt\\varepsilon)\\ge 1-\\frac{1}{\\varepsilon^2}\\\\\\text{c.a.d.} &amp;amp;P(-\\varepsilon\\lt X\\lt\\varepsilon)\\ge1-\\frac{1}{\\varepsilon^2}\\\\&amp;amp;F(\\varepsilon) - F(-\\varepsilon)\\ge 1-\\frac{1}{\\varepsilon^2} \\text{ F: fonction de densite de }\\mathcal N(0,1)\\\\&amp;amp;F(\\varepsilon) - (1-F(\\varepsilon))\\ge 1-\\frac{1}{\\varepsilon^2}, \\forall\\varepsilon\\gt0\\\\\\Rightarrow &amp;amp;2F(\\varepsilon) -1 \\ge 1-\\frac{1}{\\varepsilon^2}(*)\\end{aligned}\\] On a aussi $\\frac{1}{\\sqrt{2\\pi}}\\int_0^xe^{-\\frac{t^2}{2}} = F(x) - F(0) = F(x) - \\frac{1}{2}, \\forall x\\gt0$\\[\\begin{aligned}\\Rightarrow \\int_0^xe^{-\\frac{t^2}{2}} &amp;amp;= \\sqrt{2\\pi}(F(x) - \\frac{1}{2})\\\\&amp;amp;=\\frac{\\sqrt{2\\pi}}{2}(2F(x) - 1), \\forall x\\gt0\\end{aligned}\\] Grace a lâ€™inegalite $(*)$ et en remplacant $\\varepsilon$ par $x$, on obtient $\\forall x\\gt0$:\\[\\int_0^xe^{-\\frac{t^2}{2}}=\\frac{\\sqrt{2\\pi}}{2}(2F(x) - 1)\\ge\\frac{\\sqrt{2\\pi}}{2}(1-\\frac{1}{x^2})\\] On a bien: \\(\\forall x\\gt0, \\int_0^Xe^{-\\frac{t^2}{2}}\\ge\\sqrt{\\frac{\\pi}{2}}(1-\\frac{1}{x^2})\\) Exercice 6On considere une suite suite de v.a.a $(X_n), n\\in\\mathbb N^*$ dsitribue suivant la loi de Poisson $\\mathcal P(\\frac{1}{n}), (\\lambda = \\frac{1}{n})$. Montrer que $X_n$ converge en loi vers la variable aleatoire $X=0$ $(X_n\\to_{n\\to+\\infty}^L0)$ Solution $(X_n), n\\in\\mathbb N^*$ suit la loi de Poisson $\\mathcal P(\\frac{1}{n})$. Rappel:\\[P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!} \\text{ (avec } \\lambda = \\frac{1}{n}\\text{)}\\] \\[P(X_n = k)= e^{-\\frac{1}{n}}\\frac{1}{n^kk!}, \\forall k\\in\\mathbb N\\] Si $k=0$, $P(X_n = 0) = e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}1$ Si $k\\ge1$, $P(X_n=k)=\\frac{1}{n^kk!}e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ car $\\frac{1}{n^k}\\to_{n\\to+\\infty}0$ Conclusion: on a montre que\\[\\begin{cases}&amp;amp;\\lim_{n\\to+\\infty}P(X_n=0)=1=P(X=0) \\Leftrightarrow X_n\\to_{n\\to+\\infty}^L0 \\text{ variable certaine}\\\\&amp;amp;\\lim_{n\\to+\\infty}P(X_n=k) = 0 = P(X=k), \\forall k\\ge1\\end{cases}\\]Exercice 7Soir $X$ une v.a. suivant la loi exponentielle de parametre $(\\lambda\\gt0)$. Montrer que $\\forall\\varepsilon\\gt0$, $P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\le\\frac{1}{\\lambda^2\\varepsilon^2}$ En deduire que $P(X\\gt\\frac{3}{\\lambda})\\le\\frac{1}{4}$ Solution $X$ suit la loi exponentielle$(\\lambda)$ de parametre $\\lambda$. 1.On rappelle que $E(X)=\\frac{1}{\\lambda}$ et $V(X)=\\frac{1}{\\lambda^2}$. En appliquant lâ€™inegalite de Tchebychev:\\[\\begin{aligned}&amp;amp;P(\\vert X-E(X)\\vert\\ge\\varepsilon)\\le\\frac{V(X)}{\\varepsilon^2}, \\forall\\varepsilon\\gt0\\\\\\Rightarrow &amp;amp;P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\le\\frac{\\lambda}{\\lambda^2\\varepsilon^2}, \\forall\\varepsilon\\gt0\\end{aligned}\\] 2.Lâ€™evenement:\\[(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon) = (X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\cup(X-\\frac{1}{\\lambda}\\le-\\varepsilon)\\\\\\text{or: } A\\in A\\cup B\\\\\\text{donc: } (X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\in(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon \\vert)\\] On en deduit, par croissance de la probabilite:\\[\\begin{aligned}&amp;amp;P(X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\le P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\\\\\Rightarrow &amp;amp;P(X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\le\\frac{1}{\\lambda^2\\varepsilon^2} \\text{ (d&#39;apres la question 1)}\\end{aligned}\\] En choisissant $\\varepsilon=\\frac{2}{\\lambda}\\gt0$, on obtient $P(X\\ge\\frac{3}{\\lambda})\\le\\frac{1}{4}$ Exercice 8$(X_n)$ une suite de v.a. telle que $\\forall n\\in\\mathbb N^*$: $X_n$ suit la loi geometrique $G(\\frac{1}{n})$ (de parametre $\\frac{1}{n}$).On pose $Y_n=\\frac{X_n}{n}$. Determiner la fonction de repartition de la suite $Y_n:P(Y_n\\le x), \\forall x\\in\\mathbb R$ Montrer que $Y_n\\to_{n\\to+\\infty}^LY$ avec $Y$ suit la loi exponentielle $(\\lambda = 1)$ Solution $(X_n), n\\gt0$ une suite de v.a. geometrique $G(\\frac{1}{n})$ avec $p=\\frac{1}{n}$ parametre. Rappel:\\[\\begin{aligned}P(X_n = k) &amp;amp;= (1-p)^{k-1}p, \\forall k\\ge1\\\\&amp;amp;= (1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\end{aligned}\\] 1.On veut determiner la fonction de repartition de $Y_n$.\\[\\forall x\\le0, P(Y_n\\le x) = P(X_n\\le nx) = 0 \\text{ car } nx\\le0\\] Remarque: donc $\\forall x\\le 0$, $\\lim_{n\\to+\\infty}P(Y_n\\le x) = 0$. $\\forall x\\gt 0$ (reel strictement positif). Des que $n$ est assez grand, $nx\\ge 1$.\\[\\begin{aligned}P(Y_n\\le x) &amp;amp;= P(X_n\\le nx) = \\sum_{k=1}^{[nx]}P(X_n=k) \\text{ }([nx] \\text{participation entiere de } nx)\\\\\\forall x\\gt0, P(Y_n\\le x) &amp;amp;= \\sum_{k=1}^{[nx]}(1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\\\&amp;amp;= \\frac{1}{n}\\sum_{k=1}^{[nx]}(1-\\frac{1}{n}^){k-1} = \\frac{1}{n}\\biggr(\\frac{1-(1-\\frac{1}{n})^{[nx]}}{1-(1-\\frac{1}{n})}\\biggr)\\\\&amp;amp;= P(Y_n\\le x) = 1 - (1-\\frac{1}{n})^{[nx]}\\end{aligned}\\] Donc:\\[F_n(X) = P(Y_n\\le x) =\\begin{cases} 0 &amp;amp;x\\le0\\\\ 1-(1-\\frac{1}{n})^{[nx]} &amp;amp;x\\gt0\\end{cases}\\] On a:\\[(1-\\frac{1}{n})^{[nx]} = \\exp([nx]ln(1-\\frac{1}{n}))\\\\\\ln(1-\\frac{1}{n})\\sim-\\frac{1}{n} \\text{ (} n \\text{ au voisinage de } +\\infty \\text{)}\\\\\\text{(}\\ln(1+x)\\sim x\\text{ au (voisinage de 0))}\\] Par definition de la partie entiere:\\[\\begin{aligned}&amp;amp;[nx]\\le nx\\lt[nx] + 1\\\\&amp;amp;nx-1\\lt[nx]\\le nx\\\\&amp;amp;\\Rightarrow 1-\\frac{1}{nx}\\lt\\frac{[nx]{nx}}\\le1\\\\&amp;amp;\\Rightarrow\\lim_{n\\to+\\infty}\\frac{[nx]}{nx}\\le1\\\\&amp;amp;\\Rightarrow [nx]\\sim nx \\text{ (} n \\text{ au voisinage de } +\\infty\\text{)}\\end{aligned}\\] Donc $[nx]\\ln(1-\\frac{1}{n})\\sim nx(-\\frac{1}{n})=-x$.\\[\\exp([nx]\\ln(1-\\frac{1}{n}))\\sim e^{-x} \\text{ (} n \\text{ au voisinage de } +\\infty\\text{)}\\\\\\forall x\\gt0, \\lim_{n\\to+\\infty} F_n(x) = \\lim_{n\\to+\\infty}P(Y_n\\le x)=1-e^{-x}\\] Conclusion:\\[\\forall x\\le 0, \\lim_{n\\to+\\infty}F_n(x)=\\lim_{n\\to+\\infty}P(Y_n\\le x)=0\\\\\\text{et}\\\\\\forall x\\gt0, \\lim_{n\\to+\\infty}F_n(x)=\\lim_{n\\to+\\infty}P(Y_n\\le x)=1-e^{-x}\\\\\\text{or } F(x)\\begin{cases} 0 &amp;amp;x\\le 0 \\\\ 1-e^{-x} &amp;amp;x\\gt 0\\end{cases}\\] $F(x)$ est la fonction de repartition de la loi exponentielle$(\\lambda=1)$ " }, { "title": "ISIM: Les textures", "url": "/cours/posts/isim_textures/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, texture, couleur, mapping, volume, transparent", "date": "2021-03-08 11:00:00 +0100", "snippet": "Lien de la note HackmdLes textures Objectifs Ajouter du realisme Simplifier la modelisation des secenes Simuler lâ€™eclairage Applications Algorithmes temps reels Algorithmes photorealistes Types: Textures procedurales Textures plaquees Effet de volume Eclairage Les couleurs Associer une couleur par face Effet de volume donee par lâ€™illumination Gouraud Phong Associer une couleur par sommet interpolation Indiquer les proprietes des materiaux diffusion specularite Les textures plaquees â€œMapperâ€ un bitmap sur un polygone Realise Consommation memoire elevee Comment plaquer une texture? Sur un plan $\\to$ facile Sur une surface quelconque &amp;gt; Trouver une fonction Plaquer la texture suivant un projection simple Plan Sphere Cylindre Cube â€¦ Conformal map Projection: planar cylindrical spherical triplanar On cree un plan quâ€™on projette sur le theiere On cree un cyclindre quâ€™on projette sur le theiere On cree une sphere quâ€™on projette sur le theiereProjections: triplanar On le projette en fonction de la normale du point quâ€™on considere Permet de dissocier les textures en fonction de lâ€™orientation Pour un personnage (ou objet complexe), on ne trouvera pas de fonction intermediaire.Association texture $\\leftrightarrow$ model On decoupe soi-meme sont modele Voir quel est le mapping entre le modele decoupe et aplatit et le bitmap quâ€™on veut mapperPossible dâ€™avoir un decoupage plus â€œintelligentâ€. Conformal mapOrigine du Bitmap Image (photo)Est-ce quâ€™on peut faire des photos ou des dessins ?On peut peindre â€œcomme un artisteâ€ les surfaces 3D Resultat dâ€™un rendu (render to texture) Surfaces reflechissantes Ca va ? Pas trop le mal de mer maintenant ?Dans ce cas on map 6 textures sur la sphere Change quand on bouge la camera Pour le rendu final on a 6 rendus intermediairesâ€œMapperâ€ un bitmap sur un polygone Interpolation dependante du $z$ Repetition de la texture si non compris entre 0 et 1Textures repetitivesQuâ€™est-ce qui se passe quand on veut faire un mur de brique ? Motif repetitif On prend un motif quâ€™on duplique Avantages Inconvenients Economise de lâ€™espace Le motif peut devenir visible Pour reduire les inconvenients: Prendre des patches plus petits Prendre des motifs differents Ce nâ€™est quâ€™une facon de repousser le problemeMipmap Si on a notre mur quâ€™on voit de loin, plein dâ€™artefacts apparaissent Le but du MIP est dâ€™eviter la pixelisation lorsquâ€™on sâ€™eloigne dâ€™une texture Le niveau de detail des textures est adapte a la distance de lâ€™objet Souvant supporte nativement par les moteurs graphiques Lissage Mip mapping: niveau de detail (LOD) Point sampling: texel le plus proche Bilineaire: interpolation sur 4 texels Trilineaire: interpolation inter-LOD Anisotropique: prise en compte des effets dâ€™angle (32 texels) Textures procedurales Texture generee Avantages: Economie de memoire Pas de repetition dans le motif Possibilite dâ€™avoir une texture 3D â€¦ Effets classique: Damier, Rayures, â€¦ Je vous ai fait une espece de bronze ou je ne-sais-quoi Generation de bruit pour simuler lâ€™aspect de certains elements Bruit structure Bruit de Perlin Afin de donner une impression dâ€™organisation, seul un sous enesemble de points est genere aleatoirement. Le reste des points es calcule par interpolation.Ajout dâ€™autres frequences: $bruit(i,x)=p^{(i-1)}.bruit(2^{(i-1)},x)$ Parametres: pas, persistance et nombre dâ€™octaves Resultat: Somme de lâ€™ensemble des $bruit(i,x)$ 1 octave $p=0.5$ On interpole (interpolation lineaire) On prend un autre echantillonage et on interpole avec cette autre matrice $\\Leftrightarrow$ 2 tirages aleatoires donc 2$^{eme}$ octave 2 octaves $p=0.5$ 5 octaves $p=0.5$ 5 octaves $p=0.8$ 5 octaves $p=0.2$Applications: fumee Interpolation du balanc $\\to$ noir cieluages En dessous dâ€™un certain seuil: Interpolation du gris bleu $\\to$ bleu Au dessus dâ€™un certain seuil: bleu bois En dessous dâ€™un certain seuil, marron fonce En dessous dâ€™un certain seuil, marron clair Entre les deux, interpolation psychoâ€¦ A force de jouer avec les couleurs jâ€™ai un peu craque marbre $n = 1-\\sqrt{\\vert\\sin(2\\pi v)\\vert}$ Interpolation linaire du gris vers le noir en fonction de $n$ Generation possible en 3DUsage des texturesBillboard Element toujours face a lâ€™observateur sur lequel est plaque une texture Permet de simuler un objet/phenomene complique simplement a lâ€™aide dâ€™une texture: Arbre Feu â€¦ Environnement On peut sâ€™enfermer dans un objet pour avoir notre environnement Equirectangular Une seule texture pour lâ€™ensemble de lâ€™environnement Cubemap Skybox On enferme notre personnage dans un cube Meme resolution pour tous les points Mettre 6 cameras qui prennent $90^o$ dans une direction In-theiere stellarTexture particuliereObjets transparents Rendu type raytracing Loi de Snell-Descartes Rendu par projection openGL Pas de deviation de rayon Rend tous les objets qui ne sont pas transparents On verrouille le z-buffer en ecriture avant de dessiner tous les objets transparents Objets transparents: melanger la couleur de ce qui a deja ete dessine avec lâ€™objet transparent TexturesEffet de volume Perturbation des normales Bump mapping (Blinn) Permet de faire apparaitre des variation sur la surface Realise avec blender(Câ€™est une mure en haut a droite)Comment voir que câ€™est bien juste la perturbation de normale ? Si on trace les contour, on voit bien quâ€™ils sont lissent et quâ€™ils ne vont pas dans les creux de la mure.Pour aller plus loin: Parallax mapping Relief mappingAmeliorations La texture permet dâ€™ajouter du realisme et evite de modeliser les details dâ€™une surface. Toutefois le resultat est un peu plat. Initialement, on plaque un bitmap Ne pas considerer seulement le bitmap Ajout dâ€™informations:1. Deformations locales Height map Carte dâ€™elevation Normales deduites en faisant une derivee partielle Normal map Diminue le niveau de details (polygones) Stocke dans une imageBitmap:Bitmap + bump mapping: Tache dâ€™illumination a disparue2. Proprietes localesEx: speculariteBitmap + bump mapping + modifications speculairesConclusions Participe au realimse Permet la simplification des modeles Permet de simuler certains objets/phenomenes difficiles" }, { "title": "ISIM: Rendu temps reel", "url": "/cours/posts/isim_rendu_temps_reel/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, clipping, backface culling, polygone, eclairage", "date": "2021-03-08 09:00:00 +0100", "snippet": "Lien de la note HackmdLe renduRendu temps reel vs Rendu photorealiste Rendu photorealiste: Objectif: Generation dâ€™images realistes Contrainte de temps faible Strategies Object-based rendering algorithms Illumination globale calculee independamment du point de vue Image-based rendering algorithms Illumination calculee partiellement, en fonction du point de vue Deterministic rendering algorithms Monte Carlo rendering algorithms Rendu temps reel Objectif: Generation rapide dâ€™images Le rendu temps reelPrincipe general Modelisation des objets dans un repere local Modelisation de la scene dans un repere global Projection de la scene sur le plan image passage repere global au repere camera projection sur le plan image (+dessin 2D) Pour faire le rendu: camera qui possede son propre repere les objets sont exprimes dans le repere lies a la scene on les change de repere et on les exprimes dans le repere lie a la camera on peut maintenant les projeter sur le plan image. Algorithmes 3D fondamentauxProjection des objets sur le plan image:Comment projeter un objet sur le plan image ? Plusieurs objets ? Il faut identifier les problemes! Comment determiner les sommets/face non visibles ? Comment determiner les objets caches (ou partiellement caches ?) Comment determiner les objets qui sont hors champ (ou partiellement hors champ/derrrier le plan image) ? Comment determiner les objets qui sont derriere le plan image ou partiellement visible ?Afin de les resoudre et: avoir une projection correcte etre efficaceClipping Comment determiner les objets qui sont hors champ (ou partiellement hors champ/derrrier le plan image) ? Comment determiner les objets qui sont derriere le plan image ou partiellement visible ? Estimation de la positiopn dâ€™une face par rapport aux plans Elimination des faces a lâ€™exterieur Decoupage des polygones a cheval (equations parametriques) Backface cullingComment determiner les faces non visibles ? Enumerer les sommets toujours dans le meme sens Determiner lâ€™orientation de la face par rapport a lâ€™axe optique: Calculer le vecteur normal a la surface (produit vectoriel) Determiner lâ€™angle entre le vecteur normal a la surface et le vecteur directeur de lâ€™axe optique (produit scalaire) Comment determiner les objets caches ou partiellement caches ? Trier les objets et les dessiner dans lâ€™ordre Comment determiner cet ordre ? Utiliser le centre de gravite Ne fonctionne pas dans tous les cas ! Si on dessine du plus pres au plus loin au lieu de par-dessus, on peut etre plus rapide. Utilisation dâ€™un arbre B.S.P. (Binary Space Partitionning Tree) Chaque noeud represente un hyperplan (deduit dâ€™une face F) Le 1$^{er}$ fils contient les faces du demi-espace derriere F et le second fils contient les faces du demi-espaces devant F Lorsque lâ€™hyperplan intersecte une face, la face est coupee en 2 On peut deduire un ordre de parcours des polygones pour les dessiner du plus eloigne au plus proche idem, du plus proche au plus eloigneEfficacite: Compromis entre arbre equilibre et nombre de polygones (fragmentation des polygones)Z-bufferComment determiner les objets caches ou partiellement caches ?Utilisation du Z-buffer Sauvegarde de la profondeur pour chaque pixel dessine Avantages Inconvenients Simple Oblige a projeter lâ€™ensemble des polygones Â  Probleme de resolution lors de lâ€™encodage du Z ProjectionUne fois que lâ€™on a elimine les elements hors champ de la camera, les elements qui ne sont pas de face On projette les sommets et on dessine (et rempli) le polygone en tenant compte de la profondeur\\[\\begin{aligned}&amp;amp;p_i=\\frac{fp}{z} &amp;amp;(1)\\end{aligned}\\]Algorithmes 2D fondamentauxRemplissage de polygones Suivant la projection des polygones, il faut dessiner/remplir le polygone Determiner si une partie nâ€™est pas visibile Determiner la couleur et lâ€™eclairage Eventuellement plaquer une texture â€¦ Les donnees sont la liste des sommetsDepend de plusieurs choses: Triangle de polygone Triangle ? Convexe ? Quelconqueâ€¦? Donnees: Liste de sommet Approches: Triangulation Remplissage direct Inondation Algorithme: Parcourir toutes les arretes de haut en bas et remplir horizontalement Algorithme Trier les sommets pour definir les section Ordre de remplissage Determiner les arretes actives (dans la section) A chaque transition, il faut remettre a jour la liste des arretes actives On arrive a une frontiere de section On regarde le sommet suivant Il faut desactiver lâ€™arrete actuelle et activer la suivante A chaque niveau il faut tracer des segments horizontaux On obtient des points dâ€™intersection avec chaque arrete On les trie horizontalement pas ordre croissant Il faut etre prudent car en arrivant a un niveau une arrete peut etre ignoree. Simplification pour les polygones convexes (ou meme dans le cas du triangle) Se restreindre a des cas plus simples Trace de segments Trace rapide de segments Affichage de segments Suivi des arretes activer Comment faire ?Algorithme naif: Repose sur lâ€™utilisation des nombres a virgule flottante (un peu lent)for (x = 1; ...;) { y = ax + b plot(x,y)}Critiquons ce bout de code: câ€™est pas ouf Si on parcourt les x et quâ€™on veut dessiner les y Matrice de pixel Si coeff faible (ex: 1), on avance lentement Si on a a = 4, pente tellement forte quâ€™on a des discontinuite dans le trace du segment Est-ce qu mon algo est bien ? a est un ratio donc float multiplication $\\rightarrow$ beaucoup de calculs Le resultat est un float avec une multiplication et additionAutre solution: Bresenham (65?)Uniquement avec des additions dâ€™entiersCritere: $y=mx+p$ avec $m=\\frac{d_y}{d_x}$ $D=d1-d2=(m(x_p+1)+p+y_p)-(y_p+1-m(x_p+1)+p)$ $D=d1-d2=2d_y(x_p+1)-2d_xy_p-d_x+2d_xp$ $D\\lt0\\Rightarrow(x_{p+1}, y_p)$ inc: $2d_y$ $D\\gt0\\Rightarrow(x_{p+1},y_{p+1})$ inc: $2d_y-2d_x$ Probleme dâ€™aliasing.Trace de cercleAlgorithme naif Repose sur lâ€™utilisation des nombres a virgule flottante float (un peu lent) Utilisation des symetries Precalcule des fonctions trigosAlgorithme de Bresenham Meme esprit que pour les segmentsCritere: $D(P) = x^2 + y^2 - r^2$ $D(A) = (x+1)^2 + y^2-r^2$ $D(B) = (x+1)^2+(y-1)^2-r^2$ $S=D(A)+D(B)$ $S\\ge0\\Rightarrow B$ $S\\lt0\\Rightarrow A$ Calcul de S incrementalClippingUne fois quâ€™on a projete le polygone, on lâ€™a clipe mais on peut aussi le projeter et le fenetrer.Meme sâ€™il est possible de fenetrer les polygones dans lâ€™espace, on peut aussi le faire dans le plan (apres projection) Fenetrage rectangulaire de segments: Cohen-sutherland Fenetrage dâ€™un polygone a partir des segments: Weiler-Atherton Fenetrage rectangulaire de segmentsCohen-sutherland Pour fenetrer il faut des criteres simples et rapides Fenetre de vue: 4 frontieres dans le plan Code associe a la position relative du point dans le plan Attribue a chaque sommet un code a 4bits Chaque bit representant la position relative du point par rapport a la frontiere Les points a lâ€™interieur de lâ€™image on tous leurs bits a 0 Les points a lâ€™exterieur ont au moins un bit a 1 Pour savoir si une arrete est completement visible, on fait un ou logique entre le code du premier et deuxieme sommet Si le resultat = 0, lâ€™arrete est entierement visible Pour savoir si une arrete est visible quand ses sommets sont hors de lâ€™image, on fait un et logique Si resultat = 0, lâ€™arrete est potentiellement visible Sinon, probablement hors de lâ€™image Weiler-ArthertonPolygone projete sur lâ€™image: Partie a lâ€™interieur Partie a lâ€™exterieurOn prend notre polygone et fenetre de vue et on y insere tous nos points dâ€™intersection: Ex: AB1, 1 sommet supplementaire, on lâ€™insere Obtient 2 nouveaux polygonesComment trouver le polygone resultat de la fenetre de vue ? Partir dâ€™un point dun polygone depuis la fenetre de vue Parcours les arretes A point dâ€™intersection, change de polygone (polygone $\\leftrightarrow$ quadrilatere) Toujours partir dâ€™un point in lâ€™interieur de la fenetre sinon on tourne en rond. Sâ€™il nâ€™y a pas de point du polygone a lâ€™interieur de lâ€™image, commencer par une intersection Avoir parcouru tous les points du polygone dans la fenetre Cyrus-BeckFenetrage entre 2 polygones Cyrus-Beck (Pour deux polygones convexes)Connaitre la position dâ€™un point $Q$ par rapport a un cote de la fenetre ?\\[\\begin{align}&amp;amp;I(Q) = (Q-P).n\\begin{cases}&amp;amp;= 0\\\\&amp;amp;\\lt0\\\\&amp;amp;\\gt0\\end{cases}&amp;amp;(2)\\end{align}\\]Fenetrage dâ€™un segment ? $L(t)=A+(B-A)t$ $I(Q)=(Q-P).n$ $I(L(T)) = (L(T)-P).n$ Intersection $(L(t)-P).n = 0\\Leftrightarrow t = \\frac{(A-P).n}{A-B.n}$ $D=(B-A)$ Cas 1: $D.N\\lt0\\Rightarrow t=t_{\\text{sup}}$ Cas 2: $D.N=0$ Cas 3: $D.N\\gt0\\Rightarrow t=t_{inf}$ On recommence pour tout les segments de la fenetre puis si $t_{\\text{inf}}\\gt t_{\\text{sup}}$ segment non visible sinon segment compris entre $[t_{\\text{inf}}..t_{\\text{sup}}]$ Polygones non convexe Decoupage en polygones convexes Triangulation de DelaunayRetour sur le clippingApplication de Cohen-Sutherland sur la pyramide 3D Peut appliquer lâ€™algo en 3D Au lieu de 4 codes on en a 6 Determination de la couleur des pixels durant le remplissageRemplissage en fonction de: La couleur de la face ? Lâ€™eclairage ?EclairageDetermination de la couleur Modele de Lambert $I_d = k\\times \\frac{N.L}{\\Vert N\\Vert.\\Vert L\\Vert}$ Meme niveau dâ€™eclairement pour un polygone donne Un peu moche dâ€™avoir des polygones uniformes Impression polygones plats Modele de Gourand Essayer de lisser le polygone On calcule lâ€™illumination a chaque extremite du polygone Interpoler lâ€™illumination Repeter lâ€™interpolation pour tous les points de la surface Utile quand on a beaucoup de points sur la surface Anecdote: Sur les verisons ancienne de OpenGL, câ€™etait soit Lambert soit Gourand. Fabrizio voulait avoir une lampe torche pour son 1$^{er}$ projet OpenGL, des quâ€™un spot illumine un angle ca eclaire beaucoup plus que si on eclaire plus le centre Modele de Phong On interpole la normale en tous les points du polygone suivant les arretes Beaucoup plus de calcul Marche mieux Attention au calcul des normales Echnatilloner suffisemment la surface ou bien placer la normaleOn approxime une surface ronde par des polygones. Si on calcule Lambert, on espere que lâ€™interpolation represente la normale reelle a la surface. Lâ€™aclairage donne lâ€™impression de volume.Pour chaque sommet du maillage, on stoque la normale.ResultatsLa difference entre Phong et Gouraud se creuse lorsque le modele est pauvrelightmapEclairages plus evoluesOn peut afficher des eclairages pre-calcules (du moment quâ€™il nâ€™y a pas trop dâ€™illumination)Permet de donner pas mal de realisme en temps reelConclusion Beaucoup dâ€™algorithmes Implementes dans les moteurs A connaitre pour inter-agir avec ces moteurs De nouvelles technologies emergent (RTXâ€¦)" }, { "title": "PRST: Table Normale Centree Reduite", "url": "/cours/posts/prst_table_normale_centree_reduite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, normale, table", "date": "2021-03-05 16:30:00 +0100", "snippet": "Lien de la note HackmdPRST - Table normale centree reduiteSi $P(Z\\le-1,6)$:\\[P(Z\\le-1,6) = 1 - P(Z\\le1,6)\\] Commencer passer dâ€™une loi normale a une loi centree reduite ?On a:\\(X\\sim N(\\mu,\\sigma^2)\\\\X-m\\sim N(0,\\sigma^2)\\\\\\frac{X-m}{\\sigma}\\sim N(0,1)\\)" }, { "title": "PRST: Feuille 2 - Exercice", "url": "/cours/posts/prst_second_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, brenoulli, binomial, loi, partiel", "date": "2021-03-05 15:30:00 +0100", "snippet": "Lien de la note Hackmd Lâ€™ordre des exos dans le cours est 6 $\\to$ 4 $\\to$ 15 $\\to$ 19 $\\to$ 18Exercice 4Montrer que la somme de n variables alÃ©atoires indÃ©pendantes suivant une loi de Bernoulli de paramÃ¨tre p suit une loi binomiale de paramÃ¨tres n et p. Solution $1^{ere}$ etape: Fonction caracteristique de $\\mathcal B(n,p)$, Pour $k\\in{0,1,2,â€¦,n}$ \\(P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\\) \\[\\begin{aligned}E(e^{itX})&amp;amp;=\\sum_{k=0}^{n}e^{itk}P(X=k)\\\\&amp;amp;= \\sum_{k=0}^{n}e^{itk}\\binom{n}{k}p^k(1-p)^{n-k}\\\\&amp;amp;= \\sum_{k=0}^{n}\\binom{n}{k}a^kb^{n-k} = (pe^{it}+n-p)\\end{aligned}\\] $2^e$ etape: Soient $X_1,â€¦,X_n$ $n$ v.a. independantes de loi $\\mathcal B(p)$\\[\\begin{aligned}\\phi_{X_1+...+X_n}(t) &amp;amp;= (\\phi_{X_1}(t))^1\\\\\\phi_{X_1+...+X_n}&#39;(t) &amp;amp;= (pe^{it} + 1 - p)^n\\end{aligned}\\]Exercice 6 Exercice qui risque dâ€™etre au partiel !Soient deux variables alÃ©atoires indÃ©pendantes suivant respectivement des lois exponentielles de paramÃ¨tres respectifs $\\lambda1$ et $\\lambda2$. Montrer que la variable alÃ©atoire $min(X1; X2)$ suit une loi exponentielle de paramÃ¨tre $\\lambda1 + \\lambda2$. Solution On cherche:\\[\\begin{aligned}Y&amp;amp;=min(X1, X2)\\\\R_Y(x) &amp;amp;= e^{-(\\lambda_1+\\lambda_2)x}\\end{aligned}\\] On pose $Y=\\min(X_1,X_2)$. Par definition, pour $x\\gt0$:\\[\\begin{aligned}R_Y(x) &amp;amp;= P(Y\\gt x)\\\\&amp;amp;= P(min(X_1, X_2)\\gt x)\\end{aligned}\\] Point de logique: si le minimum est plus grand que $x$ alors les 2 sont plus grnads que $x$. \\[R_Y(x) = P(\\{X_1\\gt x\\}\\cap\\{X_2\\gt x\\})\\] $X_1$ et $X_2$ sont independantes donc:\\[\\begin{aligned}R_Y(x) &amp;amp;= P(X_1\\gt X_2)P(X_2\\gt x) = e^{-\\lambda_1x}\\times e^{-\\lambda_1x}\\\\&amp;amp;= e^{-(\\lambda_1+\\lambda_2)x}\\end{aligned}\\] Conclusion: $Y\\sim \\xi(\\lambda_1+\\lambda_2)$Exercice 15Soient $X$ et $Y$ deux variables alÃ©atoires indÃ©pendantes et suivant toutes deux une loi normale centrÃ©e rÃ©duite. ConsidÃ©rons les variables alÃ©atoires $U = X + Y$ et $V = X âˆ’ Y$ Solution \\[\\begin{pmatrix} U\\\\ V\\end{pmatrix} =\\begin{pmatrix} 1 &amp;amp;1\\\\ 1 &amp;amp;-1\\end{pmatrix}\\begin{pmatrix} X\\\\ Y\\end{pmatrix}\\] On pose:\\[A=\\begin{pmatrix} 1 &amp;amp;1\\\\ 1 &amp;amp;-1\\end{pmatrix}\\] Toute combinaison lineaire de $U$ et $V$ es une combinaison de $X$ et $Y$, comme ce sont des vecteurs gaussien alors $(U,V)^T$ est un vecteur gaussien. 2.\\[\\begin{aligned} E(U)&amp;amp;=E(X+Y)=E(X)+E(Y)=0 \\\\E(V)&amp;amp;=E(X-Y)=E(X)-E(Y)=0\\\\E(UV)&amp;amp;=E(X^2-Y^2)=E(X^2)-E(Y^2)\\end{aligned}\\] $X$ et $Y$ sont centrees.\\(\\begin{aligned}VM(X)&amp;amp;=E(X^2)-\\underbrace{E(X)^2}_{=0}\\\\E(X^2)&amp;amp;=E(Y^2)=1\\\\E(UV)&amp;amp;=1-1=0\\\\Cov(U,V)&amp;amp;=0-0=0\\end{aligned}\\)Exercice 18Soit $X$ une variable alÃ©atoire discrÃ¨te de support $\\mathbb N^*$ telle que, pour tout entier $k \\ge 1$,\\(P(X = k) = \\frac{\\alpha}{k!}\\)pour un certain rÃ©el $\\alpha$. DÃ©terminer le rÃ©el $\\alpha$ Calculer $E(X)$ puis $E(X(X âˆ’ 1))$. En dÃ©duire $V(X)$. Solution Par definition: \\[\\sum_{k\\ge 1}P(X=k)=1\\] \\[\\sum_{k\\ge1}\\frac{\\alpha}{k!}=1 \\Rightarrow\\alpha\\sum_{k\\ge1}\\frac{1}{k!}\\] Developpement limite de $e^z$, $z\\in\\mathbb R$:\\[e^{z}=\\sum_{k\\ge0}\\frac{z^k}{k}=1\\] \\[\\begin{aligned}\\sum_{k\\ge1}\\frac{1}{k!}&amp;amp;=\\sum_{k\\ge0}\\frac{1}{k!}=e-1\\text{ developpement limite.}\\\\\\sum_{k\\ge1}P(X=k)&amp;amp;=\\alpha(e-1)\\\\ \\text{donc } \\alpha(e-1)&amp;amp;=1\\Leftrightarrow\\alpha=\\frac{1}{e-1}\\end{aligned}\\] Notons que $\\alpha$ est positif. 2.\\[\\begin{aligned}E(X) &amp;amp;= \\sum_{k\\ge1}X_{\\alpha}P(X=k) = \\sum_{k\\ge1}\\alpha\\frac{k}{k!} = \\alpha\\sum_{k\\ge1}\\frac{1}{(k-1)!}\\\\&amp;amp;= \\alpha\\sum_{j\\ge0}\\frac{1}{j!} = \\alpha e = \\frac{e}{e-1}\\end{aligned}\\] Calculons $E(X(X-1))$:\\[\\begin{aligned}E(X(X-1)) &amp;amp;= \\sum_{k\\ge1}k(k-1)P(X=k)\\\\&amp;amp;= \\sum_{k\\ge1}k(k-1)\\times\\frac{\\alpha}{k!}=\\sum_{k\\ge2}\\frac{\\alpha}{(k-2)!}\\\\&amp;amp;= \\sum_{j\\ge0}\\frac{\\alpha}{j!}=\\alpha e = \\frac{e}{e-1}\\\\E(X(X-1)) + E(X) &amp;amp;= E(X^2) \\text{ donc } E(X^2)=2 \\frac{e}{e-1}\\\\V(X)&amp;amp;=2 \\frac{e}{e-1}-\\biggr(\\frac{e}{e-1}\\biggr)^2\\\\&amp;amp;= \\frac{2e(e-1)e}{(e-1)^2} = \\frac{e^2-2e}{(e-1)^2}\\end{aligned}\\]Exercice 19 Exercice qui risque dâ€™etre au partiel !Soit $(U_n)$ une suite de variables alÃ©atoires indÃ©pendantes suivant une loi uniforme sur lâ€™intervalle $[0; 1]$.On pose, pour tout entier $n \\ge 1$, $M_n := max(U_1, . . . , U_n)$ et $X_n = n(1âˆ’M_n)$. Soit $n \\ge 1$. DÃ©terminer la fonction de rÃ©partition de $M_n$ puis celle de $Xn$. Montrer que la suite $(Xn)$ converge en loi. Mael a 5 cousins bretons qui viennent du Morbihandâ€¦ Solution 1.Soit $x$ un reel.\\[\\begin{aligned}P(M_n\\le x) &amp;amp;= P(max(U_1, . . . , U_n)\\le x) = P(\\{U_1\\le x\\}\\cap...\\cap\\{U_n\\le x\\})\\\\&amp;amp;= \\Pi_{k=1}^n P(\\{U_k\\le x\\}) = (P(U_1\\le x))^n\\\\&amp;amp;= (F(x))^n\\end{aligned}\\] ou F designe la fonction de repartition. Fonction de repartition de la loi $U([0;1])$:\\[\\begin{aligned}F(x)&amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\x &amp;amp;\\text{si } x\\in[0;1]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\\\int_0^x1dt &amp;amp;= x\\\\F_n(x)=P(M_n\\le x) &amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\x &amp;amp;\\text{si } x\\in[0;1]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\G_n(x) = P(X_n\\le x) &amp;amp;= 1-P(X_n\\gt x)\\\\&amp;amp;= 1-P(n(1-M_n)\\gt x)\\\\&amp;amp;= 1-P(1-M_n\\gt\\frac{x}{n}) = 1 - P(-M_n\\gt\\frac{x}{n}-1)\\\\&amp;amp;= 1-P(M_n\\lt1-\\frac{x}{n})\\\\ &amp;amp;=\\begin{cases}1-0 &amp;amp;\\text{si } 1-\\frac{x}{n}\\lt0\\\\1-(1-\\frac{x}{n}) &amp;amp;\\text{si } 0\\lt1-\\frac{x}{n}\\lt1\\\\1-1 &amp;amp;\\text{si } 1-\\frac{x}{n}\\gt1\\end{cases}\\\\&amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\1-(1-\\frac{x}{n})^n &amp;amp;\\text{si } x\\in[0;n]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\\\end{aligned}\\] 2.Quelle propriete du cours doit-on utiliser ? Remarquons que:\\[\\lim_{n\\to+\\infty}G_n(x)=\\begin{cases}0 &amp;amp;\\text{ si } x\\lt0\\\\1-e^{-x}\\end{cases}\\\\\\] Il sâ€™agit de la fonction de repartition de la loi $\\xi(1)$ Donc $X_n\\Rightarrow^{\\text{loi}} \\xi(1)$ $\\lim_{n\\to+\\infty}(1+\\frac{z}{n})^n = e^{z}$ pour tout reel $z$." }, { "title": "PRST: Feuille 1 - Exercice, suite", "url": "/cours/posts/prst_first_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, exponentielle, bernoulli, binomial", "date": "2021-03-05 14:45:00 +0100", "snippet": "Lien de la note Hackmd Lâ€™ordre des exos dans le cours est 3 $\\to$ 9 $\\to$ 15 $\\to$ 16 $\\to$ 13Exercice 3 DÃ©terminer la fonction caractÃ©ristique de la loi de Bernoulli de paramÃ¨tre $p$. DÃ©terminer la fonction caractÃ©ristique de la loi exponentielle de paramÃ¨tre $\\lambda$. Solution $X\\sim\\mathcal B(p), E(e^{itx}) = p\\times e^{it\\times 1} + (1-p)e^{it\\times 0} = 1-p+p e^{it}$ Soit $t\\in\\mathbb R$: \\[\\begin{aligned}\\phi(t) = E(e^{itX}) &amp;amp;= \\int_0^{+\\infty}e^{itx}\\lambda e^{-\\lambda x}dx\\\\&amp;amp;= \\lambda\\int_0^te^{(it-\\lambda)x}dx\\\\\\text{Soit } A\\gt0: \\int_0^Ae^{(it-\\lambda)x}dx &amp;amp;= \\biggr[\\frac{1}{it-\\lambda}e^{(it-\\lambda)x}\\biggr]_0^A\\\\&amp;amp;= \\frac{1}{it-\\lambda}e^{(it-\\lambda)A} - \\frac{1}{it-\\lambda}\\times1\\\\e^{(it-\\lambda)A} &amp;amp;= \\underbrace{e^{itA}}_{\\le1 \\text{ car bornee}}\\times e^{-\\lambda A}\\\\\\end{aligned}\\\\\\lim_{A\\to+\\infty} e^{-\\lambda A} = 0\\] Car $\\lambda\\gt 0$. Par ailleurs $\\vert e^{itA}\\vert\\le1$. Donc $\\lim_{A\\to+\\infty}\\frac{1}{it-\\lambda} e^{-\\lambda A} = 0$ dâ€™ou $\\lim_{A\\to+\\infty}\\int_0^Ae^{(it-\\lambda)x}dx = - \\frac{1}{it-\\lambda} = \\frac{1}{\\lambda - it}$. Conclusion: $\\int_0^{+\\infty}e^{(it-\\lambda)x}dx$ est bien definie et egale a $\\frac{1}{\\lambda - it}$ \\(\\phi(t) = \\frac{\\lambda}{\\lambda - it}\\) Exercice 9Dans une fabrication en sÃ©rie, 7% des produits prÃ©sentent un dÃ©faut. 40 articles sont contrÃ´lÃ©s Que vaut la probabilitÃ© que 4 articles prÃ©sentent un dÃ©faut? Que vaut la probabilitÃ© que moins de 4 articles prÃ©sentent un dÃ©faut? Solution Pourquoi peut-on considerer que chaque V.A. (echantillon) sont independantes les unes des autres ? Comme câ€™est une fabrication en serie, câ€™est fait en tres grand nombre et un echantillon de 40 ne change rien. Pour parler de loi binomiale, il faut que lâ€™echantillon soit petit par rapport a la population. \\[\\begin{aligned}P(X=4)&amp;amp;=\\binom{40}{4}\\times0,07^4\\times4,96^36\\simeq0,16\\\\P(X\\lt4)&amp;amp;=P(X=1)+P(X=2)+P(X=3)\\simeq 0,69\\end{aligned}\\]Exercice 13Soient $\\alpha$ un rÃ©el strictement positif et X une variable alÃ©atoire dont la densitÃ© est dÃ©finie par:$f_X(x) = \\alpha x^{âˆ’\\alphaâˆ’1}$ pour $x \\ge 1$ et $f_X(x) = 0$ sinon. VÃ©rifier que $f_X$ est bien une densitÃ© de probabilitÃ© et dÃ©terminer la fonction de rÃ©partition associÃ©e Calculer $P(0 \\lt X \\le 2)$, Pour quelles valeurs de $\\alpha$, la variable alÃ©atoire $X$ admet-elle une espÃ©rance? La calculer quand elle existeDans cet exercice, nous avons Ã©tudiÃ© la loi de Pareto de paramÃ¨tre $\\alpha$. Solution Montrons que $f_X$ est bien une densite. \\[\\begin{aligned}&amp;amp;\\text{i. } f_X(x)\\ge0 \\text{ par construction.}\\\\&amp;amp;\\text{ii. } \\int_1^{+\\infty}f_X(x)dx=1?\\end{aligned}\\] Soit $A\\gt0$:\\[\\begin{aligned}\\int_1^Af_X(x)dx=\\int_1^A\\alpha x^{-\\alpha-1}dx &amp;amp;= \\biggr[\\frac{\\alpha}{-\\alpha}x^{-\\alpha}\\biggr]_1^A\\\\&amp;amp;= [x^{-\\alpha}]_1^A\\end{aligned}\\] On sait que\\[lim_{A\\to+\\infty}A^{-\\alpha}=lim_{A\\to+\\infty}\\frac{1}{A^\\alpha} = 0\\] Dâ€™ou\\[\\int_1^{+\\infty}f_X(x)dx=\\lim_{A\\to+\\infty}\\int_1^Af_X(x)dx = 1\\] Fonction de repartition:\\[F_X(x) = \\int_1^x\\alpha t^{-\\alpha-1}dt = 1-x^{-\\alpha}\\] 2.\\[\\begin{aligned}P(0\\lt x\\le2) &amp;amp;= P(1\\le Y\\le2) = \\int_1^2\\alpha x^{-\\alpha-1}dx\\\\&amp;amp;=[-x^{-\\alpha}]_1^2 = 1-\\frac{1}{2^\\alpha}\\end{aligned}\\] 3.$\\alpha\\gt 1$Exercice 15Les Å“ufs pondus par une poule ont une longueur pouvant Ãªtre modÃ©lisÃ©e Ã  lâ€™aide dâ€™une loi normale dâ€™espÃ©rance 6 et dâ€™Ã©cart-type 1,4. Quelle est la probabilitÃ© de trouver un oeuf: dâ€™une longueur supÃ©rieure Ã  8cm? dâ€™une longueur infÃ©rieure Ã  5cm? Solution Notons L la v.a. consideree $L\\sim\\omega(6,(1,4)^2)$, $Y=\\frac{X-6}{1,4}\\sim\\mathcal N(0,1)$ \\[\\begin{aligned}1-P(X\\le8) &amp;amp;= 1-P(\\frac{X-6}{1,4}\\le \\frac{8-6}{1,4}) \\text{ Possible de le faire directement car 8 est positif}\\\\&amp;amp;= 1-P(Y\\le\\frac{10}{7})\\simeq1-P(Y\\le 1,43)\\end{aligned}\\] Cherchons 1,43 dans la table $\\mathcal N(0,1)$\\[1-P(Y\\le1,43)\\simeq0,92\\sim0,08\\] 2.\\[\\begin{aligned}P(X\\lt5) &amp;amp;= P(Y\\lt\\frac{5-6}{1,4}) = P(Y\\lt-\\frac{1}{1,4})\\simeq P(Y\\lt-0,71)\\\\&amp;amp;= 1-P(Y\\lt0,71)\\end{aligned}\\] Dâ€™apres la table de la loi $\\mathcal N(0,1)$ $P(Y\\lt0,71)\\simeq0,76$ donc $P(Y\\ge0,71)\\simeq 0,24$ et $P(X\\lt5) = P(Y\\lt-0,71)\\simeq0,24$Exercice 16Les composants dâ€™un autoradio ont une durÃ©e de vie pouvant Ãªtre modÃ©lisÃ©e par une loi normale dâ€™espÃ©rance 2400 (heures dâ€™utilisation) et dâ€™Ã©cart-type 300. Un autoradio est utilisÃ©, en moyenne, 1000 heures par an. Quelle est la probabilitÃ© quâ€™un composant ait une durÃ©e de vie supÃ©rieure Ã  3 ans? Solution Methode de professionnel: Si $X$ suit une loi normale $N(\\mu,\\sigma^2)$ \\(P(\\mu-\\sigma\\le X\\le\\mu+\\sigma)\\simeq0,68\\\\P(\\mu-2\\sigma\\le X\\le\\mu+2\\sigma)\\simeq0,95\\\\P(\\mu-3\\sigma\\le X\\le\\mu+3\\sigma)\\simeq0,997\\\\\\) \\[P(2400-2\\times300\\le X\\le2400+2\\times300) = P(1800\\le X\\le3000)\\simeq0,95\\\\Y=\\frac{X-2400}{300}\\sim\\mathcal N(0,1)\\\\P(X\\gt3000)=P(\\frac{X-2400}{300}\\gt2)\\Rightarrow1-P(Y\\le2)\\simeq1-0,977=0,023 \\text{ le jeu des arrondis}\\]" }, { "title": "PRST: Convergence", "url": "/cours/posts/prst_convergence/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-03-05 14:30:00 +0100", "snippet": "Lien de la note HackmdPRST - Seance 2Definition Soit $X$ une v.a (aucune condition prescrite) $\\phi$ definie sur $\\mathbb R$ par: $\\phi_X(t) = E(e^{itx})$ $\\vert e^{itx}\\vert \\le 1$ $\\phi(t)=\\int_{\\omega}e^{itx(\\omega)}$ Caracterise la loi dâ€™une v.a, i.ei $\\phi_X=\\phi_Y \\Rightarrow X$ et $Y$ suivent la meme loiLois marginales Lois des v.a $X_i$ Impossible, sans hypothese supplementaire, de determiner la loi conjointe a partir des lois marginalesMatrice de covariance Matrice carre dâ€™ordre $d$ definie par $m_{ij} = Cov$Indepenance de 2 variables: cas discret 2 va $X$ et $Y$ sont dites independantes si, pour tout reel $x$ et $y$ de leur supports respectifs: $P({X\\le x})$ 2 variables aleatoires sont independantes si:Definition Un vecteur aleatoire $(X_1,â€¦,X_d)$ est dit gaussien si toute combinaison des VA $X_k$ est gaussienne Un vecteur gaussien est entierement caracterise par $m=(E(X_1),â€¦,E(X_d))^T$ et sa matrice de variance-covariances $\\Sigma$. Sa loi sera notee $N(m,\\Sigma)$ et nous parlerons de loi normale multidimensionnellePropositionSi $X$ est un vecteur gaussien et $A$ est une application lineaire definie sur $\\mathbb R^+$$Y = AX$ est un vecteur gaussien Lâ€™image dâ€™un vecteur gaussien par une application lineaire est un vecteur gaussien.Comment prouver que la d-ieme composante est gaussienne ?Soit $(X_1, X_2, X_3)$ un vecteur gaussien. Pourquoi $X_3$ suit-elle une loi gaussienne ?\\(\\underbrace{\\begin{pmatrix}0 &amp;amp; 0 &amp;amp;1\\end{pmatrix}}_{\\text{application lineaire}}\\begin{pmatrix}X_1\\\\X_2\\\\X_3\\end{pmatrix} = X_3\\)On considere Leo et Alexandre jouent a un jeu de pile ou face et font bourses communes. Â  Leo pile 10 â‚¬ face -10 â‚¬ Â  Alexandre Proba Image 10 â‚¬ 1/2 SCIA 5 â‚¬ 1/10 GISTRE -100 â‚¬ 4/10 Ils vont pas en cours les SCIA - AlexandreOn a $(X;Y)$ avec $X$ les gains de Leo et $Y$ les gains de Alexandre. Les deux VA sont independantes\\[P(X=1-;Y=10) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\\\P(X=-10;Y=100) = \\frac{1}{2}\\times\\frac{4}{10} = 0,5\\\\(E(X); E(Y)) = (0; -34,5)\\]PropositionSoit $X = (X_1,â€¦, X_d)$ un vecteur gaussien.Les variables aleatoires $X_1,â€¦X_d$ sont independantes si et seulement si la matrice $\\Sigma$ est diagonale.$Cov(UV) = E(UV) - E(U) \\times E(V)$\\(\\Sigma =\\begin{pmatrix} Var(U) &amp;amp; Cov(U, V)\\\\ Cov(U, V) &amp;amp; Var(U)\\end{pmatrix}\\)Convergence presque sure (p.s.) $(X_i)$ suite de variables aleatoires sur le meme espace $\\Omega$ et $X$ une variable aleatoire egalement definie $\\Omega$ convergence ponctuelle implique tous les autres$\\lim_{n\\to+\\infty}X_n(\\omega) = Y(\\omega)$ pour tous $\\omega\\in\\Omega$Convergence en probabilite Meme cadre que precedemment $\\forall\\varepsilon\\gt 0, \\lim_{n\\to+\\infty}P(\\vert X_n - X\\vert\\ge \\varepsilon) = 0$Convergence en loi Meme cadre que precedemment $\\lim_{n\\to+\\infty}F_{X_n} = F_X$Theoreme de Paul Levy Si la suite de v.a. $(X_n)$ converge en loi vers une v.a. $X$ alors $\\lim_{n\\to+\\infty}\\pi_{X_n} = \\phi_X(t)$Convergence $L^2$ aussi appelee convergence en moyenne quadratique $\\lim_{n\\to+\\infty}E(\\vert X_n - X\\vert^2) = 0$ nâ€™a de sens que pour les VA telles que $E(X^2)\\lt+\\infty$ implique la convergence en probabiliteConvergence $L^1$ aussi appelee convergence en moyenne $\\lim_{n\\to+\\infty}E(\\vert X_n -X\\vert) = 0$Loi forte des grands nombresSoit $(X_i)$ une suite de VA i.i.d. (independant et suivat la meme loi)\\[\\lim_{n\\to+\\infty}\\overline{X_n} = E(X)\\]au sens de la convergence p.s. ou $\\overline{X_n} := \\frac{X_1 + â€¦ + X_n}{n}$Cas unidimensionnel Soit $(X_i)$ une suite v.a. i.i.d. Noton $m:=E(X_i)$ et $\\sigma^2 = V(X_i)$ $X_1$ et $X_2$ deux v.a. independantes.\\(\\phi_{X_1 + X_2}(t) = \\phi_{X_1}(t) + \\phi_{X_2}(t)\\)Preuve\\(\\begin{aligned}\\phi_{X_1 + X_2}(t) &amp;amp;= E(e^{it(X_1 + X_2)})\\\\&amp;amp;= E(e^{itX_1})E(e^{itX_2})\\end{aligned}\\)Car les v.a. sont independantes\\(\\phi_{X_1+X_2} =\\)" }, { "title": "DBRE: Conditions de la protection", "url": "/cours/posts/dbre_protection/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-03 12:00:00 +0100", "snippet": "Lien de la note HackmdRecapLe monopole est confere pour favoriser la creation/innovation mais comporte un certain nombre dâ€™exceptions pour ne pas avoir de blocage du marche.Le droit international prevoit une harmonisation pour quâ€™une oeuvre soit utilisee dans plusieurs pays, lâ€™oeuvre depend des regulations de chacune des pays.La condition de protection La condition de protection est etudiee uniquement lorsquâ€™on veut faire valoir ses droits. Pourquoi me reprocher dâ€™avoir copie quelquechose qui nâ€™est pas protege ? Code de la propriete intellectuelle: une oeuvre est protegee si elle est originale. Mais ce nâ€™est pas la seule condition de protection dâ€™une oeuvre ! Est-ce que mon oeuvre est elligible au droit dâ€™auteur ? Quâ€™est-ce qui, dans mon oeuvre, est considere comme protegeable? Ce ne sont pas les mots prits un a un Parmi la liste des oeuvres elligibles, je regardes quels elements sont originaux.$\\Rightarrow$ ce sont les etapes suivies par un juge lors dâ€™un proces en contrefacon. Volet penal: passible dâ€™une peine jusquâ€™a 3 ans de prison Volet civile: demander des dedomagemments ont considÃ©rÃ©s notamment comme oeuvres de lâ€™esprit au sens du prÃ©sent code : 1Â° Les livres, brochures et autres Ã©crits littÃ©raires, artistiques et scientifiques ; 2Â° Les confÃ©rences, allocutions, sermons, plaidoiries et autres oeuvres de mÃªme nature ; 3Â° Les oeuvres dramatiques ou dramatico-musicales ; 4Â° Les oeuvres chorÃ©graphiques, les numÃ©ros et tours de cirque, les pantomimes, dont la mise en oeuvre est fixÃ©e par Ã©crit ou autrement ; 5Â° Les compositions musicales avec ou sans paroles ; 6Â° Les oeuvres cinÃ©matographiques et autres oeuvres consistant dans des sÃ©quences animÃ©es dâ€™images, sonorisÃ©es ou non, dÃ©nommÃ©es ensemble oeuvres audiovisuelles ; 7Â° Les oeuvres de dessin, de peinture, dâ€™architecture, de sculpture, de gravure, de lithographie ; 8Â° Les oeuvres graphiques et typographiques ; 9Â° Les oeuvres photographiques et celles rÃ©alisÃ©es Ã  lâ€™aide de techniques analogues Ã  la photographie ; 10Â° Les oeuvres des arts appliquÃ©s ; 11Â° Les illustrations, les cartes gÃ©ographiques ; 12Â° Les plans, croquis et ouvrages plastiques relatifs Ã  la gÃ©ographie, Ã  la topographie, Ã  lâ€™architecture et aux sciences ; 13Â° Les logiciels, y compris le matÃ©riel de conception prÃ©paratoire ; 14Â° Les crÃ©ations des industries saisonniÃ¨res de lâ€™habillement et de la parure. Sont rÃ©putÃ©es industries saisonniÃ¨res de lâ€™habillement et de la parure les industries qui, en raison des exigences de la mode, renouvellent frÃ©quemment la forme de leurs produits, et notamment la couture, la fourrure, la lingerie, la broderie, la mode, la chaussure, la ganterie, la maroquinerie, la fabrique de tissus de haute nouveautÃ© ou spÃ©ciaux Ã  la haute couture, les productions des paruriers et des bottiers et les fabriques de tissus dâ€™ameublement. Article L112-2 Il nâ€™y a pas de site web, jeux videos, etc. mais dâ€™apres la jurisprudence ils en font partie. La jurisprudence a exclu a plusieurs reprises des textes sans originalite (definitions, lettre de lâ€™alphabet, etc.).Lâ€™originalite quâ€™est-ce que câ€™est ? Câ€™est lâ€™empreinte de la personnalite de lâ€™auteur. Ex: un style (en peinture, litterature, etc.).La titularite2 Hypotheses: Un oeuvre a un auteur unique La pluralite dâ€™auteurs Article L111-1ModifiÃ© par LOI nÂ°2020-1674 du 24 dÃ©cembre 2020 - art. 35 (V) Lâ€™auteur dâ€™une oeuvre de lâ€™esprit jouit sur cette oeuvre, du seul fait de sa crÃ©ation, dâ€™un droit de propriÃ©tÃ© incorporelle exclusif et opposable Ã  tous. Ce droit comporte des attributs dâ€™ordre intellectuel et moral ainsi que des attributs dâ€™ordre patrimonial, qui sont dÃ©terminÃ©s par les livres Ier et III du prÃ©sent code. Lâ€™existence ou la conclusion dâ€™un contrat de louage dâ€™ouvrage ou de service par lâ€™auteur dâ€™une oeuvre de lâ€™esprit nâ€™emporte pas dÃ©rogation Ã  la jouissance du droit reconnu par le premier alinÃ©a, sous rÃ©serve des exceptions prÃ©vues par le prÃ©sent code. Sous les mÃªmes rÃ©serves, il nâ€™est pas non plus dÃ©rogÃ© Ã  la jouissance de ce mÃªme droit lorsque lâ€™auteur de lâ€™oeuvre de lâ€™esprit est un agent de lâ€™Etat, dâ€™une collectivitÃ© territoriale, dâ€™un Ã©tablissement public Ã  caractÃ¨re administratif, dâ€™une autoritÃ© administrative indÃ©pendante dotÃ©e de la personnalitÃ© morale, de la Banque de France, de lâ€™Institut de France, de lâ€™AcadÃ©mie franÃ§aise, de lâ€™AcadÃ©mie des inscriptions et belles-lettres, de lâ€™AcadÃ©mie des sciences, de lâ€™AcadÃ©mie des beaux-arts ou de lâ€™AcadÃ©mie des sciences morales et politique. Les dispositions des articles L. 121-7-1 et L. 131-3-1 Ã  L. 131-3-3 ne sâ€™appliquent pas aux agents auteurs dâ€™oeuvres dont la divulgation nâ€™est soumise, en vertu de leur statut ou des rÃ¨gles qui rÃ©gissent leurs fonctions, Ã  aucun contrÃ´le prÃ©alable de lâ€™autoritÃ© hiÃ©rarchique. Article L111-1 Lâ€™existence ou la conclusion dâ€™un contrat de louage dâ€™ouvrage ou de service par lâ€™auteur dâ€™une oeuvre de lâ€™esprit nâ€™emporte pas dÃ©rogation Ã  la jouissance du droit reconnu par le premier alinÃ©a, sous rÃ©serve des exceptions prÃ©vues par le prÃ©sent code.Il faut imperativement avoir un contrat de cession de droits si on sous-traite la creation dâ€™une oeuvre. (ex: creation dâ€™un jeu video) Le simple fait de commander une oeuvre ne veut pas dire quâ€™on est investi des droits sur lâ€™oeuvre, il faut un transfere de titularite.Il y a une exception: Les droits des salaries appartiennent aux salaries.Ce nâ€™est pas parce quâ€™un salarie est paye pour creer quelque chose que lâ€™oeuvre appartient a lâ€™employeur, il faut une passation de droits.Et si on fait un projet a Epita, a qui appartient les droits ? Lâ€™oeuvre nous appartient car nous nâ€™avons jamais signe de passation de droits MAIS il nous appartient sous reserve quâ€™on lâ€™ai fait entierement seul (cad pas de sujet, encadrement, etc.). Article L131-1CrÃ©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La cession globale des oeuvres futures est nulle." }, { "title": "ASE2: TD 1, suite", "url": "/cours/posts/ase2_exercices_convergence_estimation_2/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-03-03 09:00:00 +0100", "snippet": "Lien de la note HackmdExercice 3Soit $X$ une VA de densite $f(x) = e^{-x-e^{-x}}$ $\\forall x\\in\\mathbb R$. Determiner la fonction de repartition de $X$ Soit $Y=e^{-X}$, determiner la fonction de repartition de $Y$, puis sa densite Calculer $E(Y)$, $V(Y)$ Soit $(Y_1,â€¦, Y_n)$ un echantillon de $Y$, cad $(Y_i), 1\\le i\\le n$ sont alors des VA independantes et de meme loi que $Y$. On pose $\\overline{Y_{n}} = \\frac{1}{n}\\sum_{i=1}^nY_i$ Montrer que $\\overline{Y_n}\\to_{n\\to+\\infty}^P1$ Montrer que $\\overline{Y_n}\\to_{n\\to+\\infty}^{m.q}1$ Solution 1.$F(x) = P(X\\lt x) = \\int_{-\\infty}^xf(t)dt$ $\\forall x\\in\\mathbb R$\\[\\begin{aligned}F(x) &amp;amp;= \\int_{-\\infty}^xe^{-t}\\times e^{-e^{-t}}\\\\&amp;amp;= \\biggr[e^{-e^{-t}}\\biggr]_{-\\infty}^x = e^{-e^{-x}} \\text{ car } (e^{-e^{-t}})&#39; = e^{-t}e^{-e^{-t}}\\\\&amp;amp;= e^{-e^{-x}}\\end{aligned}\\] 2.$Y = e^{-X}$, Soit $G(y)$ la fonction de repartition de $Y$. $Y$ etant positive donc $G(y) = P(Y\\lt y) = 0$ pour $y\\le 0$. Pour $y\\gt 0$:\\[\\begin{aligned}G(y) &amp;amp;= P(Y\\lt y) = P(e^{-X}\\lt y) = P(-X\\lt \\ln(y))\\\\&amp;amp;= P(X\\gt-\\ln(y)) = 1 - F(-\\ln(y))\\\\&amp;amp;= 1 - e^{-y}\\\\\\text{Donc } G(y) &amp;amp;=\\begin{cases} 0 &amp;amp;y\\le 0\\\\ 1-e^{-y} &amp;amp;y\\gt 0\\end{cases}\\end{aligned}\\] La densite de $Y = e^{-X}$ est:\\[g(y) = G&#39;(y) =\\begin{cases} 0 &amp;amp;y\\le 0\\\\ e^{-y} &amp;amp;y\\gt 0\\end{cases}\\] 3.$E(Y) = \\int_{\\mathbb R}yg(y)dy = \\int_{-\\infty}^{+\\infty}ye^{-y}dy$ On integre par parties:\\(\\begin{cases} v = y &amp;amp;v&#39;=1\\\\ u&#39; = e^{-y} &amp;amp;u = -e^{-y}\\end{cases}\\\\\\begin{aligned}E(Y) = \\underbrace{\\biggr[-ye^{-y}\\biggr]_0^{+\\infty}}_{_{y\\to+\\infty}\\to0} - \\int_0^{+\\infty}(-e^{-y})dy &amp;amp;= \\int_0^{+\\infty}e^{-y}dy\\\\&amp;amp;= \\biggr[-e^{-y}\\biggr]_0^{+\\infty} = 1\\end{aligned}\\\\V(Y) = E(Y^2) - E^2(Y)\\\\E(Y^2) = \\int_0^{+\\infty}y^2e^{-y}dy\\\\\\text{Integration par parties:}\\begin{cases} v = y^2 &amp;amp;v&#39;=2y\\\\ u&#39;=e^{-y} &amp;amp;u=-e^{-y}\\end{cases}\\\\\\begin{aligned}E(Y^2) &amp;amp;=\\int_0^{+\\infty}Y^2e^{-y}dy = \\underbrace{\\biggr[-y^2e^{-y}\\biggr]_0^{+\\infty}}_{_{y\\to+\\infty}\\to0}-\\int_0^{+\\infty}2y(-e^{-y})dy\\\\&amp;amp;= 2\\int_0^{+\\infty}ye^{-y}dy = 2E(Y) = 2\\\\\\text{Donc: } V(Y) &amp;amp;= 2 - 1 = 1\\end{aligned}\\) 4.1.$\\overline{Y_n}=\\frac{1}{n}\\sum_{i=1}^{n}Y_i$, $(Y_i)_{1\\le i\\le n}$ idependantes et de meme loi que $Y$.\\[\\begin{aligned}E(\\overline{Y_n}) &amp;amp;= \\frac{1}{n}\\sum_{i=1}^nE(Y_i) = \\frac{1}{n}\\sum_{i=1}^n1 = \\frac{n}{n} = 1\\\\V(\\overline{Y_n}) &amp;amp;= \\frac{1}{n^2}\\sum_{i=1}^nV(Y_i)= \\frac{n}{n^2} = \\frac{1}{n}\\end{aligned}\\] En utilisant Tchebychev:\\[\\begin{aligned}\\forall\\varepsilon\\gt0, &amp;amp;P(\\vert\\overline{Y_n}-E(\\overline{Y_n})\\vert \\gt\\varepsilon)\\lt\\frac{V(\\overline{Y_n})}{\\varepsilon^2}\\\\\\Rightarrow &amp;amp;P(\\vert\\overline{Y_n}-1)\\vert \\gt\\varepsilon)\\lt\\frac{1}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\text{Donc: } &amp;amp;\\overline{Y_n}\\to_{n\\to+\\infty}^P1\\end{aligned}\\] 4.2.Montrons que $\\overline{Y_n}\\to_{n\\to+\\infty}^{m.q}1$\\[\\begin{aligned}E(\\vert\\overline{Y_n}-1)\\vert^2) &amp;amp;= E(\\vert\\overline{Y_n}-E(\\overline{Y_n})\\vert^2)\\\\&amp;amp;=V(\\overline{Y_n}) = \\frac{1}{n}\\to_{n\\to+\\infty}0\\\\\\text{Donc: } \\overline{Y_n}&amp;amp;\\to_{n\\to+\\infty}^{m.q}1\\end{aligned}\\]Exercice 4Soit $X$ une VA de loi $\\gamma_p$, $(p\\in\\mathbb N^*)$ Determiner la fonction caracteristique de $X$ En deduire celle de $\\frac{X-p}{\\sqrt{p}}$ Montrer que $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$ Solution 1.$X$ suit la loi $\\gamma_p$ (gamma). Sa densite est $f(x) = \\frac{1}{\\Gamma(p)}e^{-x}x^{p-1}$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\frac{1}{\\Gamma(p)}\\int_0^{+\\infty}e^{itx}e^{-x}x^{p-1}dx\\\\&amp;amp;=\\frac{1}{\\Gamma(p)}\\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\\\text{Posons: } I_{p-1}&amp;amp;=\\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\I_0 &amp;amp;= \\int_0^{+\\infty}e^{(it-1)x}dx = \\biggr[\\frac{e^{(it-1)x}}{it-1}\\biggr]_0^{+\\infty} = -\\frac{1}{it-1}\\\\\\text{Car: } e^{(it-1)x} &amp;amp;= e^{itx}.e^{-x}\\to_{x\\to+\\infty}0 \\text{ puisque }\\vert e^{itx}\\vert = 1\\text{ (bornee) }\\\\I_{p-1} &amp;amp;= \\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\\\end{aligned}\\\\\\text{Integration par parties:}\\begin{cases} v = x^{p-1} &amp;amp;v&#39;=(p-1)x^{p-2}\\\\ u&#39;=e^{(it-1)x} &amp;amp;u=\\frac{1}{it-1}e^{(it-1)x}\\end{cases}\\\\\\begin{aligned}I_{p-1}&amp;amp;=\\underbrace{\\biggr[\\frac{e^{(it-1)x}}{it-1}x^{p-1}\\biggr]_0^{+\\infty}}_{\\to_{x\\to+\\infty}0} - \\frac{p-1}{it-1}\\int_0^{+\\infty}e^{(it-1)x}x^{p-2}dx\\\\\\text{Car: } \\underbrace{e^{itx}}_{\\text{bornee}, \\vert e^{itx}\\vert = 1}&amp;amp;e^{-x}x^{p-1}\\to_{x\\to+\\infty}0\\\\I_{p-1} &amp;amp;= -\\frac{p-1}{it-1}I_{p-2}\\text{ } \\forall p\\ge 2\\\\I_{p-2} &amp;amp;= -\\frac{p-2}{it-1}I_{p-3}\\\\&amp;amp;.\\\\&amp;amp;.\\\\&amp;amp;.\\\\I_2 &amp;amp;= -\\frac{2}{it-1}I_1\\\\I_1 &amp;amp;= -\\frac{2}{it-1}I_1\\\\\\end{aligned}\\] En faisant le produit:\\[\\begin{aligned}I_{p-1} &amp;amp;= \\frac{(-1)^{p-1}(p-1)!}{(it-1)^p}I_0\\\\&amp;amp;= \\frac{(-1)^p(p-1)!}{(it-1)^p}\\\\\\phi_X(t) &amp;amp;= \\frac{1}{\\Gamma(p)}I_{p-1}=\\frac{(-1)^p}{(it-1)^p} \\\\&amp;amp;= (1-it)^{-p}\\end{aligned}\\] 2.On veut la fonction caracteristique de $\\frac{X-p}{\\sqrt{p}}$. Or, dâ€™apres le cours:\\[\\phi_{\\frac{X-m}{\\sigma}}(t) = e^{-\\frac{itm}{\\sigma}}\\phi_X(\\frac{t}{\\sigma})\\] Ici $m=p$ et $\\sigma=\\sqrt{p}$ Donc:\\[\\begin{aligned}\\phi_{\\frac{X-p}{\\sqrt{p}}} &amp;amp;= e^{-\\frac{itp}{\\sqrt{p}}}\\phi_X(\\frac{t}{\\sqrt{p}})\\\\\\Rightarrow \\phi_{\\frac{X-p}{\\sqrt{p}}} &amp;amp;= e^{-\\frac{itp}{\\sqrt{p}}}(1-\\frac{it}{\\sqrt{p}})^{-p}\\end{aligned}\\] 3.Montrons que $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$\\[\\ln(\\phi_{\\frac{X-p}{\\sqrt{p}}}) = -\\frac{itp}{\\sqrt{p}}-p\\ln(1-\\frac{it}{\\sqrt{p}})\\] Or $\\ln(1+x)\\sim x-\\frac{x^2}{2}$ au voisinage de 0. Donc:\\[\\begin{aligned}\\ln(\\phi_{\\frac{X-p}{\\sqrt{p}}})&amp;amp;\\simeq-\\frac{itp}{\\sqrt{p}}-p(-\\frac{it}{\\sqrt{p}} + \\frac{t^2}{2p}) \\text{ pour p au voisinage de } +\\infty\\\\&amp;amp;\\simeq -\\frac{itp}{\\sqrt{p}}+\\frac{itp}{\\sqrt{p}}+\\frac{t^2}{2} = \\frac{t^2}{2} \\text{ pour p au voisinage de } +\\infty\\\\\\Rightarrow \\phi_{\\frac{X-p}{\\sqrt{p}}}&amp;amp;\\simeq e^{-\\frac{t^2}{2}} \\text{ : fonction caracteristique de } N(0,1)\\end{aligned}\\] Conclusion: $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$" }, { "title": "PRST: Feuille 1 - Exercice", "url": "/cours/posts/prst_first_exercise/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-02-24 15:30:00 +0100", "snippet": "Lien de la note HackmdExercice 4Demontrer les proprietes suivantes dans le cas discret: Soient $X$ et $Y$ deux variables aleatoires definies sur un meme espace $\\Omega$ et $\\lambda$ un nombre reel. Solution Soit $\\omega_1,â€¦,\\omega_n$ les issues i.e. $\\Omega = {\\omega_1;â€¦;\\omega_n}$\\[\\begin{aligned}E(X\\times Y) &amp;amp;= \\sum_{\\omega\\in\\Omega}(X(\\omega) + Y(\\omega))\\\\&amp;amp;= \\underbrace{\\sum_{\\omega\\in\\Omega} p(\\omega)X\\vert\\omega\\vert}_{=E(X)} + \\underbrace{\\sum_{\\omega\\in\\Omega} p(\\omega)Y\\vert\\omega\\vert}_{=E(Y)}\\\\&amp;amp;= E(X) + E(Y)\\end{aligned}\\]\\[\\begin{aligned}E(\\lambda X) &amp;amp;= \\sum_{\\omega\\in\\Omega}p(\\omega)\\lambda X(\\omega)\\\\&amp;amp;= \\lambda\\sum_{\\omega\\in\\Omega}p(\\omega)X(\\omega)\\\\&amp;amp;= \\lambda E(X)\\end{aligned}\\]Exercice 3Determiner la loi $\\mathcal B(3, \\frac{1}{3})$ Solution $P(X = x_1) = \\binom{3}{0}\\times\\frac{1}{3}^0\\times\\frac{2}{3}^3 = \\frac{8}{27}$ $P(X = x_2) = \\binom{3}{1}\\times\\frac{1}{3}^1\\times\\frac{2}{3}^2 = \\frac{4}{9}$ $P(X = x_3) = \\binom{3}{2}\\times\\frac{1}{3}^2\\times\\frac{2}{3}^1 = \\frac{2}{9}$ $P(X = x_4) = \\binom{3}{3}\\times\\frac{1}{3}^3\\times\\frac{2}{3}^0 = \\frac{1}{27}$ $P(X)$ $\\frac{8}{27}$ $\\frac{4}{9}$ $\\frac{2}{9}$ $\\frac{1}{27}$ $X$ $x_1$ $x_2$ $x_3$ $x_4$ Exercice 14Soit $X$ une variable aleatoire suivant une loi geometrique. Montrer que $P(X\\gt n+k\\vert X\\gt k) = P(X\\gt n)$ pour tous entiers naturels $k$ et $n$.Nous dirons que la loi geometrique est sans memoire. Solution Soient $n$ et $k$ deux entiers naturels.\\[\\begin{aligned}P(X\\gt n) &amp;amp;= \\sum_{k\\gt n} pq^{k-1}\\\\&amp;amp;= pq^n + pq^{n+2} +...\\\\&amp;amp;= pq^n(1+q+q^2+...)\\end{aligned}\\] Or $\\sum_{k\\ge0}q^k=\\frac{1}{1-q}$ pour $0\\le q\\lt1$ Dâ€™ou:\\[P(X\\gt n) = pq^n\\times\\frac{1}{1-q} = pq^n\\times\\frac{1}{p} = q^n\\] Ainsi:\\[P(X\\gt n+k\\vert X\\gt k) = \\frac{P(\\{X=n+k\\}\\cap\\{x\\gt k\\})}{P(X\\gt k)}\\] Or ${X=n+k}\\cap{x\\gt k} = {X\\gt n+k}$ Dâ€™ou: \\(P(X\\gt n + k) = \\frac{P(X\\gt n + k)}{P(X\\gt k)} = \\frac{q^{n+k}}{q^k} = q^n = P(X\\gt n)\\)Exercice 6Considerons une variable aleatoire $X$ suivant une loi de Poisson de parametre 3 Calculer $P(X=10)$ Calculer $E(X)$ et $V(X)$ Solution \\(P(X=10) = e^{-3}\\times\\frac{3^{10}}{10!}\\\\E(X) = V(X) = 3\\)Exercice 11La variable aleatoire $U$ suit une loi uniforme sur lâ€™intervalle $[2;5]$.Calculer $P(U)\\in[2;3]$ et $E(U)$ Solution $P(U) = \\frac{1}{3}$" }, { "title": "PRST: Les differentes lois", "url": "/cours/posts/prst_first_class/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-02-24 14:30:00 +0100", "snippet": "Lien de la note HackmdSyllabus Rappel sur les notions de probas elementaires Rappel sur les variables scalairesGeneralites Etude dâ€™experiences aleatoires Experience aleatoire: experience dont on ne peut prevoir lâ€™issue a lâ€™avance mais dont on connait toutes les issues possibles Alea vient du latin alea qui est un jeu de desSituation elementaire $n$ issues $\\omega_1,â€¦, \\omega_n$ univers $\\Omega={\\omega_1,â€¦, \\omega_n}$ Proba dâ€™occurence associee $p_1,â€¦, p_n$ loi de proba: donnees des $p_i Les probas $p_i$ sont positives et verifient: $p_1+â€¦+p_n = 1$ evenements: sous-ensemble de $\\Omega$ Probabilite dâ€™un evenements: somme des probas des issues qui le realiseExemple dâ€™experience aleatoire: traverser la route et voir si on se fait ecraser ou non (Alexandre tu vas bien ?) $\\rightarrow$ experience de Bernoulli a 2 issuesQuelles experiences aleatoire en informatique ?La duree de vie dâ€™un composant electroniqueProprietes equiprobabilite: toutes les issues ayant la meme proba exercice: proposer une situation qui nâ€™est pas equiprobable $A\\cap B$: ensemble des issues qui realisent simultanement $A$ et $B$ $A\\cup B$: ensmeble des issues qui realisent au moins un des 2 evenemenentsConditionnement Soient A et B evenements (supposons $P(A) \\neq 0$ et $P(B) \\neq 0$) $P_A(B) = \\frac{P(A \\cap B)}{P(A)}$ Formule de Bayes: $P_B(A) = \\frac{P_A(B)\\times P(A)}{P_A(B)\\times P(A) + P_{\\overline{A}}(B) \\times P(\\overline{A})}$ $P(B) = P_A(B)\\times P(A)+P_A(B)\\times P(\\overline{A})$Demonstration\\(\\begin{aligned}P_B(A) &amp;amp;= \\frac{P(A \\cap B)}{P(B)}\\\\&amp;amp;= \\frac{P_A(B)P(A)}{P(B)}\\\\&amp;amp;= \\frac{P_A(B)P(A)}{P_A(B)\\times P(A) +P_A(B)\\times P(\\overline{A})}\\end{aligned}\\) Câ€™est une proba a posteriori, cad apres que lâ€™experience ait eu lieu.VA discrete VA $X :$ fonction definie sur $\\Omega$ et a valeurs dans $\\mathbb R$ $X$ peut prendre les valeurs $x_1,â€¦, x_n$ $\\Omega$ sera â€œoublieâ€ et on se concentrera sur les probas $p_i := P({\\omega\\in\\Omega\\vert X(\\omega) = x_i}):= P(X=x_i)$ Loi dâ€™une variable aleatoire: donnee par des reels $P(X=x_i)$ exercice: modeliser le gain a un jeu de Pile ou Face a lâ€™aide dâ€™une VA (gain de 100 euros si le â€œPileâ€ et perte de 80 euros si â€œFaceâ€) valeurs: 100 et -80 ex: si la piece tombe sur 2 on gagne 100 euros, sinon on en perde 80 $p_g = \\frac{1}{6}$ $p_p = \\frac{5}{6}$ Cf. Exercice 4Prenons Clara et Nizar en cobayent avec leurs numero prefere Â  Clara Nizar Â  1 -10 30 20 2 50 -20 30 3 -10 30 20 4 -10 -20 -30 5 50 30 80 6 -10 -10 -20 $x_1 = -10$ $x_2 = 50$ $y_1 = -20$ $y_2 = -10$ $y_3 = 30$ Attention, la definition des reels $p_i$ a change ! Esperance: $E(X) = \\sum_{i=1}^np_i(x_i-\\overline x)^2$ Variance: $V(X) = E(X - E(X)^2) = E(X^2) - E(X)^2$Loi de Bernoulli VA $X$ pouvant prendre les valeurs 0 et 1 proba de prendre la valeur 1 notee $p$ par consequent: $P(x=0)=1-p$ $E(X) = p\\times1 + (1-p)\\times 0 = p$ et $V(X) =E((X - E(X)^2)) = p(1-p)$ Loi notee $B(p)$Loi binomial de parametre $n$ et $p$ some de $n$ variables independantes suivant une loi $B(p)$ Nombre de succes apres $n$ repetitions dâ€™une experience de Bernouilli VA $X$ pouvant prendre les valeurs entieres comprises entre 0 et $n$ $P(X=k) = \\binom{n}{k}p^k(1-p)^{n-k}$ pour $k\\in{0,â€¦,n}$ Loi notee $B(n,p)$ $\\binom{n}{k}$: coefficient binomial $E(X) = np$ et $V(X) = np(1-p)$ $\\binom{4}{0} = 1$ $\\binom{4}{1} = 4$ $\\binom{4}{2} = 6$ $\\binom{4}{3} = 4$ $\\binom{4}{4} = 1$Comment trouver de maniere maths ?On utilise le triangle de Pascal $\\binom{6}{3} = 20$ $\\binom{3}{2} = 3$Quels sont les elements remarquables sur le triangle de Pascal ? $\\binom{n}{k} = \\binom{n}{n-k}$ $\\binom{n}{0} = \\binom{n}{n} = 1$ $\\binom{n}{1} = \\binom{n}{n - 1} = n$ Cf. Exercice 3Loi binomial negative de parametre $n$ et $p$ aussi appelee loi de PascalLoi geometrique de parametre p nombre dâ€™essais avant le premier succes dans une repetition de tirages inde de Bernoulli $p$ : probabilite de â€œSuccesâ€ $X$ peut prendre toutes les valeurs entieres hormis 0 $P(X=k)=pq^{k-1}$ ou $q=1-p$ $E(X) = \\frac{1}{p}$ et $V(X)=\\frac{q}{p^2}$ Loi notee $G(p)$ Câ€™est une loi sans memoire.Quâ€™est-ce que ca veut dire ? La loi geometrique est â€œsans memoireâ€, cad que les evenements passes nâ€™influent pas les evenements futurs. Cf. Exercice 14 Les 2 grandes lois sans memoire sont les lois: exponentielle geometrique Loi Poisson de parametre $\\lambda$ $X$ peut prendre toutes les valeurs entieres $\\lambda$ parametre strictement positif $P(X=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$ $E(X) = \\lambda$ et $V(X) = \\lambda$ loi notee $P(\\lambda)$ Cf. Exercice 6Cadre $X$ definie sur lâ€™univers $\\Omega$ et a valeurs dans $\\mathbb R$ ou dans un intervalle $I$ $P(X\\in[a;b]) = \\int_a^bf(x)dx$ fonction $f$ appelee la densite de la variable aleatoire $X$ Pour un reel $x$ donne: $P(X=x)=0$Densite de probabilite 2 conditions a connaitre $f(x)\\ge0$ pour tout reel $x\\in I$ $\\int_If(x)dx = 1$ (lâ€™intervalle peut etre $\\mathbb R$)Fonction de repartition Soit $X$ une variable aleatoire $F_X(x) := P(X\\le x) = \\int_{-\\infty}^{x}f(t)dt$ Fonction de survie: $R_X(x) := P(X\\gt x) = 1 - F_X(x)$$\\int_0^{+\\infty}e^xdx$ a un sens dans $[0; +\\infty]$Esperance formule analogue au cas discret si $\\int_f\\vert x\\vert f(x)dx\\lt+\\infty$Variance Si $\\int_fx^2\\vert f(x)\\vert dx\\lt+\\infty$ la VA $X$ est dite de carre integrable $V(X) = \\int_f(x-E(X))^2f(x)fx$ est bien definie $V(X) = E(X^2) - E(X)^2$ (theoreme de Koenig-Huyghens) $V(aX) = a^2V(X)$Pour $X$ et $Y$ Tout depend de la dependance des variables, si $X$ et $Y$ sont independantes: $E(XY) = E(X)E(Y)$Loi uniforme sur lâ€™intervalle $[a;b]$ $f(x) = \\frac{1}{b-a}$ pour $x\\in [a;b]$ et $f(x) = 0$ pour $x\\not\\in[a;b]$ $P(X\\in[c;d]) = \\frac{d-c}{b-a}$ si $a\\le c \\le c\\le d \\le b$ et $a\\lt b$ $E(X) = \\frac{a+b}{2}$ et $V(X) = \\frac{(b-a)^2}{12}$ Exercice: demontrer ce resultat puis calculer la fonction de reparatition associes Notee $U([a;b])$ CF. Exercice 11Loi exponentielle de parametre $\\lambda\\gt 0$ $f(x) = \\lambda e^{-\\lambda x}$ pour $x\\ge 0$ et $f(x) = 0$ pour $x\\lt0$ $E(X)=\\frac{1}{\\lambda}$ et $V(X) = \\frac{1}{\\lambda^2}$ $F(x) = 1-e^{-\\lambda x}$ pour $x\\ge 0$ et $F(x) = 0$ sinon $R(x) = e^{-\\lambda x}$ pour $x\\ge 0$ etLoi exponentielle Loi notee $\\varepsilon(\\lambda)$ duree de vie dâ€™un phenomene sans memoire $\\forall s\\gt 0, \\forall t \\gt 0, P_{T\\gt t}(T\\gt s + t) = P(T\\gt s)$Loi normale centree reduite $f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$ pour $x\\in\\mathbb R$ $E(X) = 0$ et $V(X) = 1$ Loi notee $N(0;1)$ $P(X\\le0)=P(X\\ge0) = 0.5$ $P(X\\le-a) = P(X\\ge a)$ $P(-196\\le X\\le 1.96)\\approx0.95$ et $P(-2,58\\le X\\le2.58)\\approx 0.99$ Loi notee $N(0,1)$Loi normale de parametre $\\nu$ et $\\sigma$ Loi notee $N(\\nu,\\sigma^2)$ $X$ suit une loi $N(\\nu,\\sigma^2)$ si $Y = \\frac{X-\\nu}{\\sigma}$ suit une loi normale centree reduite $P(\\nu-\\sigma\\le X\\le \\nu+\\sigma)\\approx0.68$ $P(\\nu-2\\sigma\\le X\\le \\nu+2\\sigma)\\approx0.95$ $P(\\nu-3\\sigma\\le X\\le \\nu+3\\sigma)\\approx0.997$" }, { "title": "DBRE: Introduction", "url": "/cours/posts/dbre_introduction/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-02-24 11:00:00 +0100", "snippet": "Lien de la note HackmdDBRE: Introduction Le coeur de la protection dâ€™un logiciel se fait via les droits dâ€™auteurs. On nâ€™a aucune solution dont on puisse etre sur a 100%.La solution la plus probable est celle retenue par les juges. Câ€™est pas bon pour la securite juridique mais on ne peut pas faire autrementPropriete intellectuellesPour quâ€™une invention soit brevetable, il faut que lâ€™inventeur ait une activitee inventive, cad trouver une solution pas evidente pour â€œlâ€™homme du metierâ€. Lâ€™inventivite et lâ€™evidence sont subjectifs.On doit aussi avoir un peu de personnalite de lâ€™auteur, que lâ€™oeuvre soit originale $\\rightarrow$ subjectifFair use Le â€œfair useâ€ nâ€™a pas dâ€™equivalents en droit francais.Une autre difficulte vient de la recherche constante du compromis entre â€œaccordons suffisemment de droits pour que les gens creentâ€ mais â€œpas trop pour pas bloquerâ€.Exceptions Dans les proprietes intellectuelles, il y a des tonnes dâ€™exceptions.Le but est de contrebalancer un monopole necessaire pour retablir un equilibre, mais cela cause des incertetitudes juridiques.Exemple Apres le premier sequencage du genome humain, le president des US a precise quâ€™il nâ€™etait pas brevetable car ce sont des genes (de meme avec le genome du COVID-19)Il est tout a fait possible de depose un vaccin libre de droits (mais cela ne se fait pas car pas viable economiquement)Certaines personnes ne deposent pas de brevets car lâ€™invention peuvent vite devenir obsolete ou pour mettre lâ€™invention a disposition de la communaute.Monsanto nâ€™a pas brevete du mais, mais une facon de le cultiverDiffusion dâ€™une oeuvre Selon de la ou une oeuvre est diffusee, ce ne sont pas les memes droits qui sâ€™appliquent $\\rightarrow$ cela ne depend pas de la nationalite de lâ€™auteur.De meme pour le droit du travail.Exemple Nous utilisons teams conformement aux droits dâ€™auteur francais. Si on vend des chaussures sur Internet, quâ€™on sâ€™addresse au public dâ€™un pays, quâ€™on livre la-bas, etc. on est soumis au droit de consommation du pays en question" }, { "title": "ASE2: TD 1", "url": "/cours/posts/ase2_exercices_convergence_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-02-24 10:00:00 +0100", "snippet": "Lien de la note HackmdExercice 1Determiner les fonctions caracteristiques dans les cas suivants:$X$ suit la loi binomiale $B(n,p)$ Solution $X$ suit la loi $B(n,p)$.$X$ est une somme independante de variables de Bernoulli $B(p)$.\\[X = \\sum^n_{j=1}X_j\\] ou $X_j\\to B(p) \\forall j = 1,â€¦, n$ Dâ€™apres le cours, on a calcule la fonction caracteristique de Bernouilli $\\phi_{x_j}(t) = q + pe^{it}$ avec $q = 1-p$ or les $X_i$ sont independantes\\[\\phi_{\\sum_{j=1}^{k}X_j} = \\Pi^k_{j=1}\\phi_{X_j}(t) = (q+pe^{it})^n\\] Remarque: Comme 2e methode on peut calculer directement $\\phi_X(t)$, $X\\to B(n,p)$\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\sum^n_{k=0}e^{itk}P(X=k)\\\\&amp;amp;= \\sum^n_{k=0}e^{itk}\\binom{n}{k}p^k(1-p)^{n-k} \\\\&amp;amp;= \\sum^n_{k=0}\\binom{n}{k}(pe^{it})^k(1-p)^{n-k}\\\\&amp;amp;= (1-p+pe^{it})^n \\text{ (Netwon)}\\\\&amp;amp;= (q+pe^{it})^n\\end{aligned}\\]$X$ suit la loi de Poissons $P(\\lambda)$ Solution $X\\to P(\\lambda)$ Poisson de parametre $\\lambda$.\\[\\begin{aligned}P(X=k) &amp;amp;= e^{-\\lambda}\\frac{\\lambda^k}{k!} \\forall k\\in\\mathbb N\\\\\\phi_X(t) &amp;amp;= \\sum_{k=0}^{+\\infty}e^{itk}P(X=k) = \\sum_{k=0}^{+\\infty}e^{itk}e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\&amp;amp;=e^{-\\lambda}\\sum_{k=0}^{+\\infty}\\frac{(\\lambda e^{it})^{k}}{k!}\\\\\\end{aligned}\\] Rappel: $\\sum_0^{+\\infty}\\frac{x^k}{k!} = e^x$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= e^{-\\lambda}\\exp(\\lambda e^{it})\\\\&amp;amp;= \\exp(-\\lambda+\\lambda e^{it})\\end{aligned}\\]$X$ suit la loi uniforme $U[-a,a]$ Solution $X\\to U_{[-a, a]}$ (Loi uniforme sur $[-a, a]$)Sa densite est:\\(f(x)=\\begin{cases} \\frac{1}{2a} &amp;amp;\\forall x\\in [-a, a]\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\) Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\int_{\\mathbb R}e^{itx}f(x)dx = \\frac{1}{2a}\\int_{-a}^ae^{itx}dx\\\\&amp;amp;= \\frac{1}{2a}\\biggr[\\frac{e^{itx}}{it}\\biggr]^a_{-a} = \\frac{1}{2a}\\biggr(\\frac{e^{ita} - e^{-ita}}{it}\\biggr)\\\\&amp;amp;\\Rightarrow \\phi_X(t) = \\frac{2i\\sin(at)}{2ait} = \\frac{sin(at)}{at}\\end{aligned}\\]$X$ suit la loi normale $N(0,1)$ Solution $X\\to N(0,1)$ (Loi normale centree reduite)En utilisant la formule de Mac-Laurin:\\[\\phi_X(t) = \\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}i^kE(X^k)\\] or $X\\to N(0,1)$ $E(X^k) = 0$ si $k$ impair et $E(X^{2k}) = \\frac{(2k)!}{2^kk!}$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\sum_{k=0}^{+\\infty}\\frac{(-\\frac{t^2}{2})^k}{k!} \\\\&amp;amp;= e^{-\\frac{t^2}{2}}\\end{aligned}\\]Exercice 2Soit $X_n$ une suite de variables aleatoires de densite $f(x)=\\frac{ne^{-nx}}{(1+e^{-nx})^2}$.Montrer que $X_n\\to^P_{n\\to+\\infty}0$ Solution $X_n$ suite de VA $f_n(x) = \\frac{ne^{-nx}}{(1+e^{-nx})^2}$ On veut montrer que $X_n\\to^P_{n\\to+\\infty}0$\\[\\begin{aligned}P(\\vert X_n\\vert\\gt\\varepsilon) &amp;amp;= 1 - P(\\vert X_n\\vert\\le\\varepsilon)\\\\&amp;amp;= 1 - P(-\\varepsilon\\le X_n\\le\\varepsilon)\\\\&amp;amp;= 1 - \\int_{-\\varepsilon}^{\\varepsilon}f_n(x)dx\\\\&amp;amp;= 1-\\int_{-\\varepsilon}^{\\varepsilon}\\frac{ne^{-nx}}{(1+e^{-nx})^2}dx\\\\&amp;amp;= 1 - \\biggr[\\frac{1}{1+e^{-nx}}\\biggr]_{-\\varepsilon}^{\\varepsilon} = 1-\\frac{1}{1+e^{-n\\varepsilon}}+\\frac{1}{1+e^{n\\varepsilon}}\\\\\\lim_{n\\to+\\infty}P(\\vert X_n\\vert\\gt\\varepsilon) &amp;amp;= 1- 1 + 0 =0\\\\\\end{aligned}\\\\\\] Donc $X_n\\to^{P}_{n\\to+\\infty}0$" }, { "title": "ASE2: Convergence et estimation - 1", "url": "/cours/posts/ase2_convergence_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-02-24 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroduction Lâ€™estimation: on va considerer une population qui obeit a une loi de probabilite avec un parametre $\\theta$ inconnu.Lâ€™objectif de lâ€™estimation câ€™est estimer le parametre. On preleve un echantillon (suite de variables aleatoires independantes $X_1$, $X_2$,â€¦, $X_n$ suivant la meme loi que la population $X$) dans cette population, on va construire un estimateur destine a converger vers le parametre $\\theta$. Un estimateur est une fonction $T = f(X_1, X_2, â€¦, X_n)$ de notre echantillon.Qualites de lâ€™estimateur: Etre convergent Etre precis Plus la variance est minimale, plus on a un estimateur precis Etre efficacePour etudier la convergeance, on va voir 3 types: Convergence en proba Convergence quadratique Convergence discreteRappels de la loi Gamma et la loi Normale On dit quâ€™une variable aleatoire positive $X$ suit une loi gamma de parametre r, notee $\\gamma_r$ si sa densite est donnee par \\(f(x) = \\frac{1}{\\Gamma(r)}\\exp(-x)x^{\\gamma - 1}\\)Avec $\\Gamma(x) = \\int^{+\\infty}_0\\exp(-t)t^{x-1}dt$ (fonction Gamma) definie pour $x\\gt 0$Propriete de la fonction Gamma $\\Gamma(x+1)=x\\Gamma(x)$ (integration par partie) $\\Gamma(1)=1$ $\\Gamma(n+1)=n!$ $\\Gamma(k+\\frac{1}{2}) = \\frac{1.3.5â€¦..(2k -1)}{2^k}\\Gamma(\\frac{1}{2})$ $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$Esperance de la loi $\\gamma_r$: soit $X$ une variable aleatoire suivant la loi gamma de parametre r.On a:\\(E(x)=\\frac{1}{\\Gamma}\\int^{+\\infty}_0 t^T\\exp(-t)dt = \\frac{\\Gamma(r+1)}{\\Gamma(r)} = r\\)Variance de la loi $\\gamma_r : V(X) = E(X^2) - E^2(X)$\\(E(X^2) = \\frac{1}{\\Gamma(r)}\\int^{+\\infty}_0 t^2\\exp(-t) t^{r-1}dt = \\frac{1}{\\Gamma(r)}t^{r+1}\\exp(-t)dt = \\frac{\\Gamma(r+2)}{\\Gamma(r)} = r(r + 1)\\)Donc $V(X) = r(r + 1) - r^2 = r$Loi Normale de parametre $(m, \\sigma)$On dit quâ€™une variable aleatoire $X$ suit la loi normale notee $N(m, \\sigma)$ si sa densite est $f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}(\\frac{x-m}{\\sigma})^2)$ou: $m=E(X)$ $\\sigma=\\sqrt{V(X)}$ (ecart-type)Avec le changement de variable $U=\\frac{X-m}{\\sigma}$ (variable normale centree reduite), la densite de $U$ est $f(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}u^2)$.Montrons que $V(U) = 1$On a $V(U) = E(U^2) = \\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}}u^2\\exp(-\\frac{1}{2}u^2)du = \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}u^2\\exp(-\\frac{1}{2}u^2)du$.Posons: $t = \\frac{u^2}{2}$ ut = udu\\(\\begin{aligned}V(U) &amp;amp;= \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}2t\\exp(-t)\\frac{dt}{\\sqrt{2t}}\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\int^{+\\infty}_{0}t^{\\frac{1}{2}}\\exp(-t)dt\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\Gamma(\\frac{3}{2})\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\frac{1}{2}\\Gamma(\\frac{1}{2})\\end{aligned}\\)Donc $V(U) = \\frac{1}{\\sqrt{\\pi}}\\sqrt{\\pi} = 1$Moments de la loi normale centree reduiteSoit $U$ une variable normale centree reduite, on appelle moment dâ€™ordre $k$ de $U$: $u_k = E(U^k)$ Si $k = 2p + 1$ alors $u_{2p+1} = 0$ (car fonction impaire) Si $k = 2p$ alors $u_{2p} = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}u^{2p}\\exp(-\\frac{1}{2}u^2)du = \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}u^{2p}\\exp(-\\frac{1}{2}u^2)du$Posons: $t= \\frac{u^2}{2}$ $dt=udu$\\(\\begin{aligned}u_{2p} &amp;amp;= \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_0(2t)^p\\exp(-t)\\frac{dt}{\\sqrt{2\\pi}}\\\\&amp;amp;=\\frac{2^p}{\\sqrt{\\pi}}\\int^{+\\infty}_0t^{p-\\frac{1}{2}}\\exp(-t)dt\\\\&amp;amp;=\\frac{2^p}{\\sqrt{\\pi}}\\Gamma(p + \\frac{1}{2})\\end{aligned}\\)Or $\\Gamma(p+\\frac{1}{2})=\\frac{1.3.5â€¦(2p-1)}{2^p}$ et $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$Donc $u_{2p}=1.3.5â€¦..(2p-1) = \\frac{(2p)!}{2^pp!}$Fonctions caracteristiquesDefinition la fonction caractÃ©ristique dâ€™une variable alÃ©atoire rÃ©elle $X$ est la transformÃ©e de Fourier de sa loi de probabilitÃ©. elle est notÃ©e $\\phi_x(t)$ et on a $\\phi_x=E(\\exp(itX))$ ($i$ complexe)Si $X$ est une variable a densite ($X$ est une VA continue de densite $f$) alors:\\(\\phi_X(t)=\\int_{\\mathbb R}\\exp(itx)f(x)dx\\)Si $X$ est une variable discrÃ¨te alors sa fonction caractÃ©ristique est:\\[\\phi_X(t) = \\sum_k\\exp(itk)P(X = k)\\]Proprietes $\\phi_{\\lambda X} = \\phi_X(\\lambda t)$ $\\forall \\lambda$ un scalaire $\\phi_{X+a}(t) = \\exp(ita)\\phi_X(t)$ Si $X$ est une variable aleatoire dâ€™esperance et dâ€™ecrat-type $\\sigma$ et $U = \\frac{X-m}{\\sigma}$\\[\\phi_{\\frac{X-m}{\\sigma}}(t) = \\phi_U(T) = \\exp(-\\frac{itm}{\\sigma})\\phi_X(\\frac{t}{\\sigma})\\]Remarquela fonction caractÃ©ristique se prÃªte bien aux additions de variables alÃ©atoires indÃ©pendantes :Si $X$ et $Y$ sont deux variables alÃ©atoires indÃ©pendantes alors\\[\\phi_{X+Y}(t)=\\phi_X(t)\\phi_Y(t)\\]En effet $\\phi_{X+Y}(t) = E(\\exp(it(X+Y))) = E(\\exp(itX)\\exp(itY))$Or $X$ et $Y$ sont indÃ©pendantes $E(\\exp(itX)\\exp(itY)) = E(\\exp(itX))E(\\exp(itY))$Donc $\\phi_{X+Y}(t) = \\phi_X(t)\\phi_Y(t)$PropositionSoit $X$ une variable alÃ©atoire de fonction de rÃ©partition $\\phi_X(t)$.On a: $\\phi_X(0) = 1$ $\\frac{d^k\\phi_X}{dt^k}(0) = \\phi_X^{(k)}(0) = i^kE(X^k)$DemoSupposons que $X$ est une variable continue de densitÃ© $f$On a $\\phi_X(t)=\\int_{\\mathbb R}\\exp(itx)f(x)\\Rightarrow\\phi_X(0) = \\int_{\\mathbb R}f(x)dx=1$ (car $f$ est une densitÃ©)En derivant $\\phi_X(t)$ par rapport a t: $\\phi_xâ€™(t)=i\\int_{\\mathbb R}x\\exp(itx)f(x)dx$ Si $t=0$, $\\phi_Xâ€™(0) = i\\int_{\\mathbb R}xf(x)dx=iE(X)$Si on dÃ©rive 2 fois, $\\phi_X^{(2)}(t)=\\int_{\\mathbb R}(ix)^2\\exp(itx)f(x)dx$ Pour $t = 0$, $\\phi_X^{(2)}(0) = (i)^2\\int_{\\mathbb R}x^2f(x)dx = -\\int_{\\mathbb R}x^2f(x)dx=-E(X^2)$En dÃ©rivant $k$ fois par rapport Ã  $t$: $\\phi_x^{(k)}(t)=\\int_{\\mathbb R}(ix)^k\\exp(itx)f(x)dx$ $\\phi_X^{(k)}(0) = (i^k)\\int_{\\mathbb R}x^kf(x)dx = i^kE(X^k)$ $\\forall k\\in\\mathbb N$Formule de Mac-Laurin Si $\\phi_X(t)$ est indÃ©finiment dÃ©rivable on a:\\(\\phi_x(t) = \\sum^{+\\infty}_{k=0}\\frac{t^k}{k!}i^kE(X^k)\\)Exemple 1Soit X une variable alÃ©atoire continue de densitÃ©:\\(\\begin{cases} f(x) = \\exp(-x) &amp;amp;\\text{si } x\\gt0\\\\ f(x) = 0 &amp;amp;\\text{sinon}\\end{cases}\\)Determiner la fonction caracteristique de $X$ Solution On a \\(\\begin{aligned}\\phi_X(t)&amp;amp;=\\int_{\\mathbb R}\\exp(itx)f(x)dx=\\int_{0}^{+\\infty}\\exp(itx)\\exp(-x)dx = \\int_{0}^{+\\infty}\\exp(-(1-it)x)dx\\\\&amp;amp;= \\int_{0}^{+\\infty}\\exp(-(1-it)x)dx = \\biggr[\\frac{-\\exp(-(1-it)x)}{(1-it)}\\biggr]^{+\\infty}_{0} = \\frac{1}{1-it}\\end{aligned}\\) car $\\exp(-(1-it)x) = \\exp(-x)\\exp(itx)\\to 0$ lorsque $x\\to +\\infty$Puisque $\\exp(itx)$ est bornee de module 1 et $\\exp(-x)\\to 0$ quand $x\\to +\\infty$Exemple 2DÃ©terminer la fonction caractÃ©ristique de la loi de Bernoulli de paramÃ¨tre $p$ Solution Soit X une variable de Bernoulli : $X=1$ avec la probabilite $p$ $X=0$ avec la probabilitÃ© $1-p$ $X$ Ã©tant discrÃ¨te, donc sa fonction caractÃ©ristique est:\\(\\phi_X(t)\\sum_k\\exp(itk)P(X=k) = \\sum_{k=0}^1\\exp(itk)P(X=k)=P(X=0)+\\exp(it)P(X=1)\\\\\\phi_X(t) = 1 - p + p\\exp(it) = q + p\\exp(it) \\text{avec } q =1 - p\\)Convergence des suites de variables aleatoires Une suite $X_n$ de variables alÃ©atoires Ã©tant une suite de fonctions il existe diverses faÃ§ons de dÃ©finir la convergence de $X_n$ dont certaines jouent un grand rÃ´le en statistiques.Convergence en probabiliteDefinition La suite $X_n$ converge en probabilitÃ© vers une variable alÃ©atoire $X$Si $\\forall\\varepsilon\\gt0, \\eta\\gt 0$ ( arbitrairement petits) il existe un entier $n_0$ tel que\\[\\forall n\\gt n_o \\Rightarrow P(\\vert X_n-X\\vert\\gt\\varepsilon)\\lt\\eta\\] Câ€™est-Ã -dire $P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$ On notera $(X_n)\\to^PX$ InÃ©galitÃ© de BienaymÃ©-Tchebychev:\\[P(\\vert X - E(X)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2} \\text{ , } \\forall\\varepsilon\\gt 0\\]RemarqueLorsque $E(X_n)\\to_{n\\to+\\infty}0$, il suffit de montrer que $V(X_n)\\to_{n\\to+\\infty} 0$ pour Ã©tablir la convergence en probabilitÃ© de la suite $(X_n)$ vers a.En effet dâ€™aprÃ¨s Tchebychev:\\(P(\\vert X_n-E(X_n)\\vert\\gt\\varepsilon)\\lt\\frac{V(X_n)}{\\varepsilon^2}\\to 0\\)Donc en passant a la limite:\\[\\lim_{n\\to+\\infty}P(\\vert X_n - a\\vert\\gt\\varepsilon) = 0\\\\ \\forall\\varepsilon\\gt0\\]Convergence en moyenne quadratiqueOn suppose que $E(\\vert X_n-X\\vert^2)$ existe.Definition On dit quâ€™une suite de variables alÃ©atoires $(X_n)$ converge en moyenne quadratique vers une variable X si\\[E(\\vert X_n-X\\vert^2)\\to_{n\\to+\\infty}0\\] On notera $(X_n)\\to^{m.q}X$Convergence en loiDefinition La suite $(X_n)$ converge en loi vers la variable $X$ de fonction de rÃ©partition $F$ si en tout point de continuitÃ© de $F$ la suite $(F_n)$ des fonctions de rÃ©partition des $(X_n)$ converge vers $F$, câ€™est-Ã -dire $\\lim_{n\\to+\\infty}F_n(x)=F(x)$ pour tout x point de continuitÃ© de F On noter $X_n\\to^LX$RemarquePour les variables discrÃ¨tes, la convergence en loi est Ã©quivalente Ã \\[\\lim_{n\\to+\\infty}P(X_n=k) = P(X=k)\\]TheoremeSi la suite des fonctions caractÃ©ristiques $\\phi_{x_n}(T)$ converge vers $\\phi_X(t)$ alors $(X_n)\\to^LX$Applications - Convergence en loi de la binomiale vers la loi NormaleThÃ©orÃ¨me (Moivre-laplace) Soit $(X_n)$ une suite de variables binomiales $B(n,p)$Alors $\\frac{X_n - np}{\\sqrt{npq}}\\to^LN(0,1)$ lorsque $n\\to+\\infty$DemonstrationLa fonction caractÃ©ristique de la loi $B(n,p)$ est:\\[\\begin{aligned} \\phi_{X_n}(t) &amp;amp;= (p\\exp(it)+1-p)^n \\text{ donc celle de } Y_n=\\frac{X_n-np}{\\sqrt{npq}} \\text{ est:}\\\\ \\phi_{Y_n} &amp;amp;=(p\\exp(\\frac{it}{\\sqrt{npq}})+1-p)^n\\exp(-\\frac{itnp}{\\sqrt{npq}})\\\\ Ln(\\phi_{Y_n}(t)) &amp;amp;= nLn(p(\\exp(\\frac{it}{\\sqrt{npq}})-1)+1) - \\frac{itnp}{\\sqrt{npq}}\\end{aligned}\\]On rappelle le dÃ©veloppement limitÃ© de lâ€™exponentielle Ã  lâ€™ordre 2: $\\exp(x) \\approx 1+x+\\frac{x^2}{2}$ (au voisinage de 0)\\[Ln(\\phi_{Y_n}(t)) \\approx nLn(p(\\frac{it}{\\sqrt{npq}} - \\frac{t^2}{2npq})+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle $Ln(1+x)\\approx x - \\frac{x^2}{2}$ (au voisinage de 0)Donc:\\[\\begin{aligned}Ln(\\phi_{Y_n}(t))&amp;amp;\\approx n[\\frac{pit}{\\sqrt{npq}}-\\frac{pt^2}{2npq}+\\frac{p^2t^2}{2npq}]-\\frac{itnp}{\\sqrt{npq}}\\\\&amp;amp;\\approx -\\frac{t^2}{2q} + \\frac{pt^2}{2q} = \\frac{t^2}{2q}(p-1)=-\\frac{t^2}{2}\\end{aligned}\\]En composant par lâ€™exponentielle:\\[Ln(\\phi_{Y_n}(t))\\approx\\exp(-\\frac{t^2}{2}) \\text{ caractÃ©ristique de la loi normale } N(0,1)\\]Conclusion: $\\frac{X_n-np}{\\sqrt{npq}}\\to^LN(0,1)$Remarque Lorsque $n$ est assez grand on peut donc approximer la loi Binomiale par la loi normale. On donne gÃ©nÃ©ralement comme condition $np$ et $nq\\gt5$Il convient cependant dâ€™effectuer la correction de continuitÃ© : on obtient donc une valeur approchÃ©e de $P(X=x)$ par la surface sous la courbe de densitÃ© de la loi normale $N(np,\\sqrt{npq})$ comprise entre les droites dâ€™abscisse $x-\\frac{1}{2}$ et $x+\\frac{1}{2}$\\[P(X=x)\\approx P(x-\\frac{1}{2}\\lt X\\lt x+\\frac{1}{2}) = P(\\frac{x-\\frac{1}{2}-np}{\\sqrt{npq}}\\lt\\frac{X-np}{\\sqrt{npq}}\\lt\\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}})\\]Et $P(X\\le x)\\approx P(\\frac{X-np}{\\sqrt{npq}}\\lt\\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}})$" }, { "title": "ISIM: Rendu photorealiste 2", "url": "/cours/posts/isim_rendu_photorealiste_2/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-22 11:00:00 +0100", "snippet": "Lien de la note HackmdLa RadiositeOn essaye dâ€™estimer la â€œradiositeâ€ de chaque element de la scene, câ€™est a dire la quantite dâ€™energie de chaque element emetâ€¦ $B_i$ la radiosite de la surface $i$ $E_i$ la quantite de lumiere emise par la surface $i$ $P_i$ la fraction de lumiere incidente qui est reflechie par la surface $i$ $F_{ij}$ la fraction de lumiere quittant la surface $i$ et atteignant la surface $j$\\[B_i = E_i + P_i\\sum_i(F_{ij}B_j)\\]Calcul des $F_{ij}$ par hemi-cubesOn projet un triangle, la partie bleue est la projection de ce triangle. Cela nous donne le niveau dâ€™energie recue par â€œpetits carresâ€. Ne permet pas directement de calculer une vue de la scene mais simplement lâ€™illumination globale Avantages: Prend mieux en compte les sources secondaires Calculee une fois pour toutes Inconvenients Tient compte de la diffusion Assez lourd Obligation dâ€™avoir un maillage (il faut discretiser les surfaces) Objets transparents ? Photon map Pre-calcul de lâ€™illumination de la scene Lancement des rayons lumineux depuis les sources et calcul des accumulations des photons Avantages: Permet de modeliser plus proprement les sources secondaires, les ombres portees (â€¦) et surtout les objets transparents (caustiques) Faire des ombres correctes sous les objets transparents Inconvenients Calculs Complexite Penible a coder Resultats: video manquante :(Ameliorations: Projection Maps Visual importance map (3-pass Technique) Shadow photons â€¦Path Tracing/Bidirectional Path Tracing Modelisation des proprietes de reflexion des surfaces: (Bidirectional reflectance distribution function BRDF) (idem pour la transmission) Si on a une surface et quâ€™on lance un laser, quâ€™elle est lâ€™energie ressortante en fonction de lâ€™angle dâ€™incidence? Solution pour resoudre lâ€™illumination BRDF: Biderectional reflectance distribution function (Reflectivite bidirectionnelle)Conservative:\\(\\int f_r(x,\\theta,\\theta_o)L_{input}(x, \\theta_i)\\vert\\theta_i.N_x\\vert\\delta w_0\\le 1\\)Reciprocite de Helmholtz:\\(f_r(x, \\theta_i, \\theta_o) = f_r(x,\\theta_o^{-1}, \\theta_i^{-1})\\) Mesuree Goniophotometer â€¦ Modele Blinn-Phong Cook-Torrance GGX â€¦ Principe du rendu:Path Tracing Avantages: Rendu realiste Convient bien aux scenes dâ€™exterieurs Prend bien en compte lâ€™apport des autres objets Rend les caustiques Possibilite de modeliser les effets (profondeur de champâ€¦) Inconvenients: len bruite (Il faut bcp dâ€™iterations pour converger) difficile pour scenes avec des petites sources lumineuse (ou sources cachees) Bidirection Path Tracing Amelioration du calcul du rendu Lancement des rayons depuis lâ€™observateur et depuis les sources Avantages: Facilite la recherche du chemin vers la source lumineuse Permet de modeliser les petites sources lumineusesPBGI: Point-Based Global Illumination Tres peu enseigne Beaucoup utilise dans lâ€™industrie du cinema Monster Academy: 1er long-metrage en raytracing La-haut: utiliser PBGI SFX de Pirates des Caraibes avec PBGI Methode pour estimer lâ€™illumination globales Avantages: Rapide Image non bruitee (pas dâ€™artefacts temporel) Inconvenients Pas aussi precis que le raytracing Difficile de gerer les effets miroir Approximation de la scene par nuage de points Un point - un disque de couleur Calcul de lâ€™illumination direct de la scene Approximation de la scene par nuage de points Un point = un disque de couleur Calcul de lâ€™illumination directe de la scene Regroupement des pointsCalcul de lâ€™illumiantion globale Calcul de la contribution des points sur un disque Pour les points eloignes Utilisation du cluster Pour les points proches Raytracing Pour les autres points Utilisation directe du disque Bilan et remarquesRendusRendu simpleRendu simple avec anti-aliasingRendu avec la radiositeRendu avec les photonsRendu avec la radiosite et les photonsRendu avec anti-aliasingBilan Raytracing Calcul de lâ€™illumination en fonction dâ€™un point de vue Calcul lâ€™illumination approximatif : gÃ¨re mal les objets transparents, les lumiÃ¨res secondaires, les ombres portÃ©esâ€¦ On peut combiner cet algorithme avec des techniques de calcul dâ€™illumination globale pour palier Ã  ces problÃ¨mes Radiosity Calcul lâ€™illumination globale GÃ¨re que la diffusion mais amÃ©liore lâ€™apport des lumiÃ¨res secondaires PhotonMap Calcul lâ€™illumination globale Plus diffcile Ã  mettre en Ã·uvre (implÃ©mentation, artÃ©factsâ€¦) GÃ¨re bien les objets transparents (caustiques) et Ã©ventuellement les ombres portÃ©es et les sources secondaires PathTracing GÃ¨re bien les objets transparents, les lumiÃ¨res secondaires, les ombres portÃ©es Calcul trÃ¨s long Risque dâ€™apparition de bruit PBGIRemarques sur lâ€™implementation Doit Ãªtre bien rÃ©flÃ©chie ParallÃ©lisation possible Utilisation du GPU possible â€¦ModelisationPour chaque â€œformeâ€ il faut Ãªtre capable de: calculer la normale en chaque point calculer lâ€™intersection avec une droite, Ã©ventuellement calculer les coordonnÃ©es de la textureCalcul des intersections : dans le repÃ¨re monde ou le repÃ¨reobjet ?Pour aller plus loin Textures Autres effets (Brouillard, Bleu atmosphÃ©rique, â€¦) â€¦ gÃ©nÃ©ration dâ€™anaglyphes (cyan et rouge (espacement $\\frac{1}{30} âˆ— f$ ))Post scriptumRaycasting Principe: On ne lance que les rayons depuis lâ€™observateur et on ne calculpas les rebondsâ€¦(Raytracing est une extension du raycasting ?)Wolfstein: On lance des rayons dans le plan!La longueur du rayon permet de conclure sur la hauteur du mur 1 rayon donne 1 colonne de lâ€™image + gestion des objetsAvanatages: Algorithme rapide On est loin du rendu photorÃ©alisteâ€¦" }, { "title": "TIFO: Codage, partie 2 - Histogramme", "url": "/cours/posts/tifo_codage_partie2/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8", "date": "2021-02-19 10:00:00 +0100", "snippet": "Lien de la note HackmdAnalyse globale de lâ€™imageHistogramme Recense les occurrences de chaque couleur Donne une information globale sur lâ€™image Permet la realisation de petits traitement globaux Peut etre calcule sur une image en couleur Calcul de lâ€™histogramme Code:histogramme: tableau initalise a 0image: l&#39;image sour forme d&#39;un vecteurfor (offset = 0; offset &amp;lt; sx*sy; ++offset) histogramme[image[offset]]++Quels information peut apport lâ€™histogramme Si une image est sur-exposee Si une image est sous-exposee Si une image manque de contrasteApplicationsAmelioration du contrasteApplication: modification du contraste a lâ€™aide de lâ€™histogrammeCorrection de lâ€™histogramme: Etirement $[min, max] \\to [0, \\text{borne_sup}]$ Fonction de correction: $f(x) = ax + b$ $a = \\frac{b_{sup} - b_{inf}}{max - min}$ $b = b_{inf} - ax$ Generalement $b_{inf} = 0$ Etirement du resultat Jâ€™ai bien augmente le contraste Jâ€™ai detruit une partie de lâ€™information On a sature des pixels, effacant des details Amelioration de lâ€™imageApplication: modification du contraste a lâ€™aide de lâ€™histogrammeimage: l&#39;image sous forme d&#39;un vecteurfor (offset = 0; offset &amp;lt; sx*sy; ++offset) image[offset] = f(image[offset])Tout depend du choix de f Fonction $\\log$ si $x\\neq 0$, $f(x)=\\frac{\\ln(x)}{\\ln{max}}*max$ si $x=0$, $f(x) = 0$ Lâ€™intervalle des zones sombres est augmentee Fonction $\\exp$ Lâ€™intervalle des zones claires est augmentee Lâ€™image est assombrie Attention aux plages de valeurs (exp(255)â€¦) Modification des couleurs de lâ€™imageApplication: calcul du negatif Fonction de correction: $f(x) = b_{sup} - x$Amelioration du contrasteApplication: amelioration du contraste a lâ€™aide de lâ€™histogramme cumule Calcul de lâ€™histogramme cumule\\(\\begin{cases} hc(x) = hc(x-1) + h(x) &amp;amp;\\text{pour } x\\gt 0\\\\ hc(x) = h(x) &amp;amp;\\text{pour } x = 0\\end{cases}\\) Essayer dâ€™uniformiser la repartition des niveaux de gris dans lâ€™histogramme Cela revient a essayer de rendre lâ€™histogramme cumule lineaire $f(x) = b_{sup} * \\frac{hc(x)}{nb_{pix}}$ Resultat:Histogramme et images couleurs Differentes manieres de calculer Globale Par plan Traitements: Independamment sur chaque canal Changement dâ€™espace et traitement uniquement dans le plan L ou V ApplicationsAmelioration du contraste Egalisation dâ€™histogramme de couleur Effectuer lâ€™egalisation sur chaque canal ? Donne de mauvais resultats en general (modification des couleurs) Solution: Changer dâ€™espace de representation Utilisation de HSV ? Egalisation uniquement sur la valeur Amelioration de lâ€™imageSpecification dâ€™histogramme Imposer la forme de lâ€™histogramme (comme pour lâ€™egalisation qui donne un histogramme plat) Indexation Distance entre histogrammes Comparaison dâ€™images Segmentation automatique en plan de sequences Difference entre images consecutives Distances Bin-by-bin distances Distances de Hellinger Bhattacharyya â€¦ Cross-bin distances Earth Moverâ€™s Distance â€¦ Diminution du nombre de couleurs Pourquoi diminuer le nombre de couleurs? Simplifier lâ€™image Diminuer lâ€™espace necessaire de stockage Focaliser sur les elements qui nous interessent Effet artisitique Pourquoi plus precsiement passer de la couleur aux niveaux de gris ? Traitement de la couleur pas toujours aisee Plusieurs canaux Pas vraiment de relation dâ€™ordre utilisable avec la couleur Pourquoi plus precisement passer en noir et blanc ? Focaliser sur les elements qui nous interessent Separation fond/forme (O.C.R., â€¦) Objectif Reduire le nombre de couleurs utilisees tout en conservant le plus possible une image proche de lâ€™originaleAlgorithme Mediane cut Basee sur lâ€™etude de lâ€™histogramme Diffusion de lâ€™erreur Adoucit certaines erreurs pour la visualisation Median cut algorithm Reduction du nombre de couleurs Construction de lâ€™histogramme des couleurs Elimination des extremites vides Decoupage du prallelepipede restant en 2 sous-blocs contenant autant de points Pour chaque sous bloc, recommencer jusquâ€™a avoir autant de sous blocs que de couleurs souhaitees Trouver pour chaque partie, une couleur representante Diffusion de lâ€™erreurLe but est de compenser lâ€™erreur commise sur un pixel en propageant cette erreur sur les pixels voisins\\(\\text{FloydSteinberg:}\\\\\\begin{matrix} 12 &amp;amp; 15 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\)Ex: on fait une erreur en substituant le 12 par son representant, on propage la difference entre 12 et son representant sur son voisin 15 On remplace la couleur du pixel considere par le representant\\(\\text{FloydSteinberg:}\\\\\\begin{matrix} &amp;amp; 15 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\)\\(\\begin{matrix} &amp;amp; 21 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\) On calcul lâ€™erreur commise par cette substitution en faisant la difference entre la vraie couleur et la couleur de remplacement: on trouve une erreur pour chaque canal.\\(+6\\) On repartie lâ€™erreur estimee sur les pixels voisins Les voisins en haut et a droite participent plus que les voisins en diagonales Â  $X$ $-7$ â€¦ $-3$ $-5$ $-1$ â€¦ \\[\\text{FloydSteinberg:}\\\\\\underline{\\begin{matrix} &amp;amp; 21 &amp;amp; 11 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 64 &amp;amp; 20 &amp;amp; 25 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}}\\] Ce dernier tableau etait recommande par FloydSteinberg pour la propagation de lâ€™erreur. Â  X 7/16 3/16 5/16 1/16 Resultats:Passage en noir et blanc (binarisation)Binarisation: Separation fond/formeSeuil global: Utilisation de lâ€™histograme On suppose lâ€™histogramme bi-modal (1 mod pour le fond et 1 pour la forme) Trouver le niveau de gris a la jonction entre les 2 Seuil global - resultats:Seuil global - un algorithme simple: Supposons un seuil T initial Calculons les moyennes m1 et m2 des ensembles des pixels dâ€™intensite inferieure a T et superieur ou egale a T respectivement Corriger T avec $T = \\frac{m_1 + m_2}{2}$ Si $T \\gt \\Delta T$ continuer en 2Seuil global - Le critere dâ€™Otsu On cherche 2 classes Minimiser la variance intra-classe Maximisier la variance inter-classe $m_1(k)$ et $m_2(k)$ les moyennes des 2 classes formees par le seuil k $m_g$ la moyenne $p_1(k)$ et $p_2(k)$ les probabilites dâ€™occurrence des 2 classes formees par le seuil k Maximiser la variance inter-classe: $\\sigma(k)^2=P_1(k)(m_1(k)-m_g)^2 + P_2(k)(m_2(k)-m_g)^2$ Or $P_1(k)m_1(k) + P_2(k)m_2(k) = m_g$ et $P_1(k) + P_2(k) = 1$ $\\sigma(k)^2 = P_1(k)P_2(k)(m_1(k) - m_2(k))^2 = \\frac{(m_gP_1(k)-m_1(k))^2}{P_1(k)(1-P_1(k))}$ Reviens a chercher le k dans lâ€™intervale ou $P_1(k)(1-P_1(k))\\neq 0$ rel que $\\sigma(k)^2$ est le maximum (si plusieurs max, faire la moyenne) Seuil global Rapide et simple Se calcul directement sur lâ€™hisotgramme Dans la pratique pas toujours efficace selon le contexte ResultatsOriginal:Otsu:" }, { "title": "TIFO: Codage, partie 1 - couleurs et representations", "url": "/cours/posts/tifo_codage_partie1/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8", "date": "2021-02-19 09:00:00 +0100", "snippet": "Lien de la note HackmdCodage des couleursLe modele RGB/RVBEspace RGB/RVB (Red-Green-Blue) One code une couleur par un triplet representant la quantite de rouge, de vert et bleu de la couleur Une couleur est un point du cube: Lâ€™origine du repere $(0,0,0)$: le noir Lâ€™opposee: $(1,1,1)$ le blanc Chaque axe code une couleur primaire (R,G,B) Decomposition dâ€™une image suivant les 3 axes:Sur une image reelle: Le modele RGB Modele base sur la perception humaine (couleurs primaires en synthese additive) Pas toujours intuitif pour selectionner une couleur Tres repandu Le model HLSLâ€™espace HLS (Hue, Lightness, Saturation) On code une couleur par 3 composantes: teinte, luminance et saturation. Lâ€™espace ressemble a 2 cones que lâ€™on a joint par leurs bases. Une couleur est un point de cet espace Teinte Câ€™est lâ€™angle sur le disque $0^o$ rouge $60^o$ jaune $120^o$ vert $180^o$ cyan $240^o$ bleu $300^o$ magenta Luminance La luminance est la hauteur dans le cone Saturation La saturation (â€œpurete de la couleurâ€) est la distance au centre du disque Decomposition suivant les 3 axes:Sur une image reelle:La saturation Jâ€™ai un pâ€™tit singe ici: Modele intuitif pour â€œchoisir une couleurâ€. Lâ€™utilisation de la teinte est interessante toutefois, sur des saturations faibles, la teinte nâ€™a plus vraiment de signification Beaucoup de variantes (HSVâ€¦)Le modele YMCA CMYLâ€™espace CMY (couleurs primaires en syntese soustractive) Mieux adpate pour les peripheriques dâ€™impression Beaucoup de variantes En image on lâ€™utilise quasiment jamais.Codage dâ€™un niveau de grisComment coder un niveau de gris ? Une seule composante qui code la luminance Une convention possible: Composante nulle $\\rightarrow$ pas de lumiere (noir) Composante au maximum $\\rightarrow$ maximum de lumiere (blanc) Un niveau de gris quelconque = un point de lâ€™axe: Autres espacesIl existe dâ€™autres espaces de representation YIQ NTSC 1953 Facilite la transmission et la compatibilite de lâ€™image tant pour un ecran couleur que un ecran noir et blanc Y donne la luminance Lab La distance entre 2 couleurs dans cet espace est representative de la difference percue visuellement entre les 2 couleurs XYZ YCbCr â€¦Conversions entre espaces de couleursRGB $\\leftrightarrow$ HLS H$[0^o, 360^o]$ L$[0,1]$ S$[0,1]$ Teinte Estime en fonction de 2 bornes min et max Pour L $\\le 0,5$ Saturation Joue sur lâ€™ecartement min $\\leftrightarrow$ max sur la teinte Si S $=0$, min $=$ max $=$ L Donc max $=$ ($1$ + S)L et min $=$ ($1$ - S)L Pour L $\\ge 0,5$ Meme raisonnment RGB $\\leftrightarrow$ YIQLe passage de lâ€™un a lâ€™autre est simple:\\[\\begin{pmatrix} Y\\\\ I\\\\ Q\\end{pmatrix}=\\begin{pmatrix} 0.30 &amp;amp; 0.59 &amp;amp; 0.11\\\\ 0.60 &amp;amp; -0.28 &amp;amp; -0.32\\\\ 0.21 &amp;amp; -0.52 &amp;amp; 0.31\\end{pmatrix}\\begin{pmatrix} R\\\\ G\\\\ B\\end{pmatrix}\\]RGB $\\leftrightarrow$ CMY Les couleurs primaires de lâ€™espaces CMY sont les couleurs complementaires des couleurs primaires de lâ€™espace RGB La conversion est donc simple: $R = 1 - C$ $G = 1 - M$ $B = 1 - Y$ RGB $\\leftrightarrow$ niveaux de gris Idee simple et intuitive: $L = (r + v + b)/3$ Amelioration $L = 0.299r + 0,587v + 0,114b$ Pourquoi la premiere idee est-elle fausse ? Car nos yeux percoivent certaines couleurs mieux que dâ€™autres (cf. la seconde formule) Peut-on faire lâ€™inverse (passer du niveau de gris a la couleur ?) Non bien-sur: projection, on passe dâ€™un image 3D a 2D, on a perdu de lâ€™info Avec des regles on peut se donner une colorisation de lâ€™espace (teinte sepia, vert comme une camera de surveillance, etc.) mais on ne retrouvera pas la couleur dâ€™origine RGB $\\leftrightarrow$ noir et blanc Est-il possible de passer a une image noir et blanc ? Utile pour traiter les images â€œtropâ€ riches On binarise lâ€™image Quâ€™est-ce quâ€™on veut extraire de lâ€™image ? Y a t il un interet a passer a une image en noir et blanc ?Codage des couleursIl existe differents espaces pour la representation des couleurs Il faut etre capable de choisir le bon, en fonction de lâ€™objectif recherche Etre capable, dans la mesure du possible de passer de lâ€™un a lâ€™autreCodage de lâ€™imageRepresentation dâ€™une image couleurCodage dâ€™une image par une matrice: Lâ€™image est une fonction discrete 2D, elle est souvent codee par une matric Pour une image codee en RGB, un point de lâ€™image = un triplet (r,g,b) de valeurs dans la matrics Un point de lâ€™image = un pixel. Que signifie pixel ? Picture element Representation dâ€™une image en niveaux de grisCodage dâ€™une image par une matrice: Lâ€™image est une fonction discrete 2D, elle est souvent codee par une matrice Pour une image codee en niveaux de gris, un point de lâ€™image = une valeur dans la matrice codant la luminanceAcces aux pixels Comment coder cette image en memoire ? Matrice ? Vecteur ? Comment acceder a un point de cette image ? Comment acceder a ses voisins ? Comment parcourir lâ€™image ?for (i = 0; i &amp;lt; sx; i++) for (j = 0; j &amp;lt; sy; j++) offset = i + j * sxfor (j = 0; i &amp;lt; sy; j++) for (i = 0; j &amp;lt; sx; i++) offset = i + j * sxfor (offset = 0; offset &amp;lt; sx * sy; ++offset) Utiliser un iterateur ?Resolution/Echantillonage Discretisation spatiale (resolution) Echantillonage (amplitude)Nombre de couleurs - EchantillonnageCodage par palette (couleurs indexees) Bit(s) par pixel Couleurs 1 bpp ??? 2 bpp ??? 4 bpp ??? 6 bpp ??? 8 bpp ??? Codage sans palette Bits par pixel Couleurs Bits par canaux 16 bpp ? ? 24 bpp ? ? 32 bpp ? ? Representation de lâ€™imageUn moyen classique de representer une image est dâ€™utiliser une matrice. Y a t il dâ€™autres approches ? Arbres (max tree, min tree, tree of shape) Graphes â€¦Maillage On choisit intuitivement un maillage carre mais cela peut-il presenter des inconvenients ? Y a t il dâ€™autres maillages possibles ?TopologieChoix de la connexite des pixels4-connexe: Voisins en haut, en bas, a gauche, a droite Pas lies aux voisins en diagonale Plusieurs regions8-connexe: Une seule region Cela pose un probleme de topologie: Si le fond est 8-connexe (en noir), la forme (en blanc) est 4-connexe Si le fond est 4-connexe (en noir), la forme (en blanc) est 8-connexe Contradiciton avec le theoreme de Jordan Que faire ? Vivre avec Changer la forme de pixels Intercaler des frontieres entre les pixels â€¦ Changer la forme de pixels:Codage en memoire:Pour: Plus de probleme de connexite Plus de probleme de distance Tout le monde est a la meme distance Contre: Gestion de la memoire Inteprete chaque ligne de la matrice comme ayant un decalage offset Intercaler des frontieres entre les pixelsLes frontieres sont determinees par les inter-pixelsExemple dâ€™arbre: Max treeA chaque fois quâ€™on a 2 regions qui se separent, on cree des branchesStockage/Transfer Differents formats: JPEG, TIFF, PNM, PNG, BMP, GIF, TGA Choix en fonction de criteres Avec ou sans compression (avec ou sans perte) Avec ou sans couleur Avec ou sans palette Une seule image ou plusieurs Optimise pour une architecture ? (Ex. BMP sauvegarde a lâ€™envers) Libre ou pas (Ex. GIF et Compuserve) Exemple Format PNM PBM: noir et blanc PGM: niveaux de gris PPM: couleurs 2 variantes PNM TGA Format tres simple (extrait de spec)Application On a vu pas mal de choses sur la formation dâ€™une image On va lâ€™appliquer en changeant les couleurs ou lâ€™illumination dâ€™une image en changeant lâ€™organisation spatiale des pixels de lâ€™image en combinant des changements dans le couleurs et dans lâ€™organisation spatiale des pixels Changement dâ€™illuminationEn tous points de la scene, la reponse du capteur est donne par:$L(x,y) = \\int E(x,y,\\lambda)S(x,y,\\lambda)R(\\lambda)d\\lambda$ Avec $E(x,y)$ lâ€™eclairage $S(x,y,\\lambda)$ la reflectance de la surface (fonction de la longueur dâ€™onde $\\lambda$) $R(\\lambda)$ la sensitivite du capteur qui (pour simplifier est supposse repondre a une seule longueur dâ€™onde: $R(\\lambda) = \\sigma(\\lambda-\\lambda_k)$)On a donc: $L(x,y) = E(x,y)S(x,y,\\lambda_k)$ La meme image prise avec 2 niveaux dâ€™illuminations differents: $L1(x,y) = E_1(x,y)S(x,y,\\lambda_k)$ $L2(x,y) = E_2(x,y)S(x,y,\\lambda_k)$Donc: $L2(x,y) = (E_2(x,y)/E_1(x,y))*L1(x,y)$Et donc: $L2(x,y)=C*L1(x,y)$ Pour changer lâ€™illumination il faut donc multiplier les valeurs des pixels par une constante (et non additionner/soustraire par une constante comme câ€™est usuellement fait)Correction dâ€™illumination non uniforme Soit une image acquise $I_1$ avec un eclairage non uniforme $I_1(x,y)=S(x,y,\\lambda_k)E(x,y)$ Soit lâ€™image du fond $I_f$ $I_f(x,y)=F(x,y,\\lambda_k)E(x,y)$La soustraction des deux donne:\\(I_1(x,y)-I_f(x,y) = [S(x,y,\\lambda_k)-F(x,y,\\lambda_k)]E(x,y)\\)Le ratio des 2 donne:\\(\\frac{I_1(x,y)}{I_f(x,y)} = \\frac{S(x,y,\\lambda_k)}{F(x,y,\\lambda_k)}\\)Difference vs RatioModification des couleurs de lâ€™image Application : effet artistique $\\rightarrow$ effet sepia On associe a un niveau de luminance une couleur \\[\\begin{pmatrix} r\\\\ g\\\\ b\\end{pmatrix}=\\begin{pmatrix} 0,784 &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0,588 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0,391\\end{pmatrix}\\begin{pmatrix} l\\\\ l\\\\ l\\end{pmatrix}\\]Resultat:Modification de lâ€™organisation spatiale des pixelsApplication: effets artistiques $\\text{image_resultat}(x,y) = \\text{image_origin}(g(x,y), h(x,y))$ Les fonctions $g$ et $h$ ne tiennent pas forcement compte de la valeur du pixel Rotation - cisaillement Etirement - retrecissement Ondulations Spirale Tranlations aleatoires â€¦ La 2e image câ€™est quand on me chatouille le cou $\\text{image_resultat}(x,y) = \\text{image_origin}(g(x,y), h(x,y))$La transformation doit etre appliquee dans ce sens !Application: le morphing dâ€™imagesModification des couleurs et de lâ€™organisation spatiale des pixels Application: le morhping Vu la structure dâ€™une image, il est possible dâ€™appliquer des operateurs sur ces images Exemple: la moyenne En combinant Une moyenne ponderee des images (dont les poids evoluent au cours du temps) Un champ de vecteur de translation Problemes de precision Sur les fonctions colorimetriques Sur les transformations spatialesLa correction gammaRetour sur la perception La perception de lâ€™oeil est logarithmique La repartition des niveaux dâ€™energie nâ€™est donc pas lineaire mais exponentielle Tous les calculs fait jusquâ€™a present sont completement faux car 50% du signal nâ€™est pas a la moitie du niveau de gris (128) mais a 186.\\(r = \\frac{number}{255}^{gamma}\\\\gamma = 2.2\\) Les niveaux de gris ne sont que des numeros, faire des operations (moyenne, addition, application de filtres, interpolationâ€¦) nâ€™a pas vraiment de sens Dans la pratique, on omet souvent la correction gamma lors des etapes de filtrages Câ€™est faux Il y a un compromis entre precision du resultat et vitesseRetour sur le passage de la couleur en niveuax de gris Espace CIE XYZ 1931 $Râ€™= r/255 Vâ€™ = v/255 Bâ€™ = b/255$ $Rsrvb = [(Râ€™+0.055)/1.055]^{2.4}$ $Vsrvb = [(Vâ€™+0.055)/1.055]^{2.4}$ $Bsrvb = [(Bâ€™+0.055)/1.055]^{2.4}$ \\(\\begin{pmatrix} X\\\\ Y\\\\ Z\\end{pmatrix}=\\begin{pmatrix} 0,4124 &amp;amp; 0,3576 &amp;amp; 0,1805\\\\ 0,2126 &amp;amp; 0,7152 &amp;amp; 0,0722\\\\ 0,0193 &amp;amp; 0,1192 &amp;amp; 0,9505\\end{pmatrix}\\begin{pmatrix} Rsrvb\\\\ Vsrvb\\\\ Bsrvb\\end{pmatrix}\\) $Y$ donne la luminanceLâ€™interpolation Que faire lorsque lâ€™on doit â€œchercherâ€ la valeur dâ€™un pixel mais que lâ€™on ne tombe pas precisement sur un pixel ? 1er solution (rapide): prendre la du pixel le plus proche 2nd solution: Faire une interpolation bi-lineaire Peut-on faire mieux ? Interpolation bicubique Utilise 4 points (calcul de la derivee) Interpolation bicubique\\[f(x) = ax^3+bx^2+cx+d\\\\f&#39;(x)=3ax^2+2bx+c\\]On connait les valeurs pour $x=-1$, $x=0$, $x=1$ et $x=2$\\(f(-1)=p0, f(0)=p1 \\text{ et } f(2)=p3\\\\f&#39;(0)=(p2-p0)/2 \\text{ et } f&#39;(1)=(p3=p1)/2\\)Mais aussi\\(f(0) = d\\\\f(1) = a+b+c+d\\)\\[f&#39;(0) = c\\\\f&#39;(1) = 3a+2b+c\\]On peut donc en conclure que les coefficients a,b,c,d du ploynome et donc interpoler les valeurs intermediaires du signal entre 0 et 1.Artefact:Autres interpolation Il existe dâ€™autres methodes dâ€™interpolation Pour faire le choix de lâ€™interpolation, il faut faire un compromis entre vitess et qualiteConclusion Codage de lâ€™image et de la couleur Espaces de couleurs, passage dâ€™un espace a lâ€™autre Applications Effet sepia Transformation artistiques Morphing Correction gamma Interpolation" }, { "title": "DEVI: Presentation", "url": "/cours/posts/devi_presentation/", "categories": "Image S8, DEVI", "tags": "Image, DEVI, S8", "date": "2021-02-18 13:00:00 +0100", "snippet": "Lien de la note HackmdJoseph Chazalon, Clement DemoulinsFebruary 2021EPITA Research &amp;amp; Development Laboratory (LRDE)About this courseThis is a course about containers using Docker What it is How to use it for simple, then less simple cases PracticeTools an gradingGraded content for each sessions using Moodle For sessions 1 and 2: 10 min quiz on Moodle at the end of each sessionSoftware stack illustratedA real case of 2 incompatible software stacks we had to handleMany solutions Use libs with forward/backwared compatibility FIx bad dependency declarations in packages Use lnagugae compatibility layer Rebuild stuff manually Install various versions of libs at different placesDependency hellWhen you have to rebuild manually, step by step, all your software stack checking each dependencyWhat are you paid for ?Waht you really want is simply to separate: your development &amp;amp; product software stack your os &amp;amp; userland software stackAnd what about deployement ?Deployement challengeSolutions Containers Beaucoup plus leger Demarrage presque immediat Virtual Machines Emuler le systeme dâ€™exploitation Devoir reserver RAM, CPU, etc. On peut avoir plusieurs VMs sur une meme machine Containers and virtual machines are 2 good solutions to software stack isolation have similar resource isolation and allocation benefits(CPU, mem, net &amp;amp; disk IO) but function differently because containers virtualize the OS (the kernel) instead of hardware so containers are lighter and faster than VMs (min storage) more portable less secure DockerPromises lightweight easy deployementBenefits for devBuild onceâ€¦ run anywhere portable runtime env no worries about missing dependencies run each app in its own isolated container Automate testing, integration, packagingBefenits for adminConfigure onceâ€¦ run anything Make the entire lifecycle more efficient, consistent and repeatable Increase the quality of codeDocker adoption Docker was launched in 2013 (8 years ago) and became a massive trend. Github project search â€œdockerâ€ $\\rightarrow$ $\\gt$ 45 000 projectsReasons for NOT using (Docker) containers (currently) Archive your program (because it is not made for that) Your program uses OSX primitives Your program runs on Windows only You need to deploy many containers on clustersDemo1: VSCode Remote ContainerImplementation of Docker ContainersUnder the hood, Docker is built on the following components: The Go programming language The following features of the Linux kernel Namespaces groups capabilities NamespacesAccording to man namespaces: A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that hey have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes. One use of namespaces is to implement containers.CgroupsAccording to man cgroups Control groups, usually referred to as cgroups, are a Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored. The kernelâ€™s cgroup interface is provided through a pseudo-filesystem called cgroupfs. Grouping is implemented in the core cgroup kernel code, while resource tracking and limits are implemented in a set of per-resource-type subsystems (memory, CPU, and so on).CapabilitesAccording to man capabilities: Traditional UNIX implementations distinguish two categories of processes: privileged processes (whose effective user ID is 0, referred to as superuser or root), and unprivileged processes (whose effective UID is nonzero). Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the processâ€™s credentials (usu ally: effective UID, effective GID, and supplementary group list). Starting with kernel 2.2, Linux divides the privileges traditionally associated with superuser into distinct units, known as capabilities, which can be independently enabled and disabled. Capabilities are a per-thread attribute.Open Container Initiative runtime (container) specificationsContainer configuration, lifecycle, and how to rpx them using JSON files. creating the container is being created created the runtime has finished the create operation, and the container process has neither exited nor executed the user-specified program running the container process has executed the user-specified program but has not exited stoppedOpen Container Initiative image specificationsAn image stores the files for the root FS of a container, ie the files or containerized program will seeProblem(s) Many containers share the same basis (Ubuntum Alpine, Debian, etc.) because we do not want to rebuild a complete software stajc by hand down to the kernelSolution: Split images into meaningful layers Ubuntu base, Python dependencies, Appâ€¦ Share common layers between containers in read-only Add a thin writable layer on top of this stack of layers View this stack as a single, consistent and writable filesystemImage LayersEfficiency implemented using Copy-on-Write (COW)Open Container Initiative distribution specificationsAPI protocol to facilitate distribution of images: What is a repository How to list, pull, push images HTTP APIImages and containersWhen using Dokcer, you think about images and containersGood to remember A (Docker) container is just: a root filesystem with some bind mounts containing all the software stack down to the kernel a control policy enforced by the kernel with some isolation mechanisms: PID, network, etc. some environment variables, kernel configuration and automatically generated file: for hostname, DNS resolution, etc. an abstract view of a group of processes not even a single kernel object Using DockerRegular workflow Obtain an image docker image pull USER/IMAGENAME:TAGdocker image import ARCHIVEdocker image build ... Create a container for image docker container create --name CONTAINER_NAME IMAGE Start the container docker container start CONTAINER_NAME (opt.) execute more programs within the container docker container exec CONTAINER_NAME Attach your console to the container docker container manage/monitor the containerContainer storage explainedStorage overviewWhere is Docker data stored ?Under var/lib/dockerBase image contentBind mountsVolumesWhat Shareable space management by Docker Can bes used to share data between container Create using docker volume create VOLNAME or --volume or --mount type=volume on start/run Survive container removal: must be removed manuallyWhere Stored under /var/lib/docker/volumes/+ name or unique idReusing volumes for another containerIt is possible to mount volumes from another container.This can be convenient in several cases: get a shell in a super minimal container migrate a database upgrade a containerFragile isolation with host Relies on kernel security You can share a lot of things with host Many public images run services as root" }, { "title": "ISIM: Rendu photorealiste", "url": "/cours/posts/isim_rendu_photorealiste/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-18 11:00:00 +0100", "snippet": "Lien de la note HackmdRendu photorealiste Objectif Generation dâ€™images realistes Contrainte de temps faible Strategies: Object-based rendering algorithms Illumination globale calculee independamment du point de vue Image-based rendering algorithms Illumination calculee partiellement, en fonction du point de vue Deterministic rendering algorithms Monte Carlo rendering algorithms Les algorithmes quâ€™on va voir: Raytracing Path Tracing et Bidirectional Path Tracing â€¦ Radiosity Photon map â€¦Formation de lâ€™imageCapture de lâ€™image:Modele stenope:Capture de lâ€™image (capteur CCD, CMOS)Dans notre cas nous pouvons faire passer des rayons avec differentes longueurs dâ€™onde par le meme point On peut facilement modeliser la camera Il faut reussir a modeliser lâ€™eclairage Idee: â€œsuivreâ€ les rayons lumineux pour trouver le chemin parcouru depuis la source jusquâ€™a lâ€™oeil Principe: Lancer une â€œinfiniteâ€ de rayons depuis la source pour esperer trouver ceux qui frappent lâ€™oeil de lâ€™observateur Câ€™est tres lourd!Raytracing Historique 68, Appel (du raycasting?) 80, Whitted (ajoute les effets optiques: reflexion, transparenceâ€¦) Principe Idee de base: Difficile de suivre tous les rayons partant de la source en revanche il est possible dâ€™estimer le chemin inverse Faire le chemin inverse pour trouver les objets â€œvusâ€ Pour chaque objet vu, on peut estimer une approximation de lâ€™eclairage local Approximation de 2 types de contributions: la partie diffuse la partie speculaire Calcul de lâ€™illumination locale: Composante diffuse Composante speculaire Apport des sources primaires Apport des sources secondaires Sources primaires: Lumieres ponctuelles Spots Lumieres directionnelles Objets lumineux Sources secondaires: Les autres objets eclaires Modele local:La composante diffuse La propriete de diffusion de la surface est $k_d$ La couleur de la surface est $C$Voila ce que ca donne: â€œMais vous avez triche monsieur il y a des ombres !â€ Câ€™est faux, il faut regarder lâ€™effet de degrade: câ€™est la lumiere diffusante.La composante speculaire La propriete de reflexion de la surface est $k_s$ Lâ€™intensite de la lumiere depend de lâ€™angle fait par $S$ et $L$On a en resultat: La lumiere est blanche donc on a un reflet blanc sur les objets.Il y a un coefficient de brillance, la tache speculaire est plus ou moins piquee (ex: la lumiere dans les yeux des gens) Les â€œ$k_d$â€ incluent la couleur Il faut sommer toutes les sources lumineuse $i$â€¦ Resultat: Encore une fois je triche comme un arracheur de dent car je nâ€™ai pas explique comment avoir lâ€™ombre, normalement ca devrait etre le degrade du bleu.Est-ce quâ€™on peut affiner ce modele ? On peut ajouter un coeff dâ€™attenuation $f(d)$ ($d$ $\\rightarrow$ distance) Estimer que ce nâ€™est pas un rayon qui repart mais un cone $f(d) = 1/d$ $f(d) = 1/d^2$ $f(d) = 1/(d + k)$ â€¦ Quel modele de couleur prendre ?Une synthese additive RVB.AlgorithmeEtape 1: Prise en compte des sources primairesPour lâ€™ensemble des points de lâ€™â€˜image: Calculer le vecteur directeur du rayon lumineux $v$ partant de lâ€™observateur Chercher les intersections de ce rayon lumineux avec lâ€™integralite des objets de la scene et garder le plus proche Calculer le niveau dâ€™eclairement au point dâ€™intersection en sommant lâ€™apport diffus et speculaire pour chaque source lumineuse Problemes: Ne tient pas compte des sources lumineuses secondaire Ne gere pas les ombres Prise en compte des sources secondaires:On ne considere pas tous les points de toutes les surfaces de lâ€™espace, par contre on va aller explorer la direction du rayon rebondissant sur la table.Pour y arriver, on calcule lâ€™illumination au point sur la table, rien nous empeche de â€œrelancerâ€ un rayon et voir quel objet on intersecte. Une fois quâ€™on lâ€™intersecte, on calcul lâ€™illumination au point. Câ€™est du cast ray. La reponse â€œlancer plus de rayonâ€ ca fonctionne.Etape 2: Prise en compte des sources primaitres et certaines sources secondairePour lâ€™ensemble des points de lâ€™image: Calculer le vecteur directeur du rayon lumineux $v$ partant de lâ€™observateur Chercher les intersections de ce rayon lumineux avec lâ€™integralite des objets de la scene et garder le plus proche Relancer un rayon dans la direction de $S$ puis calculer le niveau dâ€™eclairement recursivement Calculer le niveau dâ€™eclairement au point dâ€™intersection en sommant lâ€™apport diffus et speculaire pour chaque source lumineuse ainsi que lâ€™eclairement dans la direction de $S$Etape 3: Prise en compte de lâ€™ombrePour lâ€™ensemble des rayons que lâ€™on â€œlanceâ€ vers les sources primaires, il faut chercher si un objet de la scene ne sâ€™est pas insere entre le point considere et la source. Pour cela, il faut a nouveau calculer lâ€™intersection du rayon avec lâ€™ensemble des objets de la scene et prendre le plus proche.Resultats Je triche plus (ou quasiment plus) Je triche jâ€™ai pas du tout parle de texture et dâ€™anti-aliasing Lâ€™algorithme du raytracing est un processus simple, recursif Il faut etre capable, pour chaque objet, de calculer la normale en chaque point Il faut reflechir a la condition dâ€™arret Avantages Algorithme simple et rapide a mettre en oeuvre Genere des images honorables â€¦Inconvenients Temps de calcul un peu eleve Pas de gestion de la profondeur de champ et autres effets Mauvaise gestion des ombres (frontieres trop brutales) Sources secondaire pas suffisamment prises en compte (eclairage indirect incorrect) Objets transparents â€œAlisaingâ€ â€¦Les problemes du RaytracingProbleme de lâ€™aliasing Probleme: si on lance un rayon câ€™est touche ou pas touche alors que ca devrait etre la proportion de chaque.On risque aussi de louper les petits objets.Solution On lance plus de rayons (cast ray)! Sur-echantillonage Lancer plusieurs rayons pour chaque pixel De maniere organisee Au hasard Lancer plusieurs rayons pour chaque pixel ou le gradient est eleve Bon resultats mais peut etre tres lent Post-filtrage Resultat moyen mais tres rapide ResultatsAvec anti-alisaing sur toute lâ€™image (50 rays/pixel)temps: de lâ€™ordre de 7-8 secondesAnti-aliasing sur les zones de gradient eleve (50 rays/pixel)Temps: lâ€™ordre de la secondeProbleme du temps de calcul On lance plus de rayons (cast ray)!Solutions: Volumes englobants Projection sur un plan/partition de lâ€™espace Pre-trier les objets? Calcul parallele Utilisation dâ€™OpenGL â€¦Probleme des objets transparentsSolutions: Comme nous avons relance le rayon reflechi, il faut â€œsuivreâ€ le rayon refracte Loi de la refraction Tenir compte du rayon refracte pour lâ€™illumination locale: $I=I_d+I_s+I_s+k_tT$Milieux transparents: Loi de la refraction (Snell Descartes): $n_1\\sin i_1 = n_2\\sin i_2$Surfaces translucides: Distribution probabilisteCalcul de lâ€™ombre Solution approchee:Ne pas devier le rayon mais filtrer les longueurs dâ€™ondesProbleme de lâ€™eclairage indirectSi on va sous notre bureau, dâ€™apres nos calculs il devrait faire totalement noir alors que ce nâ€™est pas le cas avec lâ€™eclairage indirect.Solution Ajouter une lumiere ambiante: $I=k_a*I_a+I_d+I_r+I_t$ Solution vraiment approximativeResultats:Probleme de lâ€™ombreOn lance un rayon pour savoir si on est eclaire mais ca donne une reponse binaire, câ€™est comme considerer la source comme ponctuelle. Notre source lumineuse nâ€™est pas ponctuelle.Quel est la proportion de notre source ?Comment faire pour avoir des ombres plus douces ?Solution Cast ray ! Ne plus considerer une lumiere comme ponctuelle Probleme de temps de calcul BilanAvantages Algorithme tres simple Donne des images honorablesDes problemes majeurs persistent Les sources secondaires ne sont pas suffisamment bien geres Les objets transparents non plusAmelioration Raytracing distrubue (84) Sur-echantillonnage pour simuler les ombres douces la profondeur de champ â€¦ Ne regle pas le probleme de lâ€™apport de la diffusion des sources secondaires Quantite de calcul enorme Conclusion Algorithme simple Necessite beaucoup dâ€™ameliorations pour avoir des images photorealistes" }, { "title": "ISIM: Rappels", "url": "/cours/posts/isim_rappels/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-18 09:00:00 +0100", "snippet": "Lien de la note HackmdOptique et image Pour synthetiser une image, il faut comprendre comme celle-ci se forme et est capturee.Dans ce cas: Table Observateur (cam) Source lumineuse rayons se propagent dans toutes les directions eclaire la table la table renvoie la lumiere qui est captee par lâ€™observateur $\\rightarrow$ source lumineuse secondaire Lâ€™observateur ne peut pas faire de difference entre un objet qui emet de la lumiere et un objet qui le renvoieQuâ€™en est-il de la couleur ?Quelles sont les couleurs primaires ? RGB RJBComment ca se fait que je vois la nape bleue ?Dans les rayons lumineux il y a des longueurs dâ€™ondes.La table filtre les longueurs dâ€™onde et renvoie les rayons qui correspondent au bleu.2 systemes: Source primaire: rajoute des couleurs RVB couleurs primaires $\\Rightarrow$ sysnthese additive Objets qui renvoient la lumiere et en absorbe une partie: enleve de la couleur CMJ (Cyan, Magenta, Jaune) complementaire aux couleurs primaires $\\Rightarrow$ sysnthese soustractive Capture de lâ€™imageDans un appareil photo/oeil/camera: Chambre noire Pellicule/capteurs photosensibles transforme la lumiere recue en energie transforme la lumiere recue en teinte (ancien appareils photos) Point image image envoyee Foyer selectionne les rayons lumineux Plan image image recue a lâ€™envers Caracteristiques Zoomer ou dezoomer En augmentant ou reduisant la distance focale Zoomer: reduire le champ de vision (grande distance focale) Dezoomer: augmenter le champ de vue (petite distance focale) Ouvrir ou fermer le diaphragme Si ouvre Plus de foyer unique Image devient flou On reduit la zone de nettete Plus on ouvre le diaphragme, plus on reduit la profonder de champ Si reduit le diaphragme Plus de profondeur de champ Moins de lumiere Varier la taille de diaphragme Peut etre une contrainte Rendre lâ€™arriere-plan flou Jouer avec dans les images de synthese Le foyer doit etre avant le plan image IRL, mais en virtuel il peut etre apres (cf. schema).Comment capturer lâ€™image en pratique Dans lâ€™appareil photo: matrice de capteurs photosensibles qui generent de lâ€™energie quand ils sont frappes.Image en niveau de gris: Pour la couleur, pour chaque capteur photosensibles on met des filtres (ex: capturer que les longueurs dâ€™onde qui capturent le vert).Probleme: on connait lâ€™intensite en tout point mais pas pour toutes les longueurs dâ€™onde, il faut la deduire via les voisins. Câ€™est le patterne de Bayer.Pourquoi ces couleurs ? Câ€™est les couleurs primaires RVB. Pourquoi RVB?Pourquoi plus de vert ? Lie a la perception humaine, nos yeux sont plus sensibles au vert/jaune.Pour un capteur virtuel, pour chacune des cellules on peut mesurer toutes les longueurs dâ€™ondes pour RVB.Formation de lâ€™image Les longeurs dâ€™onde du spectre visible est une plage tres etroite.Pourquoi les couleurs primaires sont RVB ?On a des capteurs dans nos yeux pour RVB.Pourquoi on peut reconstituer toutes les couleurs a partir de RVB? Si par exemple on voit une couleur jaune, nos capteurs vert et rouge sont stimules. Dans les couleurs possibles il nâ€™y a pas de blanc, ca arrive quand on stimule tous les capteurs en meme temps. De meme pour le magenta, qui arrive quand uniquement le cone vert nâ€™est pas stimule. Certaines couleurs nâ€™existent pas, notre oeil nous donne une representation.Codage de la couleurModele RGB One code une couleur par la quantite de rouge, de vert et de bleu que contient cette couleur Une couleur est alors un point du cube Modele directement lie a notre perceptionLe modele RGB est directement issue de notre perception des couleurs.Generation dâ€™une image synthetique Simuler les phenomenes optiques qui conduisent a la formation de lâ€™image.Geometrie Euclidienne Produit scalaire: forme ilineaire, symetrique, definie positive Espace pre-hilbertien $(E,\\vert)$ reel $E$: R-espace vectoriel $\\vert$: produit scalaire Espace euclidien Espace pre-hilbertien reel de dimension finie Espace affine $\\mathcal F$ de $E$ (e.v): $\\mathcal F$ s.e.v de $E$ Soit $A\\in E, \\forall x\\in\\mathcal F; A + x\\in\\mathcal F$ Cas particuliers: Dim 0 $\\Rightarrow$ un point Dim 1 $\\Rightarrow$ une droite affine Dim 2 $\\Rightarrow$ un plan affine Repere cartesien de $\\mathcal F : (O, B)$ avec $O$ un point de $\\mathcal F$ et $B$ une famille de vecteurs de $\\mathcal F$ formant une base de $\\mathcal F$ Soir $E$ un $\\mathbb R$-espace vectoriel, une norme $N$ sur $E$ est une application de $E$ dans $\\mathbb R$ tel que: $\\forall u\\in E, N(u) \\ge 0$ $\\forall u \\in E, N(u) = 0 \\Leftrightarrow u = 0$ $\\forall (u,\\lambda)\\in (E\\times\\mathbb R), N(\\lambda u) = \\vert\\lambda\\vert N(u)$ $\\forall(u,v)\\in E^2,N(u+v)\\le N(u)+N(v)$ Definition associee au produit scalaire: $N(u)=\\sqrt{u\\vert u}$: norme euclidienne Produit mixte: $[u,v,w] = det(u,v,w)$ $= (u\\times v).w$ Donne le volume du parallelepipede Produit vectoriel; $x;[u,v,w] = x.w(x=u\\times v)$ $\\Vert u\\times v\\Vert$ aire du rectangle $\\frac{1}{2}\\Vert u\\times v\\Vert$ aire du triangle Vecteurs et angles en euclidien Produit scalaire: $u.v=\\Vert u\\Vert\\Vert v\\Vert\\cos(u,v)$ Produit vectoriel: $u\\times v = \\Vert u\\Vert\\Vert v\\Vert\\sin(u,v)$ $u.v = 0 \\Leftrightarrow u$ et $v$ ortho $(u.v)^2 + (u\\times v)^2 = \\Vert u\\Vert^2\\Vert v\\Vert^2$ Equation de droites 2D Cartesienne: $y=ax + b$ Implicite: $ax+by+c=0$ Parametrique: $A+\\lambda\\overrightarrow v$ 3D Cartesienne Implicite Parametrique: $A+\\lambda\\overrightarrow v$ Equation dâ€™un plan 3D Cartesienne: $ax+by+cz+d=0$ Implicite Parametrique Prendre un point du plan et donner 2 vecteurs qui vont definir une base $A+\\lambda_1\\overrightarrow v_1\\lambda_2\\overrightarrow v_2$ Equation dâ€™un cercle/sphere 2D/3D Cartesienne: $(x-a)^2+(y-b)^2+(z-c)^2 = r^2$ Implicite Parametrique\\(\\begin{cases} x &amp;amp;= a + r\\cos(\\theta)\\sin(\\lambda)\\\\ y &amp;amp;= b + r\\sin(\\theta)\\cos(\\lambda)\\\\ z &amp;amp;= c + r\\sin(\\lambda)\\\\\\end{cases}\\) Determinant Utilite du determinant: Equation de droite passant par ($x_1$, $y_1$) et $u(a,b)$ \\(\\begin{vmatrix} x-x_1 &amp;amp; a\\\\ y-y_1 &amp;amp; b\\\\ \\end{vmatrix} = 0\\) Equation de droite passant par ($x_1$, $y_1$) et ($x_2$, $y_2$) \\(\\begin{vmatrix} x-x_1 &amp;amp; x-x_2\\\\ y-y_1 &amp;amp; y-y_2\\\\ \\end{vmatrix} = 0\\) Idem pour lâ€™equation dâ€™un plan dans un espace 3DIntersectionIntersection droite/plan Droite: $P+t\\overrightarrow v$ Plan: $ax+by+cz+d=0$ ou $\\overrightarrow N.\\overrightarrow X = d$ $\\overrightarrow N.(P+t\\overrightarrow v) = d$ $t_i = \\frac{d-\\overrightarrow N.P}{\\overrightarrow N\\overrightarrow v}$ Cas particulier si $d$ parallele au plan ($\\overrightarrow N\\overrightarrow v=0$) $I=P+t_i\\overrightarrow v$Intersection droite/plan $\\rightarrow$ droite\\triangle Verifier que $I$ est dans le triangle $ABC$ Exprimer $I$ en fonction de $A$, $B$ et $C$ Les coordonnees barycentriques doivent etre toutes positives Determiner les de chaque cote du triangle Determiner la position de $I$ vis a vis de chaque cote i.e $ax+by+c\\lt0$ ou $ax+by+c\\gt0$ Avec lâ€™algorithme de Cyrus-Beck En regardant lâ€™orientation du sens de parcours Intersection droite/sphere Calcul de lâ€™intersection dans le repere local ou global ? Idem que pour le plan mais avec lâ€™equation de la sphere. 3 cas possibles: Pas de solution (pas dâ€™intersection) Solution double (la droite touche la surface de la sphere) Deux solutions distinctes (la droite traverse la sphere) Distance point/droite $d(p, D) = \\frac{\\vert ax_p + by_p + c\\vert}{\\sqrt{(a^2 + b^2)}}$ $d(p, D) = \\frac{\\vert\\overrightarrow{AM}.\\overrightarrow n\\vert}{\\Vert n\\Vert}$ Distance point/plan $d(p,P)=\\frac{\\vert ax_p+by_p+cz_p+d\\vert}{\\sqrt{(a^2+b^2+c^2)}}$ $d(p, P) = \\frac{\\vert\\overrightarrow{AM}.\\overrightarrow n\\vert}{\\Vert n\\Vert}$ Distance droite/droite $D_i(A_i, \\overrightarrow{v_i})$ $d(D_1, D_2) = [\\overrightarrow{A_1A_2}, \\overrightarrow{v_1}, \\overrightarrow{v_1}]/\\Vert\\overrightarrow{v_1}\\overrightarrow{v_2}\\Vert$ Distance sphere/sphereGeometrie projective Geometrie euclidienne Etude des formes des â€œobjetsâ€ Invariance par rotation, tranlsation, reflexion Geometrie projective Etude des objets tel quâ€™ils sont vus Perception des angles, des distances, du parallelisme distordu Exemple avec des rails de train paralleles mais qui semblent se rejoindre au point de fuite: Nâ€™allez pas aller vous faire renverser par un trainDependant du point de vie, B est entre A et C ou A est entre B et C:Projection sur le plan image On a juste a projeter les sommets dâ€™une faceDans lâ€™espace, on ne prend pas lâ€™objet entier mais juste une face. On trace une droite qui passe par le foyer et le sommet, on note lâ€™intersection avec le plan image ce qui nous donne sa projection.Point de fuiteSi on a une droite quâ€™on veut projeter sur le plan image, on prend le plan forme par la droite et le plan qui inclut le foyer de projection. Si on fait une intersection de ce plan avec le plan image, câ€™est exactement la projection de la droite sur le plan image en accord avec le foyer. Si on fait de meme avec dâ€™autres droites, elle convergeraient toutes vers un meme point: la point de fuite.Horizon Intersection du plan passant par le foyer et parallele au plan objetTous les points de fuite de droites paralleles sont alignees sur le lâ€™horizonPoints a lâ€™infiniOn a lâ€™ensemble de droites, si on les projettent on a undividuellement lâ€™ensemble des points de la droite, avec une image et un antecedent sauf que si on prend une droit qui va suffisament loin on est parallele au plan objet. Ce sont les points a lâ€™infini.On a le corollere dans lâ€™autre sens: certains points appartiennent au plan parallele au plan image et passent par le foyer, ils ne peuvent pas etre projetes sur le plan image car leur droite ne coupe jamais le plan image. On doit rajouter au plan objet et au plan image des points a lâ€™infini. Un ensemble de droites paralleles convergent vers ce point a lâ€™infini.On peut representer le plan projectif par un disque, lâ€™ensemble de paralleles est represente par une seule droite sur ce disque. Le point de fuite est le meme de chaque cote du plan image.Pour le rajouter sur le disque, on doit le â€œplierâ€ pour que les extremites se rejoignent.Coordonnees homogenesDans le plan $RP^2$ est lâ€™ensemble des triplets $[p] = [p_1, p_2, p_3]$ avec $(p1,p2,p3)$ dans $\\mathbb R^3$ prive de $(0,0,0)$ Deux points $p$ et $q$ sont egaux si et seulement si il existe un $k$ dans $R^*$ tel que: $p_1=kq_1$ et $p_2 = kq_2$ et $p_3=kq_3$ Deux cas: $p_3 = 0$, $[p_1,p_2,p_3] = [p_1,p_2,0]\\in RP^2$ $p_3 \\neq 0$, $[p_1,p_2,p_3] =[p_1/p_3,p_2/p_3,1]\\in RP^2$Pourquoi sâ€™embeter avec cette 3e coordonnes ?Si $p_3$ est a 0, on parle des points a lâ€™infini. Homogenes: peut representer les points euclidiens et les points ideaux.$[a,b,0]:(a,b)$ donne la direction des points associesIdem pour une droite projective et pour lâ€™espace 3D.Transformation usuellesRepresentation des transformations usuelles dans lâ€™espace projectif Translation Echelle Rotation ProjectionCombinaison des transformations.Translation Euclidien: \\(P + \\begin{pmatrix} t_x\\\\ t_y\\end{pmatrix}\\) Coordonnees projective: on a une coordonnees de plus\\(\\begin{pmatrix} x + t_x\\\\ y + t_y\\\\ 1\\end{pmatrix}=\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; t_x\\\\ 0 &amp;amp; 1 &amp;amp; t_y\\\\ 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\begin{pmatrix} X\\\\ Y\\\\ 1\\end{pmatrix}\\) La translation est passe dâ€™une addition a une multiplication matriciel.Si on passe en 3D, on a une matrice qui permet dâ€™expliquer la translation en 3D:\\(\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; t_x\\\\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; t_y\\\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; t_z\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\)Mise a lâ€™echelle:\\(\\begin{pmatrix} S_x &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; S_y &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; S_z &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\)Rotation: Suivant un axe canonique:\\[\\begin{pmatrix} \\cos &amp;amp; -\\sin &amp;amp; 0 &amp;amp; 0\\\\ \\sin &amp;amp; \\cos &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\] Suivant un axe quelconque:\\[\\begin{pmatrix} x^2(1 - \\cos) + \\cos &amp;amp; xy(1-\\cos)-z\\sin &amp;amp; xz(1-\\cos) + y\\sin &amp;amp; 0\\\\ yx(1 - \\cos) + z\\sin &amp;amp; y^(1-\\cos)+\\cos &amp;amp; yz(1-\\cos) - x\\sin &amp;amp; 0\\\\ xz(1 - \\cos) + y\\sin &amp;amp; yz(1-\\cos)+x\\sin &amp;amp; z^2(1-\\cos) + \\cos &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\]Modelisation des rotations: Lâ€™ordre des rotations compte Specifier un ordre suivant les axes $O_x$, $O_y$ et $O_z$ Specifier lâ€™axe de rotation Utilisation des quternions $Q=a+bi+cj+dk$ $a,b,c,d$ reels $\\rightarrow$ $a$ partie reelle et $(b,c,d)$ partie imaginaire $I^2=j^2=k^2=-1$ $i.j=k;j.k=i;k.i=j$ $j.i=-k;k.j=-i;i.k=-j$ Les quaternions unites (norme $(Q) = 1$) permettent une representation plus compacte de nâ€™importe quâ€™elle rotation Combinaisom des transformations On peut pre-calculer une matrice qui est lâ€™ensemble des transformations.Rajouter une coordonnees nous permet dâ€™exprimer lâ€™ensemble des transfomrations sous forme dâ€™un produit matriciel." }, { "title": "BOOM: La tranformee et Series de Fourier", "url": "/cours/posts/boom_SF_TF/", "categories": "Image S8, BOOM", "tags": "Image, BOOM, S8", "date": "2021-02-17 10:00:00 +0100", "snippet": "Lien de la note HackmdTheoreme de superpositionComment sâ€™appelle le theoreme a lâ€™origine de la transformee de Fourier ?Tous les signaux peuvent etre reconstruits a partir de sinusoides. Theoreme de superposition: tous les signaux compliques sont une superposition de signaux simples.Exemples La musique Le son Les rides sur lâ€™eau premier signal decompose de cette maniere: la lumiere blanche somme de toutes les longueurs dâ€™ondes des differentes couleurs on a tous les memes recepteurs en theorie, on est + ou - sensibles en pratique Being discrete but looking continuousInside some audio file:Partie rouge: la note de musique quâ€™on entend depuis le debut du cours: abscisses: frequence ordonnee: hauteurSampling the real world Physical phenomena are continous by nature (light, sound pressure, temperature, current, voltage, etc) and must somehow be discretized in order to be digitally handled and stored on computers. Theoreme de Shannon: pour echantilloner sans pertes, on doit echantilloner a une frequence 2x superieure a celle du signal.Quand on echantillone un son, on veut avoir le meme son que dans la vraie vie mais on veut pas un fichier de 3To. Le but dâ€™echantillonage est de trouver le meilleur echantillonage possible pour reconstruire un son mais pas avoir un fichier enorme. Fourier: trouver la frequence fondamentale dâ€™un signal.Pas assez precis $\\rightarrow$ sous echantillonageTrop precis $\\rightarrow$ sur echantillonageHow fast is a signal varying ?Consider the sample signal $x(t) = A_0\\cos(2\\pi f_0t)$ On parle de serie de Fourier et transformee de Fourier, repectivement pour les signaux periodiques purs et les autres. Decomposition en serie de Fourier: trouver les coefficients pour decomposer un signal periodique.Phenomene de Gibbs Au niveau des discontinuites dâ€™un signal: lâ€™approximation oscille beaucoup, câ€™est un effet de bord lors des transformees et series de Fourier.Decomposition en Series de Fourier (SF)Exemple Offset: amplitude moyenne du signal ($A_0$)On va prendre une premiere sinusoide, regarder lâ€™erreur par rapport au signal dâ€™origine et recommencer jusquâ€™a avoir le signal voulu.$b_N$: coefficient des series de Fourier associes au sinus$a_N$: coefficient associes aux cosinusDans ce cas il nâ€™y a que des $b_N$ car on a que des sinus. Dans le cas dâ€™une fonction paire ?Que des coefficients $b_N$ Dans le cas dâ€™une fonction impaire ?Que des coefficients $a_N$Avec lâ€™offset notre fonction $\\widetilde{f}(t)$ nâ€™est ni paire ni impaire. Pour savoir si une fonction est paire ou impaire, on la centre sur lâ€™axe des abcisses (on lui enleve sa moyenne). Nos sinus ont une periodicite $\\frac{n}{T}$Definition $T \\equiv$ periode $f = \\frac{1}{T} \\equiv$ frequence $nf = n \\times \\frac{1}{T} \\equiv$ harmonique de rang $n$ \\(x(t) = a_0 + \\sum^{+\\infty}_{n = 1} \\biggr(a_n\\cos(2\\pi\\frac{n}{T}t) + b_n\\sin(2\\pi\\frac{n}{T}t) \\biggr)\\)en tout point de continuite de $x\\in \\mathcal{C}^1$ par morceaux dâ€™apres le theoreme de DIRICHLET. $a_0 =$ moyenne sur une periode $= \\biggr(\\int_0^Tx(t)dt\\biggr)\\times\\frac{1}{T} \\equiv$ offset $(\\big\\updownarrow)$ \\[\\forall n \\ge 1 \\begin{cases}a_n &amp;amp;= \\frac{2}{T}\\int^T_0x(t)\\cos(2\\pi\\frac{n}{T}t)dt\\\\b_n &amp;amp;= \\frac{2}{T}\\int^T_0x(t)\\sin(2\\pi\\frac{n}{T}t)dt\\end{cases}\\] Phenomene de GibbsSi $x$ est discontinu en $t$, la serie converge vers $\\frac{1}{2}(x(t^-)+x(t^+))$. $\\Delta(x(t_0)) = \\vert x(t_0^-) - x(t_0^+)\\vert \\Rightarrow$ le sursaut en $x(t_0^-)$ et $x(t_0^+)$de la somme partielle $S_n(t)$ est de lâ€™ordre de $0,09\\Delta x(t_0)$Proprietes Si $x$ est pair, $b_n = 0 \\forall n \\in \\mathbb{N}^*$ Si $x$ est impair, $a_n = 0 \\forall n \\in \\mathbb{N}^*$$\\Rightarrow$ parite â€œmodulo lâ€™offsetâ€Vive les nombres complexes ! \\(x(t)=\\underbrace{a_0+\\sum^{+\\infty}_{n=1}\\biggr(a_n\\cos(2\\pi\\frac{n}{T}t) + b_n\\sin(2\\pi\\frac{n}{T}t)\\biggr)}_{\\text{coeffs reels}} = \\underbrace{\\sum^{+\\infty}_{n=-\\infty}C_ne^{i2\\pi\\frac{n}{T}t}}_{\\text{coeffs complexes}}\\)\\(\\forall n \\in\\mathbb{Z}, C_n = \\frac{1}{T}\\int^T_0x(t)e^{-i2\\pi\\frac{n}{T}t}\\) ${\\vert C_n\\vert, n\\in\\mathbb{Z}}$ sâ€™appelle le spectre du signal. $\\forall n \\ge 1, C_n = \\overline{C_{-n}}$Egalite de Parseval Lâ€™energie dâ€™un signal est ce qui va caracteriser le signal, elle sera conservee entre temporel et frequenciel. \\(\\frac{1}{T}\\int^T_0\\vert x(t)\\vert^2dt = \\sum^{+\\infty}_{n = -\\infty}\\vert C_n\\vert^2 = a_0^2 + \\frac{1}{2}\\sum^{+\\infty}_{n=1}(a_n^2+b_n^2)\\)Transformee de Fourier (TF)Definition\\(\\begin{aligned}X:\\mathbb{R} &amp;amp;\\to \\mathbb{C}\\\\\\nu&amp;amp;\\mapsto\\int_{\\mathbb{R}}x(t)e^{-i2\\pi\\nu t}dt\\end{aligned}\\)\\(\\begin{aligned}\\nu&amp;amp;\\equiv\\text{ frequence}\\\\ &amp;amp;\\equiv\\frac{n}{T}\\end{aligned}\\) Tansformee de Fourier (TF pour les intimes) $\\equiv$ decomposition en serie de Fourier ou les harmoniques varient de maniere continueTF inverse\\(x(t)=\\int_{\\mathbb{R}}X(\\nu)e^{+i2\\pi\\nu t}d\\nu\\)Proprietes de la TF $x$ est reel et pair $\\Leftrightarrow X$ reel et pair $x$ est reel et impair $\\Leftrightarrow X$ imaginaire pur et impair \\[\\begin{aligned}X(\\nu) &amp;amp;= \\Re e (X(\\nu)) + i\\Im m(X(\\nu))\\\\ &amp;amp;= \\vert \\underbrace{X}_{\\text{module}}(\\nu)\\vert e ^{i\\underbrace{\\phi}_{\\text{phase}}(X(\\nu))}\\end{aligned}\\] spectre $= \\vert X(\\nu)\\vert\\equiv$ lâ€™amplitude des frequences dans $x$ phase $\\equiv$ position des frequences dans le signalTheoreme de Plancherel \\(\\mathcal{F}(x*y) = \\mathcal{F}(x) \\times \\mathcal{F}(y)\\\\\\mathcal{F}(x\\times y) = \\mathcal{F}(x) * \\mathcal{F}(y)\\)$z = x\\times y \\Rightarrow Z(\\nu) = X(\\nu)Y(\\nu)$$x* y = \\mathcal{F}^{-1}(X(\\nu)\\times Y(\\nu))$Dirac \\(\\delta(t)\\begin{cases} = 0 &amp;amp;\\text{si } t \\neq 0\\\\ =+\\infty &amp;amp; \\text{si } t = 0\\end{cases}\\text{et}\\int_{\\mathbb{R}}\\delta(t)dt = 1\\)Peigne de Dirac\\(\\begin{aligned}Ğ¨_T : \\mathbb{R} &amp;amp;\\to \\mathbb{R}\\\\t &amp;amp;\\mapsto \\sum_{n\\in\\mathbb{Z}}\\delta(t-nT)\\end{aligned}\\) Signal echantillonne: $x_e(t) = x(t) \\times Ğ¨_{Te}(t)$$\\Rightarrow$ Theoreme de Shannon: $\\nu e \\ge 2\\nu_{max}$ (pour eviter la perte dâ€™information)" }, { "title": "BOOM: La correlation et la convolution", "url": "/cours/posts/boom_correlation_convolution/", "categories": "Image S8, BOOM", "tags": "Image, BOOM, S8", "date": "2021-02-15 10:00:00 +0100", "snippet": "Lien de la note Hackmd Les TD et TP ne sont pas notes et ont des corrections (a la fin de la semaine).Typical reaction of an average EPITA students when he discovered that this cours was about the Fourier transform Lâ€™ordi dâ€™Elodie crash ? â€œMathÃ©matiques du â€œpas de signalâ€â€Piqure de rappelOn a entendu une magnifique note de piano puis une note de piano bruitee.On va regarder les signaux:Lequel est bruite et lequel nâ€™est pas bruite ? Resultat: celui de gauche. Oscillations rapides: hautes frequences.Le signal de gauche câ€™est notre signal + un autre signal qui oscille tres vite. Le but câ€™est de reperer quelles frequencer enlever. Filtrage de signal: selection de certaines frequences ou suppression dâ€™autres. Comme les chercheurs dâ€™or: on met le sable dans le tamis et on tamise, les mailles laisse passer le sable et garde les pepites.Dans ce cas, on supprime les hautes frequences (en theorie).Dâ€™ou peut venir le bruit ?Peut etre lie au capteur, sâ€™applique aussi en Image, on a besoin de connaitre les bruits pour les enlever.En pratique, toujours une petite correlation. Quand on parle de mathematiques de signaux, on lâ€™applique aussi a lâ€™image car câ€™est un signal en 2D; le traitement dâ€™image est une sous-partie du traitement du signal. Les bibliotheques utilisees en python nâ€™ont pas toutes la meme representation de lâ€™image. Certaines bibliotheques transforment lâ€™image en 1D et dâ€™autres en 2D. Convolution en 1D sur du signal est + ou - la meme en 2D sur les images.A droite: transformee de Fourier du signal classique et a gauche signal bruite.On a un â€œpateâ€ en bas. Si on zoom:Les signauxQuâ€™est-ce quâ€™un signal ? Quelque chose qui evolue au cours du temps, quâ€™on peut mesurer (ex: la temperature; la mesure reguliere la transforme en signal, un electrocardiogrammeâ€¦).Un flux dâ€™electron quâ€™on va mesurer.Lâ€™image Une image est aussi un signal car il y a une mesure: la mesure du nombres de photons qui arrivent. Les images en noir et blanc nâ€™existe pas, ce sont des photos en niveaux de gris.Prendre une photo avec un telephone: on a un capteur et plus un photon tape a un endroit plus le pixel sera blanc. Plus on laisse le capteur â€œouvertâ€, plus on capte de photons et lâ€™image sera plus net.Le signalA quoi ca sert ?Verifier les risques dâ€™incendie (temperature + humidite), le rechauffement climatique, etc. Les signaux sont utiles pour les statistiquesExemple: le radar Ne pas toucher a cette fenetre !Cas parfait: signal continu.On envoie un signal et on compte le temps que ca prend pour revenir. Attention aux variations avec lâ€™air, lâ€™eau, le vide, etc.Les chauves-souris le font â€œautomatiqumentâ€ mais attention a lâ€™effet Dopler: si une mouche bouge, la frequence renvoyee est modifiee.Premier problemeNotre chauve-souris envoie un signal continu mais nos ordis ont pas une memoire infinie et le signal risque dâ€™avoir du bruit a cause du capteur, numerisation, etc On passe dâ€™un monde analogique a numerique et il risque dâ€™y avoir de la perte dâ€™information $\\rightarrow$ problemes dâ€™effets de bords.Cas reelOn recupere un signal decale et bruite.Les outils pour traiter ce signal: la correlation Lâ€™ensemble des signaux forment un espace vectoriel. La ressemblance = la correlation La norme = la distanceLa ressemblance est max quand ?Quand on a une superposition des deux signaux. On va â€œglisserâ€ le signal de gauche sur celui de droite et calculer la ressemblance, cad la correlation ou une integrale (lâ€™aire sous la courbe des 2 signaux).Quand on va faire, on ne va pas avoir la correlation maximale theorique. Dans la correlation: Lâ€™auto-correlation Entre 2 signaux $x$ et $x$ Entre le meme signal sans aucune modification Nous sert a definir lâ€™espace des calculs quâ€™on va faire Lâ€™inter-correlation Entre 2 signaux $x$ et $y$ Dans ce cas câ€™est lâ€™inter-correlation.Notre correlation est maximale en $-5$ car on a un decalage de $-5s$Recap sur le bruitPourquoi on arrive quand meme a retrouver notre signal de base ? La correlation entre le signal et le bruit est nulle car le bruit est non-correle.La correlationDefinition\\(\\Gamma_{xx}(\\tau) = \\int_{\\mathbb{R}}x(t)\\overline{x(t-\\tau)}dt = &amp;lt;x(t),x(t-\\tau)&amp;gt;\\)$\\Gamma_{xx}(0)$ est maximale car il nâ€™y a pas de decalage\\[\\begin{aligned}&amp;amp;= &amp;lt;x(t), x(t)&amp;gt;\\\\&amp;amp;= \\int_{\\mathbb{R}}|x(t)|^2\\\\&amp;amp;= ||x(t)||^2 = \\text{ENERGIE du signal}\\end{aligned}\\]Proprietes Dans le cas des signaux reels, si $x$ est reel, lâ€™auto-correlation est paire: $\\Gamma_{xx}(-\\tau) = \\Gamma_{xx}(\\tau)$ Inter-correlation:\\(\\Gamma_{xy}(\\tau) = \\int_{\\mathbb{R}}x(t)\\overline{y(t-\\tau)}dt = &amp;lt;x(t),y(t-\\tau)&amp;gt;\\) Câ€™est la formule quâ€™on utilisera.Lâ€™inter-correlation est nulle si les signaux ne sâ€™intersectent pas. On prend un signal, on le fait glisser sur un autre et on calcul la multiplication des aires sous la courbes de lâ€™intersection des 2.Cas du radarOn envoie $x(t)$ et on recupere $y = x(t-t_0) + \\nu(t)$ $\\nu(t)$ : bruit $x(t-t_0)$ : signal retarde de $t_0$Le bruit depend de $t$ et pas de $x$.\\[\\begin{aligned}\\Gamma_{xy}(\\tau) = &amp;lt;x(t),y(t-\\tau)&amp;gt; &amp;amp;= &amp;lt;x(t),\\overbrace{x(t - (\\tau + t_0) + \\nu(t-\\tau))}^{y(t-\\tau)}&amp;gt;\\\\&amp;amp;= &amp;lt;x(t), x(t - (\\tau + t_0))&amp;gt; + \\underbrace{&amp;lt;x(t),\\nu(t-\\tau)&amp;gt;}_{=0}\\\\&amp;amp;= \\Gamma{xx}(\\tau-t_0)\\end{aligned}\\]$\\Gamma{xx}(\\tau+t_0)$ est maximal en $0$:\\(\\tau + t_0 = 0 \\Rightarrow \\tau=-t_0\\)Sur le notebook: les courbes ne sont pas arrondies, si on zoom dessus on pourrait voir des traits.La convolution On va parler de convolution continue: En numerique: des sommes En analogique: des integrales Avec la convolution, possible de recuperer un signal debruite:On veut recuperer notre signal a partir du gros pate bleu. La convolution est utilisee pour debruiter des signaux tout le temps.Câ€™est faisable avec la correlation mais plus chiant. Convolution avec une image: probleme aux bords. La â€œfenetre glissanteâ€ passant sur une image risque de sortir du bord de lâ€™image.Attention a comment on gere les bords.ExempleDefinition\\((f*g)(t) = \\int_{-\\infty}^{+\\infty}g(x)f(t-x)dx = \\int_{-\\infty}^{+\\infty}g(x)f(t-x)dx = (g*f)(t)\\)Difference de la correlation: On ne prend pas le conjugue, $t-x$ inverse $g$ Il nâ€™y a pas de $t-\\tau$Proprietes Element neutre de la convolution: le delta de Dirac\\[f*g=g*f=f \\Rightarrow g \\equiv \\delta:t\\to\\begin{cases} 0 &amp;amp; t\\neq 0\\\\ +\\infty &amp;amp; t= 0\\end{cases}\\text{et}\\int_{\\mathbb{R}}\\delta(t)dt = 1\\] Si $f$ et $g$ sont de meme parite: $f*g$ est paire. Si $f$ et $g$ sont de parite contraire: $f*g$ est impaire." }, { "title": "AWS TD 4 - Modules 9 and 10", "url": "/cours/posts/aws_td_4/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 18:30:00 +0100", "snippet": "Lien de la note HackmdAWS TD 4Any company La loi de Conway: â€œles organisations qui conÃ§oivent des systÃ¨mes [â€¦] tendent inÃ©vitablement Ã  produire des designs qui sont des copies de la structure de communication de leur organisation. â€œDudil: lorsque tu demandes a un parti tiers de tâ€™auditer pour montrer ta bonne foi Quand tu te fais racheter, tu caches les cadavres et tu repeint les murs.AnyCompany backgroundAnyCompany architecture: Fly and SnapAnyCompany architecture: Show and Sell" }, { "title": "AWS Module 10 - Automatic Scaling and Monitoring", "url": "/cours/posts/aws_module_10/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 11:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Load Balancing Distributes incoming app or network traffic across multiple targets in a single or multiples AZ Scales your load balance as traffic to your aapp changes over time Types of loads balancersHow Elastic Loads Balancing works With Application Load Balncers and Network Load Balancers, you register targets in traffic to the target groups With Classic Load Balancers, you register instance with the load balancer Load balancer performs health checks to monitor health of registered targetsElastic Load Balancing use cases High available and fault-tolerant app Containerized app Elasticity and scalability VPC Hybrid environments Incoke Lambad functions over HTTP(S)Load balancer monitoring Amazon CloudWatch metrics Used to verify that the system is performing as expected and creates an alarm to initiate an action if a metric goes outside an acceptable range Access logs Capture detailed information about requests sent to your load balancer AWS CloudTrail logs Capture the who, what, when, and where of API interactions in AWS services Section 2: Amazon CloudWatchMonitoring AWS resourcesTo use AWS efficiently, you need insight into your AWS resources: How do you know when you should launch more Amazon EC2 instances ? Is your appâ€™s performance or availability being affected by a lack of sufficient capacity ? How much of your infrastructure is actually being used ?Amazon CloudWatch Monitors AWS resources App that run on AWS Collect and track Standard metrics Custom metrics Alarms Send notifications to an Amazon SNS topic Perform Amazon EC2 Auto Scaling or Amazon EC2 actions Events Define rules to match changes in AWS environment and route these events to one or more target functions or streams for processing CloudWatch alarsm Create alarms basde on Static threshold Anomlay detection Metric math expression Specify Namespace Metric Statistic Period Conditions Additional configuration Actions Section 3: Amazon EC2 Auto ScalingWhy is scaling important ? Scaling is the ability ot increase of decrease the compute capacity of your app. First graph: unused capacity on most days of the week, not cost optimized Second graph: under capacity on certain days Automatic capacity scaling is necessary to support the fluctuating demands for service.Amazon EC2 Auto Scaling Hels you maintaint app Enables you to automatically add or remove EC2 instances according to conditions that you define Detects impaired EC2 instances and unhealthy app, and replaces the instances without your intervention Provides several scaling options Manual Scheduled Dynamic (on-demand) Predictive Typical weekly traffic at Amazon.comNovember traffic to Amazon.comAuto Scaling groups An Auto Scaling group is a collection of EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. Scaling ou vs scaling inHow Amazon EC2 Auto Scaling worksImplementing dynamic scalingAWS Auto Scaling Monitors you app and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost Provides a simple, powerful user interface that enables you to build scaling plans for resources, including Amazon EC2 instances and Spot Fleet Amazon Elastic Container Service (Amazon ECS) Tasks Amazon DynamoDB tables and indexes Amazon Aurora Replicas Wrap-upWhich service would you sue to send alerts base on Amazon CloudWatch alarms ? Amazon Simple Notification Service AWS CloudTrail AWS Trusted Advisor Amazon Route 53 Answer Keywords: send alerts Amazon CloudWatch Alarms Answer: 1." }, { "title": "AWS Module 9 - Cloud Architecture", "url": "/cours/posts/aws_module_9/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS Well-Archtitected FrameworkArchitecture: designing and building Architecture is the art and science of designing and building large structure. manage size and complexity identify business goals capabilities needing improvement alignement between tech deliverables of a solution and business goals work with delivery teamWhat is the AWS Well-Architected Framework ? A guide for designing infrastructure that are Secure High-performing Resilient Efficient A consistent approach to evaluating and implementing cloud architectures A way to provide best practices that were developed through lessons learned by reviewing customer architecturesPillars of the AWS Well-Architected FrameworkPillar organizationBest practice area Identity and Access ManagementQuestion text SEC 1: How do you manage credentials ad authentication ?Question context Credential and authentication mechanisms include password, tokens and keys granting access directly or inderectly in your workload. Protect credentials with appropriate mechanisms to help reduce the risk of accidental or malicious use.Best practices Define requirements of identity and access management Secure AWS account root user Enforce use of multi-factor authentication Automate enforcement of access controls Integrate with centralized federation provider Enforce password requirements Rotate credentials regularly Audit credentials periodicallySection 2: Operational Excellence Pillar Focus Run and monitor systems to deliver business value, and to continually improve supporting processes and procedures Key topics Managing and automating changes Responding to events Defining standards to successfully manage daily operations Operational excellence design principles Perform operations as code Define entire workload (app and infra) Limit human error Consistent responses to event Annotate documentation automating the creation of annoted doc input to your operations as code Make frequent, small, reversible changes components updated regularly Refine operations procedures frequently opportunities to improve procedures Anticipate failure potential sources of failure Learn from all operational events failures share what is learned Operational excellence questions Prepare How do your determine what your priorties are ? How do you design your workload so that you can understand its state ? How do you reduce defects, ease, remediation and improve flow into production ? How do you mitigate deployement risks ? How do you know that you are ready to support a workload ? Operate How do you understand the health of workload ? How do you manage workload and operation events ? Evolve How do you evolve operations ? Section 3: Security Pillar Focus Protecte info, systemes, and assets while delivering business value through risk assessments and mitigation strategies Key topics Identifying and managing who can do what Establishing controls to detect security events Protecting systems and services Protecting confientiality and integrity of data Security design principles Implement a strong identity foundation principle of least privileges separation of duties Enable traceability monitor, alert and audit actions integrate logs and metrics to automatically respond and take action Apply security to all layers defense-in-depth security controls to all layers of your architecture Automate security best practices improve ability to securely scale more rapidly and cost effectively Protect data in transit and at rest classify data into sensitivity levels use mechanisms such as encryption, tokenization and access control Keep people away from data reduce risk of loss or modif of sensitive data due to human error create tools to reduce manual processing of data Prepare for security events incident management process Security questions Identity and access management How do you manage credentials and authentication ? How od you control human access ? Ho do you control programmatic access ? Detective controls How do you detect and investigate security events ? How do you defend against emerging security threats ? Infrastructure protection How do you protect your networks ? How do you protect your compute resources ? Data protection How do you classify your data ? How do you protect your data at rest ? How do you protect your data in transit ? Incident response How od you respond to an incident ? Section 4: Reliabality Pillar Focus Prevent and quickly recover from failures to meet business and customer demand Key topics Setting up Cross-project requirements Recovery planning Handling change Reliability design principles Test recovery procedures test how you system fails validate recovery procedures expore failure pathways Automatically recover from failure monitor systems for key performance indicator configure system to trigger an automated recovery when a threshold is breached Scale horizontally to increase aggregate system availability replace one large resources with multiple smaller one reduce impact of a single point of failure Stop guessing capacity monitor demand and system usage automate the addition or removal of resources to maintain the optimal level Manage change in automation use automation to make changes to infra manage changes to automation Reliability question Foundations How do you manage service limits ? How do you manage your network topology ? Change management How does your system adapt to changes in demand ? How do you monitor your resources ? How do you implement change ? Failure management How do you back up data ? How does your system withstand component failure ? How do you test resilience ? How do you plan for disaster recovery ? Section 5: Performance Efficiency Pillar Focus Use IT and computing resources efficiently to meet system requirements and to maintain that efficiency as demand changes and technologies evolve Key topics Selecing thr right resource types and sizes based on workload requirements Monitoring performances Making informed decisions to maintain efficiency as business needs evolve Performance efficiency design principles Democratize advanced technologies consume tech as a service focus on product dev Go global in minutes deploy systems in multiple AZ Use serverless architectures remove operational burden of maintaining servers reduce costs Experiment more often comparative testing Have mechanical sympathy use tech approach aligning best with what you want to achieve Performance efficiency question Selection How do you select the best performing architecture ? How do you select your compute solution ? How do you select your storage solution ? How do you select your db solution ? How do you select your networking solution ? Review How do you evolve your workload to rake advantageof new releases ? Monitoring How do your monitor your resources to ensure they are performing as expected ? Tradeoffs How do you use tradeoffs to improve performance ? Section 6: Cost Optimization Pillar Focus Run systems to deliver business value at the lowest price point Key topics Understanding and controlling when money is being spent Selecting the most appropriate and right number of resource types Analyzing spending over time Scaling to meeting business needs without overspending Cost optimization design principles Adopt a consumption mode pay only for the computing resources required Measure overall efficiency measure business output cost associated measure the gain you are making Stop spending money on data centers operations AWS does the heavy-lifting Analyze and attribute expenditure accuratly identify system usage and cost Use managed and application-level services to reduce cost of ownership reduce operational burden of maintaining servers for tasks lower cost per transaction Cost optimization questions Expenditure awareness How do you govern usage ? How do you monitor usage and cost ? How od you decommission resources ? Cost-effective resources How do you evaluate cost when you select services ? How do you meet cost target when you select resource type and size ? How do you you use pricing models to reduce cost ? How do you plan for data transfer changes ? Matching supply and demand How do you match supply of resources with demand ? Optimizing over time How do you evaluate new services ? Section 7: Reliability and Availability â€œEverything fails, all the timeâ€ - Werner Vogels, CTO, Amazon.comReliability A measure of your systemâ€™s ability to provide functionality when desired by the user System includes: hardware, software, firmware Probability that your entire system will function as intended for a specified period Mean time between failures (MTBF) = total time in serviceumber of failuresUnderstanding reliability metricsAvailability Normal operation time / total time A percentage of uptime (ex: 99.9%) over time (ex: 1y) Number of 9s - 5 9s means 99.999% availabilityHigh availability System can withstand some measure of degradation while still remaining available Downtime is minimized Minimal human intervention is requiredAvailability tiersFactors that influenc availability Fault tolerance The built-in redundancy of an app compononents and its ability to remain operational Scalability The ability of an app to accomodate increases in capacity needs without changing design Recoverability The process, policies, and procedures that are related to restoring service after a catastrophic event Section 8: AWS Trusted Advisor Online tool that provides real-time guidnace to help you provision your resources following AWS best practices Looks at your entire AWS enivronment and gives you a real time recommendations in Cost Optimization eliminating unused resources commitment to reserve capacity Performance checking service limit service throughput Security improve security of the app by identifying gaps permissions increase availability and redundancy Fault Tolerance service usage more than 80% of the service limit values based on snapshot Wrap-upA SysOps engineer working at a company wants to protect their data in transit and at rest. What service could they use to protect their data ? Elastic Load Balancibg Amazon Elastic Block Stor (Amazon EBS) Amazon Simple Storage Service (Amazon S3) All of the above Answer Keywords: protect their data in transit and at rest Answer: 4." }, { "title": "AWS TD 3 - Modules 7 and 8", "url": "/cours/posts/aws_td_3/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 18:30:00 +0100", "snippet": "Lien de la note Hackmd Lâ€™exam de la certif est beaucoup plus dur que les knowledge checks.Il existe 2 types de devices: char device block device" }, { "title": "MBTI - Les differents types de personnalite", "url": "/cours/posts/mbti_1/", "categories": "tronc commun S8, MBTI", "tags": "tronc commun, MBTI, S8", "date": "2021-02-11 14:00:00 +0100", "snippet": "Lien de la note HackmdPrÃ©sentationAnne Dewilde Directrice Labo 3IE 15 ans chez HP TravaillÃ© dans Le secteur de la dÃ©fense Le secteur banque/assurance Le cours: approche de connaissance de soi Lâ€™Ã©cole veut mettre lâ€™accent sur les soft skills.Exercice dâ€™introspection sur soi-mÃªme Veut en aucun cas nous caller dans des cases Exercice difficile DÃ©velopper notre savoir-ÃªtreExercie SUR FEUILLE 5 mots qui nous caractÃ©risent 2 mots random et on signe Les mÃªme mot et signature mais avec lâ€™autre mainQuels retours sur le dernier exo ? Pas ambidextre La signature change totalement Ecrit aussi mal avec les 2 mains Identifier nos zones de prÃ©fÃ©rence.QuestionnaireQuestionnaire CCTITotal de 11 par colonne, câ€™est un indicateur de clartÃ©.MBTIHistorique MBTI sâ€™appuie sur la thÃ©orie de la personnalitÃ© de Carl Jung Le modÃ¨le a Ã©tÃ© mis au point par Briggs Et Myers Rare modÃ¨le de personnalitÃ© qui dÃ©cit de maniÃ¨re positiveRecherche 20 ans de recherche 4000 articles scientifiques AmÃ©liorÃ© et maj en continuLa rÃ¨gle dâ€™or Les diffÃ©rences de comportement que nous observons ne sont pas du hasardPoints importants Pas de bon ou mauvais type Tout le monde peut utiliser les huit prÃ©fÃ©rences Chacun meilleur juge de son type DÃ©termine ni aptitudes, ni compÃ©tences MBTI utilisÃ© quâ€™en dev et pas sÃ©lection Â  Ce que je sais Ce que je ne sais pas Ce que les autres savent Ouvert Aveugle Ce que les autres ne savent pas CachÃ© Inconnu $\\rightarrow$: feedback $\\downarrow$: ouverture Diagonale: luciditÃ©Lâ€™orientation de lâ€™Ã©nergie Certains dâ€™entre nous sont attirÃ©s par le monde extÃ©rieur (E) StimulÃ© par les gens Action rÃ©flexion action Souvent amical Exprime ses Ã©motions A besoin de contact Elargit Peut sembler superficiel Ã  un I Dâ€™autre le monde intÃ©rieur (I) StimulÃ© par les pensÃ©es RÃ©flexion action rÃ©flexion Souvent rÃ©servÃ© Ravale ses Ã©motions A besoin dâ€™intimitÃ© Approfondit Peu sembler Ã©loignÃ© Ã  un E Modes de perception PrÃ©fÃ©rences pour la Sensation et lâ€™iNtuition Certains prÃ©fÃ¨rent les fait prÃ©cis (S) Vit dans le prÃ©sent et savoure ActivitÃ©s concrÃ¨tes Commence par le dÃ©but, avance pas Ã  pas Manipule les piÃ¨ces pour trouver lâ€™assemblage par tÃ¢tonnements Aime les procÃ©dures et dÃ©marches Ã©prouvÃ©es Peut sembler matÃ©rialiste pour un N Dâ€™autres ont une vue dâ€™ensemble (N) Vit tournÃ© vers lâ€™avenir PrÃ©fÃ¨re imaginer des possibilitÃ©s ProcÃ¨de par bonds, saute les Ã©tapes Etudie le schÃ©ma dâ€™ensemble pour comprendre comment les piÃ¨ces sâ€™assemblent Aime le changement et la variÃ©tÃ© Peut sembler inconscient pour un S CritÃ¨res de dÃ©cision T: thinking F: feeling Certains procÃ¨dent plutÃ´t dâ€™une maniÃ¨re logique avec une grille de critÃ¨res (T) VÃ©ritÃ©, justice Regarde les Ã©vÃ¨nements en spectateur extÃ©rieur Commence Ã  voir ce qui ne va pas Bon pour analyser des plans Peu sembler froid et condescendant Ã  F Dâ€™autres se dÃ©cident selons leurs sentiments et leurs valeurs (F) Relations humaines Regarde les Ã©vÃ¨nements en participant Commence par apprÃ©cier spontanÃ©ment Bon pour comprendre les gens Peu sembler brouillon et sensible Ã  T Organisation J: Judgement P: Perception Aime prendre des dÃ©cisions Curieux, aime lâ€™imprÃ©vu" }, { "title": "AWS Module 8 - Databases", "url": "/cours/posts/aws_module_8/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 11:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Amazon Realtional Database Service (RDS)Unmnagade vs managed servicesUnmanagedmanaged by you: Scaling Fault tolerance AvailabilityMore fine-tune controlManagedbuilt in the service: Scaling Fault tolerance AvailabilityRequires less configurationChallenges of relational databases Server maintenance and energy footprint Software installation and patches Database backups and high availability Limits on scalability Data security OS installation and patchesAmazon RDS Managed services that sets up and operates a relational database in the cloudManaged services responsabilitiesYou manage App optiAWS manages: OS installation and patches Databse software installation and patches Database backups High availability Scaling Power and racking and stacking servers Server maintenanceAmazon RDS DB instancesAmazon RDS in a VPC Select IP address range Subnets Configure routing and access control listHigh availability with Multi-AZ deployement1 Automatically generates a standby copy in another AZ within the same VPC Enhanced availability2 If the main database instance fails, Amazon RDS automatically brings the standby instance online.Amazon RDS read replicasFeatures Offers asynchronous replication Can be promoted to master if neededFunctionality Use for read-heavy database workloads Offload read queriesUse casesWhen to Use Amazon RDS Use Amazon RDS when your app requires Do not use Amazon RDS when your app requires Complex transactions or complex queries Massive read/write rates A medium to high query or write rate (Up to 30,000 IOPS) Sharding due to high data size or throughput demands No more than a single worker node or shard Simple GET or PUT requests and queries that a NoSQL database can handle High durability Relational database managemnet (RDBMS) customization Amazon RDS: Clock-hour billing and db characteristicsClock-hour billing Resources incur charges when runningDatabas characteristics Physical capacity Engine Size Memory class Amazon RDS: DB purchase type and multiple DB instancesDB purcharse type On-demand isntances Compute capacity by the hour Reserved Instance Low, one-time, upfront paymenent for db instances that are reserved with a 1-year or 3-year term Number of DB instances Provision multiple DB instance to handle peak loadsAmazon RDS storageProvisioned storage No charge Bakcup storage up to 100% of db storage for an active db Charge (GB/month) Backup storage for terminated DB instances Additional storage Charge (GB/month) Backup storage in addition to provisioned storage Amazon RDS: Deployement type and data transferRequests The number of input and output requests that are made to the dbDeployement type - storage and I/O vary, depending on whether you deploy to Single AZ Multiple AZData transfer No charge for inbound data transfer Tiered charges for outbound data transferSection 2: Amazon DynamoDBRealtion vs non-relation DBWhat is Amazon DynamoDB ? Fast and flexibe NoSQL db service for any scale NoSQL db tables Can be scaled Create tables and add items Global tables Automatically replicates choices across AWS regions Virtually unlimited storage Items can have differing attributes Donâ€™t have to migrate schema Low-latency queries Scalable read/write throughput Store data accross multiples facilities fault-toleratn architecture stored in SSDs encrypt data at rest set time to live Automatically partitions dataAmazon DynamoDB core components Tables, itmes and attributes DynamoDB supports 2 different kinds of primary keys Partition key Sort key Items in a table must have a keySection 3: Amazon RedshiftAmazon Redshift Fast, fully managed data warehouse, simple and cost-effective to analyze data using SQL and business intellignec tools.Introduction to Amazon Redshift Fast and fully-managed data warehouse Pay for what you use Complex analytics queries Parallel processing Only seconds Parallel processing architectureAutomation and scalingAutomate manage monitor scale Security is built-in with encryption of data.Compatibility Supports standard SQL Connect with SQL clients Java connectivity Open DB connectivity Interact direclty with AWS CLI or management consoleAmazon Redshift use cases Enterprise data warehouse (EDW) Migrate at a pace that customers are comfortable with Experiment without large upfront cost or commitment Respond faster to business needs Big data Low price point for small customers Managed service for ease of deployment and maintenance Focus more on data and less on database management SaaS Scale the data warehouse capacity as demand grows Add analytic functionality to app Reduce hardware and software costs Section 4: Amazon Aurora MySQL and PostreSQL compatible relational db built for the cloud. Enterprise-class relational db Compatible with MySQL or PostgreSQL Automate time-consuming tasks (such as provisioning, patching, backup, recovery, failure detection and repair) Can reduce db costsAmazon Aurora service benefits Fast and available Managed service Simple Pay-as-you-go CompatibleHigh availability Storing multiple copies through different AZ Data backed up to Amazon S3 Use up to 15 read replicaResilient design Instant crash recovery Does not need to replay the redo log Do it on every read operation Removes the buffer cache from the db processWrap-upWhich of the following is a fully managed NoSQL db service ? Amazon RDS Amazon DynamoDB Amazon Aurora Amazon Redshift Answer Keywords: NoSQL Answer: 2." }, { "title": "AWS Module 7 - Storage", "url": "/cours/posts/aws_module_7/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Amazon Elastic Block Store (Amazon EBS)Storage Provides persistent block storage volumes with Amazon EC2 instances Called non-volatile storage Replicated within AZAWS Storage options: block storage vs object storageWhat if you want to change one character in a 1-GB file ?Amazon EBS Amazon EBS enables you to create individual storage volumes and attach them to an Amazon EC2 instance Amazon EBS offers block-level storage Volumes are automatically replicated within its AZ Can be backed up automatically to Amazon S3 through snapshots Uses include Boot volumes and storage for Amazon Elastic Compute Cloud (Amazon EC2) instance Data storage with a file system Database hosts Enterprise app Amazon EBS volume typesAmazon EBS Snapshots Point-in-time snapshots Recreate a new volume at any time Encryption Encrypted Amazon EBS volumes No additional cost Elasticity Increase capacity Change to different types Volumes, IOPS and pricing Volumes Amazon EBS volumes persist independently from the instance All volume types are charged by the that is provisioned per month IOPS General Purpose SSD Charged by the amount that you provision in GB per month until storage is released Magnetic Charged by the number of requests to the volume Provisioned IOPS SSD Charged by the amount that you provision in IOPS (multiplied by the percentage of days that you provision for the month Snapshots Added cost of Amazon EBS snapshots to Amazon S3 is per GB-month of data stored Data transfer Inbound data transfer is free Outbound data transfer accross Regions incurs charges Section 2: Amazon Simple Storage Service (Amazon S3)Storage Amazon S3 is object-level storage. If want to change part of a file, must do the change and repload the entier fileAmazon S3 overview Data stored as objects in buckets Virtually unlimited storage Single object is limited to 5 TB Designed for 11 9s of durability Granular access to bucket and objects Data private per default Can set up notification When object is added When object is deleted Amazon S3 stroage classesAmazon S3 offers a range of object-level storage classes that are designed for different use cases Amazon S3 standard High availability High durability Perfomance Frequently access data Amazon S3 Intelligent-Tiering Optimize cost Moving data to the most cost-effective access tier long-live data with unpredictable access pattern Amazon S3 Standard-Infrequent Access (Amazon S3 Standard-IA) Data accessed less frequently long-term storage Amazon S3 One Zone-Infrequent Access (Amazon S3 One Zonw-IA) Data accessed less frequently Stores data in a single availbility zone Amazon S3 Glacier Secure Durable low cost data archiving three retrieval options min to hours Amazon S3 Glacier Deep Archive Lowest cost long-term detention retrieved once or twice a year Amazon S3 bucket URLS (two styles)To upload your data: Create a bucket in an AWS Region Upload almost any number of objects to the bucketBucket path-style URL endpoint:https://s3.ap-northeast-1.amazonaws.com/bucket-nameBucket virtual-hosted-style URL endpointhttps://bucket-name.s3-ap-northeast-1.amazonaws.comData is redundantly stored in the RegionPrevent data lossDesigned for seamless scalingAmazon S3: automatically manage the storage scales to handle high volume of request billed for what you useAccess the data anywhere AWS CLI AWS Management Console SDK Bucket names must be globally unique and DNS compliant: all lowercase, only letters, numbers and dashesAmazon S3 common scenarios Backup and storage Application hosting Media hosting SoftwareAmazon S3 pricing Pay for what you use GBs per month Transfer OUT to other Regions PUT, COPY, POST, LIST and GET requests You do not pay for Transfers IN to Amazon S3 Transfers OUT from Amazon S3 to Amazon CloudFront or Amazon EC2 in the same region Amazon S3: Storage pricingTo estimate Amazon S3 costs: Types of storage classes Standard storage is for 11 9s of durability 4 9s of availability S3 Standard-Infrequent Access (S-IA) is for 11 9s of durability 3 9s of availaibility Amount of storage The number and size of objects Requests Number of requests (GET, PUT, COPY) Type of requests Different rates for GET requests Data transfer Pricing based on amount of data transferred ou of Amazon S3 Region Data transfer in is free, but incur charges for data transferred out Section 3: Amazon Elastic File System (Amazon EFS)Storage Implements storage for EC2 instancesFeatures File storage in the AWS Cloud Works well for big data and analystics, media processing workflows, content management, web serving and home directories Petabyte-scale, low-latency file system Shared storage Elastic capacity Gigabytes to petabytes of data Supports Network File System (NFS) versions 4.0 and 4.1 (NFSv4) Compatible with all Linux-based AMIs for Amazon EC2 Pay for what you useAmazon EFS architectureAmazon EFS implementation create your Amazon EC2 resources and launch your instance Create your Amazon EFSfile system Create your mount targets in the appropriate subnets Connect your Amazon EC2 instances to the mount targets Verify the resources and protection of your AWS accountAmazon EFS resources Mount target Subnet ID Security gorups One or more per file system Create in a VPC subnet One per AZ Must be in the same VPC Tags Key0value pairs Section 4: Amazon S3 GlacierStorage Secure, durable and extremely low-cost data archiving. Archive Any object such as photo, video, file or document stored in Amazon S3 Glacier Bas unit of storage unique ID Vault Container for storing archive Specifies vault name Premissions access policy Vault lock policy Amazon S3 Glacier review Designed to provide 11 9s of durability for objects Supports encryption of data in transit/at rest through Secure Sockets Layr (SSL) or Transpor Layer Security (TLS) Vault lock: enforces compliance through a policy Extremely low-cost for long-term archiving Three options: expedited, standard or bulk Retrieval times from a few minutes to hours Amazon S3 Glacier Storage service for low-cost data archiving and long-term backup Configure lifecycle archiving Amazon S3 content to Amazon S3 Glacier Retrieval options Standard: 3-5 hours Bulk: 5-12 hours Expedited: 1-5 min Amazon S3 Glacier use cases Media asset archiving Healthcare info archiving Regulatory and compliance archiving Sicentific data archiving Digital preservation Magnetic tape replacementUsing Amazon S3 Glacier RESTful web services Java or .NET SDKs Amazon S3 with lifecycle policiesLifecycle policies Amazon S3 lifecycle policies enable you to delete or move objects based on age.Amazon S3 storage classesStorage comparisonServer-side encryptionServer-side encryption: SSE S3 each objects has unique key AES 256 SSE-C Own encryption keys AWS Key Management Service Scaled for the cloud Customer master keys IAM Console or API Access keys How keys can be used Security with Amazon S3 Glacier Controle access with IAM Amazon S3 Glacier encrypts your data with AES-256 Amazon S3 Glacier manages your keys for youWrap-upA company wants to store data that is not frequently accessed. What is the best and cost-effective solution that should be considered ? Amazon S3 Storage Gateway Amazon S3 Glacier Amazon EBS Amazon S32 Answer keyword: not frequently accessed cost-effective solution Answer: 2." }, { "title": "AWS TD 2 - Module 5 and 6", "url": "/cours/posts/aws_td_2/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 19:30:00 +0100", "snippet": "Lien de la note Hackmd Mes draps sont pleins de neige mais a part ca ca va bien - ChewieModule 5VPC Le sol sur lequel on va construire. Un VPC est un sac de subnets. Un VPC existe au sein dâ€™une region. Dedie a notre compte Existe a travers de AZIP addressingSac des differents blocs quâ€™on va prendreRoute tables and routes La table de routage est la â€œrepresentationâ€ dâ€™un router. Elle sâ€™applique a un ou plusieurs subnets et le subnet a exactement une table.VPC endpointsPour eviter de â€œsortirâ€ de Amazon pour aller utiliser dâ€™autres services" }, { "title": "AWS Module 6 - Compute", "url": "/cours/posts/aws_module_6/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 16:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Compute services overviewAWS compute services Amazon EC2: resizable virtual machine Amazon EC2 auto-scaling: define conditions to launch or terminate EC2 instances Amazon ECR: store and retrieve Docker images Amazon ECS: Container orchestration service that supports Docker VMWare Cloud on AWS: hybrid cloud without custom hardware AWS Elastic Beanstalk: run and manage web app AWS Lambda: serverless compute solution Amazon EKS: run managed kubernetes on AWS Amazon LightSail: building app or website AWS Batch: running batch job at any scale AWS Fargate: run containers AWS Outpost: run AWS services in your on-premises data center AWS Serverless Repository: discover, deploy and publish application Categorizing compute servicesChoosing the optimal compute service The optimal compute service or services that you use will depend on your use case Some aspects to consider What is your application design ? What are your usage pattern ? Which configuration settings wll you want to manage ? Selecting the wrong compute solution for an architecture can lead to lower performance efficiency A good starting place: understand the available compute options Section 2: Amazon EC2Amazon Elastic Compute Cloud (Amazon EC2)Example uses of Amazon EC2 instances: App server web server Database server Game server Mail server Media server Catalog server File server Computing server Proxy serverAmazon EC2 overview Amazon Elastic Compute Cloud (Amazon EC2) Provides virtual machines (EC2 instance) in the cloud Fives you full control over the guest operating system (Windows or Linux) on each instance You can launch instances of any size into and Availability Zone anywhere in the world Launch instance from Amazon Machine Images (AMIs) Launch instances with a few clicks or a line of code, and they are ready in minutes You can control traffic to and from instancesLaunching an amazon EC2 instance Nine key decisions when creating a EC2 instance.1. Select an AMI Amazon Machine Image (AMI) Is a template that is used to create an EC2 instance Contains a Windows or Linux OS Often has some software pre-installed AMI choices: Quick Start Linux and Windows AMIs provided by AWS My AMIs Any AMIs that you created AWS Marketplace Pre-configured templates from third parties Community AMIs AMIs shared by others; use at you own risk 2. Select an instance type Consider you use case How will the EC2 instance you create be used ? The instance type that you choose determines Memory (RAM) Processing power (CPU) Disk space and disk type (Storage) Network performance Instance type categories General purpose Compute optimized Memory optimized Storage optimized Accelerated computed Instance types offer family, generation and sizeInstance type naming and sizesBased on use caseNetworking features The network bandwith (GBps) varies by instance type To maximize networking and bandwith performance of your instance type If you have interdependent instances, launch them into a cluster placement group Enable enhanced networking Enhanced networking types are supported on most instance types Enhanced networking types Elastic Network Adapter (ENA): Supports network speeds of up to 100 Gpbds Intel 82599 Virtual Function interface: Supports network speeds of up to 10 Gbps Section 3: Amazon EC2 Part 23. Specify network settings Where should the instance be deployed ? Identify the VPC and optinally the subnet Should a public IP address be automatically assigned ? To make it internet-accessible 4. Attach IAM role (optional) Will software on the EC2 insrance need to interact with other AWS services ? If yes, attach an appropriate IAM Role An AWS Identity and Access Management (IAM) role that is attache to an EC2 instance is kept in an instance profile You are not restricted to attaching a role only at instance launch You can also attach a role to an instance that already exists 5. User data script (optional) Optionally specify a user data script at instance launch Use user data scripts to customize the runtime environment of your instance Script executes the first time the instance starts Can be used strategically Reduce the number of custom AMIs that you build and maintain 6. Specify storage Configure the root volume Where the guest operating system is installed Attach additional storage volumes (optional) AMI might already include more than one volume For each volume, specify: The size of the disk (in GB) The volume type Different types of SSDs and HDDs are available If the volume will be deleted when the instance is terminated If encryption should be used Amazon EC2 storage options Amazon Elastic Block Store (Amazon EBS) Durable, block-level storage volumes You can stop the instance and start it again, and the data will still be there Amazon Elastic Block Store Storage is provided on disls that are attached to the host computer where the EC2 instance is running If the instance stops, data stored here is deleted Other options for storage (not for root volume) Mount an Amazon Elastic File System (Amazon EFS) file system Connect to Amazon Simple Storage Service (Amazon S3) Example storage options Instance 1 characteristics It has an Amazon EBS root volume type for the operating system What will happen if the instance is stopped and then started again ? The OS volume would survive Any data stored on Amazon EBS would remain intact Any data stored in ephemeral volume 1 would be lost Instance 2 characteristics It has an Instance Store root volume type for the operating system What will happen if the instance stops (because of user error or a system malfunction)? All data stored in ephemeral volume 2 would be lost, including the OS Section 4: Amazon EC2 Part 37. Add tags A tag is a label that you can assign to an AWS resource Consists of a key and an optional value Tagging is how you can attach metadata to an EC2 instance Potential benefits from tagging - Filtering, automation, cost allocation and access control8. Security group settings A security group is a set of firewall rules that control traffic to the instance. It exsists outside of the instanceâ€™s guest OS Create rules that specify the source and which ports that network communications can use. Specify the port number and the protocol, such as TCP, UDP or ICMP Specify the source that is allowed to use the rule9. Identify the key pair At instance launch, you specify an existing key pair or create a new key pair A key pair consists of A public key that AWS stores A private key file that you store It enables secure connections to the instance For Windows AMIs Use the private key to obtain the administrator password that you need to log in to your instance For Linux AMIs Use the private key to use SSH to securely connect to your instance Amazon EC2 console view of a running EC2 instanceAnother option: Launch an EC2 instance with the AWS CLI EC2 instances can also be created programmaticallyaws ec2 run-instances --image0id ami-1a2b3c4d --count 1 --instance-type c3.large \\--key-name MyKeyPair --security-groups MySecurityGroup --region us-east-1This example shows how simple the command can be. This command assumes that the key pair and security group already exists More option could be specifiedAmazon EC2 instance lifecycleConsider using an Elastic IP address Rebooting an instanc will not change any IP addresses or DNS hostnames When an instance will not change any IP addresses or DNS hostnames When an instance is stopped and then started again The public IPv4 address and external DNS hostname will change The private IPv4 address and internal DNS hostname do not change If you require a persistent public IP address Associate an Elastic IP address with the instance Elastic IP address characteristics Can be associated with instances in the Region as needed Remains allocated to your account until you choose to release it EC2 instance metadata It is data about your instance While you are connected to the instance, you can view it In a browser: http://169.254.169.254/latest/meta-data/ In a terminal window: curl http://169.254.169.254/latest/meta-data/ Example retrievable values Public IP address, private IP address, public hostname, instance ID, security groups, Region, Availability zone Any user data specified at instance launch can also be accesse at: http://169.254.169.254/latest/user-data/ It can be used to configure or manage a running instance For example, author a configuration script that read the metadata and uses to configure applications or OS settings Amazon CloudWatch for monitoring Use Amazon CloudWatch to monitor EC2 instances Provides near-real-time metrics Provides charts in the Amazon EC2 console Monitoring tab Maintains 15 months of historical data Basic monitoring Default, no additional cost Metric data sent to CloudWatch every 5 minutes Detailed monitoring Fixed monthly rate for seven pre-selected metrics Metric data delivered every 1 min Section 5: Amazon EC2 Cost OptimizationAmazon EC2 pricing models On-Demand Instances Pay by the hour No long-term commitments Elligible for the AWS Free Tier Dedicated Hosts A physical server with EC2 instance capacity fully dedicated to your use Dedicated instances Instances that run in a VPC on a hardware that is dedicated to a single customer Reserverd Instances Full, partial, or no upfront payment for instance you reserve Discount on hourly charge for that instance 1-year or 3-year term Scheduled Reserverd Instances Purchase a capacity reservation that is always available on a recurring schedule you specify 1-year term Spot Instances Instances run as long as they are available and your bid is above the Spot Instance price They can be interrupted by AWS with a 2-minute notification Interruption options include terminated, stopped or hibernated Prices can be significantly less expensive compared to On-Demand Instances Good choice when you have flexibility in when your applications can run Benefits On-Demand Instances Spot Instances Reserved Instances Dedicated Hosts Low cost and flexibility Large scale, dynamic workload Predictability ensures compute capacity is available when needed Save money on licensing costs &amp;lt;/br&amp;gt; Help meet compliance and regulatory requirements Use casesThe 4 pillars of cost optimizationPillar 1: Right size Provision instances to match the need CPU, memory, storage and network throughput Selct appropriate instance types for your use Use Amazon CloudWatch metrics How idle are instances? When Downsizze instances Best practice: right size, then reservePillar 2: Increase elasticity Stop or hibernate amazon EBS-backed instances that are not actively in use Example: non-production development or test instances Use automatic scaling to match needs base on usage Automated and time-based elasticity Pillar 3: Optimal pricing model Leverage the right pricing model for your use case Consider your usage patterns Optimize and combine purchase types Examples: Use On-Demand Instance and Spot Instances for variable workloads Use Reserved Instances for predictable workloads Consider serverless solutions (AWS Lambda)Pillar 4: Optimize storage choices Reduce cost while maintaining storage performance and availability Resixe EBS volumes Changes EBS volumes types Can you meet performance requirements with less expensive storage ? Example: Amazon EBS Throughput Optimized HDD (st1) storage typically costs half as much as the default General Purpose SSD (gp2) storage option Delete EBS snapshots that are no longer needed Identify the most appropriate destination for specific types of data Does the app need the instance to reside on Amazon EBS ? Amazon S3 storage options with lifecycle policies can reduce costs Measure, monitor and improve Cost optimization is an ongoing process Recommendations Define and enforce cost allocation tagging Define metrics, set targets, and review regularly Encourage teams to architect for cost Assign the responsibility of optimization to an individual or to a team Section 6: Container servicesContainer basics Containers are a method of operating system virtualizationBenefits: Repeatable Self-contained environments Software runs the same in different environments Developerâ€™s laptop, test, prod Faster to launch and stop or terminate than virtual machinesWhat is Docker ? Docker is a software platform that enables you to build, test, and deploy app quickly. You run containers on Docker Containers are created from a template called an image A container has everything a software app needs to runContainers vs VMsAmazon Elastic Container Service (Amazon ECS) A highly scalable, fast, container management service. Key benefit Ocherstartes the running of Docker containers Maintains and scales the fleet of nodes that run your containers Removes the complexity of standing up the infrastucture Integrated with features that are familiar to Amazon EC2 service users Elastic Load Balancing Amazon EC2 security groups Amazon EBS volumes IAM roles Amazon ECS orchestrates containersAmazon ECS cluster optionsDo you want to manage the Amazon ECS cluster that runs the containers ? Yes: create an Amazon ECS cluster backed by Amazon EC2 Provides more granular control over infrastructure No: create an Amazon ECS cluster back by AWS Fargate Easier to maintain, focus on your app What is Kubernetes ? Kubernetes is open source software for containers orchestration deploy and manage containerized app at scale The same toolset can be used on premises and in the cloud Complements Docker Docker enables you to run mutliple containers on a single OS host Kubernetes orchestrates mutliple Docker hosts (nodes) Automates Container provisioning Networking Load distribution Scaling Amazon Elastic Kubernetes Service (Amazon EKS) EKS Enables you to run Kubernetes on AWS Certified Kubernetes conformant Supports Linux and Windows containers Compatible with Kubernetes community tools and add-ons Use Amazon EKS to Manage clusters of Amazon EC2 instances Run containers that ar ochestrated by Kubernetes on those instances Amazon Elastic Container Registry (Amazon ECR) Amazon ECR is a fully managed Docker container registry that makes it easy for developpers to store, manage and deploy Docker container images. Supports Team collab Acces control Third party integration Possible to use with Amazon EKSSection 7: Introduction to AWS LambdaAWS Lambda: Run code without servers AWS Lambda is a serverless compute service.Benefits of Lambda Supports multiple programming languages Completely automated administration Built-in fault tolerance Supports orchestration of multiple functions Pay-per-use pricingAWS Lambda event sourcesAWS Lambda function configuration Create lambda function: give a name Runtime environment Python Node.js Execution role to grant IAM permission to the function to interact with other services Configure the function adding a trigger Add function code Specify the memory in megabytes (up to 3008MGB) Specify env variableSchedule-based Lambda function example: start and stop EC2 instancesEnvent-based Lambda function example: create thumbnail imagesAWS Lambda limitsSoft limits per Region Concurrent executions = 1,000 Function and layer storage = 75GBHard limits for individual function: Max function memory alloc = 3,008 MB Function tiemout = 15 min Deployement package size = 250 MB unzipped, including layersSection 8: Introduction to AWS Elastic BeanstalkAWS Elastic Beanstalk An easy way to get web app up and running A managed service that automatically handles Infra provisionning and config Deployement Load balancing Automatic scaling Health monitoring Analysis and debugging Logging No additional charge for Elastic Beanstalk Pay only for the underlying ressources that are used AWS Elastic Beanstalk deployements Supports web app written for common platforms Java, .NET, PHP, Node.js, Python, Ruby, Go and Docker You upload your code Elastic Beanstalk automatically handles the deployement Deploys on servers such as Apache, NGINX, Passenger, Puma, and Microsoft Internet Information Services (IIS) Benefits of Elastic BeanstalkWrap-upWhich AWS service helps developers quickly deploy resources which can make use of different programming languages, such as .Net and Java ? AWS CloudFormation AWS SQS AWS Elastic Beanstalk Amazon Elastic Compute Cloud (Amazon EC2) Answer Keywords: developers quickly deploy resources different programming languages Answer 3." }, { "title": "AWS Module 5 - Networking and Content Delivery", "url": "/cours/posts/aws_module_5/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 14:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Networking basicsNetworks A computer network is 2 or more machine connected together A network can be partitionned into subnets Requires a networking device (router/switch)IP addresses Each machine on the network has a unique Internet Protocol address (IP) assigned to it Unique number assigned to a machine Four decimal number separated by dots Each number is 8 bits max (between 0 and 255) $\\rightarrow$ total = 32 bitsIPv4 and IPv6 addresses IPv4 (32-bit) address: 192.0.2.0 IPv6 (128-bit) address: 2600:1f18:22ba:8c00:ba86:a05e:a5ba:00FF Adapt to more user Each column is 16 bits (0 to FFFF) Classless Inter-Domain Routing (CIDR) A CIDR adress is expressed as an IP address and is the first address of the network. Itâ€™s followed by a â€˜/â€™ character The numer after is how many bits of the routing prefix must be steady Express a group of addressesOpen Systems Interconnection (OSI) modelSection 2: Amazon VPCAmazon VPC Private space in Amazon Cloud Enables you to provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define Gives you control over your virtual networking resources Selection of IP address range Creation of subnets Configuration of route tables and network gateways Enables you to customize the network configuration for your VPC Enables you to use multiples layers of security Can use IPv4 and IPv6VPCs and subnets VPCs: Logically isolated from other VPCs Dedicated to your AWS account Belong to a single AWS Region and can span multiple Availability Zones Subnets: Range of IP addresses that divide a VPC Belong to a single Availability Zone Classified as public or private Do not have a direct access to internet IP addressing When you create a VPC, you assign it to an IPv4 CIDR block (range of private IPv4 addresses) You cannot change the address raneg after you create the VPC The largest IPv4 CIDR block size is /16 The smallest IPv4 CIDR block size /28 IPv6 is also supported (with a different block size limit) CIDR blocks of subnet cannot overlapReserved IP addressesExample: A VPC with an PIv4 CIDR block of 10.0.0.0/16 has 65,636 total IP addresses. The VPC has four equal-sized subnets. Only 251 IP addresses are available for use by each subnet.Public IP address type Public IPv4 address Elastic IP address Manually assigned through an Elastic IP address Associated with an AWS account Automatically assigned through the auto-assign public IP address settings at the subnet level Can be allocated and remapped anytime Â  Additional costs might apply Elastic network interface An elastic network interface is a virtual network interface that you can Attach to an instance Detach from the instance and attach ot another instance to redirect network traffic Its attributes follow when it is reached to a new instance Each instance in your VPC has a default network interface that is assigned a private IPv4 address from the IPv4 address range of your VPCRoute tables and routes A route table contains a set of rules (or routes) that you can configure to direct network traffic from your subnet. Each route specifies a destination and a target By default, every route table contains a local route for communication within the VPC Each subnet must be associated with a route table (at most one)Section 3: VPC networkingInternet gateway An internet fateway is a scalable, redundant, and highly availble VPC, allows communication between VPC and public internet.Two purposes: Provide a target in your VPC route tables for internet traffic Perform network address translations for intances that were assigned public PIv4 addressesTo make a subnet public, you attach an internet gateway to your VPC and add a route entry to the route table. Network Address Translation (NAT) gateway enables intances in a private subnet to connect to the public internet and prevent it from initation a connection.To create a NAT Gateway: Must specify the public subnet in which NAT gateway should live Must specify an elastic IP address to associate with the NAT gatewayAfter NAT gateway is created: Update the private subnet route tableCan use a NAT instance in a public subnet in your VPCVPC sharing Enables customers to share subnets with other AWS accounts (participant) in the same organization.VPC peering Enables you to privately route traffic between 2 VPCs.You can connect VPCs in your own AWS account, between AWS accounts, or between AWS RegionsRestrictions: IP spaces cannot overlap Transitive peering is not supported You can only have one peering resource between the same 2 VPCs.AWS Site-to-Site VPN By default, Amazon VPC cannot communicate with your own remote network enable by attaching a virtual private gateway to the VPC creating a custom route table updating security group rule creating an AWS site-to-site VPN connection configuring routing AWS Direct Connect Performance can be negatively affected if your data center is located far away from your AWS region AWS direct connect dedicated private connection between your network and one of the direct connect locations uses open standard 802.1q virtual local area networks VPC endpoints A VPC endpoit is a virtual device that enable you to privately connect to Amazon regional servicesAWS PrivateLink: Requires VPC interface endpoint Private connectivity between 2 VPCs, AWS services and on-premises appTwo types of endpoints: Gateway endpoints (Amazon S3 and Amazon DynamoDB) Interface endpoints (powered by AWS PrivateLink)AWS Transit Gateway A transit gateway is a network transit hub that you use to interconnect your VPCs and on-premises network.Section 4: VPC securitySecurity groups A security group acts as a virtual firewall that controls inboud and outbound traffic from your instance. Security groups have rules to manage instance traffic Default security groups are sealed shut to inbound traffic. we need to define rules. Security groups are stateful. The outbound traffic is always allowed.Network access control lists (network ACLs) Act at a subnet level. One-to-one relationship with subnet A network ACL has separate inbound and outbound rules, and each rule can either allow or deny traffic. Default network ACLs allow all inbound and outbound IPv4 traffic Network ACLs are statelessSecurity groups versus network ACLs Attribute Security Groups Network ACLs Scope Instance level Subnet level Supported Rules Allow rules only Allow and deny rules State Stateful (return traffic is automatically allowed, regardless of rules) Stateless (return traffic must be explicitly allowed by rules) Order of Rules All rules are evaluated before decision to allow traffic Rules are evaluated in number order before decision to allow traffic Section 5: Amazon Route 53DNS resolution It is the process of tranlsating an internal name to the corresponding IP address.Route 53 Is highly available and scalable Domain Name System (DNS) web service Is used to route end users to internet applications by transalting names into numeric IP addresses Is fully compliant with IPv4 and IPv6 Connects user requests to infrastructure running in AWS and also outside of AWS Is used to check the health of your resources Features traffic flow enables you to register domain nameSupported routing Simple routing Use in single-server environments Weighted routing Assign wights to resource record sets to specify the frequency Latency routing Help improve your global app Geolocation routing Route traffic based on location of your users Geoproximity routing Route traffic based on locations of your resources Failover routing Fail over to a backup site if your primary site becomes unreachable Multivalue answer routing Respond to DNS queries with up to eight healthy records selected at random Use case: Multi-region deployementDNS failoverImprove the availablity of your applications that run on AWS by: Configuring backup and failover scenarios for your own app Enabling highly available multi-region architectures on AWS Creating health checkDNS failover for a multi-tiered web appSection 6 Amazon CloudFrontContent delivery and network latency Challenge of network communication: network performance. Latency can happen depending on the geographical location of the user.Amazon CloudFront Fast, global and secure CDN service Global, network of edge locations and Regional edge caches Self-service model Pay-as-you-go pricingInfrastructureWhen a customer makes a demand, CloudFront respond with the IP address of the edge location closest to the customer. CloudFront obtains the data and copies it to the edge location. Edge locations Network of data centers that Cloudfronts uses to serve popular content quickly to customer Regional edge cach CloudFront location that caches content that is not popular enough to stay at an edge location. It is located between the origin server and the global edge location When data become stale, it is removed from the cache of the edge location Wrap-upWhich AWS networking service enables a company to create a virtual network within AWS? AWS Config Amazon Route 53 AWS Direct Connect Amazon VPC Answer keyword: AWS networking service Create a virtual network Answer 4." }, { "title": "Open Source: Comprendre, Contribuer", "url": "/cours/posts/open_source/", "categories": "tronc commun S8, Open Source", "tags": "tronc commun, Open Source, S8", "date": "2021-02-10 09:00:00 +0100", "snippet": "Lien de la note HackmdPar Lionel Laskelionel@lespot-bouygues.comIntroductionLionel LASKE Responsable Le Spot BOUYGUES Membre du board de lâ€™organisation Open source sugarlabs Auteur et Lead developpeur sugarizer 10 000 utilisateurs 80 contibuteurs Plateforme educative pour enfant Mentor Google Summer of Code depuis 2013Pourquoi ce cours ? Parce que lâ€™Open Source est un phenomene mondial ! devenu culturel open data: open source lie a la data Wikipedia Open Street Map TousAntiCovid Parce que câ€™est un sujet complexe part de technique (Github) part de juridique modele economique Comment ca fonctionne ? Comment on gagne de lâ€™argent avec des outils ouverts ? Pour nous faire partager son experiencePartie 1 - ComprendreQuizz TimeQuelle est la societe qui contribue le plus sur GitHub ? The Linux Foundation Google Microsoft RedHat Microsoft $1^{er}$ contributeur GitHub TypeScript Visual Studio Gode GitHub Npm Google $2^{nd}$ contributeur GitHub Android Angular TensorFlow Kubernetes Facebook React React Native GraphQL IBM RedHat Eclipse Apache Spark Pourquoi on fait de lâ€™open source ? Lâ€™Open Source est omnipresentAvantages de lâ€™Open Source Cout dâ€™usage Cout de developpement Sâ€™appuie sur dâ€™autres developpeurs pour developper un outils Communaute Mettre un projet en open source: permet de developper une communaute Avancer plus vite sur lâ€™outils Innovation Plus facile dâ€™innover Beneficier des idees des autres Securite Peut etre a double tranchant Avoir le code ouvert: â€œVous pouvez me faire confianceâ€ White hat trouvent des failles de securite Reversible Voir comment sont traitees nos donnees Definition Les 4 libertes fondamentales Liberte 0: Pouvoir executer le programme Liberte 1: Pouvoir etudier son fonctionnement Liberte 2: Pouvoir le redistribuer Liberte 3: Pouvoir le modifier et le redistribuer Comment sâ€™assurer quâ€™un logiciel est Open Source ?Plusieurs licences possibles open source initative Free Software Foundation Approche pragmatique Approche Ethique Considerations techniques: logiciels de meilleurs qualites car plus de contributeurs et de reviewers Considerations idealistes: lâ€™utilisateur doit garder le controle du logiciel Favoriser les modeles economiques Liberer les utilisateurs â€¦ en opposition au logiciel proprietaire Seul lâ€™auteur peut acceder au code source (ou des partenaires sous NDA) Pour utiliser le logiciel vous devez accepter une licence qui: Interdit la redistribution/pret/revente Exemple: Licence WindowsHistoriqueQuizz TimeQui a invente le concept dâ€™Open Source ? Steve Job Linus Torvald Bill Gates Richard Stallman Aucune des 4 reponses nâ€™est fausse1960: Prehistoire Le hardware est tres cher Lâ€™informatique est reservee aux chercheurs Le logiciel a une complexite limitee Le logiciel est disponible librement1970: Proprietaire Baisse du cout des ordinateurs Augmentation de la complexite des logiciels Apparition des 1er micro-ordinateurs Premieres licences proprietaire Seules les universites continuent a partager le codeAnecdote : An Open Letter to Hobbyusts par Bill Gates1980: Naissance 1983: annonce du projet GNU par Richard Stallman 1985: Creation de la Free Software Fundation 1987: Lancement de GCCAnecdote: lâ€™imprimante de Stallman Richard Stallman est programmeur au AI Lab du MIT Il souhaite modifier le pilote dâ€™une imprimante Xerox pour signaler automatiquement les bourrages papiers Il sollicite un collegue qui dispose du code source mais qui refuse â€œIl mâ€™a explique quâ€™il sâ€™etait engage a ne pas en donner de copierâ€ car il avait une NDA avec Xerox â€œCe qui rendait lâ€™enjeu important etait le caractere systematique et impersonnel de son refus, le fait quâ€™il sâ€™etait engage dâ€™avance a ne cooperer ni avec moi ni avec aucune autre personneâ€ - R. Stallman 1990: Fondation 1991: Creation de Linux 1993: Lancement des distributions Debian, NetBSD, FreeBSD, RedHat 1994: Creation de MySQL 1995: Creation de PHP 1996: Creation dâ€™Apache 1998: Lancement de Netscape 1999: Lancement de SourceForce2000: Explosion 2002: Lancement Firefox 2004: Lancement de la distribution Ubuntu sur base Debian 2005: Lancement du projet Git 2007: Lancement de Android, sur une base Linux 2008: Lancement de GitHub 2008: Lancement de Chromium en meme temps que Chrome2010: Evidence 2010: Lancement de nom 2013: Revelations de Edward Snowden 2014: Lancement de Signal 2018: Rachat de Github par Microsoft pour 7,5 milliards de $ 2019: Rachat de RedHat par IBM pour 34 milliards de $LicencesQuizz TimeCombien existe-t-il de licences Open Source â€œofficiellementâ€ reconnues ? 3 10 100A qui appartient votre code ? A votre ecole si vous etes etudiants A votre employeur si vous etes salaries A vous si vous le faites chez vous Sauf contrat employeur specifique Pour permettre a dâ€™autres dâ€™y contribuer, il faut donc utiliser une licence ouverte. Permissive Copyleft Tout le monde peut modifier Tout le monde peut modifier Les versions peuvent ne pas etre modifiables Tout le monde doit pouvoir modifier les versions modifiees Ce que decrivent les licences Les regles de mention de paternite du programme Les regles pour modifier le programme Les regles pour redistribuer le programme Les regles pour associer dâ€™autres licences dans le meme programme La protection contre les brevetsCartographie des licences Open SourceAnecdote: la controverse React React est lance par Facebook en 2013 sous Apache v2 En 2014 React passe sous licence BSD avec une note sur lâ€™utilisation des brevets: Permet dâ€™utiliser les brevets possedes par Facebook Facebook sâ€™autorise a vous retirer les droits dâ€™utilisation si vous menez une action en justice contre eux ou contre une autre entreprise utilisant React En 2015 Facebook ajoute une note supplementaire a la licence pour eviter les confusions En 2017 la fondation Apache prend position contre lâ€™utilisation de React car il nâ€™est pas sous une licence Open Source En novembre 2017, React passe sous licence MITAnecdote: la licence SSPL MongoDB MongoDB est lance en 2009 sous licence AGPL v3 Les clouds dâ€™Amazon, dâ€™IBM, â€¦ louent des instances MongoDB sans que MongoDB en tire benefice En Octobre 2017, MongoDB devient une societe cotee En Octobre 2018 passe son code sous licence SSPL et soumet cette nouvelle licence a lâ€™OSI La licence impose quâ€™un fournisseur de cloud utilisant MongoDB ouvre toute la stack technique permettant son herbegement En Mars 2019 lâ€™OSI refuse de consider la licence SSPL comme une licence Open Source RedHat, Debian, Fedora et les autres distributions Linux excluent MongoDB de leurs distributions En Janvier 2019, Amazon lance DocumentDB, une base de donnees NoSQL compatible MongoDBGouvernanceQuizz TimeQui dÃ©cide des contributions acceptÃ©es dans le Kernel Linux ? Linus Torvald seul Le board de la Linux Foundation Les entreprises qui contribuent au KernelLe modeles de gouvernance Open SourceDictateur bienveillant â€œBDLFâ€: Benevolent Dictator For Life Le Dictateur est generalement lâ€™auteur initial A le dernier mot sur toutes les grandes decisions Evite des discussions sans finâ€¦ La qualite et le succes du projet dependent beaucoup de la sagess du dictateurExemple: Gouvernance Linux Jeremy Malcolm - Internet Governance Forum â€œTorvalds possesses ultimate authority to decide which contributions to the Linux operating system kernel should be accepted and which should be refusedâ€ â€œThe Linux kernel development process is neither anarchistic nor consensual: if Torvalds does not like a patch, it does not go in to the kernelâ€ Gouvernance Communautaire Pilotage ouvert et public (mailing list, IRC, â€¦) Choix collegiaux: Qui peut contribuer Qui peut commiter Qui peut resoudre les conflits Recherche de consensus dans la decisions Favorise la Meritocratie Release sont generalement mois frequentes car circuit de decision plus longExemple: Gouvernance FreeBSD Composition: Contributeurs (plusieurs milliers) Commiters (500) Core team (9) Les Commiters approuvent les PR des Contributeurs Les Commiters elisent la Core Team La Core team choisi les Commiters parmi les Contributeurs La Core team decide des orientations du projetGouvernance Entreprise Une seule entite controle la Conception, le Developpement et les Release Contributions externes pas forcement bienvenue Roadmap pas necessairement publique Discussions internes et controverses pas forcement publiquesExemple: Gouvernance AOSP â€œThe Android Open Source Project (AOSP) includes individuals working a variety of roles. Google is responsible for Android product management and the engineering process for the core framework and platform; however, AOSP considers contributions from any source, not just Google.â€ â€œProject leads are senior contributors who oversee the egineering for individual Android projects.â€Modeles EconomiquesQuizz TimeQuelle est la sociÃ©tÃ© qui tire le plus de revenu de lâ€™Open Source ? Google Docker RedHatRedHat: 3,5 milliards de $ de revenus par anGagner de lâ€™argent avec lâ€™Open Source ? Vente de licences Une version â€œCommunityâ€ gratuite avec une licence copyleft Une version â€œEntrepriseâ€ payante avec plus de features et une licence permissive Vente de services Hosting ou mode SaaS Formations/Certifications Support Autres Publicite Dons/Mecenat Droit dâ€™usage de la marque Exemple:Elastic SearchIntelliJ IDEAVLC â€œLe logiciel Francais le plus utilise au mondeâ€¦ et le moins rentableâ€ J.B. Kempf 1 million de telechargements/jour 450 millions dâ€™utilisateur Plus de 3 milliards de telechargement Developpe en 1997 a lâ€™Ecole Centrale Paris Sous GPL en 2001 Gere par lâ€™association VideoLan en 2008 Creation en 2012 de la societe VideoLabs 18 employes, 1m dâ€™euros de CA Monetise la terchnologie et les utilisateurs VLC pour delivrer des services Anecdote: Heartbleed Vulnerabilite dans OpenSSL en 2011 Decouverte en avril 2014 OpenSSL etant utilise tres largement (Nginx, Apache, Android, â€¦) la faille touche 17% des serveurs wen et 800.000 objets connectes En 2012 la Open SSL Foundation touchait 2.000$/an pour financer ses contributeurs Lancement en 2014 de la Core Infrastructure Initiative Idee de la Linux Foundation 3.000.000$/an pour financer des projets Open Source â€œcoreâ€ Partie 2 - ContribuerPourquoi contribuer a lâ€™Open Source ? Ameliorer ses competences Participer au bien commun Recontrer des gens du monde entier Apprendre ou apprendre aux autres Ameliorer les outils quâ€™on utilise Se faire connaitreQuel projet choisir ?Quizz TimeQuel est le pourcentage estimÃ© de projets Open Source actifs ? 30% 10% 5% La plupart des projets Open Source sont des echecsâ€¦Les causes les plus courantes: Ne repond pas a un vrai besoin Plus assez de developpeuts interesses (ou le developpeur principal sâ€™en desinteress) Le projet est depasse techniquement, un competiteur fait mieux Manque de documentation Manque de leadership, pb de gouvernance, conflits Manque de temps/dâ€™argent Ce fort taux dâ€™echec nâ€™est pas necessairement une mauvaise chose, beaucoup dâ€™idees peuvent en decoulerIdentifier les signes vitaux dâ€™un projet Regarder les statistiques du projet Watch / Star / Fork / Used by Verifier les commits De quand date le dernier commit ? Combien y a-t-il de contributeurs ? Verifier les issues Combien y a-t-il dâ€™issues ? Sont-elles recentes ? Sont-elles fermees regulierement ? Verifier les PR Combien y a-t-il de PR ? Sont-elles recentes ? Exemple:React contributors vs Vue.js contributorsStatistiques Angular sur Synopsis Open HubVerifier que le projet est accueillant Est-ce un projet Open Source ? Y a-t-il une licence ? Comment acceuille t-il les contributeurs ? Y a-t-il un guide du contributeur ? un code de conduite ? Y a-t-il de la documentation ? Y a-t-il des issues tagguees â€œgood first issueâ€ ? Comment les mainteneurs repondent aux contributions ? Repondent-ils rapidement aux questions/issues ? Repondent-ils amicalement ? Y a-t-il des dicussions sur les issues/PR ? Remercient-ils les gens pour leur contribution ? Exemple: code de conduite KubernetesComment contribuer ?Checklist: demarrer une contribution Installer lâ€™application/le projet Sâ€™assurer que câ€™est la derniere version Jouer avec lâ€™application/le projet Lire la doc Sâ€™abonner aux listes de diffusion, forum, IRC, slack, â€¦ Commenter des posts/issues Câ€™est deja une contribution ! Declarer une issue Verifier quâ€™il nâ€™y a pas deja une issue similaire Indiquer les etapes pour la reproduire et lâ€™env. de test Faire une Pull RequestCreer une Pull Request Les Pull Request (PR) sont la base des contributions Open SourceExercie: First Contributions Un site pas a pas pour realiser votre $1^{ere}$ Pull Request Faites une PR pour ajouter votre nom a la liste des contributeursExemple: Hacktober Fest Evenement organise par Digital Ocean pour inciter a contribuer a des projets Open Source Chaque annee du 1$^{er}$ au 31 Octobre Les projets interesses inscrivent leur repo et tagguent des issues â€œhackotberfestâ€ Les 70 000 premiers participants qui font 4 PR gagnent un t-shirtLe Google Summer Of CodeQuâ€™est-ce que câ€™est ? Le Google Summer of Code (GSoC) est un programme â€œonlineâ€ international destine a encourager les etudiants des ecoles et universites a participer au developpement de projets Open Source.Objectifs du programme Pour les organisations Open Source: identifier chaque annees de nouveaux dev Pour les etudiants: participer au dev de projets Open Source, se construire une experience et un reseau, etre remunere (~4,000 euros/2 mois) Pour Google: soutenir le monde de lâ€™Open SourceComment ca marche ? Les organisations faisant de lâ€™Open source font la demande a Google pour etre des organisations du GSoC Google choisit les organisations qui participent Les etudiants soumettent leurs candidatures pour realiser les projets proposes Les organisations choisissent les meileurs etudiants Les etudiants developpent, encadres par les mentors des organisationsQuelques organisations participant au GSoCComment etre retenu au GSoC ? Commencer a contribuer avant Mars/Avril Se presenter a lâ€™organisation Mailing list, forum Multiplier les contributions (PR, issue) Bien comprendre le projet propose Echanger avec les mentors Suggerer des solutions Realiser un prototype Passer du temps a rediger sa proposition Demander une relecture de sa propositionConclusion Lâ€™Open Source est un phenomene culturel Comprendre son fonctionnement est indispensable Contribuer est une source de satisfaction et un vrai plus pour monter en competence Questions/ReponsesDans le cas oÃ¹ la licence est ajoutÃ©e aprÃ¨s la crÃ©ation du repository, son effet est-il rÃ©troactif ? La premiÃ¨re version (les premiers commits avant la licence) du projet est-elle concernÃ©e par la nouvelle licence ? Non, la licence ne sâ€™applique quâ€™aux versions actuellesOn a parlÃ© de lâ€™open source en terme de software. Quâ€™en est il du hardware ? Je ne peux pas vous en apprendre plusComment sera evalue le cours ? Aucune idee, a voir avec la pedagoCe nâ€™est pas fini !Pour en savoir plus: retrouver la version integrale sur YouTubeFinal QuizzAvez-vous maintenant envie de devenir contributeur ? Oui Non Ne sais pas" }, { "title": "TD AWS 1 - Rappel des modules 1, 2, 3 et 4", "url": "/cours/posts/aws_td_1/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 18:30:00 +0100", "snippet": "Lien de la note HackmdModule 1 Le cloud câ€™est la democratisation de la VM. 2006 par AWS qui parle de cloud computing Le cloud est une revolution car on peut acheter de la puissance de calcul directementExemple: une entreprise se dvpt, on peut sâ€™attendre a ce que lâ€™evolution de la puissance de calcul soit lineaire. En pratique, la courbe reel est tres aleatoire Zone verte: â€œje paye pour rienâ€ Ensuite besoin de plus de machines mais il faut les commander, faire livrer, installer etc. (15j au mieux) $\\rightarrow$ arrive apres la bataille et repayer une fortune pour rien Le cloud veut regler ce probleme. Le client ne veut pas des machines mais de la puissance de calcul (machine virtuelle) -AmazonPermet lâ€™elasticite: la puissance de calcul suit en live le besoin Le cloud, câ€™est la transformation du capex en opex (pay-as-you-go) Capex: capital expenses One-time and upfront cost Investment in capital Opex: operational expenses Regular cost Exemple: Croquetor, leader mondial de la vente de croquettes en ligneBesoin de: Data center (equinix) Provisioning (obtention des machines) Configurer les machines Deploy App (et la coder au passage)Avant le cloud: avait son propre data centerLe coeur de lâ€™entreprise câ€™est lâ€™app, du moment quâ€™il y a As a Service, on ne peut pas outsourcer le reste ? App SaaS Deploy PaaS (Heroku) Configure Â  Provisioning IaaS (Compute, network, storage) Data center (Equinix) Heroku: historiquement le premier, git push de lâ€™application et le serveur git deploy Outlook est un SaaS, on nâ€™a pas a lâ€™installer. En tant que end user, on consomme le service dâ€™un SaaS, qui utilise probablement un PaaS qui utilise lui-meme le IaaSModule 2Module 3 Infrastructure globale: on a des Regions Data replication Dans une Region: Availability Zones (data center) Best practice: replique au sein de Availability Zones edge locations: cache et CDN Ce nâ€™est PAS dans les data centers Sainte trinite infra: Compute Network Storage IaaS+: Database" }, { "title": "StartUp Lab", "url": "/cours/posts/startup_lab/", "categories": "tronc commun S8, StartUp Lab", "tags": "tronc commun, StartUp Lab, S8", "date": "2021-02-09 11:00:00 +0100", "snippet": "Lien de la note HackmdPresentation youtube.Daniel Jarjoura Startup Lab Founder (2013) EPITA Alumni (2006)3 chiffres 5,4 milliards dâ€™euros investis dans les entreprises tech FROu va cet argent ?Quels sont les autres financements de ces entreprises ? Il nâ€™y a jamais eu de meilleur moment pour creer une startup tech 22,7 % de fondateurs issus dâ€™une ecole dâ€™inge Pas besoin de faire une ecole de commerce pour reussir, mais trop peu dâ€™ingenieurs osent se lancer 12 millionaires crees depuis la creation du StartUp Lab Câ€™est possible a EpitaLe Startup Lab câ€™est quoi ?Etudiants qui ont envie dâ€™entreprendre a avoir un produit qui fonctionne et repond a une problematique bien definie en 1 an. Un suivi hebdomadaire Des masterclasses thematiques Des rencontres avec des fondateurs tech Un accompagnement de lâ€™EPITA 100% remote en 2020 Restera en remote car nâ€™a pas eu dâ€™impact sur les startups creees Nouveaute cette annee: limite fixe, 8 equipes seront recrutees Option 1: 1 equipe + 1 idee Profil des membres de lâ€™equipe Valeur ajoutee de lâ€™ideee Niveau technique de lâ€™idee Ouverture dâ€™esprit de lâ€™equipe Option 2: 1 equipe + 0 idee Profil des membres de lâ€™equipe FOCUS: Developer Startups Option 3: 0 equipe + 0 idee Recrutement de personnes pour le StartUp Lab Head of communication Head of sales Head of product 100% des premieres idees ne sont pas bonnes et ne survivent pas au 1er contact avec les clients.La partie la plus difficile est le contact avec les clients." }, { "title": "AWS Module 4 - AWS Cloud Security", "url": "/cours/posts/aws_module_4/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 10:30:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS shared responsibility modelAWS: Security of the cloud Physical facilities and system Hardware, software for running AWS services Customers: Securing app and datasets in the cloud Data encryption in transit from one systeme to another Use Amazon Tools Network configured for security Firewall configuration and security of OSAWS responsability: Security of the cloudAWS responsibilites: Physical security of data centers Controler, need-based access Hardware and software infrastructure Storage decommissioning, host operating, system (OS) access logging, and auditing Network infrastructure Intrusion detection Virtualization infrastructure Instance isolation Between customers workloads Customer responsibility: Security in the cloudCustomer responsabilities: Amazon Elastic Compute Cloud (Amazon EC2) instance operating system Including patching, maintenance Applications Passwords, role-based access, etc. Security group configuration OS or host-based firewalls Including intrusion detection or prevention systems Network configurations Account management Login and permission settings for each user Service characteristics and security responsibilityInfrastructure as a service (IaaS) Customer has more flexibility over configuring networking and storage settings Customer is responsible for managing more aspects of the security Customer configures the access controlsPlatform as a service (PaaS) Customer does not need to manage the underlying infrastructure AWS handles the operating system, database patching, firewall configuration, and disaster recovery Customer can focus on managing code or dataSoftware as a service (SaaS) Sofware is centrally hosted Licensed on a subscription model or pay-as-you-go basis Services are typically accessed via web browser, mobile app, or application programming interface (API) Customers do not need to manage the infrastructure that supports the serviceSection 2: AWS Identity and Access Management (IAM) Use IAM to manage access to AWS resources A resource is an entity in an AWS account that you can work with Example resources; An Amazon EC2 instance or an Amazon S3 bucket Example: control who can terminate Amazon EC2 instances Define fine-grained access rights Who can access the resours Which resources can be accessed and what can the user do to the resource How resources can be accessed IAM is a no-cost account featureIAM: Essential components IAM user A person or application that can authenticate with a AWS account IAM group A collection of IAM users that are granted identical authorization IAM policy The document that defines which resources can be accessed and the level of access to each resource Created independently than users and groups IAM role Usefule mechanism to grant a set of permissions for making AWS service requests Grant temporary access to a service Similar to sudo in Linux Authenticate as an IAM user to gain accessWhen you define an IAM user, you select what types of access the user is permitted to use.Can use either programmatic access, AWS Management Console access, or both.Programmatic access Authenticate using: Acces key ID Secret access key Provides AWS CLI and AWS SDK accessAWS Management Console access Autheticate using: 12-digit Account ID or alias IAM user name IAM password If enabled multi-factor authentificatuin (MFA) prompts for an authentification codeIAM MFA MFA provides increased security In addition to user name and password, MFA requires a unique authentification code ot access AWS serviceAuthorization: What actions are permittedAfter the user or application is connected to the AWS account, what are they allowed to do ?IAM: Authorization Assign permissions by creating an IAM policy Permissions determine which resources and operations are allowed: All permissions are implicitly denied by default Is something is explicitly denied, it is never allowed Best practice: Follow the principle of least privilege.Note: the scope of IAM service configurations is global. Settings apply accross all AWS RegionsIAM Policies An IAM policy is a document in JSON that defines permissions Enables fine-grained access control 2 types of policies identity-base resource-based Identity-based policies * Attach a policy to any IAM entity An IAM user, an IAM group or an IAM role * Policies specify; Actions that may be performed by the entity Actions that may not be performed by the entity * A single policy can be attached to multiple entities * A single entity can have multiple policies attached to it Resource-based policies * Attached to a resource (such as an S3 bucket) IAM policy example Any actions not explicitly allowed are denied $\\rightarrow$ out-of-the-box access are always deny (implicit deny) Any actions explicitly denied are always denied If there is a competition betwee an allowed statement and a deny statement, the deny statement always wins Resource-based policies Identity-based policies are attached to a user, group or role Ressource-based policies are attached to a resource (not to a user, group or role) Characteristics of resource-based policies Specifies who has access to the resource and what actions they can perform on it The policies are inline only, not managed Resource-based policies are supported only by some AWS servicesIAM permissionsHow IAM deterines permissions:IAM groups An IAM group is a collection of IAM users A group is used to granted by attaching IAM policy or policies to the group A user can belong to multiple groups There is no default group Groups cannot be nestedIAM role An IAM role is an IAM identity with specific permissions Similar to an IAM user attach permissions policies to it Different from IAM user Not uniquely associated with one person Intended to be assumable by a person, application or service Role provides temporary security credentials Examples of how IAM roles are used to delegate access Used by an IAM user in the same AWS account as the role Used by an AWS service (such as Amazon EC2) in the same account as the role Used by an IAM user in a different AWS account than the role Example use of an IAM roleScenario: An app that runs on an EC2 instance needs access to a S3 bucketSolution: Define an IAM policy that grants read-only access to the S3 bucket Attach the policy to a role Allow the EC2 instance to assume the roleSection 3: Securing a new AWS accountAWS account root user access versus IAM access Best practice: Do not use the AWS account root user except when necessary Access to the account root user requires logging in the the email address (and password) that you used to create the accout Example actions that can only be done with the account root user: Update the account root user password Changed the AWS Support plan Restore an IAM userâ€™s permissions Change account settings (for example, contact info, allowed Regions) Securing a new AWS account: Account root userStep 1: Stop using the account root user as soon as possibleThe account root user has unrestricted access to all resourcesTo stop using the account root user: While you are logged in as the account root user, create an IAM user for yourself. Save the access keys if needed Create an IAM group, give it full administrator permissions, and add the IAM user to the group Disable and remove your account root user access keys, if they exist Enable a password policy for users Sign in with your new IAM user credentials Store your account root user credentials in a secure placeStep 2: Enable multi-factor authentication (MFA) Require MFA for your account root user and for all IAM users You can also use MFA to control access to AWS service APIs Options for retrieving the MFA token Virtual MFA-compliant applications Google Authenticator Authy Athenticator (Windows phone app) U2F security key devices YubiKey Hardware MFA options Key fob or dispLy card offered by Gemalto Step 3: Use AWS CloudTrail CloudTrail tracks user activity on your account Logs all API requests to resources in all supported services your account Basic AWS Cloud event history is enabled by default and is free It contains all management event data on latest 90 days of account activity To accces CloudTrail Log in to the AWS Management Console and choose the CloudTrail service Click Event History to view, filter and search the last 90 days of events To enable logs beyond 90 days and enable specified event alerting, create a trail From the CloudTrail Console trails page, click Create trail Give it a name, apply it to all Regions, and create a new Amazon S3 bucket for log storage Configure access restrictions on the S3 bucket (for example, only admin users should have access) Step 4: Enable a billing report, such as the AWS Cost and Usage Report Billing reports provide info about your use of AWS resources and estimated costs for that use AWS delivers the reports to an Amazon S3 bucket that you specify report is updated at least one per day The AWS Cost and Usage Report tracks your AWS usage and provides estimated charges associated with you AWS account, either by the hour or by the daySection 4: Securing accountsAWS Oganizations AWS Organizations enables you to consolidate multiple AWS accounts so that you centrally manage them Security features of AWS Organizations: Group AWS accounts into organizational units (OUs) and attach different access policies to each OU Integration and support for IAM: permissions to a user are the intersection of what is allowed by AWS Organizations and what is granted by IAM in that account Use service control policies to establish control over the AWS services and API actions that each AWS account can access Service control policies Offer centralized control over accounts: limit permissions that are available in an account that is part of an organization Not a subsitute for Identity and Access management configurations ! In JSON Ensure that accounts compuly with access control guidelines SCPs are similar to IAM permissions policies They use similar syntax However, an SCP never grants permissions Instead, SCPs specify the maximum permissions for an organization AWS Key Management Service (AWS KMS) Enables you to create and manage encryption keys Enables you to control the use of encryption across AWS services and in your applications Integrated with AWS CloudTrail to log all key usage Uses hardware security modules (HSMs) that are validated by Federal Information Processing Standards (FIPS) 140-2 to protect keysAmazon Cognito Adds user sign-up, sign-in and access control to your web and mobile app Scales to millions of users Support Sign-in with social identity providers, such as Facebook, Google and Amazon, and enterprise identity providers, such as Microsoft Active Directory via Security Assertion Markup Language (SAML) 2.0 Help meet security requirementesAWS Shield is a managed distributed denial of service (DDoS) protection service Safeguards applications running on AWS Provides always-on detextion and automatic inline mitigations AWS Shield Standard enabled for at no additional cost. AWS Shield Advanced is an optional paid service Available to all customers Use it to minimize application downtime and latencySection 5: securing data on AWSEncrytpion of data at rest Encryption encodes data with a secret key, wich makes it unreadable Only those who have the secret key can decode the data AWS KMS can manage you secret keys AWS supports encryption of data at rest Data at rest = Data stored physically Can encrypt any data supported by AWS key management service You can encrypt data stored in any service that is supported by AWS KMS Amazon S3 Amazon EBS Amazon Elastic File System (Amazon EFS) Amazon RDS managed databases Encryption of data in transit Encryption of data in transit (data moving across a network) Transport Layer Security (TLS) (formerly SSL) is an open standard protocol AWS Certificate Manager provides a way to manage, deploy and renew TLS or SSL certificates Secure HTTP (HTTPS) creates a secure tunnel uses TLS or SSL for the bidirectional exchange of data AWS services support data in transit ecryptionSecuring Amazon S3 buckets and objects Newly created S3 buckets and objects are private and protected by default When use cases require sharing data objects on Amazon S3 It is essential to manage and control the data access Follow the permissions that follow the principle of least privilege and consider using Amazon S3 encryption Tools and options for controlling access to S3 data include Amazon S3 Block Public Access feature IAM policies Bucket policies: when canâ€™t log with IAM Access control lists (ACLs): a legacy access control mechanism AWS Trusted Advisor bucket permission check: a free feature Section 6: Working to ensure complianceAWS compliance programsCustomers are subject to many different security and compliance regulations and requirements AWS engages with certifyin bodies and independent auditors to provide customers with detailed infromation about the policies, processes, and controls that are established and operated by AWSCompliance programs can be brodaly categorized Certifications and attestations Assessed by a third-party, independent auditor Examples: ISO 27001, 27017, 27018 and ISO/IEC 9001 Laws, regulations, and privacy AWS provides security features and legal agreements to support compliance Examples: EU General Data Protection regulation (GDPR), HIPAA Alignments and framework Industry- or function-specific security or compliance requirements Examples: Center for Internet Security (CIS), EU-US Privacy Shield certified AWS Config Assess, audit and evaluate the configurations of AWS resources Use for continuous monitoring of configurations Automatically evaluate recorded configurations versus desired configurations Review configuration changes View detailed configuration histories Simplify complicance auditing and security analysisAWS Artifact Is a resource for compliance-related information Provide access to security and compliance reports, and select online agreements Can access example downloads: AWS ISO certifications Payment Card Industry (PCI) and Service Organization Control (SOC) reports Access AWS Artifact directly from the AWS Management Console Under Security, Identity \\&amp;amp; Compliance Accept agreements with AWS on multiple accountsWrap-upSample exam questionWhich of the following is AWSâ€™s reponsibility under the AWS shared responsibility model ? Configuring a third-party app Maintaining physical hardware Securing app access and data Managing custom Amazon Machine Image (AMIs) Answer keywords: AWSâ€™s responsibility AWS shared responsibility model Answer 2." }, { "title": "AWS Module 3 - AWS Global Infrastructure Overview", "url": "/cours/posts/aws_module_3/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS Global Infrastructure The AWS Global Infrastructure is designed and built to deliver a flexible, reliable, scalable and secure cloud computing environmnent with high-quality global network performanceAWS Region An AWS Region is a geographical area Data replication across Regions is controlled by you Communication between Regions uses AWS backbone network infrastructure Each region provides full redundancy and connectivity to the network A region typically consists of two or more Availability ZoneSelecting a Region Might be legal requirements Local laws can restrict the Region Ex: European Union Latency Can test with Cloud Ping Not all AWS services are available depending on the regionAvailability Zones Each Region has multiple Availabiity Zones Each Availability Zone is fully isolated partition of the AWS infrastructure 69 Availability Zones worldwide Availability Zones consist of discrete data centers Usually 3 They are designed for fault isolation They are interconnected with other Availability Zones by using high-speed private networking Dedicated fiber You choose your Availability Zones AWS recommends replicating data and resources across Availability Zones for resiliency Protected for tornadoes, lightning, earthquakesâ€¦ AWS data centers AWS data centers are designed for security Data centers are where the data resides and data processing occurs Each data has redundant power, networking and connectivity, and is housed in a separate facility A data center typically has 50,000 to 80,000 physical serversAWS uses custom netowrking equipment source from multiple ODMs. ODM: Original Device ManufacturersDesign and manufacture product based on specifications from a second company. The second company rebrand the products for sale.Points of Presence AWS provides a global network of 187 Points of Presence locations Consists of 176 edge locations and 11 Regional edge caches Used with Amazon CloudFront A global Content Delivery Network (CDN) that delivers content to end users with reduced latency Regional edge caches used for content with infrequent accessAWS infrastructure features Elasticity and scalability Elastic infrastructure; dynamic adaption of capacity Scalable infrastructure; adpats to accomodate growth Fault-tolerance Continues operating properly in the presence of a failure Built-in redundancy of components High availability High level of operational performance Minimize downtime No human intervention Section 2: AWS services and service category overviewAWS foundational servicesAWS categories of servicesStorage service category Amazon Simple Storage Service (Amazon S3) Object storage Scalability, data availbility and performance Amazon Elastic Block Store (Amazon EBS) high performance block storage Used with Amazon EC2 Amazon Elastic File System (Amazon EFS) Scalable file system (NFS) Use with AWS Cloud Services Amazon Simple Storage Service Glacier Extremely low-cost Data archiving Compute service category Amazon EC2 Resizable compute capacity Amazon EC2 Auto Scaling Automaticaly add or remove EC2 instances Amazon Elastic Container Service Supports docker container Amazon EC2 Container Registry (ECR) Fully managed docker container registry AWS Elastic Beanstalk Deploying and scaling web applications AWS Lambda Run code without servers No charge when the code is not running Amazon Elastic Kubernetes Service (Amazon EKS) Deploy, manage and scale applications using Kubernetes AWS Fargate Run container without having to manage servers Database service category Amazon Relational Database Service (RDS) Relational database in the cloud Scalable Automating database setup, patching, back-ups Amazon Aurora MySQL and PostreSQL 5 time faster than MySQL 3 times faster than PostreSQL Amazon Redshift Analytic queries against petabytes of data Fast Amazon DynamoDB NoSQL database Single digit performance Networking and content delivery service category Amazon VPC Isolated sections AWS Cloud Elastic Load Balancing Automatically distributes incoming application traffic Amazon CloudFront Delivery network (CDN) Secures data to cutsomers AWS Transit Gateway Connect Amazon VPC and on-premises network Amazon Rout 53 Scalable cloud domain name system Translate URL to IP addresses AWS Direct Connect Established dedicated private network AWS VPN Secure private tunnel to AWS global network Security, identity and compliance service category AWS Identity and Access Management (IAM) Enables you to manage access AWS Organizations Restricts actions and services allowed in your account Amazon Cognito Let you add user authentification and access control to web and mobile apps AWS Artifact On-demand access to AW security and compliance reports AWS Key Management Service (KMS) Create and manage encryption keys AWS Shield Managed distributied denial of service protection service AWS cost management category AWS Cost and Usage Report Set AWS cost and usage data AWS Budget Set custom budget AWS Cost Explorer Visualize and manage AWS cost and usage Management and governance service category AWS Management Console Web-based user interface for accessing your AWS account AWS Config Track resource inventory Amazon CloudWatch Monitor resources and app AWS Auto Scaling Scale multiple resources to meet demand AWS Command Line Interface (CLI) Unified tool to manage AWS services AWS Trusted Advisor Optimize perfomance and security AWS Well-Architected Tool Reviewing and improving workloads AWS CloudTrail Track user activity an API usage Wrap-up videoSample exam questionWhich component of AWS global infrastructure does Amazon CloudFront use to ensure low-latency delivery ? AWS Regions AWS edge locations AWS Availability Zones Amazon Virtual Private Cloud (Amazon VPC) Answer keyword: components of AWS global infrastructure CloudFront: AWS service low-latency: benefit provided by the component Answer: 2." }, { "title": "GPRO - Refresh from ing1 classes", "url": "/cours/posts/gpro_refresh/", "categories": "tronc commun S8, GPRO", "tags": "tronc commun, GPRO, S8", "date": "2021-02-08 14:00:00 +0100", "snippet": "Lien de la note HackmdRefresh du cours de GPRO de lâ€™ing1What is a Project ? Un projet est une entreprise temporaire initiee dans le but de fournir un produit, un service ou un resultat unique.Exemple: Bridge Railroad Apollo Vaccine Mobile Ap Web Site NOT a project: OperationsProject ManagementA pragmatic approach vs â€œJust do it!â€A quoi ca nous sert le project management ? En entreprise, travail toujours sur un projet, on aborde le project management de facon genericCharacteristics of a project Scope Quâ€™est-ce quâ€™on veut faire ? Comment on doit le faire ? Time Sâ€™organiser pour livrer le projet a une deadline Cost Realiser le projet avec le budget Parties prenantes - Stakeholders Toute personne ayant une influence sur le projetDans les parties prenantes: Pour une application, les utilisateurs Dans un stage, le maitre de stageProject life cycleScope: Cadre du projet Pour une app, si on veut quâ€™elle tourne sur IOS, Android, etc.Plannification: Organiser le travail Gros du boulot du chef de projetExecute/control: Commencer a developper Suivre le planPM Classic or AGILE ?BOTH !Classic predictive Liste de fonctionnalites precises Decoupe en lots de travaux Partage le travail Predictive car on prevoit tout des le depart.Agile Methode cyclique Developpe par cyclesMethode quand on est pas certain du but finalAgile ScrumUn sprint dure maximum un mois et a chaque sprint on livre un bout de logiciel qui fonctionneQUIZZ 1Parmi toutes ces realisations quelle est celle qui Nâ€™EST PAS un projet ? Modifier une application existante pour introduire une toute nouvelle fonctionnalite Construire un nouveau DATACENTER Asssurer recurreement la mise en production de toutes les nouvelles applications, ou de nouvelles versions pour la corporation qui vous emploie Implementer une nouvelle application Mettre en oeuvre une nouvelle comptabilite sur SAPPhase 1: InitiateUnderstand the meaning of the projectProject CharterFiche de route du projetContient des infos detaillees: Objectifs Dates cles Parties prenantesUne objectif flou et vous ne savez pas ce quâ€™on attend de vousLe client vous pilote sans donner une vision claire du projetVous avez le Droit et le Devoir de collecter les informations de comprehension du PROJECT CHARTERProject Charter contents Project purpose Measurable project objectives and related success criteria High0level requirements Fonctionnalites definies de maniere large High-level project decription, boundaries, and key deliverables Summary milestone schedule Key stakehodler list Clients Manager Les gens qui travaillent sur le projet Overall project risk Project approval requirements Faire valider le projet une fois fini ExamplesExemple 1 - PFEE MTI Bouyfues Telecom 2020 Presente dâ€™abord le contexte Problematiques Baisses des ventes suite a des promotions agressives de la concurrence Veille concurrentielle faite a la main Detection tardive des actions des concurrentes Objectifs du projet Ameliorer la capacite dâ€™analyse des marketplaes Reduire le temps de reaction face aux promotions agressive des concurrentes Grandes lignes du projet Visualiser les evolutions de prix Predire lâ€™evolution des prix Alerter lâ€™utilisateur de changement de prix Disposer dâ€™un module dâ€™opti des prix sous contraintes Planning des Jalons principaux Risques globaux Risque de livraison dâ€™un projet difficilement maintenable Risque que le scraping soit peu durable Risque que la realisation ne corresponde pas aux attentes a cause dâ€™un besoin faiblement ecrit Critere de sortie du projet Les differents livrables sont fonctionnels dans une version pilote de production disponible sur lâ€™env AWS de lâ€™entreprise Exemple 2 Perimetre TimelinePhase 2: ScopeProduct Scope (Perimetre Produit) pour un logiciel applicatif: Exigences fonctionnelles Contraintes (techniques, de qualite, projet)Exigence fonctionnelle Ce que le client attend comme fonction de notre produitExemples pour une application: Permet de creer un compte Permet de rejoindre un groupe de discussiom Permet de prendre RDV Exigence fonctionnelle Nâ€™EST PAS une specifite fonctionnelle.Get the product scopeSituation 1: Customer team provides fully Documented Product/Project Scope Dev team reviews the Scope with appropriate Product Owner Collecting requirements - Recueillir les exigences Fromalizing the requirements - formaliser les exigences Tableau des exigences ExempleAgile Methodology: The product backlogUser story En tant que &amp;lt;qui&amp;gt;, je veux &amp;lt;quoi&amp;gt; afin de &amp;lt;pourquoi&amp;gt;.Difference GILE: On peut affiner au fur et a mesure les exigences en avancant dans la release.ExempleCompleter les Product Backlog ou les tableaux dâ€™exigence4 types dâ€™exigences (projet dev de logiciel) Exigences Fonctionnelles Contraintes techniques Exigences Qualite Exigence du ProjetQuizz 3Dans la methode Predictive, un cahier des charges ou un tableau des exigences, ou, dans la methode Agile, un Product Backlog est un document dont le contenu correspond a: Description des mecanismes techniques permettant le fonctionnement du produit Description des travaux a mettre en oeuvre pour realiser le produit Description des tests unitaires pour valider le produit Description du planning produit Description des exigences, besoins et fonctionnalites auxquels le produit correspondFrom SCOPE to Project ScheduleTake scope definition result as INPUT Work Breakdown Structure: WBSWork Package: WBWB are usually attached to a Project DeliverableOne WBS for Presence:Defining activitiesAmount of work that can be estimated Need for expert judgementDefine Milestones - BornesDecomposition en activitesPresence 1-POCResources Need for expert judgementDuration Need for expert judgement Estimate TOP Down vs Bottom UPOrdonner et EstimerExemples from MTI PFEEConstruite via Microsoft project En resume, en decoupant lâ€™ensemble des productions a realiser et le travail quâ€™elles representent. Puis apres estimation, en repartissant dans le temps ces activites. Vous disposez dâ€™un plan et dâ€™un planning initial (BASELINE) de realisation de votre projet complet.Planning AGILESet an order to User Stories - Organiser les Users StoriesOn peut definir un flot de narration. Par rapport a ce flot de narration, pour chaque etape des User Stories corresponsdent (se connecter, se deconnecter, modification de mot de passe, creation de mot de passe, etc.).Sur lâ€™axe des ordonnees: organise les users stories suivant le flot de narration (ex: Je me connecte/deconnecte) $\\rightarrow$ ce qui parait le plus important.Release Carving - Decoupage en ReleasesQuelles sont les fonctionnalites essentielles que lâ€™on doit mettre en Release 1 Par Exemple ?Une fois quâ€™on a regroupe depuis le product backlog un des user stories pour la release (Decoupage en sprint (Sprint Carving)) on affecte des â€œStory Pointsâ€ (assign â€œStory Pointsâ€) $\\rightarrow$ assigner des pointsLâ€™affectation des points doit etre fait par lâ€™equipe de developpement. En resume,Vous avez convenu dans le Productbacklog le perimetre de la release a realiser. Vous avez decompose cette release en N Sprints dâ€™un poids equivalent pouvant etre realises successivement dans le temps que represente un Sprint.Exemple MTI PFEEExemple 1Exemple 2Des prerequis avant de commencer le developpement Sprint 0 ? Each Sprint Starts with: SPRINT PLANNINGExemple MTI PFEEQuizz 5Quelle est la SEULE affirmation vraie concernant un SPRINT dans la methode Agile ? La duree dâ€™un sprint peut etre de 3 mois Lors de lâ€™execution dâ€™un sprint, le client peut proceder a des changements de perimetre qui sont geres dans la gestion de changement Un Sprint peut debuter meme si le president nâ€™est pas termnie Un Increment Produit â€œFini fonctionnelâ€ et potentiellement utilisable est produit lors dâ€™un Sprint La duree du Sprint est variable et sâ€™adapte aux taches a realiser pour chacun dâ€™euxMonitoring Sprint Execution: Daily SCRUMUne fois le sprint fini: sprint review Client et dev Demo Doit etre valide par le clientSprint retrospective: Reunion de devs Quâ€™est-ce qui a marche Quâ€™est-ce qui nâ€™a pas marcheCommunication Client-DevConstruite dans la methode SCRUM, si le client a opte pour AGILE, il doit imperativement se plier a minima aux evenements prevus dans la methode.Bien sâ€™accorder sur les moyens (canaux, convocation, calendrier) pour fluidifier le processusExecuting in Predictive/Classic Project ManagementBaseline to control In predictive just follow the plan but lot of unexpected eventsMettre en place un cadre de communication pour controler le dev du projetExemple de plan de communication Formalisez le plan de communication Faites approuver par le clien Planifier la logistique des evenements de com (placer les RDV, format, diffusion des comptes rendusâ€¦)Internal review meetings - Reunions de suivi internesAnalysing delays in Gantt ChartChange ManagementPlan &amp;amp; Execute/control Individual project risk an uncertain event or condition that, if it occurs, has a positive or negative effect on one or more project objectivesLa methode pour les risques:Liste de risques possibles:Analyse qualitativeOn manage en priorite les risques a plus haut impactDans ce cas le rouge et noir, en bleu on ignore, en jaune on regarde un peu en detailsRisk Response Strategy Accept Acknowledge the existence of a threat but no proactive action is taken Avoid Risk response is to eliminate the threat by appropriate action Transfer Risk is transfered to a third party that will accept the risk and the potential impact Mitigate Action is taken to reduce the probability and/or impact of a threat En resume, Identifiez les risques qui peuvent affecter le projet Filtrez pour ne conserver que les plus significatifs Definir des strategies et des plans dâ€™action pour les risques retenus " }, { "title": "AWS Module 2 - Cloud Economics and Billing", "url": "/cours/posts/aws_module_2/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-08 11:30:00 +0100", "snippet": "Lien de la note HackmdSection 1: Fundamentals of pricingAWS pricing modelThree fundamental drivers of cost with AWS: Compute Charged per hour/second Varies by instance type Storage Charged typically per GB Data transfer Outbound is aggregated and charged Inbound has no charge (with some exceptions) Charged typically per GB How do you pay for AWS ?Pay for what you usePay only for the servuces that you consume, with no large upfront expensesPay less by using moreRealize volume-based discounts: Savings as usage increases Tiered pricing for services like Amazon Simple Storage Service (Amazon S3), Amazon Elastic Book Store (Amazon EBS) or Amazon Elastic File System (Amazon EFS) $\\rightarrow$ the more you use, the less you pay per GB Multiple storage service deliver lower storage costs based on needsPay even less as AWS Grows AWS focuses on lowering cost of doing business This pratice results in AWS passing savings from economies of scale to you Since 2006, AWS has lowered pricing 75 times (as of Septembre 2019) Future higher-performing resources replace current resources for no extra chargeCustom pricing Meet varying needs through custom pricing Available for high-colume projects with unique requirementsAWS Free TierEnables you to gain free hands-on experience with the AWS platform, products and services. Free for 1 year for new customersServices with no chargeModule 2: Total cost of OwnershipOn-premises versus cloudWhat is Total Cost of Ownership (TCO) ? Total Cost of Ownership (TCO) is the financial estimate to help identify direct and indirect costs of a system.Why use TCO ? To compare the costs of running an entire infrastructure environmnet of specific workload on-premises versus on AWS To budget and build the business case for moving to the cloudTCO ConsiderationOn-premises versus all-in-cloudYou cloud cave up to 96 percent a year by moving your infratstructure to AWS. Your 3-year total savings would be $159,913AWS Pricing CalculatorUse the AWS Pricing Calculator to: Estimate monthly costs Identify opportunities to reducse monthly costs Model your solutions before building them Explore price points and calculations behind your estimate Find the available instance types and contract terms that meet your needs Name your estimate and create name groups of servicesReading an estimateYour estimate is broken into: first 12 months total total upfront total monthlyAdditional benefit considerations Cloud Total Cost of Ownership: what will be spent to run the solution Return on Investement analysis (ROI): determine the value generated while considering savings $\\rightarrow$ soft and hard benefits Hard benefits Soft benefits Reduced spending on compute, storage, networking, security Reuses of service and applications that enabl you to define (and redefine solutions) by using the same cloud service Reductions in hardware and softare purchases (capex) Increased developer productivity Reductions in operational costs, backup, and disaster recovery Improved customer satisfaction Reduction in operations personnel Agile business processes that can quickly respond to new and emerging opportunities Â  Increase in global reach Case study: Delaware NorthBackground: Growing global company with over 200 locations 500 million customers: $3 billion USD annual revenueChallenge: Meet demand to rapidly deploy new solutions Constantly upgrade aging equipmentCriteria: Have a broad solution to handle all workloads Be able to modify processes to improve efficiency and lower costs Eliminate busy work (such as patching software) Achieve a positive return on investment (ROI)Solution: Move their on-premises data center to AWS Eliminated 205 servers (90%) Moved nearly all aplications to AWS Used 3-year Amazon ECE2 Reserved InstancesCost comparisonResultsSection 3: Billing AWS Organizations: account management service to consolidate multiple AWS accounts a branch can have only one parentKey features and benefits Policy-base account management Group based account management APIs that automate account management Consolidate billingSecurity with AWS Organizations Control access with AWS Identity and Access Management (IAM) IAM policies enable you to allow or deny access to AWS services for users, groups and roles Service control policies (SCPs) enable you to allow or deny access to AWS services for individuals or group accounts in an organizational unit (OU)Organization setupAccessing AWS Organizations AWS Management Console AWS Command Line Interface (AWS CLI) tools Software development kits (SDKs) HTTPS Query application programming interfaces (API)Section 4: AWS Billing and Cost ManagementAWS Billing DashboardSpend summary: how much you spent last monthMonth-to-Date spend by service: services most usedTools AWS Budgets AWS Cost and Usage Report AWS Cost ExplorerMonthly billsCost ExplorerForecast and track costsCost and usage reportingSection 5: Technical Support ModelsAWS Support Provide unique combination of tools and expertise: AWS Support AWS Support Plans Support is provided for: Experimenting with AWS Production use of AWS Business-critical use of AWS Proactive guidance Technical Account Manager (TAM) Best practices: AWS Trusted Advisor Account assistance AWS Support Concierge Support plansAWS Support offers four support plans: Basic Support: Resource Center access, Service Health Dashboard, product FAQs, discussion forums, and support for health checks Developper Support: Support for early development on AWS Business Support: Customers that run production workloads Entreprise Support: Customers that run business and mission-critical workloadsCase Severity and response timesWrap-upSample exam questionWhich AWS service provides infrastructure security optimization recommendations ? AWS Price List Application Programmin Interface (API) Reserved Instances AWS Trusted Advisor Amazon Elastic Comput Cloud (Amazon EC2) Spot Fleet Answer Keyword: recommendations Answer: 3." }, { "title": "AWS Module 1 - Cloud Concepts Overview", "url": "/cours/posts/aws_module_1/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-08 10:00:00 +0100", "snippet": "Lien de la note HackmdIntroduction Intro to cloud computing Advantages of cloud computing Introduction to AWS AWS Cloud Adoption FrameworkSection 1: Introduction to cloud computingWhat is cloud computing ? Cloud computing is the on-demand delivery of compute power, database, storage applications, and other IT resources via the internet with pay-as-you-go pricingInfrastructure as softwareCloud computing enable you to stop thinking of your infrastructure as hardware and instead think of it as software.In the traditional compute model: Infrastructure as hardware Hardware solutions Require space, staff, physical security, planning, capital expenditure Have a long hardware procurement cycle Require you to provision capacity by guessing max peaks Cloud computing model: Infrastructure as software Software solutions: Are flexible Can change more quickly, easily and cost-effectively than hardware solutions Eliminate the undifferentiated heavy-lifting tasks Cloud service modelsCloud computing deployement models Cloud Hybrid Between cloud and existing premises On-premises (private cloud) Dedicated resources Similarities between AWS and traditional ITSection 2: Advantages of the cloudTrade capital expense for variable expense Capital expense = capexMassive economies of scaleBecause of aggregate usage from all customers, AWS can achieve higher economies of scale and pass savings onto customers.Stop guessing capacityIncrease speed and agilityWeeks between wanting resources and having resources to only minutes.Stop spending money on running and maintaining data centersGo global in minutesCan deploy applications in multiple places of the worldSection 3: Introduction to AWSWhat are web services ? A web service is any piece of software that makes itself availbale over the internet and uses standardized format such as XML or JSON fro the request and the response of an API interaction.What is AWS a secure cloud platform offering a broad set of global cloud-based products provides on-demand access to compute, storage, network, database, and other IT resources and management tools offers fexibility You pay only for the individual services you need, as long as you use them AWS services work together like LegosServicesChoosing a serviceThe service you select depends on your business goals and tech requirements.3 ways to interact with AWS AWS management console Easy-to-use graphical interface Command Line Interface (AWS CLI) Access to services by discrete commands or scripts Software Developement Kits (SDKs) Acces services directly from your code Section 4: Moving to the AWS CloudAWS Cloud Adoption FrameworkAWS CAF provides guidance and best practices to help organizations build a comprehensive approach to cloud computing across the organization and throughout th IT lifecycle to accelerate successful cloud adoptionAWS CAF is organized into six perspectives Perspectives consist of sets of capabilities.Six core perspectivesBusiness perspectives We must ensure that IT is aligned with business needs, and that IT investments can be traced to demonstrable business results - Business managers, finance managers, budget owners, and strategy stakeholdersPeople perspectives We must prioritize training, staffing and organizational changes to build an agile organization - Human resources, staffing, and people managersGoverance perspective We must ensure that skills and processes align IT strategy and goals with business strategy and goals so the organization can maximise the business value of its IT investments and minimize business risks. - CIO, program managers, business analysts and portgolio managersPlatform perspective We must understand and communicate the nature of IT systems and their relationships. We must be able to describe the architecture of the target state environment in detail. - CTO, IT managers and solutions architectsSecurity perspective We must ensure that the organization meets its security obejctives - CISO, IT security managers and IT security analystsOperations perspective We align with and ssupport the operations of the business, and define how day-to-day, quarter-to-quarter, and year-to-year business will be conducted - IT operations manager and IT support managersWrap-upSample exam questionWhy is AWS more economical than traditional data centers for applications with variable compute workloads ? Amazon Elastic Compute Cloud (Amazon EC2) costs are billed on a monthly basis Customers retain full administrative access to their Amazon ECE2 instances Amazon ECE2 instances can be launched on-demand when needed Customers can permantly run enough instances to handle peak workloads Answer Keywords: AWS more economical than traditional data centers, indicate one of the 6 computing benefits and variable indicates need for flexibility Answer: 3" }, { "title": "Kickoff Image", "url": "/cours/posts/kickoff_image/", "categories": "Image S8, Kickoff", "tags": "Image, S8", "date": "2021-02-05 09:30:00 +0100", "snippet": "Lien de la note HackmdCours Tous les cours sont TD/TPPremiere partie du semestreBooster MASI (BOOM) Lundi et mercredi Rappels de MASI Quâ€™est-ce quâ€™une convolution ? Quâ€™est-ce quâ€™une correlation ? TD aprem Pour les TP: pas de salle Notebook Jupyter Devoir ramener ordis en presentiel Python pour le Big Data Apprendre a se servir de Python pour traiter de la donnee avec le prof de CAMA Cours possiblement en Zoom au lieu de Teams Pour suivi personnalise Introduction aux Reseaux de Neurones Avec prof de CAMA 6h de cours 6h TD/TP Sur zoom Cours de Olivier Ricou en distanciel Olivier Ricou ouvert aux remarques constructivesDeployement et Virtualisation Apprendre a se servir de Docker TP avec intro au cours Cours modal Une partie de la classe presentiel Autre distanciel Echange de place 1 semaine sur 2 Introduction a la synthese dâ€™images Prof de THL Plus de traitement que de synthese Cours compact au debut du semestre Premier projet a rendre Traitement dâ€™image fondamentale Gros cours du S8 36h au total Jonhattan presente les bases du traitement dâ€™image en C++ Evaluation par partiels Elody presente plus avance et en python Evalue par projet Projet communs a plusieurs matieres pour des projets plus avances et moins de projets a completer, charge de travail plus legerePour tous les modules doit etre fourni une note a lâ€™admProbabilite et statistique (commun avec SCIA) En distanciel 12h de cours magistraux 6h de TD seuls Partiel classique Fondement des probas stats pour le machine learning Devoir sur tableOptimisation convexe (commun avec SCIA) Bi-modal Bashar et Guillaume Approches differentes Plus gros du cours: apprendre ce que câ€™est une differentielle Debut mi-mars et fini au mois de Juin 19h de cours 7h de cours 12h de TD Controle continu + compte rendu de TP pour 2e partie du semestreIntroduction au machine learning Guillaume et Joseph Cours maudit: profs changent chaque annee 18h de cours 2h dâ€™intro 4 seance de 4h Imagerie medicale Commence avant la semaine de partiels 3 seances avant puis 3 apres 1ere seance: â€œdetenteâ€ Evaluation par projet Pas le droit de faire du deep learning Seulement traitement dâ€™image classique 20h de cours de spe/semaine, 4j de cours sur 5, journee remplie 3h de cours le matin et 3h l&#39;aprem, avoir des creneaux libres pour avancer sur les projets Peut rajouter des heures en plus (soutenance, etc.)Lâ€™an dernier les etudiants on pas eu de soutenance, juste rendre projet/video prez, dur de faire un retour personnalise.Cette annee repasse sous un systeme de soutenance pour les projets, pas de rapport mais presentation (et soutenance de mini-projets). Si on nous donne un projet a faire pour dans 2 mois, veut pas dire que 2 mois de boulot mais 2 mois pour sâ€™organiser et etaler la charge de travail.QuestionProjet en commun avec dâ€™autre majeures ? NonPour les projets en commun entre plusieurs matieres ? But dâ€™utiliser les outils pour faire quelque chose de bienCours avec les SCIA ? Veut reprendre les cours au max en presentiel mais SCIA + Image = bcp dâ€™eleves et depend des annonces gouvernementales sur les universite (pour lâ€™instant tres floues). Personne nâ€™est force a venir en presentiel.Rediffusion des cours ? NonConclusion 1ere partie du semestre2 projets: IREN (Introduction aux Reseaux de Neurons) et ISIM (Introduction a la synthese dâ€™image)2eme partie du semestrePlus de projetsOCVX, IMEDImagerie Couleur et Capteur Specifite imagerie couleur, quâ€™est-ce que la couleur Aimerai y ajoindre une intervention de Benoit PochonEtude de cas pratique en image et RdF Peut-etre dispense pour les RDI Pour ceux qui ne font pas de recherche, voir comment on fait Choisir un article et le presenter Forcer a lire un article de conf et a le synthetiser Implementation rapide GPGPU Edwin et Joseph Ce cours est comme le vin, sâ€™ameliore dâ€™annee en annee En SM 14 (presentiel) Evaluation par projet (LE GROS PROJET de cette partie du semestre)Introduction a VTK et ITK Distanciel Julien Jomier, gars de la boite derriere CMake ProjetProgrammation OpenGL Eval par projetMachine Learning pour la reconnaissance des formes (commun SCIA) 2h de cours le matin et 3h de TP le vendredi Cours pref des etudiants pendant le S8Hackhaton PIFUN Remplacer le projet traitement dâ€™Image Hackhaton sur 3 jours Manipulation Raspberry Pi Computer vision + machine learning Apres les partiels (et si possible soutenances de projet) RDI dispensesPFEE Gens des labos dispenses Projet qui demarre entre Avril/Mai et continue jusquâ€™a Janvier Les entreprises viennent proposer des sujets Ce sont des clients et on doit realiser leur projet Ils presentent et on choisi Par groupe de 3 ou 4 Interdit groupes de 3 avec 2 assistants Interdit groupes de 4 avec 3 assistants Travail en continu Si un assistant arrete de bosser en Septembre les autres doivent continuer Tout le monde a interet que le PFEE se passe bien Permet aux entreprises de proposer des sujets lâ€™annee suivante Peut obtenir des stages Des fois ou le PFEE se passe mal a cause de lâ€™entreprise Possibilite de contacter les entreprises nous-meme pour recuperer des sujetsOrganisation Pas de creneaux PFEE car besoin dâ€™un prof associe Cette annee: creneaux Mise au point avec Elodie Si lâ€™entreprise ne donne plus de signe de vie, contacter Elodie directement.Si lâ€™entreprise utilise notre travail, on leur suggere de donner un petit quelque chose en echange.Le labOn en a pas.Canaux de communicationTeams + mailing listLes chefs de majeure ne seront pas sur le DiscordLes rolesLes delegues2 delegues, a elire avant mercredi 10/02, trait d&#39;union entre l&#39;adm et les chefs de majeure Communiquer avec les chefs de majeure, leur transferer les mails Invites au conseil de classe Transmettre les infos des industriels Une fois choisis, envoyer la liste a Elody et GuillaumeLab Role fantome Besoin dâ€™un respo lab Respo com 4 respos com, minimum 2 Interface avec la com Etre la pour les JPOs Au moins un respo com par JPO Electif dedie (peut faire du theatre) Peut pas etre RDI Pas vendre Epita, vendre la majeure Appariteur 2 appariteurs Reprendre max dâ€™activite en presence Aimerai mettre en place: Diviser la promo en 2 Chaque etudiant dâ€™un groupe est en binome avec un etudiant de lâ€™autre groupe Lâ€™eleve en presentiel sâ€™occupe de celui en distanciel Rentransmettre en live Dans chaque groupe une personne respo de la retransmission Responsable de lâ€™organisation qui vient distanciel/presentiel" }, { "title": "PFEE GE Healthcare 2", "url": "/cours/posts/pfee_ge_healthcare_2/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 16:15:00 +0100", "snippet": "Lien de la note HackmdProbleme La fluoroscopie ne montre pas toutes les informations Injection cause des contrastesSolutionsScanner preoperatoire 2-3 mois en amontPendant lâ€™operationFusion manuelle des 2 modalitesEn resume Premiere donnee: image 2D (fluoroscopie) Seconde donnee: volume 3D (scanner CT)But du projetAutomatisation de ce processusBut de lâ€™agentGeneration de donneesRecherches de donnees publiquesFichiers .DICOM Ensemble de coupes dâ€™un patient donneGeneration de donneesPour un scanner donne: Reconstruction volume 3D Generation de projectionPour une projection: Generation de patchesDonnees 2D uniquementNotre projet: recalage 2D/2D afin de se concentrer sur la mise en place dâ€™une architecture globalesApprentissage par renforcement Trouver la meilleure sequence dâ€™actions permettant dâ€™aligner 2 images Un agent artificiel apprend la meilleure strategieQ-learning But de lâ€™agent de trouver la policy La notion de q-value renvoie a la recompense obtenue sur le long termeApprentissage par renforcement superviseq-values deja calculees avant lâ€™apprentissage On va faire une regressions entre q-value et output du reseau Permet dâ€™avoir une convergence plus stableRole du reseau de neurones Determiner action optimale pour chaque etat Estimer les q-values pour chaque paire etat/action Le reseau prend un etat en entree et retourne les q-vqlues pour chaque actionPre-traitement Patch normalise entre 0 et 1Phase dâ€™entrainementObtention des images a chaque etape dâ€™inference Choisi action parmi 6 pour q-value maximale Applique lâ€™actionResultatsReduction de la dimension du problemeConclusionCe que le projet nous a apporte Montee en competences Recalage dâ€™image Imagerie medicaleCe que le projet a apporte a GE Meilleure connaissance des bases de donees publiques Premiere approche de lâ€™apprentissage par renforcementQuestionsGuillaume TochonCâ€™est quoi epsilon policy ? Fonction qui permet de diriger exploration et exploitationElodie PuybareauLe temps de traitement sur une image ? Relativement instantaneeRetours GE HealthcareRetour globalement positif, resultat fonctionnel" }, { "title": "PFEE GE Healthcare: Deep Learning Inpainting", "url": "/cours/posts/pfee_ge-healthcare/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 15:30:00 +0100", "snippet": "Lien de la note HackmdHow to get a volume ? Turn around the patient X ray acquisition in different anglesArtifactsDifferent types of artefact: Motion artifact Metal artifact Ring artifacts (detector)State of the art Where Correction applied on volumes Inpainting Fill selected image area Requires having the mask of the missing partsMethodsInterpolation 2DInterpolation algorithm from skimage to create a basline: Nearest neighbor LinearU-NET 2DImprovements ? Conv2D/3D do not consider the mask Losses (MSE/MAE) do not consider the maskPartial convolution Presented by Nvidia in 2018 Mask area is much less visible and overall results are improvesKeras ?Loss improvement Using a train VGG deep learning classifier Layers used: 3rd, 6th and 10th DataExperimentsGoal 2D Perfomance machine learning Added value 3D Adding temporal gives best results Can we be more memory efficient using patches ? Evaluation method Quantitative evaluation MSE MAE SSIM Structural similarity PSNR Peak To Signal Noise Ratio More quantitative than qualitative Quality eval Eval by human eye ResultsQualitative 2DRibs reconstructionQualitative 2D+TAnalysis Machine learning can be used for this task PConv and VGG loss are the best improvementsConclusion Implementation of PConv2D and PConv3D Promising resultls Kickstarted GE exploration and gave them insights on their future work Had fun with advance machine learningQuestionsGuillaume TochonLe papier a ete utilise sur des images de scan ? Non sur des images naturellesExpliquer â€˜smoothing lossâ€™ Dilatation verticale et horizontale des resultatsElodie PuybareauGeneration des artefacts: probleme avec modele 2D+T, pourquoi blanc alors que modele 2D noir ? Les modeles 2D sont aussi blanc sur les imagesElevesExemple dâ€™applications concretes ? Application de corrections permet dâ€™avoir des images pouvant etre travaillees pour un medecinGenration des artefacts aleatoires ? Oui pour la position et rotation en 3D mais sinon non, pas de perte de temps a generer de la donneeTester avec des formes differentes ? Oui avec des coins et des aiguillesGenerer un nombre infini de donnees, probleme de fit ? OuiInterpolation lineaire plus simple ? Oui mais beaucoup de stries et nâ€™arrive pas a reconstruire certaines partiesRetour GE HealthcareBonne organisation, bon avancement des projets mais baisse dâ€™activite lors dâ€™examens, groupe autonome" }, { "title": "PFEE Mihaly", "url": "/cours/posts/pfee_mihaly_prez/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:45:00 +0100", "snippet": "Lien de la note HackmdPrototypage dâ€™un voxeliseur avec VTKMihaly Startup dâ€™impression 3D Nouvelle tech dâ€™impression qui permet dâ€™avoir du texturing et de la couleur Precision a lâ€™echelle du micrometre Creation de lâ€™application et du pipeline de traitements des objets a imprimer Problematique: Impression 2.5D/3D dans un espace reduit Incapacite de creer des structures de soutien pour les objets flottants Opti de lâ€™utilisation de materiaux colorises Gros volume de donnees (scan de plusieurs millions de vertices) Premieres approches2 solutions possible: Voxeliser Decouper la partie externe du volume Imprimer cette couche et reassembler le modele creux Voxeliser Decouper le volume en sous-volumes Imprimer et reassembler Premieres iterations Utilisation de notre propre voxeliseur a partir de bibliotheques quâ€™on adapteGrand tournant: Decouverte VTKOutils VTK On a eu un cours Visualisation et interactions integrees Gestion PyQT Package python Simplifie utilisation Blender rapide mais mauvais sur les grosses donnees Meshlab meilleur pour les gros sets Pipeline Entree: modele 3D (OBJ)Sorties attenduesPlein de formats differents : utilise OBJ et XMLResultatProblemesVTK: Pas de doc Peu dâ€™exemples et pas dans tous les langages Import vtkmodules.allConclusion Gerer les fichiers de facon plus propre Trouver un moyen de generer un bitmap de maniere intelligente Automatiser de plus en plus la segmentation en sous-volumes Comprendre VTKQuestionsGuillaume TochonComment a ete decoupe le travail ? Avant VTK, probleme de restreindre le sujet et VTK probleme de lâ€™engineQuels cours on ete utiles ? VTK tres utile meme si le cours est legerImpression 2.5D ? Pour des scans de tableau, seulement une face compteElody PuybareauEst-ce que le projet vous a plu ? Oui meme si beaucoup de galeres, on pu voir lâ€™imprimante 3D de $3m^2$ElevesPourquoi le screenshot du tableau ? Tableau: fichier de 1,6Go, seule solution de screen le tableau pour avoir la textureRetour de Mihaly2-3 precisions sur la machine: 9 tetes avec des micro-buses qui lache du polymere sur $3m^2$ donc beaucoup de donnees, galere car confinement, retour tres positif" }, { "title": "PFEE Mihaly", "url": "/cours/posts/pfee_mihaly/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:45:00 +0100", "snippet": "Lien de la note HackmdPrototypage dâ€™un voxeliseur avec VTKMihaly Startup dâ€™impression 3D Nouvelle tech dâ€™impression qui permet dâ€™avoir du texturing et de la couleur Precision a lâ€™echelle du micrometre Creation de lâ€™application et du pipeline de traitements des objets a imprimer Problematique: Impression 2.5D/3D dans un espace reduit Incapacite de creer des structures de soutien pour les objets flottants Opti de lâ€™utilisation de materiaux colorises Gros volume de donnees (scan de plusieurs millions de vertices) Premieres approches2 solutions possible: Voxeliser Decouper la partie externe du volume Imprimer cette couche et reassembler le modele creux Voxeliser Decouper le volume en sous-volumes Imprimer et reassembler Premieres iterations Utilisation de notre propre voxeliseur a partir de bibliotheques quâ€™on adapteGrand tournant: Decouverte VTKOutils VTK On a eu un cours Visualisation et interactions integrees Gestion PyQT Package python Simplifie utilisation Blender rapide mais mauvais sur les grosses donnees Meshlab meilleur pour les gros sets Pipeline Entree: modele 3D (OBJ)Sorties attenduesPlein de formats differents : utilise OBJ et XMLResultatProblemesVTK: Pas de doc Peu dâ€™exemples et pas dans tous les langages Import vtkmodules.allConclusion Gerer les fichiers de facon plus propre Trouver un moyen de generer un bitmap de maniere intelligente Automatiser de plus en plus la segmentation en sous-volumes Comprendre VTKQuestionsGuillaume TochonComment a ete decoupe le travail ? Avant VTK, probleme de restreindre le sujet et VTK probleme de lâ€™engineQuels cours on ete utiles ? VTK tres utile meme si le cours est legerImpression 2.5D ? Pour des scans de tableau, seulement une face compteElody PuybareauEst-ce que le projet vous a plu ? Oui meme si beaucoup de galeres, on pu voir lâ€™imprimante 3D de $3m^2$ElevesPourquoi le screenshot du tableau ? Tableau: fichier de 1,6Go, seule solution de screen le tableau pour avoir la textureRetour de Mihaly2-3 precisions sur la machine: 9 tetes avec des micro-buses qui lache du polymere sur $3m^2$ donc beaucoup de donnees, galere car confinement, retour tres positif" }, { "title": "PFEE ForEvent", "url": "/cours/posts/pfee_forevent/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:00:00 +0100", "snippet": "Lien de la note HackmdPar Alexandre Girard - Nassim Habib-Allah - Xavier FichterForEvent Agence dâ€™animation evenementielle implantee a Paris et BordeauxEtat de lâ€™art App Ipad pour creer sa propre BD photos Dev en Swift Quelques secondes de calcul par imageObjectifs Ameliorer le temps de traitement des images Ajout de nouveaux filtres Creer une verion PC, portable sur un serveurFonctionnement du projet/filtres On utilise C++/OpenGL: GLFW et glad Combinaison de Vertex/Fragment Shader Chaque filtre est rendu dans un FrameBufferFiltre Manga/CouleurFilte ComicsDeployer sur un serveur Deployer avec docker et Serveur-X Utiliser nvidia-docker-runtime et xvfb Contrainte de la versio dâ€™OpenGL Deployer sans docker et Serveur-X Utiliser EGL au lieu de GLFW OpenGL moderne dispo Rendu Headless API Web Une interface simple pour upload une image vers le serveur et choisir le filtre a appliquer Permet de telecharger lâ€™image filtreeResultatsBenchmark:Ameliorations Faire de GPGPU $\\rightarrow$ Compute Shader ou CUDA Reunir plus de filtres dans un shaderConclusionProjet interessant, nouvel aspect de OpenGL et rendu sur serveurQuestionsGuillaume TochonPourquoi parti sur lâ€™aspect rendu que traitement ? Pas pret a composer des filtres, besoin de connaissances en Swift: â€œOuh la câ€™est quoi cette choseâ€Elody PuybareauSur la version comics, outils deja pret ou polarisation maison ? Filtre deja disponible sur lâ€™application, portage PC, quelques types a changer/opti mais sinon filtres deja existantsElevesSatisfait du rendu ? Bien-sur câ€™est styleCombien de temps ? Avril/Mai en fonction de si un virus ne bloque pas lâ€™economie mondiale jusquâ€™a FevrierForEventQuestion pour les profs: comment se passe lâ€™attribution des projets ? Proposition des sujets, repartis par groupe (1 groupe = un sujet), beaucoup de bataille pour obtenir un sujet mais surtout les etudiants choississentRetour de ForEventExperience nouvelle et positive, communication a ameliorer mais reussi a remplir les objectifs surtout que ralenti aussi a cause du corona, explorations a essayer mais manque de connaissance de la part de lâ€™entreprise (ex: filtre peinture impressioniste)" }, { "title": "Epee et fusee", "url": "/cours/posts/epee_fusee/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 12:15:00 +0100", "snippet": "Lien de la note Hackmd Quâ€™est-ce qui se passe si on fusionne une epee et une fusee ?Jeu dâ€™epee ou les joueurs peuvent se deplacerLe reseau Defini la structure du code Photon Unity Network Synchronisation du minimum Pas ouf de synchoniser tout Synchro les animations Personnage 3D Modele 3D et animations Si le joueur bouge sa main dans le jeu, tout le monde doit le voir Hit Box par membre du corps (tete, torseâ€¦) Metaphore du corps du joueurModele camera Retranscrire les deplacements reels du joueur dans le jeu Le personnage est la camera Le corps du personnage suit la cameraLes fusees Une fusee par main (activable par le joueur) Changement de velocite du personnage selon orientation de la main Deplacement tridimensionnel Permet un deplacement assez fun Ne cause pas la nauseeLes armes Abstraction: support de plusieurs armes (et bouclier) Detection des collisions avec les personnages Systeme dâ€™energe: solution pour gerer les collisions entre les armesChangement dâ€™arme Propre a chaque main Changement enclenche par: main derriere la nuque Calcul par rapport a la position du joueurEnvironnement 3D Objectif: vertigineux, theme urbain Probleme: souvent trop lourd pour le Quest Solution: texture basse qualiteQuestionsLe mouvement des personnages synchro sur le reseau ? Ce quâ€™on synchro câ€™est la target dâ€™origine et sa rotation, on synch la tranlsationDegats de chutes ? Non pas implemFaire des deplacements dans une zone de non gravite ? Manque lâ€™aspect de retomber facilementQuelles interactions PC ? Pas dâ€™interaction PC, la vue sert de debuggueur" }, { "title": "Station spaciale", "url": "/cours/posts/space/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 12:00:00 +0100", "snippet": "Lien de la note HackmdSujet Pilotage station spatialeConcept Joueur VR Pilote le vaisseau dans la station Joueur PC Dirige la station Communication Entre joueurs: discordJoueur 1: Pilote Positionne dans un vaisseau Controle du vaisseau via les manettes VR Peut se deplacer dans toutes les directionsJoueur 2: Tour de controle Deplacement via clavier/souris Se deplace sur les passerelles/plateformes pour appuyer sur les boutons Dispose de differents boutons Controle ce qui se passe dans la station a lâ€™aide de 4 camerasBut: aide le vaisseau a se poser sans encombres et repartirInteractions entre les 2 joueurs Le gardien de la station ferme les portes apres avoir verifie lâ€™identite du vaisseau Le gardien indique au vaisseau ou se poser Le gardien indique les manoeuvresMetaphores dâ€™interactions Utilisation dâ€™un pointeur laser dans le menu Utilisation dâ€™une main virtuelle dans le jeu pour controller le vaisseau Le pilote appuie sur la gachette de la manette pour saisir les joysticks Le gardien de la station active les boutons en cliquant sur la souris a lâ€™aide dâ€™un reticule Le gardien de la station se deplace en vue 1er personneDifficultes Integration de la VR (assets, port USB-C) Joysticks du vaisseau instable Problemes de reseau (perte de paquets) rendant le gameplay instable (mouvement saccadesâ€¦)QuestionsLibrairies pour integration casque/reseau ? Package integration Occulus pour le casque et pour le reseau des sockets" }, { "title": "Master Piece", "url": "/cours/posts/master_piece/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:50:00 +0100", "snippet": "Lien de la note HackmdGeneration du terrain Bruit de PerlinGameplay Inspire mais pas copie des Transformers Un joueur PC controle la voiture et lâ€™autre controlle la tourelle a lâ€™arriere de la voitureCe que lâ€™on peut parametrer Vie ennemi/joueur Degates ennemi/joueur Vitesse dâ€™appartion des ennemis / munitions Carateristiques de la voiture Nombre dâ€™ennemisAmelioration possibles Power-upQuestionsQuels outils pour le reseau ? Photon mais ne fonctionne pas donc demo en localLe comportement des ennemis ? Vont direct sur la voiture, sâ€™arrete puis lance animation dâ€™attaque" }, { "title": "Mad Maze", "url": "/cours/posts/mad_maze/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:30:00 +0100", "snippet": "Lien de la note HackmdIntroduction Jeu inspire de â€œKeep Talking and nobody exploresâ€ Grand labyrinthe rpz les salles dâ€™un vaisseau Trouvez et declenchez les boutons pour en sortirMapLe joueur PC dispose de la carte du chemin a prendre pour guider le joueur VR.Implem Package: SteamVR avec commandes personnalisees Contient des deplacement Teleportation Map: Cree sur Space Engineers, exportee en .obj Multiplayer: Cooperation pour trouver les boutons et la sortieNiveau de difficulte Le joueur PC doit communiquer clairement et savoir lire une carte, les numeros de salle sont une aide La vision est reduite a la lampe frontale en interieur, possibilite dâ€™utiliser la vue VR Facile de se perdre complemetement, meme avec la carte, meme pour les devProblemes rencontrees Generer la map (trop) volumineuse Gerer correctement toutes les collisions Avoir des boutons non bogues Compliquer de tester la VRQuestionsPossible de generer des maps randoms ? Malheureusement non, pas de chargement procedural mais generer la visualisation en chunks donc technique possible de le faireLe joueur PC ne voit pas le joueur VR ? Non mais peut partager la vue VR du joueur" }, { "title": "Obstacles", "url": "/cours/posts/obstacles/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:15:00 +0100", "snippet": "Lien de la note HackmdPar Amelie, Alexandre, BrunoSujet: un jeu collaboratif2 joueurs: un avec un casque VR, lâ€™autre PCBut: Le joueur VR doit finir le niveau Le joueur PC doit lâ€™en empecher, en utilisant la mapMap3 zones Attente (spawn): choix des armes Combat FinJoueur PC Empecher le joeur VR de finir le niveau Faisant spawn des ennemis sur la map Accelerer la vitesse des plateformesJoueur VR Deplacement avec Joystick Rotation en bougeant la tete Se defendre avec une armeCombat Les ennemis peuvent lancer des boules de feu Le joueur VR perd des PV sâ€™il se fait toucher ou touche une ennemi Tirer sur une boule de feu permet de la detruire, meme avec un coup de sabre laserFin de la partie Le joueur VR a passe la porte de fin de niveau $\\rightarrow$ joueur VR gagne Le temps imparti $\\rightarrow$ joueur PC gagne Le joueur VR tombe $\\rightarrow$ joueur PC gagneProblemes rencontres Le reseau Mirror Le spawn des joueurs sur la scene et leurs gameobjects La synchro (objets, ennemis, etc.) QuestionsPertinant que les ennemis et boules de feus synchro ? Sans la synchro, le joueur PC ne verrait pas la vraie sceneBoule de feu instantiee sur le network ou chez le client ? Avec Photon: utilise photon view, de meme que les ennemisComment sont gerer les deplacement ? OVR ControllerInteraction entre les 2 joueurs: comment le joueur PC voit le joueur VR ? Le joueur PC a une camera fixe et le joueur VR est rpz par un cube sur son ecran." }, { "title": "Martin et Titouan", "url": "/cours/posts/martin_titouan/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:15:00 +0100", "snippet": "Lien de la note Hackmd Je vais me faire une fondue savoyarde ca ira mieux.A chaque fois que la camera bouge, on render une nouvelle texture sur le plan.QuestionSi on recule a traver le portail ? On reste dans la salle, on calcule lâ€™angle par rapport au plan pour traverser le portailInteraction avec dâ€™autres joueurs ? Un joueur PC et un joueur VR, un joueur se cache et lâ€™autre le cherche (pas implem)Musique de la video uniquement sur la video ou dans le jeu ? Uniquement sur la video" }, { "title": "Mona VR", "url": "/cours/posts/mona/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:40:00 +0100", "snippet": "Lien de la note Hackmd Coupler peinture/VR Plsrs modes Enregistrement des oeuvres dans une gallerie Partager en reseauPeinture et reprod oeuvre Canvas creer sur Blender Interaction peinture / toile Impression en filigrane des oeuvres Image desaturee utilise comme textures Lien unity/occulus Peu tuto Plugin 2019 Occulus Integration XR unity utilitiesGallery Possible sauvegarder Clear le tableau Nom du fichier: date sauvegarde Display des productions disponibles a partir du menuMulti Mode peinture a 2 Photon Pun 2 Utilisation intuitive Modele host/client vs room server Une room avec 2 joueurs maxConclusion Approche pedagogique Donner le gout de la peinture Faire connaitre des tableaux Decouverte dev vr Ameliorations possibles Upload son tableau au choix Precision Pallette de couleurs plus complexe QuestionsCreation de lâ€™image ? Texture du canvas changee et updateePu partager la texture par reseau ? Oui" }, { "title": "War VR", "url": "/cours/posts/war/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:30:00 +0100", "snippet": "Lien de la note Hackmd War VR A collaborative VrWar : a card game War: a 2-player card game Deck evenly divided between 2 players At each round, top cards are revealed: higher card wins Winner gains the opponentâ€™s card If equal value = â€œwatâ€ Next card top down End of game when a player got no card leftWar VR: in Reality Hard to work on while being homestuck Hard to rush Massive restructuring mid-development Drastic artistic and game design shift No collaboration Jâ€™en appelle au Dragon blanc aux yeux bleus !Whatâ€™s left Game mechanics (hidden by the scenario) Second player: plays automaticallyProblems encountered Network: PC build One Occulus Quest that needs the game to be built to test XR interactable madnessQuestionsComment shuffle les cartes ? En Csharp fonction pour SuffleDifficile dâ€™emuler le casque VR sur PC ? Anne sâ€™est occupe de tout ce qui touche a la VRPartie reseau dâ€™abord mirror, et pour la partie PC ? But pour verifier les instanciation, pour Occulus fonctionne mais a jamais build PC, tester le multi dans lâ€™editeurInteractions avec les manettes ? Tester â€œflip the tableâ€ mais faisait nâ€™importe quoiComment recuperer les sons Yugi-oh ? Pas tres legalement avec la serie sur Netflix" }, { "title": "Whiteboard in VR", "url": "/cours/posts/whiteboard/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:15:00 +0100", "snippet": "Lien de la note Hackmd On va vous montrer un projet tout pourri!Projet: whiteboard en VRProject goals Write on a whiteboard Implement mutliple tools Interact with multpile people with the whiteboardFeatures implemented Write on the whiteboard Create a pen Grab a pen Detect collision between pen and whiteboard Problems encountered Difficulte avec textures Detecte collision mais pas de texture Pas pu rajouter le multi Difficult test environment Difficulty on Linux Moving, could only work in the kitchen but had an occulus 50cm space to test a VR game Pourquoi je suis penche ? Le cable etait pas assez long Câ€™est parce que je sais pas dessiner que câ€™est moche - en dessinant un moutonQuestionEst-ce quâ€™il y une sensation en ecrivant ? Non car la manette vibre en permanenceEn terme de mutliplayer ? Utiliser PhotonComment applique la texture ? Repere la collision et applique la texture en X,Y" }, { "title": "Le Projet Grosses Mains", "url": "/cours/posts/grosses-mains/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:00:00 +0100", "snippet": "Lien de la note HackmdUn jeu triple AConcept Coop VR/PC Platformer Object displacement Mutliple scalesVR Player Capacity to grab objects in environment Creation of passageInteractable Can grab a plankKeyboard/mouse player Input System Manager Cimemachine Camera Handles Mouse input Define movement direction according to the camera vectors Handles rotation and animations Add jump and gravityNetwork handling Photon Photon view: dire au perso ou il est pour le netowrk Character follow: permet au personnage network de suivre le perso client Verifier que perso network bien instancieLevel Design The floor is lava Movable objects to help the player go through the levelQuestionPourquoi photon pour la partie reseau ? Le plus simple a utiliser, a la base serveur dedier mais Photon bien plus simple et moins de tempsQuel casque ? Occulus quest, dans la video 2 joueurs sur Quests car autant de joueurs VR + PC possibleComment la cooperation se fait entre 2 joueurs en VR ? Ne peuvent pas interagir, uniquement pour la video demoPour les animations du perso PC, comment ? Tout ete fourni avec le personnage (assets)" }, { "title": "Bowowob", "url": "/cours/posts/bowowob/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 09:30:00 +0100", "snippet": "Lien de la note HackmdProject presentation Inspired by The Lab by Vavle Castle defense Enemy waveTool used XP interaction toolkit Photon Network UnityPlayer Movement Room scale Teleportation Network Player avatar spawned on network Movement synch with avatar Bow &amp;amp; arrowQuiver On enterBow Complex interaction Shooting an arrow Place arrow on string Bow hand and string hand distance for animation and particles Arrow When released Force applied Check for certain collisions Line renderer and particles Network Arrows are spawned on the server Forces and positions are synchronizedEnnemies 3 different spawns Checkpoint system Death animation For each wave: More enemies Same health Map Assets were combined to build it unity URP is used to make the game look better Shadows were usedMultiplayer Interactable objects Potions Shareable equipment Arrows Bow Conclusion Problems encountered Arrow synch Objects were not shareable Random hand crashing Good proof of concept and quite funQuestionsCommence quand ? Combien de temps ? Solo rapide a faire, tout casse avec le reseau, beaucoup de temps a fix le multi, a du faire des impasses sur certaines parties du gameplayComment faire les particules ? Package Unity qui gere les particules, suffit dâ€™activerClient master ? Celui qui recoit les infos en premier et recoit les trucs en synchro" }, { "title": "Comballoration", "url": "/cours/posts/comballoration/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 09:00:00 +0100", "snippet": "Lien de la note HackmdVideo de demonstration: duel 1v1 en VR avec des armes (epee, pistolet, assiettes, etc.) Le but est tout simple: câ€™est de le tuerContexte Projet de Realite Virtuelle et AUgmentee Necessite dâ€™avoir de la collaboration, aka pas de solo Dernier projet a EpitaSujet choisi Jeu de combat 1v1 Gare du Nord CollaborationComposants de base Le paquet OVR Gestion de base du casque VR Gestion de base des manettes Occulus Le paquet Mirror Gestion de reseau Copie de Unet, API reseau de Unity Fonctionnement Pour les armes: Reprise du fonctionnement du TP INtroduction de Commands Pour la camera VR: Reprise du TP Ajout dâ€™un script pour lâ€™initialisation du multi Boucles de jeu principales Pas de PVs Emphase sur la vitesse pour attraper lâ€™epee ou le pistolet Des quâ€™un joueur se fait toucher: MORTDifficultes La camera Reprendre le TP correctement Avoir la camera au bon endroit Synchro de la camera et bugs mix VR/Network Le reseau Synchro des positions Gestions dâ€™autorite avec Mirror Tentatives ratees Robot Kyle avec des animations Bug de reseau, etcâ€¦ VR Rig Perso 3D Notre propre mesh de personnage (blender et unity voulaient pas) Ajout de joueurs (sur tel par exemple)Outils Polybrush LowPOlyConclusion Projet ultra fun Necessite de recruter des cobayes pour les tests (Nausee, etc.) Bonne decouverte de Unity (admissions paralleles) Press F to pay respect at Robot KyleQuestionsProjets de combien de temps ? Fait la semaine derriereImmobile ou on peut se deplacer ? On peut se deplacer mais certainement mort instantFonctionne sur casque autre que Occulus ? Utilisation de OVR, jamais pose la question vu que le but est de le faire en QuestCreation des contenus 3D? Recuperation dâ€™assets + assemblage des scenes a la main.Organisation du travail ? Occulus maison, 1 sâ€™occupe des scenes et les 2 autres le reste, beaucoup de pair programming" }, { "title": "PFEE Vesselness Covid", "url": "/cours/posts/pfee_covid/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-01 16:00:00 +0100", "snippet": "Lien de la note HackmdSous la supervision dâ€™Odyssee MerveillePar Camille, Rene-Louis, Salome et SophieAnalyse des consequences du Covid dans les vaisseaux sanguins.VesselnessAlgo se basant sur les structures tubulaires des vaisseaux sanguinsRORPO Tool using mathetical morpholy to segment vessels characterizing the curvilinear structures detecting these strcutures by countin th number of high responses of an oriented filter, the path operatorsUne reponse indique le rayon et lâ€™autre le chemin du vaisceauBut et problematique du PFEE Peut-on utiliser RORPO pour analyser les differences entre patient sain et pattient atteint ? Ces differences nous permettent-elles de determiner lâ€™avancement de la maladie ?La pipeline Segmentation via RORPO Extraction de donnees/metriques Visualisation des metriques Analyse des resultatsTimeline du projetPrise en main de nouveaux outils Slicer: tres utilise dans lâ€™imagerie medicale HPC avec qsubMetriques Valider les hypotheses: dilatation du reseaux vasculaire + lesions Certaines metriques moins pertinentes que dâ€™autres mais sont garder car on connait mal cette maladieSegmentation des vaisseaux:Metriques quantitatives Nombre de composantes connexes Nombre de Voxels labellisesDes donnees par labelMetriques par label, cad par composante connexePas eu le temps de recuperer un outilsUn maximum de minimumOn travail sur les rayons des composantes connexePar element connexe, on calcul le rayon minimum et on en retire: le min des min la moyenne des min le maximum des min un histogramme des minUn maximum de maximumPar element connexe, on calcul le rayon minimum et on en retire: le min des max la moyenne des max le maximum des max un histogramme des maxLa moyenne, une donnee controversee le min des moyennes la moyenne des moyennes le maximum des moyennes Manque de sens theorique si mauvaise segmentation. Mais cette perte de sens ne serait pas exploitable ? Devrion nous pas nous tourner vers une moyenne pondere par la taille des vaisseaux ?Des metriques pour le futur des moyennes ponderees Volume du reseau vasculaire relativement au volume des poumons Volune des composantes connexes Remplacer les metriques par label par des metriques par embranchement grace a un algorithme de transformation en graphePresentation du Dataset Donnees confidientielles Patients + ou - atteintsNombre de composantes connexe augmente avec la severite duUniforme chez les patients les plus atteints, mais besoin de plus de donnees pour en tirer une conclusionRayon moyenExtremum toujours patient severement atteintRecapAugmentation du nombre de voxel pour une taille de poumon qui nâ€™augmente pas chez les patients atteints.Conclusion a partir des resultats Les metriques sont a adpate Pas de resultats concluantPour la suite Ajouter de nouvelles metriques Plus grand datasetQuestionsElody PuybareauRORPO ne fait directement de segmentation: quelle est la brique rajoutee pour la segmentation ? Commencer par utiliser RORPO, stagiaire de Odyssee a cree la brique en plus qui a ete reprise pour ce PFEEUtilisation des output du stagiaire ? Faire une pipeline qui prend tout en compte mais algorithme lourd donc division des taches Utilistion de Matplotlib: attention car segmentation binaire mais 3 couleurs a cause de Matplotlib qui en melange pour les objets fins \\(\\rightarrow\\) ne jamais faire confiance a Matplotlib et son interpolationGuillaume TochonBase de donnees restreinte, dur dâ€™en tirer des estimateurs fiable et representatif: pertinent de montrer des histogramme ? Coefficient de correlation plus pertinents ? Outils pour la posterite car le projet va etre repris, pas vraiment pense a un autre indicateur, but de faire lâ€™analyse de donnees que dâ€™en tirer des conclusionsVous etes satisfait du travail fourni ? Bien aime avoir plus de temps pour travailler, dommage de pas avoir plus de temps pour PFEE, assez content du projet. A la fin du projet proche dâ€™avoir une demarche scientifique complet, manque de temps. Frustration a cause de blocages sur sujets techniques.Quels sont les cours qui ont ete le plus utile? IMED, IMED2 utile mais arrive un peu tard $\\rightarrow$ PFEE utile pour IMED2Repartition du travail? Pair programming, rotations 2 par 2Question etudiantsTres peu de resultats: comment faire dans ce cas? On peut esperer en avoir plus, tres complique de recuperer des donnees surtout venant de lâ€™hopital. On ne peut pas en tirer de conclusion.Si vous aviez plus de donnees, comment aurai ete la fin du projet? Beaucoup de recul sur les patients, reflexion sur les resultats mais pas sure de comment conclure.OdysseeIdee de ce PFEE: degrossir la pipeline globale, des etudiants qui travaille sur le pipeline complet, avoir des resultats concrets.Une fois quâ€™on a le pipeline complet, on a une vision plus globale et on se rend compte de ce qui bloque, ils ont eu une tres bonne demarche sur le projet. Beaucoup de contraintes: lâ€™accessibilite des donnees, acces moyens de calcul, etc.Pipeline develope qui va etre tres util et repris par la suite." }, { "title": "PFEE RORPO", "url": "/cours/posts/pfee_odyssee/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-01 15:30:00 +0100", "snippet": "Lien de la note HackmdRORPO By Odyssee MerveilleMathematical morphologyThe basic operators: Erosion Dilation Opening ClosingHow it works Relies on path operatorsC++ directional featuresRORPO: recuperer des features directionnelles, objets tubulairesDans lâ€™exemple: indiquer vecteur directionel Pointwise Rank Filter Find orientation of interest Combine orientationsDans lâ€™exemple: la separation qui minimise le mieux la formule est la bleueImplementationParametres optionel:Iterer pixels image:Chercher la bonne separation des groupes:Combiner orientations sur un meme vecteur:PyRORPOPython moduleLibrairie entierement en C++ pour PythonMethods: RORPO RORPO_multiscaleBindings libs: Ctypes CFFI Boost::PythonWhy pybind11: Focus on C++ Use of c++ to specify the module Simple to useBindingsA droite: definir la methode de notre module python $\\rightarrow$ mapping de notre fonction chapeauBINDING_OF_TYPE: defini tous nos bindings a chaque ligneDocumentationThe documentation on how to create shared library, import shared module in python, on each available functionNew options for C++ progran uint8: convert image in uint8 normalize: input mage normalizedTests pytest virtualenv integretaion machineTests: Float/double input image Input image containging negative values uint8 option windows optionIsotropic imagesIsotropy is uniformity in all orientationsUse of:itk::ResampleImageFilter&amp;lt;TInputImage, TOutputImage, TInterpolarPrecisionType, TTransformationPrecisionType&amp;gt;Encountered difficulties Creation of a PIP package Pas forcement de documentation: package en C++ pour python Package pas installable et distribuables sur differentes plateformes Isotropic imagesQuestionsGuillaume TochonPackage pip manquant mais hors ca est-ce que le produit est considere fini ? Pour les features implementees, le produit est termine, est fonctionel et fonctionne comme planifie au debutApplications concretes de tout ca? Non, hors celle de Odyssee. Odyssee a fourni des images synthetiques pour tester le programme et verifier que les resultats marchaient.Quels ont ete les cours suivis dans la majeur les plus utiles ? Le cours TK et morpho de mathsElody PuybareauQuestion sur RORPO: Vous avez montre lâ€™exemple avec un nifty, marche que sur nifty ou dâ€™autres types dâ€™image? Ca marche sur dâ€™autres type dâ€™image, marche sur nâ€™importe quel type dâ€™image. Le â€œload to numpyâ€ nâ€™est quâ€™un exemple Comment vous gerer la conversation en uint8? Par exemple les donnees medicales sont souvent en 16bits, regarde en details les histoire de dynamique ? Gerer automatiquement: lorsquâ€™on recoit des images de type uint16, directement gerer par RORPO Comment a ete decoupe le travail en equipe ? Tous ensembles, separes les differentes taches, etc. ? Separer les differentes tachesPression de faire des points avec Odyssee qui a permis dâ€™avancer ou auto-motive ? Lorsquâ€™on a plusieurs projets en simultanes, oui les reunions avec Odyssee permette de progresser regulierement. Repartir bredouille dâ€™une reunion permet de se motiver pour la fois dâ€™apres.ElevesQuâ€™est-ce qui a bloque le developpement du package pip? Que ce soit pas du full python, pas de facon propre de bind une librairie en C++OdysseeRessenti et travail fourni: projet long a demarrer au debut mais pas mal de background pour comprendre RORPO, beaucoup de code pas forcement hype propre a prendre en main et aussi beaucoup de projets en parallele.Gael et Anna ont propose des solutions satisfaisantes pour le binding, Anna a meme trouve des bugs dans le code original.Le binding en python est suffisant et librairie deja en cours dâ€™utilisation et au final tres satisfaite du travail.Travail pas tres axe recherche mais plus dev et amelioration." }, { "title": "Reunion rentree", "url": "/cours/posts/reunion_rentree/", "categories": "tronc commun S8, Rentree", "tags": "S8, tronc commun", "date": "2021-02-01 11:00:00 +0100", "snippet": "Lien de la note HackmdJoel Courtois Changer les relation ecole-eleves Generation etudiants purement consomateur (reproches fait si le produit ne correspond pas aux attentes) A tous les niveaux: evolution en temps reel, marche quand tout le monde sâ€™applique $\\rightarrow$ echanges Comment suivre les cours dans des condtions correctes ? 170 connectes au lieu de 220 (oups)Les cours Maximum de presentiel ! Accueil dans les labos Contraintes distanciations Etudiants ne souhaitant pas revenir Pour ne pas le nommer, le laboratoire de Gistre - Jojo Depends des eleves, des personnes souhaitant revenir Travaux dâ€™aggrandissiment impossible car corona On ne peut pas avoir une pure attitude de consommateur, on doit co-construire des solutions.Je nâ€™ai pas eu mon 1er voeu :cry: Effet de desertement: SRS: 50 places pour 25 personnes Aujourdâ€™hui: 90+ demandes Certains ravis de ne pas avoir leur 1er choix, on ne peut pas donner le 1er voeu a tout le monde :(Beaucoup de personnes en Gistre dont ce nâ€™etait pas le 1er choixOuvertue de la majeure SanteLe staffNouveaux personnes dans lâ€™adm pour le suivi des etudiants, equipe mises en place pour renforcer + arrivee de Claire Lecoq15 fevrier: arrivee Florent Boulay pour suivi dâ€™eleves $\\rightarrow$ personne ressourcesJob a la sortie~20 etudiants nâ€™ayant pas fait leur stage TC car pas dâ€™offre On est dans le creux de la vague.Les ing3 ont des stages avec un taux similaires aux annees precedentes.La demande reste extremement forte, notre arrivee sur le marche du travail sera probablement apres la pandemie. Les entreprises vont chasser les epiteens/epiteennes Vous etes les prochains a rejoindre lâ€™eliteSoumis aux aleas, prob confinement dans les semaines a suivre, etc. On passera cette periode en mieux que si nous sommes dans cet esprit de travail commun - JojoClaire Lecoq Vous nâ€™etes pas en fin dâ€™etudes, vous etes en debut de carriere.1er annee eprouvantes, conditions sanitaires pas oufs, eleves en souffrance On doit creer des collectifs etudiants de notre cote, pour apprendre, retransmettre aux eleves a distance, etc.Questions Gistre Le lab: lâ€™extension nâ€™a pas ete faite, transfo en salle de classe mais peut rentransformer en labo si besoin Responsable de majeure present Gistre ne bouge pas Gistre est la et va fonctionner! Les mineures seront en S9 Presentiel prevu, dans GITM par exemple Quelle procedure pour elire les delegues ? Historiquement les etudiants se debrouillent entre eux Le chef de majeure organise lui-meme les elections Semaine AWS : tronc commun avec activites AWS, anime par CHEWIIIIIIIIIIIE Ce nâ€™est PAS une semaine AWS Attendre les annonces pour savoir si presentiel ou non Tout sera regler cette semaine Tom si tu veux vraiment un mug Amazon, il leur en reste quelques-uns Pour les petits fruits je sais pas, il faut voir avec Joel Courtois Cartes etudiantes pretes cette semaine, distribuee aux delegues $\\rightarrow$ attendre lâ€™election des delegues A quoi sert le coatching ? Personne a appeler en cas de difficultes (scolaires, morales, etc.) Profil complementaires entre Elody et Delphine Elody: eleves en decrochage scolaire Delphine: preparateur psychologique, peut aider a construire un chemin en plusieurs etapes $\\rightarrow$ coaching Soutenance de stages gerees au fil de lâ€™eau, mois de fevrier jusquâ€™a Avril/Mai/Juin Nous vous souhaitons un bon parcours dans vos majeures - Claire &amp;amp; Jojo Bonzai, on y va ! - Jojo" }, { "title": "SEDE : How to pass the exam?", "url": "/cours/posts/sede_how_to_pass_the_exam/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-07-13 15:00:00 +0200", "snippet": "Lien de la note HackmdMCQ Have to know basic terms You should be able to demonstrate that you understand the term by explaining it in your own words You should be able to RTFM for Unix Basics c/Unix development give concrete examples create your own examples Advanced questions There will be source code samples to edit (and fix) It wonâ€™t be 100% clean It wonâ€™t be exactly like â€œstandard epita codeâ€ Security issues to fix are nasty ones If itâ€™s different itâ€™s not necessarily wrong Beware of wrong assumptions You should be able to point ou the most problematic lines Write in proper English" }, { "title": "PROC : Seance de revisions", "url": "/cours/posts/proc_revisions/", "categories": "S6, tronc commun, PROC", "tags": "S6, PROC, tronc commun", "date": "2020-07-03 14:00:00 +0200", "snippet": "Lien de la note HackmdCalculer la densiteEtant donnee $f$, est-ce une densite ? Si oui, $P(\\text{X}\\le3)$ ? Verifier que la $f \\ge 0$ et $\\int^{+\\infty}_{-\\infty} = 1$Calculer avec la densiteEtant donnee $f$ densite, calculer $E(\\text{X})$, $Var({\\text{X}})$ $E(\\text{X}) = \\int^{+\\infty}_{-\\infty}xf(x)dx$ $Var(\\text{X}) = \\int^{+\\infty}{-\\infty}\\biggr(x-E(x)\\biggr)^2f(x)dx=\\int^{+\\infty}{-\\infty}x^2f(x)dx - \\biggr(E(x)\\biggr)^2$X et Y independants, calculer la densite$\\text{X}$ et $\\text{Y}$ independants, densite $f$ et $g$. Densite de $\\text{X} + \\text{Y}$ ? $h(x) = \\int^{+\\infty}_{-\\infty}f(x - y)g(y)dy$Calculer la densite de $\\alpha\\text{X} + \\beta$Densite de $\\alpha\\text{X} + \\beta$. Densite de $\\text{X}$ : $f$. Il faut passer par la fonction de repartition. $F(X) = P(\\text{X}\\le x) = \\int^{+\\infty}_{-\\infty}f(t)dt$ $f(x) = Fâ€™(x)$ Soit $\\text{Y} = \\alpha\\text{X} + \\beta$, $g$ sa densite $G(x) = P(\\text{Y}\\le x) = P(\\alpha\\text{X} + \\beta\\le x)$ Premier CasSi $\\alpha\\gt 0, G(x) = P(\\alpha\\text{X} + \\beta\\le x) = P(\\text{X}\\le\\frac{x-\\beta}{\\alpha}) = F(\\frac{x-\\beta}{\\alpha})$En derivant $Gâ€™(x) = \\frac{1}{\\alpha}Fâ€™(\\frac{x-\\beta}{\\alpha})$Second CasSi $\\alpha\\lt 0, G(x) = P(\\alpha\\text{X}+\\beta\\lt x) = P(\\text{X}\\ge\\frac{x-\\beta}{\\alpha}) = 1 - \\frac{1}{\\alpha}Fâ€™(\\frac{x-\\beta}{\\alpha})$En derivant $Gâ€™(x) = -\\frac{1}{\\alpha}Fâ€™(\\frac{x-\\beta}{\\alpha}) \\Rightarrow g(x) = -\\frac{x-\\beta}{\\alpha}f(\\frac{x-\\beta}{\\alpha})$Convergence en probabiliteDefinition $\\vert X_n\\vert$ converge en probabilite vers $\\text{Y}$ si $\\forall\\epsilon\\gt0, P(\\vert\\text{X} - \\text{Y}\\vert\\gt\\epsilon)\\to_{n\\to\\infty}0$Rappel \\(\\int_1^{+\\infty}\\frac{1}{x^{\\alpha}}dx\\begin{cases} \\text{converge si et seulement si} &amp;amp; \\alpha\\gt1\\\\ \\text{diverge si et seulement si} &amp;amp; \\alpha\\le1\\end{cases}\\)\\(\\int_0^{1}\\frac{1}{x^{\\alpha}}dx\\begin{cases} \\text{converge si et seulement si} &amp;amp; \\alpha\\lt1\\\\ \\text{diverge si et seulement si} &amp;amp; \\alpha\\ge1\\end{cases}\\)Primitive de $\\frac{1}{x^\\alpha}$:\\(\\begin{aligned}x^{-\\alpha} &amp;amp;= f(x)\\\\F(x) &amp;amp;= \\frac{1}{-\\alpha+1}x^{-\\alpha+1}\\end{aligned}\\)Cas particulier On tire $X_1, X_2,â€¦, X_n$ independemment distribuee et on definit la moyenne $\\bar X_n = \\frac{X_1 + â€¦ + X_n}{N}$\\(\\begin{aligned}E(\\bar X_n) &amp;amp;= E(X_1)\\\\Var(\\bar X_n) &amp;amp;= \\frac{1}{n}Var(X_1)\\\\\\sigma(\\bar X_n) &amp;amp;= \\sqrt{Var(\\bar X_n)}\\\\\\text{Car}\\space E(\\bar X_n) &amp;amp;= \\frac{1}{n}(E(X_1) + ... + E(X_n)) \\\\ &amp;amp;= E(X_1)\\\\Var(\\bar X_n) &amp;amp;= \\frac{1}{n^2}(Var(X_1) + ... + Var(X_n))\\\\&amp;amp;= \\frac{nVar(X_1)}{n^2} = \\frac{Var(X_1)}{n}\\end{aligned}\\)InÃ©galitÃ© de Tchebychev \\(\\begin{aligned}\\forall\\epsilon\\gt0, P(\\vert\\bar X_n - E(X_n)\\vert\\ge\\epsilon) &amp;amp;\\le \\frac{Var(\\bar X_n)}{\\epsilon^2}\\\\&amp;amp;\\le\\frac{Var(X_1)}{n\\epsilon^2}\\to_{n\\to\\infty}0\\end{aligned}\\)Donc $P(\\vert\\bar X_n - E(X_n)\\vert\\gt\\epsilon)\\to_{n\\to\\infty}0$Theoreme central limite $X_1, X_2, â€¦, X_n$ $\\bar X_n = \\frac{X_1 + â€¦ + X_n}{n}$On a vu que $E(\\bar X_n) = E(X_1)$ et que $Var(\\bar X_n) = \\frac{1}{n}Var(X_1)$ \\(Z_n = \\frac{\\bar X_n - E(\\bar X_n)}{\\sigma(\\bar X_n)}\\to Z\\)Ou $Z$ a une distribution normal centre reduite: $Z\\rightsquigarrow N(0,1)$ \\(E(Z_n) = 0 \\space\\text{et}\\space Var(Z_n) = 1\\)On a $\\forall[a,b]\\subset\\mathbb{R}$,\\(P(Z_n\\in[a,b])\\to_{n\\to\\infty}P(Z\\in[a,b])\\)Exercice typiquePremier exerciceSoient $X_1, â€¦, X_n$ independemment distribuee avec $E(X_1) = 3$, $Var(X_1) = 4$ et $\\bar X_n = \\frac{X_1 + â€¦ + X_n}{n}$. Trouver n tel que $P(\\vert\\bar X_n - 3\\vert \\ge 1)\\le 5\\%$. Solution :warning: Si $Z\\to N(0,1)$, $P(-1,96\\le Z\\le1,96) = 95\\%$1 est pris au hasar mais pas 3, câ€™est lâ€™esperance.Ici, on definit \\(\\begin{aligned}Z_n &amp;amp;= \\frac{\\bar X_n - E(\\bar X_n)}{\\sigma(\\bar X_n)}\\\\&amp;amp;= \\frac{\\bar X_n - 3}{\\sqrt{\\frac{4}{n}}}\\\\&amp;amp;= \\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}}\\end{aligned}\\)Si n est grand:\\(P\\Biggr(-1,96\\le\\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}} \\le 1,96\\Biggr) = 95\\%\\\\P\\Biggr(\\Biggr\\vert\\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}}\\Biggr\\vert \\le 1,96\\Biggr) = 95\\%\\\\P\\Biggr(\\vert\\bar X_n - 3\\vert \\le \\frac{1,96 * 2}{\\sqrt n}\\Biggr) = 95%\\\\P\\Biggr(\\vert\\bar X_n - 3\\vert \\ge \\frac{3,92}{\\sqrt n}\\Biggr) = 5\\%\\) Si $\\frac{3,92}{\\sqrt n} = 1$, on a:\\(P(\\vert\\bar X_n - 3\\vert\\ge 1) = 5\\%\\) Si $\\frac{3,92}{\\sqrt n} \\ge n_0$ avec $n_0 = 3,92^2$ valeur minimale de n, on a:\\(P(\\vert\\bar X_n - 3\\vert\\ge 1) \\ge P(\\vert\\bar X_n - 3\\vert\\ge \\frac{3,92}{\\sqrt n}) \\le 5\\%\\) Deuxieme exerciceOn achete une machine. $P_{\\text{Machine defectueuse}} = 2\\%$. On achete $n$ machines. Pour $i\\in [1, n]$\\(X_i =\\begin{cases} 1 &amp;amp; \\text{si defectueuse}\\\\ 0 &amp;amp; \\text{sinon}\\end{cases}\\)et $\\bar X_n = \\frac{X_1 + â€¦ + X_n}{n}$On sait que $\\bar X_n\\to_{\\text{prob}}2\\%$. Trouver $n_0$ tel que $\\forall n\\ge n_0$, $P(0,01\\le\\bar X_n\\le 0,03) \\ge 95\\%$. Solution Autrement dit, \\(\\begin{aligned}P(\\vert\\bar X_n - 0,02\\vert\\le0,01)&amp;amp;\\ge95\\%\\\\\\text{donc}\\space P(\\vert\\bar X_n - 0,02\\vert\\ge0,01)&amp;amp;\\le5\\%\\end{aligned}\\)\\(X_i =\\begin{cases} 1 &amp;amp; \\text{avec proba}\\space p = 0,02\\\\ 0 &amp;amp; \\text{avec proba}\\space 1-p\\end{cases}\\\\E(X_i) = 0*(1-p)+ 1\\ast p = p\\\\\\begin{aligned}Var(X_i) &amp;amp;= E\\biggr((X_i-E(X))^2\\biggr)\\\\&amp;amp;= E\\biggr((X_i - p)^2\\biggr) = p(1-p) = 0,02 * 0,98\\end{aligned}\\)Pour $\\bar X_n$:\\(\\begin{aligned}E(\\bar X_n) = E(X_1) = p\\\\Var(\\bar X_n) = \\frac{1}{n}Var(X_1) = \\frac{p(1-p)}{p}\\end{aligned}\\)On pose:\\(Z_n = \\frac{\\bar X_n \\ E(\\bar X_n)}{\\sigma{\\bar X_n}} = \\frac{\\bar X_n - p}{\\sqrt{\\frac{p(1 - p)}{n}}}\\) On a donc:\\(\\begin{aligned}P(\\vert Z_n\\vert\\ge 1,96) &amp;amp;= 5\\%\\\\P(\\biggr\\vert \\frac{\\bar X_n - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\biggr\\vert\\ge 1,96) &amp;amp;= 5\\%\\\\P(\\vert \\bar X_n - p\\vert\\ge 1,96\\sqrt{\\frac{p(1-p)}{n}}) &amp;amp;= 5\\%\\\\\\end{aligned}\\)Si $n$ tel que $1,96\\sqrt{\\frac{p(1-p)}{n}} \\le 0.01$, on a $P(\\vert X_n - p\\vert\\ge 0,01)\\le5\\%$Troisieme exerciceSoit $f(x) = â€¦$. Si vous pensez que $f$ est une densite, entrer $P(X\\le3)$ Sinon rentrer $-1$ Solution :abc: Discussion sur les integrales impropres.Il faut verifier que $\\int_{-\\infty}^{\\infty}f(x)dx = 1$. Si $f$ est non-nulle sur une partie infinie de $\\mathbb{R}$, il faut discuter de la nature de lâ€™integrale. Soit elle est: divergente et $f$ nâ€™est pas une densite convergente et verifier que lâ€™integrale vaut 1 et que $f$ est positive ExemplesExemple 1\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{si}\\space x\\le1\\\\ \\frac{1}{x} &amp;amp; \\text{si}\\space x\\gt1\\end{cases}\\) Solution \\(\\int^{+\\infty}_{-\\infty}f(x)dx = \\int^{+\\infty}_{1}\\frac{1}{x}dx\\)Lâ€™integrale est divergente donc $f$ nâ€™est pas une densite.Exemple 2\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{sur}\\space ]-\\infty, 1]\\\\ \\frac{1}{x^{10}} &amp;amp; \\text{sur}\\space ]1, +\\infty[\\end{cases}\\) Solution \\(\\begin{aligned}\\int^{+\\infty}_{-\\infty}f(x)dx &amp;amp;= \\int^{+\\infty}_{1}\\frac{1}{x^{10}}\\space\\text{avec}\\spacex^{-10}\\to\\text{primitive:}\\space\\frac{1}{-10 + 1x^{^-10+1}}\\\\&amp;amp;=\\biggr[-\\frac{1}{9}\\ast\\frac{1}{x^9}\\biggr]^{+\\infty}_{1}\\\\&amp;amp;=0-(-\\frac{1}{9}) \\\\&amp;amp;= \\frac{1}{9}\\end{aligned}\\)$f$ nâ€™est pas une densite.Exemple 3\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{si}\\space x\\le1\\\\ \\frac{9}{x^{10}} &amp;amp; \\text{si}\\space x\\gt 1\\end{cases}\\) f est une densite (cf exo ci-dessus) $P(X\\le3)$? $E(X)$? $Var(X)$? Solution $P(X\\le3)$?\\(\\begin{aligned}P(X\\le3) &amp;amp;= \\int^{3}_{-\\infty}f(x)dx\\\\&amp;amp;=\\int^3_1\\frac{9}{x^{10}}dx \\space\\text{avec}\\space\\frac{9}{x^{10}}\\to\\text{primitive:}-\\frac{1}{x^{9}}\\\\&amp;amp;=\\biggr[-\\frac{1}{x^{9}}\\biggr]_1^3 = -\\frac{1}{3^9} + \\frac{1}{1^9} = 1 - \\frac{1}{3^9}\\end{aligned}\\) $E(X)$?\\(\\begin{aligned}E(X) &amp;amp;= \\int^{+\\infty}_{-\\infty}xf(x)dx\\\\&amp;amp;= \\int^{+\\infty}_{1}\\frac{9x}{x^{10}}dx\\\\&amp;amp;= \\int^{+\\infty}_{1}\\frac{1}{x^{9}}dx \\space\\text{avec}\\space x^{-9}\\to\\text{primitive:}\\frac{1}{-9+1}x^{-9+1} = -\\frac{1}{8}x^{-8}\\\\&amp;amp;= 9\\biggr[-\\frac{1}{8}x^{-8}\\biggr]_1^{+\\infty}\\\\\\&amp;amp;= 9[-0+\\frac{1}{8}] = \\frac{9}{8}\\end{aligned}\\) $Var(X)$?\\(\\begin{aligned}Var(X) &amp;amp;= \\int^{+\\infty}_{-\\infty}(x-\\frac{9}{8})^2f(x)dx\\\\&amp;amp;= E(X^2) - (E(X))^2\\\\&amp;amp;= \\int^{+\\infty}_{-\\infty}x^2f(x)dx - (\\frac{9}{8})^2\\end{aligned}\\)\\(\\int^{+\\infty}_{-\\infty}x^2f(x)dx = \\int^{+\\infty}_{1}x^2\\frac{x9}{x^{10}}dx \\space\\text{avec}\\space x^{-8}\\to\\text{primitive:}\\frac{1}{-8+1}x^{-8+1}=-\\frac{1}{7}x^{-7}\\)\\(E(X^2) = 9\\biggr[-\\frac{1}{7x^7}\\biggr]_{1}^{+\\infty} = 9\\biggr(-0+\\frac{1}{7}\\biggr)\\)\\(Var(X) = \\frac{9}{7} - \\frac{9}{8}^2\\) Densite de $X + Y$ quand $X$ et $Y$ independants $X$: densite $f$ $Y$: densite $g$ $Z = X + Y$: densite $h $h$ est la convolution de $f$ et $g$\\(h(x) = \\int^{+\\infty}_{-\\infty}f(x-y)g(y)dy\\) Exemple de distribution uniforme $X\\rightsquigarrow\\mathcal{U}([1, 2])$ $Y\\rightsquigarrow\\mathcal{U}([4, 5])$$f(x)g(y)\\not = 0 \\Leftrightarrow x\\in[1,2]\\space\\text{et}\\space y\\in[4,5]$\\(h(x) = \\int^{+\\infty}_{-\\infty}f(y)h(x - y)dy = \\int^{+\\infty}_{-\\infty}f(x-y)g(y)dy\\)Soit $x_0$ fixe, on calcule $h(x_0) = \\int^{+\\infty}_{-\\infty}f(x_0-y)g(y)dy$.\\(\\begin{aligned}f(x_0-y)g(y) \\not= 0 &amp;amp;\\Leftrightarrow \\begin{cases}1\\le x_0-y\\le2\\\\4\\le y\\le 5\\end{cases}\\\\&amp;amp;\\Leftrightarrow \\begin{cases}\\begin{aligned}x_0 -2\\le\\space &amp;amp;y\\le x_0 - 1\\\\4\\le\\space &amp;amp;y\\le 5\\end{aligned}\\end{cases}\\end{aligned}\\) Vert: $x_0 -2\\le\\space y\\le x_0 - 1$Rouge $4\\le\\space y\\le 5$ Cas $x_0 - 1\\lt4$ ($x_0 \\lt 5$): Pas de $y$ qui convient $h(x_0)=\\int^{+\\infty}_{-\\infty}0dx=0$ Cas $5\\le x_0 - 2$ ($x_0\\ge7$): Pas dâ€™intersection $h(x_0) = 0$ Cas $4\\le x_0 - 2\\le5\\le x_0 - 1$: $h(x_0) = \\int_{x_0 -2}^5 1\\ast1dx=[x]_{x_0 -2}^5 = 5-(x_0 - 2) = 7 - x_0$ Cas $x_0-2\\le4\\le x_0 -1\\le5$ ($5\\le x\\le6$): $h(x_0) = \\int_4^{x_0-1}1dy = [y]_4^{x_0-1} = x_0 - 1 - 4 = x_0 - 5$ Finalement: $x\\in[5,6]$, $h(x_0) = x_0 - 5$ $x\\in[6,7]$, $h(x_0) = 7 - x_0$ Ailleurs, $h(x_0)=0$" }, { "title": "OPEL : Seance de revisions", "url": "/cours/posts/opel_revisions/", "categories": "S6, Shannon, OPEL", "tags": "S6, OPEL, Shannon", "date": "2020-07-03 10:00:00 +0200", "snippet": "Lien de la note HackmdCalculer les integrales doubles On fixe une integrale et on calcule lâ€™autre.Premier exo$I = \\iint_D x^2 dxdy, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb{R}^2, x\\le1, \\space y\\ge0,\\text{ et } y\\le x\\rbrace$On trouve dâ€™abord les bornes, on fixe $x$ et on regarde les variations de $y$. Comme $x\\le1$ et $x\\ge y^2$, $x$ est positif et varie entre 0 et 1. Donc on fixe $x\\in[0, 1]$, on integre par rapport a $y$ positif et $y\\le\\sqrt{x}$, $y$ varie de 0 a $\\sqrt x$. \\(\\begin{aligned}I &amp;amp;= \\int^{x=1}_{x=0}x^2\\biggr(\\int_{y=0}^{y=\\sqrt{\\sqrt{x}}}dy\\biggr) dx\\\\&amp;amp;= \\int^{1}_{0}x^2\\sqrt{x}dx\\\\&amp;amp;= \\int^{1}_{0}x^{\\frac{5}{2}}dx = \\biggr[\\frac{2}{7}x^{\\frac{7}{2}}\\biggr]^{1}_{0}\\\\&amp;amp;= \\frac{2}{7}\\end{aligned}\\)Deuxieme exo$J = \\iint_D x^2dxdy, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb{R}^2, \\frac{x^2}{a^2}+\\frac{y^2}{b^2}\\le1\\rbrace$Cette integrale nous rappelle lâ€™interieur dâ€™un ellipse.Meme technique, on fixe $x$ et on regarde les variations de $y$.Premiere partieQuand on trace une ellipse, $x$ varie entre $-a$ et $a$. Pour trouver les variations de $y$, on fixe $x$ puis on isole $y$, $y$ va dependre de $x$ en fonction de la trajectoire de lâ€™ellipse. On obtient deux branches: une branche positif et une branche negatif en bas. \\(\\frac{x^2}{a^2}+\\frac{y^2}{b^2}\\le1 \\Rightarrow -b\\frac{\\sqrt1 - x^2}{a^2} \\le y\\le +b\\frac{\\sqrt1 - x^2}{a^2}\\)$y$ varie de $-b\\frac{\\sqrt1 - x^2}{a^2}$ a $+b\\frac{\\sqrt1 - x^2}{a^2}$.Deuxieme partieCette integrale est plus dur car on a une racine carree, cela peut sâ€™apparenter a un changement de variable.\\(\\begin{aligned}J &amp;amp;= \\int_{-a}^{a}x^2\\biggr(\\int_{-b\\frac{\\sqrt1 - x^2}{a^2}}^{+b\\frac{\\sqrt1 - x^2}{a^2}}dy\\biggr)dx\\\\J &amp;amp;= 2b\\int_{-a}^{a}x^2\\sqrt{1-\\frac{x^2}{a^2}}dx \\\\&amp;amp;\\text{On utilise la parite, tous les x sont au carre.}\\\\ &amp;amp;\\text{On fait donc deux fois l&#39;integrale de 0 a a}\\\\J &amp;amp;= 4b\\int_0^{a}x^2\\sqrt{1-\\frac{x^2}{a^2}}dx\\end{aligned}\\)On pose $x = a\\cos(t)$ pour se debarasser de la racine carre. Lâ€™astuce est de faire apparaitre une fonction trigonometrique pour obtenir $1-\\cos^2\\Rightarrow\\sin^2$, $x = a\\cos(t)\\Rightarrow dx=-a\\sin(t)dt$ Il y a un changement de bornes. $0 = acos(t)\\Rightarrow\\frac{\\pi}{2}$ et $x =a, \\cos(t) = 1\\Rightarrow t=0$\\(\\begin{aligned}J &amp;amp;= 4b\\int_{\\frac{\\pi}{2}}^0 a^2\\cos^2(t)\\vert\\sin(t)\\vert(-a\\sin(t)dt)\\\\ &amp;amp;= 4ba^3\\int^{\\frac{\\pi}{2}}_0\\cos^2(t)\\sin^2(t)dt\\space\\text{Attention! les bornes ont ete permuttees}\\\\ &amp;amp;= ba^3\\int^{\\frac{\\pi}{2}}_0\\biggr(\\sin(2t)\\biggr)^2dt=ba^3\\int^{\\frac{\\pi}{2}}_0\\biggr(\\frac{1-\\cos(4t)}{2}\\biggr)dt\\space\\text{car}\\space\\sin(2t) = 2\\sin(t)\\cos(t)\\\\ &amp;amp;= \\frac{ba^3}{2}\\biggr[-\\frac{\\sin(4t)}{4} + t\\biggr]^{\\frac{\\pi}{2}}_0 = \\frac{a^3b\\pi}{4}\\end{aligned}\\) Si la fonction etait impair le resultat serait 0 car $\\int_{-a}^a = 0$Troisieme exo$K = \\iint_D\\cos(x^2+y^2) dxdy, \\space\\text{ou } D=\\text{Disque de centre O et de rayon R}$ Faites un changement de variable en polaire.On pose $x = r\\cos(\\theta)$ et $y = r\\sin(\\theta)$. On est sur un disque de centre $O$ et de rayon $R$. Lâ€™angle polaire $\\theta$ varie de $0$ a $2\\pi$ et r varie de $0$ a $R$.Posons $\\begin{cases}x = r\\cos(\\theta)\\y = r\\sin(\\theta)\\end{cases}$.\\(\\begin{aligned}K &amp;amp;= \\int^{\\theta=2\\pi}_{\\theta=0}\\int^{r = R}_{r=0}cos(r^2)rdrd\\theta\\space\\text{car c&#39;est le Jacobien}\\\\&amp;amp;= \\int^{2\\pi}_{0}d\\theta\\int^{R}_{r=0}r\\cos(r^2)dr\\\\&amp;amp;= 2\\pi\\biggr[\\frac{1}{2}\\sin(r^2)\\biggr]=\\pi\\sin(r^2)\\end{aligned}\\)Quatrieme exo$Iâ€™ = \\iint_D\\frac{dxdy}{(1+x^2)(1+y^2)}, \\space\\text{ou } D=0\\le y\\le x\\le 1$$x$ varie de $0$ a $1$ et $y$ varie de $0$ a $x$. Le domaine est un triangle. Si $y = x$ câ€™est la bissetrice.\\(\\begin{aligned}I&#39; &amp;amp;= \\iint_D\\frac{dxdy}{(1+x^2)(1+y^2)}\\\\&amp;amp;= \\int^{x=1}_{x=0}\\int^{y=x}_{y=0}\\frac{dxdy}{(1+x^2)(1+y^2)}\\\\&amp;amp;= \\int^{1}_{0}\\frac{dx}{1+x^2}\\int^{y=x}_{y=0}\\frac{dy}{1+y^2}\\\\&amp;amp;= \\int^{1}_{0}\\frac{\\arctan(x)}{1+x^2}\\\\&amp;amp;= \\biggr[\\frac{1}{2}(\\arctan(x))^2\\biggr]^1_0 = \\frac{1}{2}(\\frac{\\pi}{4})^2 = \\frac{\\pi^2}{32}\\end{aligned}\\)Cinquieme exo$Jâ€™ = \\iint_D\\frac{dxdy}{(1+x^2+y^2)^2}, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb(R), \\space \\vert x\\vert\\le x^2+y^2\\le 1\\rbrace$On a lâ€™interieur dâ€™un disque de centre $O$ et de rayon 1. Si $x\\ge0$ $\\vert x\\vert = x \\le x^2 + y^2$ $x^2 - x + y^2 ge 0 \\Rightarrow \\biggr(x - \\frac{1}{2}\\biggr)^2 + y^2\\ge\\frac{1}{4}$ Si $x\\lt0$ $\\vert x\\vert = x \\le x^2 + y^2\\Rightarrow\\biggr(x+\\frac{1}{2}^2\\biggr) + y^2 \\ge \\frac{1}{4}$$D$ est la partie du disque de centre $O$ et de rayon $1$, exterieure au disque de centre $\\Omega(\\frac{1}{2}, 0)$ et de rayon $R=\\frac{1}{2}$ et au disque de centre $\\Omega^1(-\\frac{1}{2}, 0)$ et $R=\\frac{1}{2}$\\(D = D_1U D_2U D_3U D_4\\)D et la fonction $f(x, y)$ sont invariantes dans les symetrie par rapport aux axes. Determiner les extremes des fonctions suivantesPremier exo$f(x,y) = -x^2y+\\frac{1}{2}y^2+y$On determine les points critiques: $\\vec{grad}f=\\vec 0$\\(\\Rightarrow\\begin{cases}\\frac{\\partial f}{\\partial x} = -2xy = 0 \\Leftarrow x= 0\\space\\text{ou}\\space y=0\\\\\\frac{\\partial f}{\\partial y} = -x^2+y+1=0\\end{cases}\\) si $x=0\\Rightarrow y+1=0\\Rightarrow y=-1$ si $y=0\\Rightarrow x^2+1\\Rightarrow x=\\pm1$Donc il existe 3 points critiques: $M_1(0,-1)$, $M_2(-1,0)$ et $M_3(1,0)$.La matrice Hessienne:\\(\\nabla^2f(x,y)=\\begin{pmatrix}-2y &amp;amp; -2x\\\\-2x &amp;amp; 1\\end{pmatrix}\\)Nature des points critiques:\\(\\nabla^2f(x,y)=\\begin{pmatrix}2 &amp;amp; 0\\\\0 &amp;amp; 1\\end{pmatrix}\\)$r=2$, $t=1$, $s=0$$s^2-rt=-2\\lt0$ et $r=2\\gt0\\Rightarrow M_1(0,-1)$ est un minimum local.\\(\\nabla^2f(M_2) = \\begin{pmatrix}0 &amp;amp; 2\\\\2&amp;amp;1\\end{pmatrix}\\\\\\)$s^2-rt=4-gt0\\Rightarrow M_2(-1, 0)$ est un point.\\(\\nabla^2f(M_3) = \\begin{pmatrix}0 &amp;amp; -2\\\\-2 &amp;amp; 1\\end{pmatrix}\\\\\\)$s^2-rt=4-gt0\\Rightarrow M_3(1, 0)$ est un point. Deuxieme exo $f(x, y) = (x^2+y^2)e^{-x}$ Troisieme exo $f(x,y)=e^{x+y}-x^2-y$ Quatrieme exo $f(x,y,z) = z^2+xyz^2+xy$ " }, { "title": "CCMP2 : Seance de revisions", "url": "/cours/posts/ccmp2_revisions/", "categories": "S6, tronc commun, CCMP2", "tags": "S6, CCMP2, tronc commun", "date": "2020-07-02 11:00:00 +0200", "snippet": "Lien de la note HackmdRevisions CCMP2Middle End Traduction vers le langage Tree Lineariser le code etape de linearisation: casser lâ€™arborescence faire remonter les expressions et instructions qui sont imbriquees jusquâ€™a la racine on doit conserver la semantique de notre programme si on remonte quelque chose trop haut il peut ecraser dâ€™autres instructions Traduction vers des Block de Bases commence par un label, fini par un JUMP ou CJUMP necessaire car: les microprocesseurs actuels nâ€™ont pas des if then else, ils connaissent les CJUMP, condition, label on tronconne le code si on a un block qui commence sans labe =&amp;gt; on rajoute un label si on a un block qui fini sans jump =&amp;gt; on rajoute un jump permet dâ€™avoir des BB qui peuvent etre â€œbougesâ€ a volonte Back End Finir la linearisation Choisir un microprocesseur et regarder son jeu dâ€™instruction Instruction Selection pour trouver la meilleure instruction en supposant quâ€™on a un nombre de registres illimite Couvrir lâ€™AST par le jeu dâ€™instructions code non generique =&amp;gt; diverge en fonction des microprocesseurs Analyse de vivacite construire un controle flow graph calculer live in et live out (duree de vie de nos variables) deduit le graphe dâ€™interference =&amp;gt; variable a et b vivent simultanement (peuvent pas etre dans le meme registre) Allocation des registres input : AST linearise + graphe dâ€™interference on va travailler sur le graphe dâ€™interference une fois le registre pour une variable trouve on va propager les modification dans lâ€™AST (a = registre 1, b = registre 2, etc.) probleme quand on decremente le nombre de registres mettre des variables dans le meme registre si pas assez de registres: faire un spill, mettre des variables sur la pile 1. Faire une coloration 2. Si on nâ€™y arrive pas: faire un spill 3. Recacul graphe de flow control 4. Reproduire du in et out 5. Reproduire un graphe dâ€™interference PartielOn reprend le code et on regarde toutes les utilisations de a.Une premiere idee serait de faire des utilisations directement avec le stack pointer. Le probleme câ€™est que les architectures actuelles nâ€™ont pas un double acces de memoire" }, { "title": "CCMP1 : Seance de revisions", "url": "/cours/posts/ccmp1_revisions/", "categories": "S6, tronc commun, CCMP1", "tags": "S6, CCMP1, tronc commun", "date": "2020-07-01 11:00:00 +0200", "snippet": "Lien de la note HackmdRappelsCompilateur a 3 etapes front-end middle-end back-endOn utilise des outils: Le scanner prend en entree un fichier (Java, â€¦) but : reconnaitre des mots (jâ€™ai reconnu un entier, variable â€¦) renvoie un token quand reconnais quelque chose token $sujet$, token $verbe$, token complement Le parser marche main dans la main avec le scanner tokens doivent etre connus par le scanner + parser check si le flux de tokens est valide par rapport a une grammaire il faut definir la grammaire: peut etre ambigue TC flashbacks ex : Sujet Verbe Complement Point utilise un arbre de derivation: $\\text{sujet}\\to\\text{verbe}\\to\\text{complement}$ probleme: embarque tout un tas de choses inutiles ex : $Point$ retourne un AST (Abstract Syntax Tree) rpz les differents elements du langage source etre capable de gerer les cas dâ€™ambiguite (conflits shift/reduce) verifier que lâ€™AST soit valide utiliser un visiteur trouver un mecanisme pour automatiser lâ€™AST: visiteur Le binder lier les utilisations aux declarations des variables faire une premiere phase de nettoyage pour etre sur que notre AST est correct si ce nâ€™est pas bon : erreur de typage utiliser des regles dâ€™inferences liage declaration-appel Type-checker verifie si le programme est semantiquement correct parcours lâ€™AST check la coherence des types de variable deduction des types Annale Mars 2018VisiteurPermettent de prendre une hierarchie de classe et dâ€™etre capable de la visiter, cad explorer chacun des elements les un a la suite des autres.Il a egalement un traitement exclusif dâ€™une classe: un visiteur peut visiter les enfants dâ€™un noeud. Il a un traitement exclusif dâ€™une classe.Resoudre le probleme du dispatch statique/dynamique.Appliquer les regles dâ€™inferenceSi je suis capable de montrer que 1 est de type entier je ne fais rien. Si je suis capable de montrer que 4 est de type entier et que je suis capable de montrer que 1 est de type entier alors $4 + 2$ est de type entierJe suis capable de montrer que 3 est de type floatant alors $4 + 2 * 3.0$ est de type floatant.8.0 est de type flottant alors lâ€™expression est de type floatantDifference coerxicion ouvrante/retrecissante coerxicion ouvrante : prendre un type petit et le mettre dans un type plus gros int i = ....float j = i coexircion fermante : sens inverse mais on perd de lâ€™info Reprise sur erreur if (toto;blablabla) Lâ€™utilisateur peut ecrire quelque chose de invalide mais le programme est capable de nous redonner des informations sur la suite du programme. Lâ€™erreur est sur le â€˜;â€™, on se met en mode erreur et on continue a â€œmangerâ€ des tokens jusquâ€™a retrouver un etat stable pour afficher plusieurs erreurs (ex: retrouver la parenthese fermante).Lire et discard les tokens jusquâ€™a retrouver un token valide Construction dans un langage existant AST Java, C, C++ (plus de Tiger) Liaison des nomsQue modifie le ebreakLe ebreak va nous permettre de breaker sur plusieurs niveaux de boucle Le scanner ? oui Le parser? oui ebreak est-il une instruction ou une expression ? instruction car ne retourne pas de valeur Lâ€™AST? ne seras pas demander car toute la promotion ne fait pas Tiger Problemes de typageVerifie quâ€™on ait un entier et non autre chose. Vu que le ebreak prend un argument câ€™est forcement une expression, hors un string est une expression. Il va falloir sâ€™assurer dans le type checker que la valeur prise par le ebreak est un nombre.Lier le ebreak avec un whileOn pourrait lier le ebreak avec le while mais on ne sait pas ce quâ€™il y a la suite car on peut avoir des valeurs que au runtime.DesucragePrendre une construction et la transformer en une autre constructionEvaluation : QCM points negatifs" }, { "title": "Partiels Shannon", "url": "/cours/posts/partiels_shannon/", "categories": "", "tags": "Shannon, partiels", "date": "2020-06-30 00:05:00 +0200", "snippet": " Lundi 6 juillet Mardi 7 juillet Mercredi 8 juillet Jeudi 9 juillet Vendredi 10 juillet PROC10h00-11h30 Â  CCMP110h00-11h30 Â  CCMP210h00-11h30 OPEL14h00-15h30 Â  GPRO14h00-15h30 Â  Â  Lundi 13 juillet Mardi 14 juillet Mercredi 15 juillet Jeudi 16 juillet Vendredi 17 juillet Â  Â  SEDE10h00-11h30 Â  CAMA10h00-11h30 Â  Â  TRSE14h00-14h45 Â  Â  Lundi 20 juillet Mardi 21 juillet Mercredi 22 juillet Jeudi 23 juillet Vendredi 24 juillet ASE110h00-11h30 Â  LOFOLOGI2FMSI_E10h00-11h00 Â  JANGUSOCRASEDE210h00-11h30 ANFI14h00-15h00 Â  RESE14h00-15h00 Â  DRG114h00-15h00 BGEN15h30-16h30 Â  RXANMOB215h30-16h30 Â  Â  " }, { "title": "QUI : Le formalisme quantique du qubit", "url": "/cours/posts/le-formalisme-quantique-du-qubit/", "categories": "S6, electif, QUI", "tags": "S6, QUI, electif", "date": "2020-06-25 20:00:00 +0200", "snippet": "Lien de la note HackmdLa notion dâ€™etat quantiqueEspace des etatsEspace lineaire Les etats purs sont la polarisation en selon $O_x$ et $O_y$Pour decrire la polarisation dâ€™un photon on utilise un espace lineaire, un espace vectoriel de dimension finie $\\mathcal H$ dont les vecteurs de base correspondent aux etats purs.On associe la base ${\\vert x\\rangle, \\vert y\\rangle}$ a $O_x$ et $O_y$. Un etat de polarisation ${\\vert\\Phi\\rangle}$ correspond a un vecteur appartenant a $\\mathcal H$ : \\(\\vert\\Phi\\rangle = \\lambda\\vert x\\rangle + \\mu\\vert y\\rangle\\) On utilise la notation de Dirac.Etat de polarisationIl existe differents types de polarisation pouvant etre representes par un vecteur complexe. $\\mathcal H$ est un espace vectoriel complexe de dimension 2 Cela permet de prendre le conjugue dâ€™un vecteur:\\(\\overline{\\vert\\Phi\\rangle} = \\langle\\Phi\\vert = \\bar\\lambda\\langle x\\vert + \\bar\\mu\\langle y\\vert\\) $\\bar\\lambda, \\bar\\mu$ : conjugues de $\\lambda,\\mu$ Produit scalaire On peut ecrire une amplitude de probabilite comme un produit scalaire:\\(\\langle\\Psi\\vert\\Phi\\rangle = \\biggr(\\bar\\nu\\langle x\\vert + \\bar\\sigma\\langle y\\vert\\biggr) + \\biggr(\\lambda\\vert x\\rangle + \\mu\\vert y\\rangle\\biggr) = \\bar\\nu\\lambda\\langle x\\vert x\\rangle + \\bar\\sigma\\mu\\langle y\\vert y\\rangle\\) $\\vert\\Psi\\rangle = \\nu\\vert x\\rangle + \\sigma\\vert y\\rangle$ Les vecteurs de bases sont orthogonaux entre eux et sont de norme unitaire:\\(\\begin{matrix}\\langle x\\vert x\\rangle = \\langle y\\vert y\\rangle = 1 &amp;amp; \\text{et} &amp;amp; \\langle x\\vert y\\rangle = \\langle y\\vert x\\rangle = 0\\end{matrix}\\) On a donc:\\(\\langle \\Psi\\vert \\Phi\\rangle = \\bar\\nu\\lambda + \\bar\\sigma\\mu = \\overline{\\langle \\Phi\\vert \\Psi\\rangle}\\)Norme La norme au carre dâ€™un vecteur $\\vert\\Phi\\rangle$ sâ€™ecrit comme le produit scalaire de $\\vert\\Psi\\rangle$ avec son conjugue $\\langle\\Phi\\vert$:\\(\\Vert\\Phi\\Vert^2 = \\langle\\Phi\\vert\\Phi\\rangle = \\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2\\)Un etat physique represente par un vecteur doit etre normalise : \\(\\Vert\\Phi\\Vert^2 = \\langle\\Phi\\vert\\Phi\\rangle = \\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2 = 1\\)Espace de Hilbert Un espace de Hilbert $\\mathcal H$ est un espace vectoriel complexe pas forcement de dimension finie muni dâ€™un produit scalaire; introduisant une norme, et complet.Amplitude et probabiliteCalcul dâ€™amplitudeLes etats de polarisation sont rpz par des vecteurs unitaires dans $\\mathcal H$. Un etat de polarisation rectiligne ou lineare selon $\\theta$, note $\\vert\\theta\\rangle$ sâ€™ecrit:\\(\\vert\\theta\\rangle = \\cos\\theta\\vert x\\rangle + \\sin\\theta\\vert y\\rangle\\)On peut calculer lâ€™amplitude de probabilite en utilisant la notation de Dirac pour quâ€™un photo polarise suivant $\\theta$ traverse un polariseur oriente suivant $\\alpha$:\\(\\begin{aligned}\\textbf{a}(\\theta\\to\\alpha) &amp;amp;= \\langle\\alpha\\vert\\theta\\rangle \\\\&amp;amp;= \\biggr(\\cos\\alpha \\langle x\\vert + \\sin\\alpha \\langle y\\vert\\biggr)\\biggr(\\cos\\theta \\vert x\\rangle + \\sin\\theta \\vert y\\rangle\\biggr) \\\\&amp;amp;= \\cos\\alpha\\cos\\theta + \\sin\\alpha\\sin\\theta\\\\&amp;amp;= \\cos(\\theta - \\alpha)\\end{aligned}\\)Probabilite Suite au calcul precedent, la probabilite de traverser lâ€™analyseur (probabilite de mesurer un photon polarisation selon $\\alpha$) est:\\(\\textbf{P}(\\theta\\to\\alpha) = \\cos^2(\\theta - \\alpha) = \\vert\\langle\\alpha\\vert\\theta\\rangle\\vert^2\\)La probabilite de trouver un etat $\\vert\\Phi\\rangle$ dans un autre etat $\\vert\\Psi\\rangle$ sâ€™exprime selon:\\(\\begin{matrix}\\textbf{a}(\\Phi\\to\\Psi) = \\langle\\Psi\\vert\\Phi\\rangle &amp;amp; \\textbf{et} &amp;amp; \\textbf{P}(\\Phi\\to\\Psi) = \\vert\\langle\\Psi\\vert\\Phi\\rangle\\vert^2\\end{matrix}\\)La mesure quantiqueOn reprend le systeme de polariseur/analyseur avec lâ€™analyseur oriente selon $O_x$. Le polariseur ($\\textbf{P}$) va prepare lâ€™etat quantique puis lâ€™analyseur ($\\textbf{A}$) va tester sa polarisation.$\\textbf{P}_s$ est la probabilite de sortie du photon de ($\\textbf{A}$): ($\\textbf{P}$) est selon $O_x$ : $\\textbf{P}_s = 100\\%\\Rightarrow\\text{Resultat : 1}$ ($\\textbf{P}$) est selon $O_y$ : $\\textbf{P}_s = 0\\% \\Rightarrow\\text{Resultat : 0}$ Polarisation arbitraire Supposons que le polariseur est oriente selon la direction $\\theta$ ou sa direction orthogonale $\\theta_{\\bot}$, on peut construire un systeme orthonorme de vecteur de base ${\\vert\\theta\\rangle, \\vert\\theta_{\\bot}\\rangle}$ a partir de la base ${\\vert x\\rangle, \\vert y\\rangle}$:\\(\\begin{matrix}\\vert\\theta\\rangle = \\cos\\theta\\vert x\\rangle + \\sin\\theta\\vert y\\rangle &amp;amp; \\textbf{et} &amp;amp; \\vert\\theta_{\\bot}\\rangle = -\\sin\\theta\\vert x\\rangle + \\cos\\theta\\vert y\\rangle\\end{matrix}\\)Le polariseur prepare le photon dans lâ€™etat $\\vert\\theta\\rangle$, on a donc:\\(\\textbf{P}_s = \\cos^2\\theta\\) Apres le passage du photon dans lâ€™analyseur, son etat $\\vert\\theta\\rangle$ devient $\\vert x\\rangle$. La mesure modifie (ou perturbe) lâ€™etat de polarisation.Difference entre mesure classique et quantiqueIl y a une difference de principe entre la mesure en physique classique et la mesure en physique quantique: Cas classique: la quantite physique preexiste a la mesure Si une voiture est contolee a $180km.h^{-1}$, cette vitesse preexistait avant la mesure Cas quantique: lâ€™etat de polarisation $\\vert\\theta\\rangle$ nâ€™existait pas avant dâ€™etre mesure. Si on prend lâ€™exemple de la voiture dans une version quantique, son etat de vitesse serait donne par la superposition dâ€™un etat a $120km.h^{-1}$ et dâ€™un autre a $180km.h^{-1}$.La notion dâ€™operateurComment un etat quantique peut se transformer sous lâ€™effet dâ€™operateurs de la forme de matrices de dimensions 2?PrincipesOn peut formuler 2 principes a partir de lâ€™analyse de la structure mathematique: Lâ€™etat physique dâ€™un systeme quantique est rpz par un vecteur $\\vert\\Phi\\rangle$ appartenant a $\\mathcal H$. $\\vert\\Phi\\rangle$ est unitaire ($\\Vert\\Phi\\Vert^2 = 1$) et est un vecteur dâ€™etat du systeme quantique. Soient $\\vert\\Psi\\rangle$ et $\\vert\\Phi\\rangle$ 2 etats physiques. Lâ€™amplitude de probabilite de trouver $Phi$ dans $Psi$ est $\\textbf{a}(\\Phi\\to\\Psi) = \\langle\\Phi\\vert\\Psi\\rangle$. La probabilite pour $\\Phi$ de reussir le test $\\Psi$ est:\\(\\textbf{P}(\\Phi\\to\\Psi)=\\vert a(\\Phi\\to\\Psi)\\vert^2 = \\vert\\langle\\Psi\\vert\\Phi\\rangle\\vert^2\\) Pour realiser le test on doit preparer le systeme dans lâ€™etat $\\vert\\Phi\\rangle$ puis on va tester le systeme qui va le mettre dans lâ€™etat $\\vert\\Psi\\rangle$.Operateur de projectionMesure et projectionDans le test precedent on a fait une projection orthognale sur $\\vert\\Psi\\rangle$" }, { "title": "QUI : La physique du qubit", "url": "/cours/posts/qui-la-physique-du-qubit/", "categories": "S6, electif, QUI", "tags": "S6, QUI, electif", "date": "2020-06-25 19:30:00 +0200", "snippet": "Lien de la note HackmdGeneralitesInformatique quantique Lâ€™informatique quantique est lâ€™utilisation des lois et proprietes de la mecanique quantique pour encoder et tranposter de lâ€™information.Mecanique quantique La mecanique quantique est une theorie physique pour decrire un systeme dont la taille est celle dâ€™un atome ($10^{-10}m$) ou moindre. Tout systeme est ultimement un objet quantique. La mecanique quantique doit permettre de retrouver les lois classiques.Qubits Qubits (Quantum bits) : changer les proprietes quantiques individuelles dâ€™une particule telle que son energie, sa polarisation, son â€œspinâ€ pour encoder de lâ€™information. Câ€™est la plus petite quantite dâ€™information que lâ€™on peut transporter ou stocker dans un systeme quantique.Loi de Moore Le nombre de transistors garves sur une puce double tous les 18 mois environ.Dâ€™apres cette loi, les dimensions dâ€™un puce seront inferieures a 10 nm apres 2020. A cette echelle les proprietes quantiques des atomes et electrons vont devenir importantes.Avantages et inconvenients du calcul quantique Superposition Un bit classique peut seulement prendre les valeurs 0 et 1 Un qubit peut prendre les valeurs 0 et 1 et toutes celles intermediaires Un qubit est constitue dâ€™une superposition lineaire des etats quantiques correspondant aux bits 0 et 1 cela decuple les capacites de calcul, le cryptage et de transport de lâ€™information Intrication 2 objets quantiques intriques bien que separes pas une distance arbitraire sont une seule et meme entite on ne peut pas comprendre cette entite comme la reunion de 2 objets independants Parallelisme mise en oeuvre des proprietes de superposition et dâ€™intrication permet a un ordinateur quantique de realiser plus dâ€™operations quâ€™un ordinateur classique algoritmes quantiques algorithme de Shor algorithme de Grover Decoherence : Obstacle majeur sensibilite a lâ€™environnement entraine une perte de relation de phase entre 2 etats quantiques relation necessaire a la realisation dâ€™un calcul quantique interaction des qubits avec lâ€™environnement qui brouille les superpositions lineaires Un ordinateur quantique fiable doit etre parfaitement isole. Des codes dâ€™erreur ont ete creer pour palier aux defauts dâ€™isolation.Premier modele physique dâ€™un qubit : le photon La polarisation du photon sers a encoder de maniere quantique un qubit.PolarisationLa polarisation a ete mise en evidence avec un cristal birefringent, c.a.d. qui decompose la lumiere en deux rayons polarises dans des directions perpendiculaire alors que la lumiere incidente est polarisee. Les vibrations lumineuses ont un caractere vectoriel.Une onde transverse Pour une orientation convenable, on observera une extinction dâ€™un des deux rayons. Câ€™est une vibration transverse (orthogonale) a la direction de propagation. Une onde scalaire se propageant au cours du temps selon la direction $O_z$ est decrite par:\\(u(z,t) = u_o\\cos(\\omega t - kz)\\) $\\omega = ck = \\frac{2\\pi}{T} = 2\\pi f$ : frequence angulaire de la vibration ($s^{-1}$) $c$ : vitesse de la lumiere ($m.s^{-1}$) On se place dans un plan fixe en $z = 0$ : \\(u(z = 0, t) = u(t) = u_0\\cos(\\omega t)\\) Vecteur polarisation Le modele de lâ€™onde scalaire peut se generaliser aux 3 dimensions pour representer le vecteur champ electrique qui caracterise une onde lumineuse:\\(\\vec E = \\vec E_0\\cos(\\omega t)\\) Lâ€™orientation de ce champ est la polarisation de la lumiere.La lumiere est percue comme un champ electromagnetique dont la composante electrique est orthogonale a sa direction de propagation. Pour decire lâ€™orientation du champ electrique on a besoin dâ€™un systeme dâ€™axe $O_x$ et $O_y$. En posant $\\Vert \\vec E_0 \\Vert = E_0$ : \\(\\vec E = \\begin{pmatrix} E_x \\cr E_y \\end{pmatrix} = E_x \\vec u_x + E_y \\vec u_y \\Rightarrow \\vec E = E_o\\cos \\theta \\cos(\\omega t)\\vec u_x + E_0 \\sin \\theta\\cos(\\omega t)\\vec u_y\\) Lâ€™angle $\\theta$ caracterise lâ€™orientation de $\\vec E$ dans $xOy$, c.a.d. la polarisation Lâ€™intensite de lâ€™onde lumineuse est proportionnelle au carre du champ electrique\\(I \\propto E_0^2\\) On introduit un vecteur unitaire, note $\\hat{p}$ et appartenant au plan $xOy$ tel que:\\(\\hat{p} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta\\end{pmatrix} \\Rightarrow \\vec E = E_0\\cos(\\omega t)\\hat{p}\\) Si $\\theta = 0$ : polarisation selon $O_x (\\hat{p} = \\vec u_x)$ Si $\\theta = \\pi / 2$ : polarisation selon $O_y (\\hat{p} = \\vec u_y)$ Changement et mesure de la polarisation de la lumierePolariseur et analyseurOn utilise un systeme a 2 polarisateurs consecutifs pour changer et mesurer lâ€™orientation du champ $\\vec E$: polariseur â€œdâ€™entreeâ€ : oriente la polarisation de la lumiere incidente selon un angle $\\theta$ par rappor a $O_x$ polariseur â€œde sortieâ€ (lâ€™analyseur) : possede un axe de polarisation faisant un angle $\\alpha$ avec $Ox$ On utilise un vecteur unitaire $\\hat{n}$ pour decrire la polarisation de lâ€™analyseur\\(\\hat{n} = \\cos\\alpha\\vec u_x + \\sin\\alpha\\vec u_y = \\begin{pmatrix}\\cos\\alpha\\\\ \\sin\\alpha\\end{pmatrix}\\)Loi de Malus On doit determiner lâ€™orientation du champ electrique $\\vec Eâ€™$ pour mesurer la polarisation a la sortie de lâ€™analyseur.On projete $\\vec E$ oriente selon $\\hat{p}$ dans la direction $\\hat{n}$\\(\\begin{aligned}\\vec E &amp;amp;= (\\vec E \\cdot\\hat{n})\\hat{n} \\\\&amp;amp;= E_0\\cos(\\omega t)(\\hat{p}\\cdot\\hat{n})\\hat{n} \\\\&amp;amp;= E_0\\cos(\\omega t)(\\cos\\theta\\cos\\alpha + \\sin\\theta\\sin\\alpha)\\hat{n}\\\\\\vec E &amp;amp;= E_0\\cos(\\omega t)\\cos(\\theta - \\alpha)\\hat{n}\\end{aligned}\\) La loi de Malus est une loi classique pour lâ€™intensite a la sortie de lâ€™analyser:\\(I&#39; = I\\cos^2(\\alpha-\\theta)\\)Type de polarisation Pour une polarisation lineaire, les deux composantes de $\\vec E$ ont la meme dependence par r Les composantes de $\\vec E$ se notent avec une phase specifique a chacune qui peut etre differentes : \\(\\begin{cases}E_x = E_0\\cos\\theta\\cos(\\omega t - \\delta_x) \\\\E_y = E_0\\cos\\theta\\cos(\\omega t - \\delta_y)\\end{cases}\\) En fonction de la differnce de phase $\\delta = \\delta_x - \\delta_y$: Si $\\delta = 0$ ou $\\delta = \\pm\\pi$ : polarisation rectiligne $E_x$ et $E_y$ oscillent dans un plan fixe faisant un angle $\\theta$ avec $Ox$ Si $\\theta = \\pm\\frac{\\pi}{2}$ : polarisation circulaire lâ€™extremite du vecteur $\\vec E$ decrit un cercle au cours du temps Si $\\theta \\not = p\\frac{\\pi}{2}$ avec $p \\in \\mathbb{Z}$ : polarisation elliptique pas de relation particuliere entre les phases des composantes lâ€™extremite de $\\vec E$ decrit une ellipse On ne peut pas mesurer la phase individuelle dâ€™une composante $\\vec E$, seule $\\delta$ est accessible. On peut imposer $\\delta_x = 0$ en redefinissant lâ€™origine des temps. Le champ electrique $\\vec E$ peut aussi sâ€™ecrire : \\(\\vec E = E_0\\textbf{Re}\\biggr[e^{-i\\omega t}\\begin{pmatrix}\\lambda \\\\ \\mu\\end{pmatrix}\\biggr]\\space \\text{avec} \\begin{pmatrix}\\mu \\\\ \\lambda\\end{pmatrix} = \\begin{pmatrix}\\cos\\theta e^{i\\delta_x} \\\\ \\sin\\theta e^{i\\delta_y}\\end{pmatrix}\\) $\\begin{pmatrix}\\mu \\ \\lambda\\end{pmatrix}$ : polarisation $\\mu,\\lambda\\in \\mathbb{C}$ $\\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2 = 1$ Approche quantique de la polarisationEn reduisant lâ€™intensite lumineuse, on peut etudier la polarisation rectiligne individuelle de chaque photon constituant la lumiere. La taille typique dâ€™un photon est donnee par sa longueur dâ€™onde de lâ€™ordre du nanometre.On detecte $N$ photons, si $N\\to\\infty$ on doit retrouver le comportement ondulatoire classique de la lumiere.On prend une lame birefringente avec des photons incidents dont la polarisation rectiligne fait un angle $\\theta$ avec $O_x$.Non simultaneiteLe faisceau est separe en des faisceaux dâ€™intensite: $I\\cos^2\\theta$ polarise selon $O_x$ $I\\sin^2\\theta$ polarise selon $O_y$ Un photon est detecte soit en $D_x$ soit en $D_y$ Pour mesurer la probabilite de detection dâ€™un photon pour chaque detecteur:\\(\\textbf{P}_x = \\cos^2\\theta \\space \\textbf{et}\\space \\textbf{P}_y = \\sin^2\\theta\\)Cette experience met en valeur lâ€™aspect corpulaire de la lumiere.Recouvrement de la loi classique Si $N$ photons sont envoyes alors le nombre de photons detectes par chaque detecteur est :\\(D_x:N_x\\simeq N\\cos^2\\theta \\space \\textbf{et} \\space D_y:N_y\\simeq N\\sin^2\\theta\\)On retrouve la loi de Malus lorsque $N\\to\\infty$.Nature probabilisteIl est impossible de prevoir le chemin dâ€™un photon, ce qui est en opposition avec le determinisme de la mecanique classique.Recombinaison de faisceauOn cherche a recombiner deux faisceaux, et retrouver la loi de Malus malgre la differentiation de chemin, par ce dispositif:On sâ€™attend a une intensite de sortie proporionelle a $\\textbf{P}_x$.Le photons a 2 chemins possibles : (E) : il traverse le polariseur avec une probabilite de $\\cos^2\\theta$, puis lâ€™analyseur avec une probabilite de $\\cos^2\\theta$ la probabilite totale est $\\cos^2\\theta\\cos^2\\alpha$ (O) : il traverse le polariseur avec une probabilite de $\\sin^2\\theta$, puis lâ€™analyseur avec une probabilite de $\\sin^2\\theta$ la probabilite totale est $\\sin^2\\theta\\sin^2\\alpha$ La probabilite totale est : \\(\\textbf{P}_{tot} = \\cos^2\\theta\\cos^2\\alpha + \\sin^2\\theta\\sin^2\\alpha \\not = \\cos^2(\\theta - \\alpha)\\)Le raisonnement est FAUX.Amplitude de probabilite Pour retrouver la loi de Malus, il faut raisonner a partir de la notion dâ€™amplitude de probabilite pour chaque chemin. Le module au carre de cette amplitude donne la probabilite: \\(\\begin{matrix}\\textbf{a}(\\theta\\to x) = \\cos \\theta &amp;amp; \\textbf{a}(\\alpha\\to x) = \\cos \\alpha\\\\\\textbf{a}(\\theta\\to y) = \\sin \\theta &amp;amp; \\textbf{a}(\\alpha\\to y) = \\sin \\alpha\\end{matrix}\\) $\\textbf{a}(\\theta\\to x)$ : amplitude assiociee a la probabilite de detecter un photon polarise selon $O_x$ Lâ€™amplitude totale de sortie sâ€™obtient en superposant les amplitudes pour des chemins indiscernables:\\(\\textbf{P}_{tot} = \\vert\\textbf{a}_{tot}^2\\vert = \\cos^2(\\theta - \\alpha)\\)Le raisonnement est BON.DiscernabiliteUn photon ne fait aucune distinction entre les chemins (E) et (O), sinon la probabilite serait $\\textbf{P}_{tot} = \\cos^2\\theta\\cos^2\\alpha + \\sin^2\\theta\\sin^2\\alpha \\not = \\cos^2(\\theta - \\alpha)$. Câ€™est lâ€™indiscernabilite des chemins possibles.InterpretationOn a 2 interpretations possibles: Le photon emprunte 2 trajets a la fois la question â€œQuel trajet ?â€ nâ€™a aucun sens La deuxieme interpretation est preferable car il est impossiblde de differencier les chemins experimentalement. La notion de trajectoire nâ€™existe pas en physique quantique. Elle est remplacee par la notion de probabilite de presence. Un photon ne peut prendre physiquement quâ€™un seul des 2 chemins.Application : La cryptographie quantiqueOn attribue arbitrairement : Valeur 1 : photon polarise par $O_x$ Valeur 0 : photon polarise par $O_y$Convention de communicationSi Alice (A) et Bob (B) echangent des informations sous forme quantique alors cela prend la forme dâ€™une suite de photons polarises : \\(\\text{y y x y x y y y x ...}\\)Bob analyse la polarisation de lâ€™information recue a lâ€™aide dâ€™une lame birefringente et en deduis le message de Alice\\(\\text{0 0 1 0 1 0 0 0 1 ...}\\)Possibilite dâ€™ecoutePour intercepter le message, Eve va devoir mesurer la polarisation quantique dâ€™un des photons, elle a $50%$ de chance de se tromper, puis doit renvoyer le photon a Alice et a $50%$ de chance de se tromper. Si leur message a ete espionne, Alice et Bob peuvent constater une plu grande quantite dâ€™erreurs.Protection de la cle publiqueProtection de la cle publique La cryptographie repose sur une cle de chiffrage (cle publique) connue seulement de lâ€™expediteur et du destinataire.Le temps de calcul est le principal obstacle pour dechiffrer le messageCryptographie quantiqueIl sâ€™agit de proteger la cle de chiffrage, tel que sâ€™assure que la transmission dâ€™une cle nâ€™a pas ete espionee (distribution quantique dâ€™une cle).Protocole BB84Choix de polarisation On suppose quâ€™Alice peut envoyer 4 types de photons avec des polarisations rectilignes differentes: On peut regrouyper les polarisations en 2 ensembles differents:TransmissionAlice choisit au hasard une des deux bases pour emettre / recevoir des photonsCes bases sont constituees par des systemes similaires a la lame birefringente.Quand Bob recoit un photon, il choisit parmis ce bases aleatoirement. Il va ensuite analyser la polarisation du photon recu.ReceptionParfois la base de reception de Bob $\\mathfrak B_B$ nâ€™est pas â€œaligneeâ€ avec la polarisation du photon recu, lâ€™etat de polarisation est projete sur lâ€™une des 2 directions de $\\mathfrak B_B$.ComparaisonAlice rend publique sa base dâ€™emission $\\mathfrak B_A$ pour indiquer a Bob les photons recus dont la polarisation nâ€™etait pas alignee. Si $\\mathfrak B_B \\not = \\mathfrak B_A$ il y a eu une projection, dans ce cas le photon recu est rejete et Bob conserve que les photons dont la $\\mathfrak B_B$ etait en accord avec $\\mathfrak B_A$. Dans le tableau la cle conservee ou clee reconciliee est $\\text{0 1 0 1 â€¦}$InterceptionUne personne souhaitant intercepter le message (Eve) doit recevoir dâ€™Alice puis renvoyer a Bob chaque photon intercepte. 2 cas se presentent : La base $\\mathfrak B_E$ de Eve est alignee Eve a 0% de chances de se tromper La base $\\mathfrak B_E$ de Eve est non-alignee Eve a 50% de chances de se tromper Non-clonageIl est impossible pour Eve de proceder differemment, elle est obligee de projeter. Theoreme de non-clonage : Il est impossible dâ€™interagir avec un â€œetat quantiqueâ€ sans le modifier, il ne peut pas etre clone. Alice et Bob peuvent detecter un eventuel espion avec une probabilite de $1-\\frac{3}{4}^n$" }, { "title": "SUDE : Last session", "url": "/cours/posts/sude_last_session/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-06-17 10:00:00 +0200", "snippet": "Lien de la note HackmdAssessment To upload before the presentation tomorrow We can do a video, just make sure itâ€™s available in Teams The difficult part is to find green it actions If people canâ€™t speak during the presentation because of thechnical issues, no problem : others can speak or video Donâ€™t mix up the Green IT with corporate obligations. We should talk about the actions taken to reduce the impact on the environment.There used to be a club called Club Green IT, good lead for a subject.SDG Put the SDG at the end of the presentation We donâ€™t have to develop them, just do orally the presentation on the first part One sentence per SDG is enough We are not asking for a report, just put bullet points GHG emissionsWhat is the point of computing GHG emitted by a company ? To prepare an action plan to reduce them.Metal in IT China owns most of the rare earth production, they can choose to not provide it anymore.We have to be careful about metals in IT, some resources are low and the price may rise.Average computer lifespan 1985 : 10 to 15 years (average lifespan of 10 years), easy to upgrade, fix, reuse and recycle 2007 : lifespan dropped to 2,5 years launch of Windows Vista =&amp;gt; most companies had to change equipment because the hardware couldnâ€™t support the new OS versions same problem for MacOS perfect example on how they did not consider that everyone had good enough hardware 2015 : 3 to 15 years (average lifespan of 5 years), impossible to upgrade, fix, reuse or recycleImpacts on the life cycleWhat are the impacts at each stage of the life cycle ?ProductionWhat are the environmental impacts of the components ? 40 chemical components in a smartphone, including rare earth. Part of our electronic equipment are mined in unsanitary conditions and uses child labor =&amp;gt; confilct minerals pollution high production ratesUse Devices with various energy efficiencyEnd of life 1,68 millions tons of electronic waste put on the market in 2015 166 times the Eiffel Towerâ€™s weight 75% of electronical waste is out of the official radar sent to illegal landfills (Ghana, Nigeria, China, India, Pakistan, Bangladesh, South America) Production has the biggest impact on the environment.VocabularyGreen IT Continous improvement process aiming at reducing ICT ecological, economical and social footprint.IT For Greem The approach that uses digital with th objective to reduce environmental impact.Sustainable design for digital service Approach allowing to integrate environmental, economical and social aspects in the design of a digital service.What is Eco Design ? Eco-design is an innovative approach.Stages of the life cycle Raw materials Focus on renewable/recycled materials Volume/weight reduction Manufacturing Choice of cleaner technologies Reduction of the number of parts and materials Reduction in assembly operations Reduction in production waste and emissions Distribution Eco-design and packaging Reduction of the weight / volume ratio Logistics optimization Sales Consideration of the eco-design of POS advertising and other sales support Eco-design of shops Usage Increase durability (reliability, repair, modularity, etc.) Promotes updates (recharge, etc.) Switch from product to service Shared use og the product End of life Separable materials Material recovery Component recovery Product recovery (reuse) Digital AccessibilityExample : Color BlindnessAbout 8% of men and 0.5% of women worldwide are red-green colorblind. Make sure to use colors that everyone can see.Green IT Actions" }, { "title": "Reunion APP ERO", "url": "/cours/posts/appero/", "categories": "S6, tronc commun, APP ERO", "tags": "S6, APP ERO", "date": "2020-06-10 10:00:00 +0200", "snippet": "Lien de la note HackmdDrone: parcourir les rues au moins une fois graphe non orientÃ©DÃ©neigeuses : reprend le graphe en orientÃ© 2 arcs : une fois dans un sens pour dÃ©neiger dâ€™un cÃ´tÃ© et la deuxiÃ¨me fois pour lâ€™autre cÃ´tÃ© une rue peut etre Ã  sens uniquerÃ©seau pÃ©destre et routier : on ne sâ€™occupe que des deneigeuses qui dÃ©neigent la route, pas les trottoirsProblÃ©matique de graphe euleriens et non eulerien Si non-eulerien : degrÃ©s impairs rendre le graphe eulerien de faÃ§on optimale =&amp;gt; poids minimalQuels sont les paramÃ¨tres attendus ? solve : option orientÃ©e et non orientÃ©e orientÃ©e : dÃ©neigeuse non-orientÃ© : drone PrÃ©sentation vidÃ©oPlutÃ´t libre, contrainte de durÃ©e (10 min)MoulinetageExpliquer dans le readme comment executerExpliquer nos choix, quelles sont les limitesQuâ€™est-ce quâ€™on regardeLa distance entre 2 sommets distincts : Floyd-Warshall et non DjisktraDans le cas non-oriente : je prend lâ€™arrete qui me coute le moins cher =&amp;gt; couplage parfaitNotationOuvrir tout les rendus, on explique comment lâ€™executer et Bashar le fait tourner sur un graphePouvoir iterer sur cles + valeurs2 solves: solve_dummy : utiliser les librairies pour faire un truc opti solve normal : celui qui sera utilise" }, { "title": "Journee de presentation de stages", "url": "/cours/posts/stage/", "categories": "S6, stage", "tags": "S6, stage", "date": "2020-06-09 10:00:00 +0200", "snippet": "Lien de la note Hackmd adista : ogrosjeanne@adista.fr python typescripts Boston consulting group : freier.niels@bcg.com Pas de descriptif exact de stage profile data science bon en python (possible si bon java / scalar / c++) stage a Paris 4/5 stagiaires Datakeen : gael@datakeen.co Machine learning engineer JS, Python, Docker, Kubernetes Grande arche de la defense Factonics Data science devops AWS, PostgreSQL 19e Paris Make me reach : axelm@perion.com AWS, NodeJS, TypeScript Dans Paris en face du grand Rex Mindo : dan.elgrabli@mindo.app, sebastien.lepy@mindo.app Brainsonic : tutur@brainsonic.com CB+ : Front-end Back end Fullstack Veesion Front end : Python, GCP, AWS, Azure, Docker, Ansible, Jenkins Backend : Python, Django, concept dâ€™APIs, Docker, Ansible Jenkins 3IE Advance QCM " }, { "title": "SUDE : Les gazs a effet de serre", "url": "/cours/posts/sude_gaz_serre/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdIntroduction to GreenHouse Gases (GHG) emission calculationWhat are the main green house gases? Carbone Dioxyde Methane N2O Methodologies to compute GHG emissions GHG protocol (US methodology) ISO 14064-1 Bilan Carbone (french methodology)Designing a carbon footprint Organizational boundaries In a control approach you account for all GHG emissions from facilities over which you have a financial or operational control In a equality share approach you would account for GHG emissions in proportion to the percentage ownership over the facility Base year have to set a base year so you can follow the emission trend Operational boundaries have to decide which emissions to report Direct emissions (scope 1) and energy indirect emissions (scope 2) are mandatory Reporting of other indirect emissions (scope 3) is not Emission scopes Scope 1 = Direct energy sources Any source activity from an asset controlled by the organization Ex : electricity to light the office Scope 2 = Indirect energy sources Any source activity not controlled by the organization that generates energy used by the organization Ex : a car used by an employee Scope 3 = Other indirect sources Any non-energy related sources not controlled by the organization that impacts the organization Monitoring Emissions Data collection Data processing Organisation project management people involved etc. Identify sources Activity that impacts organizationâ€™s operation and results in the emission of greenhouse gases Examples Natural gas heating Water use Business travel Air conditionning Waste sent to municipal landfillâ€¦ Collect data and define units to use Natural gas heating m3 Gj ft3 Ccf Electricity kWh Gj Emission factors An emission factor is a ratio corresponding to the amount of greenhouse gases emitted as a result of a given unit of activityExample - Natural Gas GWP : a ration denoting the effect of a quantity of a greenhouse gas on climate change with an equal quantity of carbon dioxyde usually expressed over a 100 year period Carbon dioxyde always has a GWP of 1 Result are expressed in Carbon Dioxyde equivalent (g/kg/t C02e) Natural Gas Emission GWP t C02e C02/m3 ~27t 1 27 CH4/m3 0.0005t 25 0.0125 N20/m3 0.0005t 298 0.149 Implement strategies / actions to reduce Computing is necessary the most important being to understand what to reduce and which actions are neededGreenIt or Sustainable ICT We cannot solve our problems with the same thinking we used when we created them â€“ Albert EinsteinGeneral statemets - Shift Project 2018 Digital consumption as forecast is not sustainable Energy intensity of digital industry is in continuous growth No digital impact foreseen on worldwide productivity nor growth It is still possible to move ot a more sober digital worldDigital energy consumptionIn France : Digital Energy Consumption represents $12\\%$ of total energy consumption.GHG emissions : $2,5\\%$ in 2013 to $4\\%$ in 2020Example : Iphone" }, { "title": "SOCRA : Cours du 4 juin", "url": "/cours/posts/socra/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdIT in companySoftware needs Software Apache Monitoring Linux NetworkClassic segregation itâ€™s not what you think| IT-Development | IT-Production | IT-System ||â€”â€“ | â€”â€”- | â€”â€”â€” || Develop software | Manage software in production | Manage hardware and OS+ || | Assist users | Handles DPR || Paid for new features | Paid for uptime | Paid for stability, security |Assume failures No software is guaranteed without bugs.User error investigation Call support (Niveau 1) Use standard procedures (N1) Check logs (N2) Check configuration (N2) Call development : error in software (N3)Help them using Error messages Cristal clear logsExamples : LogsCreate new wishError returned With that kind of log, impossible to know what happened.2020-03-31 09:48:26.1539|INFO|0HLULB1T307F0|WishController|Create : New wish for #433 by #ce4ed122-3cfd-47cd-a8ea-9d0b9d4c55f4 : My Mobility2020-03-31 09:48:26.1575|WARN|0HLULB1T307F0|WishController|HasOneNotNull - Property not found : LinkedID2020-03-31 09:48:26.1577|WARN|0HLULB1T307F0|WishController|Error returned form HasOneNotNull : Property not found : LinkedId With this kind of log, we see the error right away.Logs Use different levels : Trace, Debug, Info, Warning, Error, Fatal Use and existing framework There is never too much logsFrom dev to PRODCI/CD Quesaco Continous : forming an unbroken whole; without interruption integration : the coodination of processes delivery : delivering letters, packagesâ€¦. babiesâ€¦ deployement : bringing resources into effective action CI process goalValidate code at each steps, for each developersConfirm software stability (a minimum)Create a delivery workflowAvoid human interactionHow to go live Take a (development) ticket Develop using BDD, TDD (and pair programming) Push on VCS Deploy on a test environment Test your software Everything is OK, then deploy on production Eventually calculate metrics like coverage, technical debtâ€¦A softwareDelivery process Get sources Add version Build Run tests Publish componentsEnvironmentsDEV, PROD, PRE-PROD, UATCreate packages Get sources Add version Build Run tests Create one package for each componentsCI/DC Tools Shell script! Jenkins Travis CI Bamboo Teamcity Monolyth AKA Single-tiered Self-contained IndependantMulti-tier Layer separation Flexible3-tier| Presentation ||â€“|| Logic || Data |Example| Console : Get report||â€“|| Business Logic : list of all sales and aggregate them || Data : MySQL : access salesâ€™ store |SOA : Service Oriented Architecture A service : represents a business activity is self contained is a black box for its consumers may consist of other underlying services CommunicationLocal : IPC|File|Shared Memory||â€”-|â€”-||Local - Bidirectional, one process at time for writing|Local - Bidirectional, one process at time for writing| Signal Socket Local - Unidirectional, not used for data Local or netowrk - bidirectional, synchrone Pipe Message queue Local - Unidirectional Local or network - bidirectional, asynchrone Problem.. What if a I send a message and the service is down ?How to send a message which can be handled by multiples service, but only processed by one ?How to handle a client deconnection ? A master ?Message queueing (aka MQ) Like a mailbox Increase TCP/IP features: Durability - purging : is the message saved ? What is TTL ? Delivery policy : should the message be delivered once more ? Security : which applications should have the message ? Notifications : the publisher can be notified when message is received Implementations : Apache ActiveMQ, OMQ, RabbitMQ, JMS, â€¦APICRUDREST CRUD operations Stateless On HTTP/S VERB Request has body Response has body Safe Indempotent Cacheable Â  Â  GET Optional YES YES YES YES Â  POST YES YES NO NO YES Â  PUT YES YES NO YES NO Â  DELETE NO NO NO YES NO /api/users|GET|POST|PUT|DELETE||â€”|â€”-|â€”|â€”â€”||Retrieve all users|Create a new user|N/A|Delete all users|/api/users/{id}|GET|POST|PUT|DELETE||â€”|â€”-|â€”|â€”â€”||Retrieve one user|Create a new user|Update|Delete one user|OpenData - OpenAPI Free to use, reuse and redistribute Lots of companies : GAFAM, RATP, gouvernementsâ€¦ Lots of domains : genetic, chemical, geographic, justiceâ€¦ Swagger oh no itâ€™s 2010 againAn SOA SoftwareTo manage more users : But there is still a problem..The current state problem What did my user?How can I guaranty it?Can I prove it? So letâ€™s think events!Events afterall|Item added||â€”â€”||Item removed||Payment received||Order shipped| Item added : book Item added : DVD Item removed : DVD Payment received Order shippedEvents sourcing Command : user intention =&amp;gt; AddItemToCart Event : happened in the past =&amp;gt; ItemAddedToCart Immutable Event storeCQRSCommand and Query Responsibility SegregationCloudHow to run ? Software Libraries - dependencies Operating system HardwareI am a userI USE SERVICES!!!!Iâ€™m a developer Why should I care about hardware failure ? Infrastructure as a Service Why must I update the operating system ? Platform as a service Is the (right) JVM installed ? Platform as a service I know nothing about SQL Server, I just want a database ! Platform as a service / Software as a Service ITO are against me !IaaS to SaaSMe or nothing|Entreprise|Cloud provider||â€”â€”â€”-|â€”â€”â€”â€”â€“||On premise|Cloud|Entreprise &amp;amp; cloud provider : hybridLambda functions One endpoint, one function Focus on objective Access defined resources Call other functions if" }, { "title": "ASE1 : Typical exam", "url": "/cours/posts/ase1-typical-exam/", "categories": "S6, tronc commun, ASE1", "tags": "S6, ASE1, tronc commun", "date": "2020-06-02 15:00:00 +0200", "snippet": "Lien de la note HackmdFormatFichier excel deja pret ou on devra mettre nom + prenom + uid. Format CSV fr, separation des champs avec ,Jouons avec RUID&amp;lt;-20254 #UID de l&#39;etudiantX&amp;lt;-runif(1000) #Loi uniforme pour une variable X et on en prend milleplot(X) #Affiche XZ&amp;lt;-1:1000 #Vecteur Zplot(Z)alpha&amp;lt;-UID/23000K&amp;lt;-UID/7500alpha0.8806087K2.700533Ces nombres sont differents pour tout le mondeV&amp;lt;-K*X^alphaW&amp;lt;-K*Z^alphasort(V) #Loi uniforme de Vsort(W) #Loi uniforme de WLe vecteur W a ete construit par vous, il depend de votre numero. Vous devez etre capable de decrire W.boxplot(W) #Ne sera pa demande au partielsummary(W) #Decrit des valeurs utilesMin 1st Qu. Median Mean 3rd Qu. Max2.7 350.1 643.5 630.1 919.1 1193.8 sd(W) #Ecart typevar(W) #VarianceOn aura la commande dans lâ€™enonce.cor(V, W) #Correlation entre V et WK&amp;lt;-2.5alpha&amp;lt;-2.1W&amp;lt;-K*Y^alphasummary(W)Jouez avec mean, sd, boxplot, summary, var, cov, cor.X&amp;lt;-1:100Y&amp;lt;-X^2plot(X, Y)Le coefficient de correlation de X et Y au pif ?Plutot proche de 1 car la courbe ressemble a une droite. :snail:cor(X, Y)0.96Intervalle de confianceOn va sâ€™interesser au poids dâ€™un nouveau-ne. :snail: On en a pese 49 On a trouve une moyenne de 3.6 KgsJe sais que lâ€™ecart-type est de 0.5 Kg. Je souhaite avoir un intervalle de confiance a $95\\%$ du poids moyen.Derniere hypothese: le poids suit une loi normale.Il y a 2 facons de faire: Rappeler le raisonnement Apprendre la formule du coursRappelons le raisonnementEn general â€œObservation = moyen + ecart = moyenne + k * ecart typeâ€ sauf quâ€™on doit faire une deduction sur la moyenne.Estimation de moyenne de type moyenne observee +- k * ecart type. Quand on connait lâ€™ecart type K depend de la distribution de la loi normale.x.barre&amp;lt;-3.6sigma&amp;lt;-0.5n&amp;lt;-49Formule du coursUn intervalle de confiance a $95\\%$, $\\alpha = 5\\%$, $\\frac{\\alpha}{2} = 2.5\\%$ et $1-\\frac{\\alpha}{2} = 0.975$On utilise qnormu&amp;lt;-qnorm(0.975)u1.959964mu.inferieur&amp;lt;-x.barre-u*sigma0/sqrt(n) #Formule du coursmu.superieur&amp;lt;-x.barre+u*sigma0/sqrt(n) Lâ€™intervalle de confiance a $95\\%$ est $[3.46, 3.74]$.On a mesure un ecart type de 0.53 Kgs. Quel est lâ€™intervalle de confiance?On a mesure une moyenne de 3.6 Kgs et un ecart type de 0,53 Kgs sur 49 bebes.v&amp;lt;-qt(0.975, 49-1)v2.010635ecart&amp;lt;-v*0.53/sqrt(n-1)mu.inferieur&amp;lt;-x.barre-ecartmu.superieur&amp;lt;-x.barre+ecart3.443.75Patients maladesPour une maladie donnee, un traitement gueri $90\\%$ des patients.Jâ€™ai fait un test avec 1000 patients et 850 sont gueris au bout de 2 semaines. :snail:Jâ€™accepte le 90% sur cette base?Un test de chi2, dans le cours.Ici : k=2 classes patients gueris, p1 = 0.9 patients non gueris, p2 = 0.1n&amp;lt;-1000N1&amp;lt;-850N2&amp;lt;-150p1&amp;lt;-0.9p2&amp;lt;-0.1Z&amp;lt;-(N1-n*p1)^2/(n*p1) + (N2-n*p2)/(n*p2)Z27.77778qchisq(0.95, 1)3.84qchisq(0.99, 1)6.63La valeur de Z est trop grande, les ecarts de Z sont trop grands. En principe Z doit rester petit, on va refuser lâ€™hypothese de guerison a $90\\%$. :snail:H0: la proba de guerison est de $90\\%$, la proba de non guerison est $10\\%$.Regression lineaireplot(X, Y, col=&quot;blue&quot;) On veut appliquer ces formulesmX&amp;lt;-mean(X)mY&amp;lt;-mean(Y)sX&amp;lt;-sd(X)sY&amp;lt;-sd(Y)rho&amp;lt;-cor(X, Y)beta&amp;lt;-rho*sY/sXalpha&amp;lt;-mY-beta*mXPREV&amp;lt;-beta*X+alphapoints(X,PREV,col=&quot;red&quot;,pch=19,cex=0.8)ECARTS&amp;lt;-Y-PREVvar(PREV)var(ECARTS)var(PREV) + var(ECARTS)2174766:snail:" }, { "title": "SUDE : cours du 28 mai", "url": "/cours/posts/sude_dev_durable/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-05-28 10:00:00 +0200", "snippet": "AssessmentPresentation (4-5 students) to be presented on session 4 - (~10 min per group) and uploaded prior the beginning of the courseInstructions Select a company with Green IT actions Choose at least 4 Green IT actions and explains why they can be considered as good practices and how they reduce the environmental impact At the end of the presentation (not to be presented orally), put the work on Sustainable Development Goals : Which SDG the company contributes to? (give 1 example per SDG) and for SDGs it does not contributes to, give an example of what the company could do. Quick presentationValÃ©rie Schneider: Founded her own company: ValÃ©rie Schneider Conseil Lectures at ISEP, ECE, EPITA, SUP RH CSR, Circular Econmy, Green IT Strategy, Business Models, Awareness, ProjectsWhat is the definition of sustainable development ? â€œSustainable development is the development which meets the needs of current generations without compromising the ability of future generations to meet their own needsâ€ â€“ Brundtland report, 1987 Development means everyone get access to better education, better health and minimun income. 3 keywords for the defnition development needs future generation What are the key challenges humanity has to face today ?Proposed by students: Global warming Climate change Waste management Covid19 Over consumptionWe are more than 7 billions. How many of us will there be in 2050? Challenge #1 : population growth : the population should stabilize at the end of the century, the growth rate is decreasing. In the last 40 years, the population doubled. Challenge #2 : Consumption growth : We are consumming more and more energy, goods, etc. We own more and more goods, want to get the newest technologies and throwing the old devices too often. It is the linear economy Challenge #3 : Limited resources : Global overshoot occurs when humanityâ€™s annual needs exceeds what Earthâ€™s ecosystems can renew in a year. It means we are drawing down the planetâ€™s resources rather than living off its annual interest. It leads to a depletion of Earthâ€™s life-supporting natural capital. Our ecological footprint get bigger and bigger. If everyone lived like we do it France, we would need 3 Earths to feed everyone. Challenge #4 : Global warming : The Greenhouse effect is a natural phenomen, without it there would not be life on Earth. However, because of human activities, we are emitting more gases than necessary (CO2, CH4, etc.). Challenge #5 : Biodiversity : Currently there are more than 91,520 species on the IUCN Red List more than 25,820 are threatened with extinction including 41% of amphibians 34% of conifers 33% of reef building corals 25% of mammals and 13% of birds Middle East has Oil, China has Rare Earths - Deng Xiaoping, 1992ContextMore than 1 ton of resources is needed to produce a laptop. Precious metals, such as gold, silver, platinum, etc. can be found inside of a computer.Critical metals: Rare earths : China has more than 60% of rare earths, produce 88% and consume 69% of it. They are used in many electronic appliances, magnets, wind turbines, etc. Cobalt Lithium NickelChina owns 44% of those metals and is 58% of its demand. However, these resources are limited. How can we continue to use them?Impact of rare earths extraction / production Environmental impacts Social impactsSolutions Open or re-open mines ? Social acceptance Environmental risks ROI? Finding alternatives ? Reduce or do not use rare earths Like tellurium and indium CdTE solar PV How to combine humanity development and sustainability ?The importance of biodiversity Aesthetic and scientific value Medical research Traditional and modern medicine Direct economic value Food Clothing Energy Sustainable development goals " }, { "title": "CAMA : ma42 - Gradient conjuguÃ©", "url": "/cours/posts/ma42-gradient-conjugue-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-25 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25/05Programmer le gradient conjuguÃ©A partir de ce cours sur le gradient conjuguÃ© programmez en Python + Numpy le gradient conjuguÃ© en exploitant les astuces mathÃ©matiques indiquÃ©es pour optimiservotre code. Effectuez des tests pour valider votre code. Comparez la vitesse de convergence Ã  celle du gradient avec Î¼ optimal. Tracez des courbes de convergence (cf la feuille qui en parle) Comparez les temps de calcul.Note : Veuillez Ã©crire des fonctions les plus propres possibles, en particulier qui nâ€™utilisent pas des variables globales comme câ€™est le cas dans ma correction du gradient (ma33). Solution import numpy as npimport scipy.linalg as linimport matplotlib.pylab as plt%matplotlib inline%config InlineBackend.figure_format = &#39;retina&#39; def make_system(N): A = 1.0 * np.random.randint(-10, 10, size=(N,N)) A[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominante A = A + A.T # symÃ©trique A = A / np.abs(A).sum(axis=0).mean() b = 1.0 * np.random.randint(-10,10,size=(N)) return A, bA, b = make_system(2)print(A, &quot;\\n\\n&quot;, b) [[ 0.65174129 -0.32338308] [-0.32338308 0.70149254]] [ 6. -1.] def gradient_conjuguÃ©(A, x0, b, error=1E-9, convergence=False): x = x0.copy() # je ne veux pas modifier les paramÃ¨tres qu&#39;on me donne e2 = error**2 r = A @ x - b # le gradient mais aussi le rÃ©sidu r2 = r @ r p = -r if convergence: conv = [np.sqrt(r2)] while r2 &amp;gt; e2: alpha = (r @ r) / np.dot(A @ p, p) x += alpha * p r += alpha * (A @ p) beta = (r @ r) / r2 p = -r + beta * p r2 = r @ r if convergence: conv.append(np.sqrt(r2)) return np.array(conv) if convergence else x gradient_conjuguÃ©(A, np.array([0.,0.]), b, convergence=True) array([6.08276253e+00, 2.51964707e+00, 2.22044605e-16]) def compute_error(N, method=gradient_conjuguÃ©): A, b = make_system(N) x = method(A, np.zeros(N), b) err = A @ x - b return np.sqrt(err @ err)compute_error(10) 4.165926057296536e-15 Comparons avec le gradient simple def gradient(A, x0, b, e = 1E-9, convergence=False, max_iterations=1000): x = x0.copy() e2 = e**2 k = 0 gradJ = A @ x - b g2 = gradJ @ gradJ divergence_limite = 1E6 * g2 if convergence: conv = [np.sqrt(g2)] while g2 &amp;gt; e2: Âµ = np.dot(gradJ, gradJ) / np.dot(A @ gradJ, gradJ) x -= Âµ * gradJ gradJ = A @ x - b g2 = gradJ @ gradJ if convergence: conv.append(np.sqrt(g2)) # la suite n&#39;est que des tests pour se protÃ©ger if g2 &amp;gt; divergence_limite: # au cas oÃ¹ on diverge print(&quot;DIVERGE&quot;) break k += 1 if k &amp;gt; max_iterations: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(conv) if convergence else x # vÃ©rifions que ca marchecompute_error(10, method=gradient) 6.767792116739432e-10 Perfs # comparons les performancesseed = 123np.random.seed(seed)%timeit compute_error(1000, method=gradient) 34 ms Â± 4.23 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each) seed = 123np.random.seed(seed)%timeit compute_error(1000, method=gradient_conjuguÃ©) 32.1 ms Â± 847 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each) Le gain nâ€™est pas clairâ€¦ Nombre dâ€™iteration dans les 2 cas N = 1000A,b = make_system(N)x0 = np.zeros(N) Pour le gradient simple err = gradient(A, x0, b, convergence=True) plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient&#39;)plt.semilogy(); Pour le gradient conjuge err = gradient_conjuguÃ©(A, x0, b, convergence=True) plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient conjuguÃ©&#39;)plt.semilogy(); Argh, le gradient conjuguÃ© nâ€™est pas la rÃ©volution prÃ©dite !Un cas rÃ©elLogiquement vous devriez Ãªtre dÃ©cu aussi on va tester avec un problÃ¨me rÃ©el qui correspond Ã  cet exemple de lâ€™Ã©quation de Poisson. Le systÃ¨me matriciel de ce problÃ¨me est tÃ©lÃ©chargeable ici. Une fois le fichier sauvÃ©, pour rÃ©cupÃ©rer A et b faites :npz = np.load(&#39;/tmp/Ab.npz&#39;)A = npz[&#39;A&#39;]b = npz[&#39;b&#39;] Faites une Ã©tude rapide de A, indiquez quel pourcentage des valeurs de A est diffÃ©rent de 0. Afficher lâ€™image de la matrice avec plt.imshow(A) (faire une grande image pour voir quelque chose). Refaites la comparaison entre les deux mÃ©thodes avec ce systÃ¨me matriciel. Regardez la documentation de lin.solve (en particulier les options) et comparer lin.solve Ã  vos deux algorithmes. Solution print(A.min(), A.max()) -1.5693731138089555 4.357203686821435 diff0 = (A != 0).sum() / (A.shape[0] * A.shape[1])print(f&quot;Pourcentage de valeurs != 0 : {100 * diff0:.3} %&quot;) Pourcentage de valeurs != 0 : 0.339 % plt.figure(figsize=(15,15))plt.imshow(A) Comparaison gradient simple et conjuguÃ© %time err = gradient_conjuguÃ©(A, np.zeros(len(A)), b, convergence=True) CPU times: user 1.75 s, sys: 155 ms, total: 1.91 sWall time: 521 ms plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient conjuguÃ©&#39;)plt.semilogy(); # le gradient simple%time err = gradient(A, np.zeros(len(A)), b, convergence=True, max_iterations=10000) CPU times: user 1min 11s, sys: 4.3 s, total: 1min 15sWall time: 19.4 s plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient&#39;)plt.semilogy(); On voit la supÃ©rioritÃ© du gradient conjuguÃ© tant en nombre dâ€™itÃ©rations (175 contre 7800) quâ€™en temps de calcul (0,5 s contre 20 s). Comparaison avec lin.solve ?lin.solve %time x = lin.solve(A, b, assume_a=&#39;pos&#39;) CPU times: user 170 ms, sys: 85.1 ms, total: 255 msWall time: 94.4 ms r = A @ x - br @ r 2.0359257929180678e-25 On note aussi lin.solve est plus rapide et sa solution est nettement meilleureâ€¦ lin.solve utilise une mÃ©thode directe ici. Cela est dÃ» au fait que Scipy utilise la bibliothÃ¨que Lapack (qui est imbatable). Le gradient conjuguÃ© de Scipy (avec Lapack) Le gradient conjuguÃ© Ã  tout son sens pour les matrices creuses aussi il est dans la partie â€œsparseâ€ de Scipy. On a vu que notre matrice Ã  plus de 99 % de valeur nulles ce qui en fait bien une matrice creuse. Aussi je la charge dans le format COO qui ne stocke que les valeurs non nulles et: import scipy.sparse as sparsefrom scipy.sparse.linalg import cgAc = sparse.load_npz(&#39;/tmp/Acoo.npz&#39;)%time x = cg(Ac, b) CPU times: user 24.8 ms, sys: 15.1 ms, total: 39.9 msWall time: 10.8 ms On gagne un facteur 10 !" }, { "title": "CAMA : ma41 SystÃ¨me matriciel non linÃ©aire", "url": "/cours/posts/ma41-systeme-matriciel-non-lineaire/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-25 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25 / 06 Si la matrice $A$ dÃ©pend de ${\\bf x}$ (notÃ© $A({\\bf x})$), alors le systÃ¨me matriciel \\(A({\\bf x)x = b}\\)nâ€™est pas linÃ©aire.Exemple :\\[\\begin{bmatrix}1 &amp;amp; x_1 \\\\2x_1 &amp;amp; -x_2 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1} \\\\x_{2} \\\\\\end{bmatrix} =\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\end{bmatrix}\\]donne le systÃ¨me suivant non linÃ©aire puisquâ€™on a descarrÃ©s :\\[\\begin{align}x_1 + x_1 \\, x_2 &amp;amp;= b_1 \\\\2 \\, x_1^2 - x_2^2 &amp;amp;= b_2 \\end{align}\\]Comment rÃ©soudre un tel systÃ¨me ?La mÃ©thode du point fixe La mÃ©thode du point fixe consiste Ã  appliquer lâ€™algorithme itÃ©ratif suivant : \\({\\bf x}^{k+1} = g({\\bf x}^k)\\)pour rÃ©soudre $g({\\bf x}) = {\\bf x}$. $x_0$ donnÃ© ${\\bf \\bar x} = g({\\bf \\bar x})$ un point fixe de $g$ ${\\bf x}^{k+1} = g({\\bf x}^k)$ avec $k = 0, 1, 2, â€¦$Est-ce que $g({\\bf x}^k)^k$ converge ? Si $\\bf{x_0} \\lt {\\bf \\bar x_2}$ : $\\lim_{k\\to+\\infty} = {\\bf \\bar x_1}$ Si $\\bf{x_0} \\gt {\\bf \\bar x_2}$ : $\\lim_{k\\to+\\infty} = +\\infty$ Selon le point de dÃ©part, la mÃ©thode converge ou diverge.La mÃ©thode du point fixe pour rÃ©soudre $A({\\bf x)x = b}$ On doit dÃ©finir une fonction $g$ telle que la solution de $J({\\bf x}) = {\\bf x}$ soit la solution du systÃ¨me matriciel non linÃ©aire : \\(g({\\bf x}) = A^{-1}({\\bf x}) \\, {\\bf b}\\)Inverser A est trop coÃ»teux, on Ã©crit notre algorithme itÃ©ratif sous forme de problÃ¨me matriciel linÃ©aire Ã  rÃ©soudre:\\(A({\\bf x}^k) \\, {\\bf x}^{k+1} = {\\bf b}\\)Si on connait ${\\bf x}^k$ on peut Ã©valuer $A({\\bf x}^k)$, le systÃ¨me est linÃ©aire et permet de trouver ${\\bf x}^{k+1}$.Le fonctionnement de lâ€™algorithme va dÃ©pendre du type de la matrice $A$ et de la valeur initiale $x_0$.Exemple :\\(\\begin{bmatrix}x_0 - 2 x_1 &amp;amp; x_1 \\\\x_0 &amp;amp; 2 x_0 + x_1 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_0 \\\\x_1 \\\\\\end{bmatrix} =\\begin{bmatrix}1 \\\\9 \\\\\\end{bmatrix}\\)Ce systÃ¨me a pour solutions [1, 2] et [2, 1].def A(x): return np.array([[x[0] - 2*x[1], x[1]] , [x[0] , x[1] + 2*x[0]]]) / 10 b = np.array([1, 9]) / 10 # avec normalisation grossiÃ¨rex = np.array([1, 1])for i in range(1, 10): x = lin.solve(A(x), b)...x^7 = [1.37317932 2.74635363]x^8 = [0.72823777 1.45647516]x^9 = [1.37317809 2.74635608]La solution oscille sans converger. La mÃ©thode du point fixe a un petit rayon de convergence.Appliquon lâ€™inertieÂµ = 0.5 # on avance de moitiÃ© vers le prochain xx = np.array([3, 2])for i in range(1, 10): x_old = x x = lin.solve(A(x), b) x = Âµ * x + (1-Âµ) * x_old...x^9 = [1.00876429 1.98253948]La convergence est rapide (9 iterations). L&#39;inertie augmente le rayon de convergence : plus $\\mu$ est petit plus le rayon de convergence est grand. Pour trouver les autres solutions il faut choisir un autre point initial.La mÃ©thode de Newton-Raphson \\({\\bf x}^{k+1} = {\\bf x} - \\frac{f({\\bf x_n})}{f&#39;({\\bf x_n})}\\) La mÃ©thode de Newton est une mÃ©thode de point fixe.\\({\\bf x}^{k+1} = g({\\bf x}^k)\\)oÃ¹ $g({\\bf x)} = {\\bf x} - \\frac{f({\\bf x})}{fâ€™({\\bf x})}$On souhaite rÃ©soudre notre systeme non linÃ©aire. GrÃ¢ce Ã  la formule ci-dessus, on a en 1D:\\(f&#39;(x^k) \\; (x^{k+1} - x^k) = - f(x^k)\\)Ce qui donne en $n$ dimensions:\\(J_{\\bf f}({\\bf x}^k) \\; ({\\bf x}^{k+1} - {\\bf x}^k) = - {\\bf f}({\\bf x}^k)\\)avec $J_{\\bf f}$ la matrice Jacobienne de ${\\bf f}$ :\\(J_{\\bf f}\\left({\\bf x}\\right)=\\begin{pmatrix} \\dfrac{\\partial f_1}{\\partial x_1} &amp;amp; \\cdots &amp;amp; \\dfrac{\\partial f_1}{\\partial x_n} \\\\\\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\\\dfrac{\\partial f_n}{\\partial x_1} &amp;amp; \\cdots &amp;amp; \\dfrac{\\partial f_n}{\\partial x_n}\\end{pmatrix}\\)Notre systÃ¨me non linÃ©aire avec $f$ une fonction vectorielle:\\({\\bf f}({\\bf x}) = A({\\bf x})\\, {\\bf x} - {\\bf b}\\)ExempleOn reprend le systÃ¨me matriciel prÃ©cÃ¨dent. La matrice Jacobienne de la fonciton $f$ est : \\(J_{\\bf f}({\\bf x}) = \\begin{bmatrix}2 x_0 - 2 x_1 &amp;amp; 2 x_1 - 2 x_0\\\\2 x_0 + 2 x_1 &amp;amp; 2 x_0 + 2 x_1 \\\\\\end{bmatrix}\\)def f(x): return A(x) @ x - bdef J_f(x): return 2 * np.array([[x[0] - x[1], x[1] - x[0]], [x[0] + x[1], x[0] + x[1]]])x = np.array([3, 2])for i in range(30): delta = lin.solve(J_f(x), -f(x)) x = x + delta...x^29 = [2.05693134 1.05693134]On converge (moins vite) oÃ¹ la methode du point fixe oscille sans converger. Le coÃ»t de la construction de la matrice Jacobienne peut Ãªtre tres Ã©levÃ©. Pour aller plus vite on peut recalculer la matrice toutes les 3 iterations ou plus. Il sâ€™agit dâ€™une matrice pleine qui rend compliquÃ© la resolution du systeme (une methode de gradient ne marchera pas) " }, { "title": "CAMA : Ecriture du produit scalaire", "url": "/cours/posts/produit-scalaire/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note Hackmd" }, { "title": "CAMA : ma40 MÃ©thode du gradient conjuguÃ©", "url": "/cours/posts/ma40-methode-du-gradient-conjugue/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 24 / 05MÃ©thode du gradient conjugueSi on a calculÃ© le $\\mu$ optimal alors la plus forte pente $\\nabla J ({\\bf x}^{k+1})$ sera orthogonale Ã  la pente qui dÃ©finie la droite sur laquelle on cherche $\\mu$. On a donc\\(\\nabla J ({\\bf x}^{k+1})^T \\, . \\, \\nabla J ({\\bf x}^k) = 0\\)Le minimum suivant ${\\bf x^{k+2}}$ sera le minimum de lâ€™espace gÃ©nÃ©rÃ© par $\\nabla J ({\\bf x}^{k+1})$ et $\\nabla J ({\\bf x}^k)$. On ne sait pas si ${\\bf x^{k+3}}$ sera calculÃ© le long de la direction $\\nabla J ({\\bf x}^k)$.Une recherche optimale du minimum dâ€™une fonction convexe dans un espace $\\mathbb{R}^n$ ne devrait pas prendre plus de $n$ itÃ©rations si on est capable de calculer le $\\mu$ optimal dans la direction choisie.On cherche le minimum dans les directions des vecteurs de la base de notre espace $\\mathbb{R}^n$ afin de trouver le minimum global.GÃ©nÃ©rer une base de $\\mathbb{R}^n$Si on veut trouver notre minimum global en $n$ itÃ©rations au maximum, il faut que nos directions ne soient pas redondantes et que les $n$ premiÃ¨res directions gÃ©nÃ¨rent $\\mathbb{R}^n$ ou en forment une base.La nouvelle direction $d^k$ doit Ãªtre orthogonale Ã  toutes les directions prÃ©cÃ©dentes et permet de trouver une base qui gÃ©nÃ¨re un espace de dimension $k + 1$.Le cas ${\\bf Ax = b}$La fonctionnelle Ã  minimiser est :\\(J({\\bf x}) = \\frac{1}{2} \\, {\\bf x}^T \\, A \\, {\\bf x} - {\\bf b}\\, . {\\bf x}\\) Si A est symÃ©trique, son gradient est $\\nabla J({\\bf x}) = A \\; {\\bf x} - {\\bf b}$Si on calcule ${\\bf x^k}$ comme avant on a lâ€™orthogonnalitÃ© de 2 directions successives.Que se passe-t-il si ${\\bf x^k+1}$ minimise $J$ dans lâ€™espace $G_k$ gÃ©nÃ©rÃ© par toutes les directions prÃ©cÃ©dentes ?\\(J({\\bf x}^{k+1}) = \\min_{\\bf v \\in G_k} J({\\bf x}^k + {\\bf v})\\)avec ${\\bf G_k} = span{ {\\bf d}^0, {\\bf d}^1,\\dots, {\\bf d}^k} = \\left{ {\\bf v} = \\sum_{i=0}^{k} \\alpha_i \\, {\\bf d}^i \\quad \\forall \\alpha_i \\in â„ \\right}$. Toutes les dÃ©rivÃ©es partielles par rapport aux vecteurs de ${\\bf G_k}$ sont nulles :\\(\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf w} = 0 \\quad \\forall {\\bf w} \\in {\\bf G_k}\\)Cela se vÃ©rifie si ${\\bf w}$ est un des vecteurs de la base:$$ \\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf e}_i = \\begin{bmatrix}\\partial J / \\partial x_{1} \\\\\\partial J / \\partial x_{2} \\\\\\vdots \\\\\\partial J / \\partial x_{i} \\\\\\vdots \\\\\\partial J / \\partial x_{n} \\\\\\end{bmatrix}\\, . \\,\\begin{bmatrix}0 \\\\0 \\\\\\vdots \\\\1 \\\\\\vdots \\\\0 \\\\\\end{bmatrix} =\\frac{\\partial J}{\\partial x_i}({\\bf x}^{k+1}) $$ La dÃ©rivÃ©e partielle de $J$ dans une direction ${\\bf w}$ de ${\\bf G_k}$ est nulle revient a dire $\\nabla J({\\bf x}^{k+1})$ est orthogonal Ã  ${\\bf w}$.GÃ©nÃ©rer les directions ${\\bf d}^i$La formule itÃ©rative devient :\\({\\bf x}^{k+1} = {\\bf x}^k - Âµ^k\\, {\\bf d}^k\\) Pour calculer les ${\\bf d}^k$ on utilise la formule des dÃ©rivÃ©es partielles de $J$ par rapport Ã  un vecteur ${\\bf w \\in G_k}$ oÃ¹ elles sont nulles. ${\\bf d}^i$ gÃ©nÃ¨rent lâ€™espace ${\\bf G_k}$, il suffit que les dÃ©rivÃ©es partielles de $J$ par rapport ${\\bf d}^i$ soient nulles\\(\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf d}^i = 0 \\quad \\forall i \\le k \\qquad (1) \\\\\\) En dÃ©roulant les calculs on obtient : \\(\\begin{align}\\nabla J({\\bf x}^{k}) \\, . \\, {\\bf d}^i - Âµ^k \\, A \\, {\\bf d}^k \\, . \\, {\\bf d}^i &amp;amp;= 0 \\quad \\forall i \\le k \\\\\\end{align}\\) Si $i \\lt k$, le premier terme est nul : \\(A \\, {\\bf d}^k \\, . \\, {\\bf d}^i = 0 \\quad \\forall i &amp;lt; k \\qquad (2)\\) On a les conditions pour construire la nouvelle direction ${\\bf d}^k$ \\({\\bf d}^k = \\nabla J({\\bf x}^k) - \\sum_{i=0}^{k-1} \\frac{A\\, \\nabla J({\\bf x}^k) \\, . \\, {\\bf d}^i} {A\\, {\\bf d}^i \\, . \\, {\\bf d}^i} \\; {\\bf d}^i\\) Si $i =k$, on obtient la valeur nÃ©cessaire $Âµ^k$ pour garantir que $\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf d}^k = 0$ : \\(Âµ^k = \\frac{\\nabla J({\\bf x}^{k}) \\, . \\, {\\bf d}^k} {A \\, {\\bf d}^k \\, . \\, {\\bf d}^k} = \\frac{(A \\, {\\bf x}^{k} - b) \\, . \\, {\\bf d}^k} {A \\, {\\bf d}^k \\, . \\, {\\bf d}^k} \\\\\\,\\) PropriÃ©tÃ© Lâ€™ensemble des gradients de $J$ aux points $\\bf{x}^i$ forment une base de lâ€™espace ${\\bf G_k}$ : \\(\\nabla J({\\bf x}^{k+1}) \\perp \\nabla J({\\bf x}^i) \\quad \\forall i \\le k\\) " }, { "title": "CAMA : Derivees partielles", "url": "/cours/posts/derivees-partielles/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note HackmdLes fonctions Une fonction $f$ est dite scalaire lorsque son espace dâ€™arrivÃ©e est $\\mathbb{R}$. Une fonction $f$ est dite vectorielle lorsque son espace dâ€™arivÃ©e est $\\mathbb{R}^n$ avec $n \\gt 1$.Les deriveesSoit $f(x, y)$ une fonction scalaire: sa derivÃ©e partielle premiÃ¨re en $x$ : $\\frac{\\partial f}{\\partial x} = \\partial_x f$ sa dÃ©rivÃ©e partielle seconde en $y$ : $\\frac{\\partial^2 f}{\\partial y^2} = \\partial_{yy} f$ sa diffÃ©rentielle totale $df(x, y) = \\frac{\\partial f}{\\partial x}(x, y)dx + \\frac{\\partial f}{\\partial y}(x, y)dy$ $\\frac{\\partial(f \\circ g)}{\\partial x} = \\frac{\\partial f}{\\partial g} \\frac{\\partial f}{\\partial x}$Nabla $\\nabla$Lâ€™opÃ©rateur nabla pour une fonction qui part dâ€™un espace a 2 dimensions est \\(\\nabla =\\begin{pmatrix}\\frac{\\partial f}{\\partial x} \\\\\\frac{\\partial f}{\\partial y} \\\\\\end{pmatrix}\\) Pour une fonction scalaire $f:\\mathbb{R}^2\\to\\mathbb{R}$ : \\(Gradiant : Grad(f) = \\nabla f = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} \\\\\\frac{\\partial f}{\\partial y} \\\\\\end{pmatrix} \\\\ Laplacien : \\triangle f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} \\space avec\\space \\nabla.\\nabla = \\triangle\\) Pour une fonction vectorielle $f:\\mathbb{R}^2\\to\\mathbb{R}^2$ : \\(Divergence : Div(f) = \\nabla.f = \\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y} \\\\ Laplacien: \\triangle f = \\begin{pmatrix} \\frac{\\partial^2 f_x}{\\partial x^2} + \\frac{\\partial^2 f_x}{\\partial y^2}\\\\\\frac{\\partial^2 f_y}{\\partial x^2} + \\frac{\\partial^2 f_y}{\\partial y^2}\\end{pmatrix}\\)DÃ©veloppement limitÃ©Le D.L. dâ€™une fonction $f:\\mathbb{R}^2\\to\\mathbb{R}$ en ${\\bf u} = (u_x, u_y)$ est:\\(f({\\bf u + \\delta u}) = f(u) + &amp;lt;\\nabla f(u), \\delta u&amp;gt; + \\frac{1}{2!}&amp;lt;\\nabla^2f(u)\\delta u, \\delta u&amp;gt; + o(\\Vert\\delta u\\Vert^2) \\\\ = f(u) + \\partial_x f(u)\\delta u_x +\\partial_y f(u)\\delta u_y + \\partial_{xx}f\\frac{\\delta u_x^2}{2} + \\partial_{xy}f\\delta u_x \\delta u_y + \\partial_{yy}f\\frac{\\delta u_y^2}{2} + o(\\Vert\\delta u\\Vert^2)\\)Avec $\\nabla^2 f$ la matrice hessienne de f et $&amp;lt;u, v&amp;gt;$ une autre notation du produit scalaire." }, { "title": "CAMA : ma33 - Gradient pour rÃ©soudre Ax = b -- Exercice", "url": "/cours/posts/ma33-gradient-pour-resoudre/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 17/05La mÃ©thode du gradient pour rÃ©soudre A x = bLe but de ce TP est de vous laisser avancer tout seul. Reprenez les cours et programmez la mÃ©thode du gradientpour rÃ©soudre le systÃ¨me matriciel $A {\\bf x} = {\\bf b}$ avec A symÃ©trique et Ã  diagonale dominante($a_{ii} &amp;gt; \\sum_{k \\ne i} |a_{ik}|$). Commencez en 2D avec une matrice 2x2, vÃ©rifier que le rÃ©sultat est bon et tracer la courbe de convergence Passez en nxn (on montrera que cela marche avec une matrice 9x9)Il peut Ãªtre intÃ©ressant de normaliser la matrice A pour Ã©viter que les calculs explosent. Solution 2x2 # plein de copier coller du coursimport numpy as npimport scipy.linalg as linimport matplotlib.pylab as pltimport plotly.offline as pyimport plotly.graph_objects as go%matplotlib inline%config InlineBackend.figure_format = &#39;retina&#39;np.set_printoptions(precision=3, linewidth=150, suppress=True)plt.style.use([&#39;seaborn-whitegrid&#39;,&#39;data/cours.mplstyle&#39;]) N = 2A = np.random.randint(-10, 10, size=(N,N))A = A * 1.0 # pour passer en reelsA[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominanteA = A + A.T # symÃ©triqueA = A / np.abs(A).sum(axis=0).mean()b = np.random.randint(-10,10,size=(N))print(A, &quot;\\n\\n&quot;, b) [[1.037 0.184] [0.184 0.596]] [7 2] def grad_J(x): return A@x - b def minimum_J(start_value, Âµ=0.1, e = 0.001): x = [np.array(start_value)] while True: x.append(x[-1] - Âµ * grad_J(x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: break # la suite n&#39;est que des tests pour se protÃ©ger if np.square(x[-1] - x[-2]).sum() &amp;gt; 1E9: # au cas oÃ¹ on diverge print(&quot;DIVERGE&quot;) break if len(x) &amp;gt; 1000: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(x)x = minimum_J(np.zeros(N)) x[-1] - lin.solve(A, b) array([-0.007, 0.016]) plt.plot(x[:,0], x[:,1], &#39;x:&#39;) nxn np.abs(A) array([[1.037, 0.184], [0.184, 0.596]]) N = 9A = np.random.randint(-10, 10, size=(N,N))A = A * 1.0 # pour passer en reelsA[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominanteA = A + A.T # symÃ©triqueA = A / np.abs(A).sum(axis=0).mean()b = np.random.randint(-10,10,size=(N)) x = minimum_J(np.zeros(N)) x[-1] - lin.solve(A, b) array([ 0. , -0.006, 0.001, 0.006, 0.017, 0.008, -0. , 0.014, 0.004]) print(&quot;Converge en %d itÃ©rations&quot; % len(x))x Converge en 178 itÃ©rations array([[ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0.3 , -0.2 , 0. , ..., 0.8 , -0.6 , -0.4 ], [ 0.576, -0.396, -0.001, ..., 1.548, -1.176, -0.783], ..., [ 3.088, -4.714, 0.223, ..., 13.007, -14.827, -9.853], [ 3.088, -4.714, 0.223, ..., 13.007, -14.827, -9.853], [ 3.088, -4.714, 0.223, ..., 13.007, -14.828, -9.854]]) Introduire de lâ€™inertieIntroduire de lâ€™inertie dans la mÃ©thode du gradient. Que constate-t-on ? Reponse Ajouter de lâ€™inertie dans une mÃ©thode itÃ©rative veut dire quâ€™on avance moins vite vers le point suivant : x_next = ...x = w * x_next + (1 - w) * x avec w qui reprÃ©sente la force dâ€™avancÃ©e (ou lâ€™inverse du poids de lâ€™inertie).Dans le cas de la mÃ©thode du gradient cela donne : x_next = x - |Âµ| grad_J(x)x = w * x_next + (1 - w) * x ce qui se dÃ©veloppe ainsi : x = w * (x - |Âµ| grad_J(x)) + (1 - w) x ou x = x - w * |Âµ| grad_J(x) On voit donc quâ€™ajouter de lâ€™inertie ne fait que modifier le paramÃ¨tre Âµ qui justement sert Ã  avancer plus ou moins vite. Âµ est dÃ©jÃ  une sorte dâ€™inertie. Donc cela ne change pas la mÃ©thode et cela nâ€™ammÃ©liore pas lâ€™algorithme.Valeur optimale de ÂµOn note que deux directions de pente sucessives sont orthogonales si le point suivant est le minumum dansla direction donnÃ©e ($\\nabla J ({\\bf x}^k$)).\\[\\nabla J ({\\bf x}^{k+1})^T \\; \\nabla J ({\\bf x}^k) = 0\\]DÃ©monstrationOn veut rÃ©gler Âµ pour arriver au minimum de J lorsquâ€™on avance dans la direction $- \\nabla J({\\bf x}^{k})$.Cela veut dire que la dÃ©rivÃ©e partielle de $J({\\bf x}^{k+1})$ par rapport Ã  Âµ doit ÃªtreÃ©gale Ã  0 ou bien en faisant apparaitre Âµ dans lâ€™Ã©quation :\\[\\frac{\\partial J ({\\bf x}^k - Âµ \\; \\nabla J ({\\bf x}^k))}{\\partial Âµ} = 0\\]En dÃ©veloppant on a\\[\\begin{aligned}\\frac{\\partial J ({\\bf x}^{k+1})}{\\partial {\\bf x}^{k+1}} \\; \\frac{\\partial {\\bf x}^{k+1}}{\\partial Âµ} &amp;amp;= 0 \\\\J&#39;({\\bf x}^{k+1}) \\, . \\, (- \\nabla J ({\\bf x}^k)) &amp;amp;= 0 \\\\(A\\, {\\bf x}^{k+1} - b) \\, . \\, \\nabla J ({\\bf x}^k) &amp;amp;= 0 \\quad \\textrm{puisque A est symÃ©trique}\\\\\\nabla J ({\\bf x}^{k+1}) \\, . \\, \\nabla J ({\\bf x}^k) &amp;amp;= 0 \\quad \\textrm{CQFD}\\end{aligned}\\]En utilisant cette propriÃ©tÃ©, Ã©valuer la valeur optimale de Âµ pour atteindre le minimum dans la direction de$\\nabla J ({\\bf x}^k)$.ExerciceÃ‰crire le mÃ©thode du gradient avec le calcul du Âµ optimal Ã  chaque itÃ©ration pour rÃ©soudre $A {\\bf x} = {\\bf b}$. Solution On reprend lâ€™avant-derniÃ¨re ligne de la dÃ©monstration et on remplace $\\bf x^{k+1}$ par $\\bf x^{k} -\\mu\\nabla J(\\bf x^k)$:\\[\\begin{aligned}(A(\\bf x^k - \\mu\\nabla J(\\bf x^k)) -b)\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\(A\\bf x^k -b - \\mu A\\nabla J(\\bf x^k))\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\(A\\bf x^k -b)\\cdot\\nabla J(\\bf x^k) - \\mu A\\nabla J(\\bf x^k)) -b\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\\\mu &amp;amp;= \\frac{\\nabla J(\\bf x^k)\\cdot\\nabla J(\\bf x^k)}{A\\nabla J(\\bf x^k)\\cdot\\nabla J(\\bf x^k)}\\end{aligned}\\] def minimum_J(start_value, e = 0.001): x = [np.array(start_value)] while True: gradJ = grad_J(x[-1]) Âµ = np.dot(gradJ, gradJ) / np.dot(A @ gradJ, gradJ) x.append(x[-1] - Âµ * grad_J(x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: break # la suite n&#39;est que des tests pour se protÃ©ger if np.square(x[-1] - x[-2]).sum() &amp;gt; 1E9: # au cas oÃ¹ on diverge print(&quot;DIVERGE&quot;) break if len(x) &amp;gt; 1000: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(x) x = minimum_J(np.zeros(N))x[-1] - lin.solve(A, b) array([-0., -0., 0., -0., 0., 0., 0., 0., -0.]) print(&quot;Converge en %d itÃ©rations&quot; % len(x))x Converge en 14 itÃ©rations array([[ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], [ 5.295, -3.53 , 0. , -15.884, -8.824, -1.765, 14.119, -10.589, -7.06 ], [ 3.488, -5.355, -0.197, -12.432, -13.603, -3.608, 12.295, -13.31 , -8.402], [ 3.085, -4.72 , 0.257, -14.479, -14.586, -3.802, 12.956, -14.127, -9.531], [ 3.128, -4.877, 0.194, -13.924, -15.279, -4.164, 12.973, -14.572, -9.669], [ 3.076, -4.743, 0.232, -14.255, -15.457, -4.161, 13. , -14.712, -9.837], [ 3.091, -4.75 , 0.226, -14.166, -15.569, -4.242, 13.013, -14.786, -9.842], [ 3.083, -4.72 , 0.226, -14.224, -15.6 , -4.239, 13.009, -14.815, -9.863], [ 3.087, -4.718, 0.225, -14.208, -15.618, -4.257, 13.011, -14.829, -9.859], [ 3.086, -4.711, 0.224, -14.22 , -15.623, -4.256, 13.008, -14.836, -9.861], [ 3.087, -4.71 , 0.223, -14.217, -15.627, -4.26 , 13.009, -14.839, -9.859], [ 3.087, -4.708, 0.223, -14.219, -15.627, -4.26 , 13.008, -14.84 , -9.859], [ 3.087, -4.708, 0.222, -14.219, -15.628, -4.261, 13.008, -14.841, -9.858], [ 3.087, -4.708, 0.222, -14.219, -15.628, -4.261, 13.007, -14.841, -9.858]]) " }, { "title": "CAMA : ma32 ma32 MÃ©thode du gradiant pour systÃ¨me matriciel", "url": "/cours/posts/ma32-methode-du-gradient-pour-systeme-matriciel/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25/06$Ax = b$ vu comme un probleme dâ€™optimisationPour rÃ©soudre $Ax = b$ on va chercher le minimum de la fonctionnelle\\(J(x) = \\frac{1}{2}x^TAx - b.x\\)La dÃ©rivÃ©e sâ€™annule en ce point et est $Ax - b$Calcul de la dÃ©rivÃ©eLes derivÃ©es de dimension supÃ©rieure a 1 peuvent Ãªtre manipulÃ©es comme des derivÃ©es partielles ou une derivÃ©e totale. On sâ€™intÃ©resse Ã  la derivÃ©e dans une direction, c.a.d la derivÃ©e partielle en $y$ si on va dans la direction de lâ€™axe $y$. DÃ©finition$f : \\Omega \\subset {X\\to Y}$ ($\\Omega$ ouvert) est dÃ©rivable en $a\\in\\Omega$ si\\(\\exists f&#39;(a)\\in L(X,Y)\\space tel\\space que \\\\f(a+h) = f&#39;(a) + f(a)(h) + h\\space\\epsilon(h)\\)avec: $\\lim_{h\\to 0}\\epsilon (h) = 0$ $L(X, Y)$ applications linÃ©aires continues de $X$ dans $Y$ $fâ€™(a)\\in L(X, Y)$ et non $fâ€™$ Si $f$ est dÃ©rivable en $a$ alors $\\forall h \\in X$\\(f&#39;(a)(h) = lim_{\\theta\\to0}\\frac{f(a + \\theta h) - f(a)}{\\theta}\\) Attention Ã  vÃ©rifier le type de chaque terme.$f$ est une fonction scalaire donc : $Y = \\mathbb{R}$ $X = \\mathbb{R}^n \\space avec\\space n\\gt 1$ Notation avec le gradient\\(f(a + h) = f(a) + (\\nabla f)(a)^T h + h^T\\epsilon(h)\\) $f$ est scalaire $(\\nabla f)(a)$ est un vecteur dont le produit scalaire avec h donne un rÃ©elCalculons la dÃ©rivÃ©e de J suivant une directionOn calcule la dÃ©rivÃ©e de $J(x)$ au point $a$ suivant la direction $h$\\(J&#39;(a)(h) = \\lim_{\\theta\\to0}\\frac{J(a + \\theta h) - J(a)}{\\theta} \\\\= \\lim_{\\theta\\to 0}\\frac{1}{\\theta}\\biggr(\\frac{1}{2}(a+\\theta h)^TA(a+\\theta h) - b^T(a+\\theta h) - \\frac{1}{2}a^TAa+b^Ta\\biggr) \\\\= \\lim_{\\theta\\to0}\\frac{1}{\\theta}\\biggr(\\frac{1}{2}(\\theta a^TAh + \\theta h^TAa +\\theta^2 h^TAh) - \\theta b^Th\\biggr) \\\\= \\frac{1}{2}(a^TAh + h^TAa) - b^T h\\)donc\\(J&#39;:x\\in\\Omega\\subset\\mathbb{R}^n\\to L(\\mathbb{R}^n,\\mathbb{R}) \\\\x\\mapsto\\frac{1}{2}(x^TA + Ax)-b\\)A symÃ©triqueDans le cas ou A est symÃ©trique, on a:\\(J&#39;(x) = \\nabla J(x) = Ax - b\\)Si la dÃ©rivÃ©e s&#39;annule, c.a.d qu&#39;on trouve le minimum, on a rÃ©solu le systÃ¨me matriciel Les conditions pour utiliser la mÃ©thode de gradient sont: A symÃ©trique J a un minimum PropriÃ©te Si A est symÃ©trique et dÃ©finie positive alors $J$ est convexe strictement et coervice ($\\lim_{\\lVert a \\rVert\\to\\infty}J(a) = +\\infty$), alors elle a un minimum." }, { "title": "CAMA : ma31 x.T A x sur un maillage en Numpy", "url": "/cours/posts/ma31-x.TAx-sur-un-maillage-en-numpy/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 17/05Calculons $x^TAx$ avec NumpyNous voulons tracer la courbe, avec $x\\in\\mathbb{R}^2$ :\\(J_A(x) = x^TAx\\)On prendra $x\\in\\mathbb{R}^n$ plus tard. Pour une valeur de $x$ le calcul est x.T @ A @ x, mais on veut faire ce calcul pour un ensemble de $x$ On construit un maillage: un ensemble de point $x$ pour lesquels on calculera $J_A(x)$On utilise np.meshgridx = np.linspace(-1,1,3) # retourne des nombres espaces egalement dans un intervalle specifiey = np.linspace(-1,2,4)mesh = np.meshgrid(x,y) # donne les x puis les y du maillageM = np.array(mesh)M = M.transpose([1,2,0])shape of M: (4, 3, 2)M = array([[[-1., -1.], [ 0., -1.], [ 1., -1.]], [[-1., 0.], [ 0., 0.], [ 1., 0.]], [[-1., 1.], [ 0., 1.], [ 1., 1.]], [[-1., 2.], [ 0., 2.], [ 1., 2.]]])Pour calculer $x^TAx$, on commence par calculer $x^TA$ pour tous points du maillage. On utilise la matrice identitÃ© pour vÃ©rifier nos calculs.Cas avec $A = 2*Id$A = 2 * np.diag([1, 1]) # Construit un array diagonalMA = np.einsum(&quot;ijk, ka -&amp;gt; ija&quot;, M, A) # Notation d&#39;EinsteinMA = array([[[-2., -2.], [ 0., -2.], [ 2., -2.]], [[-2., 0.], [ 0., 0.], [ 2., 0.]], [[-2., 2.], [ 0., 2.], [ 2., 2.]], [[-2., 4.], [ 0., 4.], [ 2., 4.]]])On retrouve `2*M`.On peut vÃ©rifier sur un certain point:M[0,1] @ Aarray([ 0., -2.]) Notez quâ€™on a Ã©crit $xA$ et non $x^TA$. Lorsquâ€™on a un vecteur, Numpy privilÃ©gie le produit matrice vecteur qui donne un vecteur. Ainsi: m[0,1] @ A == m[0,1].T @ ASi on veut une diffÃ©rence entre un vecteur vertical et horizontal, il faut utiliser des arrays 2D de taille 1*n ou n*1np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, MA, M) # comme k n&#39;est pas dans le rÃ©sultat, c&#39;est sur lui qu&#39;on fait la sommearray([[ 4., 2., 4.], [ 2., 0., 2.], [ 4., 2., 4.], [10., 8., 10.]])Comme A est la matrice identitÃ© x2, on retrouve pour tout point sa norme au carrÃ©Optimisons :np.tensordot Un tensor est une matrice en N dimensions.Comparons les temps de calcul.%timeit np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, np.einsum(&quot;ijk, ka -&amp;gt; ija&quot;, M, A), M)135 Âµs Â± 2.56 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)%%timeit # pour calculer le temps d&#39;execution de toute la cellule %%MA = np.tensordot(M, A, axes=(2,1)) # on somme sur l&#39;axe 2 de M (les points) et l&#39;axe 1 de A (les colonnes)np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, MA, M) 102 Âµs Â± 1.2 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each) On peut avoir un gain de temps 30% et plus ou un peu moins bien que einsum" }, { "title": "CAMA : ma30", "url": "/cours/posts/ma30-methode-du-gradient/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCAMA : ma30 Optimisation - MÃ©thode du gradientCours du 17/05Probleme dâ€™optimisationSoit une fonction $J : \\mathbb{R}^n\\to\\mathbb{R}$, trouver le minimum de $J$, c.a.d trouver $u$ tel que\\(J(u) = \\inf_{v\\in\\mathbb{R}^n}J(v)\\)ProblÃ¨me dâ€™optimisation avec contrainte Il est possible de chercher $u$ non pas dans $\\mathbb{R}^n$ mais dans une partie de $\\mathbb{R}^n$, câ€™est alors un problÃ¨me dâ€™optimisation avec contrainte.Exemple : On cherche le minimum de $J(x, y)$ avec $x \\lt y$, on cherche dans la partie de $\\mathbb{R}^2$ qui vÃ©rifie $x \\lt y$.La mÃ©thode du gradientOn imagine un problÃ¨me dâ€™optimisation en 2D comme un terrain avec du relief, $J(x, y)$ represente lâ€™altitude en tout point $(x, y)$. La mÃ©thode du gradient consiste a prendre un point au hasard et descendre dans la direction qui descend le plus afin de trouver le minimum de $J$.L&#39;algorithme du gradient consiste Ã  :* prendre un point de dÃ©part au hasard $p^0 = (x_0, y_0)$* calculer le gradient de $J$ en ce point$$\\nabla J(x_0, y_0) = \\begin{bmatrix} \\frac{\\partial J}{\\partial x} \\\\\\frac{\\partial J}{\\partial y}\\end{bmatrix} (x_0, y_0)$$* avancer dans la direction opposÃ©e (le gradient monte) ${\\bf p}^{k+1} = {\\bf p}^k - \\mu \\, \\nabla J({\\bf p}^k)$* on recommence l&#39;Ã©tape prÃ©cÃ©dente jusqu&#39;Ã  avoir un point fixe, c.a.d $|| {\\bf p}^{k+1} - {\\bf p}^k|| &amp;lt; \\varepsilon$ avec $\\epsilon$ une petite valeur.def J(x, y): return x**2 + 0.5 * y**2 - 2 * x + 3x = np.linspace(-3,3,100) # genere des points a distance egale sur l&#39;intervalle [-3,3]y = np.linspace(-3,3,100)mx, my = np.meshgrid(x,y)mz = J(mx, my) Calcul du gradient : def grad_J(x,y): return np.array([2*x-2, y]) # calculÃ© Ã  la main Ã  partir de J **Algorithme du gradient :**``` pythonx = np.array([0,0]) # un point au hasardÂµ = 0.1 # plus il est petit et moins on avance vitee = 0.0001 # epsilon pour la condition d&#39;arrÃªtwhile True: x_old = x x = x - Âµ * grad_J(*x) # *x donne en arguments toutes les valeurs de x donc x[0] en 1er arg et x[1] en 2e if np.square(x_old - x).sum() &amp;lt; e**2: break```Le minimum obtenu en appelant $J(*x)$ est au point $[1. 0.]$ ayant pour valeur $2.0000001053122918$.Etude de la convergence du gradientOn stocke les valeurs des points entre le point initial et le point final pour obtenir un ensemble de points et tracer des courbes de convergence.def minimum_J(start_value, Âµ=0.1, e = 0.001): x = [np.array(start_value)] while True: x.append(x[-1] - Âµ * grad_J(*x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: breakx = minimum_J(start_value = (0,1)) # valeur initiale non alignee avec la solutionImpact de $\\mu$Comment est-ce que $\\mu$ influence sur la convergence? $\\mu = 0.1$ : on fait des petits pas. $\\mu = 2$ : on diverge, les pas sont trop grands. On passe de $1$ a $-1$ puis $1$, $-1$ sans tomber sur la solution $0$. $\\mu = 0.8$ : on converge en $17$ iterations contre $46$ avec $\\mu = 0.1$, câ€™est 3x plus rapide. $\\mu = 1$ : boucle infinie, on oscille infiniment entre $[0, 0]$ et $[2, 0]$. La valeur de $\\mu$ est importante. Si elle est trop petite on perd du temps, si elle est trop grande on ne trouve pas la solution." }, { "title": "SOCRA : Cours du 15 mai", "url": "/cours/posts/socra-design-patterns/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-05-15 10:00:00 +0200", "snippet": "Working with others Avoid : missing code files ugly code naming code deletion Anticipate problems Rules are required Coding style Code reviewal Automated process Software Craftmanship Basics Quality : clean code, refactoring, tests, simple design Humility : question yourself, countinously improvement Sharing : pair programming, collective ownership of source code Pragmatism : understand constraint, adapt ! Professionalism : treat your client as a partnerDesign patternsWhat is a design pattern ? A general, reusable solution to a commonly occurring problem within a given context in software design.GoF : 24 patterns Creational Builder, Factory Method, Abstract factory, Prototype, Singleton Structural Adapter, Bridge, Composite, Decorator, Facade, Flyweight, Proxy, Delegation Behavioral Chain of responsability, Command, Interpreter, Iterator, Mediator, Memento, Observer, State, Strategy, Template method, Visitor Design patterns CreationalThe singleton Restricts the instanciation of a class to one object. Singleton - Singleton : Singleton - Singleton() + getInstance() : Singleton public class Singleton { private static readonly Singleton instance = new Singleton(); private Singleton() { } public static Singleton Instance() { return instance; }} This is a thread-safe implementation.Factory method Creating objects without having to specify the exact class of the object that will be created.interface IFruit { int Price { get; }}class Cherry : IFruit { public int Price { get; } = 75;}class Apple : IFruit { public int Price { get; } = 100;}class Banana : IFruit { public int Price { get; } = 150;}enum FruitType { Banana, Apple, Cherry}class FruitFactory { private Dictionary&amp;lt;FruitType, Func&amp;lt;IFruit&amp;gt;&amp;gt; mapper; public FruitFactory() { mapper = new Dictionary&amp;lt;FruitType, Func&amp;lt;IFruit&amp;gt;&amp;gt; { {FruitType.Apple, () =&amp;gt; new Apple()}, {FruitType.Banana, () =&amp;gt; new Banana()}, {FruitType.Cherry, () =&amp;gt; new Cherry()} }; } public IFruit Create(FruitType type) { if (!mapper.TryGetValue(type, out var result)) { throw new Exception(&quot;No fruit with type {type}&quot;); } return result(); }}Design Patterns StructuralAdapter (aka Wrapper) Allows the interface of an existing class to be used as another interface.interface IOAdapter { String Read(); void Write(String message);}class ConsoleAdapter : IOAdapter { public String Read() { return Console.Readline(); } public void Write(String message) { Console.WriteLine(message); }}Decorator Allows behavior to be added to an individual object, either statically or dynamically, without affecting the behavior of other objects from the same class.public interface IBananaDecorator : IFruit { Banana Banana { get; }}public class HandOfBanana : IBananaDecorator { const int factor = 4; public HandOfBanana(Banana banana) { Banana = banana; } public int Price =&amp;gt; Banana.Price * factor; public Banana Banana { get; } public int Accept(IFruitVisitor fruitVisitor) { return Banana.Accept (fruitVisitor) * factor; }}Design Patterns BehaviouralVisitor A way of separating an algorithm from an object structure on which it operates.public interface IFruit { int Price { get; } int Accept(IFruitVisitor fruitVisitor);}public class Cherry : IFruit { public int Price { get; } = 75; public int Accept(IFruitVisitor fruitVisitor) { return fruitVisitor.Apply(this); }}public interface IFruitVisitor { int Apply(Cherry fruit); int Apply(Banana fruit); int Apply(Apple fruit);}internal class CherryPromotion : IFruitVisitor { private int count; public int Apply(Apple fruit) { return fruit.Price; } public int Apply(Banana fruit) { return fruit.Price; } public int Apply(Cherry fruit) { var reduction = 0; count++; if (count % 2 == 0) { reduction = -20; } return fruit.Price + reduction; }}Observer An object, called the subject, maintains a list of its dependents, called observers, and notifies them automatically of any state changes, usually by calling one of their methods.public interface IObservableBasket{ void Register(IBasketObserver observer); void Add(IFruit fruit);}public class ObservableBasket : IObservableBasket{ List&amp;lt;IFruit&amp;gt; list = new List&amp;lt;IFruit&amp;gt;(); private readonly List&amp;lt;IBasketObserver&amp;gt; observers = ... public void Register(IBasketObserver observer) { observers.Add(observer); } public void Add(IFruit fruit) { list.Add(fruit); Notify(fruit); } private void Notify(IFruit fruit) { foreach (var observer in observers) { observer.Notify(fruit); } }}public interface IBasketObserver{ void Notify(IFruit fruit);}class BasketLogger : IBasketObserver{ public void Notify(IFruit fruit) { ConsoleAdapter.Instance.Write($&quot;Item added : â€œ + fruit.GetType().Name); }}Strategy Enables selecting an algorithm at runtime.public class CherryForStrategy : Cherry{ public CherryForStrategy(IPriceStrategy strategy) { Strategy = strategy; } public IPriceStrategy Strategy { get; set; } public override int Price =&amp;gt; Strategy.Apply(base.Price);}public interface IPriceStrategy{ int Apply(int defaultPrice);}public class SecondAtHalfPrice : IPriceStrategy{ private int count; public int Apply(int defaultPrice) { var reduction = 0; count++; if (count % 2 == 0) { reduction = -20; } return defaultPrice + reduction; }}Organize your timeGet Things Done Capture / collect Clarify / process Organize Reflect / plan Engage / doPomodoro Focus on one task during 25 min Take a break 5 min Repeat 3 or 4 times Take a break 20 minEisenhower matrixOrganize your codeVersion control system VCS Revision Mode CVS Per file Client-server SVN Per commit Client-server GIT Per commit Distributed Branching modes How many productions versions ? How many developers ? Which development process ?FeatureReleaseOrganize your learningTrain yourself Monitory technology Try them : POC Be careful of the silver bullet syndromeTrain with others Coding dojo / Kata Pair programming Code reviews" }, { "title": "CAMA : ma21 - Exercice", "url": "/cours/posts/ma21-surrelaxation-exos/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-11 11:00:00 +0200", "snippet": "Lien de la note HackmdCAMA : ma21 Surrelaxation pour Gauss-Seidel â€“ ExerciceCours du 11/05import numpy as npimport scipy.linalg as linimport matplotlib.pylab as plt%matplotlib inlinenp.set_printoptions(precision=3, linewidth=150, suppress=True)On va augmenter le rayon de convergence la mÃ©thode Jacobi ammÃ©liorÃ©e faite en TD Ã  savoir la mÃ©thode de Gauss-Seidel.On Ã©tudiera sa convergence dans diffÃ©rents cas.Gauss-SeidelLorsquâ€™on calcul le x suivant avec Jacobi on ne profite pas du fait que N est triangulaireet donc quâ€™on connait la nouvelle valeur de $x_n$ lorsquâ€™on calcule $x_{n-1}$. Avec Gauss-Seidelon utilise toujours la derniÃ¨re valeur calculÃ©e ce qui accÃ©lÃ¨re la convergence.Pour rÃ©sumer Gauss-Seidel dâ€™un point de vu matriciel on a : D = la matrice diagonale extraite de A : D = np.diag(np.diag(A)) L = la matrice stritecement triangulaire infÃ©rieure de A : L = np.tril(A, -1) U = la matrice stritecement triangulaire supÃ©rieure de A : U = np.triu(A, 1)et une itÃ©ration est donnÃ©e par la formule suivante :\\[(D + L){\\bf x}^{k+1} = -U{\\bf x}^k + {\\bf b}\\]ou\\[{\\bf x}^{k+1} = D^{-1} \\, ( -L\\, {\\bf x}^{k+1} - U\\; {\\bf x}^k + {\\bf b})\\]c.a.d.\\[\\begin{bmatrix}x_{1}^{k+1} \\\\x_{2}^{k+1} \\\\\\vdots \\\\x_{n}^{k+1} \\\\\\end{bmatrix}=\\begin{bmatrix}1/a_{11} \\quad 0 \\quad \\ldots \\quad 0 \\\\0 \\quad 1/a_{22} \\quad \\ldots \\quad 0 \\\\ \\vdots \\\\0 \\quad 0 \\quad \\ldots \\quad 1/a_{nn} \\\\\\end{bmatrix}\\;\\left(\\;-\\begin{bmatrix}0 \\quad 0 \\quad \\ldots \\quad 0 \\\\a_{21} \\; 0 \\quad \\ldots \\quad 0 \\\\ \\vdots \\\\a_{n1} \\, a_{n2} \\; \\ldots \\quad 0 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1}^{k+1} \\\\x_{2}^{k+1} \\\\\\vdots \\\\x_{n}^{k+1} \\\\\\end{bmatrix}-\\begin{bmatrix}0 \\; a_{12} \\; \\ldots \\; a_{1n} \\\\0 \\quad 0 \\; \\ldots \\; a_{2n} \\\\ \\vdots \\\\0 \\quad 0 \\; \\ldots \\; 0 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1}^k \\\\x_{2}^k \\\\\\vdots \\\\x_{n}^k \\\\\\end{bmatrix}+\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\vdots \\\\b_{n} \\\\\\end{bmatrix}\\; \\right)\\]Notons que je peux mettre $L\\, {\\bf x}^{k+1}$ Ã  droite du signe Ã©gal si je rÃ©soud mon systÃ¨me ligne par ligne en commencant par le haut puisque dans ce cas les ${\\bf x}^{k+1}$ utilisÃ©s sont connus. Câ€™est ce quâ€™on a fait lors du dernier TP.Surrelaxation de Gauss-SeidelComme on a fait avec Jacobi, on introduit de lâ€™inertie avec $w$ :\\[{\\bf x}^{k+1} = w \\, D^{-1} \\, ( -L\\, {\\bf x}^{k+1} - U\\; {\\bf x}^k + {\\bf b}) + (1-w) \\; {\\bf x}^k\\]VÃ©rifiez que lâ€™on arrive Ã  lâ€™Ã©criture matricielle suivante :\\[\\left(\\frac{D}{w} + L\\right)\\, {\\bf x}^{k+1} = \\left(\\frac{1-w}{w} \\, D - U\\right)\\; {\\bf x}^k + {\\bf b}\\]Ã‰crit ainsi on voit que cette mÃ©thode consiste Ã  avoir les Ã©lÃ©ments de la diagonale des 2 cotÃ©s de lâ€™Ã©galitÃ©. On peut interprÃ©ter cela comme un avantage liÃ© Ã  un gain dâ€™information lors des opÃ©rations matrice vecteur.Programmons Gauss-Seidel surrelaxÃ©On Ã©crira deux fonctions : solve_triangular(L,b) qui retourne la solution de L x = b lorsque L est triangulaire infÃ©rieure gauss_seidel_r(A, b, x0, w, n) qui fait n iteration de Gauss-Seidel avec w donnÃ© en argument Ã  partir de x0. Cette fonction retourne un tableau des valeurs de x calculÃ©es (donc tableau en 2D).Comme toujours, attention Ã  limiter les for et Ã  faire le plus possible dâ€™opÃ©rations vectorielles et matricielles. Solution def solve_triangular(L, b): x = np.empty(len(b)) x[0] = b[0] / L[0,0] for i in range(1,len(L)): x[i] = (b[i] - L[i,:i] @ x[:i]) / L[i,i] return x # je teste A = np.tril(np.random.randint(10, size=(4,4)))b = A.sum(axis=1)solve_triangular(A,b) array([1., 1., 1., 1.]) def gauss_seidel_r(A, b, x0, w=0.5, n=100): D = np.diag(np.diag(A)) L = np.tril(A, -1) U = np.triu(A, 1) L = D / w + L U = ((1-w) / w) * D - U x = x0 values = [] for _ in range(n): x = solve_triangular(L, U @ x + b) values.append(x) return np.array(values) Lâ€™algorithme de Wikipedia est difficile alire, lent et il sâ€™agit de Jacobi avec relaxation et non Gauss-Seidel avec relaxation, il est tout ce quâ€™il ne faut pas faire. np.random.seed(123)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1)x0 = np.random.random(4)res = gauss_seidel_r(A, b, x0, w=0.2, n=100)print(res[-1])[1. 1. 1. 1.]def plot_convergences(values, result): error = np.square(values - result).sum(axis = -1) / np.square(result).sum(axis=-1) error2 = np.square(np.diff(values)).sum(axis = -1) / np.square(values).sum(axis=-1) fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,4)) ax1.plot(range(len(error)), error) ax1.set_title(&#39;Erreur absolue normalisÃ©e&#39;) ax1.semilogy(); ax2.plot(range(len(error2)), error2) ax2.set_title(&#39;Erreur relative normalisÃ©e&#39;) ax2.semilogy() print(&quot;ItÃ©ration du minimum :&quot;,np.argmin(error), np.argmin(error2))plot_convergences(res, np.ones(4)) Resultat ItÃ©ration du minimum : 99 99 Est-ce que la mÃ©thode de Gauss-Seidel non relaxÃ©e converge dans ce cas ? Reponse gauss_seidel_r(A, b, x0, w=1, n=100)[-1] # oui array([1., 1., 1., 1.]) Le bon casTrouver un seed qui permet de gÃ©nÃ©rer un cas qui ne converge pas avec Gauss-Seidel de base mais qui converge avec la relaxation ($w=0.2$). Solution seed = 0while True: np.random.seed(seed) A = np.random.randint(10, size=(4,4)) b = A.sum(axis=1) x0 = np.random.random(4) res = gauss_seidel_r(A, b, x0, w=0.2, n=100) res2 = gauss_seidel_r(A, b, x0, w=1, n=100) if np.square(res[-1] - np.ones(4)).sum() &amp;lt; 0.01 and np.square(res2[-1] - np.ones(4)).sum() &amp;gt; 1 : print(seed) break seed += 1 87 Tracer les courbes de convergence pour le cas retenu avec et sans relaxation. Solution np.random.seed(87)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1)x0 = np.random.random(4) plot_convergences(gauss_seidel_r(A, b, x0, w=0.2, n=100), np.ones(4)) ItÃ©ration du minimum : 95 97 plot_convergences(gauss_seidel_r(A, b, x0, w=1, n=100), np.ones(4)) ItÃ©ration du minimum : 0 0 Ã‰tude de $w$Toujours dans notre cas retenu,indiquer quel est lâ€™intervale devaleurs de $w$ qui garantit la convergence pour notre systÃ¨me matriciel A x = b avec toujours le mÃªme x0 et un nombre dâ€™itÃ©rations Ã  dÃ©terminer.Trouver la valeur optimiale de $w$ pour converger le plus rapidement pour ce cas.La prÃ©cision demandÃ©e pour lâ€™intervale et la valeur optimale est de $10^{-2}$. Solution # utilisons une mÃ©thode par dichotomiewmin = 0wmax = 1while wmax - wmin &amp;gt; 1E-2: w = (wmax + wmin) / 2 res = gauss_seidel_r(A,b,x0, w, n=1000)[-1] if np.square(res - np.ones(4)).sum(axis=-1) &amp;lt; 1E-3: # converge wmin = w else: wmax = wprint(f&quot;Intervale de convergence : ]0,{(wmin+wmax)/2}]&quot;) Intervale de convergence : ]0,0.69140625] plot_convergences(gauss_seidel_r(A, b, x0, w=0.7, n=500), np.ones(4)) # ca converge tres doucement ItÃ©ration du minimum : 493 494 plot_convergences(gauss_seidel_r(A, b, x0, w=0.7 + 1E-2, n=500), np.ones(4)) # ca diverge clairement Il semble que $\\omega=0.7$ soit la limite de la convergence. # MÃ©thode brutale (Newton serait plus joli mais je ne sais pas si vous connaissez)# de toute facon c&#39;est trÃ¨s rapideN = 500best_w = 0best_it = Nfor i in np.arange(0.01, 0.7, 0.01): it_cv = np.argmax(np.square(gauss_seidel_r(A, b, x0, i, 500) - np.ones(4)).sum(axis=-1) &amp;lt; 1E-6) # attention, si la rÃ©ponse est 0 cela veut dire que cela n&#39;est pas descendu en dessous de 1E-6 if it_cv &amp;gt; 0 and it_cv &amp;lt; best_it: best_w = i best_it = it_cvbest_w, best_it (0.36000000000000004, 154) plot_convergences(gauss_seidel_r(A, b, x0, w=0.36, n=100), np.ones(4)) ItÃ©ration du minimum : 99 99 Trouver la valeur optimale de $\\omega$ doit bien sÃ»r pouvoir Ãªtre fait rapidement. Pour certains problÃ¨mes particulier on connait la formule qui donne le $\\omega$ optimal, sinon il faut utiliser des heuristiques sans garanties." }, { "title": "CAMA : ma20 Convergence de Jacobi avec inertie", "url": "/cours/posts/ma20-convergence-jacobi-interie/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-11 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 11 / 05Ajouter de lâ€™inertie Ã  Jacobi La mÃ©thode de Jacobi mÃ¨ne au systÃ¨me itÃ©ratif :\\({\\bf x}^{k+1} = M^{-1} \\, ( N\\; {\\bf x}^k + {\\bf b})\\)Cette mÃ©thode converge ssi la matrice $b$ a un rayon spectral infÃ©rieur Ã  1 (cf ma12). On peut agrandir le rayon de convergence en ajoutant de lâ€™inertie:\\({\\bf x}^{k+1} = w \\, M^{-1} \\, (N\\; {\\bf x}^k + {\\bf b}) + (1-w) \\, {\\bf x}^k\\) $0 &amp;lt; w \\le 1$. si $w = 1$ : Jacobi classique si $w = 0$ : on nÃ©glige les termes en dehors de la diagonale et $b$ donc Ã§a ne marche pas On parle dâ€™inertie car on avance â€œmoins viteâ€: la nouvelle valeur de ${\\bf x}^{k+1}$ est comprise entre lâ€™ancienne valeur de ${\\bf x}^{k+1}$ et ${\\bf x}^k$. Câ€™est la surrelaxationProgrammons lâ€™inertie pour JacobiOn commence pour un Jacobi qui diverge.np.random.seed(799)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[5 7 6 0] [1 7 2 5] [5 6 5 1] [0 6 3 7]] b: [18 15 17 16] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[5 0 0 0] [0 7 0 0] [0 0 5 0] [0 0 0 7]]N: [[ 0 -7 -6 0] [-1 0 -2 -5] [-5 -6 0 -1] [ 0 -6 -3 0]]x0 = np.random.random(4)x = x0for i in range(20): x = (N @ x + b) / M...x_16 = [-4448.651 -1888.411 -4149.91 -1981.882]x_17 = [7627.267 3238.983 7114.521 3399.456]x_18 = [-13068.402 -5548.37 -12190.539 -5823.066]x_19 = [22399.965 9511.401 20894.459 9982.548] Ajoutons de lâ€™inertie :x = x0 # on reprend la mÃªme valeur initiale pour la comparaisonw = 0.5 # on choisit w for i in range(20): x = w * (N @ x + b) / M + (1-w) * x...x_17 = [1.059 0.977 0.972 1.03 ]x_18 = [1.063 0.977 0.968 1.031]x_19 = [1.067 0.978 0.963 1.032]La solution est [1,1,1,1], l&#39;inertie fonctionne.Ã‰tudions la convergenceOn trace une courbe de: lâ€™erreur absolue (lorsquâ€™on connait la solution) de lâ€™erreur relative (entre 2 ${\\bf x}^i$ successifs) du rÃ©sidu ($||A \\, {\\bf x}^i - {\\bf b}||$). x = x0 # on reprend la mÃªme valeur initiale pour la comparaisonw = 0.5 # on choisit w error = [np.square(x - np.ones(4)).sum()]for i in range(20): x = w * (N @ x + b) / M + (1-w) * x error.append(np.square(x - np.ones(4)).sum()) A lâ€™Ã©chelle logarithmique: Il faut toujours regarder une erreur en Ã©chelle logarithmique.En faisant le calcul sur 200 itÃ©rations : On s&#39;est rapprochÃ© de la solution puis on a divergÃ©.Erreur relativeRegardons lâ€™Ã©cart entre 2 ${\\bf x}^k$ successifs.x = x0 # on reprend la mÃªme valeur initiale pour la comparaisonw = 0.5 # on choisit w error2 = []for i in range(200): old_x = x x = w * (N @ x + b) / M + (1-w) * x error2.append(np.square(x - old_x).sum()) Il y a une relation entre lâ€™Ã©cart de deux valeurs successives et lâ€™erreur absolue.L&#39;Ã©cart entre 2 ${\\bf x}$ successifs est une facon de savoir quand arrÃªter un algorithme itÃ©ratif.RÃ©sidux = x0 # on reprend la mÃªme valeur initiale pour la comparaisonw = 0.5 # on choisit w residu = []for i in range(200): old_x = x x = w * (N @ x + b) / M + (1-w) * x residu.append(np.square(A @ x - b).sum())Normaliser Si la solution est un milliard, avoir une erreur de 0.1 est trÃ¨s bien. Si la solution est 0.01, avoir une erreur de 0.1 est Ã©norme. On ne peut juger une erreur quâ€™avec une rÃ©fÃ©rence. Si on connait la solution exacte : \\(\\frac{||{\\bf x}^k - {\\bf x}||}{||{\\bf x}||}\\)De mÃªme, lâ€™erreur entre 2 itÃ©rations successives doit Ãªtre normalisÃ©e : \\(\\frac{||{\\bf x}^{k+1} - {\\bf x}^k||}{||{\\bf x}^k||}\\)def mk_A(seed): np.random.seed(seed) return np.random.randint(10, size=(4,4))def plot_error(M, N, b, x0, w, n=200): x = x0 error = [np.square(x - np.ones(4)).sum()] error2 = [] for i in range(n): old_x = x x = w * (N @ x + b) / M + (1-w) * x error.append(np.square(x - np.ones(4)).sum()) error2.append(np.square(x - old_x).sum())def plot_error_normalized(M, N, b, x0, w, n=200): x = x0 error = [np.square(x - np.ones(4)).sum()] error2 = [] for i in range(n): old_x = x x = w * (N @ x + b) / M + (1-w) * x error.append((np.square(x - np.ones(4)).sum())/4) # normalisÃ© par rapport Ã  la solution error2.append((np.square(x - old_x).sum())/np.square(x).sum()) # normalisÃ© par rapport Ã  xA = mk_A(799)b = A.sum(axis=1) M = np.diag(A) N = np.diag(M) - A x0 = np.random.random(4)plot_error(M, N, b, x0, w=0.1, n=1000) plot_error_normalized(M, N, b, x0, w=0.1, n=1000) L&#39;erreur relative normalisÃ©e se stabilise." }, { "title": "CAMA : ma13 - SystÃ¨me matriciel -- Exercices", "url": "/cours/posts/ma13-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-04 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 04/05Programmation vectorielle Le but des exercices est dâ€™avoir un programme qui donne la bonne rÃ©ponse qui soit le plus rapide possible (et pour cela on utilise massivement Numpy) En rÃ¨gle gÃ©nÃ©ral si vous avez des for imbriquÃ©s câ€™est mauvais signe.MÃ©thode du pivot de Gauss partielLâ€™ennoncÃ© est dans le cours Solution def solve_gauss_partial(A, b): # on prend le max dans la colonne i parmi les lignes en dessous (plus facile) for i in range(len(A)-1): pivot = np.argmax(np.abs(A[i:, i])) # il n&#39;y a que 3 lignes Ã  ajouter pour Ã©changer les lignes A[[i, pivot]] = A[[pivot, i]] b[[i, pivot]] = b[[pivot, i]] E = np.diag(np.array([1.,] * len(A), dtype=A.dtype)) coefs = - A[i+1:,i] / A[i,i] E[i+1:,i] = coefs A[i:, i:] = E[i:,i:] @ A[i:,i:] b[i+1:] += coefs * b[i] # multiplication terme Ã  terme # A est maintenant triangulaire surpÃ©rieur res = np.zeros(len(b), dtype=b.dtype) res[-1] = b[-1] / A[-1,-1] for i in range(len(A)-1)[::-1]: res[i] = (b[i] - A[i,i+1:] @ res[i+1:]) / A[i,i] return res e = 1E-6A = np.array([[e, 1], [1, 2]], dtype=&#39;float32&#39;)b = np.array([1., 3.], dtype=&#39;float32&#39;)print(f&quot;A\\n {A} \\nb\\n {b}\\n&quot;)x = solve_gauss_partial(A, b)print(&#39;solution : &#39;,x)print(&#39;vÃ©rification\\n&#39;, A@x) A [[0.000001 1. ] [1. 2. ]] b [1. 3.]solution : [1.0000019 0.99999905]vÃ©rification [3. 0.999997] Factorisation de CholeskiIl sâ€™agit de dÃ©composer A en $A = B\\, B^T$ avec B une matrice triangulaire infÃ©rieure. Cela nâ€™est possibleque si la matrice A est symÃ©trique et dÃ©finie positive (câ€™est dâ€™ailleurs un facon de vÃ©rifier quâ€™unematrice est dÃ©finie positive).Ã‰crire lâ€™algorithme de Choleski qui prend A et retourne B (pour deviner lâ€™algorithme, essayez de trouver les coefficients de B Ã  partir des coefficients de A sur une matrice A 4x4). Solution \\(A = B\\, B^T =\\begin{bmatrix}b_{11} &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0\\\\b_{21} &amp;amp; b_{22} &amp;amp; \\dots &amp;amp; 0\\\\&amp;amp; \\vdots&amp;amp;\\\\b_{n1} &amp;amp; b_{n2} &amp;amp; \\dots&amp;amp; b_{n,n}\\end{bmatrix}\\begin{bmatrix}b_{11} &amp;amp; b_{21} &amp;amp; \\dots &amp;amp; b_{n1}\\\\0 &amp;amp; b_{22} &amp;amp; \\dots &amp;amp; b_{n2}\\\\&amp;amp; \\vdots&amp;amp;\\\\b_{n1} &amp;amp; b_{n2} &amp;amp; \\dots&amp;amp; b_{n,n}\\end{bmatrix}=\\begin{bmatrix}b_{11}^2 &amp;amp; b_{11}b_{21} &amp;amp; \\dots &amp;amp; b_{11}b_{n1}\\\\x &amp;amp; \\sum_{i=1}^2b_{2i}^2 &amp;amp; \\dots &amp;amp; \\sum_{i=1}^2b_{2i}b_{ni}\\\\&amp;amp; &amp;amp; \\vdots&amp;amp;\\\\x &amp;amp; x &amp;amp; \\dots&amp;amp; \\sum_{i=1}^2b_{n,i}^2\\end{bmatrix}\\)avec $x$ la mÃªme valeur que de lâ€™autre cotÃ© de la diagonale On voit que $b_{11} = \\sqrt{a_{11}}$ et maintenant quâ€™on a $b_{11}$ on peut trouver toute la premiÃ¨re ligne de $B^T$ : $b_{j1}=a_{1j}/b_{11}$. Une fois quâ€™on connait la premiÃ¨re ligne de $B^T$ , on sâ€™attaque Ã  la deuxiÃ¨me en commencant par trouver $b_{22}$ puis ensuite tous les autres Ã©lÃ©ments de la ligne comme on a fait pour la premiÃ¨re ligne. On a donc dans le cas gÃ©nÃ©ral : $b_{ii} = \\sqrt{a_{ii} - \\sum_{k=1}^{i-1}b_{ik}^2}$ $b_{ji} = a_{ij} - \\sum_{k=1}^{i-1}b_{ik}b_{jk}/b_{ii} = a_{ij} - \\sum_{k=1}^{i-1}b_{ik}b_{kj}^T/b_{ii} \\space\\forall j\\gt i$ def Choleski(A): B = np.zeros(A.shape) for i in range(len(A)): B[i,i] = np.sqrt(A[i,i] - np.sum(np.square(B[i, :i]))) # garanti ok car A est def positive B[i+1:, i] = (A[i, i+1:] - B[i, :i] @ B.T[:i, i+1:]) / B[i,i] # les âˆ‘ sous forme de prod. scalaire return B Matrice symetriqueRappel : pas de boucles for imbriquÃ©es mais des opÃ©rations vectorielles et matricielles (sur des sous-matrices).CrÃ©er une matrice symÃ©trique dÃ©finie positive est vÃ©rifier que votre programme marche bien. Solution A = np.random.randint(10, size=(4,4))A = A + A.T # symmÃ©triqueA = A + np.diag(A.sum(axis=0)) # diagonale dominanteprint(&#39;A:\\n&#39;, A)B = Choleski(A)print(&#39;B\\n&#39;, B)print(&#39;vÃ©rification\\n&#39;, B @ B.T) A: [[55 8 18 5] [ 8 33 7 10] [18 7 54 9] [ 5 10 9 28]]B [[7.4161984871 0. 0. 0. ] [1.0787197799 5.6423721639 0. 0. ] [2.4271195049 0.7765914857 6.8924593995 0. ] [0.6741998625 1.6434093681 0.8831939788 4.9055711788]]vÃ©rification [[55. 8. 18. 5.] [ 8. 33. 7. 10.] [18. 7. 54. 9.] [ 5. 10. 9. 28.]] AmÃ©liorer JacobiLorsquâ€™on Ã©crit une itÃ©ration de la mÃ©thode de Jacobi avec lâ€™ensemble des coefficients, on constate quesi on calcule la nouvelle valeur de x Ã©lÃ©ment par Ã©lement alors lorsquâ€™on veut mettre Ã  jour x[1], on connait dÃ©jÃ  x[0]. Idem lorsquâ€™on met Ã  jour x[2] on connait dÃ©jÃ  x[0] et x[1], etc.Lâ€™idÃ©e de la version ammÃ©liorÃ©e de Jacobi est dâ€™utiliser la nouvelle valeur de x[0] et non pas lâ€™anciennecomme câ€™est le cas dans lâ€™algorithme du cours. Ainsi en utilisant des valeurs mise Ã  jour on peut espÃ©rerconverger plus vite.Dans ce chaque itÃ©ration demande un calcul ligne par ligne et donc une boucle for dans la boucle for surles itÃ©rations.Test dâ€™arrÃªtOn ajoutera un argument error Ã  la fonction qui indique la prÃ©cision dÃ©sirÃ©e du rÃ©sultat. PardÃ©faut sa valeur est de 1E-6 et pour offrir une bonne garantie on arrÃªte lâ€™algorithme lorsque$||x_{t+1} - x_t|| &amp;lt; \\texttt{error}\\, / \\, 10$. Solution def Jacobi(A, b, error=1E-6, verbose=False): L = np.tril(A) U = -np.triu(A, k=1) if verbose: print(f&quot;L:\\n {L}\\nU\\n {U}\\n&quot;) previous_x = np.zeros(len(b)) x = np.random.random(len(b)) err = (error / 10) ** 2 while np.sum(np.square(x - previous_x)) &amp;gt; err: previous_x = x.copy() if verbose: print(f&quot;x = {x}&quot;) # on rÃ©soud L x = U x + b avec L matrice triangulaire infÃ©rieure y = U @ x + b x[0] = y[0] / L[0,0] for i in range(1,len(L)): x[i] = (y[i] - L[i,:i] @ x[:i]) / L[i,i] return x A = np.random.randint(10, size=(4,4))A = A + np.diag(A.sum(axis=0))b = A.sum(axis=1) # ainsi la solution est [1,1,1,1]print(&#39;A:\\n&#39;, A, &quot;\\nb:\\n&quot;, b, &quot;\\n&quot;)Jacobi(A,b, verbose=True) A: [[24 2 1 7] [ 5 19 4 6] [ 9 2 20 9] [ 2 9 9 32]] b: [34 34 40 52] L: [[24 0 0 0] [ 5 19 0 0] [ 9 2 20 0] [ 2 9 9 32]]U [[ 0 -2 -1 -7] [ 0 0 -4 -6] [ 0 0 0 -9] [ 0 0 0 0]]x = [0.8870874823 0.8448958895 0.2146829205 0.8281640711]x = [1.0957657001 1.194392389 1.0147923641 0.9351814319]x = [1.0020897014 1.0168049182 1.0265474982 0.9876765266]x = [1.0010877908 0.9980164155 1.0052544156 0.9990120918]x = [1.0002345046 0.9991440665 1.000424625 1.000106649 ]x = [1.0000225291 0.9998709979 0.9999547701 1.0000475947]x = [0.999998753 0.9999948204 0.9999796615 1.0000072549]x = [0.9999991631 1.000002211 0.9999968908 1.0000003049]x = [0.9999998564 1.0000005961 0.9999998678 0.9999998785]x = [0.9999999913 1.0000000685 1.0000000518 0.9999999667] array([1.0000000018, 0.9999999991, 1.0000000142, 0.9999999961]) " }, { "title": "SOCRA : Cours du 30 avril", "url": "/cours/posts/socra-clean-code/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-04-30 10:00:00 +0200", "snippet": "Clean code, what is it ?What is your pain ? Bugs ? Not cool when a client find a bug Coding style ? Having a bad coding style Working with others ? Coordinating actions Developer lifeâ€¦ Never thanked, only complaints !By code : Compilation failed Seg fault Stack overflowBy client : ASAP Bad UX Not workingâ€¦is awesome ! We create products We discover new trades We learn !Software craftmanship manifesto Not only working software, but also well-crafted software.Not only responding to change, but also steadily adding value.Not only individuals and interactions, but also a community of professionals.Not only customer collaboration, but also productive partnership.Technical debt impact Code readbility New features development Bug fixingBeâ€¦ KISS : Keep It Simple Stupid DRY : Donâ€™t Repeat Yourself Focused YAGNI : You Ainâ€™t Gonna Need It DIE : Duplication Is Evil plz donâ€™t actually die Copy/paste is easy but hard to bug fix Simple rulesBugs are everywhere : one operation per line helps you identify the location list.Add(line.WordToString());become : var words = line.WordToString();list.Add(words);Do not ask twice for the same thing, it improves your system perfs Foo(lines.Where(l =&amp;gt; l.section == null).ToArray());Bar(lines.Where(l =&amp;gt; l.section == null).ToArray(), lines);become : var linesWithSection = lines.Where(l =&amp;gt; l.section == null).ToArray();Foo(linesWithSection);Bar(linesWithSection, lines); Everytime ask yourself : Sould I be able to understand my code in 6 months ? One year ? Use explicit names Read your code Code phrasesHow ?OO Principles Encapsulation Inheritance Polymorphism Overloading Templates / Generics Subtypings S.O.L.I.D. Snake SRP : Single Responsibility Principle OCP : Open/closed principle LSP : Liskov Substitution Principle ISP : Interface Segregation Principle DIP : Dependency Inversion PrincipleSingle Responsibility PrincipleA class should have only one reason to change. public class Person { public String Name { get; set; } public String Email { get; set; } public Person(String Name, String email) { Name = name; Email = email; ValidateEmail(); } private void ValidateEmail() { // throw if not an email }} public class Person{ public String name { get; set; } public Email Email { get; set; }}public class Email{ public String Adress { get; private set; } public Email(String address) { Address = address; ValidateEmail(); } private void ValidateEmail() { // throw if not an email }}Open/Close PrincipleSoftware entities should be open for extension, but closed for modification. public class Greeter { String formality; public String Greet() { if (this.formality == &quot;formal&quot;) { return &quot;Good evening, sir.&quot;; } else if (this.formality == &quot;casual&quot;) { return &quot;Sup bro?&quot;; } else if (this.formality == &quot;intimate&quot;) { return &quot;Hello Darling!&quot;; } else { return &quot;Hello.&quot;; } } public void SetFormality(String formality) { this.formality = formality; }} public class Greeter { private Personality personality; public Greeter(Personality personality) { this.personality = personality; } public String greet() { return this.personality.greet(); }}Liskov Substitution Principle If $S$ is a subtype of $T$, then objects of type $T$ in a program may be replaced with objects of type $S$ without altering any of the desirable properties of that program.Interface segregation principleMany client-specific interfaces are better than one general-purpose interface.Dependency Injection PrincipleOne should â€œdepend upon abstractions, not concretionsâ€. public class FileLogger { public void Info(String message) { // Write message into a file }}public class Application { private FileLogger logger; public Application() { this.logger = new FileLogger(); } public void Run() { logger.Info(&quot;Running&quot;); }} public class FileLogger : ILogger { public void Info(String message) { // Write message onto a file }}public class Application { private ILogger logger; public Application(ILogger logger) { this.logger = logger(); } public void Run() { logger.Info(&quot;Running&quot;); }}Be AgileV CycleAgileSCRUMMethodology Product owner Scrum master Developer team BacklogWorkflow Sprint Meeting Planning Plan what needs to be done for the next version Daily Scrum Meeting where are we at Sprint Retrospective what is well done, what is not, etc. KANBANTickets per actionThink testsWhy do we test ? Tests to help understand requirements Tests protects future developments Tests are a fall protection We are human after allHow do we test ? We create code to test our code. Unit Test : Focus on ONE function usage, mock dependencies Integration Test : Crosses the boundary between components Behaviour Test : An example of the user using the systemThe test pyramidTDD : Test Driven DevelopmentNo code without a test Write a test which fails Write the code which fulfil the test Refactor source code (feature and test !)What is a good unit test ? Easy to understanf, clear when it fails Determinist Focused AAA : Arrange / Act / AssertBDD : Behaviour Driven Development A simple test : Givenâ€¦â€¦Whenâ€¦â€¦.Thenâ€¦â€¦. Given a user with an account When he tries to create a new account with existing account credentials Then it must be logged in with the existing account The double loopTest coverage A 100% covergae is not a bug-free code." }, { "title": "CCMP2 : Intermediate Representation", "url": "/cours/posts/ccmp2_intermediate-representation/", "categories": "S6, tronc commun, CCMP2", "tags": "S6, CCMP2, tronc commun", "date": "2020-04-27 11:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27/04Boulot qui reste a faire: Lineariser le programme Allocation des registres Gerer la pileCompilers structureEnds: front end: analysis lexical analysis (scanning) synctactic analysis (parsing) ast generation static semantice analysis (type checking) source language specific optimizations hir generation middle end: generic synthesis optimisations generiques back end: specific synthesis register allocation The gcc team suggests: front-end name (â€œa front endâ€) front-end adjective (â€œthe front-end interfaceâ€)Retargetable CompilersSi on veut generer du ARM a partir du JAVA, le trait rpz un compilateur complet. On rajoute un compilateur de JAVA a MIPS, de JAVA a IA-32, etc. et ce pour tous les compilateurs en entree.Cette strategie nâ€™est pas bonne car il y a beaucoup de compilateurs et de la duplication de code.Supposons quâ€™on aie une representation intermediaire:Il suffit plus dâ€™un traducteur de la representation intermediaire vers ARM, MIPS, etc. On a plus que 4 traducteurs, on a transforme une multiplication en addition. Comment definir cette representation intermediaire?On a besoin dâ€™une representation flexible pour pouvoir etre la cible des langages de hauts niveaux mais assez assembleur pour etre traduit en assembleur. Le front-end â€œtireâ€ le langage intermediaire vers lui Le back-end â€œtireâ€ la representation intermediaire pour etre le plus proche possible du langage assembleur Premiere idee: baricentre Affecter un poids aux langages en entree et ceux en sortie: avoir un baricentreSi tout le mone a un poids de 1, le langage intermediaire sera plutot front-end, sinon plutot backend. Comment calculer le baricentre de tous mes langages ?On fait lâ€™instersection de toutes les fonctionnalites des langages. Quâ€™est-ce qui se passe le jour ou on rajoute un nouveau langage? Le baricentre va bouger.Seconde ideeDeux langages intermediaires: un pour le front-end, un pour le back-endTraduction de Java a 1 câ€™est facile, de 1 a 2 difficile.On aura plein de petits traducteurs simples et un gros traducteur complique, on a seulement 10 traducteurs.On rajoute deux nouveaux langages intermediaires:La traduction de 1 vers 3 et de 4 vers 2 est moins dure que de 1 vers 2. On est en train de reconstruire une multiplicite de traducteurs.Idee finale couche: jâ€™enleve la partie objet couche: enlever le support des fonctions variadique couche: transformer les for en while couche: enlever une autre fonctionnalite etc.Câ€™est le desucrage. Dans notre langage intermediaire on veut desucrer notre langage en entier. Comment definir tous ces langages intermediaires?Syntax, grammaire, type-checker, etc.Deux solutions: Nouveau parser/lexer mais pas coherent On va definir des langages intermediaires mais on va jamais ecrire de parser on va definir une grammaire on va traduire lâ€™AST de notre langage original en AST du langage choisir Other Compiling Strategies Intermediate language-based strategies: SmartEiffel, GHC Bytecode strategy: Java bytecode (JVM), CIL (.NET) Hybrid approaches: GCJ (Java bytecode or native code) Retargetable optimizing back ends: MLRISC, VPO (Very Portbale Optimizer), and somehow Câ€“ (Quick Câ€“) Modular systems: LLVM (compiler as a library, centered on a typed IR). Contains the LLVM core libraries, Clang, LLDB, etc. Also: VMKit: a substrate for virtual machines (JVM, etc.) Emscripten: an LLVM-to-JavaScript compiler. Enables C/C++ to JS compilation Intermediate Representations (IR) are fundamental.Intermediate representationsFormat? Representation? Language?Intermediate representation: a faithful model of the source program â€œwrittenâ€ in an abstract language, the intermediate language may have an external syntax may be interpreted/compiled (havm, byte code) may have different levels (gccâ€™s Tree is very much like C)What language flavor ? imperative? Stack based? Register based? Functional? Most function languages are compiled into a lower lever language, eventually a simple $\\lambda$-calculus. Other?What level?A whole range of expressivities, typically aiming at making some optimizations easier: Keep array expressions? Yes: adequate for dependency analysis and related optimizations No: Good for constant folding, strength reduction, loop invariant, code motion, etc. Keep loop construcs? What level of machine independence? Explicit register names? On doit construire notre langage en essayant dâ€™etre le plus proche possible du code assembleur tout en etant suffisemment abstrait pour pas faire rentrer le nom des registresDesigning an Intermediate Representation Intermediate-language design is largely an art, not a science.Muchnink, 1997float a[20][10]...a[i][j+2]Traduction dans les langages intermediaires:t1 &amp;lt;- a[i, j+2] On va avoir besoin de temporaires pour noter les resultats intermediaires.t1 &amp;lt;- j + 2t2 &amp;lt;- i * 20t3 &amp;lt;- t1 + t2t4 &amp;lt;- 4 * t3t5 &amp;lt;- addr at6 &amp;lt;- t5 + t4t7 &amp;lt;- *t6On a une approche progressive plus agreable quâ€™une approche directe.r1 &amp;lt;- [fp - 4]r2 &amp;lt;- r1 + 2r3 &amp;lt;- [fp - 8]r4 &amp;lt;- r3 * 20r5 &amp;lt;- r4 + r2r6 &amp;lt;- 4 * r5r7 &amp;lt;- fp - 216f1 &amp;lt;- [r7 + r6]Sans la traduction precedente, il est impossible de comprendre comment cette traduction fonctionne.GCCStack Based: Java Byte-Codeclass Gcd { static public int gcd(int a, int b) { while (a != b) { if ( a &amp;gt; b) a -= b; else b -= a; } return a; } static public int main(String[] arg) { return gcd(12, 34) }}Stack Based (Edwards, 2003)Advantages Trivial translation of expressions Trivial interpreters No pressure on registers Often compactDisadvantages Does not fit with todayâ€™s architecture Hard to analyze Hard to optimizeRegister Based tcâ€™s Tree Une representation sous forme de registre est fatalement plus verbeux.Du a: La pile Lâ€™epilogue Le prologueChaque fonction utilise un certain nombre de registres, il y a beaucoup de travails supplementaires pour maintenir la coherence des registres.Register Based: What structure ?How is the structure coded ? Addresses Expressions and instructions have names or (absolute) addresses. (Stack based is a bit like relative address) 2 address instructions ? (triples) 3 addresses instructions ? (quadruples) Quadruples vs Triples:i &amp;lt;- i + 1t1 &amp;lt;- i + 1t2 &amp;lt;- p + 4t3 &amp;lt;- *t2p &amp;lt;- t2t4 &amp;lt;- t1 &amp;lt; 10*r &amp;lt;- t3if t4 goto L1(1) i + 1(2) i sto (1)(3) i + 1(4) p + 4(5) *(4)(6) p sto (4)(7) (3) &amp;lt; 10(8) *r sto (5) (9) if (7), (1)On note le resultat de chaque ligne dans (nb). Autant ne pas prendre cette strategie et prendre une proche des microprocesserus actuels.Register Based (Edwards, 2003)Advantages: Suit todayâ€™s architecture Clearer data flowDisadvantages Harder to synthesize Less compact Harder to interpretTreeOn a besoin dâ€™un langage intermediaire qui nous sert de support pour le reste du coursGrammarTree sampleMemory managementOn en train de faire remonter les infos du microprocesseur au langage intermediaire, on doit gerer le minimum possible de la memoire pour rester abstraitMemory HierarchyDifferent kinds of memory in a computer, with different performances: Registers Small memory units built on the CPU L1 Cache Last main memory acces results L2 Cache (MB, 10 cycles) Memory The usual ram (GB, 100 cycles) Storage Disks (100GB)Use the registers as much as possibleRegister Overflow Si notre langage a pas la recursion, on nâ€™a pas de pile a gerer.What if there are not enough registers ? Use the main memory, but how?Recursion: Without: Each name is bound once. It can be statically allocated a single unit of main memory (Cobol, Concurrent Pascal, Frotran)\\ With: a single name can be part of several concurrent bindings. Memory allocation must be dynamicDynamic Memory AllocationDepending on the persistence, several models: Global: global object whose liveness is equal to that of the program, are statically allocated Automatic: liveness is bound to that of the host function Heap: Liveness is indenpendant of function liveness User controlled: malloc/free Garbage collected StackActivation Blocks In recursive languages, a single routine can be â€œopenedâ€ several times concurrently An activation designates one single instance of execution Automatic variables are bound to the liveness of the activation Their location is naturally called activation block or stack frameActivation Blocks ContentsData to store on the stack: arguments: incoming local varibales: user automatic variables return address: where to return saved registers: the callerâ€™s environment to restore temp: compiler automatic variables, spills static link: when neededActivation Blocks LayoutEst-ce quâ€™on peut mettre le content dans lâ€™ordre que je veux ? On doit decider dâ€™un layout respecte par tous les compilateurs.The layout is suggested by the constructor. fp: frame pointer sp: stack pointer Au milieu de ces 2 pointers on a notre block dâ€™activation. Lors dâ€™un appel de fonction, on descend fp sur sp puis on descend sp. On doit etre capable de stocker lâ€™ancienne valeur de fp.Flexible Automatic Memoryauto: Static size, automatic memorymalloc: Dynamic size, persistent memoryAutomatic memeory is extremely convenientintopen2(char* str1, char* str2, int flags, int mode){ char name[strlen(str1) + strlen(str2) + 1]; strcpy(strcpy(name, str1), str2); return open(name, flags, mode)}On est en train de faire un tableau dynamique.On est sur une variable locale stockee sur la pile, cad stockee sur le bloc dâ€™activation. On doit etre capable de preallouer la zone necessaire. Hors ici on dit que la taille de la zone depend des parametres au runtime et ne sera pas connu lors de la compilation.Pour une meme fonction f, on peut avoir des blocs dâ€™activation de taille variable. Au moment ou on rentre dans la fonction on doit pousser le stack pointer vers le bas avec alloca:intopen2(char* str1, char* str2, int flags, int mode){ char *name = (char *) alloca(strlen(str1) + strlen(str2) + 1); strcpy(strcpy(name, str1), str2); return open(name, flags, mode)Advantages of alloca Using alloca wastes very little space and is very fast On peut simuler allocaNonlocal variables Une variable est consideree comme une variable non locale si elle est declaree dans une fonction englobante et utilisee dans une autre fonction imbriquee.escapes-n-recursionlet function trace(fn: string, val: int) = (print(fn); print(&quot;(&quot;); print_int(val); print(&quot;)&quot;)) function one(input : int) = let function two() = (trace(&quot;two&quot;, input); one(input - 1)) in if input &amp;gt; 0 then (two(); trace(&quot;one&quot;, input)) endin one(3); print(&quot;\\n&quot;)endResultat de lâ€™execution:" }, { "title": "CAMA : ma12 MÃ©thodes itÃ©ratives", "url": "/cours/posts/ma12-methode-iterative/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-27 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27 / 04La simulation numÃ©rique Pour faire cette image, on transforme des Ã©quations physique en systÃ¨mes matriciels ou les inconnues sont dÃ©finies en chaque point dâ€™un maillage a dÃ©finir.Dans ce cas lâ€™inconnue est la pression et le maillage est une boÃ®te imaginaire comprenant lâ€™avion et lâ€™air qui circule autour.Si la boÃ®te est un cube avec 1000 points dans chaque direction, on a 1 milliard de points et une matrice a 1 trillion dâ€™Ã©lÃ©ments : \\(\\begin{bmatrix}a_{11} \\; a_{12} \\ldots a_{1,10^9} \\\\a_{21} \\; a_{22} \\ldots a_{2,10^9} \\\\ \\vdots \\\\a_{10^9,1} a_{n2} \\ldots a_{10^9,10^9} \\\\\\end{bmatrix}\\;\\begin{bmatrix}p_{1} \\\\p_{2} \\\\\\vdots \\\\p_{10^9} \\\\\\end{bmatrix}=\\begin{bmatrix}f_{1} \\\\f_{2} \\\\\\vdots \\\\f_{10^9} \\\\\\end{bmatrix}\\)Cela prendrait 300 000 ans Ã  inverser la matrice. Inverser une matrice ou rÃ©soudre par une mÃ©thode directe nâ€™est pas la bonne solution pour rÃ©soudre un grand systÃ¨me matriciel.MÃ©thodes itÃ©ratives Les mÃ©thodes itÃ©ratives sâ€™approchent pas Ã  pas de la solution recherchÃ©e et permettent de trouver une approximation de ${\\bf x}$ dans $A\\, {\\bf x} = b$.On arrÃªte le calcul lorsquâ€™on est Ã  une distance choisie de la solution, appelÃ©e lâ€™erreur. On cherchera jamais Ã  avoir une erreur plus petite que notre prÃ©cision maximale.On a une formule $\\; {\\bf x}^{t+1} = B \\, {\\bf x}^t + {\\bf c}\\;$ ou en Python:x = np.random(size = c.size)while np.square(x - old_x) &amp;gt; seuil: old_x = x x = B @ x + cSi ${\\bf x}$ converge on a atteint un point fixe, c.a.d ${\\bf x}^{t+1} = {\\bf x}^t$ et donc $${\\bf x}^t = B \\, {\\bf x}^t + {\\bf c} \\quad \\textrm{c.a.d.} \\quad (Id -B) \\, {\\bf x}^t = {\\bf c}$$MÃ©thode de Jacobi La mÃ©thode de Jacobi dÃ©coupe la matrice A en M et N avec $M$ : matrice diagonale des Ã©lÃ©ments de la diagonale de $A$ $N = M - A$ (donc 0 sur la diagonale et lâ€™opposÃ© des Ã©lÃ©ments de $A$ ailleurs) Le systÃ¨me Ã  resoudre est $(M - N) {\\bf x} = {\\bf b}$.La formule iterative pour $k + 1$ est : \\(M \\; {\\bf x}^{k+1} = N\\; {\\bf x}^k + {\\bf b}\\)Comme $M$ est une matrice diagonale :\\(\\begin{array}{l}a_{11} x_1^{k+1} = \\qquad -a_{12} \\, x_2^k - a_{13} \\, x_3^k \\ldots - a_{1n} \\, x_n^k + b_1 \\\\a_{22} x_2^{k+1} = -a_{21} \\, x_1^k \\qquad - a_{23} \\, x_3^k \\ldots - a_{2n} \\, x_n^k + b_2 \\\\a_{33} x_3^{k+1} = -a_{31} \\, x_1^k - a_{32} \\, x_3^k \\qquad \\ldots - a_{3n} \\, x_n^k + b_3 \\\\ \\vdots \\\\a_{nn} x_n^{k+1} = -a_{n1} \\, x_1^k - a_{n2} \\, x_3^k \\ldots - a_{n-1,n-1} \\, x_{n-1}^k \\qquad + b_n \\\\\\end{array}\\)Pour calculer $x_i^{k+1}$ il faut diviser par $a_{ii}$ donc il faut que $A$ nâ€™ait pas pas de zÃ©ro sur sa diagonale.A = np.random.randint(10, size=(4,4))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[2 2 6 1] [3 9 6 1] [0 1 9 0] [0 9 3 4]] b: [11 19 10 16] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[2 0 0 0] [0 9 0 0] [0 0 9 0] [0 0 0 4]]N: [[ 0 -2 -6 -1] [-3 0 -6 -1] [ 0 -1 0 0] [ 0 -9 -3 0]]x = np.random.random(4)for i in range(20): x = (N @ x + b) / M...x_16 = [-4.194 -1.298 0.76 -4.026]x_17 = [6.531 3.45 1.255 6.35 ]x_18 = [-4.891 -1.608 0.728 -4.704]x_19 = [7.277 3.779 1.29 7.073] Ca ne converge pas.2e essai :A = np.random.randint(10, size=(4,4))A = A + np.diag(A.sum(axis=0))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[24 2 4 8] [ 0 24 9 3] [ 4 6 16 5] [ 6 2 1 32]] b: [38 36 31 41] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[24 0 0 0] [ 0 24 0 0] [ 0 0 16 0] [ 0 0 0 32]]N: [[ 0 -2 -4 -8] [ 0 0 -9 -3] [-4 -6 0 -5] [-6 -2 -1 0]]x = np.random.random(4)for i in range(20): x = (N @ x + b) / M...x_17 = [1. 1. 1. 1.]x_18 = [1. 1. 1. 1.]x_19 = [1. 1. 1. 1.]Pourquoi le 2e cas marche ? Pour quâ€™une mÃ©thode itÃ©rative du type ${\\bf x} = B\\; {\\bf x} + {\\bf c}$ converge il faut au choix : $\\rho(B) &amp;lt; 1\\quad$ $\\rho$ : le rayon spectral (la plus grande valeur propre en valeur absolue) $||B|| &amp;lt; 1\\quad$ oÃ¹ : \\(||B|| = \\sup_{\\bf v} \\frac{||B\\, {\\bf v}||}{||\\textbf{v}||} = \\sup_{\\textbf{v} \\, t.q. ||\\textbf{v}|| = 1} ||B\\, {\\bf v}|| = \\sup_{\\textbf{v} \\, t.q. ||\\textbf{v}|| \\le 1} ||B\\, {\\bf v}||\\) Cas de la mÃ©thode de Jacobi On respecte ces conditions si $A$ est a diagonale dominante, c.a.d. que chaque Ã©lÃ©ment de la diagonale est plus grand que tous les autres de sa ligne et colonne. Jacobi converge aussi si $A$ est symÃ©trique, rÃ©elle et dÃ©finie positive ($\\forall {\\bf x}, \\; {\\bf x}^T \\, A \\, {\\bf x} &amp;gt; 0$)." }, { "title": "CAMA : ma11 Conditionnement d&#39;une matrice", "url": "/cours/posts/ma11-conditionnement-matrice/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-27 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27 / 04Soit la matrice symÃ©trique $A$ suivante :A = np.array([[10, 7, 8, 7], [7, 5, 6, 5], [8, 6, 10, 9], [7, 5, 9, 10]])array([[10, 7, 8, 7], [ 7, 5, 6, 5], [ 8, 6, 10, 9], [ 7, 5, 9, 10]])lin.det(A) # calcul son determinant0.9999999999999869 # on peut arrondir a 1Construisons $b$ tel que $A{\\bf x} = b$ et $\\bf x = [1,1,1,1]$b = A.sum(axis=1)[32 23 33 31]x = lin.solve(A, b)array([1., 1., 1., 1.]) Perturbons $b$, comme sâ€™il y avait une erreur de mesure ou dâ€™arrondi.bp = [32.1, 22.9, 33.1, 30.9]eb = lin.norm(b - bp) / lin.norm(b) # une erreur se mesure par rapport Ã  la valeur de la donnÃ©e0.0033319453118976702On a une erreur de lâ€™ordre de $0,3\\%$. On note lâ€™erreur :\\(\\frac{||{\\bf \\delta b}||}{||{\\bf b}||}\\)Regardons la solution ${\\bf x}$ de notre systÃ¨me matriciel perturbÃ©:xp = lin.solve(A, bp)array([ 9.2, -12.6, 4.5, -1.1]) La solution nâ€™a rien nâ€™a voir avec $[1,1,1,1]$ex = lin.norm(x - xp) / lin.norm(x) #mesure de l&#39;erreur8.19847546803699Lâ€™erreur est de lâ€™ordre de 8.ex / eb2460.567236431514 Câ€™est $2460$ fois plus que lâ€™erreur sur $b$.Pourquoi ?\\(\\begin{aligned} A ({\\bf x} + {\\bf \\delta x}) &amp;amp;= {\\bf b} + {\\bf \\delta b} \\quad \\textrm{et donc} \\\\ A \\, {\\bf \\delta x} &amp;amp;= {\\bf \\delta b} \\; \\textrm{ puisque } A {\\bf x} = {\\bf b} \\quad \\textrm{et finalement}\\\\{\\bf \\delta x} &amp;amp;= A^{-1} \\, {\\bf \\delta b}\\end{aligned}\\)Comme $A$ et son inverse sont des applications linÃ©aires :\\[||{\\bf b}|| \\le ||A|| \\, ||{\\bf x}||\\quad \\textrm{et} \\quad ||{\\bf \\delta x}|| \\le ||A^{-1}|| \\, ||{\\bf \\delta b}||\\]donc :\\[\\frac{||{\\bf \\delta x}||}{||{\\bf x}||} \\le ||A^{-1}|| \\, \\frac{||{\\bf \\delta b}||}{||{\\bf x}||}\\le ||A^{-1}|| \\, ||A|| \\, \\frac{||{\\bf \\delta b}||}{||{\\bf b}||}\\]lin.norm(lin.inv(A)) * lin.norm(A)3009.5787080586942 On appelle cela le conditionnement de $A$ : \\(cond(A) = ||A^{-1}|| \\, ||A||\\)Une matrice mal conditionnÃ©e va gÃ©nÃ©rer des erreurs de calcul lors de la rÃ©solution du systÃ¨me matriciel.np.linalg.cond(A) # scipy n&#39;a pas le conditionnement mais numpy l&#39;a. 2984.0927016757555 # different de 3009Perturbons la matricenp.random.seed(0)dA = 2 * np.random.random(size = A.shape) - 1array([[ 0.098, 0.43 , 0.206, 0.09 ], [-0.153, 0.292, -0.125, 0.784], [ 0.927, -0.233, 0.583, 0.058], [ 0.136, 0.851, -0.858, -0.826]])ea = lin.norm(dA) / lin.norm(A) # erreur relative sur A0.06868857112100454Ap = A + dAarray([[10.098, 7.43 , 8.206, 7.09 ], [ 6.847, 5.292, 5.875, 5.784], [ 8.927, 5.767, 10.583, 9.058], [ 7.136, 5.851, 8.142, 9.174]])xp = lin.solve(Ap, b)array([-12.365, 15.574, 10.146, -5.94 ])ex = lin.norm(xp - x) / lin.norm(x)11.432687335993894ex / ea # valeur de l&#39;erreur166.44235204505293L&#39;erreur est moins grande. Une erreur peut fortement perturber $A$, le conditionnement et lâ€™erreur sont tous les deux importants.Pour retrouver le conditionnement de $A$ dans ce cas : \\(\\begin{align}&amp;amp; (A + \\Delta A) \\, ({\\bf x} + {\\bf \\delta x}) = {\\bf b} \\quad \\textrm{et donc} \\\\&amp;amp; A \\, {\\bf \\delta x} + \\Delta A \\, ({\\bf x} + {\\bf \\delta x}) = 0 \\; \\textrm{ puisque } A {\\bf x} = {\\bf b} \\quad \\textrm{et finalement}\\\\&amp;amp; {\\bf \\delta x} = -A^{-1} \\,\\Delta A \\, ({\\bf x} + {\\bf \\delta x}) \\quad \\textrm{et} \\\\&amp;amp; ||{\\bf \\delta x}|| \\le ||A^{-1}|| \\, ||\\Delta A|| \\, ||{\\bf x} + {\\bf \\delta x}||\\end{align}\\)Donc \\(\\begin{align}\\frac{||{\\bf \\delta x}||}{||{\\bf x} + {\\bf \\delta x}||}\\le ||A^{-1}|| \\, ||\\Delta A|| = ||A^{-1}|| \\, ||A|| \\, \\frac{||\\Delta A||}{||A||}\\end{align}\\)et\\(\\begin{align}\\frac{||{\\bf \\delta x}||}{||{\\bf x} + {\\bf \\delta x}||}\\le cond(A) \\, \\frac{||\\Delta A||}{||A||}\\end{align}\\)PropriÃ©tÃ©s $cond(A) \\ge 1$ car $Id = A\\, A^{-1}$ et donc $1 \\le Â  A Â  \\, Â  A^{-1} Â  $ $cond(A) = cond(A^{-1})$ $\\displaystyle cond_2(A) = \\frac{\\max_i \\lambda_i }{\\min_i \\lambda_i }$ si la matrice est rÃ©elle 2 indique quâ€™on utilise la norme 2 $\\lambda_i$ sont les valeurs propres de A vp = lin.eigvals(A)vp.max() / vp.min() si A est unitaire ou orthogonale : $cond_2(A) = 1$ le conditionnement nâ€™est pas modifiÃ© par transformation unitairePrÃ©conditionnement Le conditionnement peut etre tranformÃ© : \\(\\forall A, \\exists B \\; \\textrm{appelÃ©e matrice de prÃ©conditionnement t.q.} \\quad cond(B\\, A) &amp;lt; cond(A)\\) On rÃ©soud $B\\, A {\\bf x} = B\\, {\\bf b}$." }, { "title": "CAMA : ma10 SystÃ¨me d&#39;Ã©quations", "url": "/cours/posts/ma10-systeme-equations/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-26 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 26 / 04SystÃ¨mes matriciels Un systÃ¨me de plusieurs Ã©quations Ã  autant dâ€™inconnues peut sâ€™Ã©crire comme systÃ¨me matriciel $A {\\bf x} = {\\bf b}$ : \\(\\begin{bmatrix}a_{11} a_{12} \\ldots a_{1n} \\\\a_{21} a_{22} \\ldots a_{2n} \\\\ \\vdots \\\\a_{n1} a_{n2} \\ldots a_{nn} \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1} \\\\x_{2} \\\\\\vdots \\\\x_{n} \\\\\\end{bmatrix} =\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\vdots \\\\b_{n} \\\\\\end{bmatrix}\\)ExempleOn achetÃ© 3 fois des quantitÃ©s de fruits dont nous nâ€™avons pas le prix.# A est la quantitÃ© de chaque fruit achetÃ©e# x est le prix de chaque fruit# b est la somme qu&#39;on a payÃ© pour chaque courseA = np.array([[6,5,4], [5,3,2], [7,3,2]])b = np.array([11.7, 7.9, 9.5])x = lin.inv(A) @ barray([0.8, 0.9, 0.6])RÃ©solution dâ€™un systÃ¨me matricielMÃ©thode du pivot de Gauss On transforme $A$ en une matrice triangulaire pour rÃ©soudre le systÃ¨me de $O(n^2)$ opÃ©rations.On met des $0$ sur la premiÃ¨re colonne en dessous de la diagonale en multipliant $A$ par la matrice $E_1$ suivante : \\(E_1 = \\begin{bmatrix}\\;1 \\quad 0\\; 0 \\ldots 0 \\\\\\frac{-a_{21}}{a_{11}} \\, 1\\; 0 \\ldots 0 \\\\\\frac{-a_{31}}{a_{11}} \\, 0\\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{-a_{n1}}{a_{11}}\\; 0\\; 0 \\ldots 1 \\\\\\end{bmatrix}\\)$E_2$ sera similaire avec des termes $\\frac{-a_{k2}}{a_{22}}$ sous la diagonale, de mÃªme pour les matrices $E_n$ suivantes. Si on multiplie $A$ par $E_1$ il faut Ã©galement multiplier $b$ par $E_1$.SystÃ¨me matriciel avec matrice triangulaire Il faut rÃ©soudre $U{\\bf x} = c$ avec $U$ une matrice triangulaire supÃ©rieure.On part de la derniÃ¨re ligne et on obtient\\({\\bf x}[-1] = \\frac{c[-1]}{U[-1, -1]}\\)Une fois ${\\bf x}[-1]$ connu, on en dÃ©duit la valeur de ${\\bf x}[-2]$, puis celle de ${\\bf x}[-3]$, etc.def solve_gauss(A, b): for i in range(len(A)-1): E = np.diag(np.array([1.,] * len(A), dtype=A.dtype)) coefs = - A[i+1:,i] / A[i,i] E[i+1:,i] = coefs A[i:, i:] = E[i:,i:] @ A[i:,i:] b[i+1:] += coefs * b[i] # multiplication terme Ã  terme # A est maintenant triangulaire supÃ©rieur res = np.zeros(len(b), dtype=b.dtype) res[-1] = b[-1] / A[-1,-1] for i in range(len(A)-1)[::-1]: res[i] = (b[i] - A[i,i+1:] @ res[i+1:]) / A[i,i] return resA = 10 * np.random.random(size=(5,5))b = A.sum(axis=1)A [[5.655 3.042 3.18 9.672 8.761] [3.963 9.923 9.868 7.934 6.328] [0.697 9.189 7.799 2.046 2.184] [6.314 8.533 4.879 8.112 4.583] [3.803 6.89 2.266 6.087 0.361]] b [30.31 38.015 21.914 32.42 19.407]solve_gauss(A, b)DÃ©composition Lower Upper Si on a besoin de rÃ©soudre plusieurs systÃ¨mes matriciels avec $A$, on dÃ©compose $A$ en un produit dâ€™une matrice triangulaire infÃ©rieure et dâ€™une matrice triangulaire supÃ©rieure.\\(A = LU\\)On utilise le pivot de Gauss mais au lieu de modifier $b$, on calcule lâ€™inverse de la matrice $E_n \\ldots E_2\\, E_1$ :\\(\\begin{aligned}E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= E_n \\ldots E_2\\, E_1 \\, b \\quad \\textrm{donc} \\\\(E_n \\ldots E_2\\, E_1)^{-1} \\, E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= b \\\\E_1^{-1} \\, E_2^{-1} \\ldots E_n^{-1} \\; E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= b \\\\\\end{aligned}\\) Ce calcul est simple, la matrice inverse a les valeurs opposÃ©es : \\(E_1^{-1} = \\begin{bmatrix}\\;1 \\quad 0\\; 0 \\ldots 0 \\\\\\frac{a_{21}}{a_{11}} \\, 1\\; 0 \\ldots 0 \\\\\\frac{a_{31}}{a_{11}} \\, 0\\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{a_{n1}}{a_{11}}\\; 0\\; 0 \\ldots 1 \\\\\\end{bmatrix}\\) Le produit $E^{-1} = E_1^{-1} \\,E_1^{-1} \\,E_2^{-1} \\,E_3^{-1} \\, \\ldots \\,E_n^{-1}$ est la concatÃ©nation des colonnes : \\(E^{-1} = \\begin{bmatrix}\\;1 \\quad 0\\; \\; 0 \\ldots 0 \\\\\\frac{a_{21}}{a_{11}} \\; \\; 1\\; \\; 0 \\ldots 0 \\\\\\frac{a_{31}}{a_{11}} \\, \\frac{a_{32}}{a_{22}} \\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{a_{n1}}{a_{11}}\\; \\frac{a_{n2}}{a_{22}}\\; \\frac{a_{n3}}{a_{33}} \\ldots 1 \\\\\\end{bmatrix}\\)Pour rÃ©soudre $L\\, U \\, {\\bf x} = {\\bf b}$ : on rÃ©soud $L\\, {\\bf y} = {\\bf b}$ obtenant ${\\bf y}$ on rÃ©soud $U\\, {\\bf x} = {\\bf y}$ obtenant la solution ${\\bf x}$def LU(A): L = np.diag([1.,] * len(A)) for i in range(len(A)-1): E = np.diag([1.,] * len(A)) E[i+1:,i] = - A[i+1:,i] / A[i,i] L[i+1:,i] = -E[i+1:,i] A[i:, i:] = E[i:,i:] @ A[i:,i:] return L, AA = 10 * np.random.random(size=(5,5))L,U = LU(A.copy()) # Attention, notre fonction modifie A donc si on veut le rÃ©utiliser il faut une copieA [[2.697 6.265 5.876 1.927 3.951] [2.495 0.021 9.085 0.504 9.23 ] [0.788 1.982 5.048 9.656 8.581] [3.19 7.474 8.344 0.124 2.577] [4.209 6.825 9.223 9.025 4.733]]L[[ 1. 0. 0. 0. 0. ] [ 0.925 1. 0. 0. 0. ] [ 0.292 -0.026 1. 0. 0. ] [ 1.183 -0.011 0.418 1. 0. ] [ 1.561 0.511 -0.529 -1.924 1. ]]U[[ 2.697 6.265 5.876 1.927 3.951] [ 0. -5.776 3.647 -1.279 5.574] [ 0. 0. 3.427 9.059 7.573] [ 0. 0. 0. -5.957 -5.201] [ 0. 0. 0. 0. -10.285]]A - (L @ U)array([[ 0., 0., 0., 0., 0.], [ 0., -0., 0., 0., 0.], [ 0., 0., -0., 0., 0.], [ 0., 0., 0., -0., 0.], [ 0., 0., 0., 0., 0.]])Gauss Jordan On diagonalise $A$ par des multiplications matricielles similaire Ã  celles de Gauss qui annulent aussi les termes au dessus de la diagonale : \\(E_3 = \\begin{bmatrix}1 \\; 0\\; \\frac{-a_{11}}{a_{33}} \\; 0 \\ldots 0 \\\\0 \\; 1\\; \\frac{-a_{21}}{a_{33}} \\; 0 \\ldots 0 \\\\0 \\; 0\\quad 1 \\quad 0 \\ldots 0 \\\\0 \\; 0\\; \\frac{-a_{41}}{a_{33}} 1 \\ldots 0 \\\\\\vdots \\\\0 \\; 0\\; \\frac{-a_{n1}}{a_{33}} 0 \\ldots 1 \\\\\\end{bmatrix}\\)def solve_gauss_jordan(A,b): for i in range(len(A)): d1 = np.diag([1.,] * len(A)) d1[:,i] = - A[:,i] / A[i,i] A = d1 @ A b = d1 @ b return b / np.diag(A)A = 10 * np.random.random(size=(5,5))b = A.sum(axis=1)solve_gauss_jordan(A, b)array([1., 1., 1., 1., 1.])" }, { "title": "CAMA : ma06 Vecteurs propres -- Exercice: nuage de points en 3D", "url": "/cours/posts/ma06-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 12:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30/03On a des rÃ©sultats de mesures et on sait quâ€™on doit avoir une relationquadratique entre x et y :\\[y = \\alpha \\, x^2 + \\beta \\, x + \\gamma\\]Comment trouver ces 3 coefficients ?Bien sÃ»r on va faire une analyse en composante principale mais attention, celane marche que pour les relations linÃ©aires (ca nous donne un vecteur). Aussiil faut introduire une nouvelle variable pour que notre Ã©quation soit linÃ©aire.Comment Ã©crire notre problÃ¨me pour quâ€™elle soit linÃ©aire suivant 2 variables ? Solution On dÃ©finit $y=x^2$ et ainsi $z$ sâ€™Ã©crit en fonction de $x$ et $y$.DonnÃ©es de lâ€™expÃ©rienceFabriquer un nuage de point 3D avec nos 3 variables en choisissant les inconnuescomme indiquÃ© dans lâ€™Ã©quation ci-dessous :\\[y = -1.3 \\, x^2 + 0.2 \\, x + 1.45 + U(-1,1) \\quad \\textrm{avec U la loi uniforme qui simule du bruit.}\\]N = 50x = 6 * np.random.rand(N) - 3nuage = np.array(...)fig = go.Figure(data=[go.Scatter3d(x=nuage[0,:], y=nuage[1,:], z=nuage[2,:], mode=&#39;markers&#39;)]) Solution N = 50x = 6 * np.random.random(N) - 3 # x varie entre -3 et 3z = -1.3 * np.square(x) + 0.2 * x + 1.45 + (2*np.random.random(N) - 1)nuage = np.array([x,z]) plt.plot(nuage[0], nuage[1], &#39;x&#39;)plt.title(&#39;Un nuage de points&#39;)plt.axis(&#39;equal&#39;); Calculs pour trouver les caractÃ©ristiques de notre nuageFabriquer Ã  partir de notre nuage de points 2D un nuage de points 3D en introduisant la nouvelle variable quâ€™on a choisit.Le nouveau nuage sâ€™appelle nuage3D. Solution y = np.square(nuage[0])nuage3D = np.array([x,y,z]) fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;)])fig.show()fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;)])fig.show() Matrice de covarianceCalculer la matrice de covariance de notre nuage et ses vecteurs propres (on stockera les vecteurs propres dans la variable vec). Solution cov = np.cov(nuage3D.copy()) array([[ 2.723, -0.146, 0.649], [-0.146, 7.802, -9.982], [ 0.649, -9.982, 13.184]]) val, vec = lin.eig(cov) [20.852+0.j 2.733+0.j 0.124+0.j][[ 0.033 -0.994 -0.107] [-0.607 -0.106 0.787] [ 0.794 -0.039 0.607]] # On trie suivant la norme des valeurs propres par ordre dÃ©croissant (ce n&#39;est pas triÃ© par dÃ©faut)idx = np.argsort(val)[::-1]val = val[idx]vec = vec.T[idx].T # ce sont les colonnes qu&#39;il faut ordonner et non les lignesprint(val, &#39;\\n&#39;, vec) [20.852+0.j 2.733+0.j 0.124+0.j] [[ 0.033 -0.994 -0.107] [-0.607 -0.106 0.787] [ 0.794 -0.039 0.607]] fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;), go.Scatter3d(x=[0,-5*vec[0,0]], y=[0,-5*vec[1,0]], z=[0,-5*vec[2,0]]), go.Scatter3d(x=[0,vec[0,1]], y=[0,vec[1,1]], z=[0,vec[2,1]])])fig.show() Vecteur propreQue peut-on dÃ©duire de notre premier vecteur propre ? Solution Il nous donne la direction principale du nuage de point. En regardant bien la figure on voit que le vecteur dÃ©pend de y mais pas de x donc il nous donne la composante de y (c.a.d. celle de xÂ²). alpha = vec[2,0] / vec[1,0] # la pente du premier vecteur propre -1.3064566708285197 Nuage de point en 2DCrÃ©er un nuage de point en 2D qui ne prend plus en compte lâ€™impact du coefficient que lâ€™on vient de trouver. Solution On appelle ce nouveau nuage nuage2D (ce nâ€™est pas le mÃªme que notre nuage initial). nuage2D = np.array([nuage3D[0], nuage3D[2] - alpha * nuage3D[1]]) plt.plot(nuage2D[0], nuage2D[1], &#39;x&#39;)plt.axis(&#39;equal&#39;); DeductionQue peut-on en dÃ©duire ? Solution cov = np.cov(nuage2D.copy()) array([[2.723, 0.459], [0.459, 0.419]]) val, vec = lin.eig(cov) [2.811+0.j 0.331+0.j][[ 0.982 -0.188] [ 0.188 0.982]] Valeurs finalesDonner les valeurs de $\\alpha, \\beta, \\gamma$ que vous avez trouvÃ©es Ã  partir de votre nuage de point 3D initial. Solution beta = vec[1,0] / vec[0,0] 0.1916825747224307 moyenne = nuage2D.mean(axis=1)print(&#39;Moyenne des points du nuage :&#39;, moyenne)eq_droite = lambda x: beta * (x - moyenne[0]) + moyenne[1]print(&quot;Le dÃ©calage verticale est de &quot;, eq_droite(0))gamma = eq_droite(0) Moyenne des points du nuage : [0.228 1.328]Le dÃ©calage verticale est de 1.2847052624609907 print(&quot;Les coefficients de z fonction polynomiale de degrÃ© 2 en x sont :\\n&quot;)print(f&quot;alpha = {alpha}&quot;)print(f&quot;beta = {beta}&quot;)print(f&quot;gamma = {gamma}&quot;) Les coefficients de z fonction polynomiale de degrÃ© 2 en x sont :alpha = -1.3064566708285197beta = 0.1916825747224307gamma = 1.2847052624609907 " }, { "title": "CAMA : ma01 et ma02 - Exercices", "url": "/cours/posts/cama_exos/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 11:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1.1Ã‰crire sous forme dâ€™un produit matriciel la symÃ©trie axiale par rapport Ã  un axe qui ne passe pas par (0,0). On prendra lâ€™axe qui passe par (2,0) et qui a un angle de Ï€/3 par rapport Ã  lâ€™horizontale.Est-ce un automorphisme orthogonal ? Le montrer. Solution def R3(Î±): return np.array([[np.cos(Î±), -np.sin(Î±), 0], [np.sin(Î±), np.cos(Î±), 0], [0, 0, 1]])Sx3 = np.array([[1,0,0], [0,-1,0], [0,0,1]])def T(v): # translation of v T = np.identity(3) T[0:2,2] = v return TÎ¸ = np.pi / 3a = np.array([2,0])S = T(a) @ R3(Î¸) @ Sx3 @ R3(-Î¸) @ T(-a)print(&quot;Matrix of symmetry:\\n&quot;, S)shape2 = S @ shape1_3dplt.plot(shape1[0], shape1[1], &quot;:&quot;)plt.plot(shape2[0], shape2[1])plt.plot([a[0]-3*np.cos(Î¸),a[0]+np.cos(Î¸)],[a[1]-3*np.sin(Î¸),a[1]+np.sin(Î¸)], &quot;-.&quot;) # axe de symÃ©trieplt.axis(&#39;equal&#39;); Matrix of symmetry: [[-0.5 0.866 3. ] [ 0.866 0.5 -1.732] [ 0. 0. 1. ]] # Ce n&#39;est pas un automorphisme orthogonal car S n&#39;est pas orthogonale :S @ S.T array([[10. , -5.196, 3. ], [-5.196, 4. , -1.732], [ 3. , -1.732, 1. ]]) Exercice 3.1 (rotation de la camÃ©ra autour de son axe)On a indiquÃ© que ğœƒ est lâ€™angle que la camÃ©ra fait par rapport Ã  lâ€™horizontal (Ã  supposer que dans le monde rÃ©el un des axes est la verticale). Ajouter Ã  toutes les transformations la possibilitÃ© de faire tourner la camÃ©ra sur son axe principal. Solution # on fait une simple matrice de rotation autour de z aprÃ¨s Ãªtre dans le repÃ¨re de la camÃ©raroll = lambda t: np.array([[np.cos(t), -np.sin(t), 0, 0], [np.sin(t), np.cos(t), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) view(F(2.3) @ roll(np.pi/4) @ R @ T(c)) Exercice 3.2DÃ©finir la direction dans laquelle regarde la camÃ©ra avec un vecteur et non 2 angles de rotation. RÃ©digez pour expliquer vos calculs.direction = [1,1,0] # Ã  gauche Ã  45 degrÃ© Solution On a vu que dans la monde 3D rÃ©el la direction initiale de la camÃ©ra est x. Il faut transformer la nouvelle direction quâ€™on nous donne pour la camÃ©ra en 2 angles de rotation ce qui donnera nos 2 matrices de rotation. On calcule les angles en fonction de la direction donnÃ©e grace aux formules de trigonomÃ©trie quâ€™on retrouve sur le cercle unitÃ©. En 2D on a : $x=\\cos(\\alpha)$ $y=\\sin(\\alpha)$ Donc si on a la direction (x,y) cela veut dire que lâ€™angle qui nous intÃ©resse est $\\alpha=\\arccos(x)$ mais ATTENTION cela nâ€™est juste que si la direction est de norme = 1. Aussi on prend le ratio entre x et y qui est Ã©gale au ratio des valeurs normÃ©es. Ainsi\\(\\alpha=\\arctan(y/x)\\)En 3D on doit se rapportee au cas 2D qui diffÃ©re suivant quâ€™on cherche lâ€™angle vertical ou horizontal. La rotation horizontale se fait dans le plan [x,y] : $x=\\cos(\\psi)$ $y=\\sin(\\psi)$ et donc\\(\\psi=\\arctan(y/x)\\)La rotation verticale se fait dans le plan [x+y, z] avec $\\psi\\in[âˆ’\\pi/2,\\pi/2]$ $ Â  x+y Â  =cos(\\phi)$ $z=\\sin(\\phi)$ et donc\\(\\phi=\\arctan(z/||x+y||)\\) def D(direction): if len(direction) == 2: # 2 angles ah = direction[0] av = direction[1] else: # on convertit la direction en angle norm = np.sqrt(direction[0]**2 + direction[1]**2) if norm == 0: # alors c&#39;est vertical ah = 0 av = 1 else: av = np.arctan(direction[2]/norm) if direction[0] == 0: if direction[1] != 0: ah = np.sign(direction[1]) * np.pi/2 else: ah = np.arctan(direction[1]/direction[0]) print(ah, av) if type(ah) == int: ah = ah * 2 * np.pi / 360 av = av * 2 * np.pi / 360 rh = np.array([[np.cos(ah), -np.sin(ah), 0, 0], [np.sin(ah), np.cos(ah), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) rv = np.array([[np.cos(av), 0, np.sin(av), 0], [0, 1, 0, 0], [-np.sin(av), 0, np.cos(av), 0], [0, 0, 0, 1]]) return rv @ rh view(F(2.3) @ R @ D([1,1,0]) @ T(c)) 0.7853981633974483 0.0 " }, { "title": "CAMA : ma05 Vectors propres -- Applications", "url": "/cours/posts/ma05-application-vecteur-propre/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Nuage de points On peut Ã©tudier la forme dâ€™un nuage de points par une analyse en composantes principales (ACP), c.a.d. chercher les vecteurs propres de la matrice de covariance ou de corrÃ©lation.On vÃ©rifie avec un nuage de points ayant une corrÃ©lation forte entre $x$ et $y$ : \\(y = 0.2 \\, x + 1.45 + U(-1,1) \\quad \\textrm{avec U la loi uniforme qui simule du bruit.}\\)Entre x et y il y a: une pente de 0.2 un dÃ©calage vertical de 1.45 en x = 0 On essaye de retrouver la corrÃ©lation entre x et y malgrÃ© le bruit avec seulement le nuage de points.N = 50x = 6 * np.random.rand(N) - 3nuage = np.array([x, 0.2 * x + 1.45 + np.random.rand(N)])On cherche la droite qui minimise la distance entre les points et leur projection sur la droite.On construit la **matrice de covariance**, le premier vecteur propre est Ã©gal au coefficient 0.2 et est le vecteur directeur de la droite recherchÃ©e. On fait la moyenne du nuage de point dans un point de la droite. cov = np.cov(nuage.copy()) # estime la matrice de covariancearray([[2.744, 0.48 ], [0.48 , 0.168]])val, vec = lin.eig(cov)val = val.astype(&#39;float&#39;) # on convertit puisqu&#39;on sait que ce sont des rÃ©elsValeurs propres de la matrice de covariance : [2.831 0.081] Vecteurs propres de la matrice de covariance : [[ 0.984 -0.177] [ 0.177 0.984]]moyenne = nuage.mean(axis=1) # Point moyen du nuage[0.328 2.085]eq_droite = lambda x: pente * (x - moyenne[0]) + moyenne[1]Matrice de covariance La covariance entre deux variables indique Ã  quel point elles sont liÃ©es.\\(\\textrm{cov}(\\textbf{x},\\textbf{y}) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\overline{\\textbf{x}}) (y_i - \\overline{\\textbf{y}})\\) $N$ le nombre de points du nuage $\\overline{\\textbf{x}}$ et $\\overline{\\textbf{y}}$ les moyennes de $\\textbf{x}$ et de $\\textbf{y}$. La matrice de covariance exprime toutes les covariances possibles :\\[\\textrm{Cov(nuage 2D)} = \\begin{bmatrix}\\textrm{cov}(\\textbf{x},\\textbf{x}) &amp;amp; \\textrm{cov}(\\textbf{x},\\textbf{y}) \\\\\\textrm{cov}(\\textbf{y},\\textbf{x}) &amp;amp; \\textrm{cov}(\\textbf{y},\\textbf{y}) \\\\\\end{bmatrix}\\]cov = lambda x,y : np.dot((x - x.mean()), (y - y.mean())) / len(x)Cov = lambda x,y : np.array([[cov(x,x), cov(x,y)], [cov(y,x), cov(y,y)]])Cov(nuage[0], nuage[1])array([[2.69 , 0.47 ], [0.47 , 0.164]])Fibonnacci Tu le sais, je le sais, on le sais Fibonnacci câ€™est ca :\\(x_n = x_{n-2} + x_{n-1}\\) $x_0 = 1$ $x_1 = 1$. Quelle est la complexitÃ© pour calculer $x_n$?Ecrivons fibonnacci sous forme dâ€™un systÃ¨me matriciel :\\[x_{n-1} = x_{n-1} \\\\x_n = x_{n-2} + x_{n-1} \\\\\\]ce qui donne\\[\\begin{bmatrix}x_{n-1}\\\\x_n \\\\\\end{bmatrix} =\\begin{bmatrix}0 &amp;amp; 1 \\\\1 &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}x_{n-2}\\\\x_{n-1} \\\\\\end{bmatrix}\\] Calculer n produits matriciels nâ€™est pas rentable.Sachant que $F = P\\, D\\, P^{-1}$, avec P matrice des vecteurs propres et D matrice diagonale des valeurs propres : $$\\begin{bmatrix}x_{n}\\\\x_{n+1} \\\\\\end{bmatrix} =\\begin{bmatrix}0 &amp;amp; 1 \\\\1 &amp;amp; 1 \\\\\\end{bmatrix}^n\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}= (P\\, D\\, P^{-1})^n\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}= P\\, D^n\\, P^{-1}\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}$$On peut calculer $x_n$ en **temps constant**.fval, fvec = lin.eig(F)fval = fval.astype(&#39;float&#39;) # la matrice est symÃ©trique donc ses valeurs propres sont rÃ©ellesValeurs propres de la matrice de fibonnacci : [-0.618 1.618] Vecteurs propres de la matrice de fibonnacci : [[-0.851 -0.526] [ 0.526 -0.851]]fibo = lambda n : (fvec @ np.diag(fval**n) @ lin.inv(fvec) @ x0)[0]Google page rank Soit $N$ pages web numerotÃ©es qui font rÃ©fÃ©rence les unes aux autres. La i-iÃ¨me ligne montre par qui est rÃ©fÃ©rencÃ©e la i-iÃ¨me page web. Il y a 1 dans la j-iÃ¨me colonne si la page j cite la page i et 0 sinon.np.random.seed(42)A = np.random.randint(2,size=(8,8))for i in range(len(A)): A[i,i] = 0 # on ne compte pas les auto-rÃ©fÃ©rencementsarray([[0, 1, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0], [1, 1, 0, 0, 1, 0, 1, 1], [1, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 1, 0], [1, 1, 0, 1, 0, 1, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0]]) Le classement des pages utilise les vecteurs propres de cette matrice.val_pr, vec_pr = lin.eig(A)np.abs(vec_pr[:,0]).astype(float) # valeur des pagesA.sum(axis=1) # nombre de citationsValeur des pages : [0.217 0.153 0.376 0.489 0.243 0.514 0.47 0.071]Nombre de citations : [2 1 5 5 3 4 5 1]* La page ayant le meilleur score n&#39;a que 4 citations mais est citÃ©e par les 3 pages ayant 5 citations* une page ayant 5 citations est moins bien notÃ©e que les autres car elle n&#39;est pas citÃ©e par la meilleure pageLa matrice A est une application linÃ©aire dont l&#39;orientation principale est celle du premier vecteur propre. Le coefficient le plus important de ce vecteur indique la page web la plus importante." }, { "title": "CAMA : ma04 Vecteurs propres", "url": "/cours/posts/ma04-vecteurs-propres/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Soit A une matrice qui reprÃ©sente une application linÃ©aire quelconque. Que se passe-t-il si on lâ€™applique $n$ fois ?array([[ 0.707, 0.966, 0.966, 0.707, 0.259, -0.259, -0.707, -1.061, -1.414, -1.061, -0.707, -0. , 0.707], [-0.707, -0.259, 0.259, 0.707, 0.966, 0.966, 0.707, 0.354, 0. , -0.354, -0.707, -0.707, -0.707]])# on prend une matrice de transformation au hasard (donc probablement pas orthoganale)A = np.array([[3,2], [1,2]])as1 = np.dot(A, mouse)as2 = 3 * A @ mouse # souris 3 fois plus grande La transformation nâ€™est pas une isomÃ©trie donc la matrice nâ€™est pas orthogonale. La souris 3x plus grande est isomÃ©trique car $A$ est une application linÃ©aire.aas1 = A @ A @ mouseaaas1 = A @ A @ A @ mouseLa figure sâ€™Ã©tire suivant le vecteur $(2, 1)$ Si $A{\\bf x}$ fait tourner la souris dâ€™environ 25Â°, appliquer 2 ou 3 fois $A$ ne fait plus tourner la figure.Vecteurs propres et valeurs propres Les valeurs et vecteurs propres respectent cette priopriÃ©tÃ© : \\(A \\, {\\bf v_i} = \\lambda_i \\, {\\bf v_i}\\) $(\\lambda_i, {\\bf v_i})$ : couple valeur / vecteur propres val_propre, vec_propre = lin.eig(A)Valeurs propres de A : [4.+0.j 1.+0.j] Vecteurs propres de A (chaque vecteur propre est Ã©crit verticalement): [[ 0.894 -0.707] [ 0.447 0.707]] Les vecteurs propres sont des attracteurs qui capturent tous les points si on fait un nombre infini de multiplications par $A$.Les points sâ€™alignent sur lâ€™un des deux vecteurs propres.N = 100cercle = np.array([[np.cos(i * 2*np.pi/N), np.sin(i * 2*np.pi/N)] for i in range(N)]).Ta10c = np.array([x for x in (A10 @ cercle).T]).Ta10cn = np.array([x/lin.norm(x) for x in a10c.T]).T # a10c normÃ©nb1 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,0]) &amp;lt; 0.01 for i in range(N)]) \\ + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,0]) &amp;lt; 0.01 for i in range(N)])nb2 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,1]) &amp;lt; 0.01 for i in range(N)]) \\ + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,1]) &amp;lt; 0.01 for i in range(N)])Nombre de points proche du 1er vecteur propre : 100Nombre de points proche du 2e vecteur propre : 0Seuls les points colinÃ©aires au second vecteur propre le resteront, les autres rejoignent le premier vecteur propre.Le cas des matrices de rotationQuels sont les vecteurs propres dâ€™une matrice de rotation ?def Rot(Î¸): return np.array([[np.cos(Î¸), -np.sin(Î¸)], [np.sin(Î¸), np.cos(Î¸)]])R = Rot(2*np.pi/10)R_valp, R_vecp = lin.eig(R)Valeurs propres de R : [0.809+0.588j 0.809-0.588j] Vecteurs propres de R : [[0.707+0.j 0.707-0.j ] [0. -0.707j 0. +0.707j]]# regardons un autre angleR = Rot(2*np.pi/3)R_valp, R_vecp = lin.eig(R)Valeurs propres de R : [-0.5+0.866j -0.5-0.866j] Vecteurs propres de R : [[ 0.-0.707j 0.+0.707j] [-0.707+0.j -0.707-0.j]] Les valeurs et vecteurs propres sont des complexes Les valeurs propres ont la mÃªme norme SymÃ©trie axiale horizontale\\(Sx = \\begin{bmatrix}1 &amp;amp; 0 \\\\0 &amp;amp; -1 \\\\\\end{bmatrix}\\)Sx = np.array([[1, 0], [0, -1]])Sx_valp, Sx_vecp = lin.eig(Sx)Valeurs propres de Sx : [ 1.+0.j -1.+0.j] Vecteurs propres de Sx : [[1. 0.] [0. 1.]] Une matrice diagonale modifie que la i-iÃ¨me coordonnÃ©ee de ${\\bf x}$ par la i-iÃ¨me valeur de sa diagonale. Ses vecteurs propres sont ceux de la base dâ€™origine :D = np.diag(np.random.randint(10,size=5))D_valp, D_vecp = lin.eig(D)Valeurs propres de D : [8.+0.j 8.+0.j 4.+0.j 7.+0.j 1.+0.j] Vecteurs propres de D : [[1. 0. 0. 0. 0.] [0. 1. 0. 0. 0.] [0. 0. 1. 0. 0.] [0. 0. 0. 1. 0.] [0. 0. 0. 0. 1.]]Diagonalisation dâ€™une matrice En changeant de repÃ¨re, on peut reprÃ©senter une application linÃ©aire par une matrice diagonale contenant ses valeurs propres.\\(\\exists P \\; / \\; A = P\\, \\Lambda \\, P^{-1} \\quad\\) avec $\\Lambda$ la matrice diagonale des valeurs propres $\\lambda_i$ P matrice de passage : vecteurs propres Avec_propre @ np.diag(val_propre) @ lin.inv(vec_propre)A : [[3 2] [1 2]] ğ‘ƒ Î› inv(ğ‘ƒ) : [[3.+0.j 2.+0.j] [1.+0.j 2.+0.j] Matrice inversible : si une des valeurs propre est nulle alors $\\Lambda$ nâ€™est pas inversible et donc A nâ€™est pas inversible Matrice non diagonalisable : si lâ€™ensemble des vecteurs propres ne genere pas un espace de meme dimension que dâ€™origine, alors on ne peut pas diagonaliser la matrice" }, { "title": "CAMA : ma03 Matrice Camera", "url": "/cours/posts/ma03-matrice-camera/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03 Calculons lâ€™image que genere une camera : positionnee en $(c_x, c_y, c_z)$ regardant dans la direction $(v_x, v_y, v_z)$ avec un angle de rotation $c_\\theta$ (que lâ€™on prend = 0 pour commencer) avec une focale $f$ On a pour tout point $X$ de lâ€™espace sa position $x$ sur lâ€™image donnÃ©e par\\[x = P X\\] $P$ : matrice qui reprÃ©sente lâ€™action de la camÃ©ra. Le but est de trouver $P$.Dimensions $X$ : point en 3D on rajoute une dimension pour les translations (cf ma02) : $X = (X_x, X_y, X_z, 1)$ $x$ : point en 2D pour les translation : $x = (x_x, x_y, 1)$ $P$ matrice de dimensions $3*4$RepÃ¨res3 reperes : celui du monde en en 3D celui de lâ€™image en 2D celui de la camera en 3DFocale On reprÃ©sente la focale comme la distance entre lâ€™origine est la position virtuelle de lâ€™image 2D.Dans le repere de la camera : $x = \\frac{f}{X_z} X = f \\frac{X}{X_z}$.Si on bouge uniquement la focale, et que le repere de la camera est le meme que celui du monde alors : \\(\\textrm{si }\\quad P = \\begin{bmatrix}f &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; f &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\quad \\textrm{ on a }\\quadP X = \\begin{bmatrix}f X_x \\\\f X_y \\\\X_z \\\\\\end{bmatrix}\\) Câ€™est presque le resultat recherche, on a $x$ a un facteur $X_z$ pret.Pour garantir $x_z = 1$ on ajoute une normalisation : f = 0.5 # focaleF = lambda f: np.array([[f, 0, 0, 0], [0, f, 0, 0], [0, 0, 1, 0]])F = array([[0.5, 0. , 0. , 0. ], [0. , 0.5, 0. , 0. ], [0. , 0. , 1. , 0. ]])def normalize(x): x[0,:] /= x[2,:] x[1,:] /= x[2,:] return x[:2,:]Changement de repÃ¨re Lâ€™axe principal de la camera est $z$, soit $x$ dans le repere du monde 3D. On choisit comme repÃ¨re inital de la camÃ©ra : $(x,y,z){cam} = (y, z, x){3D}$. La matrice de passage est:\\(X_{cam} = \\begin{bmatrix}0 &amp;amp; 1 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\1 &amp;amp; 0 &amp;amp; 0 \\\\\\end{bmatrix}\\, X_{3D}\\)Pour respecter la notation $(x, y, z, 1)$ : \\(P = \\begin{bmatrix}f &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; f &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\quad\\begin{bmatrix}0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Translation de la camÃ©ra Si la camera est en $(c_x, c_y, c_z)$ et non en $(0, 0, 0)$, câ€™est une translation : \\(T = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -c_x \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -c_y \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -c_z \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Axe principal de la camÃ©raOn change la direction de la camera et son axe principal nâ€™est plus $x$ du monde 3D. Pour pointer un vecteur 3D dans une direction, il faut 2 rotations autour de 2 axes orthogonaux a notre vecteur. En 2D il suffit dâ€™une rotation autour de $z$.Pour diriger la camera dans une direction $v$, les rotations se font autour des axes $z$ et $y$ du monde: la rotation horizontale $\\psi$ tourne autour de $z$ la rotation verticale $\\phi$ tourne autour de $y$ \\(D = \\begin{bmatrix}cos(\\phi) &amp;amp; 0 &amp;amp; sin(\\phi) &amp;amp; 0 \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\-sin(\\phi) &amp;amp; 0 &amp;amp; cos(\\phi) &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\;\\begin{bmatrix}cos(\\psi) &amp;amp; -sin(\\psi) &amp;amp; 0 &amp;amp; 0 \\\\sin(\\psi) &amp;amp; cos(\\psi) &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)def D(ah, av): if type(ah) == int: ah = ah * 2 * np.pi / 360 av = av * 2 * np.pi / 360 rh = np.array([[np.cos(ah), -np.sin(ah), 0, 0], [np.sin(ah), np.cos(ah), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) rv = np.array([[np.cos(av), 0, np.sin(av), 0], [0, 1, 0, 0], [-np.sin(av), 0, np.cos(av), 0], [0, 0, 0, 1]]) return rv @ rh" }, { "title": "CAMA : ma02 Changement de repere", "url": "/cours/posts/ma02-changement-de-repere/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Matrice de passageUne matrice peut representer un changement de repere :O = np.array((0,0))I = np.array((1,0))J = np.array((0,1))A = np.array((3,3))B = np.array((5,4))C = np.array((1.5,4)) La matrice de passage sans la translation est lâ€™ensemble des vecteurs de la seconde base exprimes dans la premiere. D = np.array([(B-A), (C-A)]).T # dÃ©formation sans la translation array([[ 2. , -1.5], [ 1. , 1. ]]) Vecteurs dans le nouveau repÃ¨reOn exprime le vecteur $OJ$ dans la base rouge en utilisant la matrice de passage (lâ€™origine dâ€™un repere nâ€™est pas utile pour un vecteur) :D @ (J-O) # donne ACarray([-1.5, 1. ])Points dans le nouveau repÃ¨reIl faut prendre en compte la translation dâ€™un repere dâ€™un repere vers lâ€™autre en separant la deformation de la translation pour rester en 2D :A + D @ I # passage de I en Barray([5., 4.])On peut integrer la translation dans une matrice dâ€™une dimension superieure (cf ma01).P = np.identity(3) # definie la taille et initialise la derniere ligne (les autres seront remplacees)P[:2, :2] = D # deformationP[:2, 2] = A # translationarray([[ 2. , -1.5, 3. ], [ 1. , 1. , 3. ], [ 0. , 0. , 1. ]])def to3D(x): if len(x.shape) == 1: return np.array([*x,1]) elif len(x.shape) == 2: return np.array([*x,np.ones(len(x[0]))])P @ to3D(J) # is Carray([1.5, 4. , 1. ])Une application linÃ©aire transposÃ©e dans le nouveau repÃ¨reAppliquons une rotation qui prend un point et le fais tourner dans le sens trigonomÃ©trique de Î¸ autour de (0,0).Que fait cette rotation dans notre nouveau repere? on applique plusieurs fois une rotation au point (1,0) autour de O (le cercle bleu) on dÃ©forme le cercle bleu avec la matrice de passage P (la forme noire) on applique plusieurs fois la rotation dÃ©formÃ©e par P du point B autour de A (la forme orange pointillÃ©) Pour calculer la rotation R dans le nouveau repere : \\(Q = P \\, R \\, P^{-1}\\)avec $P^{-1}$ permettant de revenir au repere dâ€™origine pour effectuer la rotationdef Rot(Î¸): return np.array([[np.cos(Î¸), -np.sin(Î¸)], [np.sin(Î¸), np.cos(Î¸)]])def Rot3D(Î¸): return np.array([[np.cos(Î¸), -np.sin(Î¸), 0], [np.sin(Î¸), np.cos(Î¸), 0], [0, 0, 1]])# plusieurs rotation qui donnent le cercle bleu :cercle = np.array([Rot(Î±) @ I for Î± in np.linspace(0, 2*np.pi, 10)]).T# le cercle exprimÃ© dans le nouveau repÃ¨re (noir)p_cercle = P @ to3D(cercle)# construction de QQ = lambda Î¸: P @ Rot3D(Î¸) @ lin.inv(P) # dÃ©finition de Q en fonction de Î¸# on applique Q pour faire tourner B autour de A (orange)p_rot_A = np.array([Q(Î±) @ to3D(B) for Î± in np.linspace(0, 2*np.pi, 10)]).T " }, { "title": "CAMA : ma01 Transformations isometriques", "url": "/cours/posts/ma01-transformation-isometrique/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03angle = np.array([Î¸ for Î¸ in np.linspace(-np.pi/2,np.pi/2,7)])shape1 = np.concatenate([np.array([np.cos(angle), np.sin(angle)]), np.array([[-0.5, -1, -1, -1], [1, 1, 0.5, 0]]), np.array([[-0.5, 0], [-0.5, -1]])], axis=1)[[ 0. 0.5 0.866 1. 0.866 0.5 0. -0.5 -1. -1. -1. -0.5 0. ] [-1. -0.866 -0.5 0. 0.5 0.866 1. 1. 1. 0.5 0. -0.5 -1. ]]Matrice de rotation centrÃ©e en $(0, 0)$ \\(R = \\begin{bmatrix}cos(Î¸) &amp;amp; -sin(Î¸) \\\\sin(Î¸) &amp;amp; cos(Î¸) \\\\\\end{bmatrix}\\)PropriÃ©tÃ©s Effectue une rotation de centre (0,0) et dâ€™angle Î¸ DÃ©terminant = 1 Matrice orthogonale $\\rightarrow$ pas de dÃ©formation ni dâ€™agrandissement de la forme (automorphisme orthogonal)Î¸ = np.pi / 4R = np.array([[np.cos(Î¸), -np.sin(Î¸)], [np.sin(Î¸), np.cos(Î¸)]])[[ 0.707 -0.707] [ 0.707 0.707]]R @ shape1 # multiplication de matrices Matrice orthogonale donc (par dÃ©finition) $R.R^T = \\textrm{Id}$. La transposÃ©e est la rotation dâ€™angle -Î¸ puisque sinus est une fonction impaire.SymÃ©trie axiale La symÃ©trie horizontale tranformant (a,b) en (a,-b) est:\\(Sx = \\begin{bmatrix}1 &amp;amp; 0 \\\\0 &amp;amp; -1 \\\\\\end{bmatrix}\\) Pour avoir un symÃ©trie axiale par rapport Ã  une droite passant par $(0,0)$ qui a un angle $\\alpha$ : rotation pour mettre lâ€™axe de symÃ©trie a lâ€™horizontale appliquer la symÃ©trie horizontale faire la rotation inverse\\(S = R_{-Î±}^{-1}\\; Sx\\; R_{-Î±} = R_Î±\\;Sx\\; R_{-Î±}\\) def RÎ±(Î±): return np.array([[np.cos(Î±), -np.sin(Î±)], [np.sin(Î±), np.cos(Î±)]])Sx = np.array([[1, 0],[0,-1]])Î¸ = 70 * (2 * np.pi)/360 # 70 degrÃ©sRÎ±(Î¸) @ Sx @ RÎ±(-Î¸) @ shape1La rotation selon lâ€™angle est :RÎ±(Î¸) @ Sx @ RÎ±(-Î¸)[[-0.766 0.643] [ 0.643 0.766]]Translation La translation ne peut pas etre exprimÃ©e avec un produit matriciel car ce nâ€™est pas une application linÃ©aire :\\(T(2\\;\\textbf{x}) \\ne 2\\; T(\\textbf{x})\\)Ce nâ€™est pas non plus une transformation isomÃ©trique. Une translation est une addition : $T(\\textbf{x}) = \\textbf{x} + \\textbf{v}_t$. On change la reprÃ©sentation des points pour exprimer les translations sous forme de produit matriciel : $\\textbf{x} = (x_1, x_2)$ devient $\\textbf{x} = (x_1, x_2, 1)$ La translation par le vecteur $(v_1, v_2)$ est : \\(T(X) = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; v_1\\\\0 &amp;amp; 1 &amp;amp; v_2 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}x_1 \\\\x_2 \\\\1 \\\\\\end{bmatrix}\\)v = np.array([1,2])T = np.identity(3) # matrice de translationT[0:2,2] = vMatrice de translation: [[1. 0. 1.] [0. 1. 2.] [0. 0. 1.]]shape1_3d = np.concatenate([shape1, np.ones((1, len(shape1[0])))], axis=0) # rajoute une nouvelle dimension Ã  la matrice pour la translationT @ shape1_3d La matrice inverse replacant la forme orange Ã  sa position dâ€™origine applique la transition $-\\textbf{v} = (-1,-2)$.\\(T^{-1} = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; -1\\\\0 &amp;amp; 1 &amp;amp; -2 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Ce nâ€™est pas la transposÃ©e de T, T nâ€™est pas orthogonale.Il y a 2 types dâ€™isomÃ©tries : lâ€™isomÃ©trie vectorielle ou automorphisme orthogonal : $\\forall\\, \\textbf{x}, \\;||\\textbf{f}(\\textbf{x})|| = \\textbf{x}$ et conserve les angles lâ€™isomÃ©trie geomÃ©trique :$\\forall\\, \\textbf{a}, \\textbf{b}, \\; ||\\textbf{f}(\\textbf{a}) - \\textbf{f}(\\textbf{b})|| = ||\\textbf{a} - \\textbf{b}||$ La translation est une isomÃ©trie geomÃ©trique mais pas vectorielle, câ€™est un automorphisme orthogonal." }, { "title": "SEDE : Be careful with fork", "url": "/cours/posts/sede_fork/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-03-03 11:00:00 +0100", "snippet": "" }, { "title": "SEDE : Buffer overflow and better API&#39;s", "url": "/cours/posts/sede_buffer_overflow/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-02-25 11:00:00 +0100", "snippet": "" }, { "title": "SEDE : Introduction", "url": "/cours/posts/sede_intro/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-02-11 11:00:00 +0100", "snippet": "" } ]
