[ { "title": "TNSI: Filtres lineaires stationnaires - 2", "url": "/cours/posts/tnsi_filtres_lineaires_stationnaires_2/", "categories": "Image S9, TNSI", "tags": "Image, S9, TNSI", "date": "2021-12-15 14:00:00 +0100", "snippet": "Lien de la note HackmdFiltres lineaires Linearite \\(\\begin{aligned}\\mathcal H\\{ax_1[n]+bx_2[n]\\} &amp;amp;= a\\mathcal H \\{x_1[n]\\}+b\\mathcal H\\{x_2[n]\\} \\\\ &amp;amp;= ay_1[n] + by_2[n]\\end{aligned}\\) Stationnarite \\(y[n]=\\mathcal \\{x[n]\\}\\Leftrightarrow \\mathcal H\\{x[n-n_0]\\}=y[n-n_0]\\)\\[x[n] = \\sum_{p=-\\infty}^{+\\infty}x[p]\\delta[n-p]\\\\\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}x[p]\\mathcal \\{\\delta[n-p]\\}\\\\\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}x[p]h[n-p]=x \\ast h[n]\\] $h[n]$ est la reponse impulsionnelle discrete3.La causalite\\[\\mathcal H\\{x[n]\\} = \\sum_{p=-\\infty}^{+\\infty}h[p]x[n-p]\\to h[p]=0\\text{ pour } p\\lt0\\]4.Stabilite\\[\\vert\\mathcal H\\{x[n]\\}\\vert\\le \\sum_{p=-\\infty}^{+\\infty}\\vert h[p]\\vert \\vert x[n-p]\\vert \\le \\sup_{n\\in\\mathbb Z}\\vert x[n]\\vert\\sum_{p=-\\infty}^{+\\infty}\\vert h[p]\\vert\\] On parle de BIBO stability: Bounded Input Bounded output Filtres a reponse impulsionnelle finie (RIF) Filtres a reponse impulsionnelle infinie (RII) Filtre causal Filtre non causalLa TF joue un role fondamental dans l‚Äôanalyse des operateurs stationnaires\\[\\hat y (\\omega)=\\hat h(x)\\hat x(\\omega)\\quad \\omega=2i\\pi f\\quad \\omega\\in[-\\pi, \\pi]\\] $\\hat h(\\omega)$ est la fonction de transfert ou reponse frequentielle du filtre2 effets: amplitude: amplification $(\\vert \\hat h(\\omega)\\vert\\lt 1)$ phase: decalage et deformation de $x$ExempleSoit $x[n]\\to x_b[n]=x[n]+b[n]$Filtre moyenneur \\(h_{\\Pi}[n]=\\begin{cases}1 \\\\ 0\\end{cases}\\) pour $\\Pi$ echantillons.\\[\\hat h(\\omega)=\\frac{1}{\\Pi}\\frac{\\sin(\\frac{\\omega}{2}\\Pi)}{\\sin(\\frac{\\omega}{2})}e^{-\\frac{\\omega}{2}(\\Pi-1)}\\]Un filtre causal va etre centre en $0$:Un filtre non causal ne l‚Äôest pas:On a une suite d‚Äôechantillons:Si on applique un filtre causal, on va forcement avoir un decalage dans le tempsTypes de filtres Filtres a phase nulle Filtres a phase lineaire (implique un decalage en temps) Filtre a phase non lineaire\\[\\hat h(\\omega) = e^{-i\\omega a}\\\\\\hat y (\\omega)=\\hat h(\\omega)\\hat x(\\omega) = e^{-i\\omega a}\\hat x(\\omega)\\\\y[n] = x[n-a]\\]Passe-bas ideal\\[\\hat h(\\omega) = \\begin{aligned}1 &amp;amp;\\forall \\vert\\omega\\vert \\le w_c\\\\0\\end{aligned}\\\\\\hat h (\\omega)=\\Pi(\\frac{\\omega}{2\\omega_c})\\quad\\text{ou }\\Pi(x)=\\begin{cases}1&amp;amp;\\vert x\\vert\\le\\frac{1}{2}\\\\0\\end{cases}\\]Reponse impulsionnelle d‚Äôun filtre passe-bas ideal TFTd inverse\\[\\begin{aligned}h[n] &amp;amp;= \\frac{1}{2\\pi}\\int_{-\\pi}^{pi}\\hat h(\\omega)e^{i\\omega n}d\\omega\\\\&amp;amp;= \\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega}e^{i\\omega n}d\\omega\\\\&amp;amp;= \\frac{1}{2\\pi}\\frac{1}{in}(e^{i\\omega_cn}-e^{-i\\omega_cn})=\\frac{1}{\\pi n}\\sin(\\omega_cn)\\\\\\end{aligned}\\]Quand on applique une fonction porte en frequence, ca revient a faire une convolution en temps de:En augmentant le nombre d‚Äôechantillons: On introduit des artefacts numeriques dus aux approximations mathematiquesConstruire un filtre Lobe principalPente de coupure (transition abrupte de niveau) TODOEquations recurrentes a coefficients constantsOn souhaite resoudre une equation de forme:\\[\\sum_{k=0}^{N-1}a_ky[n-k]=\\sum_{k=0}^{\\Pi-1}b_kx[n-k]\\] $a_k$ equivalent a construire un filtre en passant par l‚Äôespace de Fourier $b_k$ controle l‚Äôentree pour eviter les effets indesirablesComment calculer ces coefficients ?Et la fonction de trasnfert de ce filtre ? Fourier ?\\[\\frac{\\hat y(\\omega)}{\\hat x(\\omega)}=\\frac{\\sum_{k=0}^{M-1}b_ke^{-ik\\omega}}{\\sum_{k=0}^{N-1}a_ke^{-ik\\omega}}=\\hat h(\\omega)\\]Transformee en ZLa TZ d‚Äôun signal discret $x[n]$:\\[X(z) = \\sum_{n=-\\infty}^{+\\infty}x[n]\\underbrace{z^{-n}}_{\\color{red}{\\mathbb C}}\\quad\\text{avec } R_1\\le \\vert z\\vert\\le R_2\\]La TFtd avec $z=e^{i\\omega f}$ La TFtd est egale a la TZ sur le cercle unite Pour nos filtres, il faut donc que le cercle unite appartienne au domaine de convergenceSi on reprend l‚Äôequation de depart, sa TZ:\\[Y(z)\\sum_{k=0}^{N-1}a_kz^{-k}=X(z)\\sum_{k=0}^{M-1}b_kz^{-k}\\\\Y(z)=H(z)X(z)\\\\H(z)=\\frac{\\sum_{k=0}^{M-1}b_kz^{-k}}{\\sum_{k=0}^{N-1}a_kz^{-k}}=\\color{red}{c\\frac{\\prod_{k=0}^{M-1}(1-Z_kZ^{-1})}{\\prod_{k=0}^{N-1}(1-Z_kZ^{-1})}}\\]roniqp3ihprelkwfnwlef\\[h[n] = \\frac{1}{N}(ùüô_{\\{0,\\dots,N-1\\}})\\\\\\downarrow\\\\H(z) = \\frac{1}{N}(\\sum_{n=0}^{N-1}z^{-n})\\to\\frac{1-z^{-N}}{1-z^{-1}}\\\\H(\\omega) = \\frac{1-e^{-i\\omega N}}{1-e^{-i\\omega}}\\]Specification pour la synthese de filtre Choix d‚Äôune bande passante et d‚Äôune bande stoppante Forme de la phase Limite de calcul $\\to$ le degre de la fonction de tranfert (cad $M$ et $N$) $\\omega_p$: frequence de coupure de la bande passante $\\omega_s$: frequence de coupure de la bande coupee $\\delta_p$: ondulation en bande passante $\\delta_c$: ondulation en bande coupee $(\\omega_p + \\omega_s) / 2$: frequence de coupure du filtreFiltres RII vs RIFFiltres RII Avantages Desavantage Calcul efficace (recursif) Probleme de stabilite Facile d‚Äôobtenir une attenuation forte Difficulte a construire Adapte a l‚Äôaudio Phase non lineaire \\[H(z) = \\frac{\\Sigma b_kz^{-k}}{\\Sigma a_kz^{-k}}\\]Filtre RIF Avantages Desavantage Toujours stable Probleme de stabilite Synthese optimale possible (algorithme de Parks McCellan) Difficulte a construire Phase lineaire possible Cout computationnel plus eleve \\[H(z) = \\Sigma b_kz^{-k}\\]Filtres RIIFiltres couramment utilises sont issus du monde analogiqueExercice Comparer les filtres de: Butterworth, Chebyshev I, Chebyshev II et Elliptic scipy.signal.iirfilter scipy.signal.freqs $\\to$ tracer entre $[-1, 1]$ Interpreter Suppression composante directe $\\to$ DC biais ($\\to$ signal non centre) Quel filtre frequentiel ? Supprimer $\\omega = 0$ $\\color{red}{\\text{A faire a l‚Äôaide de la TZ}}$ \\[\\color{green}{H(z) = c\\frac{\\Pi(1-\\overbrace{z_n}^{\\color{red}{\\text{zeros}}}z^{-1})}{\\Pi(1-\\underbrace{P_n}_{\\color{red}{\\text{pole}}}z^{-1})}}\\]On veut supprimer la frequence a $0$\\[H(z)=c\\frac{\\Pi(1-z_nz^{-1})}{\\Pi(1-P_nz^{-1})}\\quad\\text{on s&#39;en fiche du denominateur}\\\\\\color{red}{\\Pi(1-z_n\\underbrace{z^{-1}}_{=1})=0\\to (1-z_n\\times 1) = 0 \\\\ z_n=1}\\\\H(z) = \\overbrace{1-z^{-1}}^{z^0}\\\\H(\\omega) = 1-e^{-i\\omega n}\\to y[n] = x[n - 0] - x[n-1]\\\\H(z) = \\frac{1-z^{-1}}{1-\\alpha z^{-1}}\\to y[n]-\\alpha y[n-1]=x[n]-x[n-1] \\quad \\alpha\\in[0;1]\\\\h(\\omega) = \\frac{1-e^{-i\\omega}}{1-\\alpha e^{-i\\omega}}\\to y[n]=x[n]-x[n-1]+\\alpha y[n-1]\\]Filtres RIFConstruction optimal par minimaxAlgorithme de Parks % McClellan / algorithme de Remez Phase lineaire Oscillation en bande passante et stoppanteL‚Äôalgorithme consiste a minimiser l‚Äôoscillation maximaleLa phase lineaire est obtenue a partir d‚Äôune reponse impulsionnelle symetrique ou antisymetrique (longueur paire ou impaire)\\[H(\\omega) = A(\\omega)e^{-i\\omega\\delta + \\phi_0}\\] ¬† Symetrique Asymetrique Impaire $\\color{red}{\\text{Type I}}$ \\(\\text{Retard entier} \\\\ \\phi_0 = 0 \\\\ \\text{pas de zeros imposes}\\) $\\color{red}{\\text{Type III}}$ \\(\\text{Retard entier} \\\\ \\phi_0 = 0 \\\\ \\text{zeros imposes en }\\omega = 0 \\text{ et } \\pi\\) Paire $\\color{red}{\\text{Type II}}$ \\(\\text{Retard non entier} \\\\ \\phi_0 = \\pi/2 \\\\ \\text{zeros imposes en }\\omega = \\pi/2\\) $\\color{red}{\\text{Type IV}}$ \\(\\text{Retard non entier} \\\\ \\phi_0 = \\pi/2 \\\\ \\text{zeros imposes en }\\omega = 0\\) Exercice Designer un filtre simple par troncature en choisissant judicieusement la fenetre Creer un filtre avec scipy et l‚Äôalgorithme de minimax (signal.remez) Analyser l‚Äôimpact des parametres Solution On fait comme si Fourier se met des oeilleres On veut appliquer une fonction porte Soit $P$ impulsion d‚Äôune fonction $e$ emise a differents instant. On souhaite retrouver les instants des differentes impulsions\\[\\begin{matrix}e[n] = \\underbrace{\\sum_{k=0}^{K-1}\\alpha^k\\delta[n-k]}\\quad \\alpha\\in]0;1[&amp;amp;y[n] = (x\\ast e)[n]\\\\\\sum_{n=0}^{K-1}\\alpha^kz^{-n}=\\frac{1-\\alpha^Kz^{-K}}{1-\\alpha z^{-1}}&amp;amp;Y(z)=X(z)\\ast E(z)\\begin{aligned}&amp;amp;\\to \\frac{Y(z)}{E(z)} \\\\ &amp;amp;\\to \\frac{1}{E(z)}\\end{aligned}\\end{matrix}\\\\H(z)\\cdot Y(z)\\\\H(z) = \\frac{1-\\alpha z^{-1}}{1-\\alpha^Kz^{-K}}\\to y[n]-\\alpha y[n-1] = x[n] - \\alpha^K x[n-K]\\] Trouver un filtre a l‚Äôaide de la TZ qui permet de retrouver $x$ (en connaissant $e$) Determiner le filtre en temps" }, { "title": "ISAT: HSI", "url": "/cours/posts/isat_hsi/", "categories": "Image S9, ISAT", "tags": "Image, S9, ISAT", "date": "2021-12-10 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionHyperspectral imagesLes acquisitions dans le domaine spectral (les bandes) presente un echantillonage beaucoup plus fin.L‚Äôimage est en fausse couleur, on a des tenseurs a 3 voies: $x$, $y$ et les bandes spectrales. Sur cette image on a associe 3 bandes au RGB, c‚Äôest une reconstruction partielle mais ca permet de visualiser.C‚Äôest des images aeriennes du massif du Mont Blanc.Quelle est la variable physique qui nous interesse ? Ici, la variable physique qui nous interesse si on veut faire une analyse continue de la scene est la reflectance.S‚Äôil n‚Äôy a pas de transmission, la reflectance est directement liee a l‚Äôabsorbance.On souhaite avoir des images exploitable, on veut un rapport image/bruit suffisant. On a typiquement un seul capteur qui a un systeme de diffraction optique (prisme, etc.), la lumiere va arriver et etre diffractee et reflechie dans differentes longueurs d‚Äôonde. On n‚Äôarrive pas a voir un bloc entier tout d‚Äôun coup lors d‚Äôune acquisition Si on veut 600 bandes, on va devoir faire un compromis sur la resolution spatiale et spectrale.On va avoir des imageurs qui ont une faible resolution spatiale ($\\sim 30m$) mais il y a un 2e capteur associe qui fait l‚Äôacquisition d‚Äôune bande panchromatique.On arrive a avoir des informations assez precises sur la reflectance des differents materiaux. On a $\\sim 600$ echantillons pour la reflectance.Des qu‚Äôon passe dans l‚Äôinfrararouge, on a une reflectance plus importante, due a la presence de la chlorophyle.Toutes les bandes sur le ‚Äúred edge‚Äù ($\\sim 0.7\\mu m$), ou on a la montee raide du spectre de reflectance de la vegetation, qui permet de discriminer certaines especes. C‚Äôest la variable physique d‚Äôinteret que l‚Äôon essaie d‚Äôextraire.ExampleQuel est l‚Äôinteret de faire des acquisitions au-dela du domaine visible ?Regardons differentes bandes des plantes:Dans le proche IR: On trouve une difference dans la 3e plante (elle est en plastique)ApplicationsDans des contextes pas forcements lie a la teledetection: Detection d‚Äôhydrocarbure dans l‚Äôeau L‚Äôhuile superposee a de l‚Äôeau a un spectre relativement proche de celui de l‚ÄôeauSi on fait le traitement d‚Äôune image avec plus d‚Äôacquisition: On extrait de l‚Äôinformation ‚Äúcachee‚Äù Monitorage et caracterisation des differents mineraux Biomedical Detection de tumeurs de la peau Astronomie Telescope ‚ÄúMuse‚Äù L‚Äôart Certaines oeuvres ont des proprietes de transmittance variant selon la longueur d‚Äôonde C‚Äôest possible de detecter des couches invisibles a l‚Äôoeil nu Controle non-destructif Evolution d‚Äôun poisson dans le temps Detection precoce de la peremption de l‚Äôechantillon Spectral UnmixingUne potentielle limitation de cette imagerie qu‚Äôon trouve assez souvent: la resolution spatiale faible $\\to$ certains objets ne sont pas completement resolusOn mesure des combinaisons en fonction des spectres des elements constituant la scene.On souhaite des echantillons en reflectance, on a une conversion a faire depuis la radiance.Si on traite une image RGB, chaque pixel est un vecteur avec $3$ composantes. Ici, on a $600$ composantes, c‚Äôest une problematique liee a la grande dimension des donnees.What to mine ?On peut utiliser une bibliotheque/catalogue de spectres de differents materiaux pour l‚ÄôunmixingOn a 2 possibilites de traitement: Spectral processing Information resides in the spectral signature of the pixels Pixels can be processed independently Approaches issuing from multivariate statistics and linear algebra Objects of interest could by sub-pixel size Analysis done on the full image Spatial processing Information resides in the spatial organization of pixels Pixels are processed together (analysis done on local parts of the image) Use image processing tools Objects of interest are fully resolved Analysis of the spectral domainHSI scene classificationSpectral classificationHigh number of features ? When the dimensionality of the problem is high How calssification accuracy depends upon the dimensionality (and amount of training data)? Computational complexity of designing the classifier ? Classification accuracy Bayes error depends on the number of statistically independant features Exampe: consider binary classification problem with $p(x\\vert \\omega_j)\\sim\\mathcal N(\\mu_j,\\Sigma_j)$ $(j=1,2)$, when $P(\\omega_{1,2})=0.5$: \\[P(e) = \\frac{1}{\\sqrt{2\\pi}}\\int_{r/2}^{+\\infty}e^{-\\frac{u^2}{2}}du\\] with $r^2=(\\mu_1-\\mu_2)^T\\Sigma^{-1}(\\mu_1-\\mu_2)$ the squared Mahalanobis distance $P(e)\\searrow$ for $r\\nearrow$ In the case of conditionally independent features $\\Sigma = \\text{diag}(\\sigma_1^2,\\dots,\\sigma_d^2)$ $r^2 = \\sum_{i=1}^d(\\frac{\\mu_{i,1}-\\mu_{i,2}}{\\sigma_2})^2$ Il y a des zones ou on a un recouvrementOn peut augmenter la dimensionnalite, rajouter un descripteurAttention a la malediction de la dimensionnalite Intuition fails in high dimensions Curse of dimensionality (Bellman, 1961): many algorithms working fine in low dimensions become intractable when the input is high-dimensional Generalizing correctly becomes exponentially harder as the dimenonality grows, because a fixed-size training set covers a smaller fraction of the input space In high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful Similarity measures based on $l_k$ norms loose meaning with respect to $k$ in high dimensions $l_1$ norm (Manhattan distance metric) is more preferable thant the Euclidean distance metric $(l_2)$ for high dimensional data miningHSI in high dimensions Volume of a hypersphere The volume of a hypersphere of radius $r$ in a $p$-dimensional \\[V_s(r)=\\frac{r^p\\pi^{\\frac{p}{2}}}{\\Gamma(\\frac{p}{2}+1)}\\] Volume of a hypercube $[-r, r]^p$ \\[V_c(r) = (2r)^p\\] The fraction of the volume contained in the inscribed hypersphere \\[f_{p_1}=\\frac{V_s(a)}{V_c(a)}=\\frac{\\pi^{\\frac{p}{2}}}{2^p\\Gamma(\\frac{p}{2}+1)}\\] Fraction of the volume of a thn spherical shell defined by a sphere of radius $r$ inscribede inside a sphere of radius $(r-\\varepsilon)$ to the volume of the entire sphere: \\(\\begin{aligned}f_{p_2}&amp;amp;=\\frac{V_s(r)-V_s(r-\\varepsilon)}{V_s(r)}\\\\&amp;amp;=\\frac{r^p-(r-\\varepsilon)^p}{r^p}\\\\&amp;amp;= 1-\\biggr(1-\\frac{\\varepsilon}{r}\\biggr)^p\\end{aligned}\\)On veut voir le rapport du volume entre une sphere et le carre qui inscrit la sphere. Small sample size Number of samples for accurate classification: Si on n‚Äôa pas assez d‚Äôechantillon pour notre estimation, notre estimation ne sera pas robuste Curse of dimensionality ! Computational complexity The blessing of non-uniformity In most application examples are not spread uniformly throughout the instance space, but are concentrated on or near a lower-dimensional manifold Intrinsic dimensionality of the data might be difficult to estimate in real data Dimensionality reduction Dimension reduction aims at representing data in a reduced number of dimensionsReasons: Easier data analysis Improved classifcation accuracy More stable representation Removal of redundant or irrevelant information Attempt to discover underlying structure by obtaining a graphical representation Dimensionality reduction is usually obtained by feature selection or extraction Feature selection keeps only some of the features according to a criterion leading to new subset of features with lower dimensionality\\[x&#39;=[x_1,x_2,x_3,x_4,\\dots,x_d]^T\\\\x&#39;=A^Tx\\] with\\[A=\\begin{pmatrix}\\color{red}{1}&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;\\color{red}{0}&amp;amp;0&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;0&amp;amp;\\color{red}{1}&amp;amp;0&amp;amp;\\dots&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;\\color{red}{0}&amp;amp;\\dots&amp;amp;0\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;\\dots\\color{red}{1}\\end{pmatrix}\\] Feature extraction transform the data in a space of lower dimensionality with an arbitrary function $f$\\[x&#39;=f(x)\\quad\\text{with } f:\\mathbb R^d\\to\\mathbb R^n, n\\lt d\\]Example: Color compositeThe pigment in plant leaves, chlorophyll, strongly absorbs visible light (from $0.4$ to $0.7\\mu m$) for use in photosynthesis. The cell structure of the leaves, on the other hand, strongly reflects near-infrared light (from $0.7$ to $1.1\\mu m$). The more leaves a plant has, the more these wavelengths of light are affected, respectively.Normalized Difference Vegetation Index (NVDI)\\[\\text{NDVI} = \\frac{b_{NIR}-b_{RED}}{b_{NIR}+b_{RED}}\\] ExampleExploratory analysis Covariance matrix A partir du moment ou c‚Äôest tres correle, on peut reduire les dimensions tout en conservant une partie de l‚ÄôinformationQuelle est la definition de la matrice de covariance ? C‚Äôest ce qui permet de visualiser la dependance des bandes entre ellesSur l‚Äôimage ci-dessus, les variables globalement entre $80$ et $100$ ont une correlation relativement elevee. Correlation matrix Si on affiche les valeurs de la diagonale de la matrice:Feature extractionEigen decomposition of the covariance matrix:\\[\\Sigma = \\phi \\Lambda \\phi^T\\]with $\\Lambda$ the matrix of eigenvalues (values only on the diagonal) and $\\phi$ the matrix of eigenvectorsPrincipal Component AnalysisApplicationDenoisingTestLet us consider the data $X\\in\\mathbb R^{b\\times n}$ with $n$ samples of $b$ bands and centered at the origin. Matrix $\\Phi=[\\phi_1,\\dots,\\phi_d]$ is composed of $d\\lt b$ eigenvectors extracted from the $n\\times n$ covariance matrix $\\Sigma$ of the data $X$Which transformation would you apply to the data for denoising based on the concepts seen so far ? $Y=X_{[1:d,:]}$ $Y=\\Sigma X$ $Y=\\Phi X$ $Y=\\Phi^T X$ $Y=\\Phi\\Phi^T X$ $Y=\\Phi^T\\Phi\\Phi^T X$Spectral Mixture AnalysisSpectral mixingLinear mixing model\\[x=\\sum_{k=1}^ma_ks_k+e=Sa+e\\] $x$: Spectrum of a pixel $a$: Coefficients in the mixture (abundance) $S$: Spectra of the sources of the mixture (endmembers) $e$: NoiseContraintes: Sum to $1$\\[\\sum_{k=1}^ma_k=1\\] Non negativity\\[\\begin{aligned}a_g\\ge 0\\\\S_{k,\\lambda}\\ge 0\\end{aligned} \\quad \\forall k\\]Geometrical interpretationOn a un cas tres simple:\\[\\begin{cases}x = a_1s_1 + a_2s_2\\\\a_1+a_2 = 1\\end{cases}\\]D‚Äôun point de vue representation, si on considere les vecteurs $s_1$ et $s_2$, toutes les valeurs de $x$ definies par l‚Äôequation ci-dessus sont retrouvees dans le segment $s_1\\leftrightarrow s_2$Endmember determination techniquePrinciples: Endmembers are the vertexes of the simplex $\\to$ find extrema when projecting the data on a line The convex-hull of the data encloses the simplex $\\to$ find endmembers such as to maximise the volumeAbundance If the endmembers are available: Solve a minimization problem of the form:\\[\\hat A = \\text{arg}\\min_A\\Vert X-AS\\Vert^2_F\\quad \\text{s.t. Constraints}\\] If the endmembers are not available: Use alternating minimization techniques (e.g., Non-negative matrix factorization)Hyperspectral in nature Mantis shrimp visual system $12$ different types of color photoreceptors see in the UV, VIS and NIR spectral domains $3$ focal points per eye ($6$ in total, we have $2$) see polarized light (linear vs circular) Bonus" }, { "title": "ISAT: Remote sensing", "url": "/cours/posts/isat_remote_sensing/", "categories": "Image S9, ISAT", "tags": "Image, S9, ISAT", "date": "2021-12-09 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionRemote sensingWhat is remote sensing ? Remote: operating without a direct contact Sensing: perform a measure Measure something at a distance, rather than in situ. It relies on propagated signal of some sort, for example optical, acoustical, or microwaveRemote sensing imagePanchromatic imageLa particularite de ces systemes est qu‚Äôils ont leur propre source d‚Äôillumination, en envoyant des signaux qui interagissent avec des objets d‚Äôinterete. Exemple: on prend une photo avec de la lumiere, c‚Äôest un systeme actifIci on s‚Äôinteresse a la teledetection ou on utilise des sources d‚Äôillumination externe (le soleil)On s‚Äôinteresse principalement au regime optique de la lumiere, avec de l‚Äôoptique geometrique. On est dans les plages du visible a l‚Äôinfrarouge.On va regarder l‚Äôheterogeneite des donnees qu‚Äôon peut avoir en teledetection:MultispectralOn a aussi des images multispectral:HyperspectralFrom low spatial resolution‚Ä¶To high spatial resolutionSpatial details in satellite imagesSpatial details in aerial imagesSpatial details in drone images Bonne precision pour identifier des feuilles de plante, utile pour verifier leur etat de sante J‚Äôespere que vous vous en rappelezMultitemporal images Ce sont les Alpes, par-dessus GrenobleCe sont des recombinaisons fausses couleursIl y a des parties manquantes sur l‚Äôimage a cause des nuagesOn a une acquisition par jour par satellite, et on a 2 satellites. On arrive a faire un suivi de certains phenomenesOn a certaines satellites ‚ÄúAgile‚Äù capablent d‚Äôorienter leurs camerasVoici d‚Äôautres acquisitions:En comparant les images, on voit clairement le deplacement de la cameraMultiangular drone imagesOn entre en convergence en computer vision, on retrouve les memes problematiques.ApplicationsThematic classificationOn veut tirer des informations de ces images, par exemple: semantic segmentationAnomaly detectionDetecter des evenements rares comme des phenomenes naturels.(Video) Nearly 20 Years of Change at Your FingertipsOptical radiation modelOptical Remote sensing principleQuant a la source d‚Äôillumination:On a des longueurs d‚Äôondes beaucoup plus elevees par rapport a ce qu‚Äôon utilise dans les capteurs optiques, on peut aller jusqu‚Äôaux ondes radiosSolar radiation The spectral radiant exitance ($M_{\\lambda}[Wm^{-2}\\mu m^{-1}]$) of a black body is modeled by Planc‚Äôs blackbody equation\\[M_{\\lambda} = \\frac{C_1}{\\lambda^5(e^{\\frac{C_2}{\\lambda T}}-1)}\\] $C_1, C_2$ constant $\\lambda$ wavelength $[\\mu m]$ $T$ black body temperature $[K]$ The blackbody function peaks at a wavelength given by Wien‚Äôs law\\[\\lambda_{max} = \\frac{2989}{T}\\]Pour le soleil, le pic d‚Äôemission par rapport a sa temperature se trouve dans le visibleSolar spectral irradiance $E_{\\lambda}^0$ spectral irradiance $[Wm^{-2}\\mu m^{-1}]$ power density that reaches the earth Quantite d‚Äôenergie Spectral irradiance at the top of atmosphere \\[E_{\\lambda}^0 = \\frac{M_{\\lambda}}{\\pi}\\times\\frac{\\text{area solar disk}}{(\\text{distance to earth})^2}\\]Et le Red-Shift ? On a un soleil dans une autre galaxie, si l‚Äôemission de cette etoile etait dans le jaune mais que la galaxie se deplace, on a une reduction en frequence qu‚Äôon voit comme un shift dans le spectre d‚ÄôemissionC‚Äôest l‚Äôeffet Doppler qui fait ca, caracterise par la nature ondulatoire de la lumiereC‚Äôest comme ca qu‚Äôon arrive a estimer les velocite de galaxiesOn relie ca aux gazs presents dans les etoiles, ces derniers ont des spectres d‚Äôemissions particulier donc avec le red-shift on peut estimer le decalageSolar/Earth radiationTout corps avec une temperature $\\le 0K$ aura un spectre d‚Äôemission hors du visibleRadiation ComponentsOn est a l‚Äôexterieur de l‚Äôatmosphere:Optical remote sensing componentRadiation mechanismRadiation component Radiance reaching the satellite sensor\\[L_{\\lambda}^s = L_{\\lambda}^{su} + L_{\\lambda}^{sd} + L_{\\lambda}^{sp}\\] $L_{\\lambda}^{su}$ the unscattered, surface-reflected radiation $L_{\\lambda}^{sd}$ the down-scattered, surface-reflected skylight $L_{\\lambda}^{sp}$ the up-scattered path radiance Surface-reflected, unscattered component $L_{\\lambda}^{su}$ The atmosphere interacts with radiation both on the solar and view path The fraction or radiation that arrives at the earth‚Äôs surface is the solar path transmittance, $\\tau_s(\\lambda)$ The molecular absorption bands of water and carbon dioxide cause deep absorphtion features that, in 2 bandas near $1.4\\mu m$ and $1.9\\mu m$, completely block transmission of radiationSolar path $0$: Rien qui est transmis $1$: La couche est totalement transparenteExemple: Sentinel-2 spectral responsesAtmospheric scattering mechanismsL‚Äôaerosol est la composante principale qui va determiner l‚Äôabsorption. Ces bandes ne sont pas forcement utiles pour le monitorage de la surface terrester mais sont des indicateurs lors du moment de l‚Äôacquisition.Si on considere l‚Äôinteraction de la couche atmospherique avec la source d‚Äôillumination, on a la transmission qui va determiner une modulation de l‚Äôenergie. Atmospheric scattering Absorption mainly due to molecules of oxygen, carbon dioxide, ozone and water which attenuates the radiation very strongly in certain wavelengths Scattering by atmospheric particles is the dominant mechanism that leads to radiometric distortion in image data Rayleigh scattering scattering due to air molecules effect proportional to $\\lambda^{-4}$ scattering mechanism in a clear sky Mie scattering scattering by aerosol (e.g. smoke, clouds, haze) with molecules larger than those of the air ($1-10$ times $\\lambda$) not much dependent on the wavelength On a du scattering avec des nuages ou du brouillard Ce type de scattering n‚Äôest pas forcement selectif en fonction de la longueur d‚ÄôondeInteraction with the surfaceSolar path Spectral irradiance at the earth‚Äôs surface\\[E_{\\lambda} = \\tau_s(\\lambda)E_{\\lambda}^0\\]Irradiance at the surface The irradiance at the surface depends on the incident angle The incident irradiance \\[E_{\\lambda}(x,y) = \\langle\\tau_s(\\lambda)E_{\\lambda}^0n(x,y), s\\rangle = \\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]\\]Surface radiance The incidence radiation interacts with the materials on the surface Assumption of a Lambertian surface $\\to$ equal radiance in all directions surface radiance $L_{\\lambda}(x,y)$ \\[\\begin{aligned}L_{\\lambda}(x,y) &amp;amp;= \\rho(x,y,\\lambda)\\frac{E_{\\lambda}(x,y)}{\\pi}\\\\&amp;amp;=\\rho(x,y,\\lambda)\\frac{\\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]}{\\pi}\\end{aligned}\\] with $\\rho$ the diffuse spectral reflectance, $\\pi$ geometric factor Bi-directional Reflectance Distribution Function (BRDF) \\[BRDF(x,y,\\phi,\\theta)\\simeq \\frac{L_{\\lambda}(\\phi)}{E_{\\lambda}(x,y)}\\]Measuring the BRDFAt the sensorRadiation mechanismOn mesure la combinaison de ces 3 composantes au niveau du capteurRadiance at the sensor Radiance reaching the sensor passes through the atmosphere Depends on the view angle at-sensor radiance \\[\\begin{aligned}L_{\\lambda}^{su}&amp;amp;= \\tau_{v}(\\lambda)L_{\\lambda}\\\\&amp;amp;= \\rho(x,y,\\lambda)\\frac{\\tau_{v}(\\lambda)\\tau_s(\\lambda)E_{\\lambda}^0\\cos[\\theta(x,y)]}{\\pi}\\end{aligned}\\] with $\\tau_v(\\lambda)$ the view path transmittance.Surface reflected, atmosphere-scattered component $L_{\\lambda}^{sd}$ The sensor also sees radiance arising from radiation that is scattered downward by the atmosphere (‚Äúskylight‚Äù) and then reflected at the earth upward Radiance due to skylight \\[L_{\\lambda}^{sd} = F(x,y)\\rho(x,y,\\lambda)\\frac{\\tau_v(\\lambda)E_{\\lambda}^d}{\\pi}\\] with $E^{d}_{\\lambda}$ the irradiance at the surface due to skylight and $F(x,y)$ the fraction of the sky hemisphere that is visible from the pixel of interest.On peut comparer ces 2 images:Les zones d‚Äôombre n‚Äôont pas de composante direct d‚Äôillumination. On recoit l‚Äôinformation d‚Äôune composante qui est reflechi sur cette zone qui est reflechi par l‚Äôatmosphere.Sans atmosphere, on n‚Äôa pas d‚Äôinformation car pas d‚Äôeclairage (photo 2). L‚Äôinteret est d‚Äôessayer de voir, si on traite une image donnee, quelles sont les variables physiques d‚Äôinteret.Image formation in optical sensorsAcquisition geometry Directions Cross-track Along-track Scanners Line scanner Whiskbroom scanner Pushbroom scanner Geometry of acquisition different from pinhole Field of view (FOV) full cross-track angular coverage Ground-projected Field Of View (GFOV) ground coverage of the FOV Instaneous Field of View (IFOV)\\[\\text{IFOV} = 2\\arctan \\biggr (\\frac{w}{2f}\\biggr)\\simeq \\frac{w}{f}\\] $f$: focal length $w$: size of a detector element Instantaneous Ground-projected Field Of View (GIFOV)\\[\\text{GIFOV} = 2H\\tan\\biggr(\\frac{\\text{IFOV}}{2}\\biggr)\\simeq \\frac{w}{m}\\] Ground-projected Sample Interval (GSI)\\[\\text{GSI} = w_d\\cdot\\frac{H}{f}=\\frac{w_d}{m}\\] with $w_d$ the inter-detector spacing GSI determined by cross-track and in-track sampling rates Cross-track GSI usually matches the GIFOV In-track GSI depends on the sampling rate and the platform velocity (and scanning velocity) Overall sensor modelSensor characterizationThe sensor will sense the physical signal with a non-zero Integration time Spectral bandwith Spatial distance Generic sensor model\\[o(z_0)=\\int_w i(\\alpha)r(z_0-\\alpha)d\\alpha\\\\o(z) = i(z) * r(z)\\] $z$ physical quantity to measure $o(z)$ sensor output $i(z)$ input signal $r(z)$ sensor response Spatial resolutionPourquoi on descend a des resolutions tres poussees ? Car d‚Äôun point de vue technologique, on arrive a produire des capteurs avec des grande precisionsOn est limites a un facteur qui est le rapport signal/bruitPoint spread functionD‚Äôun point de vue de caracterisation des instruments:Cette transformation est donnee par la point spread function. C‚Äôest la reponse a une impulsion sur un Dirac (ici un point tres brillant qui va etre ‚Äúetale‚Äù par un point optique)The sensor modifies the spatial properties of the signal blurring distortion of geometry The blur is characterized by Point Spread Function (PSF) The acquired electronix signal $e_b$ representing the signal $s_b$ given by: \\(e_b(x,y)=\\int_{\\alpha_{min}}^{\\alpha_{max}}\\int_{\\beta_{min}}^{\\beta_{max}}s_b(\\alpha,\\beta)\\text{PSF}(x-\\alpha, y-\\beta)d\\alpha d\\beta\\\\e_n = \\text{PSF}*s_b\\)The PSF is composed of different components: optical PSF $\\text{PSF}_{opt}$ image motion $\\text{PSF}_{im}$ detector PSF $\\text{PSF}_{det}$ electronix PSF $\\text{PSF}_{el}$\\[\\text{PSF} = \\text{PSF}_{opt} * \\text{PSF}_{im} * \\text{PSF}_{det} * \\text{PSF}_{el}\\] The 2D PSF is assumed to be separable:\\[\\text{PSF}(x,y) = \\text{PSF}_c(x)\\text{PSF}_i(y)\\] Optical PSF The optics spread a punctual light source on the focal plane Effect due to Optical diffraction Lens aberrations Misalignments of the optics Typically the $\\text{PSF}_{opt}$ is modeled as a 2D Gaussian function \\[\\text{PSF}_{opt}(x,y) = \\frac{1}{2\\pi ab}e^{-\\frac{x^2}{a^2}}e^{-\\frac{y^2}{b^2}}\\] with $a$ and $b$ the width of the PSF in the cross- and in-track direction Detector PSF Blurring due to the non-zero spatial extent of each cell in the detector The blur is uniform over the spatial area of the detector Typically the $\\text{PSF}_{det}$ is modeled as a 2D rectangular pulse function \\[\\text{PSF}_{det}(x,y) = \\text{rect}\\frac{x}{w}\\text{rect}\\frac{y}{w}\\] with $w$ the width of the PSFModulation Transfer Function C‚Äôest les modules de la reponse sous filtreOn retrouve ces profils dans les directions de deplacement de la plateforme D‚Äôun point de vue configuration, on ne veut pas avoir de superpositionPoint Spread Function and samplingOn fait une sorte de filtre anti aliasingSpectral resolution Si on prend un capteur qu‚Äôavec 4 bandes, on aura 4 valeurs par acquisitionLa resolution sera differentes qu‚Äôavec plus de capteursSpectral response The digital number (DN) stored in a pixel $p$ is (approximately) given by\\[\\text{DN}_{pb} = K_bL_{pb} + offset_b\\] with $K_b$ and $offset_b$ the gain and offset in the A/D conversionBayer patternMultispectral sensorsExample: WorldView2 sensorSpectral responses Ca permet de garantir d‚Äôavoir des niveaux d‚Äôenergie suffisantExample: Sentinel-2 spectral responseExample: VEN$\\mu$SVEN$\\mu$S (Vegetation and Environment monitoring on a New MicroSatellite)Illustration of a three-array TDI detector unit (image credit: EIOp Ltd.)Question - The rainbow plane Trouvee sur Google EarthOn a des repliques colorisees differement de cet avionPourquoi ? On a fait les acquisitions de differents spectres a differents momentsPourquoi on a les ‚Äúcontours‚Äù de l‚Äôavion ? On dirait le domaine frequentiel On dirait un gradient de l‚ÄôavionCe sera donc une derivee premiere ou seconde calculee sur l‚Äôimage de l‚Äôavion.Pourquoi faire ca ? Car c‚Äôest la fusion d‚Äôune image panchromatique avec une image multispectrale RECAP: surligner les effets lies a la physique et la nature, et aborder les concepts lies a la formation de l‚Äôimage d‚Äôun point de vue de l‚Äôacquisition" }, { "title": "TVID: L&#39;audio numerique en pratique", "url": "/cours/posts/tvid_audi_numerique/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-12-06 10:00:00 +0100", "snippet": "Lien de la note HackmdOnde sonoreLe briques de base de la compression du son sont un peu differentes de celle de la video.Perception du sonQu‚Äôest-ce que c‚Äôest le son ? Onde sonoreVariations de pressions convoyees par un milieu gazeux Pour la perception: Oreille humaine Transducteur sonore $\\Rightarrow$ signaux electriques Trois parties: Oreille externe: captation Oreille moyenne: amplification Oreille interne: transducteur Oreille externe Collecte et amplifie les sons Localise les sons (pavillon, phase) L‚Äôenvoie dans le conduit auditif Protege le tympa (cerumen)Oreille moyenne Vibration aerienne $\\to$ solidienne (tympan) Transformer les vibrations accoustiques en vibrations solides Amplification: marteau / enclume / etrier Protection niveaux forts (80dB): reflexe stapedienOreille interne Transforme le signal en signal electrique Vestibule: centre de l‚Äôequilibre Cochlee: transforme les vibrations en signaux electriques Recouverte de cellules cillees Hautes Frequences en bas (debut) Basses Frequences en haut (fin) Membrane basilaire: filtre special parole meme en environnement bruyant Accouphenes: cellules cillees petees qui envoient n‚Äôimporte quoiLie aux problemes de circulation du sangAussi l‚Äôusure: on a ecoute des trucs trop fortsSpecifications Spectre: $20 HZ \\to 20 KHz$ Perception d‚Äôintensite logarithmique $dB = 3\\times\\log_2(ratio)$ $3 dB: \\times2, 20 dB:\\times 100$ Jusqu‚Äôa $120dB$ pour l‚Äôoreille Seuils de perception minimale variablesEnregistrement du son ObjectifCapter les variations acoustique dans un materiauAnalogique: Transduction solide Transduction magnetiqueNumeriques: Representations binaires Nombreuses Fete du string pour les formats Transduction solide du son Principe Amplifier l‚Äôonde avec un pavillon Graver l‚Äôonde dnas un materiau par un mobile Pionnier: phonographe, Thomas Edison, 1877 En verite, c‚Äôest un francais, Edouard-Leon Scott de Martinville, 1860 le pionner avec le Phonautographe On ne pouvait que ecrire, relire detruisais le charbon qu‚Äôil utilisait pour graver On a reussi a reconstruire un de ses enregistrements ou il chante au clair de la lune aÃ∑ÕÇÃÄÕÑÕëÕÉÃÜÕÇÕåÕÉÃÄÃàÃÅÕêÃíÕêÃÇÕùÃïÕõÕëÕíÃëÕëÃôÕîÃ≥ÃπÃ±Ã≠ÕîÃ≤Ã∫Ã≥ÕâÃ™Ã∞ÃºuÃ∏ÃíÃÖÃâÃöÃæÃïÕÑÕùÕåÃçÕÅÃºÃºÃ´ÃôÕîÃ≥ÕúÃ∫ÃñÕúÃØÃ≥ÃºÃ≥ÕìÃ™Ã™Ã®Ã´Ã®ÕîÕñÃòÃ§Ãú Ã¥ÃîÕëÃπÃ•ÃùÃ∫Ã´ÃòÃ¨Ã©ÕìÃ£ÕàcÃ∂ÃãÕúÃ≤Ã†Ã•Ã´ÕìÕúÕúÃ†lÃ∂ÕóÃâÃáÃÜÃÉÃáÃäÃïÃÄÃìÕÅÃîÃàÕÜÃïÃõÃæÃÖÃèÃçÃÄÃëÕÅÃîÃçÕ†ÃöÃêÃøÃÜÕîÃüÃ•ÃúÕöÕöÃóÃ™Ã±ÕçÃßÕúÕàÕéÃ°ÕÖÕñÃ™Ã£Ã£ÕïÃßÃ®Ã©ÕïÃ©ÕÖÕîÃ≠ÕñÃüÕöaÃ∏ÕíÃÅÕëÕõÃÖÃÄÕÉÕóÃΩÃëÃÜÕëÃÄÕÇÕÇÕÇÃüÕáÕöÃ£Ã≤ÃúÕâÕìÃ®Ã∫Ã°Ã´Ã≠ÃüÃñÃòÃùÃûÃºÃôÃûÃ≠Ã≠Ã¢ÕéÕöÃ§ÃôÃ∫Ã†ÃßiÃ¥ÃÇÃÖÕÅÃÑÃøÕÇÕâÃ¢Ã®ÃûÃòÃòÕïÃ®Ã°ÃñÃ§ÕúÃÆÃ±ÕöÃùÕúÃòÃ∫rÃ∑ÃåÕÑÕÑÕ†ÃÜÃøÃÇÃΩÃÇÃîÃæÕùÕÑÃÉÃõÕÇÕõÃìÃëÕãÃíÕãÃõÃéÃÜÕÑÃÅÃìÕÉÕÄÃÜÕãÕàÕúÕöÃ•Ã≠ÕúÃñÃ≠ÕâÃ∫ÕìÃ∞ÕöÕéÃ≥ÃπÃüÃúÕîÃ≠ÃñÃ∞Ã•Ãñ Ã¥ÕíÃöÕÜÃøÃáÃïÃìÃåÕåÃÖÃàÕùÃíÃëÃΩÕùÃàÃõÃéÃàÃÖÃæÕÉÃíÕÄÃÑÕùÕùÕÉÃäÕóÃÇÕÑÕÜÕåÃ™ÃØÃûÃûÕàÃñÃúÃªÃ∫ÕìÃ•Ã≠ÃùÃ•ÃòÃùÃñÃ∞Ã†Ã¢Ã©Ã±Ã¨ÃºÕôÃóÕàÃ≥ÕúÃ≥ÃßÃ°Ã°ÕÖÃùÕâÃóÃ©dÃ∏ÕëÃàÃîÕÅÕÄÃíÃÇÕÄÕãÃêÕÑÕÉÕÑÃîÃΩÃìÃèÃÖÃêÕùÕäÃëÃ∫ÃûÃ¶ÕáÃ¢ÕÖÃòÃôÃ™ÕñÃªÕéÕöÃ∫ÕïÃºÕìÃ¶Ã≤ÕñÃ©ÃùÃ´Ã†ÕúeÃ∂ÃøÃçÃöÕõÕÅÕÇÃëÕùÃìÃëÕíÃÄÃèÕÑÃ≥ÕâÃºÕéÕâÃØÕç Ã∂ÕíÕÑÃçÃíÃîÃçÕÑÃöÃÑÃåÕãÃëÕùÕãÃÑÕóÕêÃΩÃÖÕëÃãÕóÃèÕùÕÑÃöÕäÃæÃèÃíÕÑÕÑÃïÃéÕùÃøÃçÕùÃÑÃ™ÃªÃòÕìÃπÃ∞Ã¨Ã•ÕöÃüÃªÃùÕÖÕúÃ¢ÕöÕçÕéÕçÃóÃ≤Ã©Ã¶Ã™Ã£Ã¶ÕâÕàÃ©ÃØÃ§ÕïÕúÃüÕôÃùÃôlÃµÃäÃÜÃâÃÅÃîÕêÃöÃíÃãÕíÃÇÃåÃöÕÑÃíÃÑÃÑÃöÃñÃπÃüÕöÃûÕàÃôÃ°ÃòÃóÕàÃ≠ÕçÃ≤ÕâÃ©Ã•ÃôÕñÃªÕìÃºÕöÃ±ÕéÕñÃ§ÃùÃ∫Ã±Ã∫ÕçÃ≤Ã∞ÃØÃ•aÃ∂ÃÑÕÅÃÉÕÄÃÄÃäÕÉÕÇÕÉÃêÕêÃÅÃéÃΩÃ≠ÃùÃ∫ÃôÕñÕéÕñÃ£ÃòÃØÃ¢Ã§ÕìÃ∫ÃûÃ†ÕáÃ¢ÕôÕàÃ¶ÃªÃòÕîÃ≠ÃÆÃùÕìÃ™ÕÖÃòÃ®Ã° Ã¥ÃïÕãÃîÃëÕÅÃÅÕíÃìÕÇÕùÃëÃàÃàÃåÃÜÕ†ÕùÃèÕíÃëÕãÃîÃÇÕëÕÑÃöÕÇÃ≠Ã®ÃßÃ¢Ã≥ÃóÃÆÕîÕàÕéÃòÕôÃ£Ã†ÃùÃôlÃµÃïÃàÕ†ÃæÕóÃÅÃçÃäÃÜÃõÃÖÃèÃÑÃöÃìÃêÃïÃçÃâÃêÃõÕõÕÇÕ†ÕõÕãÃìÕÇÃãÕêÕëÃëÕÅÃöÕùÃÖÃçÕíÃÜÃ¨Ã•ÕìÕáÕáÕñuÃ∏ÃÑÃâÕäÕôÃ±ÕôÃ©ÕñÃ†ÃºÃ≥ÃÆÕéÕÖÃ°ÃûÃ°Ã™ÕâÃÆÃ©ÃÆÃ≠ÃùÃùÃ¶Ã¨ÃπÃ≥ÕçÃ∞ÃôÃ®ÃüÃ™ÕïÃ•Ã∞Ã¨Ã†ÃôÃ∞ÕÖnÃ∂ÕêÃÅÃíÕùÃÇÃõÕÄÕÉÕíÃäÕÑÃøÃöÃëÕÑÃêÃèÕõÕãÕùÃ¨ÕìÕïÕôÃ≥ÃòÃ£ÃóÕçÃ≤Ã£Ã®ÃÆÃ¨ÃûÕîÃûÃ¨Ã°Ã¢ÕÖÃ£ÕôÕïÃòÃ¶eÃµÃÑÃøÕùÕùÃÖÕùÃèÃâÕãÃΩÕÅÃêÃôÃ¨ÃúÕîÃßÃ≥ÕçÃπÃ£Ã™Ã¶ÃÆÃÆÃ∞ÃÆÃ´Ã§ÃªÃ≥ÃóÃ¶ÕïÃ∞ÃùÃ™Ã£Õé Thomas Edison avait compris que ca devait etre reproductibleGramophone, Emile Berliner, 1886 Meme principe qe le Phonographe Disque rotatif industrialisable Carton (fragile) Celluloid (inflammable) Vinyle (compromis) Vitesse angulaire constante: $78$ a $100$ rpm Du bord vers le centre Perte de qualite au centre Perte de bande passante Les microsillons reconstruisant le son: En faisant les reflets qu‚Äôon voit sur un disqueTransduction magnetique du son Principe Onde accoustique $\\to$ signal electrique Signal electrique $\\to$ champ magnetique Polariser un substrat magnetisable Assez coercitif Coercitivite magnetique: resistance d‚Äôun milieu magnetique a se faire remagnetiser Plus un milieu est coercitif, plus il est resistant Comment ca se passe ? Tete en anneau, magentisation horizontale On a une bande magnetique qui defile On induit ce champ magnetique qui polarise les particules On a un signal accoustique qu‚Äôon a electrise et magnetiseEcrite: Courant electrique $\\to$ Champ magnetiqueLecture: Champ magnetique $\\to$ Courant electriquePionnier: Telegraphone a fil, Valdemar Poulsen (neerlandais), 1898 Magnetisation d‚Äôun fil de fer Bande quelques minutes $1^{er}$ enregistrement: Empereur Franz Josef d‚ÄôAutriche, 1900 Evolution immediate: fil de fer $\\to$ lame d‚Äôacier Plus robuste, plus dangereuxMagnetophone a bande, BASF/AEG (allemands), 1930Cassete 8 pistes, Ampex/RCA/MOTOROLA (US), 1963 On dirait une bobine mais elle s‚Äôenroule sur elle-meme Lecture sans fin ! Quand on le mettais dans l‚Äôauto-radio (c‚Äôetait fait pour les voitures), ca rembobinait et ca jouait en bouclePourquoi 8 pistes ? C‚Äôest en stereo en 4 voie, des qu‚Äôon arrive a la fin d‚Äôune piste, on saute 2 voiesIl y a ~1h30 de musiqueCompact Cassette, Philips (Neerlandais), 1963Enregistrement numerique du sonOnde sinusoidale Une onde sinusoidale est: continue dans le temps continue en intensite Discretiser un signal continu periodiquement $\\Rightarrow$ Choix d‚Äôune frequence $F_e$Theoreme de ShannonUn signal est une somme de sinusoides: La frequence la plus elevee est $f_{max}$ Echantillonner a $F_e$ est valide si\\[F_e\\gt 2\\times f_{max}\\]En dessous: aliasing $=$ repliement de spectre $=$ frequences parasitesEchantillonage Signal echantillone en intervalles reguliersQuid de l‚Äôintensite ? Sous-ensemble discret de valeur d‚Äôun espace contine ${0\\to V_{max}}$ Idealement les valeurs quantifiees appartiennent a la courbe Sauf que nonPas de quantificationEspace discret a $N$ valeurs $[0\\dots V_{max}/N]$ En numerique: $N=2^M$ aec $M$: nombre de bits Erreur de quantification $e$ \\(0\\lt e\\lt V_{max} / 2^M\\) Erreur de quantification inevitable $N$ petit $\\to$ $\\color{red}{e}$ eleve $\\color{orange}{Visible}$ $\\color{red}{Audible}$$\\color{red}{e}$ d‚Äôun signal triangulaire$\\color{red}{e}$ d‚Äôun signal sinusoidalFormat PCM Pulse Coded Modulation Signal continu discretise en temps et en intensite Via circuits CNA/ADC Echantillonnage temporel a $F_e$ $F_e\\ge 2f_{max}$ Sinon aliasing Quantification d‚Äôintensite sur $N$ bits: $2^{N}$ valeurs Erreur de quantification $e$ Dynamique $\\simeq 6dB$ par bit ($16bits\\simeq96 dB$) Reconstruction Via circuits CNA/DAC Filtre passe-bas fort a $F_e/2$ Audio numerique non compresseCD Sony + Philips, 1982 Diametre: $12 cm$ PCM: $44.1KHz$, $16$ bits, stereoo Debit: $2\\times44100\\times2=176.4Ko/s (1.411 Mb/s)$ Lecture: Du centre vers le bord Laser infrarouge Vitesse lineaire constante $500\\to200 rpm$ $74$ minutes de son $\\Rightarrow 783Mo$ Peu de correction d‚Äôerreur Pas grave‚Ä¶ Avec correction d‚Äôerreur: $650Mo$ $\\Rightarrow$ CD-ROM (Read Only Memory) DAT Sony, 1987 2 canaux PCM, $48KHz$, $16$ bites Debit: $2\\times 48000\\times 2 = 192Ko/s (1.536 Mb/s)$ Lecture: Bande magnetique $\\sim 50cm/min (8.15mm/s)$ $4mm$ d‚Äôepaisseur Jusqu‚Äôa 3h par bandeComment ? $\\Rightarrow$ Lecture hellicoidale Tete rotative $2000rpm$ Inclinee $\\Rightarrow 3.15m/s$ Comme VHS Et streamers (DDS, AIT, LTO, ‚Ä¶) DVD-A Un DVD contient bien plus de donnees On etait dans l‚Äôinfrarouge pour les CDs, on est dans les rouges pour les DVD-AD‚Äôou le nom blu-ray DVD Forum, 2000 2 a 6 canaux $44.1 KHz$ a $192KHz$ $16$, $20$, $24$ bits Majoritairement non compresse Cas extremes: Meridian Lossless Packing $\\color{green}{\\text{Sans perte}}$ Lecture: Laser rouge Simple couche/double couche ($8.5Go$) Incompatible DVD-VIDEO, CD AUDIO, CD-ROMSuper Audio CD Sony + Philips, 1999 ‚ÄúSuccesseur du CD‚Äù 2 a 6 canaux $\\color{red}{2.8224MHZ !?}$ $\\color{orange}{1\\text{ bit ??}}$ LISIBLE PAR LA PS3 ??? Format DSDFormat PWM Approximation d‚Äôun signal analogique par des pulses Bruit de quantification $=V_{max}/2^N$ Rappel PCM: Densite constante $=$ Largeur pulses constante Amplitude variable Bruit audible (8 bits, 16 bits‚Ä¶) Reconstruction du signal Filtrage BF a $F_e/2$ $\\color{red}{\\text{PMW: Pulse With Moderation}}$ Densite variable $=$ Largeur pulses variable Amplitude constante Reconstruction du signal: Integration +Filtrage BF Inconvenients Electronique rapide Bruit max de quantification fort $[0\\dots V_{max} / 2]$ !Avantages Bruits de quantification tres haute frequence ($MHz$) Personne n‚Äôest capable de l‚Äôentendre Inaudible ! Qualite $++$ Filtrage BF simple Cout $‚Äì$ Compression numerique du sonL‚Äôaudio non compresse,Qualite CD 2 canaux, $44.1KHz$, $16$ bits Non compresse: $2\\times 44.K * 2$ $\\color{red}{176.4 Ko/s = 1.411 Mb/s}$ CD: 650 Mo data, $\\sim 780 Mo$ audio $\\Rightarrow 74$ min ADSL de 2000: $64 Kb/s$ a $45$ euros par mois: non $128 Kb/s$ a $90$ euros par mois: non $2 Mbits$ a $200$ euros par mois: $100\\%$ du debit en audio ‚Äúet mon internet ?‚Äù Aujourd‚Äôhui (fibre, 4G, 5G) Toujours pas mainstream Reste un service Premium (Deezer HiFi, Spotify HD, ‚Ä¶) Qualite ‚ÄúHome Cinema‚Äù $\\ge 6$ canaux, $48KHz$, $16$ bits Non compresse: $6\\times 48K* 2$ $\\color{red}{576 Ko/s = 4Mbit/s = 2Go/h}$ Dvd: $4.9 Go$ $\\Rightarrow 2.5h$ de son pas de video ! ADSL, mauvaise 4G: 8 Mbits 50\\% du debit juste en audio Et le debit video ? Injouable sans compresseurAlgorithmes temporelsDifferential PCM (DPCM) Hypothese: signal source stationnaire $=$ proprietes independantes dans le temps (esperance, variance) Ok avec des basses frequences (Pas sur en hautes frequences) Principe: pas le sample PCM courant depend du precedent Codage des differences $\\Rightarrow$ Differential PCMEncodeur Memoriser les 2 valeurs consecutives Calcule la difference $\\Rightarrow$ dynamique reduite Encodage du residu avec moins de bits Compression de $25\\%$Decodeur Accumule la valeur reconstruite courante Dequantifie le residu Signal reconstruit $=$ d‚Äôorigine ? $\\color{red}{NON!}$ La quantification des differences induit de l‚Äôerreur $\\color{red}{\\text{qui s‚Äôaccumule a la reconstruction}}$DPCM in-loopEncodeur ameliore Memorise deux valeurs consecutives Calcule la difference $\\Rightarrow$ dynamique reduite Encodage sur moins de bits ! Compression de $25\\%$ Calcule la valeur reconstruite en prevision du decodeur Erreur de construction contenueDecodeur Idem decodeur simpleAdaptive DPCM Codage differentiel adaptatifEncodeur Minimise l‚Äôerreur differentielle adaptativement: Prediction du signal courant avec les valeurs passees Polynome ordre $\\sim 8$ Quantification variable du residu 4 a 6 bits Compression de 75\\% Usages Multimedia (MS/IMA ADPCM, 44.1KHz, 4 bits) Telephonie ($G.721$ $8KHz$, $5-6$ bits) Dans les DS et GBA, le son est exclusivement en ADPCMOn se mange l‚Äôerreur de la compressionRaffinement: deux bandes de frequences Deux residus, deux debits Bande passante plus grande ($7KHz\\Leftrightarrow F_e = 14 KHz$) $\\Rightarrow G.722$ (VolP HQ, DECT HQ)NICAM Nearly Instantaneous Companded Audio Multiplex BBC, $\\sim1986 \\to 2012$, France $1995\\to 2011$ $32kHz$, $14$ bits stereo, $728Kbits/s$ Codec multiplexe avec signal video analogique (QPSK) Exemple: signal SECAM + NICAM @ 5.85 MHzFiltrage BF luma: image plus floue :( On ne peut pas faire rentrer plus que ce qui est possible dans un meme tuyauParenthese perceptuelleComment on percois le son ? Qu‚Äôentend l‚Äôoreille ? Le son peut etre masque par d‚Äôautres sons Phenomene de masquage sonore temporel Posterieur Si on son $\\color{red}{faible}$ suit un son $\\color{green}{fort}$, l‚Äôoreille n‚Äôentend $\\color{red}{\\text{pas}}$ le son $\\color{red}{faible}$Est-ce qu‚Äôil y a un masquage anterieur ? Oui ! Anterieur Si on son $\\color{green}{fort}$ suit un son $\\color{red}{faible}$, l‚Äôoreille n‚Äôentend $\\color{red}{\\text{pas}}$ le son $\\color{red}{faible}$ (non causal !) Autant qu‚Äôon le deteste, notre cerveau un bien un temps de latence de traitement$\\Rightarrow$ Latence de perception des transitoires de dynamiqueNICAM: Principe de fonctionnement Echantillonnage PCM 32 KHz 14 bits Decoupage en tranches de $1ms=32$ samples Pour chaque tranche: Prendre le plus grand sample $\\Rightarrow$ sert de facteur d‚Äôechelle Quantifier a $10$ bits tous les samples Selon le facteur d‚Äôechelle (‚ÄúCompand‚Äù) $\\color{red}{Faible}$: enlever les bits de poids $\\color{green}{forts}$ vides (petits signaux, pas de perte) $\\color{green}{Fort}$: enlever les bits de poids $\\color{red}{faibles}$ (signaux fortsm pertes ‚Äúnegligeable‚Äù) Au pire: quantification forte et breve de petits signaux $\\to$ RSB eleve Variations dynamiques et masquage temporels cachent la misereDecodeur Dequantifier selon le facteur d‚Äôechelle CNA avec $1ms$ de latence (‚ÄúNearly instantaneous‚Äù)SchematisationQuantification CompandQuantification non-lineaire : A-LAWContexte Proprietes temporelles de la voix: Peu de niveaux $\\color{green}{forts}$ Beaucoup de niveaux $\\color{red}{faibles}$, silences Voix numerique: typiquement $8KHz/8$ bits Rappel numerisation PCM: Bruit de quantification uniforme Fort dans les niveaux $\\color{red}{faibles}$, faible dans les niveaux $\\color{green}{forts}$ Autrement dit: PCM 8 bits degrade souvent la voix Quelles alternatives ? PrincipeModifier la dynamique Augmenter les niveaux $\\color{red}{faibles}$ Baisser les niveaux $\\color{green}{forts}$ Bruit de quantification remodeleQuelle fonction fait cela ? Loi logarithmique\\[F(x)=\\text{sgn}(x)\\begin{cases}\\frac{A\\vert x\\vert}{1+\\ln(A)}, &amp;amp;\\vert x\\vert\\lt \\frac{1}{A}\\\\\\frac{1+\\ln(A\\vert x\\vert)}{1+\\ln(A)}, &amp;amp;\\frac{1}{A}\\lt \\vert x\\vert \\lt1\\end{cases}\\]En pratiqueAnalogiquement: Avant CAN + apres CNA Paquets numeriques: PCM 8 bits classiquesNumeriquement: Apres CAN PCM $\\color{green}{HQ}$ (12 bits) + avant CNA PCM HQ Paquets numeriques: traitement A-Law $12\\leftrightarrow 8$ bitsResultat On a inverse la tendance des erreursErreur de quantification: Forte sur les signaux $\\color{green}{forts}$ Faible sur les signaux $\\color{red}{faibles}$Standard telephone $G.711$" }, { "title": "EPIQUANTI : Noisy Intermediate-Scale Quantum (NISQ) Computing", "url": "/cours/posts/epiquanti_nisq/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-11-30 16:00:00 +0100", "snippet": "Lien de la note HackmdNISQ ComputingMotivationShor‚Äôs algorithm - how many qubits does it take to factor an integer ?Textbook examples of quantum algorithm largely assume that qubits and gates are not subject to noise. In the absence of noise, to factor and integer ,ade of $1024$ bits takes about $2050$ qubits and over $10^9$ gatesIn the presence of noise, quantum error correction has to be incorporated into the computation, adding a large overhead.Fault-tolerant quantum computations of arbitrary length are not within reach of today‚Äôs technology (need qubits in the millions)Algorithms for small number of qubits (in the $\\sim100$) and limite coherence time will need to offload pre and post-processing to classical computers. Noisy Intermediate Scale quantum (NISQ) computed is thriving field of research: $50-100$ qubits Limited gate fidelity Limited qubit connectivity Limited correction capabilities $\\to$ low depth circuit Killer apps: simulate correlated matter, machine learning, optimizationVariational Quantum AlgorithmsVariational Quantum Algorithms are a hybrird quantum-classical approach. Goal: finding ground state of a Hamiltonian $H$, or alternatively, optimizing a cost function Choose a good Ansatz $\\vert\\psi(\\theta)\\rangle$ Design a quantum circuit that implements $\\vert\\psi(\\theta)\\rangle$ Measure cost function $E_{\\theta}=\\langle\\psi(\\theta)\\vert H\\vert\\psi(\\theta)\\rangle$ Use classical optimizer to find optimal $\\theta^{*}$VQA consist of a quantum processor that can prepare quantum states belonging to a parameterized class ${\\psi(\\theta)\\rangle}$ efficiently and an external loop (running on classical hardware) that optimizes its parameters The absence of error correcting means that the effective error rate will be non-vanishing, and as a consequence, the length of the possible circuit will be boundedVQA: Inner routine The inner routine prepares a state parameterized by $\\theta$Quantum Approximate Optimization AlgorithmCombinatorial optimization Combinatorial optimization is about finding an optimal configuration in a set of possible configurations.In general, combinatorial problems are very big so exhaustive search is not tractable.There are many methods to tackle optimisation problems, such as Constraint Programming, Branch and Bound/Cut methods, and local search heuristics.A specific NP-hard problem under consideration, known Quadratic Unconstrained Binary Optimization Problem (QUBO), can be expressed a a local energy problem and therefore phrased as an Ising model. Given a set of spins $s_i = \\pm1$, the foal is to find the configuration which minimizes the energy function.\\[H(s_1,\\dots s_N) = -\\sum_{i\\lt j}J_{ij}s_is_j-\\sum_{i=1}^Nh_is_i\\]Simulated AnnealingHeuristic algorithms are used to find approximate solutions to combinatorial problems that, while being suboptimal, are ‚Äúgood enough‚Äù. Simulated Annealing is a local search heuristic inspired by the physical process of thermal annealing.SA performs local changes in the current candidate solution and checks whether the new candidate has lower energy. If it does, it becomes the leading candidate, if it does not, one may still accept the new candidate with probability, in the hope that it will help explore the space of solutions. This hill-climbing events become less liekly as the algorithm progresses, and they are controller by an effective temperature parameter. C‚Äôest du recuit simule !Tunneling effect Tunneling is the intuition behind QA.Classicaly, particles with low energy will rebound upon collision with a high energy barrier.In the quantum setting, it is possible for a low energy particle to pass through the energy wall. This is because quantum particles are not point-like, but rather like wave-packets.Quantum annealing recapRecall that in QA, an easy Hamiltonian is graduallyAnsatzQAOA For MaxCut" }, { "title": "EPIQUANTI : Quantum Fourier Transform", "url": "/cours/posts/epiquanti_quantum_fourier/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-11-30 14:00:00 +0100", "snippet": "Lien de la note HackmdOverviewThree kind of quantum advantage Oracle-based Adiabatic optimisation Simulation of quantum systemsQuer model and Oracles Oracle: boite noire qui repond oui ou non a une questionIn the query model, you are given access to some function $f$, giving a Y/N answer to all inputs in polynomial time. This function is called the blac-box, or the oracle. An oracle with input $i$ and output $x_i$ can be described by the unitary operation\\[O_x:\\vert i,b\\rangle\\to\\vert i, b\\otimes x_i\\rangle\\]By linearity, this oracle gate can be applied to quantum superpositions. In order to measure the time complexity of an algorithm, one determines the number of queries it makes to the oracle.\\[U_TO_xU_{T-1}O_x\\dots O_xU_1O_xU_0\\vert 0\\dots0\\rangle\\]Quantum Fourier TransformDFT RecapGiven a vector $x$ of dimension $2^N$ with components $x_j$, the Discrete Fourier Transform of a vect $x$ is avector $y$ of dimension $2^N$\\[y_k=\\sum_{j=0}^{2^N-1}x_je^{2ipi jk/2^N}\\]Matrix-vector multiplication takes $O(2^{2N})$ steps. The Fast Fourier Transform algorithm reduces this to $O(N2^N)$, which renders DFT computable in linear time This is done by exploiting symmetry of the DFT matrix representationKet NotationA state on $N$ qubits corresponds to a vector $x$ of dimension $2^N$ with components $x_j$. Take the computational basis:The Fourier transform of state $\\vert x\\rangle$ is a state $\\vert y\\rangle$, i.e. vector of $2^N$ components $y_k$\\[\\vert y\\rangle = \\sum_{k=0}^{2^N-1}y_k\\vert k\\rangle = \\sum_{\\lambda=0}^{2^N-1}\\sum_{j=0}^{2^N-1}e^{2i\\pi j\\frac{k}{2^N}}x_j\\vert j\\rangle\\]1 qubit caseExploiting the symmetryLet us see how the QFT acts upon a computational basis vector. By linearity of QM, this will suffice for any quantum stateNotice that the $\\omega_{N_j}$ in ($\\vert 0\\gt\\omega_{N_j}1\\gt$) depends on the integer value, i.e. on the value of all the qubitsThis is implemented by performing controlled rotations on each qubit. The number of controlled rotations is the number of remaining qubits in the QFT.This means that one needs around $N\\times (N-1)/2$ gates to implement DFTRuntime analysis Number of gates: $N(N+1)/2$ Last reversed-ordering step: $sN/2$ swap gates, each needing 3 CNOTs Then the QFT on $N$ qubits has a runtime of $O(N^2)$ while the FFT takes about $O(N2^N)$ steps. So we have obtainend an exponential speed-upQuantum Phase EstimationGoal and assumptionsThe most salient application of QFT is the Quantum Phase Estimation routine, which is the workhorse behind several quantum algorithms featuring exponential speed-up, such as Shor‚Äôs algorithm and Quantum Matrix Inversion Goal: Estimate the eigenvalue $\\lambda=\\exp(2\\pi\\phi)$ associated to a given eigenvector $\\vert u\\rangle$ of a unitary operator $U$Two assumptions uynderly the QPE routine: Implement the gate $U^k$ in a controlled way with states from $t$ qubit register and non-negative $K$ Prepare the state $\\vert u\\rangle$ as input. This can be relaxed at the expense of introducing randomnessCircuit for QPEThe QPE algorithm ises 2 different qubit registers Register 1: necessary to implement the controlled $U$ gate. The length of this register determines the accuracy of the phase estimation Register 2: Used to prepare the state $\\vert u\\rangle$. The lenght will depend on the problem under consideration The number $\\phi = 0.\\phi_0\\phi_1\\phi_2\\phi_3\\dots$ can be expressed in binary form:\\[\\phi = \\sum_{j=0}^{+\\infty}\\phi_j2^{-j-1}\\]The QFT needs $O(t^2)$ gates. The number of needed gates is polynomial in the number of bits $\\phi$. It can be shown that if the binary fraction expression of $\\phi$ is truncated to some bit length the error can be controlled with logarithmic overheadAmplitude AmplificationClassical motivationGiven the promise that ther is only one tagged marble in this jar containing $N$ crystal marbles, how many times, on average, do you need to randomly draw a marble before finding it ? Given a set of $N=2^n$ databases entries, with $n$ the number of bits used to denote the address of an entry, and no knowledge about the database searching for a particular entry takes on average $N/2$ querie, and $N$ queries in the worst case In the quantum case, this can be sped up to abour $\\sqrt{N}$ queries thanks to Grover‚Äôs algorithmGrover‚Äôs algorithmLes us assume that the database of size $N=2^n$ can be indexed by $n$ qubits. Starting with:\\[\\vert +++\\dots+\\rangle = H^{\\otimes n}\\vert 000\\dots0\\rangle=\\frac{1}{\\sqrt{2^n}}(\\vert 000\\dots0\\rangle+\\vert 000\\dots1\\rangle + \\vert 111\\dots0\\rangle + \\vert 111\\dots1\\rangle)\\]The problem is to find indices of the states that correspon to a ‚Äòtagged‚Äô solution. GA finds thos indexes by successive applications of an oracle gate (which can identify such a solution) and a diffusion gateA signle Grover iteration consists of 4 steps: Phase Oracle H wall Phase Gate H wallThe oracle gate A phase oracle checks, via the black-box function $f$, whether the entry is part of the solution space and, if it is, it flips te sign of the corresponding index. otherwise it does nothing. Setps 2, 3,and 4 are collectively known as the mean-reflection operationGeometric interpretationGiven that $m\\lt\\lt N=2^n$ entries are solutions to the search problem, a Grover iteration can be seen as a small rotation in the $2$-dimensional subspace spanned by $\\vert\\phi_{YES}\\rangle$ and $\\vert\\phi_{NO}\\rangle$" }, { "title": "DLIM: Deepfake", "url": "/cours/posts/dlim_deepfake/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-29 14:00:00 +0100", "snippet": "Lien de la note HackmdDeepfakeLes GAN permettent de creer de faux surprenat avec des reseaux profonds (d‚Äôou Deepfakes) Creation de visage (StyleGAN) Fausse video comme celle de Poutine soulignant la faiblesse des democratiesAutoencoders Avant les GAN il y a eu les autoencodeurs qui ne demandent pas de verite terrainLes resultats sont moyensU-net U-net est une sorte d‚Äôautoencodeur avec une verite terrain et des pontsAutoencodeur variationel (VAE)On decoupe l‚Äôespace latent en sa moyenne et son ecart-typePour construire ce reseau on definit 2 fonctions d‚Äôerreur: Distance image d‚Äôarrivee/image de depart (cf autoencodeur) Divergence de Kullback-Leibler entre le vecteur de l‚Äôespace latent et une gaussienne type: $KL(N(\\mu, \\sigma), N(0,I))$\\[E=\\alpha E_{reconstruction} + \\beta[\\text{mean}^2 + \\text{std_deriv}^2 - \\log (\\text{std_deriv}^2)-1]\\]VAE - generation On peut cr√©er de nouvelles images en gardant la moyenne et en modulant l‚Äô√©cart type $z=\\mu+\\varepsilon\\sigma$Avec les chiffres manuscrits et un espace latent a 2 dimensions $[\\mu, \\sigma]$ on a:Exemple de KerasVector Quantised-Variational AutoEncoder (VQ-VAE)On fabrique une collection de valeurs de vecteurs latents (embedding space). Une valeur est un vecteur lorsque le vecteur latent est en 3DSi la sortie de l‚Äôencodeur est de $32\\times 32\\times 50$ alors la collection a des vecteurs de dimension $50$.On traduit la sortie de l‚Äôencodeur en prenant pour chaque valeur, la plus proche dans la collectionVQ-VAE CompressionUn facteur de compression de $42$: L‚Äôimage d‚Äôorigine a $128\\times128\\times 3\\times 8$ bits L‚Äôimage est encodee avec $32\\times32\\times9$ bits ($521$ valeurs possibles) (il faut aussi stocker la collection de valeurs soit $512\\times D$)On peut entrainer un classifieur sur les images $32\\times 32\\times 1$, ca marcheVQ-VAE-2 - Multi-echelleGAN Un Generative Adversarial Network (GAN) est un autoencodeur avec un discriminateur qui indique si le resultat est un vrai ou faux L‚Äôerreur du discriminateur permet qu‚Äôil se corrige (minimise l‚Äôerreur) et que le generateur se corrige (maximise l‚Äôerreur du discriminateur)Conditional GAN Le principe est d‚Äôenrichier un GAN en ajoutant des informations supplementaires (la classe de l‚Äôimage par ex.) en entree du generateur et du discriminateur On a ainsi des images plus realistes en sortiePix2PixC‚Äôest un GAN conditionelLe generateur est un reseau en U et le discriminateur un classifieur CNN adapte.On peut ainsi generer des images a partir de dessins.Cycle GANPeut-on faire de l‚Äôauto-apprentissage (sans verite terrain) avec un GAN ?Si le but est de passer d‚Äôun type d‚Äôimage a un autre, c‚Äôest possible.Pour cela on utilise 2 generateurs, $G$ et $F$, et 2 discriminateurs, $DX$ et $DY$ $G$ fabrique une image de type $Y$ a partir d‚Äôune image de type $X$ $F$ fabrique une image de type $X$ a partir d‚Äôune image de type $Y$ $DX$ indique si l‚Äôimage donnee est vraie ou a ete generee par $F$ $DY$ indique si l‚Äôimage donnee est vraie ou a ete generee par $G$ApplicationsStyleGANMelange de styleAvec 2 vecteurs de l‚Äôespace latent on peut melanger $2$ visage en injectant le 1er jusqu‚Äôa une couche dans la synthese, puis le secondPlus on injecte tard le 2e, moins l‚Äôimpact est important (seulement les hautes frequences)Vers le visage moyenLorsqu‚Äôon est dans l‚Äôespace $\\mathcal W$ avec une valeur latente $w$ on peut interpler le visage moyen $\\bar w$\\[w=\\bar w+\\psi(w-\\bar w)\\]" }, { "title": "IMED2: 3D/3D registration with labeled atlas", "url": "/cours/posts/imed2_registration_3D/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-26 09:00:00 +0100", "snippet": "DPH and TURP treatmentThe endo-vascular treatment for BPHC‚Äôest quoi le challenge ? La prostate a BEAUCOUP de variantes anatomiquesLa variante anatomique la moins embetante est la C. Meme si on bouche les vaisseaux, les os ne risque pas de se necroser.La plus compliquer est la B car le point de bifurcation est proche des arteres et du penis, boucher les vaisseaux pourrait tout niquer.Quand on fait un volume rendering, on voit ca:From CBCT to clinical informationUne fois sur le centerline, on peut labeliser les vaisseaux a la main, en fonction de si c‚Äôest des vaisseaux d‚Äôinterets ou non.Pourquoi on n‚Äôessaierai pas de faire ca automatiquement ?On a essaye dans un premier temps de classifier les arteres: on fait une boule autour de la prostate et on regarde Mais ca ne marche pas pour regarder tous les vaisseaux autoursState of the art on vessel classification Pour tester les classifier, on ouvre scikit et on teste tous les classifiers a la mainVascular tree labeling as a classification problem on subtreesOverview Compute descriptors Predict a lable Branch label assignmentTackle a machine learning problem A best practice proposal inspired from different courses Data splitting To ensure statistical relevance of the results Metric definition To compare algorithms and evaluate performances Define metrics targets Human level Dumb algorithm State of the art Data preprocessing Explore, outlier removal, feature engineering normalization Model selection Identify relevant models to test Hyper-parameter tuning Either panda or caviar Iterate Evaluate the model Learn from failure Augment data Large Diffeomorphic Deformations Metric MappingCompute the registrationPourquoi utiliser ca ? Utiliser une deformation tres non-rigide On a besoin de statistiquesToward atlas building" }, { "title": "IMED2: Project", "url": "/cours/posts/imed2_project/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 11:00:00 +0100", "snippet": "Lien de la note HackmdPart 1Retinal fundus image segmentationIterative Closest Point - ICPQuand on itere, on reste bloques sur des minimums localEn remplacant points par courbes:On construit un ensemble de courbes problables et on associe ces courbes probablesCa marche pas car on recale un objet 3D sur un objet 2DPart 2Iterative Closest Point RegistrationVedoICPProject part 3Mosaicking applicationCVRL A la fin, ca ne marchera pasMais c‚Äôest pas grave, on aura essaye :)Pathology evolutionCVRL On fait un suivi temporel d‚Äôune pathologie" }, { "title": "IMED2: TP3", "url": "/cours/posts/imed2_tp3/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 09:00:00 +0100", "snippet": "Reconstruction tomographique (2/3)Vous avez tous les outils pour comprendre la reconstruction tomographique 2D en g√©om√©trie parall√®le dans le cadre id√©al : √† partir des lignes int√©grales (transform√©e de Radon), il est possible via le th√©or√®me coupe-projection de r√©cup√©rer l‚Äôobjet correspondant aux projections (r√©troprojection filtr√©e). Cette th√©orie est bien jolie, mais‚Ä¶ la r√©alit√© est assez diff√©rente ! Le but de ce Notebook est de vous familiariser avec un certain nombre de non-id√©alit√©s des syst√®mes tomographiques, et d‚Äôidentifier les effets de ces non-id√©alit√©s dans les images reconstruites. Nous passerons en revue : Une non-id√©alit√© du tube : son caract√®re intrins√®quement polychromatique Une non-id√©alit√© du d√©tecteur : la pr√©sence de gains et d‚Äôoffsets (cela doit vous dire quelque chose !) Une non-id√©alit√© li√©e aux interactions photon/mati√®re : le diffus√©Mais il existe de nombreuses autres sources de non-id√©alit√©s, par exemple une non-id√©alit√© li√©e √† l‚Äôobjet lui-m√™me (ou au patient) : la pr√©sence de mouvement au cours de l‚Äôacquisition (avez-vous des exemples en t√™te ?)import numpy as npfrom matplotlib import pyplot as pltfrom skimage.draw import circle, diskfrom skimage.transform import radon, iradonimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)Partie 1 - Durcissement de faisceauOn se donne un vecteur d‚Äôangles theta. Puis, on construit deux images via la fonction buildImage. Cette fonction prend en entr√©e une √©nergie en keV, et g√©n√®re une image constitu√©e d‚Äôos, de mati√®re molle du cerveau, et d‚Äôiode (cas d‚Äôune imagerie vasculaire avec injection de produit de contraste). Les coefficients d‚Äôatt√©nuation d√©pendant de l‚Äô√©nergie consid√©r√©e, nous pouvons avoir deux images diff√©rentes selon que l‚Äôon se place √† 80 keV ou √† 100 keV. Vous remarquerez que j‚Äôai aussi ajout√© un facteur de dilution de l‚Äôiode : c‚Äôest que l‚Äôon n‚Äôinjecte pas toujours de l‚Äôiode pure dans le corps du patient !Lancez les deux cellules suivantes.N = 360theta_min = 0.*np.pitheta_max = 180.0+theta_mintheta = np.linspace(theta_min, theta_max, N, endpoint=False)# in g/cm3dilution = 0.25densities = {&#39;Brain&#39;:1.043, &#39;Bone&#39;: 1.8, &#39;Iodine&#39;: 4.93*dilution }massAttenuationCoefficient = {&#39;Brain&#39;: {80: 1.831e-1, 100: 1.701e-1}, &#39;Bone&#39;: {80: 2.229e-1, 100: 1.855e-1}, &#39;Iodine&#39;: {80: 3.51, 100: 1.942} }def buildImage(kev): N = 256 img = np.zeros((N,N)) rr, cc = disk(((N-1)*0.5,(N-1)*0.5),(N-1)*0.45) img[rr,cc] = massAttenuationCoefficient[&#39;Bone&#39;][kev]*densities[&#39;Bone&#39;] rr, cc = disk(((N-1)*0.5,(N-1)*0.5),(N-1)*0.4) img[rr,cc] = massAttenuationCoefficient[&#39;Brain&#39;][kev]*densities[&#39;Brain&#39;] rr, cc = disk(((N-1)*0.25,(N-1)*0.5),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] rr, cc = disk(((N-1)*0.65,(N-1)*0.7),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] rr, cc = disk(((N-1)*0.65,(N-1)*0.3),10) img[rr,cc] = massAttenuationCoefficient[&#39;Iodine&#39;][kev]*densities[&#39;Iodine&#39;] return imgimg = {80:buildImage(80), 100:buildImage(100)}fig, ax = plt.subplots(1,2,figsize=(12,4))ax[0].imshow(img[80],vmin=0,vmax=0.5)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(img[100],vmin=0,vmax=0.5)ax[1].set_title(&#39;100 keV&#39;)plt.show()Nous allons g√©n√©rer les sinogrammes correspondant √† ces deux images. Si ASTRA est une tr√®s bonne toolbox pour vous amuser √† g√©n√©rer diff√©rentes g√©om√©tries d‚Äôacquisition, utiliser des algorithmes de reconstruction it√©rative, etc., il existe √©galement une fonction standard de scikit-image pour la g√©om√©trie parall√®le 2D : radon pour la projection, et iradon pour la reconstruction. On √©crira, pour projeter une image selon un vecteur d‚Äôangles theta :radon(img, theta=theta, circle=True, preserve_range=True)De m√™me, pour reconstruire l‚Äôimage √† partir de son sinogramme, on √©crira :iradon(sino, theta=theta, circle=True)Questions G√©n√©rez les sinogrammes des deux images ci-dessus. Reconstruisez les images issues de ces sinogrammes.# Question 1# Sauvez les sinogrammes dans un dictionnaire :# p = {80: **sinogramme √† 80 keV** ; 100: **sinogramme √† 100 keV**}p = {80:radon(img[80], theta=theta, circle=True, preserve_range=True), 100:radon(img[100], theta=theta, circle=True, preserve_range=True)}fig, ax = plt.subplots(1,2,figsize=(12,4))im0 = ax[0].imshow(p[80].T)fig.colorbar(im0,ax=ax[0])ax[0].axis(&#39;auto&#39;)ax[0].set_title(&#39;80 keV&#39;)im1 = ax[1].imshow(p[100].T)fig.colorbar(im1,ax=ax[1])ax[1].axis(&#39;auto&#39;)ax[1].set_title(&#39;100 keV&#39;)plt.show()# Question 2# Sauvez les reconstructions dans un dictionnaire :# mono = {80: **reconstruction √† 80 keV** ; 100: **reconstruction √† 100 keV**}mono = {80:iradon(p[80], theta=theta, circle=True), 100:iradon(p[100], theta=theta, circle=True)}fig, ax = plt.subplots(1,2,figsize=(12,4))ax[0].imshow(mono[80],vmin=0,vmax=0.5)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(mono[100],vmin=0,vmax=0.5)ax[1].set_title(&#39;100 keV&#39;)plt.show()Le mod√®le de Beer-Lambert polychromatique emp√™che la possibilit√© de r√©cup√©rer la partie lin√©aire, puisque :\\(I = \\int_{\\mathrm{spectre}} I_0(E)e^{-p(E)}dE.\\)En supposant (c‚Äôest encore une nouvelle simplification, mais elle suffira √† illustrer le probl√®me) que le spectre est constitu√© uniquement de deux √©nergies $E_0$ et $E_1$, l‚Äôintensit√© re√ßue est donc $I=I_0(E_0)e^{-p(E_0)}+I_0(E_1)e^{-p(E_1)}$, qu‚Äôon peut r√©√©crire de la fa√ßon suivante :\\(I = I_0\\left(a\\times e^{-p(E_0)}+(1-a)\\times e^{-p(E_1)}\\right)\\)avec $a\\in[0,1]$. Si on utilise la transformation $I\\mapsto \\log(I_0)-\\log(I)$, comme on le fait en monochromatique, on obtient ici une projection $p_E$ √©gale √†\\(p_E = \\log(I_0)-\\log\\left(a\\times e^{-p(E_0)}+(1-a)\\times e^{-p(E_1)}\\right).\\)On se propose de simuler une acquisition polychromatique, c‚Äôest-√†-dire, une acquisition issue d‚Äôun faisceau de rayons X distribu√© sur plusieurs √©nergies. Le plus simple est de consid√©rer une approximation bichromatique du faisceau. Dans ce contexte, on consid√®re que les photons X incidents sont de deux √©nergies, √† savoir 80 keV et 100 keV. La probabilit√© que le photon incident soit √† 80 keV est donn√©e par $P(80) = a_{80}$, et celle d‚Äôavoir un photon incident √† 100 keV est $P(100)=1-P(80)$.Questions Avec une telle distribution de probabilit√©, et les sinogrammes pr√©c√©demment calcul√©s √† 80 keV et 100 keV, quelle est l‚Äôintensit√© re√ßue au d√©tecteur ? Calculez la projection $p_E$ dans la fonction bichromatic (on suppose $I_0=1$) ; attention : les sinogrammes que vous avez calcul√©s sont en unit√©s ‚Äúpixels‚Äù ; il faut se remettre en centim√®tres pour prendre des exponentielles qui aient un sens. Reconstruisez l‚Äôimage √† partir de ce sinogramme : qu‚Äôobservez-vous ?# Question 4def bichromatic(p,a80=0.66): pixel2cm = 0.1 return -np.log(a80*np.exp(-pixel2cm*p[80]) + (1 - a80)*np.exp(-pixel2cm*p[100]))/pixel2cma80 = 0.66sinogram = bichromatic(p,a80)fig, ax = plt.subplots(1,3,figsize=(18,4))ax[0].imshow(p[80].T)ax[0].axis(&#39;auto&#39;)ax[0].set_title(&#39;80 keV&#39;)ax[1].imshow(p[100].T)ax[1].axis(&#39;auto&#39;)ax[1].set_title(&#39;100 keV&#39;)ax[2].imshow(sinogram.T)ax[2].axis(&#39;auto&#39;)ax[2].set_title(&#39;Bichromatic&#39;)plt.show()# Question 5out = iradon(sinogram, theta=theta, circle=True)plt.imshow(out,vmin=0,vmax=0.25)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce5a3361f0&amp;gt;On se propose de comprendre l‚Äôorigine de ces artefacts (dits de durcissement de faisceau).Questions G√©n√©rez un vecteur d‚Äô√©paisseurs en cm, variant de z√©ro √† 45 cm (choisissez $n=500$ √©chantillons). Pour chaque √©paisseur test√©e $T$, calculez $T\\times \\mu_{\\mathrm{iodine}}(\\mathrm{keV})$ pour 80 keV et 100 keV. Utilisez la fonction bichromatic pour calculer la projection bichromatique de $T\\mu_{\\mathrm{iodine}}$, et tracez ce vecteur en fonction du vecteur correspondant √† une acquisition monochromatique √† 80 keV. Qu‚Äôobservez-vous ? Pouvez-vous relier cette observation aux artefacts de l‚Äôimage ci-dessus ? On veut ‚Äúrecaler‚Äù les mesures bichromatiques √† leurs mesures ‚Äúid√©ales‚Äù monochromatiques √† 80 keV. Utilisez la fonction np.polyfit √† l‚Äôordre 3 pour obtenir un fit polynomial.# Question 6# Sauvez les T*¬µ dans un dictionnaire comme fait avec les sinogrammes et reconstructions pr√©c√©dentesx = np.linspace(0, 45, 500)iodineProjection = {kev : x * mu * densities[&#39;Iodine&#39;] for kev, mu in massAttenuationCoefficient[&#39;Iodine&#39;].items()}# Question 7# y est la projection bichromatique# x0 est la projection monochromatiquey = bichromatic(iodineProjection, a80)x0 = iodineProjection[80]plt.plot(x0,y, label=&#39;Mono vs Bichro&#39;)plt.plot(x0,iodineProjection[80], label=&#39;Mono vs Ideal&#39;)plt.xlabel(&#39;Monochromatic&#39;)plt.ylabel(&#39;Bichromatic&#39;)plt.legend()plt.show()# Question 8params = np.polynomial.polynomial.Polynomial.fit(y, x0, 3)polynomial = paramsprint(params)88.09429686309687 + 103.43751237094426¬∑x¬π + 9.090711918937586¬∑x¬≤ -6.380448144804321¬∑x¬≥plt.plot(y,polynomial(y)-x0)[&amp;lt;matplotlib.lines.Line2D at 0x7fce5a115970&amp;gt;]On se propose d‚Äôutiliser ce fit polynomial pour corriger l‚Äôimage. Pour cela, et en premi√®re approximation, nous allons supposer que les artefacts observ√©s viennent uniquement des inserts d‚Äôiode. Ceux-ci sont reconstruits correctement, avec peut-√™tre une valeur √† l‚Äôint√©rieur de l‚Äôinsert l√©g√®rement diff√©rente de la vraie valeur, mais en tout cas, ces inserts sont identifiables. Ils sont aussi beaucoup plus intenses que les autres structures de l‚Äôimage reconstruite.Questions Trouvez manuellement un seuil qui vous permette d‚Äôisoler les inserts d‚Äôiode dans l‚Äôimage reconstruite. Projetez les valeurs de ces inserts d‚Äôiode ; transformez le sinogramme obtenu en utilisant le polyn√¥me trouv√© pr√©c√©demment. Reconstruisez une image √† partir de ce sinogramme transform√©. Lancez la boucle d‚Äôimages suivante : qu‚Äôobservez-vous ?# Question 9seg = out.copy()seg[seg &amp;lt; 0.4] = 0plt.imshow(seg)&amp;lt;matplotlib.image.AxesImage at 0x7fce5a606820&amp;gt;# Question 10segProj = radon(seg, theta=theta, circle=True, preserve_range=True)plt.imshow(segProj.T)plt.show()tmp = polynomial(segProj)plt.imshow(tmp.T)&amp;lt;matplotlib.image.AxesImage at 0x7fce5a5df2b0&amp;gt;# Question 11reproj = iradon(tmp, theta=theta, circle=True)plt.imshow(reproj,vmin=0,vmax=0.25)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce5a02cd00&amp;gt;# Question 12search = np.linspace(0,1,11)for alpha in search: rec = out+alpha*reproj f,ax = plt.subplots(1,2,figsize=(12,5)) ax[0].imshow(rec,vmin=0,vmax=0.5) ax[0].set_title(alpha) im = ax[1].imshow(img[80]-rec) f.colorbar(im,ax=ax[1]) ax[1].set_title(&#39;Difference from ground truth&#39;) plt.show()Partie 2 - Non-id√©alit√©s du d√©tecteurUn d√©tecteur pr√©sente plusieurs non id√©alit√©s ; en premier lieu, il pr√©sente des d√©rives en gains et en offsets. Cela signifie que la mesure faite au niveau d‚Äôune cellule du d√©tecteur (un pixel d‚Äôun d√©tecteur plan, ou un bin d‚Äôun d√©tecteur lin√©aire), au lieu de mesurer l‚Äôintensit√© $I$ des photons X qui arrivent √† la cellule, on mesure\\(I_c = \\alpha I + \\beta.\\)$\\alpha$ est un gain (proche de 1 g√©n√©ralement), et $\\beta$ est un offset. Si on ne fait pas attention √† $\\alpha$ et $\\beta$, on se retrouve avec une projection corrompue $p_c = \\log(I_0)-\\log(I_c)$.Chargez l‚Äôimage ci-dessous, et regardez son sinogramme :scale = 1e-5img = np.fromfile(&#39;CTscan.raw&#39;,dtype=&#39;float32&#39;).reshape((256,256))*scalectDisplay = {&#39;vmin&#39;:950*scale,&#39;vmax&#39;:1150*scale}plt.imshow(img,**ctDisplay)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56e10fd0&amp;gt;sinogram0 = radon(img, theta=theta, circle=True, preserve_range=True)#sinogram0[100] = (sinogram0[99] + sinogram0[101]) / 2#sinogram0[100] *= 0.9plt.imshow(sinogram0.T, aspect=&#39;auto&#39;)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56d6cd60&amp;gt;Reconstruisez l‚Äôimage √† partir de ce sinogramme :img_ = iradon(sinogram0, theta=theta, circle=True)plt.figure(figsize=(10,10))plt.imshow(img_,**ctDisplay)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce56ca4b80&amp;gt;Questions Partant du d√©tecteur utilis√© pour le sinogramme pr√©c√©dent (de taille sinogram.shape[0]), g√©n√©rer un vecteur de gains √©gaux √† 1 et un vecteur d‚Äôoffsets √©gaux √† 0 (cas id√©al). Corrompez le vecteur de gain tous les n bins par un bruit d‚Äô√©cart-type de 1%. Affichez le vecteur des gains. G√©n√©rez le sinogramme qui aurait √©t√© obtenu si la mesure avait subi ces gains √† chaque acquisition. Reconstruisez l‚Äôimage : qu‚Äôobservez-vous comme artefacts ? Corrompez le vecteur d‚Äôoffsets tous les n bins (en partant de n//2 cette fois) par un bruit d‚Äô√©cart-type de 1%. Affichez le vecteur des offsets. G√©n√©rez le sinogramme qui aurait √©t√© obtenu si la mesure avait subi ces gains et ces offsets √† chaque acquisition. Reconstruisez l‚Äôimage : qu‚Äôobservez-vous comme artefacts ? (Fixez I0=10) Changez la valeur de I0 √† 100, 1000, 10000 : qu‚Äôobservez-vous ? Quels artefacts disparaissent / se maintiennent ? Pourquoi ?sinogram = sinogram0.copy()np.random.seed(42)n = sinogram.shape[0] // 5# Question 1# Vecteur de gainsgain = np.ones(sinogram.shape[0])gain[::n] += np.random.rand() * 0.01plt.figure()plt.plot(gain)plt.show()# Question 2# Vecteur d&#39;offsetsoffset = np.zeros(sinogram.shape[0])offset[::n-1] += np.random.rand() * 0.1plt.figure()plt.plot(offset)plt.show()I0 = 10# G√©n√©ration du sinogramme corrompu en gains / en offsets / les deuxsinogram = gain.reshape(-1, 1) * sinogram + offset.reshape(-1, 1)plt.imshow(sinogram.T)plt.show()# Reconstructionout = iradon(sinogram, theta=theta, circle=True)f,ax = plt.subplots(1,2,figsize=(20,10))ax[0].imshow(img,**ctDisplay)ax[1].imshow(out,**ctDisplay)plt.tight_layout()Partie 3 - Interactions avec la mati√®re : rayonnement diffus√©Le rayonnement diffus√© est inh√©rent √† la physique des rayons X. Il r√©sulte d‚Äôinteractions avec la mati√®re (avec le patient, notamment). De deux choses l‚Äôune : soit on bloque le rayonnement diffus√© avant qu‚Äôil n‚Äôatteigne le d√©tecteur ; soit on ne le bloque pas, et si on ne corrige pas la mesure par une estimation du diffus√©, la qualit√© image peut s‚Äôen trouver r√©duite.Questions Si on calcule toujours $p=\\log(I_0)-\\log(I)$, mais que cette fois-ci $I$ n‚Äôest plus √©gal au primaire $P=I_0 e^{-p}$, mais au primaire plus le diffus√© (autrement dit: $I=P+S$), quelle erreur fait-on sur $p$ ? Les lignes int√©grales sont-elles sous-estim√©es ? sur-estim√©es ? On se propose de simuler un mod√®le tr√®s simple de diffus√© ; on suppose que le diffus√© ressemble √† une versions flout√©e du rayonnement primaire (celui qui vient directement de la source). Utilisez la fonction gaussian() de skimage pour g√©n√©rer une version liss√©e du rayonnement primaire (on se fiche de I0 ici, qu‚Äôon supposera √©gal √† 1). Prenez sigma=10 comme √©cart-type du lissage. Ajouter 10% de cette image au primaire, et r√©cup√©rez le sinogramme associ√©. Reconstruisez l‚Äôimage : qu‚Äôobservez-vous ? Et avec 20%, 30% ? Calculez le ‚Äúscatter-to-primary ratio‚Äù (ou SPR), √©gal √† $S/P$ ; quelles sont les valeurs de ce ratio ? $\\hat P = P - log(1 + SPR)$from skimage.filters import gaussian# Question 2sinogram = sinogram0.copy()# G√©n√©ration du diffus√©sigma = 10qty = 0.1primary = np.exp(-sinogram)scatter = qty * gaussian(primary, sigma=sigma)# G√©n√©ration du sinogramme corrompu en diffus√©sinogram = -np.log(primary + scatter)# Reconstructionout = iradon(sinogram, theta=theta, circle=True)f,ax = plt.subplots(1,2,figsize=(20,10))ax[0].imshow(img,**ctDisplay)ax[1].imshow(out,**ctDisplay)plt.tight_layout()# Question 3# SPRSPR = scatter / primaryplt.figure()plt.imshow(SPR.T)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fce4e72f880&amp;gt;La question du diffus√© en particulier ‚Äì et des artefacts en g√©n√©ral ‚Äì est loin d‚Äô√™tre anodine ; non seulement la qualit√© image s‚Äôen trouve d√©grad√©e, mais pire encore, les applications utilis√©es en aval (segmentation, recalage, quantification) peuvent voir leurs performances baisser √† cause d‚Äôune image de mauvaise qualit√©.Questions Regardez l‚Äôhistogramme de l‚Äôimage CT ‚Äúpropre‚Äù ; jouez avec des seuils min et max pour isoler l‚Äôhypodensit√© circulaire dans la t√™te du patient : y arrivez-vous ? Avez-vous des id√©es pour nettoyer votre segmentation des pixels segment√©s n‚Äôappartenant pas √† l‚Äôhypodensit√© ?# Question 4mask = np.zeros(img.shape)_=plt.hist(img.flatten(),bins=128)mask[img&amp;lt;0.0104] = 1mask[img&amp;lt;0.0101] = np.nanmask[mask==0] = np.nanplt.figure(figsize=(10,10))plt.imshow(img,**ctDisplay)plt.imshow(mask,cmap=&#39;hot&#39;,alpha=0.3,vmin=0,vmax=2)&amp;lt;matplotlib.image.AxesImage at 0x7fce4e5dddc0&amp;gt;Questions Refaites l‚Äôexercice, mais sur l‚Äôimage reconstruite en pr√©sence du diffus√© √† 30%. Comment est l‚Äôhistogramme des valeurs compar√© au pr√©c√©dent cas ? Est-il aussi simple de segmenter l‚Äôhypodensit√© ?# Question 5mask = np.zeros(img.shape)_=plt.hist(out.flatten(),bins=128)mask[out&amp;lt;0.0104] = 1mask[out&amp;lt;0.005] = np.nanmask[mask==0] = np.nanplt.figure(figsize=(10,10))plt.imshow(out,**ctDisplay)plt.imshow(mask,cmap=&#39;jet&#39;,alpha=0.3)" }, { "title": "IMED2: Registration in medical imaging", "url": "/cours/posts/imed2_registration/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-25 09:00:00 +0100", "snippet": "Lien de la note Hackmd Cours de recalage d‚Äôimage !GE HealthcareQu‚Äôest-ce que c‚Äôest ? Un scanner !Mais c‚Äôest une question piege, c‚Äôest dur de savoir Pour les echographie Une radio dernier criC‚Äôest portable, utile quand le patient ne peux pas etre bougeGE Healthcare in Buc Pour les mamographiesPourquoi on compresse le sein ? Pour avoir moins de matiere a traverserLes seins ont des tissus qui se superposent et qui sont super durs a analyserAvant, on compressait le sein pour l‚Äôempecher de bouger, maintenant c‚Äôest parce qu‚Äôon fait de la 3D du sein AW: station de revue dedieeLe prof @ HealthcareThese sur: Le coeur Recalage Ceci n‚Äôest pas un foieIngenieur de recherche @ GE Identification d‚Äôun besoin/manque/innovation repondant a un besoin clinique Transformer la problematique clinique en un ensemble de problematiques techniques Etude biblio sur les differents sujets techniques et identification des solutions les plus prometteuses Preuve de concept technique et evaluation de la capacite de la solution technique a resoudre le probleme clinique Rendre robuste la preuve de concept a l‚Äôensemble des conditions d‚Äôutilisation potentielles Etablissement d‚Äôune strategie de verification et de validation de la technique Support pour le lancement du produit, la generation d‚Äôevidence clinique et gestion de potentiels problemes3D/2D registration of coronary arteriesCoronary artery diseaseOn peut avoir une artere avec une section bien moins importante Si le sang passe moins bien, les tissus qui se nourrit par cette artere seront beaucoup moins nourris Douleur a l‚Äôeffort, etc.Souvent, quand on a des douleurs a la poitrine apres l‚Äôeffort, c‚Äôest le premier symptome: on a un vaisseau boucheSur l‚Äôimage a droite, il y a une partie qui est compressee Si c‚Äôest une artere du coeur, on peut faire un infarctus Infarctus: le but est de retructurer les vaisseaux coronaires pour continuer a avoir du sang C‚Äôest pas forcement une mauvaise chose ! Coronary artery bypass surgery General anesthesia Extract small artery/vein from leg or arm Open rib-cage Heart stopping On-pump Link aorta to occlusion distality Off-pump + restart the heart ~3 to 6 hours ~1 to 2 weeks of hospitalizationPercutaneous coronary intervention Le genre d‚Äôoperation qu‚Äôon fait plus aujourd‚Äôhui car moins couteuxC‚Äôest quoi la difference entre les veines et les arteres ? Les arteres envoient le sang depuis le coeur, ce sont des muscles qui pulsent au meme niveau que le coeurSi on se prend un coup et qu‚Äôon a un bleu, une veine a pete mes les arteres sont tranquillesLes veines le ramene et ne sont plus un muscleOn amene un catether pour aller jusqu‚Äôa l‚Äôartere bouchee, on met un ‚Äúbalon‚Äù pour eviter que l‚Äôartere se reboucheComment on gonfle le balon ? Il ne faut JAMAIS avoir de l‚Äôair dans les arteres C‚Äôest pour ca qu‚Äôon vide une seringue de quelques goutes, pour eviter les bulles d‚Äôair L‚Äôair peut faire un caillot sanguin On gonfle le balon avec une solution saline, aka de l‚Äôeau La machine pour visualiser l‚Äôinterieur du patientMais et en termes de rayons X ? As Low As Reasonably PossibleAussi les patients sont deja malades, certes on augmente le risque de cancer mais aussi les chances de surviesEt pour les medecins alors ? Chaque medecin porte un tablier de plomb Il y a egalement une vitre plombee (cf a tige au milieu finissant par un cercle) Il y a beaucoup de choses auxquelles ont ne pense pas en tant qu‚Äôingenieur dans nos locaux (la vitre prenant de la place, le nombre de personnes dans la salle, les moniteurs un peu partout, etc.)Pourquoi dans une video, les vaisseaux apparaissent et disparaissent ? C‚Äôest en fonction de la solution pour les faire ressortir On injecte un produit de contraste (le metal le moins nocif, l‚Äôiode)Le guide sort du vaisseau ? Quand ca arrive, c‚Äôest la merde. Dans ce cas, le vaisseau est completement boucheOn creuse dans tous ce qui est bouche, et comme le sang ne passe pas, il n‚Äôy a pas de produit de contrasteIl y a des methodes non-intrusives pour voir les veines ? L‚Äôecho dopplerLe scanner Ce vaisseau est l‚Äôaorte Potential applications for enhanced visualization On va fusionner un objet 3D avec la surface 2D pour se reperer Mais tres gagdet et medecins pas fans :( Proposition plus simple: on segemente l‚Äôartere, on extrait la ligne centrale et on la ‚Äúdeplie‚Äù, on peut visualiser ou on se situe Point de vue ingenieur: ‚ÄúMais ca ressemble a ca non ?‚ÄùPoint de vue medecin: ‚ÄúOH WOW TROP BIEN !‚ÄùThe registration problemOn veut bouger un truc en 3D pour le repositionner et le superposer de facon nickel.Aim at compensating: No link between imaging systems Patient motion Position on the table Repiratory motion Beating heart General registration problemeOn a 2 objets: bleu rougeOn a une fonction de distance qui estime notre recalage, et on veut minimiser cette valeur Avec une mamographie: The 3D/2D registration problem Difficulties due to vessels projection ‚Äúfake‚Äù bifurcations ‚Äúlate‚Äù bifurcations detection On peut confondre 2 vaisseaux et detecter la difference tard projective foreshortening (self-superimposition)2D vasculature extractionCombien de temps ca met a calculer ? Des plombesEt si on veut segmenter cette image ? Detecter des frontieresEt pourquoi pas juste un seuillage ? Ca peut etre trop simple pour que ca marche Le niveau de gris des veines peut etre confondu avec celui du foieOn fait du pre-traitement: remove background On utilise de la morpho math On prend que les vaisceaux principaux (hysteresis thresholding) Si ton montre ca a des gens: ‚ÄúC‚Äôest de la merde‚Äù (mais c‚Äôest pas si pire)Avec la reconnexion:A qui appartiennent les donnees ?Le patient ne peux pas faire l‚Äôimage sans l‚Äôhopital et l‚Äôhopital ne peux pas faire sans le patient Mais si c‚Äôest des organes, pas moyen de reconnaitre le patientAnonymiser les donnees ? Possible de desanonymiserMotion compensation for liverTrans-Arterial Chemo-Embolization - TACE procedure Radio-embolization procedurePour essayer de tuer la tumeur, on fait de la chimiotherapie Chimio therapie: version NAPALM du traitement, on balance tout en esperant de tuer la tumeur TACE: chimio et embolization On donne du poison et on coupe les vaisseaux sanguins La tumeur peut recreer des vaisseaux et se re-alimenter mais ca dimniuera deja sa taillePar rapport a l‚Äôappareil precedent: le detecteur est plus grosLe systeme est sur roulette pour pouvoir s‚Äôecarter pendant l‚Äôintervention: Mais il faut trouver la tumeur !3D Set Up Brief patient Leave the room Set-up injector Set-up system Start test-spin STOP BREATHING Acquire ! Il y a des TONNES de raison pour lesquelles ont peut avoir une reconstruction de merde Il y a eu du mouvement pendant l‚ÄôinterventionOur proposition: motion compensated reconstructionEst-ce qu‚Äôil n‚Äôy a pas moyen de refaire l‚Äôacquisition avec de la compensation de mouvement ?Qu‚Äôest-ce que GE Healthcare a fait ? Il n‚Äôest pas possible de breveter un algo mais on peut breveter un workflowOn teste formellement: La cage est un ‚Äúpatient‚ÄùWhat we measured for absolute &amp;amp; relative comparisonClinical impact evaluationStatistical analysis on clinical features Cases with significant motionPearson Chi square test N-categorical Unpaired dataFisher exact test: 2-categorical Unpaired dataMcNemar test Categorical Paired dataClinical impact evaluation" }, { "title": "TVID: Codec Video", "url": "/cours/posts/tvid_codec/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-24 14:00:00 +0100", "snippet": "Lien de la note HackmdQue faire ?Identifier les repetitions Spatiales TemporellesOptimiser leur codage de rouceDessiner le moins possible 2x les memes dessins pour chaque oeil On va decimer ce qui n‚Äôest pas important Spatialement ? Temporellement ?Detruire selectivement: En fonction de l‚Äôapplication: TV, DVD/BD, streaming Compromis qualite &amp;lt;=&amp;gt; debitCompression entropique (compromis qualite) Huffman (CAVLC) Arithmetique (CABAC)Codec ImageJPEG Le veteran: Join Photographic Experts Group (1992) Limitations de la vision humaine HF Chroma Decoupage en blocs $8\\times 8$ Transformation DCT Quantification des coefficients Lecture Zig-Zag Huffman Decoupage en blocs $8\\times 8$ Transformation DCT Quantification des coefficients ExempleBloc DCTParcours Zig zag Codage RLE: paires {Valeur, Nombre} $79; 0; -2; {-1;3}; {0;2}; -1;$ EOB Image animee: Motion JPEG DV Codec VideoMPEG-1 Le pere fondateur Motion Pictures Experts Group (1993) Base sur JPEDG et H.261 (NetMeeting, PSX FMV) CF. JDG les jeux FMVs Support: Stockage numerique: VCD Reseaux fiables En pratique $352\\times 240$ (‚ÄúNTSC‚Äù) / $352\\times288$ (‚ÄúPAL‚Äù) 30 i/s YUV $4:2:0$ MPEG-1 $1, 5 Mbs$ Blocs, Macroblocs Bloc: matrice de pixels $8\\times 8$ Aggregation en macroblocs MB-Luma: 4 blocs $\\times 8=16\\times 16$ MB-Chroma: $1$ bloc U $8\\times 8$ + 1 bloc V $8\\times 8$ =&amp;gt; 1Mb complet = 4 blocs de Luma + 2 blocs Chroma Slices Suite de macroblcos Sans recouvrement =&amp;gt; Partition de l‚Äôimage Multiusage Facteur de quantification individuel Synchronisation (start codes) Pictures Suite de slices Start code Prediction full / half pel Types: I, B, P, D‚ÄúIntra‚Äù: I Quasi-JPEG Reference: elle-meme Quantification par defaut (‚Äúintra‚Äù) surchargeable Macroblocs intra, codage DC: DPCM AC: Huffman Difference entre images Le lapin apparait d‚Äôune image a l‚ÄôautresImage 1 Traitement par blocs Recherche de mouvement Calcul des residusImage 2 Vecteurs de mouvement (pixel, demi-pixel) balle Residus Lapins Yeux Quantification nonintra uniforme Exemple: Big Buck BunnyVecteurs de mouvementsPrediction IPOn a des images qui dependent les unes des autresAvantages: Debit(P) &amp;lt; Debit(i) Aucune latenceInconvenients: Decoder une P =&amp;gt; conserver la I et les P precedents Prediction + quantification =&amp;gt; $\\color{red}{\\text{propagation d‚Äôerreur}}$Prediction IBPAvantages Debit(B) ¬´¬†Debit(P) ‚ÄúLisse les erreurs‚Äù entre I et P B bidirectionnelle =&amp;gt; moyenne des reconstructionsInconvenients: Decoder une B: garder les I et P apparentees $\\color{red}{\\Rightarrow RAM}$ Ordre de decodage $\\neq$ ordre affichage $\\Rightarrow$ Latence Zapper: besoin d‚Äôintercaler des $I$ frequemment $\\Rightarrow$ ‚ÄúGroup Of Pictures‚Äù Suite d‚Äôimage avec au moins une $I$ Parametres: $M$: distance entre une $I$ et une $P$ $N$: distance entre deux $I$ Ordre affichage vs decodage DO: Display Order - CO: Coding Order A cause des B, $CO\\neq DO$ Supposons ces images en DO: L‚Äôordre des GOP correspondant est (en CO):Sequence Header Resolution PAR Frame rateEn resumeEncodeur MPEG-1Convoyer du son et de la video en meme tempsMPEG Program stream Fichier composite contenat: 1+ flux audio elementaire 1+ flux video elementaire MPEG PES Packetized Elementary StreamPES: Flux elementaire decoupe Stream ID $\\color{red}{PTS/DTS}$ CRCMPEG Program Stream Sequence: Pack header System Clock Reference = Horloge createur PS (pour synchro PTS) Pack: Suite de PES Convient pour un support fiable (VCD, DVD) Pas adapte a la diffusion de chaines de TV (broadcast) Peu resistant au BER Une seule base de temps (SCR) MPEG-2: Le premier codec video Objectif: polyvalence applicative Broadcast DTV SD, HD (DVB, ATSC) Home video (DVD, PVR) Videoconf Differences avec MPEG-1 Profils et niveaux (7) Entrelacement Scalabilite (pseudo-HLS) Plusieurs vues Profils et niveaux MPEG-2 SDTV, DVD, MP@ML SDTV Studio: HP@ML HDTV: MP@H14Entrelacement MPEG-2 Frame entrelacee + Topness bit Field individuels C‚Äôetait bizarre et ca fait chier Ordre arbitraire Peu commodeCodecs et applicationsConvoyer plusieurs chaines: MPEG-2 Transport Stream Decoupage PES en paquets de 188 bits Multiplexage pour broadcast Packet IDentifier (PID) Program Specific Information (PSI) Program Allocation Table (PAT) Program Management Table (PMT) Horloge: Program Clock Reference (PCR)MPEG-2 TS Transport Stream Decoupage PES en paquets de 188 bits Multiplexage pour broadcast Packet Identifier (PID) Program Specific Information (PSI) Program Allocation Table (PAT) Program Management Table (PMT) Horloge: Program Clock Reference (PCR)Demultiplexage MPEG2-TS PSI (PAT + PMTs) repetes regulierement Choix d‚Äôune chaine Choix d‚Äôun PID de PMT and la PAT Recuperation de la PMT correspondante Filtrage des PIDs decrits dans la PMT Assemblage PES correspondants Extraction ES + PT PTS : TS Image PCR Distinguer PCR de PTS PTS: TS image Cadence d‚Äôaffichage des images PCR: ‚Äúheure de l‚Äôencodeur‚Äù Synchronise le decodeur (STC) avec l‚Äôencodeur En longevite (Heures) Indispensable pour du streaming realtime (DVB-S/C/T) Comparable a SCR pour un MPEG-PS (CVD, DVD) Streaming Streaming implique: Producteur Consommateur Fifos Realtime implique: Flux tendu Fifo limitees (faible buffering) Synchronisation producteur et consommateur STC VS PCR FIGHTPas de synchro STC $\\leftrightarrow$ PCR ? STC $\\gt$ PCR Decodeur consomme plus vite que prevu Que se passe-t-il ? Drainage des FIFOs A/V $\\Rightarrow$ Video: saccades / ralentissements $\\Rightarrow$ Audio: micro-silences / repetitions STC $\\lt$ PCR Decodeur consomme plus lentement que prevu Que se passe-t-il ? Buffering limite $\\Rightarrow$ blocage impossible $\\Rightarrow$ Depassement des FIFOs $\\Rightarrow$ Perte de paquets $\\Rightarrow$ Flux elementaires discontinus $\\Rightarrow$ Audio: blips, squeals, silences $\\Rightarrow$ Video: mosaiques, prediction surrealistes Synchronisation STC PCR Besoin d‚Äôasservir STC a PCR VCXO: Voltage COntrol Xtal Oscillator Mesurer diff = STC - PCR Asservir les cloks A/V correspondantes Audio: Reguler la vitess du decodeur Controle du remplissage de la fifo de samples Video Reguler la vitesse du decodeur Controle de la vitesse de production des pixels pour l‚Äôaffichage $\\color{orange}{\\text{Variations Pixel Clock de sortie}}$ $\\color{orange}{\\text{Tolerance en analogique (‚Äúeffet de volant‚Äù)}}$ $\\color{red}{\\text{TOUCHY en HDMI !}}$ H.264 Le championObjectifs Reprendre les applications de MPEG-2Couvrir tous les nouveaux usages: Disques optiques avances (BD, HD-DVD) Streaming actif (VOD, VCONF) Enregistreurs embarques StereoscopieNouveautes Nouveau protocole: Network Abstraction Layer Limite les repetitions S‚Äôadapte aux moyens de transmission Nouveaux outils d‚Äôanalyse d‚Äôimage Macroblocs plus fins Predictions plus elaborees Filtrage a l‚Äôencodage des MV Nouveaux compresseurs entropiques CABAC: Codage arithmetique binaire Intervalles adaptatifs par modeles statistiques CAVLC VLC type Huffman Dictionnaire adapatatif par rapport aux blocs voisins Historique 1998: Initiative VCEG H26L 2001: MPEG + VCEG = Joint Video Team 2003: Finalisation premiere ebauche 2005: Fidelity Range Extension $4:2:2$ $4:4:4$ bit depth &amp;gt; 8 2007: Scalable Video Coding 2009: Multiview Video CodingArithmetique Integer DCT Calculs entiers Plus simples (que MPEG-2) Entierements specifies $\\Rightarrow$ Reconstruction exacte NAL Network Abstrasction Layer NAL: Objets semantiques du flux video VCL: Video Coding Layer NAL VCL: images, macroblocs, MVs, coefficients IDCT NAL Non-VCL: parametres, metas Changent rarement Decouplage NAL vs mode d‚Äôenvoi: Byte-Stream : signalisation par start codes (~MPEG-2) Packer-Transport Pour reseaux (RTP) Le protocole sous-jacent sait quel NAL il envoie/recoit ExemplesQuelques NAL IDR: Instant Decoder Refresh (VCL) Contient seulement une nouvelle image synchronisation du decodeur avec parsing minimal Besoin prealable de metas non-VCL SPS: Sequence Parameter Set (non-VCL) Profil, niveau, resolution, cadence ~ MEPG-2 Sequence Header PPS: Picture Parameter Set Codage entropique, mode de prediction, groupe et ordre des slices, filtrage de blocs En resumeASO Arbitrary Slice Order Les slices peuvent etre envoyees dans le desordre non continument dans le temps Avantages Limite l‚Äôimpact FMO Flexible Macroblock Ordering Partition des MB par motifs Type 0: Interlaced: Lignes Type 1: Dispersed En sequnces Type 3: Foreground: par zones (ROI) Explicitement par l‚ÄôencodageAvantages Forme de segmentation Adaptation a la nature du contenu $\\color{green}{\\text{Resout des cas difficiles}}$ $\\color{green}{\\text{Dispersion des impacts BER}}$Inconvenients Pas dans tous les profilsPrediction InterPartitions de MB et sous-MBReferences multiples: 16 en theorie 5 a 6 en pratique $\\color{green}{\\Rightarrow\\text{Moins de residus}}$ Ponderations possibles (fdes)Motion Vectors au quart de pixel pres:Prediction Intra Prediction spatiale: INTRA $4\\times 4$ 9 directions de recherche Pour sous-blocs $4\\times 4$ INTRA $16\\times 16$ Pour regions plus lisses / BF Filtrage in-loop In-loop deblocking filter Filtrage frontieres Luma $8\\times 8$ ou $4\\times 4$ (resp. Chroma % sampling mode) $\\color{red}{\\text{Pendant l‚Äôencodage des MV}}$ $\\color{red}{\\text{Obligatoire}}$ Filtrage depend de la structure du bloc: Plusieurs references ? F++ Frontieres intra et/ou inter ? F++ Frontieres de MB ? F++!! Contours ? F‚Äì Avantages Encodeur et decodeur fournissent la meme image (pas un post) Meilleurs MV $\\color{green}{\\Rightarrow \\text{Residus ‚Äì}}$ $\\color{green}{\\text{Qualite perceptuelle +++}}$ PSNR identique ?!Inconvenients $\\color{red}{\\text{Complexite}}$ En baisse vu le beneficePAFF Picture Adaptative Frame/FieldFrame Mode (MPEG-2)Field mode: l‚Äôun sous l‚ÄôautreMBAFF Macro Block Adaptative..Paire de MBs: $16\\times 32$ Mode frame: $32$ lignes progressives Mode field: $2\\times 16$ lignes entrelacees Entrelance par partiesAvantages Integrite spatiale maximum Prediction MV TOP BOT possible pour une paire de MBs en mode field $\\color{green}{\\text{Precision}++}$ Pas de MV TOP BOT pour une paire de MBs en mode frame $\\color{green}{\\text{Frugalite}++(16\\%)}$ Indices de mouvement $\\color{green}{\\text{Desentrelacement}++}$ (c) H. 265 / HVECObjectifs Ceux de H. 264 Debit /= 2 Scalabilite des calculs Simplification Parallalisation 4K, 8K, 120 i/s Free Viewpoint (VR) 10/12 bpc (HDR) Simule la sensation d‚Äôeblouissement Historique 2007-2009: Rivalites MPEG - VCEG Rivalites MPEG - VCEG MPEG HPC : mauvais resultats Union JVT VC 2010: Janvier: Appel a propositions Avril: tests, Nommage HEVC Octobre: Premiere ebauche 2013: Janvier: Ebauche finale Avril: Standard ITU 2014: Avril: Ebauche V2 MV-HEVC, Rext, Scalability Octobre: V2 approuvee 2015: Janvier: Publication officielle Avril: V3 approuvee Puis definition Screen Contents: ACT, AMVR, IntraBC, Palette 2016: Juin: V4 refusee Decembre: V4 approuvee (Extension Screen Contents) Principes Decouplage enCodage Prediction Transformation CTU: Coding Tree Unit ‚ÄúMacrobloc‚Äù haut niveau $16\\times 16$, $32\\times 32$, $64\\times 64$ CU Partition carree d‚Äôune CTUPU Partition de la CU Uniquement la predictionIntra: CU == PU Sauf au dernierTU Transformation Unit Parition de la CU Uniquement les residus Independante de la partition PURessemble a ‚Ä¶ Une TU peut couvrir plusieurs PU Ou une partie de PU Ou plusieurs parties de PUOutils 33 Modes de prediction intra 9 pour H.264 Most Probable Modes Indexation dynamique $\\color{green}{\\text{Moins de prefixe (2b vs 5b)}}$ IDCT: $4\\times4$, $16\\times 16$, etc. ~IDST $4\\times 4 possible$ Slices et Tiles Slices Comme H.264 Headers individuels $\\color{green}{\\text{Limitations de l‚Äôerreur}}$ $\\color{red}{\\text{Jonctions imparfaites}}$ Tiles Partition rectangulaire de l‚Äôimage Header/sequence $\\color{green}{\\text{Decodage parallelisable}}$ $\\color{green}{\\text{ROI/VCONF}}$ Slices in Tiles, Tiles in slices: Video Split Wavefront parallel processing Slices divisees en lignes de CTU Pipeline multithreadable $\\color{green}{\\text{Efficace}}$ $\\color{red}{\\text{Intensif}}$ Strategie de parallelisationFiltrage Deblocking Filter Plus simple que H.264 Grille $8\\times 8$ $\\color{green}{\\text{Parallelisable}}$ SAO: Sample Adaptative Offset Filtre non-lineaire post-DBF Reduit les distorsions locales Categorie des samples selon voisinage Moyenne, contour, min, max LUT / index d‚Äôoffset Reduction des effets d‚Äôaplats (banding)SAOOriginal:$\\color{red}{\\text{SANS}}$$\\color{green}{\\text{AVEC}}$EpilogueAutres CODECS MPEG/VCEG/JVT: Versatile Video Codec ITU Universite Industriels Evolution de H.265 Debit $\\sim 40\\%$ Finalise 07/2020 Encodeurs dispo (09/2021) Licences, royalties‚Ä¶ comme HEVC Alliance for Open Media: AV1 Amazon, Google, Samsung, ARM Temps d‚Äôencodage¬†¬ª&amp;gt; VVC S‚Äôameliore avec ML (Google) En deploiement: Netflix: depuis 2018 Android TV 10: obligatoire Twitch: 2022 Evolution du marche Changer de code $\\Rightarrow$ $ Nouveau HW + SW Nouvelle conso (W) Nouvelles box utilisateur Bandes passantes plus importantes Fibre, 4G, 5G, 802.11ax $\\Rightarrow$ taux de compression en second plan (cf H.264) Nouveau Netflix, Hulu, Amazon, Apple TV‚Ä¶ Veulent le code ‚Äúmagique‚Äù Pour toutes les box Dont la licence est la moins chere (cf AV1) Evolution du streaming Trivia $60\\%$ du trafic internet $\\color{green}{\\text{Netflix}: \\sim$ 2.25 B / an}$ 2018: +50\\%, 2019: + 59\\%, 2020: +47\\% 300 MT $CO_2$/an (~Espagne) $1\\%$ des emissions $CO_2$ mondiales Questions financieres et sociales evidentes " }, { "title": "DLIM: Face detection", "url": "/cours/posts/dlim_face_detection/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-22 14:00:00 +0100", "snippet": "Lien de la note HackmdFace detection in generalWhy is facre detection so difficult ? Pose (Out-of-Plane Rotation) and orientation (In-Plane Rotation)Presence or absence of structural componentsOcclusionsImaging conditionsFaces are highly non-rigid object (deformations)Related problems Face localization Facial feature extraction (landmarks such as eyes, mouth, ‚Ä¶) Face recognition Verification Facial expressionOverview of different approaches: Knowledge top-down base method Feature invariant methods (localization) Template-matching methods (localization) Appearance-based methods (detection)Apparence-based methods in details Eigenfaces Distribution-based methods Support Vector Machines (SVM) Sparse Network of Winnows Naive Bayes Classifier Hidden Markov models Information Theoretic Approaches (ITA) Inductive Learning (C4.5 and Find-S algorithms) Artficial Neural Networks (ANN) techniques Shallow networks (inverse de Deep) Deep learning Les connections residuelles permettent de faire une retropropagation beaucoup plus loin que le reste du reseau. Le gros defaut des VGG: ils ont enormement de poids poids $=$ parametres $\\neq$ hyperparametresIl y a de moins en moins de neurones en \\%. Plus on a de poids, plus on a de chance que notre reseau soit puissant mais plus on a de chance qu‚Äôune partie serve a rien.The beginning in 1994 Burel et Carel proposent une methodologie pour les ANN‚Äôs: La phase d‚Äôentrainement ou un systeme tunes les parametres internes La phase d‚Äôentrainement local ou le systeme adapte les poids specifiques a l‚Äôenvironnement d‚Äôun site local La phase de detection durant laquelle les poids ne bougent pas Vaillant, Montcoq et Le Cun: first translation invariant ANN, decides if each pixel belong or not to a given objectYang et Huang: first fully automatic human face recoginition system1997 Rowleu, Baluja, Kanade propose the first rotation-invariant method: Uses template-based approach Methodology: Regions are proposed A router network estimates the orientation of this region This network prepares the windows using this angle A detector network decides if the window contains a face 2004 First real-time face detection algo by Viola &amp;amp; Jones Tells if a given image of arbitrary size contains a human face, and if so, where it is Minimizes false positive and false negative rates Usually 5 types of Haar-like features $24\\times 24$ image contains a huge number of features ($162886$) Integral image for feature computation $A=1$, $B=2$, $C=3$, etc. Allows a low computational cost of features Principle The algorithm should deploy more resources to work on those windows more likely to containa face while spending as little effort as possible on the rest We can use weak classifiers Then we can mae a strong one with a sequence of weak ones Viola &amp;amp; Jones: use AdaBoostThe more layers, the less false positive:Overfeat (2014) Winner of the ImageNet Large Scale Visual Recognition Challenger of 2013 Makes at the sae time classification (blocks), localization (grouping blocks) and detection (merge windows) This multitask approach boosts the performance of the network Trained on ImageNEt 2012 Inspired for multi-viewing voting Uses multiscale factor of 1.4 Using a dense sliding windows thanks to convolution The better aligned the network window and the object, the strongest the confidence of thenetwork response. Efficiency: convolution computations in overlapping regions are shared Bounding boxes are accumulated instead of suppressed Only one shared network for 3 functionalities Uses a feature extractor for classification purpose Use offset to refine the resolution of the proposed windows Detection fine-tuning: negative training on the flyMethodology decomposition into blocks with 3 offsets for each block, estimation of the most probable corresponding class (overlapping) region proposals for each class (see below) bounding box deduction for each class (see below)The MTCNN face detection algorithm (2016)Zhang, Zhang &amp;amp; Li Real-time deep-learning-based face detection algorithm The MTCNN is a cascade of 3 similar networks (P/R/O-nets) The four steps: Computation of the (multiscale) image pyramid P-nEt: propositional network R-net: refinement net (filters and refines the results of the P-Net) O-net: output network (still refines, and propose landmarks) Use hard sample mining (the $30\\%$ easier cases fo not intervene in the retropropagation) to improve the detection results Originality: uses multi-task learning, that is, every network predict bounding boxes use regression to refine/calibrate the position of the edges of the bounding box applies Non-Maxmal Suppression (NMS) to keep only relevant candidate windows (merge of highly overlapped candidates) (can) propose 5 facial landmarks This multi-task seems to improve face detection compared to usual mono-task learning How does it work in pratice? It minimizes:\\[Loss=$\\alpha_1\\times L_{detection} + \\alpha_2\\times L_{regression} + \\alpha_3\\times L_{landmarks}$\\]where the first is based on cross-entropy, and the others are based on Euclidian lossFast R-CNN and its predecessors (2014-2015)Spatial-Pyramid Pool network (2014) Have been proposed to speed up R-CNN by sharing computation, The SPPnet computes a shared feature map using convolutions over the entire image, and only then extract features corresponding to each proposal to make the prediction, Then it concatenates the features of the proposal coming from each scale thanks to MaxPooling to a $6 \\times 6 \\times$ scales map (spatial pyramid). SPP-nets accelerates R-CNN by 10 to 100 times at test times and by 3 at training time. Drawback 1: Like the R-CNN, it is a multi-stage approach: First, feature extraction using convolution, Second, fine-tuning of a network using log loss, Third, SVM training, Fourth, fitting bounding-box regressors. Drawback 2: Features are written to disk, The fine-tuning cannot update the convolutional layers that precede the spatial pyramid pooling (limited accuracy).Fast R-CNN0 (2015) a Fast Region-based Convolutional Network method, Mainly made of several innovation to make is faster Uses Singular Value Decomposition (SVD) truncation to fasten the computations, Uses a multi-task loss to train all the network in one single stage (it jointly learns to classify objects proposals (windows) and refine their spatial locations), Trains the VGG16 9 times faster than the RCNN and 3 times faster than the SPP-nets, Is able to retropropagate the error in the convolutional layers (contrary to SPPnets and RCNN) and then increases the accuracy, No disk storage is required for feature caching.Faster R-CNN (2016) Usual object detection methods depended on (slow) region proposal algorithms, They got the original idea to use ANN‚Äôs to do these predictions on GPU (much faster), They called this technology Region Proposal Networks (RPNs). Properties is just made of several convolutional layers applied on the feature maps, It is then a fully convolutional layer (weights are shared in space), It is then translation-invariant in space (contrary to MultiBox method), it can be seen as a mini-network with a sliding-window applied on the feature map to predict proposals, predicts at the same time proposals using regression and objectness scores, is able to predict proposals with a wide range of scales and aspect ratios (bye default, 3 and 3 respectively). Since the Fast R-CNN does not have region proposal, they added their RPN before the Fast-RCNN to obtain the Faster R-CNN, The RPN is then an attention network since it tells to the Fast R-CNN where to look Since the efficiency of the Fast R-CNN depends on the region proposals, better proposal thanks to the RPN implies a better accuracy of the Faster R-CNN, To ensure that features used between the RPN and the Fast R-CNN are the same, they shared the weights of the Feature Extractor between them (faster, more accurate). It took then 10 milliseconds to compute the predictions of the RPN.Mask R-CNN (2018) Extension of Faster R-CNN aim is instance segmentationHas 3 outputs/prediction the usual bounding box predictions (from Faster R-CNN), the usual classification predictions (still from Faster R-CNN), the mask predictions (A small FCN applied to each RoI ‚Äì NEW !!),No competition is done among classes prediction Mask prediction is done in parallel The training is done with a multi-task loss:\\[Loss = \\alpha_1L_{class} + \\alpha_2L_{reg}+\\alpha_3L_{mask}\\] We can easily change the backbone (feature extractor) It runs a 5 fpsR-FCN Architectures (2016) Region-based Fully Convolutional Networks 2-stage object detection strategy Every layer is convolutional, whatever its role Almost all the computations are shared on the entire image Rols (candidate regions) are extracted to a Region Proposal Network (RPN) Uses position-sensitive score mapsOn decale la fenetre sur la droite: At top-middle probability map, the white pixels correspond to the probability that a headRetinaNet (2018) One-stage detector Uses an innovative focal loss Naturally handles class imbalance Uses a Feature Pyramid Network (FPN) backbone of ResNet architecture Then it provides a rich multi-scale feature pyramid (efficiency) At each scale, they attach subnetworks to classify and make regressionsDetectrons (2018-2019)Detectron V1 2018 (Facebook)Detectron V2 (Facebook)Real-time detection algorithmsYOLO (You Only Look Once) (2016) single-shot detection architecture Designed for real-time applications It does NOT predict regions of interests It predicts a fixed amount of detections on the image directly, They are then filtered to contain only the actual detections. faster than region-based architectures lower detection accuracy performs a multi-box bounding box regression on the input image directly Method: the image is overlayed by a grid, and for each grid cell, a fixed amount of detections are predicted.SSD (Single Shot Multibox Detector) (2016) Is a single-shot detection architecture Instead of performing bounding box regression on the final layer like YOLO, SSDs append additional convolutional layers that gradually decrease in size. For each additional layer, a fixed amount of predictions with diverse aspect ratios are computed, It results in a large number of predictions that differ heavily across size and aspect ratio.YOLOv2 (YOLO 9000) (2016) Extension of YOLOv1 Ability to predict objects at different resolutions, Computes the first bounding box predictions using clustering, Better performance than SSD." }, { "title": "TVID: De l&#39;image a l&#39;ecran", "url": "/cours/posts/tvid_image_ecran/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-17 14:00:00 +0100", "snippet": "Lien de la note HackmdCadences en pratique On a des problemes de precisionsTout est entier: PTS: temps image source STC: temps horloge affichageResolution d‚Äôincrement: TIR TIR(PTS) = duree d‚Äôune seconde dans le flux video TIR(STC) = duree d‚Äôune seconde a l‚ÄôaffichageSi TIR(PTS) non \\% TIR(STC), probleme de $\\color{red}{\\text{fraction continue!}}$ExempleTIR PTS = 90000 = 1 secondeSupposons STC = timer hardware a 5 KHz TIR(STC) $=5000$Pour un affichage a 50 fps: $\\Delta STC=5000/50=100$ (TIR \\%)Comment comparer STC avec TIR(STC) = 5000 vs PTS avec TIR(PTS) = 90000 Produit en croix\\[STC&#39; = STC \\times TIR(PTS) / TIR(STC) = STC \\times 18\\]STC‚Äô comparable avec PTS Mais jitter de STC multiplie par $18$Adaptation source 59,97 ips -&amp;gt; affichage 60 ips Theoriquement: adaptation par repetition 1 image sur 1000 En pratique: jitter PTS + jitter STC Tremblement du criteres PTS - STC BufferisationOn veut envoyer a l‚Äôaffichage une image a l‚Äôheure !On fait de la bufferisation pour les jeux CGI realtime Bufferisation: art de choisir l‚Äôimage a afficher Il faut qu‚Äôil y ait toujours une image a l‚ÄôecranBufferisation non VSYNC Envoyer le backbuffer suivant des qu‚Äôil est pretAvantages: Un seul backbuffer RapideInconvenient: $\\color{red}{\\text{Tearing back/front}}$Bufferisation VSYNC Permutter frontbuffer et back bufferAvantages Pas de tearingInconvenient $\\color{red}{\\text{Producteur aussi leant que l‚Äôafficheur}}$ Notre jeu/application va etre ralenti C‚Äôest le meme phenomene que celui du passage des jeux japonais aux consoles europeennes avec des jeux $20\\%$ plus lentBufferisation triple + VSYNC Deux backbuffers composes en alterance Au VSYNC: envoyer le backbuffer pret en front buffer Avantages Pas de tearing Decouplage cadence production vs affichage Inconvenients $\\color{red}{\\text{Deux backbuffers}}$ $\\color{red}{\\text{CPU/GPU a donf}}$ Comment afficher ?Comment cadrer l‚Äôimage dans l‚Äôecran ? En frequence En phaseEn frequence: Pulses verticaux: VSYNC Pulses horizontaux: HSYNCEn phase: Palliers avant/arrierePulses et palliers normalisesVGA, DVI, HDMI: Display Data Channel =&amp;gt; Extended Display Identification DataXorg: ‚ÄúModelines‚ÄùCadrage d‚Äôune image Vertical blanking Horizontal blankingDVI/HDMIHDMI 3DComment afficher des images 3D ? Plusieurs formats 3D numeriques Dans tous les cas, pixel clock $\\times 2$Checkerboard (NVIDIA): VBlank + VSync HSyncs + Lignes de pixels OG/OD en quinconce Lignes deux fois plus largesFrame pack (HDMI 1.4A)Analogique" }, { "title": "IMED2: Reconstruction tomographique - quand rien n&#39;est ideal", "url": "/cours/posts/imed2_tomographie/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-17 10:00:00 +0100", "snippet": "Lien de la note HackmdLes hypotheses fortes de FBP Beaucoup trop ideal La ligne est supposee connue Autrement dit: on a recupere $p$ dans $I=I_0e^{-p}$ .. ou plutot dans $I=\\int I_0(E)e^{-p(E)}dE$ Le detecteur n‚Äôa aucun defaut (la mesure est supposee parfaite) Or un detecteur est loin d‚Äôetre parfait Un photon qui atteint le detecteur est un photon qui vient de la source Or le rayonnement diffuse ne respecte pas cette hypothese L‚Äôobjet est statique pendant l‚Äôacquisition Or un patient respire, ses organes bougent, ses vaisseaux pulsent‚Ä¶ L‚Äôobjet est integralement vu sous toutes les angulations Nous parlerons de ce sujet et d‚Äôautres sujets lies a l‚Äôechantillonnage au prochain cours ! Problematiques de troncationNon-idealite du tube Les basses energies sont absorbees en permier: a mesure qu‚Äôon traverse des epaisseurs de materiaux, le spectre se reduit vers les hautes energies: l‚Äôenergie moyenne du spectre augmente, on appelle ce phenomene le durcisement du faisceauNon-idealite du detecteur Les problemes de la radiographie 2D‚Ä¶ sont aussi les problemes de tomographie ! + spread dans le detecteur + Reponse differente en fonction de l‚Äôenergie du photon + ‚Ä¶Comment on envisagerait de reparer ces artefacts circulaires ? Changer de detecteur (mais c‚Äôest cher)Compenser le phenomeneAvec quelle methode ? Avec la transformee de HoffC‚Äôest une transformee qui detecte les lignes, utile dans la projection polaireComment on recupere les nouvelles colonnes ? On regarde le gradientQuand on travaille dans le sinogram, toutes nos colonnes sont traitees de la meme facon.On peut travailler dans 2 domaines: Le domaine image Dans le sinogramme Besoin de plus de finesse mais detection plus robuste \\[\\begin{aligned}\\bar p &amp;amp;= -log(\\frac{I}{I_0})\\quad I = P+S\\\\&amp;amp;= \\log(I_0) - \\log(P+S)\\\\&amp;amp;= \\log(I_0) - \\log(P(I+\\underbrace{\\frac{S}{P}}_{\\color{red}{\\text{SPR} \\\\ \\text{scatter-to-primaray} \\\\ \\text{ratio}}}))\\end{aligned}\\]\\[\\bar p = p_{\\text{tree}} - \\log(1+SPR)\\]Interactions avec la matieres et rayonnement diffuse Ennemi public numero 1 de la tomographie RXRejection de diffuse: Augmenter l‚Äôair gap Reduire le champ de vue (collimation) Inserer une grille anti-diffuseC‚Äôest aussi un probleme en 2D:Est-ce que ca fait sens de forcer les contrastes en imagerie medicale ? Oui !Il faut que le contraste de l‚Äôimage global soit confortableComment fixer cette image ? Estimer la non-uniformiteOn a en non-uniformite pure:Si on applique la correction, on a:Qu‚Äôest-ce qu‚Äôon a comme defaut ? La forte surbrillance sur le bordL‚Äôarc de cercleLes niveaux de gris en bas de l‚Äôimage sont un peu plus clairs, on a presque trop corrige notre image Il faut faire attention avec ces methodes: ca peut etre pratique d‚Äôun POV visuel mais il ne faut pas creer de nouveaux artefactsPlein de gens on travaille sur des methodes pour corriger ces artefacts, l‚Äôun est la retroprojection differenciee. Et ca, c‚Äôest magique ! On a l‚Äôimpression que l‚Äôaxe horizontale est privilegieQu‚Äôest-ce qui nous donne une information ligne a ligne ?On est en train de dire que les lignes sont exactement les memes.Comme algorithme, on prend notre projection, on prend la projection ligne a ligne et on retroprojecte ca\\[p\\to\\delta_u p\\to\\boxed{DBP}\\to\\text{ligne}(i) = -2\\pi \\mathcal Hf[\\text{row#}i]\\\\\\mathcal H[\\mathcal H[f]] = -f\\]Avec $\\mathcal H$: transformee de HilbertIci, elle est mal calculee: Prenons par exemple la ligne $100$: on sait que notre objet est fini.Pourquoi c‚Äôest interessant ?Si notre objet est gros est qu‚Äôon a qu‚Äôun champ de vue (notre objet depasse), on fait une retroprojection differenciee et on inverse toutes les lignes de notre vue. On arrivera a reconstruire notre vue, tant bien meme que l‚Äôobjet est tronquee Mouvement et incoherence des donnees Catastrophique en image de bas de contrastes (tissus mous) comme en imagerie vasculaire" }, { "title": "IMED2: TP2", "url": "/cours/posts/imed2_tp2/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-15 09:00:00 +0100", "snippet": "Reconstruction tomographique (1/3)Vous avez d√©j√† apprivois√© la radiographie num√©rique rayons X, nous voici maintenant partis pour explorer l‚Äôunivers de la tomographie ! La tomographie (du grec $\\tau\\omicron\\mu\\omicron\\varsigma$, coupe) recouvre l‚Äôensemble des technologies permettant de visualiser l‚Äôint√©rieur d‚Äôun patient (comme une tranche de jambon), sans l‚Äôouvrir pour autant (car le jambon, dans notre cas, c‚Äôest le patient !).Ce premier cours sur la tomographie focalise sur les math√©matiques de la reconstruction tomographique. Il est plus aride que votre cours sur la radiographie num√©rique, mais la ma√Ætrise des outils math√©matiques appliqu√©s √† la tomographie est absolument indispensable : ce notebook doit vous aider √† vous les approprier ! Vous allez √©galement d√©couvrir ASTRA Toolbox, dont vous trouverez les d√©tails ici : https://www.astra-toolbox.com/from google.colab import drivedrive.mount(&#39;/content/gdrive&#39;,force_remount=True)import sysfrom pathlib import Pathroot = Path(&quot;/content/gdrive/My Drive/EPITA-2021/TP2 - Q4 2021&quot;)sys.path.append(str(root))import numpy as npfrom pathlib import Pathimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)from matplotlib import pyplot as pltfrom PIL import Imagenp.random.seed(26)root = Path.cwd()from ipywidgets import interact!pip install scikit-image==0.18from skimage.draw import diskMounted at /content/gdriveRequirement already satisfied: scikit-image==0.18 in /usr/local/lib/python3.7/dist-packages (0.18.0)Requirement already satisfied: scipy&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.4.1)Requirement already satisfied: networkx&amp;gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2.6.3)Requirement already satisfied: numpy&amp;gt;=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.19.5)Requirement already satisfied: matplotlib!=3.0.0,&amp;gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (3.2.2)Requirement already satisfied: PyWavelets&amp;gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (1.2.0)Requirement already satisfied: imageio&amp;gt;=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2.4.1)Requirement already satisfied: pillow!=7.1.0,!=7.1.1,&amp;gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (7.1.2)Requirement already satisfied: tifffile&amp;gt;=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18) (2021.11.2)Requirement already satisfied: python-dateutil&amp;gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (2.8.2)Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (2.4.7)Requirement already satisfied: kiwisolver&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (1.3.2)Requirement already satisfied: cycler&amp;gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (0.11.0)Requirement already satisfied: six&amp;gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&amp;gt;=2.1-&amp;gt;matplotlib!=3.0.0,&amp;gt;=2.0.0-&amp;gt;scikit-image==0.18) (1.15.0)# !apt-get install automake libtool# !pip install astra-toolbox# !apt-get install automake libtool# !git clone https://github.com/astra-toolbox/astra-toolbox# %cd astra-toolbox/build/linux# !./autogen.sh# !./configure --with-cuda=/usr/local/cuda \\# --with-python \\# --with-install-type=module# !make -j2# !make installimport astraPartie 1 - G√©om√©trie parall√®le, projection parall√®le, sinogrammesComme pr√©sent√© au d√©but du cours, on consid√®re la g√©om√©trie parall√®les suivante :Le principe de la reconstruction tomographique est le suivant. Dans le cas id√©al, la mesure au d√©tecteur correspond √† une loi de Beer-Lambert $I=I_0e^{-p}$, d‚Äôo√π je peux r√©cup√©rer $p$, qui est ma ligne int√©grale. Si mon image est bi-dimensionnelle, $p$ est un signal mono-dimensionnel. On appelle acquisition tomographique, la collection de telles lignes int√©grales $p$, lorsque l‚Äôangle des lignes int√©grales couvre un certain intervalle angulaire :\\(A_\\Theta = \\left\\lbrace p_\\theta \\right\\rbrace_{\\theta\\in\\Theta}, \\quad p_\\theta(u) = \\iint_{u_\\theta(\\underline{x})=u} \\mu(\\underline{x})\\mathrm{d}\\underline{x}.\\)En g√©om√©trie parall√®le, dans notre cas d‚Äô√©tude, $\\Theta = [0,\\pi]$. En mots simples, l‚Äôacquisition tomographique revient donc √† collecter les projections d‚Äôun objet sous tous les angles d‚Äôun demi-cercle. En mots compliqu√©s, l‚Äôacquisition tomographique est la transform√©e de Radon de $\\mu$.Le probl√®me de la reconstruction tomographique consiste √† r√©pondre √† la question suivante : Etant donn√©e $A_\\Theta$, est-il possible de reconstruire une carte 2D des $\\mu$ ? Selon que l‚Äôon se place dans un cas id√©al ou non, que l‚Äôon couvre bien tout le demi-cercle $[0,\\pi]$ ou non, que les projections soient tronqu√©es ou non, etc., la r√©ponse √† cette question sera plus ou moins simple. Dans la suite, on appellera $f$, la quantit√© reconstruite √† partir de $A_\\Theta$.Nous allons reprendre les r√©sultats math√©matiques fondamentaux qui permettent de r√©pondre au probl√®me de la reconstruction tomographique dans un cas id√©al en g√©om√©trie parall√®le 2D. Comme nous l‚Äôavons fait en radiographie num√©rique, nous verrons qu‚Äôil est n√©cessaire de r√©fl√©chir hors du cadre id√©al dans les cours 2 et 3 de tomographie.Questions Quelle est l‚Äô√©quation qui relie le point $\\underline{x}=(x,y)$ √† sa coordonn√©e projet√©e $u_\\theta(\\underline{x})$ ? On se donne un nombre nbins de bins de d√©tecteurs (voyez cela comme un nombre de pixels sur une image √† une ligne). D√©finissez l‚Äôaxe detector, dont l‚Äôorigine est au milieu du d√©tecteur ; on s‚Äôattend √† quelque chose comme : [-191.5 -190.5 -189.5 -188.5 ‚Ä¶ 188.5 189.5 190.5 191.5] lorsque nbins=384. On d√©finit une taille d‚Äôimage N et une image synth√©tique, constitu√©e d‚Äôun simple petit carr√© blanc sur fond noir. Afin de coller √† la d√©finition de la g√©om√©trie ci-dessus, d√©finissez les axes X et Y afin de placer l‚Äôorigine au centre de l‚Äôimage, comme sur la figure ci-dessus. D√©duisez-en les valeurs des coordonn√©es $(x_0, y_0)$ du centre du carr√© blanc, dans ce syst√®me de coordonn√©es. V√©rifiez sur l‚Äôimage que les lignes rouges intersectent bien le centre du carr√©. Attention aux axes : rappelez-vous qu‚Äôen Python, la premi√®re coordonn√©e donne la position verticale, la second coordonn√©e donne la position horizontale. On d√©finit un vecteur d‚Äôangles de $[0,\\pi]$. Quelle est la trajectoire du point $(x_0,y_0)$ en fonction des angles ? On utilise les fonctionnalit√©s d‚ÄôASTRA pour cr√©er une g√©om√©trie d‚Äôimage et un projecteur (regardez la documentation d‚ÄôASTRA pour en savoir plus). Puis, on g√©n√®re un sinogramme : il s‚Äôagit d‚Äôune image dont chaque ligne correspond √† la projection au d√©tecteur pour une angulation donn√©e (on parcourt le vecteur des angles d‚Äôacquisition en parcourant les lignes du sinogramme). Rajoutez √† cette image votre estimation de la trajectoire du point $(x_0,y_0)$ : qu‚Äôobservez-vous ? Faites de m√™me pour une image avec plusieurs carr√©s de diff√©rents niveaux de gris ; observez le sinogramme g√©n√©r√© : que pouvez-vous en dire ?# Question 2def getDetectorAxis(nbins): return (np.arange(nbins) - 0.5 * (nbins - 1))nbins = 384detector = getDetectorAxis(nbins)N = 256img = np.zeros((N,N))m = 3ctr = [32,192]img[ctr[0]-m:ctr[0]+m+1,ctr[1]-m:ctr[1]+m+1] = 1# Question 3X = getDetectorAxis(img.shape[1])Y = -getDetectorAxis(img.shape[0])x0, y0 = X[ctr[1]], Y[ctr[0]]plt.figure()plt.imshow(img,extent=[X.min(),X.max(),Y.min(),Y.max()])plt.axvline(x0,0,1,c=&#39;r&#39;,ls=&#39;--&#39;)plt.axhline(y0,0,1,c=&#39;r&#39;,ls=&#39;--&#39;)plt.show()# Question 4def getTrajectory(x0,y0,angles): return x0 * np.cos(angles) + y0 * np.sin(angles)angles = np.linspace(0,np.pi,180,False)traj = getTrajectory(x0,y0,angles)plt.figure()plt.plot(angles,traj)plt.xlabel(&#39;Angles (rad)&#39;)plt.ylabel(&#39;Detector coordinate&#39;)plt.show()# ASTRA framework :# - create image geometry (NxN image array)# - create projection geometry (parallel-beam, detector bin size, detector size, angular positions)# - create a projector (projection method, from an image geometry to a projection geometry)# - apply the projector to an existing image (img is adapted to the image geometry that was defined)# returns: an ID and a sinogramvol_geom = astra.create_vol_geom(N,N)proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles)proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom)sinogram_id, sinogram = astra.create_sino(img, proj_id)plt.imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])plt.title(&#39;Sinogram&#39;)plt.axis(&#39;auto&#39;)plt.xlabel(&#39;Detector coordinate&#39;)plt.ylabel(&#39;Angle (deg)&#39;)# Question 5plt.plot(traj,angles * 180 / np.pi,&#39;r&#39;,alpha=0.5)plt.show()img = np.zeros((256,256))m = 5centers = [[50,250],[250,50],[128,128],[64,128]]for i,ctr in enumerate(centers): img[ctr[0]-m:ctr[0]+m+1,ctr[1]-m:ctr[1]+m+1] = i+1 # Question 6 x0, y0 = X[ctr[1]], Y[ctr[0]] plt.axvline(x0,0,1) plt.axhline(y0,0,1)plt.imshow(img,extent=[X.min(),X.max(),Y.min(),Y.max()])plt.show()sinogram_id, sinogram = astra.create_sino(img, proj_id)plt.imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])plt.title(&#39;Sinogram&#39;)plt.axis(&#39;auto&#39;)plt.xlabel(&#39;Detector coordinate&#39;)plt.ylabel(&#39;Angle (deg)&#39;)plt.show()Partie 1 : Ce qu‚Äôil faut retenir Un peu de g√©om√©trie de lyc√©e suffit √† caract√©riser la g√©om√©trie d‚Äôacquisition parall√®le ! Lorsqu‚Äôon tourne autour d‚Äôun point du plan image, celui-ci se projette √† diff√©rents endroits du d√©tecteur ; sa trajectoire en fonction de l‚Äôangle d‚Äôacquisition d√©crit une sinuso√Øde. On repr√©sente l‚Äôacquisition $A_\\Theta$ sous la forme d‚Äôun sinogramme : il s‚Äôagit simplement des profils projet√©s au d√©tecteur √† chaque angle d‚Äôacquisition.Partie 2 - R√©tro-projection filtr√©eR√©tro-projection filtr√©eC‚Äôest l√† qu‚Äôil va falloir refaire appel √† vos cours de math√©matiques ! Au programme : calcul int√©gral, changements de variables, analyse de Fourier‚Ä¶ et distributions de Dirac !Tout commence avec le th√©or√®me coupe-projection qui est le suivant :\\(\\mathcal{F}_2[f](\\rho\\underline{\\theta}) = \\mathcal{F}_1[p_\\theta](\\rho),\\)o√π : $\\mathcal{F}n$ d√©signe la transform√©e de Fourier en $n$ dimensions, $f$ est l‚Äôimage 2D correspondant √† l‚Äôacquisition tomographique, $p\\theta$ est la projection de $f$ selon l‚Äôangle $\\theta$, $\\rho\\in\\mathbb{R}$, et $\\theta\\in[0,\\pi]$.Questions On se propose de d√©montrer le th√©or√®me fondamental de la reconstruction tomographique, appel√© ‚Äúth√©or√®me coupe-projection‚Äù : Partez de la d√©finition de la transform√©e de Fourier 1D de $p_\\theta$ Utilisez la d√©finition de la ligne int√©grale de $p_\\theta$ pour exprimer $p_\\theta$ en fonction de $f$ Trouvez une transform√©e de Fourier 2D dans l‚Äôexpression que vous obtenez Ce th√©or√®me fondamental est en r√©alit√© tout ce dont vous avez besoin pour reconstruire $f$ √† partir de $A_\\Theta$. Ecrivez $f$ comme la transform√©e de Fourier inverse de $\\mathcal{F}_2[f]$ Appliquez un changement de variables Utilisez le th√©or√®me coupe-projection Le r√©sultat de la question 2 doit aboutir √† l‚Äôinversion classique de la r√©troprojection filtr√©e :\\(f(\\underline{x}) = \\int_0^\\pi (h * p_\\theta)(u_\\theta(\\underline{x})) \\mathrm{d}\\theta,\\)o√π $h$ est appel√© le filtre rampe et correspond √† une multiplication dans l‚Äôespace de Fourier par $\\rho\\mapsto|\\rho|$. Pourquoi cette √©tape de filtrage est-elle vraiment n√©cessaire ? C‚Äôest ce qu‚Äôon va √©tudier dans la suite de ce notebook.Questions On g√©n√®re une image synth√©tique constitu√©e d‚Äôun disque uniforme centr√© de rayon $R$. On d√©finit le sinogramme associ√© avec ASTRA (https://www.astra-toolbox.com/files/misc/ICTMS2019/20190722_ICTMS_ASTRA_workshop_2d.pdf). Auriez-vous pu calculer analytiquement la valeur de cette projection ?On se propose de r√©aliser une r√©troprojection ‚Äúsimple‚Äù (backprojection en anglais). Cela revient √† reconstruire : $f_{\\mathrm{BP}}(\\underline{x}) = \\int_0^\\pi p_\\theta(u_\\theta(\\underline{x})) \\mathrm{d}\\theta.$ En termes simples, la r√©troprojection d‚Äôune projection $p_\\theta$ revient √† prendre la valeur de chaque point de $p_\\theta$, et √† recopier cette valeur tout le long de la ligne de projection. Observez l‚Äôimage reconstruite : comment vous semble-t-elle ? Renormalisez l‚Äôimage reconstruite pour que son maximum corresponde √† l‚Äôimage id√©ale. Tracez un profil horizontal au milieu de l‚Äôimage pour l‚Äôimage id√©ale et l‚Äôimage reconstruite : que pouvez-vous en d√©duire ? L‚Äôobservation sur ces profils est-elle coh√©rente avec votre lecture de l‚Äôimage ? A vous d‚Äôajouter le filtre rampe ! Une fa√ßon de faire est de remarquer que $ \\rho = \\frac{1}{2\\pi}(2i\\pi\\rho)(-i\\mathrm{sign}(\\rho))$. Reconnaissez-vous √† quoi correspond la multiplications par $2i\\pi\\rho$ dans Fourier ? Et la multiplication par $-i\\mathrm{sign}(\\rho)$ ? R√©alisez un filtre rampe et appliquez-le √† notre sinogramme. Tracez une ligne du sinogramme. L‚Äôeffet du filtre est-il passe-bas ? passe-haut ? passe-bande ?‚Ä¶ Lancez la reconstruction du sinogramme filtr√©, et comparez √† nouveau les profils horizontaux au centre de l‚Äôimage : qu‚Äôobservez-vous ?# Question 3angles = np.linspace(0,np.pi,180,False)N = 512vol_geom = astra.create_vol_geom(N,N)nbins = int(1.5*N)proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles)detector = getDetectorAxis(nbins)proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom)R = 32rr, cc = disk((N//2, N//2), R, shape=(N,N))img = np.zeros((N,N))img[rr,cc] = 1000sinogram_id, sinogram = astra.create_sino(img, proj_id)f,ax = plt.subplots(1,2,figsize=(12,5))ax[0].imshow(img)ax[0].set_title(&#39;Synthetic image&#39;)ax[1].imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])ax[1].set_title(&#39;Sinogram&#39;)ax[1].axis(&#39;auto&#39;)ax[1].set_xlabel(&#39;Detector coordinate&#39;)ax[1].set_ylabel(&#39;Angle (deg)&#39;)plt.tight_layout()plt.show()def analyticalCenteredDiskProjection(detector,R,mu): &quot;&quot;&quot; Projection analytique d&#39;un disque uniforme centr√© de rayon R et de coefficient lin√©aire d&#39;att√©nuation mu sur le d√©tecteur detector &quot;&quot;&quot; return 2 * mu * np.sqrt(R**2 - (detector ** 2)).clip(max = R ** 2)plt.figure(figsize=(12,5))plt.plot(detector,sinogram.mean(axis=0),label=&#39;Sinogram profile&#39;)plt.plot(detector,analyticalCenteredDiskProjection(detector,R,1000),&#39;--&#39;,label=&#39;Analytical projection&#39;)plt.legend()plt.tight_layout()plt.show()/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in sqrt# Create a data object for the reconstructionrec_id = astra.data2d.create(&#39;-vol&#39;, vol_geom)# Set up the parameters for a reconstruction algorithm using the CPUcfg = astra.astra_dict(&#39;BP&#39;)cfg[&#39;ReconstructionDataId&#39;] = rec_idcfg[&#39;ProjectionDataId&#39;] = sinogram_idcfg[&#39;ProjectorId&#39;] = proj_id# cfg[&#39;FilterType&#39;] = &#39;none&#39;# Create the algorithm object from the configuration structurealg_id = astra.algorithm.create(cfg)# Run the algorithmastra.algorithm.run(alg_id)# Get the resultrec = astra.data2d.get(rec_id) / angles.sizeplt.imshow(rec)plt.colorbar()plt.title(&#39;BP Reconstruction&#39;)plt.show()# Question 4width = (np.arange(N)-0.5*(N-1)).astype(&#39;int&#39;)prof0 = rec[:,rec.shape[1]//2] * 1000/ np.max(rec)prof = img[:,rec.shape[1]//2]plt.plot(width,prof,label=&#39;BP middle profile&#39;)plt.plot(width,prof0,label=&#39;Ideal profile&#39;)plt.legend()plt.show()# Question 6from scipy.signal import hilbertprof = analyticalCenteredDiskProjection(detector,R,1000) *1000 / np.max(rec)prof_grad = np.gradient(prof)filt = hilbert(prof_grad).imagprof0_grad = np.gradient(prof0)filt0 = hilbert(prof0_grad).imagfor k in range(sinogram.shape[0]): sinogram[k] = filtsdiff = len(filt) - len(filt0)f,ax = plt.subplots(1,2,figsize=(12,5))ax[0].plot(detector,filt, label=&#39;BP profile&#39;)ax[0].plot(detector[sdiff//2:-sdiff//2], filt0, label=&#39;Ideal profile&#39;)ax[1].imshow(sinogram,extent=[detector.min(),detector.max(),angles.max()*180/np.pi,angles.min()*180/np.pi])ax[1].set_title(&#39;Sinogram&#39;)ax[1].axis(&#39;auto&#39;)ax[1].set_xlabel(&#39;Detector coordinate&#39;)ax[1].set_ylabel(&#39;Angle (deg)&#39;)plt.tight_layout()plt.show()/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in sqrt/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:452: UserWarning: Warning: converting a masked element to nan. dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:459: UserWarning: Warning: converting a masked element to nan. a_min = np.float64(newmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:464: UserWarning: Warning: converting a masked element to nan. a_max = np.float64(newmax)&amp;lt;string&amp;gt;:6: UserWarning: Warning: converting a masked element to nan./usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan. return array(a, dtype, copy=False, order=order)# Question 7out_id, out = astra.creators.create_reconstruction(&#39;BP&#39;, proj_id, sinogram)out /= angles.size*2plt.imshow(out)plt.show()print(cfg)width = np.arange(N)-0.5*(N-1)prof = out[out.shape[0]//2]plt.plot(width,prof,label=&#39;FBP middle profile&#39;)plt.plot(width,img[img.shape[0]//2],label=&#39;Ideal profile&#39;)plt.legend()plt.grid()plt.show()/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:452: UserWarning: Warning: converting a masked element to nan. dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:459: UserWarning: Warning: converting a masked element to nan. a_min = np.float64(newmin)/usr/local/lib/python3.7/dist-packages/matplotlib/image.py:464: UserWarning: Warning: converting a masked element to nan. a_max = np.float64(newmax)&amp;lt;string&amp;gt;:6: UserWarning: Warning: converting a masked element to nan./usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan. return array(a, dtype, copy=False, order=order){&#39;type&#39;: &#39;BP&#39;, &#39;ReconstructionDataId&#39;: 12, &#39;ProjectionDataId&#39;: 10, &#39;ProjectorId&#39;: 8}On peut directement appliquer le filtre rampe en choisissant non pas une r√©troprojection simple (BP) mais une r√©troprojection filtr√©e (FBP). C‚Äôest ce qui est fait ci-dessous. Le r√©sultat est normalis√© par la taille d‚Äôun bin d√©tecteur.cfg = astra.astra_dict(&#39;FBP&#39;)cfg[&#39;ReconstructionDataId&#39;] = rec_idcfg[&#39;ProjectionDataId&#39;] = sinogram_idcfg[&#39;ProjectorId&#39;] = proj_idcfg[&#39;FilterType&#39;] = &#39;ram-lak&#39;# Create the algorithm object from the configuration structurealg_id = astra.algorithm.create(cfg)# Run 20 iterations of the algorithm# This will have a runtime in the order of 10 seconds.astra.algorithm.run(alg_id)# Get the resultrec = astra.data2d.get(rec_id)plt.imshow(rec)plt.colorbar()plt.title(&#39;Reconstruction&#39;)plt.show()width = np.arange(N)-0.5*(N-1)prof = rec[rec.shape[0]//2]plt.plot(width,prof,label=&#39;FBP middle profile&#39;)plt.plot(width,img[img.shape[0]//2],label=&#39;Ideal profile&#39;)plt.legend()plt.grid()plt.show()En regardant l‚Äôimage avec un fen√™trage plus serr√© autour de z√©ro, on voit appara√Ætre des motifs dans le fond de l‚Äôimage : ce sont des motifs typiques de ph√©nom√®nes d‚Äôinterpolation li√©s √† l‚Äôimpl√©mentation des projecteurs / r√©troprojecteurs. Regardez cette image avec ou sans zoom !zoom = slice(150,-150),slice(150,-150)zoom = slice(None,None)plt.imshow(rec[zoom],vmin=-20,vmax=20)plt.colorbar()plt.title(&#39;Reconstruction&#39;)plt.show()Partie 2 : Ce qu‚Äôil faut retenir La r√©troprojection simple est un op√©rateur qui redistribue un profil projet√© le long de sa direction de projection. La r√©troprojection simple ne reconstruit pas l‚Äôimage attendue ; pour reconstruire l‚Äôimage, un pr√©-filtrage des projections par le filtre rampe est n√©cessaire. ASTRA Toolbox permet de r√©aliser ces reconstructions.Partie 3 - Echantillonnage angulaireDans cette partie, nous allons commencer √† toucher du doigt les probl√©matiques d‚Äô√©chantillonnage angulaire. La formule FBP est une formule continue, que l‚Äôon discr√©tise ensuite pour en faire un algorithme : on boucle sur chaque projection, on filtre, on r√©troprojette en accumulant le r√©sultat dans un buffer. Que se passe-t-il si le nombre de projections n‚Äô√©chantillonne plus correctement l‚Äôintervalle $[0,\\pi]$ ?On se construit √† nouveau une image synth√©tique, constitu√©e d‚Äôun disque centr√©, et d‚Äôun point de tr√®s fort contraste.highIntensity = TrueN = 512R = 32img = np.zeros((N,N))rr, cc = disk((N//2, N//2), R, shape=(N,N))img[rr,cc] = 1000if highIntensity: rr, cc = disk((N//2, N//5), R//8, shape=(N,N)) img[rr,cc] += 5000plt.imshow(img)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fbe107756d0&amp;gt;Questions D√©finissez deux fonctions, project et reconstruct, pour automatiser la projection et la reconstruction. project prend en entr√©e une image, un nombre d‚Äôangles, et un offset ; cela permet de cr√©er un vecteur d‚Äôangles entre angleOffset et angleOffset+np.pi, dont la taille est donn√©e par le nombre d‚Äôangles. On peut ensuite cr√©er la g√©om√©trie de projection, le d√©tecteur, le projecteur, et le sinogramme. reconstruct prend en entr√©e un identifiant ASTRA d‚Äôun projecteur, un identifiant ASTRA d‚Äôun sinogramme, et cr√©e un reconstructeur FBP, qu‚Äôon utilisera pour reconstruire une image. Lancez les diff√©rentes exp√©riences, en g√©n√©rant diff√©rents sinogrammes avec un nombre d√©croissant de vues, et en reconstruisant les images √† partir de ces sinogrammes. Qu‚Äôobservez-vous ?# Question 1def project(img,nAngles,angleOffset=0): angles = np.linspace(angleOffset, angleOffset + np.pi, nAngles, False) N = img.shape[0] vol_geom = astra.create_vol_geom(N,N) nbins = int(1.5*N) proj_geom = astra.create_proj_geom(&#39;parallel&#39;, 1.0, nbins, angles) detector = getDetectorAxis(nbins) proj_id = astra.create_projector(&#39;strip&#39;, proj_geom, vol_geom) sinogram_id, sinogram = astra.create_sino(img, proj_id) return proj_id, sinogram_id, sinogram, angles, vol_geomdef reconstruct(proj_id, sinogram_id, vol_geom): rec_id = astra.data2d.create(&#39;-vol&#39;, vol_geom) cfg = astra.astra_dict(&#39;FBP&#39;) cfg[&#39;ReconstructionDataId&#39;] = rec_id cfg[&#39;ProjectionDataId&#39;] = sinogram_id cfg[&#39;ProjectorId&#39;] = proj_id cfg[&#39;FilterType&#39;] = &#39;ram-lak&#39; alg_id = astra.algorithm.create(cfg) astra.algorithm.run(alg_id) rec = astra.data2d.get(rec_id) return rec# Question 2for nAngles in 180//2**np.arange(5): print(nAngles) # projection de img avec nAngles vues proj_id, sinogram_id, sinogram, angles, vol_geom = project(img, nAngles) # reconstruction rec = reconstruct(proj_id, sinogram_id, vol_geom) plt.imshow(rec,vmin=-500,vmax=500) plt.colorbar() plt.title(&#39;Reconstruction&#39;) plt.show() plt.plot(rec[rec.shape[0]//2]) plt.show()18090452211Dans cette derni√®re exp√©rience, on g√©n√®re une image tr√®s grande (de taille 5120x5120), dans laquelle on n‚Äôa qu‚Äôun petit disque (de rayon 8 !).N = 5120R = 8img = np.zeros((N,N))rr, cc = disk((N//2, N//2), R, shape=(N,N))img[rr,cc] = 1000zoom = slice(img.shape[0]//2-128,img.shape[0]//2+128), slice(img.shape[1]//2-128,img.shape[1]//2+128)plt.imshow(img[zoom])plt.colorbar()plt.show()Questions Choisissez nAngles=32 vues, et g√©n√©rez un sinogramme √† partir de cette image. Cela peut prendre un peu de temps, l‚Äôimage est plus grande qu‚Äôavant ! Reconstruisez l‚Äôimage √† partir de ce sinogramme, et visualisez l‚Äôimage avec le petit zoom propos√© (afin de mieux voir les artefacts d‚Äô√©chantillonnage). L√† encore, soyez patient ! Reg√©n√©rez un sinogramme √† partir de cette reconstruction, mais cette fois-ci, d√©calez les angles d‚Äôacquisition d‚Äôun demi-pas d‚Äô√©chantillonnage angulaire. Que remarquez-vous sur le sinogramme obtenu ? Justifiez ce r√©sultat math√©matiquement ! Repartez cette fois de l‚Äôalgorithme FBP en tant que boucle sur les angles d‚Äôacquisition, et remontez jusqu‚Äôau plan de Fourier !‚Ä¶# Question 3nAngles = 32vol_geom = astra.create_vol_geom(N,N)nbinsIdeal = int(1.5*N)proj_id, sinogram_id, sinogram, angles, vol_geom = project(img, nAngles)# Question 4rec = reconstruct(proj_id, sinogram_id, vol_geom)plt.imshow(rec,vmin=-100,vmax=100,interpolation=&#39;none&#39;)plt.show()zoom = slice(rec.shape[0]//2-128,rec.shape[0]//2+128),slice(rec.shape[1]//2-128,rec.shape[1]//2+128)plt.imshow(rec[zoom],vmin=-100,vmax=100,interpolation=&#39;none&#39;)plt.colorbar()&amp;lt;matplotlib.colorbar.Colorbar at 0x7fbe0a33dfd0&amp;gt;# Question 5angleOffset = np.gradient(angles).mean() * 0.5proj_id, sinogram_id, sinogram, angles, vol_geom = project(rec, nAngles, angleOffset)plt.imshow(sinogram)plt.axis(&#39;auto&#39;)plt.colorbar()plt.show()# Question 5plt.plot(sinogram.mean(axis=0))plt.axhline(0,0,1,color=&#39;r&#39;)print(np.median(sinogram))0.0Partie 3 : Ce qu‚Äôil faut retenir FBP, en tant qu‚Äôalgorithme, r√©troprojette des projections filtr√©es avec leurs rebonds li√©s au filtre rampe. Lorsque l‚Äô√©chantillonnage angulaire diminue, ces rebonds ne se compensent plus entre eux et ils deviennent visibles dans l‚Äôimage sous forme de stries de sous-√©chantillonnage. Ces stries sont intrins√®quement li√©es au peuplement du plan de Fourier de l‚Äôimage reconstruite." }, { "title": "PRSTA: Revisions 1", "url": "/cours/posts/prsta_revisions_1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-11-12 14:00:00 +0100", "snippet": "Lien de la note HackmdExercice 1Partie 1Une variable aleatoire $X$ suit une loi normale de moyenne et de variance $1$. Nous voulons tester l‚Äôhypothese $H_0 : m = 0$ contre l‚Äôhypothese $H_1 : m \\gt 0$.Pour ce faire, nous disposons des observations : $-2.3, -0.2, 4.3, 1.1, 0,2.4, -1.6, 1.4, -1$ et $0.8$.L‚Äôhypothese $(H_0)$ est-elle rejetee avec un risque d‚Äôerreur de premiere espece de $5\\%$. Solution Sous l‚Äôhypothese $H_0$,\\[T = \\sqrt{n} \\frac{\\bar X_n - m}{\\sigma}\\sim N(0,1)\\\\t= \\sqrt{10}\\frac{0,48 - 0}{1}\\simeq 1,55\\] Zone de rejet:\\[\\color{red}{R=}\\{T\\gt q_{0,95}\\}\\\\\\{T\\gt1,64\\}\\] Est-ce que $t$ appartient a notre zone de rejet ? $t\\not\\in \\color{red}{R}$ $\\color{red}{\\text{donc}}$ l‚Äôhypothese $(H_0)$ n‚Äôest pas rejetee.Partie 2Une variable aleatoire $Y$ suit une loi normale de moyenne et de variance inconnue. Nous voulons tester l‚Äôhypothese $H_0 : m = 0$ contre l‚Äôhypothese $H_1 : m \\neq 0$.Pour ce faire, nous disposons des memes observations : $-2.3, -0.2, 4.3, 1.1, 0, 2.4, -1.6, 1.4, -1$ et $0.8$.L‚Äôhypothese $(H_0)$ est-elle rejetee avec un risque d‚Äôerreur de premiere espece de $5\\%$. Solution\\[Z_n = \\sqrt{n}\\frac{\\bar X_n - m_0}{\\sqrt{S_n^2}}\\sim T_{n-1}\\\\S_n^2:= \\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X_n)^2\\] Ici,\\[t = \\sqrt{10}\\frac{0,49 - 0}{1,96}\\simeq 0,79\\] Zone de rejet: on rejette des 2 cotes\\[\\{T\\gt 2.26\\}\\cup\\{T\\lt \\color{green}{-2.26}\\}\\\\R=\\color{green}{\\{T\\gt q_{0,975}\\}\\cup\\{T\\lt q_{0,025}\\}}\\] Pourquoi on n‚Äôa pas besoin d‚Äôutiliser Python ? Car c‚Äôest symetrique $\\color{green}{\\text{Pas}}$ de rejet car $\\color{blue}{t\\not\\in R}$Partie 3Une variable aleatoire $Z$ suit une loi normale de moyenne inconnue et de variance $\\sigma^2$. Nous voulons tester l‚Äôhypothese $H_0 : \\theta^2 = 4$ contre l‚Äôhypothese $H_1 : œÉ^2 \\lt 4$.Pour ce faire, nous disposons des memes observations : $-2.3, -0.2, 4.3, 1.1, 0, 2.4, -1.6, 1.4, -1$ et $0.8$.L‚Äôhypothese $(H_0)$ est-elle rejet¬¥ee avec un risque d‚Äôerreur de premiereespece de $10\\%$. Solution\\[T = (n-1)\\frac{S_n^2}{\\sigma_0^2}=\\boxed{\\frac{1}{\\sigma^2_0}\\sum_{i=1}^n(X_i-\\bar X_n)^2}\\] Sur l‚Äôechantillon,\\[t\\simeq \\frac{1}{4}\\times 34, 55 = 8,64\\]\\[\\begin{aligned}&amp;amp;P(T\\lt t)\\quad\\text{ou } T\\sim\\chi^2(9)\\\\&amp;amp;= P(T\\lt 8,64)\\\\&amp;amp;\\simeq 0,53\\color{orange}{\\gt 0,1}\\end{aligned}\\] Comment resonne-t-on avec la P-value ? Il faut que la P-value soit superieure ou egale Donc l‚Äôhypotese $(H_0)$ n‚Äôest pas rejetee.Exercice 2Selon une etude, la duree des smartphones de la marque Pomme suit une loi exponentielle de parametre $\\frac{1}{\\theta}$ avec $\\theta \\gt 0$ inconnu.Considerons un echantillon de taille $n$ que nous noterons $(X1,\\dots,Xn)$. L‚Äôentreprise souhaite savoir si elle peut garantir ses telephones pour une duree de deux ans. Justifier que le probleme se ramene au test des hypotheses : $H_0 : \\theta = 2$ contre $H1 : \\theta \\lt 2$. Francois propose la regle de decision suivante : L‚Äôhypothese $(H_0)$ est rejetee si $T \\lt 2$ ou \\(T = \\min_{1 \\le i\\le n} Xi\\). Justifier que la variable al¬¥eatoire T suit une loi exponentielle dont le parametre sera precise. En deduire que, sous l‚Äôhypothese $(H_0)$, $P(T \\lt 2) = 1 ‚àí \\exp(‚àín)$. (a) Pour $n = 10$, determiner la valeur de $\\alpha$. (b) De meme, pour $n = 100$, que remarquez-vous ? Que pensez-vous de la regle de decision retenue par Francois ? Solution 1. Comme le parametres est $\\frac{1}{\\theta}$, on veut affirmer sur la duree de vie moyenne $\\theta$ est $2$ ans, et on aura un probleme si jamais elle est inferieure car $E(\\varepsilon(\\frac{1}{2}))=2$ 2. $H_0$ rejetee si $T\\lt 2$ avec \\(T:=\\min_{1\\le i\\le n}X_i\\) 3.\\[\\begin{aligned}F(x)&amp;amp;=\\int_0^x\\lambda e^{-\\lambda t}dt\\\\&amp;amp;= [-e^{\\lambda y}]_0^x\\\\&amp;amp;= -e^{-xt} + 1 = 1-e^{-xt}\\end{aligned}\\]\\[\\begin{aligned}R(x) &amp;amp;= 1-F(x)\\\\&amp;amp;=e^{-\\lambda x}\\end{aligned}\\]\\[\\begin{aligned}P(T&amp;amp;\\gt x)\\\\P(\\min_{1\\le i\\le n}X_i&amp;amp;\\gt x)\\\\P(\\bigcap_{i=1}^n\\{X_i&amp;amp;\\gt n\\})\\end{aligned}\\] Sous $H_0$:\\[\\begin{aligned}P(T\\gt x) &amp;amp;= \\prod_{i=1}^nP(X_i\\gt x)\\\\&amp;amp;= P(X_1\\gt x)^n\\\\&amp;amp;= e^{-\\frac{n}{\\color{blue}{\\theta}}x}\\end{aligned}\\] \\[T\\sim\\varepsilon(\\frac{n}{\\color{blue}{\\theta}})\\] 4.\\[\\begin{aligned}P(T\\lt 2) &amp;amp;= F(2)\\\\&amp;amp;= 1-e^{-\\frac{n}{2}\\times 2}\\\\&amp;amp;= \\color{red}{1-e^{-n}}\\end{aligned}\\] 5.\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T\\lt 2\\vert \\theta=2)\\\\&amp;amp;= \\color{red}{\\boxed{1-e^{-n}}}\\end{aligned}\\\\n = 10\\\\\\alpha\\simeq = 0.9999\\] 6. Rien qu‚Äôavec $n=10$, on a un $\\alpha$ extremement eleve, la regle est donc NULLE. Test GLR\\[\\color{red}{H_0:\\theta = 2\\text{ contre } H_1:\\theta\\lt 2}\\]\\[T=\\frac{L(X_1,\\dots, X_n,2)}{L(X_1,\\dots, X_n,\\hat\\theta)}\\] Soit:\\[\\color{red}{H_0:\\frac{1}{\\theta} = \\frac{1}{2}\\text{ contre } H_1:\\frac{1}{\\theta}\\lt \\frac{1}{2}}\\]\\[\\begin{aligned}T&amp;amp;=\\frac{L(X_1,\\dots, X_n,\\color{green}{\\frac{1}{\\bar X_n}})}{L(X_1,\\dots, X_n,\\frac{1}{2})}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n\\color{green}{\\frac{1}{\\bar X_n}}e^{-\\color{green}{\\frac{1}{\\bar X_n}} X_i}}{\\prod_{i=1}^n\\frac{1}{2}e^{-\\frac{1}{2}X_i}}\\\\&amp;amp;= (\\color{green}{\\frac{2}{\\bar X_n}})^ne^{-\\sum_{i=1}^n(\\color{green}{\\frac{1}{\\bar X_n}}-\\frac{1}{2})X_i}\\end{aligned}\\] L‚Äôhypothese $(H_0)$ est rejetee si $T\\gt S_{\\alpha}$. Nous allons utiliser Wilks. \\[\\begin{aligned}R&amp;amp;=2\\ln(T)\\\\&amp;amp;= 2n\\ln(\\color{green}{\\frac{2}{\\bar X_n}})-2\\sum_{i=1}^n(\\color{green}{\\frac{1}{\\bar X_n}}-\\frac{1}{2})X_i\\\\\\end{aligned}\\] Pour $n$ suffisamment grand:\\[\\{R\\sim\\chi^2(1)\\}\\]" }, { "title": "Petit disclaimer", "url": "/cours/posts/disclaimer/", "categories": "Image S9, blabla", "tags": "Image, S9, blabla", "date": "2021-11-12 10:00:00 +0100", "snippet": "Hello tres chers Images (oui je precise Image parce que je sais que les autres majeures vont direct dans categories-&amp;gt;ASE2/3)En ce moment mes notes sont plus que bancales. J‚Äôai envie de dire que c‚Äôest ‚Äúnormal‚Äù, on croule sous les projet. D‚Äôhabitude la facon dont le site fonctionne c‚Äôest que je rentre $\\to$ je retravaille mes notes $\\to$ je poste. Je vous laisse deviner qu‚Äôen ce moment c‚Äôest pas trop le cas vu que j‚Äôai pas vraiment le temps pour.J‚Äôai poste des nouvelles notes non retravaillees, elles sont super brouillon et y‚Äôa des TODO partout.Une fois cette vague de projet passes, je retravaillerais les notes en question pour que vous ayez un truc un chouia plus potable que ce qu‚Äôil y a actuellement.Voila voila, je sais pas qui va lire ca mais au moins maintenant vous savez pourquoi mes notes les plus recentes sont aussi degueu." }, { "title": "IMED2: TP1", "url": "/cours/posts/imed2_tp1/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-11-12 09:00:00 +0100", "snippet": "# from google.colab import drive# drive.mount(&#39;/content/gdrive&#39;,force_remount=True)import sysfrom pathlib import Pathroot = Path(&quot;./&quot;)sys.path.append(str(root))import numpy as npfrom pathlib import Pathimport matplotlib as mplmpl.rc(&#39;image&#39;, cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)from matplotlib import pyplot as pltfrom PIL import Imagenp.random.seed(26)Partie 1 - Loi de Beer-Lambert, bruit, contrastesJouer avec les projections‚Ä¶Loi de Beer-LambertTout mat√©riau est caract√©ris√© par un coefficient lin√©aire d‚Äôatt√©nuation $\\mu$ qui a comme dimension l‚Äôinverse d‚Äôune longueur. A la travers√©e d‚Äôun milieu, l‚Äôintensit√© initiale d‚Äôun faisceau de rayons X ($I_0$) est att√©nu√©e selon la loi de Beer-Lambert suivante :\\(I = I_0 \\exp(-p),\\)o√π :\\(p = \\int_L \\mu(l)dl,\\)et $L$ est la ligne suivie par les photons X. Nous raffinerons cette formule au fur et √† mesure du cours, car cette mod√©lisation est incompl√®te. A commencer par l‚Äôabsence de bruit statistique ! En r√©alit√©, l‚Äôobservation $I$ fluctue autour de la valeur donn√©e par la loi de Beer-Lambert selon une loi de Poisson :\\(I \\sim \\mathcal{P}\\left(I_0 \\exp\\left(-\\int_L \\mu(l)dl\\right)\\right).\\)En pratique, si on mesure $I$, on s‚Äôint√©resse plut√¥t √† l‚Äôint√©grale $p$, obtenue (lorsqu‚Äôon n√©glige le bruit) par passage au logarithme:\\(p=\\log(I_0)-\\log(I).\\)Questions Une loi de Poisson a pour densit√© de probabilit√© $P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}$. Calculer l‚Äôesp√©rance et la variance d‚Äôune variable al√©atoire suivant une loi de Poisson. Qu‚Äôen d√©duisez-vous sur l‚Äô√©volution du SNR en fonction de $I_0$ ? (Faites le calcul !) Ecrire une fonction sumCols(img) qui prend une image 2D en entr√©e et retourne le profil somme le long de l‚Äôaxe vertical (l‚Äôaxe des $x$ de l‚Äôimage). A quoi correspond cette fonction dans la loi de Beer-Lambert ? Ecrire une fonction beerLambert(img,I0) qui calcule le signal au d√©tecteur apr√®s application de la loi de Beer-Lambert (avec sa statistique de Poisson) sur un profil 1D tel que sorti de sumCols().1.\\(\\begin{aligned}E[X]&amp;amp;=\\sum_{k=0}^{+\\infty}kP(X=k)\\\\&amp;amp;= \\sum_{k=0}^{+\\infty}k\\frac{\\lambda^k}{k!}e^{-\\lambda}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k=1}^{+\\infty}\\frac{\\lambda^k}{(k-1)!}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k=1}^{+\\infty}\\frac{\\lambda^{k+1}}{k!}\\\\&amp;amp;= \\lambda e^{-\\lambda}\\underbrace{\\sum_{k=0}^{+\\infty}\\frac{\\lambda^k}{k!}}_{e^{\\lambda}}\\end{aligned}\\\\\\boxed{E[X] = \\lambda}\\\\\\)\\[\\sigma^2=\\lambda\\]3.sumCols(img) $\\to[\\int_{c_1}\\mu d, \\int_{c_2}\\mu d, \\dots]$ car une integrale n‚Äôest rien d‚Äôautre qu‚Äôune somme# Question 2def sumCols(img): &quot;&quot;&quot; img est un np.ndarray (de dimension 2) sumCols(img) retourne un vecteur de m√™me taille que le nombre de colonnes de img, chaque √©l√©ment du vecteur √©tant √©gal √† la somme des √©l√©ments de la colonne correspondante dans img &quot;&quot;&quot; return np.sum(img, axis = 0)# Question 3def beerLambert(prof,I0): &quot;&quot;&quot; prof est une sortie de sumCols() I0 est un param√®tre correspondant √† l&#39;intensit√© dans l&#39;air (feu nu) beerLambert(prof,I0) renvoie une r√©alisation de la loi de Beer-Lambert (statistique de Poisson) &quot;&quot;&quot; return np.random.poisson(I0*np.exp(-prof))arr = np.array([[1, 2],[3, 4]])arr, beerLambert(sumCols(arr), 1)(array([[1, 2], [3, 4]]), array([0, 0]))Questions Lancez le code ci-dessous, qui g√©n√®re une image synth√©tique compos√©e d‚Äôun objet de ‚Äúfond‚Äù (le grand carr√©) et d‚Äôune structure d‚Äôint√©r√™t (le petit carr√©). Distinguez-vous bien le petit carr√© du grand carr√© √† l‚Äôoeil nu? G√©n√©rez des profils de mesures selon la loi de Beer-Lambert (loi de Poisson), avec I0 = 1e6, I0 = 1e4, I0 = 1e2, et I0 = 1. Qu‚Äôobservez-vous sur le profil d‚Äôatt√©nuation ? sur le profil reconverti en log ?# Question 4backgroundValue = 0.01relativeContrast = 0.05# G√©n√©ration d&#39;une image synht√©tiqueimg = np.zeros((128,128))img[32:-32,32:-32] += backgroundValueimg[48:-48,48:-48] += relativeContrast*backgroundValueplt.figure()plt.imshow(img)plt.colorbar()plt.show()# I0 = 1e6, 1e4, 1e2, 1I0=1e6# Question 5 : g√©n√©ration du profil d&#39;att√©nuationprof0 = sumCols(img)attenuation = beerLambert(prof0, I0)f,ax = plt.subplots(1,3,figsize=(18,4))ax[0].plot(prof0,&#39;-o&#39;)ax[1].plot(attenuation,&#39;-o&#39;)# profil reconverti en logprof = np.log(I0)-np.log(attenuation)ax[2].plot(prof,&#39;-o&#39;)plt.show()Analyser les donn√©es de fa√ßon plus quantitativeNous allons quantifier les ph√©nom√®nes observ√©s pour en tirer des conclusions plus solides. Le but de l‚Äôexercice est ici de comparer le niveau de contraste que l‚Äôon observe dans img entre le petit et le grand carr√©, et le niveau de ‚Äúcontraste‚Äù associ√© dans le profil issu de sumCols(img). Aller chercher de fa√ßon plus ou moins automatique ce genre d‚Äôinformations n√©cessite de savoir jouer un peu avec les signaux.Questions Calculez (sans fonction toute faite) une diff√©rence finie d‚Äôordre 1 : Si $p$ est le profil issu de sumCols(img), alors la diff√©rence finie √† l‚Äôindice $i$ est $g_i = p_{i+1}-p{i}$. Tracez le profil de la valeur absolue de cette diff√©rence finie : que fait-il ressortir ? Nous allons extraire des informations de ce nouveau profil $g$. Utilisez la fonction np.where pour r√©cup√©rer les points de $g$ qui correspondent √† la zone projet√©e du grand carr√©. Pouvez-vous r√©p√©ter l‚Äôop√©ration pour trouver les points correspondant √† la projection du petit carr√© ? D√©duisez-en les calculs des quantit√©s suivantes : valeur moyenne $B$ dans le ‚Äúfond‚Äù (la projection du grand carr√© seul), valeur moyenne $C$ dans la ‚Äústructure‚Äù (la projection du grand carr√© et du petit carr√© ensemble), √©cart-type $\\sigma_B$ dans le ‚Äúfond‚Äù. Calculez les valeurs de contraste relatif $C_r$ et de CNR (https://howradiologyworks.com/x-ray-cnr/) d√©finis comme suit :\\(C_r = \\frac{C-B}{B}, \\quad \\mathrm{CNR} = \\frac{|C-B|}{\\sigma_B}.\\)# Question 6 : diff√©rence finie d&#39;ordre 1def g(x): &quot;&quot;&quot; g(x) calcule la diff√©rence finie &quot;Euler forward&quot; g(x)[i] = x[i+1]-x[i] &quot;&quot;&quot; return x[1:]-x[:-1]grad = np.abs(g(prof0))plt.plot(grad)[&amp;lt;matplotlib.lines.Line2D at 0x7efe27a46490&amp;gt;]# Question 7 : trouver les points de grad (et donc de prof0) qui correspondent √† la projection du grand carr√©bmin, bmax = np.where(grad &amp;gt; 0.9 * grad.max())[0]bmin += 1f,ax = plt.subplots()ax.plot(range(bmin,bmax),prof0[bmin:bmax])ax1=ax.twinx()ax1.plot(range(bmin,bmax),grad[bmin:bmax],c=&#39;r&#39;,ls=&#39;--&#39;,alpha=0.4)[&amp;lt;matplotlib.lines.Line2D at 0x7efe27963070&amp;gt;]# Question 8 : m√™me principe, pour r√©cup√©rer la zone de projection du petit carr√©bmin1, bmax1 = np.where(grad[bmin:bmax] &amp;gt; 0.9 * grad[bmin:bmax].max())[0]bmin1 += bmin + 1bmax1 += bmin plt.plot(range(bmin1,bmax1),prof0[bmin1:bmax1])[&amp;lt;matplotlib.lines.Line2D at 0x7efe278dd4c0&amp;gt;]# Question 9 : Construction des zones d&#39;int√©r√™t du profil# [u00,u01[ : zone de fond gauche# [u10,u11[ : zone de contraste# [u20,u21[ : zone de fond droitemargin = 5u00 = bmin + marginu01 = bmin1 - marginu10 = bmin1 + marginu11 = bmax1 - marginu20 = bmax1 + marginu21 = bmax - marginplt.plot(range(bmin,bmax),prof0[bmin:bmax])plt.plot(range(u00,u01),prof0[u00:u01],c=&#39;r&#39;,lw=5)plt.plot(range(u10,u11),prof0[u10:u11],c=&#39;g&#39;,lw=5)plt.plot(range(u20,u21),prof0[u20:u21],c=&#39;r&#39;,lw=5)[&amp;lt;matplotlib.lines.Line2D at 0x7efe278c1d60&amp;gt;]# Question 9 (suite) : calcul du contraste relatif et du CNR sur profbackground = np.concatenate([prof[u00:u01], prof[u20:u21]])backgroundEstimate = background.mean() # BbackgroundNoiseEstimate = background.std() # CcontrastEstimate = prof[u10:u11].mean() # teta_brelativeContrast = (backgroundNoiseEstimate - backgroundEstimate) / backgroundEstimate # Cr = (C - B) / Bcnr = np.abs(backgroundNoiseEstimate - backgroundEstimate) / contrastEstimate # CNR = |C - B| / teta_b print(&#39;Relative contrast:&#39;,np.round(relativeContrast,3))print(&#39;CNR:&#39;,np.round(cnr,3))Relative contrast: -0.998CNR: 0.975Partie 1 : Ce qu‚Äôil faut retenir Il est plus facile d‚Äôidentifier un contraste dans une image que dans une projection Le bruit de Poisson rend la t√¢che d‚Äôidentification de faibles contrastes dans les projections encore plus difficile Le bon c√¥t√© du bruit de Poisson, c‚Äôest que le bruit augmente moins vite que le signal avec $I_0$: ainsi le SNR s‚Äôam√©liore lorsque $I_0$ augmente Une image en dynamique exponentielle est difficile √† lire: on pr√©f√®re r√©cup√©rer une dynamique plus lin√©aire en passant au logPartie 2 - Cha√Æne de traitement d‚Äôune image de radiographie num√©riqueUne image brute lue au d√©tecteur √† rayons X est loin d‚Äô√™tre acceptable pour un radiologue ; dans cette partie, nous allons explorer la cha√Æne de traitement appliqu√©e sur une image brute afin de la pr√©parer √† √™tre pr√©sent√©e au radiologue.Chargez l‚Äôimage mesur√©e au d√©tecteur : c‚Äôest une image inexploitable en l‚Äô√©tat ! ‚ÄúBad pixels‚Äù, non-uniformit√©s du fond, dynamique exponentielle‚Ä¶ Cette image a besoin d‚Äô√™tre trait√©e avant d‚Äô√™tre regardable.I0 = 1e6fn = Path(&quot;homer_measurement_noisy.704.640.raw&quot;)measurement = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))plt.imshow(measurement)plt.axis(&#39;off&#39;)plt.show()Correction d‚Äôoffsets, de gains, bad pixelsEn th√©orie, lorsque la loi de Beer-Lambert annonce que l‚Äôon doit (au bruit pr√®s) mesurer une valeur $I$ au d√©tecteur, on s‚Äôattend √† ce que la mesure soit √©gale √† $I$. En pratique, ce n‚Äôest pas le cas : le plus souvent, on consid√®re que la mesure est une fonction affine de la valeur th√©orique : $I_m = aI+b$. Cette fonction affine est diff√©rente pour chaque pixel.On appelle offsets, les valeurs qui sortent d‚Äôun d√©tecteur alors qu‚Äôil n‚Äôest pas expos√© aux rayons X : en th√©orie, le d√©tecteur devrait retourner une image noire (z√©ros) ; en pratique, l‚Äô√©lectronique du d√©tecteur, les d√©fauts de conception, font que l‚Äôimage non expos√©e n‚Äôest pas nulle. Les offsets correspondent donc au param√®tre $b$ de la fonction lin√©aire.Lorsque le d√©tecteur n‚Äôest pas expos√© aux rayons X, il peut lire √† vide plusieurs images √† la suite : c‚Äôest √† partir de ces lectures multiples que l‚Äôon peut estimer une carte d‚Äôoffsets $b$.De m√™me, lorsque l‚Äôon exposre uniform√©ment le d√©tecteur sans objet dans le champ, on s‚Äôattend √† mesurer une intensit√© constante au d√©tecteur apr√®s soustraction des offsets ; en pratique, on mesure $I_m-b=aI$, l√† encore, avec des valeurs de $a$ diff√©rentes par pixel.Une lecture multiple du d√©tecteur expos√© aux rayons X peut permettre d‚Äôestimer la carte des gains $a$.Les ‚Äúbad pixels‚Äù sont des pixels du d√©tecteur qui ne r√©pondent tout simplement plus ; il y en a forc√©ment, car malgr√© toutes les pr√©cautions lors de la production et de l‚Äôacheminement des d√©tecteurs, il est impossible de garantir l‚Äôinfaillibilit√© de tous les pixels du d√©tecteur. Heureusement, il est possible d‚Äôidentifier la position de ces bad pixels, et d‚Äôinterpoler les valeurs √† partir des pixels voisins.Questions Chargez la s√©rie d‚Äôimages de lectures √† vide du d√©tecteur ; affichez la premi√®re image de la s√©rie : que voyez-vous ? Qu‚Äôest-ce qui diff√®re d‚Äôune image √† l‚Äôautre ? Proposez une estimation de la carte d‚Äôoffsets √† partir de cette s√©rie d‚Äôimages; corrigez la mesure en offsets : voyez-vous beaucoup de diff√©rences entre l‚Äôimage corrig√©e et non corrig√©e ? pourquoi ?# Question 1fn = Path(root/&quot;offsetMapAcq.50.704.640.raw&quot;)offsetMapAcq = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((50,704,640))plt.imshow(offsetMapAcq[0])plt.colorbar()plt.axis(&#39;off&#39;)plt.show()D‚Äôou vient ce bruit ? Il y a un bruit inherent a l‚Äôelectronique du detecteur# Question 2offsetMap = offsetMapAcq.mean(axis = 0)plt.imshow(offsetMap,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.axis(&quot;off&quot;)plt.colorbar()plt.show()# Question 2 (suite)f,ax = plt.subplots(1,2)ax[0].imshow(measurement,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_axis_off()ax[0].set_title(&#39;Measurement&#39;)ax[1].imshow((measurement-offsetMap).clip(min=0),cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_axis_off()ax[1].set_title(&#39;Offset-corrected&#39;)Text(0.5, 1.0, &#39;Offset-corrected&#39;)Question Chargez la s√©rie d‚Äôimages de lectures du d√©tecteur uniform√©ment expos√© ; proposez une estimation de la carte d‚Äôoffsets √† partir de cette s√©rie d‚Äôimages, et corrigez la mesure en gain : qu‚Äôobservez-vous ?# Question 3fn = Path(root/&quot;gainMapAcq.50.704.640.raw&quot;)gainMapAcq = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((50,704,640))plt.imshow(gainMapAcq[0])plt.axis(&#39;off&#39;)plt.colorbar()plt.show()gainMap = (gainMapAcq - offsetMap).clip(min=0).mean(axis = 0)gainMap /= np.median(gainMap)plt.imshow(gainMap,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.axis(&quot;off&quot;)plt.colorbar()plt.show()# Question 3 (suite)tmp = (measurement - offsetMap).clip(min=0) / gainMapplt.imshow(tmp,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-17-a5367ba78078&amp;gt;:3: RuntimeWarning: invalid value encountered in true_divide tmp = (measurement - offsetMap).clip(min=0) / gainMapQuestion Proposez une d√©tection des pixels ‚Äúmorts‚Äù (bad pixels) ; comparez votre d√©tection √† la carte des bad pixels que vous aurez charg√©. Terminez la correction de l‚Äôimage d√©j√† corrig√©e en offsets et en gains, en fournissant la carte des bad pixels √† la fonction d‚Äôinpainting.# Question 4# (...)badPixelMap = (offsetMap == 0)plt.imshow(badPixelMap,interpolation=&#39;none&#39;)plt.axis(&quot;off&quot;)plt.show()fn = Path(root/&quot;badPixels.704.640.raw&quot;)badPixels = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))plt.imshow(badPixels-badPixelMap)plt.axis(&quot;off&quot;)plt.show()# Question 4 (suite)import cv2tmp[badPixelMap==1] = 0output = cv2.inpaint(tmp.astype(&#39;float32&#39;), badPixelMap.astype(&#39;uint8&#39;), 1, cv2.INPAINT_NS)plt.imshow(output,interpolation=&#39;none&#39;,cmap=&#39;gray&#39;)plt.colorbar()plt.axis(&quot;off&quot;)plt.show()Question Chargez la d√©tection ‚Äúid√©ale‚Äù ; comparez l‚Äôimage id√©ale et l‚Äôimage corrig√©e : qu‚Äôobservez-vous ?# Question 5fn = Path(root/&quot;Inoisy.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))res = (output-I)/Iplt.imshow(res,vmin=res.mean()-3*res.std(),vmax=res.mean()+3*res.std())plt.colorbar()plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-20-63d627f3aeb6&amp;gt;:5: RuntimeWarning: divide by zero encountered in true_divide res = (output-I)/I&amp;lt;ipython-input-20-63d627f3aeb6&amp;gt;:5: RuntimeWarning: invalid value encountered in true_divide res = (output-I)/ITransformation logRappelez-vous que la loi de Beer-Lambert fournit $I=I_0e^{-p}$ ; puisque $p$ est la quantit√© r√©ellement int√©ressante, on transforme les mesures suivant : \\(p = \\log(I_0)-\\log(I).\\)Questions Transformez l‚Äôimage corrig√©e via l‚Äô√©quation pr√©c√©dente ; afin de ne pas appliquer le log √† z√©ro, utilisez la fonction np.clip pour clipper les valeurs inf√©rieures √† $10^{-3}$. Qu‚Äôobservez-vous ? D√©finissez une fonction linlog(x,x0) qui correspond au logarithme de $x$ au-del√† d‚Äôun seuil $x_0$, et qui se prolonge lin√©airement jusqu‚Äô√† z√©ro avec continuit√© des pentes. Transformez l‚Äôimage corrig√©e en utilisant cette nouvelle fonction : le r√©sultat est-il plus convaincant ?# Question 6plt.imshow(np.log(I0)-np.log(output.clip(min=1e-3)))plt.axis(&quot;off&quot;)plt.colorbar()plt.show()Des qu‚Äôon arrive dans des zones petites, notre lof s‚Äôeffondre, d‚Äôou le bruit blanc.C‚Äôest pour ca qu‚Äôon prefere linearise le $\\log$ pour avoir des pentes plus douces# Questions 7 &amp;amp; 8def linlog(x,x0): &quot;&quot;&quot; linlog(x,x0) est un logarithme naturel standard au-dessus de x0 En-dessous de x0, linlog(x,x0) est lin√©aire, avec une continuit√© de pentes en x0 &quot;&quot;&quot; x0 = float(x0) x = float(x) if isinstance(x,(int,float)) else x.astype(float)# return np.where(x &amp;gt;= x0, np.log(x), (1/x0)*x) return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + bplt.figure()x = np.linspace(0,10,1000)x0 = 3plt.plot(x[1:],np.log(x.max())-np.log(x[1:]),label=&#39;log&#39;)plt.plot(x,np.log(x.max())-linlog(x,x0),label=&#39;linlog&#39;)plt.axvline(x0,0,1,color=&#39;k&#39;,ls=&#39;dashed&#39;)plt.legend()plt.show()outLog = np.log(I0)-linlog(output,x0)plt.imshow(outLog)plt.colorbar()plt.axis(&quot;off&quot;)plt.show()&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + b&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + bf,ax = plt.subplots(1,2)ax[0].imshow(measurement,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_axis_off()ax[1].imshow(outLog,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_axis_off()On a moins de bruit et on recupere des infos interessantes.Partie 2 : Ce qu‚Äôil faut retenir Une image brute doit √™tre trait√©e avant d‚Äô√™tre pr√©sent√©e √† l‚Äôutilisateur Ces traitements comprennent g√©n√©ralement une correction en offsets et en gains, et une correction de bad pixels Ces corrections sont issues de proc√©dures de calibration offline, fournissant des informations utilis√©es ensuite online sur les images La transformation via le logarithme peut poser probl√®me dans les zones de faible exposition : dans ce cas, un logarithme lin√©aris√© dans les faibles valeurs est pertinentPartie 3 - Contr√¥le automatique de l‚Äôexposition (AEC)Le principe ALARA (as low as reasonably achievable, de plus en plus remplac√© par le terme ALADA ‚Äì as low as diagnostically achievable) signifie que si l‚Äôon doit fournir une dose importante l√† o√π on en a besoin (et o√π l‚Äôanalyse b√©n√©fice/risque est en faveur de cette exposition aux radiations), en revanche il faut √† tout prix r√©duire la dose de rayonnements ionisants lorsque celle-ci n‚Äôapporte rien d‚Äôun point de vue clinique. C‚Äôest dans cette optique que les techniques de contr√¥le automatique de l‚Äôexposition (automatic exposure control, ou AEC) ont √©t√© d√©velopp√©es dans diff√©rentes modalit√©s.Dans l‚Äôexemple qui suit, on se place dans le cadre d‚Äôune adaptation ligne √† ligne de l‚Äôexposition du patient ; cela peut √™tre le r√©sultat d‚Äôun filtre physique qui s‚Äôadapterait en sortie du tube, ou d‚Äôun syst√®me √† balayage qui scannerait ligne √† ligne.Supposons que les structures d‚Äôint√©r√™t soient ‚Äúcorrectement‚Äù centr√©es au niveau du d√©tecteur ; le bruit au d√©tecteur d√©pendant de la ligne int√©grale travers√©e $p$, si l‚Äôon veut garantir un niveau de bruit sup√©rieur ou √©gal √† un niveau cible sur une ligne du d√©tecteur, il faut identifier la zone ‚Äúcentr√©e‚Äù la plus radio-opaque de cette ligne. En r√©p√©tant cette recherche ligne √† ligne, on obtient des points ${p_{\\max,i}}_i$ qui nous d√©finissent une courbe caract√©ristique $t$.Questions Re-d√©finissez l‚Äôimage id√©ale $p$ √† partir de I et I0 ; pour chaque ligne, r√©cup√©rez le maximum de cette ligne dans le tiers central, ainsi que les indices des points r√©alisant ce maximum. Tracez le profil r√©sultant de cette op√©ration. Lissez ce profil √† l‚Äôaide d‚Äôun filtre √† moyenne glissante : il s‚Äôagit d‚Äôune convolution par un noyau constitu√© uniquement de 1. Utilisez une taille de 32 pour le noyau.# Question 1fn = Path(root/&quot;Inoisy.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))img = np.log(I0) - linlog(I, 3)n = 3idx = img.shape[1] // n + img[:,img.shape[1] // n : (n-1) * img.shape[1] // n].argmax(axis=1)integrals = np.array([img[k,idx[k]] for k in range(img.shape[0])])plt.figure()plt.plot(integrals)plt.xlabel(&#39;Row number (from top to bottom)&#39;)plt.ylabel(&#39;Max value (in central area)&#39;)plt.show()&amp;lt;ipython-input-23-34dfaf741c3b&amp;gt;:11: RuntimeWarning: divide by zero encountered in log return np.where(x &amp;gt;= x0, np.log(x), (1/x0) * x + np.log(x0)-1) # ax + b# Question 1 (compl√©ment)plt.imshow(I)plt.scatter(idx,np.arange(I.shape[0]),c=&#39;r&#39;,s=2)plt.show()# Question 2size = 32kernel = np.ones(size) / size window = size//2integrals = np.convolve(np.pad(integrals,(window,window),&#39;edge&#39;),kernel,&#39;same&#39;)[window:-window]f,ax = plt.subplots()ax.imshow(img.T)ax1 = ax.twinx()ax1.plot(integrals,&#39;r&#39;,lw=3)plt.show()Questions Utilisez les m√™mes coordonn√©es de l‚Äôimage pour tracer le profil des signaux d√©tecteurs de I. Varient-ils beaucoup ? Vous avez jusqu‚Äôici travaill√© en supposant $I_0$ constant pour toute l‚Äôimage : on parle d‚Äôexposition constante ou uniforme. Essayez maintenant d‚Äôadapter les param√®tres de tir d‚Äôune ligne √† l‚Äôautre de l‚Äôimage, afin de ramener le profil que vous venez de tracer constant autour de 100. On va donc adapter la valeur de $I_0$ d‚Äôune ligne √† l‚Äôautre. Pouvez-vous d√©terminer ce profil de modulation I0Vector, de la taille de la hauteur de l‚Äôimage ? En supposant que le kVp reste fixe, quelle quantit√© physique est ainsi modul√©e ?# Question 3detectorSignal = np.array([I[k, idx[k]] for k in range(idx.size)])plt.plot(detectorSignal)plt.yscale(&#39;log&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;Detector signal&#39;)plt.title(&#39;Signal profile&#39;)plt.show()On a un profile qui va essayer de baisser les valeurs la ou on a sous-expose et les augmenter la ou on a sur-expose.On a $p_i=\\int udl$ qui est l‚ÄôepaisseurLe profil au-dessus est\\[I_n=I_0^{\\text{(red)}}e^{-p}\\]\\[I\\simeq \\text{target}\\]# Question 4targetSignal = 100I0Vector = targetSignal * np.exp(integrals)plt.plot(I0Vector)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;$I_0$ value&#39;)plt.show()Par rapport a notre image avec la courbe et Homer, quand on regarde le profil d‚Äôepaisseur, on se rend compte que la dynamique est faible $\\in[3;14]$. Il faut un peu plus d‚Äôepaisseur pour en tirer le maximum et obtenir le meilleur resultat possible.Questions Etant donn√©s $p$ et le vecteur de modulation $I_0$, simulez l‚Äôimage ainsi acquise (sans ajout de bruit). Tracez le profil des signaux d√©tecteurs de I avec cette nouvelle acquisition. Comparez-le au profil qui aurait √©t√© obtenu avec un $I_0$ fixe √©gal √† la moyenne du vecteur de modulation. Qu‚Äôobservez-vous ? Estimez le niveau de r√©duction de dose par rapport √† une acquisition √† techniques fixes lorsque : (a) $I_0$ est constant √©gal au maximum des valeurs du vecteurs de modulation ; (b) $I_0$ est constant √©gal √† la valeur moyenne du vecteur de modulation. A quoi correspondent ces deux cas ?# Question 5Imod = I0Vector[:,None] * np.exp(-img)f,ax = plt.subplots(1,2)ax[0].imshow(I,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[0].set_title(&#39;Unmodulated&#39;)ax[0].set_axis_off()ax[1].imshow(Imod,cmap=&#39;gray&#39;,interpolation=&#39;none&#39;)ax[1].set_title(&#39;Modulated&#39;)ax[1].set_axis_off()# Question 6plt.plot([Imod[k,idx[k]] for k in range(idx.size)],label=&#39;With modulation&#39;)plt.plot([I[k, idx[k]] / I0 * I0Vector.mean() for k in range(idx.size)],label=&#39;Without modulation&#39;)plt.axhline(targetSignal,0,1,color=&#39;r&#39;,ls=&#39;dashed&#39;)plt.yscale(&#39;log&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;Detector signal&#39;)plt.title(&#39;Signal profile&#39;)plt.legend()plt.show()# Question 7cumulativeI0 = np.trapz(I0Vector)# Cas (a)cumulativeI0FixedMax = cumulativeI0.max()# Cas (b)cumulativeI0FixedMean = cumulativeI0.mean()print(&#39;Case (a): dose reduction of&#39;, np.round(100*(1-cumulativeI0/cumulativeI0FixedMax),2),&#39;%&#39;)print(&#39;Case (b): dose reduction of&#39;, np.round(100*(1-cumulativeI0/cumulativeI0FixedMean),2),&#39;%&#39;)plt.figure()plt.plot(I0Vector)plt.axhline(I0Vector.max(),0,1,color=&#39;k&#39;,ls=&#39;dashed&#39;)plt.axhline(I0Vector.mean(),0,1,color=&#39;r&#39;,ls=&#39;dashed&#39;)plt.xlabel(&#39;Image row (top to bottom)&#39;)plt.ylabel(&#39;$I_0$ value&#39;)plt.show()Case (a): dose reduction of 0.0 %Case (b): dose reduction of 0.0 %Partie 3 : Ce qu‚Äôil faut retenir Le principe ALARA (ALADA) est √† l‚Äôorigine des d√©veloppements r√©cents en strat√©gies AEC Le but est d‚Äôatteindre un signal cible au d√©tecteur, gage d‚Äôun niveau de qualit√©, et de moduler l‚Äôexposition en cons√©quence Tirer √† techniques fixes avec la valeur moyenne de modulation revient √† utiliser la m√™me dose, mais distribu√©e de fa√ßon non optimale (sous-exposition √† certains endroits, sur-exposition √† d‚Äôautres) EOSedge est le premier syst√®me d‚Äôimagerie RX √† balayage int√©grant une strat√©gie AEC : la Flex DosePartie 4 - Diffus√© et qualit√© imageEn premi√®re approximation, le rayonnement diffus√© peut √™tre vu comme un signal additionnel basse fr√©quence du signal initial (dit primaire). Si $I$ est le rayonnement primaire, et $S$ le rayonnement diffus√©, l‚Äôintensit√© mesur√©e au d√©tecteur est $I_{s}=I+S$.Questions Quel est l‚Äôeffet du diffus√© $S$ sur l‚Äôestimation de la ligne int√©grale $p=\\log(I_0)-\\log(I_s)$ ? Qu‚Äôen d√©duisez-vous sur le niveau de gris moyen dans l‚Äôimage $p$ par rapport √† l‚Äôimage id√©ale $p_{\\mathrm{true}} = \\log(I_0)-\\log(I)$ ? A l‚Äôaide de la fonction cv2.GaussianBlur, filtrez l‚Äôimage I avec un noyau isotrope de taille 51, et multipliez-la par 0.1. Appelez cette nouvelle image S : ce sera notre image de diffus√©. Ajoutez ce diffus√© √† l‚Äôimage primaire I : appelez Iscatter cette nouvelle image. G√©n√©rez une r√©alisation de bruit de Poisson associ√©e √† cette image corrompue par du diffus√©. De m√™me, g√©n√©rez une r√©alisation de bruit de Poisson associ√©e √† l‚Äôimage non corrompue I. Ecrivez une fonction qui applique la transformation log vue pr√©c√©demment. Transformez l‚Äôimage Iscatter : qu‚Äôobservez-vous par rapport √† la transformation de I ? Supposez que vous connaissez la carte de diffus√© (c‚Äôest le cas ici, puisqu‚Äôon l‚Äôa g√©n√©r√©e) ; soustrayez-la √† votre acquisition corrompue : que donne l‚Äôimage en log par rapport √† l‚Äôimage en log corrompue ? par rapport √† l‚Äôimage en log id√©ale ? Comment expliquez-vous ce r√©sultat ?fn = Path(root/&quot;I.704.640.raw&quot;)I = np.fromfile(fn,dtype=&#39;float32&#39;).reshape((704,640))# Question 2S = (...)Iscatter = I+SIscatter = (...) # add noise to IscatterInoScatter = (...) # add noise to If,ax = plt.subplots(1,3,figsize=(18,6))ax[0].imshow(I)ax[0].set_axis_off()ax[0].set_title(&#39;$I$&#39;)ax[1].imshow(S)ax[1].set_axis_off()ax[1].set_title(&#39;$S$&#39;)ax[2].imshow(Iscatter)ax[2].set_axis_off()ax[2].set_title(&#39;$I_s=I+S$&#39;)plt.show()# Question 3def logCompress(img): return (...)# Vous pouvez s√©lectionner une sous-r√©gion anatomique ou `full` pour voir toute l&#39;imagebrain = slice(100,300),slice(300,500)cervicals = slice(350,600), slice(300,500)teeth = slice(400,600), slice(100,300)full = slice(None,None)# Choisissez la r√©gion que vous voulez dans `anat`anat = brain# Questions 3 et 4pTrue = logCompress(InoScatter)pScatter = logCompress(Iscatter)pScatterCorrected = logCompress((...))vmin,vmax = pTrue.min(), pTrue.max()f,ax = plt.subplots(1,3,figsize=(18,6))ax[0].imshow(pTrue[anat],vmin=vmin,vmax=vmax)ax[0].set_axis_off()ax[0].set_title(&#39;True image&#39;)ax[1].imshow(pScatter[anat],vmin=vmin,vmax=vmax)ax[1].set_axis_off()ax[1].set_title(&#39;Scatter-corrupted&#39;)ax[2].imshow(pScatterCorrected[anat],vmin=vmin,vmax=vmax)ax[2].set_axis_off()ax[2].set_title(&#39;Scatter-corrected&#39;)plt.show()Partie 4 : Ce qu‚Äôil faut retenir Le rayonnement diffus√© est une image basse fr√©quence qui se superpose au rayonnement primaire Le diffus√© conduit √† une diminution du contraste global de l‚Äôimage La correction num√©rique du diffus√© (apr√®s acquisition) permet de restaurer le contraste de l‚Äôimage, mais conduit aussi √† une image plus bruit√©e Afin de pr√©senter une image plus acceptable √† l‚Äôutilisateur final, il faut prendre en compte ce ph√©nom√®ne, soit en amont (r√©jection du diffus√© avant qu‚Äôil atteigne le d√©tecteur) ou en aval (correction de diffus√© et d√©bruitage)" }, { "title": "TVID: La video numerique en pratique", "url": "/cours/posts/tvid_video_numerique_pratique/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-10 14:00:00 +0100", "snippet": "Lien de la note HackmdFilm et entrelacement Film = 24P, NTSC = 60I Comment passer un film a la tele ? 2:3 pulldown 4 frames, 10 fields A: TFF + RFF B: BFF C: BFF + RFF D: TFF Voila comment on envoie des films a la tele Americaine (tele-cine) Et oui, on repete des films !Desentrelacement Reconstruire les lignes manquantes Plusieurs approches Toutes inexactes Complexite variable En pratique: efficacite / cout Ce n‚Äôest pas qu‚Äôon ne sait pas faire, c‚Äôest qu‚Äôon fait pour un budgetDesentrelacer, comment ca marche, combien ca coute ?Methode Ne rien faire C‚Äôest indadmissible Weave Lire une frame (a) $$=1:1$ (a) Skip field Lire $2\\times$ le meme field (a) Si field bottom $\\to$ aligner frame (b) AlignementImage entrelacee 4:2:0 MPEG-2On doit upscaler verticalement pour skip fieldUpscaling Definition Agrandir une image source a faible resolution On cree des pixelsUpscaling NN: Nearest Neighbour / Plus proche voisin Repeter le pixel voisin Utiliser dans la Super Nintendo ou la Neo GeoAvantages: Rapide GratuitProbleme: $\\color{red}{\\text{Moche}}$Upscaling BF (Bilinear Filtering) Interpolation lineaire 2D Trois interpolations 1D entre $P_{00}$ et $P_{10}$: $Q_0$ TODOAvantages: Acceptable Pas cherProbleme: Pas pour les gros ratios (SD $\\Rightarrow$ 4K)Upscaling B-Spline Plusieurs polynome Points de passage pour les pixels en 2D B-Spline: Contrainte de continuite entres les polynomesTres souvent: B-Splines cubiquesC‚Äôest flou, mais c‚Äôest acceptable SD $\\to$ 4K: OKProblemes: Cher Risque (ringing)Le resultat est tres inegal. Il n‚Äôy a aucune strategie parfaiteLe coup de skip field c‚Äôest $ $= 1:1(a) + \\text{filtrage}(b) + \\text{upscale}(c)$ Bobbing: Lire chaque field 1/1 (a) Si field bottom $\\to$ aligner frame (b) Upscaler verticalement $\\times 2$ ( c ) Cout $=1:1(a) + \\text{filtrage}(b) + \\text{upscale}(c)$ Blending (Microsoft) Lire une paire de fields (a) Aligner fields bottom (b) Upscaler verticalement $\\times 2$ ( c ) Cout $=2:1(a) + 2\\times \\text{filtrage}(b) + 2\\times\\text{upscale}(c) + \\text{mixage}(d)$ $\\color{red}{\\text{Adaptative (Spatial, MoComp)}}$ Desentrelaceur intelligent Adaptatif spatial pur Plusieur fields: B0, T1, B1 Decoupes en zones de pixels: $Z_i$ Pour chaque $Z_i$ ‚Äúdifference‚Äù entre $B1$ et $B0$ (parite) $E_i\\sim = Z_i(B1) - Z_i(B0)$ $E_i\\gt$ seuil: $Z_i$ ‚Äúen mouvement‚Äù Pixels $Z_i(T1)$ bobbes Sinon $Z_i$ ‚Äústatique‚Äù Pixels $Z_i(T1)$ weaves avec $Z_i(B0)$ Avantages Si mouvement: $Z_i(T1)$ desentrelacee Sinon $Z_i(T1)$ pleine resolution Rendu acceptable Inconvenients Certains mouvements indetectables (translation, recouvrements) $ $=3:1+\\text{differenciateur} + \\text{bob} + \\text{multiplexeur}$Amelioration 4 fields $E_i = \\max(Z_i(B1) - Z_i(B0))$, $Z_i(T1) - Z_i(T0)$ Meilleure detection de ‚Äúmouvement‚Äù $ $=4:1+2\\times\\text{differenciateur} + \\text{bob} +\\text{multiplexeur}$Adaptatif temporel: Spatial + estimateurs de mouvements convolutifs FIR / Turbo Cuisine secrete brevetee (Faroudja) Plus beau BEAUCOUP PLUS CHERExemplesCadence image US: 1953: NTSC en couleur Interference image/son a 60 ips Solution: changer la frequence image $\\times 1000/1001$ 60 ips $\\Rightarrow$ 59,94 ips 30 ips $\\Rightarrow$ 29,97 ips 24 ips $\\Rightarrow$ 23,978 ips Transparent, economique penible ‚ÄúModes TV‚Äù, ‚ÄúModes PC‚ÄùImage animee: quelle frequence choisir ? Cinema Muer: 16 ips Parlant: 24 ips TV Synchro cameras et TVs ‚ÄúHorloge commune‚Äù ? Frequence secteur ! US, JP: 60 ips EMEA: 50 ips Cadence USUS: $60$ ips $60 \\Rightarrow 30$: sauter 1 image sur 2 $30 \\Rightarrow 60$: repeter 1 image sur 2 $24 \\Rightarrow 30$: repeter 1 image sur 5 $59,97 \\Rightarrow 60$: repeter 1 image sur 1000 $60 \\Rightarrow 59,97$: sauter 1 image sur 1000 $29,97 \\Rightarrow 60$: repeter 1 image sur 2 et 1 fois sur 1000Cadence EUEU: $50$ ips $60 \\Rightarrow 50$: sauter 1 image sur 6 $50 \\Rightarrow 60$: repeter 1 image sur 5 $24\\Rightarrow25$: repeter 1 image sur 24 ? NON! accelerer $25/24$: $+4\\%$ $2m20s/h$ $+1$ demi-ton Mega drive: toute la logique etait conditionnee par l‚Äôhorloge videoCertains jeux etaient ralentis en Europe pour le passage $60Hz\\to50 Hz$Perte de $20\\%$ de vitesse ! $30 \\Rightarrow 50$: rapport 5/3. Repeter $2\\times$ fois la 3e image ? $1$ $2$ $3$ $\\color{orange}{3}$ $\\color{red}{3}$ Pourquoi on veut pas faire ca ? Parce que c‚Äôest saccade On fait: $1$ $\\color{orange}{1}$ $2$ $\\color{orange}{2}$ $3$ Plus homogene $\\Rightarrow$ resultat plus fluide Cadences en pratiqueTout est entier: PTS: temps image source STC: temps horloge affichageResolution d‚Äôincrement: TIR TIR(PTS) = duree d‚Äôune seconde dans le flux video TIR(STC) = duree d‚Äôune seconde a l‚ÄôaffichageSi TIR(PTS) non $\\%$ TIR(STC) probleme de $\\color{red}{\\text{fraction continue !}}$ExempleTIR PTS = 90000 = 1 secnode La FC fait apparaitre de la gigue, aka JITTER" }, { "title": "TNSI: Traitement numerique du signal", "url": "/cours/posts/tnsi_traitement_num_signal/", "categories": "Image S9, TNSI", "tags": "Image, S9, TNSI", "date": "2021-11-10 09:00:00 +0100", "snippet": "Lien de la note HackmdPresentationParcours: Ingenieur topographe - INSA These en traitement du signal et de l‚Äôimage - TelecomIngenieur Chercheur a EDF R&amp;amp;D (Saclay) Groupe realite virtuelle et visualisation scientifique (avec Arnaud MAS) Numerisation et apprentissage statistique (image et 3D)Groupe Realite Virtuelle Visualisation Scientifique Aider l‚Äôexploitant des sites de production nucleaire a decider lors des phases de preparation et de realisation des arretes de tranche AiderOCR pour les plans techniquesLa reconnaissance de forme dans les imagesSegmentation semantique: deux reseau Segmentation pixelique Segmentation semantique pour classifier les pixels de l‚ÄôimageLa reconnaissance de forme dans les nuages de points Donnees DP2D FES2Local R250280 millions de pointsActuellement: manuel Segmentation en petit nuage de points + ajustement de formeTraitement numerique du signal Definition Representation de la variation d‚Äôun phenomene physique ExemplesEvolution de la temperature ou de la pression dans le temps Definition Transcrire numeriquement (i.e. des donnees) un signal continu (monde reel)On veut passer du monde continu au monde discretComment on fait le passage du continu au discret ? On va faire un echantillonage en temps et en amplitudeQuelle est la precision de cette discretisation ? On utilise le theoreme de ShannonEn resume: on prend notre signal, on compare dans chaque base de fonction a quel point notre signal ressemble et on va pouvoir voir a quel point notre signal est haute frequence et basse frequence. Avec les transformee de Fourier, on veut passer en temporel sans perdre d‚ÄôinformationTheoreme d‚Äôinterpolation Decoule du theoreme de ShannonOn utilise un sinus cardinalLe theoreme de Shannon nous dit qu‚Äôon a un signal continu:\\[x(t) = \\sum_{n=-\\infty}^{+\\infty}x[n]\\underbrace{\\frac{\\sin\\biggr(\\frac{\\pi(\\overbrace{t-\\color{red}{nT_e}}^{\\text{translation}})}{\\underbrace{\\color{red}{T_e}}_{\\text{echelle}}}\\biggr)}{\\frac{\\pi(t-nT_e)}{T_e}}}_{\\color{red}{sinc}}\\]Exercice\\[x(t) = \\sin(10t) + 2\\sin(2t) + \\sin(5t) - 3\\sin(\\frac{t}{2})\\\\t = [-2, 2]\\to 400\\] Normaliser et centrer $T_e=0.1$ Interpoler avec $sinc$On reprendre notre figureOn prend des echantillons a intervalles regulireOn va sommer les sinus cardinaux:Ca va nous permettre de reconstruire notre signal:Quel est l‚Äôinteret du sinus cardinal ? On peut utiliser n‚Äôimporte quelle interpolation, mais le sinus cardinal est le meilleurQuantification Quantification scalaire: arrondir a l‚Äôentier le plus proche $x$: amplitude des valeurs $q(x)$: valeur de quantificationTraitementComment on debruite un signal ? Convolution avec une fonction gaussienne ?Convolution avec une porte ?Non local means ? (c‚Äôest un flou gaussien ou un flou uniforme)On a un signal avec un flou gaussien: On fait une convolution avec une porteEn resume Comment echantilloner et reconstruire un signal Comment analyser un signal Comment filtrer une partie de l‚Äôinformation d‚Äôun signalTransformee de Fourier Rappel rapide Analyser harmonique Decomposition en serie de Fourier Discrete Time Fourier Transform (DTFT) Tf a temps discret Discrete Fourier Transform (DFT) TF discrete Continuous Fourier Transform (CFT) Fast Fourier Transform (FFT) Produit scalaireComment est-ce qu‚Äôon calcule un produit scalaire ?\\[\\langle x, y\\rangle = \\sum_{n=-\\infty}^{+\\infty}x[n]y[n]^*\\\\\\langle x, y\\rangle = \\int_{-\\infty}^{+\\infty}x(t)y^*(t)dt\\] Avec Fourier, on est en complexes\\[\\Vert x\\Vert^2 = \\langle x,x\\rangle = \\sum_{n=-\\infty}^{+\\infty}\\vert x[n]\\vert\\]Decomposition/reconstructionSoit \\(\\{f_n\\}_{n\\in\\mathbb N}\\to\\) base orthogonale.\\[\\langle f_n,f_p\\rangle = 0\\quad n\\neq p\\]$\\exists$ une suite $\\lambda[n]$ telle que $\\lim_{N\\to+\\infty}\\Vert x-\\sum\\lambda[n]f_n\\Vert = 0$\\[x=\\sum_{n=0}^{+\\infty}\\lambda_n f_n\\quad\\text{avec }\\lambda_n = \\frac{\\langle x,f_n\\rangle}{\\Vert f_n\\Vert^2}\\]Exercice\\[x = \\sin(2\\pi t) + 2\\sin(3\\times 2\\pi t) - 3\\sin(5\\times 2\\pi t) + \\sin(7\\times 2\\pi t)\\\\t = [0,1]\\] Tracer $x$ avec 1000 echantillons Decomposition de $x$ avec \\(\\{\\sin(n\\cdot 2\\pi t)\\}_{n\\in N}\\to\\) $N = [0,‚Ä¶,5]$ ou $N = [0,‚Ä¶,20]$ Verifier l‚Äôorthogonalite Tracer les coefficients Reconstruction Si on ajoute une phase au sinus ? Idem " }, { "title": "DLIM: Reseaux neuronaux convolutifs", "url": "/cours/posts/dlim_res_neurones_convolutif/", "categories": "Image S9, DLIM", "tags": "Image, S9, DLIM", "date": "2021-11-08 14:00:00 +0100", "snippet": "Lien de la note HackmdUn reseau de neurones convolutifLe but est d‚Äôextraire les caracteristiquesLes formules de convolutionContinue 1D:\\[(f * g)(x) = \\int_{-\\infty}^{+\\infty}f(x-t)g(t)dt = \\int_{-\\infty}^{+\\infty} f(t)g(x-t)dt\\]Discrete 2D:\\[(f*\\omega)(x,y) = \\sum_{dx=-a}^a\\sum_{dy=-b}^b\\omega(a + dx, b + dy)f(x + dx, y+dy)\\]$f$ est l‚Äôaimeg, $\\omega$ le noyau, son support est $[-a,a]\\times[-b, b]$Exemple de noyaux $\\omega$ (WP Noyau_(traitement_d‚Äôimage)):Conv2Dx = kl.Conv2D(filters = 4, kernel_size=(5, 5))(x)L‚Äôimage d‚Äôentree a 3 canaux -&amp;gt; chaque filtre a $5\\times5\\times 3 + 1$ poidsL‚Äôimage de sortie a 4 canaux, elle pert 4 pixels dans chaque directionEn details + stride + padding = ‚Äòsame‚ÄôConv2D(filters = 2, kernel_size = (3, 3), stride = (2, 2), padding = &#39;same&#39;) Stride: une facon de reduire la taille d‚Äôune image padding = ‚Äòsame‚Äô: la sortie a la meme tailleConvolution a trousEn anglais: atrous convolutionConv2D(32, kernel_size=3, dilatation_rate=(2, 2)) Couvre la meme surface qu‚Äôun noyau $5\\times 5$, ou que $2$ convolutions $3\\times 3$ a la suite, mais pour un cout moins cher (en poids)Ne reduit pas la taille de l‚Äôimage (padding = same)Convolution separee spatiale: une conv $2D\\to1$ conv. $1D$ profondeur: $N$ conv $2D$ sur $M$ couches $\\to$ $M$ conv $2D$ puis $N$ conv $1D$Convolution separeee spatialeEn pratique on fait:Conv separee en profondeurkl.SeparableConv2DIci 3 couches: $3$ conv $2D$ + $4$ conv $1D$ $4$ couches en sortieGain de calcul importantperte de representation $\\to$ utiliseMobileNetLa convolution transposee (ou deconvolution) Convolution: concentre en un pixel un bloc de pixel (fois un noyau) Conv transposee: distribue un pixel (fois un noyau) a un bloc de pixelMathematiquement les deux sont des convolutions mais la conv. transposee a pour but de simuler l‚Äôoperation inverse de la conv\\[\\begin{aligned}\\text{propagation conv transposee} &amp;amp;\\leftrightarrow \\text{retro-propagation conv}\\\\\\text{retro-propagation conv. transposee} &amp;amp;\\leftrightarrow\\text{propagation conv.}\\end{aligned}\\]Trucs d‚Äôarchitecture Pooling kl.MaxPooling2d(pool_size = (2, 2)) Si on veut augmenter le nombre de couches il faut diminuer la taille de l‚Äôimage sinon BOOM On veut une vision multi-echelle il faut diminuer la taille de l‚Äôimage + ponts. L‚Äôinverse du pooling est kl Ponts La grande astuce de ResNet qui leur a permis de tout gagner vert $\\to$ rouge $\\leftarrow$ Prog. et retro-prog. Lors de la retropropagation l‚Äôerreur prend le pont et les convolutions $\\to$ les premieres couches sont corrigees Dropout ou BatchNormalization Pas besoin de dropout si BatchNormalization Evite que les poids importants en bloquent d‚Äôautres Apres convolutionAvant fonction d‚ÄôactivationReduit le besoin de normaliser les donneesTypes de problemes en visionSemantic segmentation Classification Classification + localisation Object detection Instance segmentation Celle qu‚Äôon va faire U-net (2015)Separation semantique d‚Äôimages medicalesMulti-echelleNotre projet aujourd‚Äôhui !Copy &amp;amp; crops: ce sont des PONTS Ca sert a faire des concatenationsFonctions d‚Äôerreur pour la segmentationSi chaque image de sortie represente les pixels appartenant a la classe $k$, alors on peut finir avec un softmax: $y+k = e^{z_k}/\\sum_{i}e^{z_i}$ Erreur quadratique mse: pente douce, pas d‚Äôinformation d‚Äôexclusion Entropie croisee: $E=-\\sum_kt\\log y_k+(1-t_k)\\log(1-y_k)$ binary_crossentropy avec $t_k=0$ ou $1$ categorical_crossentropy avec resultats sous la forme $[0,0,..,1,..,0]$ pour indiquer la classe $k$ sparse_categorical_crossentropy avec les classes indiques par des entier y_true = [[1, 2], [0, 2]] #image 2x2 with 3 categoriesy_pred = [[0.05, 0.95, 0], [0.1, .01, 0.8], #proba for each category [0.7, 0.2, 0.1], [0.2, 0.2, 0.6]] #for each pixelloss = keras.losses.SparseCategoricalCrossentropy()loss(y_true, y_pred).numpy() Focal loss\\[E_{FL} = -\\sum_k t_k(1-y_k)^{\\gamma}+(1-t_k)(1-y_k)^{\\gamma}\\log(1-y_k)\\] Comme la pente du log est forte, elle favorise les cas simples a detecter. On peut ecraser la courbe de $(1-\\gamma_k)$ pour aider √† trouver les cas difficiles. Augmenter le nombre de donneesSouvent c‚Äôest bien utile, en particulier lorsqu‚Äôon manque de donnees.Parfois ca rend la tache plus difficile et ca ne marche pas.ImageDataGenerator" }, { "title": "TVID: Du pixel a l&#39;ecran", "url": "/cours/posts/tvid_pixel_a_image/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-11-08 10:00:00 +0100", "snippet": "Lien de la note HackmdOn va decouvrir les principes fondamentaux l‚Äôaudio et la video numerique. 20h dont 6 de TP TPs de 3h On va faire notre propre decodeur et afficheur videoPlusieurs parties: Fondamentaux de ce qu‚Äôest un pixel Qu‚Äôest-ce que signifie les resolutions (pourquoi pas des multiples de 10 ? Pourquoi 1080i ? Pourquoi 16/9e ?) Structure d‚Äôune image video Cadences Comment on fait pour afficher n‚Äôimporte quel film a n‚Äôimporte quelle taille vers n‚Äôimporte quelle television ? Comment on fait de l‚Äôadaptation de cadence ? Entrelacement Ca nous pourri la tete depuis 70 ans Affichage Comment trouver un mode commun d‚Äôaffichage ? Ce sont les prerequis pour la suiteLa suite: standards de compression videoPixel C‚Äôest un element d‚Äôune imageMais encore ? C‚Äôest un format Profondeur Combien de bits par composants ? espace de couleurPixel aspect ratioMonde PC: PAR = 1:1 Pixels carresMonde video: PAR &amp;gt;= 1 Pixel rectangulairesPourquoi ? On tient ca de l‚Äôanalogique: pas de resolution Analogique: pas de resolution Numerique: resolutions partout Besoin de correspondance numerique $\\leftrightarrow$ analogique On arrive sur le display aspect ration: la resolution de sortie\\[\\color{red}{\\text{PAR}\\times\\text{DIM} = \\text{DAR}}\\]Est-ce qu‚Äôon a deja essaye de jouer un fichier VOG d‚Äôun DVD tout seul ? L‚Äôimage sera plus carree et deformee car on ne lit pas les metadataColor SpaceGenerateurs de graphismes RGB Ordis, smartphones, tablettes On Screen Display (OSDs) On Screen Technique: superposition d‚Äôaffichage comme l‚Äôaffichage du numero de la chaine quand on zappe Pourquoi on affiche le nom de la chaine quand on zappe en numerique ? En analogique, quand on zappait c‚Äôetait instantane car il suffisait de changer que quelques parametres pour changer de frequence sans pre-processingC‚Äôest juste pour faire attendre les gens, sinon on n‚Äôa qu‚Äôun ecran noirPourquoi certaines box ont une mosaique avec plusieurs flux videos de differentes chaines ? Car ce n‚Äôest pas fait par la box, ce sont des chaines mosaiques pre-composees par l‚ÄôemetteurOn utilise les metadatas pour choisir une chaine sur les mosaiquesCertaines mosaiques ne permettent pas de selectionner de chaine ARGB, ABGR A est le canal $\\alpha$ (alpha) ABGR est la representation d‚ÄôAndroid BGRA, RGBA, ‚Ä¶Video: YUV Images et sequences animees Y: luminance U, V: Chrominance (aka Cb, Cr) Raisons historiquesEst-ce que les premiers signaux analogiques pour la tele etaient en couleur ? Bien sur que nonVers les annees 50 on se dit que ca serait bien d‚Äôavoir la couleurs On va faire un truc degueulasse pour que ce soit retrocompatible avec les gens ayant une tele en noir et blanc L‚Äôanalogique est la reponse de ce qu‚Äôon fait en numerique.Les US avaient NTC qui on cree un standard video de 480 lignes en noir et blanc qui est passe en couleurs en une nuit (et ca a marche !) L‚Äôheritage de l‚Äôanalogiqe nous enquiquine encore aujourd‚ÄôhuiExemple RGBQu‚Äôest-ce qu‚Äôon remarque ? Le vert est predominant car il est predominant dans la natureLes humains ont un excellent pouvoir d‚Äôobservation sur le vert (60-70% de notre champ de vision)On voit moins bien le rouge car c‚Äôest le sang et le feu (20-30% de notre champ de vision)On voit encore moins bien le bleu car on ne veut pas etre aveugle par le ciel La compression numerique va user et abuser de nos limitations de perceptionExempe YUVQu‚Äôest-ce qu‚Äôon remarque ? Dans le V il y a tres peu de rouge, noye dans du grisSi on etait un algorithme, lesquels de ces images on trouverait plus facile a digerer que les autres ? U et V ont une dynamique faible donc l‚Äôencodeur entropique va se regaler On va grignoter tout ce qui est possible pour faire des economiesFormatsFormat lineaire: Toute l‚Äôinfo est dans le pixel Profondeur: 8..16 bits/composantes HDR: 10 bits 8 bpc: ‚ÄúTrue Color‚Äù Representation des pixels : ARGB, ARGB, ARGB‚Ä¶ Exemple: #FF00FF00 C‚Äôest du vert alpha opaque et vert a fond Exotiques: high colorsConsiderations systeme: True colorsCombien ca coute ?Que faut-il dans un systeme ? Horloge Systeme CPU RAM Efficacite Bande passante (BW) BUS DMA Direct Memory Access Faire des transferts de donnees enorme sans utiliser un iota du processeur Taille: combien de bytes au max il est capable de copier BW: bande passante (nb bits/s capable de transferer) Modules hardware Carte video (GPU), carte son, etc Autres modules d‚Äôaffichage CCC Full Hd True Color ? Image fixe RGB $8bcp$ @ $1080p60$ BW afficage: $1920 \\times 1080 \\times 60 \\times 24 = 2,98 Gb/s$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ d‚Äôefficacite $\\Rightarrow$ BW RAM $= 200M \\times 32 = 6,4 Gb/s$ ~$3,88\\%$ BW ram ~$46\\%$ BW bus Juste pour afficher ! $\\times 2$: NOK. Pas d‚Äôanimation possible DMA: $64$ bits / clock (DMA++) $\\Rightarrow$ BW bus $=200M\\times 64 = 12,8 Gb/s$ $\\Rightarrow$~$3,88\\%$ BW RAM $\\Rightarrow$~$23\\%$ BW bus $\\Rightarrow$ Image animee jouable $\\Rightarrow$ Couteux CCC 4K ? Image fixe RGBTODOPixels: formatsFormat paletisse: Palette de couleur predeifinie Pixel = index couleur palette Profondeurs: 1, 2, 4, 8 bits / pixel Tous les OSDs sont paletisesCCC Full HD palettise ? Image paletisee 256 couleursTODOStructure d‚Äôune image videoColorspace YUVSampling Mode Sampling Mode: sous-echantillonnage de la chrominanceQu‚Äôest-ce que ca veut dire ? On va peut-etre enlever du U ou du V sur certains pixels car nos yeux ne peuvent pas le voir de toute faconLe fameux grignottage Seulement en color space YUV Oeil moins sensible a UVExemple:Sur la 2e image, on a commence a diviser l‚ÄôechantillonnageQu‚Äôest-ce qu‚Äôon observe ? Il y a des bandes qui apparaissent a chaque bordures de couleursElles se degeulent les unes sur les autresSi on met une video youtube avec du rouge petant on aura le meme effet Ca arrive surtout sur les cas extremes avec des transitions abruptesOn suppose 8 pixels:Ils ont chacun leurs composantes $4:4:4$ Pour 4 pixels consecutifs (pas forcement en ligne mais aussi en carre) il y a 4 $U$ et 4 $V$ $4:2:2$ Pour 4 pixels consecutifs, on n‚Äôen a que 2 qui contiennent de la chrominance On a litteralement decime une colonne de chroma sur 2 Ce sont toutes les images JPEG $4:2:0$ MPEG-1 On a 6 composantes sur 8 bits au lieu de 12 Le calculateur fait la moyenne On a beaucoup economise juste en coupant la chroma une ligne sur 2 et un colonne sur 2 $4:2:0$ MPEG-2 $4:1:1$ Utilise par les Etats-UnisPendant notre enfance on avait les camescopes DV, en Europe ils sont en $4:2:2$ et aux US du $4:1:1$ Tous les CODECs aujourd‚Äôhui sont bases sur la perception visuelleImage planaire Heritage TV: Y avant UV PC: Images interleavees (ARGB, ARGB, ‚Ä¶) Video: Images planaires: Buffers composantes separes Luma: Y, Y, Y Chroma: UV, UV, UV Decouplage hardware / composantes Une image planaire, combien ca coute ?CCC Full HD Planar $4:2:2$ ?$1080p60$ YUV $4:2:2$ $8$ bits Luma: $1920\\times 1080\\times 60\\times 8=\\sim1 Gb/s$ Chroma: $1920\\times 1080\\times 60\\times 16 / 2=\\sim1 Gb/s$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ d‚Äôefficacite $\\Rightarrow$ BW RAM $=200M\\times 64\\times 8\\times 0.8 = 81,92 Gb/s$ Deux DMA 2 fois plus petits: $16$ bits / clock $BW = 200 M \\times 16 = 3,2 Gb/s/canal$ $2,5\\%$ BW ram $31\\%$ BW par canal On pas en YUV car c‚Äôest le seul format qui nous permet de decimer le chroma sans tout casserCCC Full HD Planar $4:2:0$ ?$1080p60$ YUV $4:2:0$ $8$ bits $\\gt90\\%$ des fichiers video (TNT, SAT, YT, Netflix, ‚Ä¶) Luma: $1920\\times 1080\\times 60\\times 8=\\sim1 Gb/s$ Chroma $1920\\times1080\\times60\\times16\\times\\color{green}{4 = \\sim 0,5Gb/s}$Pour un systeme: Bus clock: $200$ MHz DRAM: DDR3 $12800$ ($8$ bytes / burst, classiquement) $8$ bursts / clock $\\Rightarrow 64$ bytes / clock $80\\%$ d‚Äôefficacite $\\Rightarrow$ BW RAM $=200M\\times 64\\times 8\\times 0.8 = 81,92 Gb/s$ Deux DMA 2 fois plus petits: $16$ bits / clock $BW = 200 M \\times 16 = 3,2 Gb/s/canal$ $2,5\\%$ BW ram $\\sim 31\\%$ BW Y, $15\\%$ BW UV CCC 4K Planar $4:2:0$ 10 bits ?$2160p60$ YUV $4:2:0$ 10 bits: Netflix Deux DMA 64 bits / clock Hardware a 2 px / clock BW = 200M x 64 = 12,8 Gb/s/canal 9% BW ram TODOEntrelacement / Desentrelacement70 ans et toutes ses dentsUn peu d‚Äôhistoire: les signaux videos ne sont pas tous faits de la meme maniere et ne sont pas fait comme on le pense.Mais nous n‚Äôavons pas parle de la structure d‚Äôune image.Il y a un peu moins d‚Äôun siecle, des ingenieurs se sont dit ‚ÄúOn va transmettre de l‚Äôimage analogique sur des tubes cathodiques‚Äù.Le principe d‚Äôun ecran cathodique est toujours le meme: on a une surface remplit de photophores qui emet de la lumiere quand elle se prend des electrons, elle met du temps a s‚Äôallumer et du temps a s‚Äôeteindre.On s‚Äôest dit qu‚Äôon allait utiliser ces ecrans pour afficher des images.Pourquoi ecran cathodique ?Car les electrons sont generes par une cathode, et si on etait un peu trop pres de l‚Äôecran on se prenait des rayons.On ecrit notre image ligne a ligne a l‚Äôecran et on obtient notre image.SAUF QUEOn a remarque de 480 lignes c‚Äôest bien pour le format d‚Äôimage. Mais si on envoie 480 lignes par image, 60 images par seconde, on a un signal beaucoup trop large.Des ingenieurs se sont dit ‚ÄúMais c‚Äôest pas un probleme, regardez le temps que prend mon ecran a s‚Äôeteindre‚Äù (c‚Äôest une gaussienne). Ces ingenieurs se sont dit ‚ÄúJe ne vais envoyer qu‚Äôune ligne sur 2 de chaque image et alterner entre lignes paires/impaires‚Äù. C‚Äôest ca l‚Äôentrelacement On a decime l‚Äôimage spatialement. On a quasiment la meme qualite d‚ÄôimageEst-ce qu‚Äôon a vu que les tubes cathodiques scintillent ? C‚Äôest lie du a l‚Äôentrelacement et alterner les imagesAujourd‚Äôhui on n‚Äôa que des ecrans plats avec des pixels avec une bonne reactivite (jusqu‚Äôa 140 Hz) Mais ca nous pose des ENORMES problemes avec l‚ÄôentrelacementSur nos ecrans actuels, chaque pixel a chacun sa vie.On a un probleme de taille d‚Äôecran, de pixels, de resolution, etc.Pourquoi garder l‚Äôentrelacement ? Car il y a encore des pays qui utilisent des teles cathodiques Si c‚Äôest moins cher, on va le faire On paye cher apres car c‚Äôest a creditUn peu d‚Äôhistoire 1941: standard NTSC 6 MHz de bande passante Dot crawl: information couleur mal filtree 15730 ligne/s 525 ligne/image 15730 / 525 = 30 ips OK pour films (24 ips) NOK pour du direct Une idee simple 1 frame: 2 fields : pair/impair Captures a des instants differentsTFF = Top filter (flag)BFF = Bottom filter (flag)ExemplesUne image entrelacee c‚Äôest une image avec des dents Tous les flux de la TNT sont entrelaces et ne sont pas en HD On en en 1440i50 Le numerique, c‚Äôest pas que c‚Äôest mieux, c‚Äôest que c‚Äôest moins cherEntrelacementAvantages: Image fixe: resolution conservee Image mouvante: $2\\times$ plus fluide BW inchangee Parfait pour un tube cathodiqueInconvenients: Resolution horizontales / 2 si mouvement Signaliser l‚Äôordre des fields Scintillement Le futur devra faire avec‚Ä¶Exemple En bas a droite l‚Äôobjet bouge mais n‚Äôest pas entrelace Ce flux video donne des maux de tete aux ingenieursLe OK ne bouge pas et ne doit pas etre entrelaceLe logo en bas a droite est le logo corporate Il y a plusieurs entrelaceursExemple: VLCOu est le K ? On a pris que les lignes du haut et on a degage les lignes du basC‚Äôest desentrelace comme un pied par le GPUPlusieurs facons de desentrelace: Prendre que les lignes du dessus et upscale $\\times 2$ en vertical" }, { "title": "VPOA: Detection et localisation", "url": "/cours/posts/vpoa_detection_localisation/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-05 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionQu‚Äôest-ce que la vision ? Percevoir le monde Compose d‚Äôobjets Structure en 3D Efficacement interprete par l‚ÄôHomme Receuil d‚Äôinformation Ensemble de points Information sur la lumiere Quantite et contenu spectral Representation du monde reel Les objets n‚Äôexistent pas sur la retine Processus visuel d‚Äôinterpretation Vision humaine Extremement complexe Active de nombreuses zones du cerveau Possede des capacites nombreuses et varieesVision par ordinateur Bio inspiree ou non Production d‚Äôun modele algorithmique fonctionnellement similaire aux capacites du cerveau humain Reprosudit seulement un sous-ensemble de capacitesQuelques termes Traitement d‚Äôimages: manipulation dont l‚Äôentree et la sortie sont des images Aide l‚Äôhumain ou la machine a examiner des images Analyse d‚Äôimages: analyse ou l‚Äôentree est une image mais la sortie est une informationTODOProcessus d‚Äôintegration dans un systemeObjectifs de la seance Trouver/extraire dans l‚Äôimage des informations pertinentes pour TODODetection Deep-learning On a entraine le modele a detecter des voitures mais ca ne reconnais que l‚Äôavant des camionsDetection et trackingGeometrie projectiveCoordonnees homogenes Systeme de coordonnees pour la geometrie projectivePasser des coordonnees cartesiennes aux coordonnees homogenes:\\[\\begin{bmatrix}x\\\\y\\end{bmatrix} \\Rightarrow\\begin{bmatrix}x\\\\y\\\\1\\end{bmatrix}\\]Passer des coordonnees homogenes aux coordonnees cartesiennes:\\[\\begin{bmatrix}u\\\\v\\\\w\\end{bmatrix}=\\begin{bmatrix}u / w\\\\v / w\\\\1\\end{bmatrix} \\Rightarrow\\begin{bmatrix}u / w\\\\v /w\\end{bmatrix} =\\begin{bmatrix}x\\\\y\\end{bmatrix}\\]Propriete homogene: $\\bar x\\sim\\lambda \\bar x, \\forall \\lambda\\in\\mathbb R, \\lambda \\neq =0$Point a l‚Äôinfini:\\[\\bar x_{inf} = \\begin{bmatrix}x \\\\ y \\\\0 \\end{bmatrix}\\]Modele du plan projectif Le plan projectif $P^2$ represente l‚Äôespace 3D sur un planIntrepretation geometrique de l‚ÄôhomographieHomographiesEstimation d‚ÄôhomographieEstimation par Direct Linear Transform Necessite au moins 4 points pour obtenir une solution exacte (2 equations par point et 8 inconnues) Etant donne $n\\ge 4$, correspondances de points 2D, determiner $H$ tel que $\\bar x_i‚Äô=H\\bar x_i$Algorithme: Pour chaque correspondance $\\bar x_i\\leftrightarrow \\bar x_i‚Äô$ pour claculer $A_i$ Assembler les matrices $A_i$ en une matrice $9\\times 9$: $A$ Calculer le SVD de $A$: $U\\Sigma V$ Solution pour $h$: derniere colonne de $V$ Determiner $H$ a partir de $h$Homographie et plan 3DLe passage de n‚Äôimporte quel plan vers n‚Äôimporte quel autre plan (y compris le plan image) est une homographieExtraction de caracteristiques localesRepresentation d‚Äôune image$I(x, y)$: valeur d‚Äôun pixel Dans $\\mathbb R$ en monochrome Dans $\\mathbb R^3$ en couleursVariations De luminosite globale: $I(x,y)\\to I(x,y)+\\alpha$ De contraste: $I(x,y)\\to\\lambda I(x,y)$ Par translationComparaison de pointsTrouver le point le plus similaireStereo-vision: on suppose que les points similaires sont sur la meme ligneComment trouver des points facilement identifiables ? GradientsContoursEtcKernel Aussi appele noyau ou masque ou matrice de convolution Permet d‚Äôappliquer une operation a l‚Äôimage Convolution:Gradient Va nous permettre d‚Äôobtenir une caracteristique de variabilite autour d‚Äôun pointEn 1D:En 2D: Filtre de SobelLaplacienDetection de contoursDetection de coins Zones ou le gradient varie dans plusieurs directionsDetecteur de Harris:Changement d‚ÄôechelleComment reconnaitre un point apres un changement d‚Äôechelle ? Avec des descripteurs !Descripteur Moyen de decrire une zone locale de l‚Äôimage Les ‚Äúfeatures‚Äù sont associees a des points localement distincts dans l‚Äôimage Les descripteurs sont la signature de ces pointsDifferences de GaussiennesDetection de blobs par differences de Gaussiennes:On soustrait l‚Äôimage floutee a l‚Äôimage normaleInvariance par changement d‚Äôechelle pour les differences de Gaussiennes:Descripteur SIFT Scale Invariant Feature TransformDetection de blobs par la methode des differences de gaussienneRotationComment reconnaitre un point apres une rotation ?Descripteur SIFTHistogramme d‚Äôorientations du gradient Decoupage en $4\\times 4$ fenetres Histogramme sur 8 directionsResume: Identification/Matching des keypointsAutres descripteurs MSER (Maximally Stabel Extremal Regions) SURF (Speeded Up Robust Features) ORB (Oriented FAST and Rotated BRIEF) SIFT et SURF sont brevetes OpenCV a invente ORB comme alternative open-source et gratuite BRIEF FAST KAZE etcExtraction de caracteristiques localesComment valoriser l‚Äôinformation ? Reconaissance/detection d‚Äôobjets Estimation de la pose/localisation De la projection d‚Äôobjets 3D sur le plan Image D‚Äôobjets 3D dans le monde De la camera dans le monde Estimation du mouvementReconaissance d‚ÄôobjetsObjectifs: Detection d‚Äôinstances d‚Äôobjets par points d‚Äôinteret Transformee de Hough RANSAC Detection de categories d‚Äôobjets Sac de mots visuels Transformee de HoughA l‚Äôorigine, detection de lignes droites: Chaque point votre pour ‚Äútoutes‚Äù les lignes qui passent par lui Les votes sont accumules Un maximum local corresponds a des lignes candidatesPossible probleme: trouver le maximum vrai Mean shift Gaussian convolution ‚Ä¶Transformee de Hough generalisee Contour/forme arbitraire Choix d‚Äôun point de reference our le contour (e.g. le centre) Pour chaque point du contour, se rappeler de sa position par rapport au point de reference Calcul de l‚Äôangle RANSACCas de lignes Choix aleatoire de droites Vote base sur le nombre de points proches de la ligne todoAmelioration Elimination de outliers par RANSAC Amelioration de l‚Äôestimation de RANSAC TODOComparaisonReconnaissance d‚Äôobjets 3DBase sur la detection de features 3 features minimum sont necessaires pour la reconnaissanceReconnaissance d‚Äôobjet 3D base sur la detection d‚Äôun modele 3D connuMots visuelsPrincipe: extraction de features locales a partir d‚Äôun certain nombre d‚Äôimages Cartographie des descripteurs vers de mots visuels qui quantifient l‚Äôespace des features Le centre des clusters definissent les prototypes de mots Determination de quel mot doit etre assigne a chaque nouvelle region de l‚Äôimage en trouvant le centre du cluster le plus procheExempleChaque groupe de patch correspond a un meme mot visuel Resumer une image entiere a partir de sa distribution de presence de mots Analogue a un sac de mots souvent utilise pour les documents de texteCreation d‚Äôun vocabulaire visuel: Repertorier un ensemble de mots visuels (~ dictionnaire) Differentes strategies Apprentissage supervise Deep learning etc Strategies d‚Äôechantillonnage:Arbre de vocabulaire: Remplissage:Probleme: certains mots visuels sont discriminants D‚Äôautres apparaissent dans de nombreuses imagesCalcul d‚Äôun poids pour chaque mot visuel Le poid correspond a la quantite d‚Äôinfo esperee Normalisation des histogrammes en fonction de ce poidsEstimation du mouvementObjectifs Detection/ Estimation du mouvement dans la scene Du au mouvement de la cmaera Mouvement des objets Perception du mouvement apparent Champs des vecteurs de deplacement Flux optique Flux optiqueDifficultes de l‚Äôestimation du flux optique Ambiguites Premiere image: deplacement de drone, champ de vecteurs = deplacement des pixels Si on aune voiture qui se rapproche de nous, on peut segementer la voiture du reste de l‚Äôimage a partir de champs de vecteursInterpretation du flux:Vitesse: La camera se deplace a une vitesse $(X‚Äô, Y‚Äô, Z‚Äô)$ par rapport a la scene Si on derive les equations de perspective on a donc:Interpretation du fluxTranslation pure selon $X$ (ou $Y$)Translation pure selon $Z$:Cas general: Donne la direction du deplacement Mouvement $(X‚Äô, Y‚Äô, Z‚Äô)$ Soit $[X_0, Y_0, Z_0]^T$ un point de la scene, apres un temps $t$, il est projete sur l‚Äôimage au point $[u_t, v_t]^t$ avec:Temps avant collision: Mesure de la taille d‚Äô‚Äòun element $\\lambda = f\\frac{\\Lambda}{z}$Bundle adjustment Nous avons pour l‚Äôinstant uniquement utilise des paires d‚Äôimage pour obtenir une information de profondeur Dans le cas general, il est possible d‚Äôutiliser $N\\gt 2$ images/cameras Le Bundle (block) adjustment ou ajustement de faisceaux en bloc, est une methode de resolution au sens des moindres carres les coordonnees 3D des points et aligner les images Plusieurs images sont corrigees ‚Äúen bloc‚ÄùPrincipe: Demarrer avec une approximation initiale Projeter les points 3D sur les plans images des cameras Comparaison avec la mesure Ajustement pour minimiser l‚Äôerreur Le BA est une approche non-lineaire de resolution par moindres carres: $\\bar x_{ij} + \\hat e_{x_{ij}} = \\lambda_{ij}P_{ij}\\bar X_i$ Avec $\\hat e_{x_{ij}}$ l‚Äôerreur de mesure du point $\\bar X_i$ $i l‚Äôindice du point, $j$ l‚Äôindice de la camera Elimination du facteur d‚Äôechelle: $\\bar x_{ij} + \\hat e_{x_{ij}} = \\frac{P_{1:2{ij}}\\bar X_i}{P{3_{ij}}\\bar X_i}$ Resolution par SVDOdometrie Visuelle Estimation du mouvement de la camera par rapport au mondeNecessaire a de nombreuses applications Pas de GPS Genre sur Mars IMU et/ou odometrie des roues insuffisants On va mettre des encodeurs sur les roues et lire de combien s‚Äôest deplace la roue Odometrie: Estimation du mouvement base sur le modele cinematique Extansion a la visionTriangulation Permet de connaitre la position 3D d‚Äôun point Principe: Trouver des correspondances de points entre 2 images successives: utilisation de descripteurs Si le monde est statique et les points bien apparies alors on peut estimer la transformation $(R,t)$ a partir des parametres extrinseque Probleme de minimisation de l‚Äôerreur de reprojection Necessite d‚Äôune bonne calibration Peu robuste aux rotations pures On compense ave l‚ÄôIMU et l‚Äôodometrie des roues Pseudo code:Capturer l&#39;image I_kCalculer les correspondannce entre I_k-1 et I_kCalcul de la matrice essentielle E et que p^TEp&#39; = 0Decomposition de E en R_k et t_k par SVDCalcul du modele 3D (coordonnees des points de correspondance)Redimensionnement de t_k pour prendre en compte l&#39;echelle Attention ! p^TEp&#39; = 0 &amp;lt;=&amp;gt; lambda p^TEp&#39;=0k = k + 1SLAM Simultaneous Localization and Mapping Si une carte est fournie, possibilite de se localiser dans cette carte uniquement Si une position est fournie, possibilite de creer une carte de l‚Äôenvironnement Le SLAM est l‚Äôestimation conjointe d‚Äôune carte de l‚Äôenvironnement et de la position de la camera dans cette carte Necessaire des qu‚Äôun robot doit explorer un environnement totalement ou partiellement inconnu Amelioration de l‚Äôodometrie visuelle On sauvegarde les coordonnees des points 3D extraits et de leurs caracteristiques locales Creation d‚Äôune carte de features 3D3 categories principales de methodes pour l‚Äôestimation de l‚Äôetat: Extended Kalman Filter Particle Filter Least Squares =&amp;gt; Graph-based SLAMGraph-based SLAM Utilisation d‚Äôun graphe pour representer les variables et les relations entre ces variables Pose Graph: contient uniquement les positions Factor Graph: contient des facteurs reliant les differentes variablesPose Graph: Chaque noeud represente une pose Les liaisons entre ces noeuds contiennent leur relation spatiale L‚Äôoptimisation essaye de trouver la position optimale d‚Äôun noeud qui minimise l‚Äôerreur introduite dans les liaisonsQuels sont les avantages ? Meilleure estimation des coordonnees 3D des points/features Fermeture de boucles (Loop-closure) Plus robuste face aux rotations pures" }, { "title": "VPOA: Analyse de l&#39;environnement 3D", "url": "/cours/posts/vpoa_analyse_3d/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-04 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionOn sait obtenir de l‚Äôinfo en 3D sous la forme d‚Äôun nuage de points (sous forme de nuage de points, carte de disparite).Comment valoriser cette donnee ? On peut se localiserDetection d‚Äôobjets Visualisation 3D Reconstruction de modele 3D Building Information Modeling Clustering 3D Dimensionnement 3D Detection d‚Äôobjets 3D Modele numerique de terrain Navigation autonome etcComment passer d‚Äôun nuage de points a une donnee a valeur ajoutee ? Analyse 3D Segementation RecalageAnalyse de Surface et Reconstruction 3DSegmentation semantique But: segmenter en temps reel tous les points segmenter toutes les donnees accumulees Utile pour les vehicules autonomesReconstruction 2DExemple de problematique en 2D: Dans la realite, le probleme n‚Äôest pas si simple Extraction de la surface Discretisation Octree (1 point par cellule) Calcul d‚Äôun champ de vecteurs Calcul de la fonction indicatrice Extraction de l‚ÄôisosurfaceReconstruction 3D En 3D, ca donne: VoxelisationDifferentes methodes de voxelisationMaillageEnsemble de sommets connectesAnalyse de surfaceCalculs de normales par ACP: On cherche le meilleur plan approche dans le voisinage d‚Äôun point $X_{i0}$ Les points du voisinage sont notes $X_i$ Equation d‚Äôun plan $n^tX=d, \\Vert n\\Vert =1$ Distance signee d‚Äôun point au plan: $d(X_i, P) = n^tX_i-d$Resolution Methode des moindres carres Resolution de l‚Äôequation de minimisation pour le planFonction a minimiser: $f(n,d)=\\sum_{i=1}^m(n^tX_i-d)^2$On pose: Barycentre des points $G=\\frac{1}{}$ Matrice de covariance des pointsTODOLe meilleur plan approche est defini par: Normale $n_{min}$ Vecteur propre norme associe a la plus petite valeur propre de $M_{cov}$ NB: indetermine a un changement de sens pres Distance $d_{min}$ $d_{min}=n^tG$ La solution fait appel a l‚Äôanalyse des directions principales de la matrice de covariance: Analyse en Composantes Principales (ACP)Segmentation 3D Definition Subdiviser (partitionner) le nuage de points 3D en sous-ensembles connexes correspondants a des modeles simples Methodes de segmentationCroissance de surface Principe A partir de ‚Äúsurfaces germes‚Äù ou ‚Äúgraines‚Äù (seed surfaces) dans le nuage de point Agregation progressive des points voisins appartenant a la meme surface Remarque: extension de l‚Äôalgorithme ‚Äúcroissance de regions‚Äù pour les imagesPour chaque point, un calcul de la normale du plan dans un voisinage:Critere d‚Äôagregation: Co-normalite: $\\alpha = \\arccos(n_1, n_2)\\le \\alpha_{seuil}$ Normales dans le meme sens Coplanarite: $d=\\max(\\vert r_{12}\\cdot n_1\\vert, \\vert r_{12}\\cdot n_2\\vert) \\le d_{seuil}$ Points sur le meme plan Clustering Definition Regroupement de donnees en paquets homogenes selon des caracteristiques commnunesDBSCAN C‚Äôest l‚Äôun des algorithme de clustering les plus repandusPrincipe: Choix d‚Äôun point graine pour la region Identification des voisins du point Pour chaque point voisin Si la densite locale de points est suffisante, ajout a la region Sinon, labellisation en tant que bruit On continue jusqu‚Äôa ne plus pouvoir etendre la regionOn peut jouer sur 2 parametres: Le rayon de recherche des voisins La quantite minimale de voisin ou densiteRANSAC RANdom SAmple ConsensusMethode de vote sur des echantillons aleatoires de surfaces Echantillons calcules a partir du nombre minimal de points necessaires pour definir la surface(quorum) Vote: un TODOPrimitives geometriques et quorum de points: Droite: Quorum = 2 points non alignes Plan: Quorum = 3 points $x_i$ non alignes TODO Vote: Nombre de points compris dans un espace a une certaine distance $\\delta$ de la surface calculeeProbabilites: Hypotheses Plusieurs surfaces possibles, points non bruites $N$ points dans le nuage de points $n$ points appartiennet a la surface recherchee $q$ points pour definir la surface (quorum)TODO Nombre de tirages necessaires: Nombre de tirage aleatoires $T_{min}$ necessaires pour avoir une probabilite $p_t$ de trouver une surface d‚Äôau moins $n_{min}$ points\\[T_{min} = \\frac{\\log(1-p_t)}{\\log(1-(\\frac{n_{min}}{N})^q)}\\] En supposant $n_{min}\\lt\\lt N:T_{min}\\simeq \\log(\\frac{1}{1-p_t})$ TODOHough 3DPrincipe: Methode de vote dans l‚Äôespace dicreTODODetection de droitesTODOProblemeDeep learningRecalage 3DPoint Set Registration, Point Matching: Processus d‚Äôalignement de jeux de points TODOIterative Closest Point ICP Determination de la transformation rigide $(R,t)$ entre les deux nuages de pointsPrincipe Appariement des points du nuage a recaler au point le plus proche dans l‚Äôautre nuage (approche de ‚Äúnearest neighbor‚Äù) Calcul de la transformation $(R,t)$ qui minimise la distance entre ces pointsCalcul de la transformation $(R,t)$Resolution par la methode des moindres carres:On calcule:\\[f(R,t) = \\sum_{i=1}^n\\Vert p_i-(R\\cdot p_i&#39;+t)\\Vert^2\\\\f:\\begin{cases}SE^3&amp;amp;\\to \\mathbb R^+\\\\(R,t)&amp;amp;\\mapsto f(R,t)\\end{cases}\\]On cherche: $(R,t)$ tel que $(R, t)=\\text{arg}\\min_{R,t}f(R,t)$Solution par decompositionTODOResolution par Singular Value Decomposition (SVD) Entree: jeux de points $(P,P‚Äô)$ sortie: Matrice de rotation $R$, vecteur translation $t$ Algorithme Determiner les barycentres $p_m=\\frac{1}{n}\\sum_{i=1}^n$ et $p_m‚Äô$ Calculer la matrice $H$ Decomposer $H$ en valeurs singulieres $\\exists(U, V, \\Sigma)$ TODO Calculer $R=VU^T$ et $t=p_m-p_m‚Äô$ Pseudo code ICP:Recalage approximatif P&#39;-&amp;gt;PRepeter: - Association de donnees P&#39; -&amp;gt; P - Calcul de la transformation (R, t) - Application de la transformation au nuage de point P&#39; - Calcul de la distance entre les nuagesTant que: - Distance normalisee &amp;gt; seuil - Et nombre d&#39;iterations &amp;lt; maximum d&#39;iterationsTemps de calcul: Appariement en $O(n_1, n_2)$, le reste en $O(n_1 + n_2)$ Acceptable pour les petits nuages de points, trop lent pour de gros nuages de points Necessite de sous-enchatilloner Possibilite d‚Äôacceleration avec ANN (Approximate Nearest Neighbor): $O(n_1\\log(n_2))$Approximate Nearest Neighbor (ANN) Principe Pre-calcul d‚Äôun kd-tree pour partitionner l‚Äôespace Recherche dichotomique avec distance seuil Variante ICP: Metrique point a plan (point to plane) Echantillonage: regulier, aleatoire, base sur les normales Rejection des outliers ‚Ä¶" }, { "title": "VPOA: Perception 3D", "url": "/cours/posts/vpoa_perception_3d/", "categories": "Image S9, VPOA", "tags": "Image, S9, VPOA", "date": "2021-11-03 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionMagellium Observation de la terre Analyse et traitement de donnees satelittes Geo-information Imagerie et Applications Essayer d‚Äôextraire de la donnee image Infrastructure logicielleL‚Äôentreprise: 248 employes 2 sitesOffres et marcheImagerie &amp;amp; applicationsActivites Image &amp;amp; video Lidar &amp;amp; 3D RobotiqueOffre Transfert de technologies Conception, systeme de perception Dev logicielPositionnement Ce n‚Äôest pas de la sous-traitanceTechnos cles Capteurs 2D &amp;amp; 3D Detection et reconnaissance d‚Äôobjets Localisation et navifation Technos informatiques avanceesSyntheseMetier et projetsResponsable technique Definition des architectures et algos Encadrement technique des equipes Echange clients et/ou partenairesThematiques Computer vision Robotique d‚Äôexploration planetaire Robotique orbitaleAutres Labo vision Deep learningProjet H-20 Projets finances par la comission europeenne Autonomous Decision MakingAssemblage de structures en orbite comme des telescopesSuite de ADET0: en moisBeaucoup implique au CNESRobot Simple Fetch Rover (SFR)MMT2 pour ThalesComputer visionComment les eleves decrivent le computer vision ? ‚ÄúUn truc de GISTRE‚Äù DefinitionUn domaine inter-disciplinaire pour permettre a une machine d‚Äôanalyser, traiter et comprendre une representation de l‚Äôenvironnement obtenue par un systeme d‚Äôacquisition. Cette branhe de l‚Äôintelligence artificielle implique le developpement d‚Äôalgorithmes permettant l‚Äôautomatisation de taches que le systeme visuel humain peut realiser. IntroductionQu‚Äôest-ce que la perception ? Une representation de la realiteOn va estimer des choses proprietes geometriques proprietes semantiques Ce qui concerne le sens/la signification Que peut-on obtenir ? Reconstruction 3D Interpretation semantique Interpretation d‚ÄôimageDe l‚Äôobjet a l‚ÄôobservationDe l‚Äôobservation a l‚ÄôobjetCe qu‚Äôon veut faire en computer visionSystemes d‚Äôacquisition 3DTomographie numeriqueRayons X Principe de l‚ÄôIRM Superposition de coupes 2D successivesTelemetrie par temps de volEnvoi d‚Äôune impulsion pulsee Lumineuse classique: camera ToFLidar ToFComment on voit derriere l‚Äôobjet ? On ne peut pas voir derriere les objetsOn devine en utilisant des donnees autour et on interpoleTelemetrie par decalage de phaseEnvoi d‚Äôune impulsion modulee Lumineuse classique: Camera SWIR a modulation de phase Lumineurse Laser: LIDAR Ultrasonore: SONAR Ondes Radio: RADARMesure du decalage de la phase Il faut utiliser des longueurs d‚Äôondes adaptees aux utilisations qu‚Äôon veut en faire C‚Äôest comme ca qu‚Äôon se fait flasher sur l‚ÄôautorouteTriangulationPrincipe utilise par les geometres, le GPS‚Ä¶Triangulation activePointeur laser Un rayon laser est envoye vers l‚Äôobjet a mesurer La lumiere diffusee est observee par une camera On peut en deduire la profondeur du pointLaser ligne, profilometrie Une image saisie donne une ligne de points Un unique balayage suffit pour assurer la couverture de la surfaceLumiere structuree Projection d‚Äôun motif connu Appariement pixels/motifCamerasAvantages: Pas de contact Peu onereux Robuste (~pas de piece mobile, pas d‚Äôinterferences‚Ä¶) Facilite d‚Äôacquisition de grandes quantites de donnees Couverture dense Grande variete de distances Possibilite d‚Äôobtenir de l‚Äôinformation 2D et 3D Pas besoin d‚Äôeclairage specifique Technique passive Informatino geometrique mais aussi semantique, interpretation de l‚Äôimage Donnee directement interpretable par l‚ÄôHommeInconvenients: Besoin de lumiere Occlusions Perte d‚Äôinformation Une image est une projection du monde 3D sur un plan 2D Difficulte de l‚Äôappariement des pixels Precision relativement faibleMono-vision passive Utilisation d‚Äôimage 2D pour avoir un rendu 3DStereo-vision Vision d‚Äôune meme scene depuis 2 endroits legerements decales l‚Äôun par rapport a l‚Äôautre Principe de la perception 3D chez l‚ÄôHommePrecision et etalonnage Les points 3D sont des mesures geometriques obtenues par des principes physique (lumiere, contact, etc.) et mecaniques Les erreurs systematiques de mesure peuvent etre ameliorees par calibrage/etalonnageModelisation de la cameraGeometrie optiquePostulats: La propagation de la lumiere est decrite par des rayons lumineux provenant d‚Äôune source de lumiere Un rayon lumineur suis une ligne droite dans un milieu homogene A l‚Äôintersection entre 2 milieux homogenes, la lumiere est reflehie ou refractee Le chemin parcouru par un rayon lumineux et reversible L‚Äôintersection de rayons lumineux est sans effetsModelisation de la camera Capteur uniquementComment eviter ca ? On met une lentille :) (Theotime) Pinhole/stenope C‚Äôest le modele stenope Distance focaleOuverture Reduction de la taille de l‚Äôouverture Amelioration de la nettete Reduction de la luminosite Problematique du computer vision: choisir la bonne ouvertureLumiere Sans lumiere, pas d‚Äôimage (pas de bras pas de chocolats) L‚Äôillumination de la scene a une influence importante sur le processus d‚Äôacquisition Controler l‚Äôillumination est un concept clef GLobalement possible de controler l‚Äôilluminatino dans l‚Äôindustrie Difficile a impossible en milieu exterieur Il faut si possible controle l‚Äôillumination Sinon, agir sur les parametres physiques de la camera Vitesse d‚Äôobturation Ouverture Petite vitesse d‚Äôobturation et/ou grande vitesse de l‚Äôobjet $\\Rightarrow$ attention au flou de mouvement Logiciel d‚Äôauto-exposition Cameras ‚Äúglobal shutter‚Äù plutot que ‚Äúrolling shutter‚ÄùLentilles Utilisation d‚Äôune lentille pour concentrer la lumiere sur le plan image Amelioration de la luminosite Amelioration de la nettete Distance focale La distance entre la lentille et le point ou tous les rayons lumineux convergentFocus Les objets sont correctement projetes sur le plan image uniquement lorsqu‚Äôils sont a une certaine distance de la lentille/lorsque le capteur est a une certaine distance de la lentilleDistance de focusHyperfocale Definition Distance minimum a laquelle il est possible de faire la mise au point tout en gardant les objets situes a l‚Äôinfini avec une nettete acceptable Depend de la distance focale et de l‚Äôouverture Validite du modele stenopeOn peut assimilier une camera munie d‚Äôune lentille a une camera stenope si: On considere uniquement le rayon lumineux central On suppose que la mise au point est faite On considere que la distance de focus de la camera avec lentille est equivalenete a la distance focale de la camera stenope On neglige ou corrige les distortions induites par la lentille On ajoute un systeme d‚Äôouverture pour limiter les erreursDistortions Probleme des lentilles Distortion radiale Distortion en moustache mais tres rare Distortion tangentielle La distortion est plus importante pour les rayons qui passent pres du bord de la lentille Astigmatisme La distance focale est differente selon l‚Äôaxe $X$ et l‚Äôaxe $Y$ car la lentille n‚Äôest pas parfaitement circulaire AbberationsProbleme des lentilles Aberration chromatique Aberration comatique S‚Äôobserve notemment sur les telescopes Malformation capteurProbleme du capteur Asymetrie des pixels ou ‚Äúskewness‚Äù Souvent negligeable sur les cameras modernesBruitProbleme du capteur Bruit lie a l‚Äôelectronique Bruit lie a la discretisation des mesures (seulement 255 valeurs possibles)Geometrie optiqueSysteme d‚ÄôequationCentre optique Le capteur et la lentille ne sont pas parfaitement alignes $\\Rightarrow$ decalage entre le centre optique et le centre de l‚ÄôimageLe point/pixel de coordonnees $(0,0)$ dans l‚Äôimage correspond au coin superieur gauche On applique une tranlsation permettant de passer au centre optique $(0,0)$ de l‚ÄôimageParametres intrinseques Retenir: matrice intrinseque3D vers image 2D:\\[\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}\\sim K\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix}\\quad\\text{Equivalent a un facteur d&#39;echelle pres}\\]\\[\\exists\\lambda\\text{ tq }\\lambda\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix} = K\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix}\\] Les coordonnees du monde ne sont pas necesairement les memes que les coordonnees de la camera Il faut convertir du systeme de cooordonnees du monde vers le system de coorodnnnees de la camera\\[\\begin{bmatrix}X_c\\\\Y_c\\\\Z_c\\end{bmatrix}=R\\cdot\\begin{bmatrix}X\\\\Y\\\\Z\\end{bmatrix} + t\\] $R$ une matrice de rotation $3\\times 3$ $t$ un vecteur translationDu monde a l‚ÄôimageEstimation de la matrice camera $P$ une matrice $3\\times 4\\Rightarrow 12$ inconnues $P\\sim K\\cdot[R\\vert t]$ On peut decomposer en $P=[\\vert P_1\\vert P_2]$ $P_1=K\\cdot R$ matrice $3times 3$ $P_2=k\\cdot t$ vecteur $3\\times 1$ Resectioning: On estime $P$ a partir de parires $\\bar x$ et $\\bar X$ connues Estimation de la matrice intrinsequePlane-based calibration On realise l‚Äôacquisition de multiple images d‚Äôune surface plane (e.g. damier) Cela permet de fixer $Z=0$ pour tous les points du plan observeOn a donc:\\[\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}\\sim K\\begin{bmatrix}r_1&amp;amp;r_2&amp;amp;t\\end{bmatrix}\\begin{bmatrix}X\\\\Y\\\\1\\end{bmatrix}=H\\begin{bmatrix}X\\\\Y\\\\1\\end{bmatrix}\\] A l‚Äôaide de ces equations et de la conaissance du plan observe, il est possible de determiner $K$ Parametres de distorsion Il est possible d‚Äôestimer des aprametres caraterisant les distortions radiales et tangentielles Plusieurs modeles de distorsion existent, notamment le modele polynomial de Brown-ConradyModele completComment realiser une bonne calibration ? La cible doit etre parfaitement plane Les motifs de type cercles asymetrqiues donnent de meilleurs resultats La distance entre les points doit etre mesuree precisement Il faut correctement definir le nombre de lignes/colonnes de la cibleControler l‚Äôenvironnement de calibration Pas de sources de lumiere directe Pas d‚Äôautres cible/motifs similaires visible Pas de relets Controle de l‚Äôexposition Il faut toujours calibrer sur siteProcedure de calibration Mettre la camera dans une position fixe Acquerir 9 images a la distance de travail la plus proche Recommecer pour la distance de travail moyenne Acquerir 8 images avec des inclinaisons differentes de la cible Acquerir 5 a 10 images supplementaires avec des angles ‚Äúaleatoires‚Äù Essayer d‚Äôavoir une distribution homogene des points dans le plan image StereovisionTriangulationGeometrie epipolaireLignes epipolairesMatrice essentielle $E$Matrice fondamentale $F$RectificationLe fait de rendre 2 images ‚Äúparalleles‚Äù Rend la triangulation facile Facilite l‚ÄôappariementAppariement de points Trouver les coordonnees en pixel d‚Äôun point 3D dans le plan image des 2 cameras Les points images sont sur la meme ligne lorsque les images sont rectifieesPlans image paralelles DispariteDistance en pixels qui separe la projection d‚Äôun meme point sur les images des 2 cameras Calcul de la profondeurImage de disparite/clarte de profondeurCalcul des coordonnees 3DMethodes de correlationComment faire pour trouver les points correspondants ?De facon naive, recherche identique mais on peut avoir des pixels qui ont la meme valeurs et avoir des faux positifs -&amp;gt; selection d‚Äôune fenetre pick a window $W$ around $\\bar p = (\\bar u, \\bar v)$ build vector $w$ Slide the window $w$ along $v=\\bar V$ in image 2 and compute $w‚Äô(u)$ for each $u$ Compute the dot product $w^Tw‚Äô(u)$ C‚Äôest sensible aux differences d‚Äôexposition On fait de la normalized crossed-correlation On peut faire varier la taille de la fenetrePetite fenetre: Plus de details Plus de bruit Problemes de la stero-visionOcclusionsProblemes de la stereo vision Regions homogenes et/ou peu texturees Patterns repetitifsInfluence de la baseline Petite baseline, petit $\\frac{B}{Z}$ Grande baseline, grand $\\frac{B}{Z}$Disparite entiere Le processus de stereo-correlation permet uniquement de calculer des valeurs entieres de disparite Il est necessaire de raliser une interpolation pour lisser les disparite Exemples ans interpolation sous-pixellique: Une fonction d‚Äôinterpolation sous-pixellique doit etre implementeeLa fonction de disparite est estimee en appliquant une fonction de la forme:\\[d_{subpix} = d_{int} + f(s_{left}, s_{med}, s_{right})\\]avec $s$ les scores de correlationOn peut simpifier la formulation de cette fonction:\\[d_{subpix}=\\begin{cases}d_{int} - 0.5 + f(\\frac{l_d}{r_d}) &amp;amp;\\text{if } l_d\\le r_d\\\\d_{int} + 0.5 + f(\\frac{r_d}{l_d}) &amp;amp;\\text{otherwise}\\end{cases}\\]L‚Äôutilisation d‚Äôune fonction d‚Äôinterpolation sous-pixellique a pour effet d‚Äôintroduire de petites erreurs sous la forme d‚Äôune sinusoideMeme si cet effet est difficilement visible sur la carte de disaprtie, il apparait clairement sur la reprojection 3D:Deep learningReseaux de neurones convolutifs:Etat de l‚Äôart" }, { "title": "PRSTA: TD 5", "url": "/cours/posts/prsta_td5/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-29 14:30:00 +0200", "snippet": "Lien de la note HackmdFeuille 3 Exercice 4La variable aleatoire $X$ suit une loi de Pareto de parametre $\\alpha$.A l‚Äôaide du theoreme de Wilks, ecrire la zone de rejet du test $H_0 : \\alpha = 2$ contre $H_1 : \\alpha \\gt 2$. Solution Nous n‚Äôavons pas de valeur pour $H_1$, mais $\\alpha\\gt 2$. Nous allons donc le remplacer par l‚ÄôEMV. Pour la loi de Pareto de parametre $\\alpha\\gt 0$ dont la densite est donnee par\\[f(x,\\alpha) = \\alpha x^{-\\alpha-1}\\] pour $x\\gt 1$. Determinons l‚ÄôEMV. On a:\\[L(x,\\alpha) = \\alpha^{n}\\prod_{i=1}^nx_i^{-\\alpha-1}\\] d‚Äôou\\[\\log L(x,\\alpha) = n\\log \\alpha + \\sum_{i=1}^n(-\\alpha-1)\\log(x_i)\\] et\\[\\frac{\\partial\\log L}{\\partial\\alpha}(x,\\alpha) = \\frac{n}{\\alpha}-\\sum_{i=1}^n\\log(x_i)\\] Ainsi\\[\\frac{\\partial\\log L}{\\partial \\alpha}(x,\\alpha) =0\\] equivaut a\\[\\frac{n}{\\alpha}-\\sum_{i=1}^n\\log(x_i) = 0\\] Nous obtenons la solution $\\hat\\alpha = \\frac{n}{\\sum_{i=1}^n\\log (x_i)}$ Reste a verifier la condition du second ordre:\\[\\frac{\\partial^2\\log L}{\\partial\\alpha^2} = -\\frac{n}{\\alpha^2}\\lt 0\\] Par consequent, $\\hat\\alpha = \\frac{n}{\\sum_{i=1}^n\\log(x_i)}$ est bien l‚ÄôEMV \\[\\begin{aligned}T&amp;amp;= \\frac{L(X_1,\\dots,X_n,\\hat\\alpha)}{L(X_1,\\dots,X_n,2)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n(\\frac{n}{\\sum_{j=1}^n\\ln(X_j)})X_i^{-(\\frac{n}{\\Sigma \\ln(X_i)+1})}}{\\prod_{i=1}^n2X_i^{-3}}\\\\&amp;amp;= \\biggr(\\frac{n}{2\\Sigma\\ln(X_j)}\\biggr)^n\\prod_{i=1}^nX_i^{-\\frac{n}{\\Sigma\\ln(X_i)+2}}\\end{aligned}\\]\\[\\begin{aligned}R_n&amp;amp;= 2\\ln(T)\\\\&amp;amp;= 2n\\ln(\\frac{n}{2S})+\\sum_{i=1}^n(2-\\frac{n}{S})\\ln(X_i)\\end{aligned}\\\\\\color{red}{S:=\\sum_{j=1}^n\\ln(X_j)}\\\\\\begin{aligned}Rn &amp;amp;= 2n\\ln(\\frac{n}{2S})+(2-\\frac{n}{S})S\\\\&amp;amp;= \\boxed{2n\\ln(\\frac{n}{2S})+2S-n}\\end{aligned}\\] Asymptotiquement, $R_n$ suit asymptotiquement une loi de $\\chi^2$ a $n$ degre de liberte. La zone de rejet est:\\[\\{R_n\\gt\\chi^2_{\\color{red}{1-\\alpha}}\\}\\] ou $\\chi^2_{1-\\alpha}$ designe le quantile de niveau $1-\\alpha$Feuille 3 Exercice 6Considerons $n$ variables aleatoires independantes de densite:\\[f(x,\\theta) = \\theta^2xe^{-\\theta x}ùüô_{\\mathbb R_+}(x)\\]ou le parametre $\\theta$ est strictement positif.Nous disponsons de $n$ observations et voulons tester l‚Äôhypothese $H_0:\\theta = \\theta_0$ contre l‚Äôhypothese $H_1:\\theta = \\theta_1$ avec $\\theta_0\\lt \\theta_1$ Justifier que $f(x,\\theta)$ definit bien une densite pour tout $\\theta\\gt 0$ Calculer $E(X)$ Determiner la statistique de Neyman-Pearson que nous noterons $T_n$ En admettant que $\\theta T_n$ suit une loi $\\Gamma(2n,1)$, determiner une expression de $\\alpha$ et $\\beta$ en fonction du seuil du test Determiner les courbes COR associes a ce test. Solution On saute les 2 premieres questions car fait et refait 3.\\[\\begin{aligned}T &amp;amp;= \\frac{L(X_n,\\dots,X_n,\\theta_1)}{L(X_n,\\dots,X_n,\\theta_0)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n\\theta_1^2X_ie^{-\\theta_1X_i}}{\\prod_{i=1}^n\\theta_0^2X_ie^{-\\theta_0X_i}}\\\\&amp;amp;= \\biggr(\\frac{\\theta_1}{\\theta_0}\\biggr)^{2n}\\times e^{\\sum_{i=1}^n(\\theta_0-\\theta_1)X_i}\\end{aligned}\\] On passe au logarithme:\\[\\begin{aligned}\\ln T&amp;amp;= \\underbrace{2n\\log(\\frac{\\theta_1}{\\theta_0})}_{\\color{green}{a}}+\\underbrace{(\\theta_0-\\theta_1)}_{\\color{green}{b}}\\sum_{i=1}^nX_i\\end{aligned}\\] L‚Äôhypothese $H_0$ est rejetee lorsque:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln T&amp;amp;\\gt\\ln C_{\\alpha}\\\\a+b\\sum_{i=1}^nX_i&amp;amp;\\gt\\ln (C_{\\alpha})\\\\\\underbrace{\\sum_{i=1}^n X_i}_{\\color{red}{T_n}}&amp;amp;\\lt \\underbrace{\\frac{\\ln(C_{\\alpha})-a}{b}}_{\\color{red}{S_{\\alpha}}}\\end{aligned}\\\\\\color{green}{\\text{car } b = \\theta_0-\\theta_1\\lt 0}\\] Donc:\\[T_n\\lt S_{\\alpha}\\] 4.\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{Rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T_n\\lt S_{\\alpha}\\vert \\theta=\\theta_0)\\end{aligned}\\] Sous $H_0$, $\\theta_0 T_n$ suit une loi $\\Gamma(2n, 1)$\\[\\begin{aligned}\\alpha &amp;amp;= P(\\theta_0T_n\\lt\\theta_0 S_{\\alpha})\\\\&amp;amp;= F_n(\\theta_0S_{\\alpha})\\end{aligned}\\] Ou $F_n$ designe la fonction de repartition de la loi $\\Gamma(2n,1)$. Exprimons $S_{\\alpha}$ en fonction de $\\alpha$: \\[\\boxed{S_{\\alpha}=\\frac{F_n^{-1}(\\alpha)}{\\theta_0}}\\] \\[\\begin{aligned}\\beta&amp;amp;= P(\\text{Rejeter }H_1\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(T_n\\ge S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\theta_1T_n\\ge\\theta_1S_{\\alpha}\\vert\\theta=\\theta_1)\\end{aligned}\\] Or sous $H_1$: $\\theta T_n\\sim\\Gamma(2n,1)$ Donc: \\[\\boxed{\\begin{aligned}\\beta&amp;amp;=1-F_n(\\theta,S_{\\alpha})\\\\&amp;amp;=1-F_n(\\frac{\\theta}{\\theta_0}F_n^{-1}(\\alpha))\\end{aligned}}\\] En python: scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.05, 20, scale=1), 20, scale = 1) 0.9184... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.05, 50, scale=1), 50, scale = 1) 0.999702... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.01, 10, scale=1), 10, scale = 1) 0.316165... scipy.stats.gamma.cdf(2 * scipy.stats.gamma.ppf(0.001, 100, scale=1), 100, scale = 1) 0.9999523... On nome $\\Pi$ la probabilite de detection:\\[\\Pi = 1-\\beta\\\\\\boxed{\\Pi = F_n(\\frac{\\theta_1}{\\theta_0}F_n^{-1}(\\alpha))}\\]Feuille 4 Exercice 4Considerons $n$ variables aleatoires independantes $X_i$ suivant la loi de densite:\\[f(x,\\theta) = \\frac{3}{\\theta} x^2e^{-\\frac{x^3}{\\theta}}ùüô_{\\mathbb R_+(x)}\\]avec $\\theta\\gt 0$ ou \\(ùüô_{\\mathbb R_+}\\) designe la fonction indicatrice de $\\mathbb R_+$Nous souhaitons tester l‚Äôhypothese $H_0:\\theta = \\theta_0$ contre $H_1:\\theta = \\theta_1$ avec $\\theta_0\\lt \\theta_1$ a l‚Äôaide d‚Äôobservations $x_i$ issues de l‚Äôechantillon precedent (a) Justifier que, pour tout $\\theta\\gt0$, $f(\\cdot,\\theta)$ definit bien une densite sur $\\mathbb R$ (b) Determiner l‚ÄôEMV $\\hat\\theta$ Determiner la statistique du test de Neyman-Pearson et indiquer la region critique associe a ce test. Verifier que la variable aleatoire $Y_i=\\frac{2}{\\theta}X_i^3$ suit une loin $\\chi^2$ a deux degres de liberte En deduire le seuil du test de Neyman-Pearson en fonction du risque de premiere espece $\\alpha$ Determiner la puissance du test en fonction du test et de $\\theta_1$ Determiner les courbes COR associees a ce test (a) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=2$ et $n=15$ (b) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=5$ et $n=30$ (c) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=2$ et $n=10$ (d) Application numerique $1$ : $\\alpha = 5\\%, \\theta_0 = 1, \\theta_1=5$ et $n=30$ Solution 3. On pose $\\phi(y)=\\frac{2}{\\theta}y^3$. Ainsi:\\[\\phi^{-1}(y) = \\sqrt[3]{\\frac{\\theta y}{2}}\\] Elle est derivable car elle est polynomiale et est bijective car elle est strictement croissante.\\[\\begin{aligned}f_Y(y)&amp;amp;=\\frac{1}{(\\frac{6}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2)}\\times f(\\sqrt[3]{\\frac{\\theta y}{2}})\\\\&amp;amp;= \\frac{1}{\\frac{6}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2}\\times \\frac{3}{\\theta}(\\sqrt[3]{\\frac{\\theta y}{2}})^2\\times e^{-(\\frac{(\\sqrt[3]{\\frac{\\theta y}{2}})^3}{\\theta})}\\\\&amp;amp;= \\frac{1}{2}\\times e^{-\\frac{y}{2}}\\end{aligned}\\] On peut en deduire que $Y$ suit une loi $\\chi^2(2)$ 4.\\[\\color{green}{\\boxed{T=\\sum_{i=1}^nX_i^3}}\\]\\[\\color{green}{Y_{i} = \\frac{2}{\\theta}X_i^3\\sim X^2(2)}\\]\\[\\Rightarrow \\frac{2}{\\theta} T\\sim \\chi^2(2n)\\]\\[\\begin{aligned}\\alpha &amp;amp;=P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T\\gt S_{\\alpha}\\vert\\theta = \\theta_0)\\\\&amp;amp;= P(\\frac{2}{\\theta_0}T\\gt \\frac{2}{\\theta_0}S_{\\alpha}\\vert \\theta=\\theta_0)\\end{aligned}\\] Sous $(H_0)$, $\\color{red}{\\frac{2}{\\theta_0}T\\sim\\chi^2(2n)}$ $\\color{green}{F_n \\text{ est la fonction de repartition }\\chi^2(2n)}$\\[\\alpha = P(W\\gt \\frac{2}{\\theta_0}S_{\\alpha})\\] \\[\\alpha = 1 -F_n(\\frac{2}{\\theta_0}S_{\\alpha})\\] $\\color{red}{Donc}$\\[1-\\alpha = F_n(\\frac{2}{\\theta_0}S_{\\alpha})\\] \\[S_{\\alpha} = \\frac{\\theta_0}{2}F_n^{-1}(1-\\alpha)\\] \\[\\begin{aligned}\\color{red}{\\beta} &amp;amp;= P(\\text{Rejeter }H_1\\vert H_1\\text{vraie})\\\\&amp;amp;= P(T\\le S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\frac{2}{\\theta_1}T\\le \\frac{2}{\\theta_1}S_{\\alpha}\\vert \\theta = \\theta_1)\\end{aligned}\\]\\[w_1 = \\frac{2}{\\theta_1}T\\sim \\chi^2(2n)\\] \\[\\beta = F_n(\\frac{2}{\\theta_1}S_{\\alpha})\\]\\[\\color{green}{\\beta = F_n\\biggr(\\frac{\\theta_0}{\\theta_1}F_n^{-1}(1-\\alpha)\\biggr)}\\] Passons aux applications numeriques: scipy.stats.chi2.cdf(0.5 * scipy.stats.ppf(0.95, 30), 30) 0.14185880202947254 scipy.stats.chi2.cdf(0.2 * scipy.stats.ppf(0.95, 60), 60) 1.6239064341119149e-09 scipy.stats.chi2.cdf(0.5 * scipy.stats.ppf(0.99, 20), 20) 0.46403880816957155 scipy.stats.chi2.cdf(0.2 * scipy.stats.ppf(0.99, 20), 20) 1.87204631776198e-08 scipy.stats.chi2.cdf(1.0001 * scipy.stats.ppf(0.99, 20), 20) 0.9900104784496678 " }, { "title": "IMED2: Principe physiques de la radiologie numerique", "url": "/cours/posts/principe_radio/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-29 09:00:00 +0200", "snippet": "Lien de la note Hackmd Rappels kVp mA Temps d‚ÄôexpositionAdaptation du faisceau: Filtration uniforme (Cu) Lames de collimationInteractions avec la matiere: Diffusion elastique Diffusion inelastique Effet photoelectriqueLes chaines images selon les modalites Quelques exemplesQu‚Äôest-ce qu‚Äôune ‚Äúbonne‚Äù image ?Tout depend de la tacheOn a 3 choses tres importantes: bruit nettete Resolution spatiale contraste Contraste-to-noise ratio Bonne image a rayons X ? Ca depend encore de la tache Differentiation de matieres Pas d‚Äôartefacts (e.g., halos pres des contours, lignes, colonnes, mouvement, flou‚Ä¶) Si on a un halo autout d‚Äôun implant, on a un peu de jeu autourIl faut certainement rajouter quelque chose pour reparer caCa peut etre tres dangereux (patient fragile, agee, etc.)Zoom sur la chaine de traitement numerique L‚Äôimage qu‚Äôon voit est loin d‚Äôetre l‚Äôimage qu‚Äôon mesureSur la premiere image on a une ligne au centreQualite Image et tache clinique Qui est mon patient ? Un gamin Un adulte Une personne agee Pour quel acte vient-il ? Un suivi de scoliose / un bilan general de posture Un depistage de cancer du sein Une ablation de tumeur hepatique Selon les cas, le besoin en qualite image et la tolerance en terme d‚Äôirradtion serra differente Un principe historique: ALARA (As Low As Reasonnably Achievable) Un acronyme qui a tendance a etre remplace par ALADA (As Low As Diagnostically Achievable)Du coup il y a des guidelines:Controle automatique de l‚Äôexposition AEC: la technologie de tous les appareils modernes d‚Äôimagerie RX ‚ÄúAutomatic Exposure Control (AEC) is an X-ray exposure termination device‚Äù Wikipedia Radiographie conventionnelle Une technique aussi vieille que les rayons XOn faisait du stitching, mais on avait des problemes de deformation geometriquesEOS/EOSedge et l‚Äôimagerie orthopediqueVideo de presentationPathologies en orthopedie Diagnostic, correction &amp;amp; suivi de scolioses Chirurgie: tiges et vis Implants (hanches, genou) Osteoporose Polyarthrite" }, { "title": "PRSTA: Seance 4", "url": "/cours/posts/prsta_seance4/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-27 17:00:00 +0200", "snippet": "Lien de la note HackmdRappel Proposition Sous des hypotheses techniques, en notant $\\hat\\theta_n$ l‚Äôestimateur du maximum de vraisemblance. $\\sqrt{n!(\\theta_0)}(\\hat\\theta_n-\\theta_0)$ converge en loi vers $\\mathcal N(0,1)$ Nous disons que l‚Äôestimateur du maximum de vraisemblance est normal asymptotiquement efficace ou NAE (Best asymptotically normal ou BAN)Nous supposerons que les hypotheses techniques evoquees sont verifiees Theoreme de Wilks Sous l‚Äôhypothese $(H_0)$, $R_n:=2\\log T_n$ converge en loi ver une loi $\\chi^2(1)$Cas particulier $H_0:\\theta=\\theta_0$ $H_1:\\theta\\neq \\theta_1$Notons $\\hat\\theta$ l‚ÄôEMV Definition La statistique de Wald est:\\[W_n=\\frac{(\\hat \\theta_n-\\theta_0)^2}{V(\\hat\\theta_n)}\\] Theoreme Sous $H_0$, $W_n$ converge en loi vers un $\\chi^2(1)$ExemplePremier exemple $X\\sim\\mathcal N(m,1)$ $H_0:m=0$ contre $H_1:m\\neq 0$\\[V(\\bar X_n)=V(\\frac{1}{n}\\sum_{i=1}^n X_i)=\\frac{1}{n^2}(\\sum_{i=1}^nX_i)\\\\\\boxed{V(\\bar X_n)=\\frac{1}{n^2}\\times n=\\frac{1}{n}}\\]Second exemple $H_0$: ‚Äúle patient est sain‚Äù $H_1$: ‚Äúle patient est malade‚Äù $\\alpha$: probabilite de rejeter $(H_0)$ alors qu‚Äôelle est vraie i.e. probabilite de fausse alarme $\\beta$: probabiliter de rejeter $(H_1)$ alors qu‚Äôelle est vraie i.e., probabilite de non detection Ainsi, la puissance $\\pi:=1-\\beta$ est la probabilite de detection Caracteristiques Operationnelles du Recepteur Elles permettent d‚Äôanalyser les performances d‚Äôun test Expression de la puissance comme une fonction de $\\alpha$ $\\beta=f(\\alpha)$" }, { "title": "PRSTA: TD 4", "url": "/cours/posts/prsta_td4/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-27 14:30:00 +0200", "snippet": "Lien de la note HackmdFeuille 4 Exercice 2Partie ALa variable aleatoire $X$ suit une loi de densite:\\[f(x,\\theta)=\\theta x^{\\theta-1}1_{[0;1]}(x)\\]ou le parametre $\\theta$ est strictement positif.En d‚Äôautres termes, $f(x, \\theta) = 0$ si $x \\not\\in [0; 1]$ et $f(x, \\theta) = \\theta x^{\\theta‚àí1}$ si $x \\in [0; 1]$. Justifier que, pour tout $\\theta \\gt 0$, $f(., \\theta)$ definit bien une densite sur $\\mathbb R$. Calculer $E(X)$ Determiner l‚Äôestimateur du maximum de vraisemblance $\\hat\\theta$ du parametre $\\theta$. Considerons maintenant la variable aleatoire $Y := ‚àí \\ln X$. Pourquoi est-elle bien definie ? Montrer que la variable aleatoire $Y$ suit une loi $\\Gamma(1, \\theta)$. Solution 1. Comme $\\theta\\gt 0$ et $x\\in[0;1]$, $f(x,\\theta)$ est strictement positive.\\[\\begin{aligned}\\int_0^1f(x,\\theta)&amp;amp;=[x^{\\theta}]^1_0\\\\&amp;amp;= 1^{\\theta}-0 =1\\end{aligned}\\] On a donc bien une densite. 2.\\[\\begin{aligned}E(X)&amp;amp;=\\int_0^1xf(x,\\theta)1_{[0;1]}dx\\\\&amp;amp;= \\int_0^1\\theta x^{\\theta}dx\\\\&amp;amp;= \\biggr[\\frac{\\theta x^{\\theta+1}}{\\theta+1}\\biggr]\\\\&amp;amp;= \\frac{\\theta}{theta+1}\\gt0\\end{aligned}\\] 3. Considerons:\\[\\begin{aligned}L(x_1,\\dots,x_n,\\theta) &amp;amp;= \\prod_{i=1}^n\\theta x_i^{\\theta-1}1_{[0;1]}(x_i)\\\\&amp;amp;= \\theta^n\\prod_{i=1}^nx_i^{\\theta-1}\\prod_{i=1}^n1_{[0;1]}(x_i)\\end{aligned}\\] Pourquoi est-ce que les indicatrices ne posent pas de problemes ? Car nos observations sont entre $0$ et $1$ Pour determiner le maximum, nous pouvons nous restreindre au cas: $(x_1,\\dots,x_n)\\in[0;1]$ car les $x_i$ sont des observations. Passons au logarithme:\\[\\ln(L(x_1,\\dots,x_n,\\theta))=n\\ln(\\theta)+(\\theta-1)\\sum_{i=1}^nx_i\\] Calculons la derivee partielle:\\[\\frac{\\partial\\ln(x_1,\\dots,x_n,\\theta)}{\\partial\\theta}=\\frac{n}{\\theta}+\\sum_{i=1}^n\\ln(X_i)\\\\\\begin{aligned}\\frac{\\partial\\ln(x_1,\\dots,x_n)}{\\partial\\theta}&amp;amp;=0\\\\\\Leftrightarrow\\theta&amp;amp;=-\\frac{n}{\\sum_{i=1}^n\\ln(X_i)}\\end{aligned}\\] Verifions la conditions du second ordre:\\[\\frac{\\partial^2\\ln(L(x_1,\\dots,x_n,\\theta))}{\\partial\\theta^2}=-\\frac{n}{\\theta^2}\\lt 0\\quad \\forall \\theta\\gt 0\\] $\\hat\\theta$ est bien l‚ÄôEMV! 4. Question 1. Elle est bien definie car comme $X\\in[0;1]$, $\\ln(X)\\lt0$ donc $-\\ln(X)\\gt 0$ 2. Pourquoi on parle de loi $\\Gamma$ au lieu de loi exponentielle ? Car c‚Äôest facile d‚Äôadditionner les loi $\\Gamma$. \\[\\begin{aligned}y&amp;amp;=-\\ln x\\\\\\ln x&amp;amp;=-y\\\\x&amp;amp;=e^{-y}\\end{aligned}\\] On pose $\\phi(x)=-\\ln(x)$\\[\\phi&#39;(x)=-\\frac{1}{x}\\\\\\phi^{-1}(x)=e^{-x}\\\\\\begin{aligned}f_Y(y)&amp;amp;=\\color{red}{-}\\frac{1}{\\phi&#39;(\\phi^{-1}(y))}\\cdot f(\\phi^{-1}(y))\\quad\\phi&#39;(\\phi^{-1}(y))=\\color{red}{-}\\frac{1}{e^{-x}}\\\\&amp;amp;=e^{-y}\\cdot\\theta\\phi^{-1}(y)^{\\theta-1}\\\\&amp;amp;=e^{-y}\\cdot e^{-y(\\theta-1)}\\\\&amp;amp;=\\theta e^{-\\theta y}\\end{aligned}\\] Donc $Y\\rightsquigarrow \\xi(\\theta)=\\Gamma(1,\\theta)$ \\[\\boxed{\\phi_y(t)=\\frac{\\theta}{\\theta-it}}\\] car fonction caracteristique de la loi exponentielle Qu‚Äôest-ce qu‚Äôon a oublie dans notre formule ? La valeur absolue du Jacobien Partie BConsiderons $n$ variables aleatoires independantes $X_i$ suivant la loi de $X$. Nous souhaitons tester l‚Äôhypothese $H_0 : \\theta = \\theta_0$ contre $H_1 : \\theta = \\theta_1$ avec $\\theta_0 &amp;lt; \\theta_1$ a l‚Äôaide d‚Äôobservations $x_i$ issues de l‚Äôechantillon precedent. Nous noterons, dans la suite de l‚Äôexercice, $Y_i = ‚àí \\ln X_i$. Montrer que la statistique de Neyman-Pearson est: $T_n:=\\sum_{i=1}^nY_i$ Determiner la loi de la variable aleatoire $T_n$ puis celle de la variable aleatoire $U_n:=\\frac{T_n}{\\theta}$ Exprimer les risques de premiere et de seconde espece $\\alpha$ et $\\beta$ en fonction du seuil $S_{\\alpha}$, des parametres $\\theta_0$ et $\\theta_1$ et de la fonction de repartition de la variable aleatoire $U_n$. Solution 1.\\[\\begin{aligned}\\frac{L(X_1,\\dots,X_n\\theta_1)}{L(X_1,\\dots,X_n\\theta_0)}&amp;amp;=\\frac{\\prod_{i=1}^n\\theta_1x_i^{\\theta_1-1}}{\\prod_{i=1}^n\\theta_0x_i^{\\theta_0-1}}\\\\&amp;amp;= \\biggr(\\frac{\\theta_1}{\\theta_2}\\biggr)^n\\prod_{i=1}^nX_i^{\\theta_1-\\theta_0}\\end{aligned}\\] $(H_0)$ est rejetee si:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln(T_n)=n\\ln(\\frac{\\theta_1}{\\theta_0})+(\\theta_n-\\theta_0)\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\gt\\ln(C_{\\alpha})\\\\\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\gt\\underbrace{\\frac{\\ln(C_{\\alpha})-n\\ln(\\frac{\\theta_1}{\\theta_0})}{\\theta_n-\\theta_0}}_{S_{\\alpha}&#39;}\\\\-\\sum\\ln(X_i)&amp;amp;\\lt -S_{\\alpha}&#39;\\\\T_n=-\\sum_{i=1}^n\\ln(X_i)&amp;amp;\\lt S_{\\alpha}\\quad \\text{ou } S_{\\alpha}=-S_{\\alpha}&#39;\\end{aligned}\\] 2. Quel loi suit $T_n$ ? On sait que $X_i\\sim P(1,\\theta)$ Donc $\\phi_X(t)=\\frac{\\theta}{\\theta-it}$\\[T_n=\\sum_{i=1}^n Y_i\\] Donc\\[\\phi_{T_n}=(\\phi_{Y_i}(t))^n\\] car les $Y_i$ sont independants. \\[\\boxed{\\phi_{T_n}=\\biggr(\\frac{\\theta}{\\theta-it}\\biggr)^n}\\] Donc: $T_n\\sim\\Gamma(n, \\theta_0)$ sous $(H_0)$ $T_n\\sim\\Gamma(n, \\theta_1)$ sous $(H_1)$ On va calculer la densite de $U_n$\\[U_n=\\theta T_n\\\\\\phi:]0;+\\infty[\\to]0;+\\infty[\\] $\\phi$ est derivable et bijective:\\[\\phi^{-1}(x)=\\frac{x}{\\theta}\\quad\\text{et}\\quad\\phi&#39;(x)=\\theta\\\\\\begin{aligned}f_{U_n}(u)&amp;amp;=\\frac{1}{\\theta}\\times\\frac{1}{\\Gamma(n)}\\biggr(\\frac{u}{\\theta}\\biggr)^{\\alpha-1}\\theta^{\\alpha}e^{-\\theta\\frac{u}{\\theta}}\\end{aligned}\\] \\[f_{U_n}(u)=\\frac{1}{\\Gamma(n)}u^{\\alpha-1}e^{-u}\\] Donc la loi de $U_n$ ne depend pas de $\\theta$ 3. Notons $H_n$ la fonction de repartition de $U_n$.\\[\\begin{aligned}\\alpha&amp;amp;=P(\\text{Rejeter }H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(T_n\\lt S_{\\alpha}\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\theta_0 T_n\\le\\theta_0 S_{\\alpha}\\vert\\theta=\\theta_0)\\\\&amp;amp;= \\color{red}{P}(U_n\\lt\\theta_0 S_{\\alpha})\\quad\\color{red}{\\text{Sous } H_0}\\\\&amp;amp;= H_n(\\theta_0S_{\\alpha})\\end{aligned}\\\\S_{\\alpha}=\\frac{H_n^{-1}(\\alpha)}{\\theta_0}\\] \\[H_n(x)=\\int_0^x\\frac{1}{\\Gamma(n)}t^{\\alpha-1}e^{-t}dt\\] Si $x\\lt y$ alors:\\[H_n(y)-H_n(x)=\\int_x^y\\frac{1}{\\Gamma(n)}t^{\\alpha-1}e^{-t}dt\\gt0\\] Donc $(H_n)$ est strictement croissante sur $[0;+\\infty[$ Par consequence, elle est strictement croissante \\[\\begin{aligned}\\beta &amp;amp;= P(\\text{Rejeter } H_1\\vert H_0\\text{fausse})\\\\&amp;amp;= P(T_n\\ge S_{\\alpha}\\vert \\theta=\\theta_1)\\\\&amp;amp;= P(\\underbrace{\\theta_1 T_n}_{\\color{green}{U_n}}\\ge S_{\\alpha}\\theta_1\\vert \\theta=\\theta_1)\\\\&amp;amp;= 1-H_n(\\theta_1S_{\\alpha})\\end{aligned}\\] \\[\\boxed{\\beta=1-H_n\\biggr(\\frac{\\theta_1}{\\theta_0}H_n^{-1}(\\color{green}{\\alpha})\\biggr)}\\] " }, { "title": "OCVX2 : Tout ce que vous avez toujours voulu savoir sur les SVMS", "url": "/cours/posts/ocvx2_svm/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-27 11:00:00 +0200", "snippet": "Lien de la note HackmdOn a un probleme de classification binaire: Probleme: donnees d‚Äôapprentissage\\[\\{(x_i,y_i)\\}_{i=1}^n\\quad x_i\\in\\mathbb R^p\\quad y_i\\in\\{-1,+1\\}\\] On cherche un hyperplan de $\\mathbb R^p$ qui separe parfaitement les deux classesDans notre exemple, il n‚Äôy a pas qu‚Äôun seul hyperplan separant les 2 classes:Hyperplan Hyperplan: caracterise par un vecteur normal $w\\in\\mathbb R^p$ et un offset $b\\in\\mathbb R$\\[x\\in H\\Leftrightarrow w^Tx+b=0\\]Lequel des hyperplans semble meilleur ? Celui du milieuOn a une infinite de solutions possibles (meme risque empirique), mais toutes les solutions n‚Äôont pas les memes performances en generalisation Geometriquement, on veut celui qui est le plus loin des points (aka la marge de l‚Äôhyperplan)On cherche $(w,b)\\in\\mathbb R^p\\times\\mathbb R$ tel que tous les echantillons de la classe $-1/+1$ soient dans le demi espace: positif: $w^Tx_i+b\\ge0$ $y_i=+1$ negatif: $w^Tx_i+b\\le0$ $y_i=-1$ Dans tous les cas:\\[\\boxed{\\forall x_i\\in\\mathbb R^p, y_i(w^Tx_i+b)\\ge 0}\\]Marge Marge: distance de l‚Äôhyperplan aux echantillons les plus proches \\(\\begin{aligned}M_H=\\min_{i=1,\\dots,n}\\{d(x_i,H)\\} &amp;amp;= \\min_{i=1,\\dots,n}\\{d(x_i,x),x\\in\\mathbb R^n,w^Tx+b=0\\}\\\\&amp;amp;= d(x_s,H)\\quad\\text{avec } x_s \\text{ vecteur de support}\\end{aligned}\\) On va chercher l‚Äôhyperplan qui maximise la marge\\[H^*=\\text{arg}\\max_{(w,b)\\in\\mathbb R^p\\times\\mathbb R}M_H=d(x_s,H)\\]Distance d‚Äôun point $x_0$ a un hyperplan:\\[d(x_0,H)=\\Vert y-x_0\\Vert\\]\\[(L)=\\{x_0+tw,t\\in\\mathbb R\\}\\]\\[y\\in(L),\\exists t\\in\\mathbb R, y=x_0+tw\\\\\\begin{aligned}&amp;amp;y\\in(H)w^Ty+b=0\\\\&amp;amp;w^T(x_0+tw)+b=0\\\\&amp;amp;w^Tx_0+\\underbrace{tw^Tw}_{\\Vert w\\Vert^2}+b=0\\\\\\end{aligned}\\\\t=-\\frac{1}{\\Vert w\\vert^2}(w^Tx_0+b)\\]\\[\\begin{aligned}d(x_0,H)=\\Vert y-x_0\\Vert&amp;amp;=\\Vert x_0+tw-x_0\\Vert\\\\&amp;amp;=\\Vert tw\\Vert\\\\&amp;amp;=\\vert t\\vert\\cdot\\Vert w\\Vert\\\\&amp;amp;=\\biggr\\vert-\\frac{1}{\\Vert w\\Vert^2}(w^Tx_0+b)\\biggr\\vert\\times\\Vert w\\Vert\\end{aligned}\\\\\\boxed{d(x_0, H)=\\frac{\\vert w^Tx_0+b}{\\Vert w\\Vert}}\\]\\[\\begin{aligned}M_H&amp;amp;=\\min_i\\{d(x_i,H)\\}\\\\&amp;amp;=\\min_i\\biggr\\{\\frac{\\vert w^Tx_i+b\\vert}{\\Vert w\\Vert}\\biggr\\}\\\\&amp;amp;= \\frac{1}{\\Vert w\\Vert}\\min_i\\{\\vert w^Tx_i+b\\vert\\}\\\\&amp;amp;= \\frac{\\vert w^Tx_s+b\\vert}{\\Vert w\\Vert}\\quad x_s\\text{ vecteur de support}\\end{aligned}\\]On cherche\\[\\text{arg}\\max_{(w,b)}M_H=\\text{arg}\\max_{(w,b)}\\frac{\\vert w^T x_s+b\\vert}{\\Vert w\\Vert}\\] Si $(w,b)$ est une solution, $(kw,kb)$ $k\\gt0$ est aussi solution.On va choisir $(w,b)$ tels que $\\vert w^T x_s+b\\vert =1$Marge normalisee: $\\frac{1}{\\Vert w\\Vert}$SVMOn cherche a:\\[\\begin{aligned}\\text{maximiser}&amp;amp;\\frac{1}{\\Vert w\\Vert}\\\\\\text{maximiser}&amp;amp;\\frac{2}{\\Vert w\\Vert}\\\\\\text{minimiser}&amp;amp;\\frac{1}{2}\\Vert w\\Vert^2\\\\\\end{aligned}\\] SVM:\\[\\boxed{\\text{arg}\\min_{(w,b)\\in\\mathbb R^d\\times\\mathbb R}\\frac{1}{2}\\Vert w\\Vert^2\\\\\\begin{aligned}\\text{tel que } &amp;amp;y_i(w^Tx_i+b)\\ge1\\\\&amp;amp;\\forall i=1,\\dots,n\\end{aligned}}\\]\\[\\frac{1}{2}\\Vert w\\Vert^2=\\frac{1}{2}w^Tw\\\\y_i(w^Tx_i+b)\\ge1\\Leftrightarrow 1 - y_i(w^Tx_i+b)\\le 0\\quad\\forall i\\] Le Lagrangien de (SVM) est:\\[\\begin{aligned}\\mathscr L(w,b,\\lambda)&amp;amp;=\\frac{1}{2}w^Tw+\\sum_{i=1}^n\\lambda_i(1-y_i(w^Tx_i+b))\\quad w\\in\\mathbb R^p, b\\in\\mathbb R,\\lambda\\in\\mathbb R^n\\\\&amp;amp;=\\frac{1}{2}w^Tw-\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)\\end{aligned}\\]Conditions KKTStationnarite du Lagrangien\\[\\begin{aligned}\\nabla_w\\mathscr L(w,b,\\lambda)&amp;amp;=0 \\\\ &amp;amp;=\\underbrace{\\frac{\\partial}{\\partial w} (\\frac{1}{2}w^Tw)}_{w} - \\sum_{i=1}^n\\frac{\\partial}{\\partial w}(\\lambda_i\\underbrace{(y_i(w^T}_{\\lambda_i y_i x_i}x_i+b)-1))\\\\0&amp;amp;= w-\\sum_{i=1}^n\\lambda_iy_ix_i\\\\w&amp;amp;=\\sum_{i=1}^n\\lambda_iy_ix_i\\quad w \\text{ est une combinaison lineaire des } x_i\\end{aligned}\\\\\\nabla_b\\mathscr L(w,b,\\lambda)=\\boxed{0=\\sum_{i=1}^n\\lambda_iy_i}\\]A chaque $x_i$ correspond un $\\lambda_i$ $\\lambda_i\\ge 0\\to\\lambda_i$ est la ‚Äúforce‚Äù avec laquelle $x_i$ repousse l‚Äôhyperplan $\\sum_{i=1}^n\\lambda_iy_i=0\\to$ l‚Äôhyperplan est a l‚ÄôequilibreComplementarite\\[\\forall i=1,\\dots,n\\quad\\lambda_i(1-y_i(w^Tx_i+b))=0\\quad(\\alpha_i^*g_i(x^*)=0\\quad\\forall i)\\]Soit $\\lambda_i=0$:\\[1-y_i(w^Tx_i+b)\\lt 0\\Leftrightarrow y_i(\\underbrace{w^Tx_i+b}_{x_i \\text{ n&#39;est pas} \\\\ \\text{un vecteur}\\\\ \\text{de support}})\\gt 1\\\\\\lambda_i=0\\begin{cases}x_i\\text{ ne repousse pas l&#39;hyperbole}\\\\\\text{ne contribue pas a la solution } w=\\sum_{i=1}^n\\lambda_iy_ix_i\\\\\\text{la solution ne change pas si on enleve } x_i\\text{ du jeu de donnees}\\end{cases}\\]Soit $\\lambda_i\\gt 0$:\\[1-y_i(w^Tx_i+b)=0\\Leftrightarrow y_i(\\underbrace{w^Tx_i+b}_{x_i \\text{ est un vecteur} \\\\ \\text{de support}})=1\\\\\\lambda_i\\gt 0\\begin{cases}\\text{la solution change si on enleve } x_i \\text{ du jeu de donnees}\\end{cases}\\]Recap\\[w=\\sum_{i=1}^n\\lambda_iy_ix_i\\\\o=\\sum_{i=1}^n\\lambda_iy_i\\\\\\mathscr L(w,b,\\lambda)=\\frac{1}{2}w^Tw-\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)\\\\\\begin{aligned}w^Tw&amp;amp;= (\\sum_{i=1}^n\\lambda_iy_ix_i)^T(\\sum_{j=1}^n\\lambda_jy_jx_j)\\\\&amp;amp;= \\sum_{i=1}^n\\lambda_iy_i(x_i)^T\\sum_{j=1}^n\\lambda_jy_jx_j\\\\&amp;amp;= \\sum_i\\sum_j\\lambda_i\\lambda_jy_iy_jx_i^Tx_j\\end{aligned}\\]\\[\\begin{aligned}\\sum_{i=1}^n\\lambda_i(y_i(w^Tx_i+b)-1)=\\sum_{i=1}^n\\underbrace{\\lambda_iy_iw^Tx_i}&amp;amp;+\\underbrace{b\\sum_{i=1}^n\\lambda_iy_i}-\\sum_{i=1}^n\\lambda_i\\\\\\sum_{i}\\lambda_iy_i(\\sum_{j=1}^n\\lambda_jy_jx_j)^Tx_i&amp;amp;=\\sum_i\\sum_j\\lambda_i\\lambda_jy_iy_jx_i^Tx_j\\end{aligned}\\] Probleme dual du SVM\\[\\boxed{\\max_{\\lambda_i\\ge 0 \\\\ \\sum_{i=1}^n\\lambda_iy_i}\\mathscr L=-\\frac{1}{2}\\sum_{i=1}^n\\sum_{j=1}^n\\lambda_i\\lambda_jy_iy_jx_i^Tx_j+\\sum_{i=1}^n\\lambda_i}\\]Sous reserve qu‚Äôon puisse resoudre le dual: On trouve $\\lambda_i^{*}$ On trouve $w^{*}=\\sum_{i=1}^n\\lambda_i^{*}y_ix_i$ On trouve $b^{*}$ grace aux vecteurs de support $y_i(w^{*t}x_i+b^{*})=1$ Probleme dual du SVM se resout par Sequential Minimal OptimizationPour resoudre" }, { "title": "OCVX2 : Tout ce que vous avez toujours voulu savoir sur l&#39;ACP (ou pas)", "url": "/cours/posts/ocvx2_acp/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-27 10:00:00 +0200", "snippet": "Lien de la note HackmdOn a un nuage de points:On une infinite de directions possibles. On projette sur les axes: On cherche un vecteur $\\vec u$ tel que l‚Äôerreur de projection des ${x_i}$ sur l‚Äôespace engendre par notre vecteur $\\text{span}(u)$ soit minimale.En formulation mathematiques:\\[\\text{proj}(x_i,\\text{span}(u))=P_u(x_i)=\\langle x_i,u\\rangle = x_i^Tu\\] En l‚Äôetat: une infinite de solutions (si $u$ solutions, $ku$ solutions avec $k\\in\\mathbb R^{*}$)On impose $\\Vert u\\Vert=1$\\[P_u(x_i)=\\langle x_i,u\\rangle=x_i^Tu\\to E(x_i,\\underbrace{P_u(x_i)}_{y_i}) = \\Vert x_i-y_i\\Vert^{(2)}\\] On cherche donc:\\[\\text{arg}\\min_{u,\\Vert u\\Vert=1}\\sum_{i=1}^n E(x_i,P_u(x_i))\\]D‚Äôapres Pythagore:\\[\\Vert x_i\\Vert^2=\\Vert y_i\\Vert^2+\\Vert x_i-y_i\\Vert\\\\\\Vert x_i-y_i\\Vert^2=\\Vert x_i\\Vert^2-\\Vert y_i\\Vert^2\\]On peut donc reecrire:\\[\\begin{aligned}\\sum_{i=1}^nE(x_i,P_u(x_i))&amp;amp;=\\sum_{i=1}^n\\Vert x_i-y_i\\Vert^2\\\\&amp;amp;=\\underbrace{\\sum_{i=1}^n\\Vert x_i\\Vert^2}_{\\text{constante}} - \\sum_{i=1}^n\\Vert y_i\\Vert^2\\end{aligned}\\]Donc:\\[\\begin{aligned}\\text{arg}\\min_{u,\\Vert u\\Vert=1}&amp;amp;=\\text{arg}\\min_{u,\\Vert u\\Vert=1}-\\sum_{i=1}^n\\Vert y\\Vert^2\\\\&amp;amp;=\\text{arg}\\max_{u,\\Vert u\\Vert=1}\\sum_{i=1}^n\\Vert y_i\\Vert^2\\\\&amp;amp;=\\text{arg}\\max_{u,\\Vert u\\Vert=1}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n\\Vert y\\Vert^2}\\\\&amp;amp;\\Vert y_i\\Vert^2=y_i^Ty_i\\underbrace{\\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i}_{\\text{var}(P_u(X))}\\end{aligned}\\]On est en train de chercher:\\[\\begin{aligned}\\text{arg}\\min_{u,\\Vert u\\Vert=1}-\\sum_{i=1}^n\\Vert y_i\\Vert^2&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i\\\\&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^n(x_i^Tu)^T(x_i^Tu)\\\\&amp;amp;= -\\frac{1}{n}\\sum_{i=1}^nu^Tx_ix_i^Tu\\\\&amp;amp;= -u^T(\\underbrace{\\frac{1}{n}\\sum_{i=1}^nx_ix_i^T}_{\\Sigma\\text{ matrice de covariance} \\\\ \\text{de } X=\\{x_i\\}^n_{i=1}\\text{ centre}})u\\end{aligned}\\] On cherche: \\(\\boxed{\\text{arg}\\min_{u\\in\\mathbb R^p \\\\ \\Vert u\\Vert =1}-u^T\\underbrace{\\Sigma}_{\\text{matrice de} \\\\ \\text{covariance}}u}\\)\\[\\text{arg}\\max_{\\Vert u\\Vert=1}u^T\\Sigma u = \\text{arg}\\max\\overbrace{\\frac{u^T\\Sigma u}{u^Tu}}^{\\text{Quotien de Rayleigh}}\\]On va reecrire:\\[\\text{arg}\\min_{u\\in\\mathbb R^p}-u^T\\Sigma u\\\\\\begin{aligned}\\Vert u\\Vert =1\\Leftrightarrow &amp;amp;\\Vert u\\Vert^2=1\\\\&amp;amp;\\begin{cases}u^Tu=1 &amp;amp;f(u)-u^T\\Sigma u\\\\u^Tu-1=0&amp;amp;g(u)=u^Tu-1\\end{cases}\\biggr\\}\\text{arg}\\min_{g(u)=0} f(u)\\end{aligned}\\]Le lagrangien de ce probleme est $\\mathscr L(u\\lambda)=f(u)+\\lambda g(u)-u^T\\Sigma u+\\lambda(u^Tu-1)$ Stationnarite de $\\mathscr L:\\nabla_u\\mathscr L(u,\\lambda)=0=\\nabla_u(-u^T\\Sigma u)+\\lambda\\nabla_u(u^Tu-1)$ Rappel: $f(x)=x^TAx$On calcule la differentielle $f(x+h)=f(x)+df_x(h)+O(h)$\\[\\begin{aligned}f(x+h)=(x+h)^TA(x+h)=\\underbrace{x^TAx}_{f(x)}+x^T\\underbrace{AH+h^T}&amp;amp;Ax+\\underbrace{h^TAh}_{O(h)}\\\\x^TAh+(\\underbrace{h^TAx})^T&amp;amp;\\\\\\underbrace{x^TA^Th}&amp;amp;\\\\x^T(A+A^T)h&amp;amp;\\to df_x(h)=x^T(A+A^T)h\\\\(=2x^TAh\\text{ si } &amp;amp;A \\text{ symetrique } A=A^T)\\end{aligned}\\\\\\]\\[df_x(h)=\\langle\\nabla_xf,h\\rangle=\\nabla_xf^Th\\to\\nabla_xf=(A+A^T)x=2Ax\\\\\\begin{aligned}\\nabla_u(-u^T\\Sigma u)=-\\nabla_u(u^T\\Sigma u)=-2\\Sigma u\\\\\\nabla_u(u^Tu)=\\nabla_u(u^TI_du)=2u\\end{aligned}\\biggr\\}-2\\Sigma u+2du=0\\]\\[\\color{red}{\\boxed{\\Sigma u=\\lambda\\mu}}\\] $u$ est un vecteur propre de $\\Sigma$$\\lambda$ est sa vlaeur propreOn se souvient qu‚Äôon cehrche $u$, $\\Vert u\\Vert=1$ qui maximise:\\[\\begin{aligned}\\underbrace{\\frac{1}{n}\\sum_{i=1}^n\\Vert y_i\\Vert^2}_{\\text{var}(P_u(x))}&amp;amp;= \\frac{1}{n}\\sum_{i=1}^ny_i^Ty_i\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n(x_i^Tu)(x_i^Tu)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nu^Tx_ix_i^Tu\\\\&amp;amp;=u^T(\\frac{1}{n}\\sum_{i=1}^nx_ix_i^T)u\\\\&amp;amp;=u^T\\underbrace{\\Sigma u}_{\\lambda u}\\\\&amp;amp;=\\lambda \\underbrace{u^Tu}_{\\Vert u\\Vert^2 =1}\\\\&amp;amp;=\\lambda\\end{aligned}\\]" }, { "title": "EPIQUANTI : Types de Qubits", "url": "/cours/posts/epiquanti_type_qubit/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-26 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursQuantum anneleaing\\[\\mathcal H_p =\\sum_{i=0}^Nh_i\\sigma_i^Z+\\sum_{i,j=0}^NJ_{ij}\\sigma_i^Z\\sigma_j^Z\\]JargonD WaveSuper conducting quantum annealing15 ans d‚Äôavance sur la creation de ses machines Spin up qubit $\\vert\\uparrow\\rangle$ Spin up qubit $\\vert\\downarrow\\rangle$ Quantum annealing and ising model\\[\\mathcal H_p =\\sum_{i=0}^Nh_i\\sigma_i^Z+\\sum_{i\\lt j}^NJ_{ij}\\sigma_i^Z\\sigma_j^Z\\] $\\mathcal H_p$: system hamiltonian $h_i$: energy difference between 2 states of qubits i $v_i$: vertices containing qubit i $J_{ij}$: coupling between vertices $v_i$ et $v_j$ with close i and j $E$: edge, connecting qubitsComputing processStarts with converting the probleme into a Ising model or QUBO (Quadratic Unconstrained Binary Optimization) Initialization of qubits states to $\\vert\\uparrow\\rangle$ or $\\vert\\downarrow\\rangle$ Setting qubits bias levels $h_i$ Slowly growing $J_{ij}$ coupling System converging to minimal $\\mathcal H_p$ Readout $\\vert\\uparrow\\rangle$ or $\\vert\\downarrow\\rangle$ states for all qubits, giving the solution to the problem of finding the energy minimum for $H_p$ Le chimera est la facon dont les qubits sont relies entre eux physiquement dans le processeurAlgorithmsPegasus / Advantage 2020 generation5436 qubitsEach qubits is connected to 15 neighbour qubits through 37440 couplers, from 6 per qubit in previous generations.Qubits are operating at 15,8 mK One order of magnitude improvement in time spent solving problems vs D-Wave 2000Q launched in 2017Pourquoi c‚Äôest plus dur de rajouter de nouveaux qubits ? C‚Äôest plus dur a intriquerSuperconducting qubitsQubits operating temperatures rationalePourquoi est-ce qu‚Äôon doit les refroidir ces qubits ? On veut eviter la decoherence des qubits mais pas queLes micro-ondes qu‚Äôon envoie sur les qubits sont conditionnees par le niveau d‚ÄôenergieOn refroidit pour que le bruit ambiant soit inferieur a la puissance des micro-ondes5 Superconducting qubits lab configuraitonIBMRoadmapGoogleGoogle‚Äôs 1 million physical qubits plan C‚Äôest quoi la consommation energetique ? - TheotimeAlice &amp;amp; Bob French startup created by Th√©au Peronnin and Rapha√´lLescanne, from ENS with the help from Benjamin Huard (ENS Lyon), ZakiLeghtas (ENS Paris), Mazyar Mirrahmi (Inria), PhilippeCampagne-Ibarcq (Inria) and Emmanuel Flurin (CEA) use cat-qubits based on two photons coupling in a cavity to increase reliability of superconducting qubits qubit information comes from measuring cavity photon number parity without measuring photon number expect to build a logical superconducting qubit with only 30 cat-qubits instead of 10 000 classical superconducting qubits significantly reduce the burden to create a LSQ FTQC (large scale quantum / fault tolerant quantum computer) plan to produce a first processor with logical qubits by 2023Amazon Amazon announced in december 2020 it will build its own quantum computers using cat-qubits superconducting, in a 118 pages theoretical paper it plans to use surface codes QECit‚Äôs partnering with Caltech (incl John Preskill), Yale (Devoret/Schoelkopf teams)and other universitiesSummaryElectron spins qubitsDifferent electron spins qubit platformsHow to detect a single charge?How to manipulate a single spin?How to realize a two-qubit gate?State of the art of two qubit gatesplanar systems with a huge number of electrodes to: define the reservoirs - source and drain control the height of the barrier between quantum dots define the depth of the quantum well manipulate the qubits read out the qubitsToward a scalable platformC12 Quantum Electronic french startup created by Matthieu and Pierre Desjardins with the help from Taki Kontos (LPENS) electron spins qubits trapped in carbon nanotubes 5 qubits demonstrator planned for 2021/2022SummaryNV centers qubitsNV centers implementation and controlsQuantum brillance Australian startup ambiant temperature qubits 5 NV centers qubits demonstrated in 2021 they plan to scale &amp;gt; 50 qubits in 2022 fits on a desktop computer form factor qubits NV centersTopologic qubitsThe topological qubit bitChez microsoft: better stability qubits low decoherence noise few errors long coherence time high gate speed nothing demonstrated so far no prototype different algorithms Majorana fermions summaryTrapped ions qubitsIonQ La boite la plus calee et ayant recu le plus de fonds: $$82$M en 2015 Maryland and Duke Universities spin-off launched by Christopher Monroe $\\color{green}{\\text{pros}}$ $\\color{red}{\\text{cons}}$ laser controlled gates slow gates $32$ qubits with a large quantum volume of $2^{22}$ reached in 2020 not easy to scale, planning to network several tiny units (above) long coherence time and good qubits fidelity ¬† excellent qubit connectivity thanks to phonons ¬† available on Microsoft and Amazon cloud services ¬† IPO planned in 2021Honeywell 2D trapped ions announced in march 2020 4 qubits in march 2020 6 qubits in june 2020 10 qubits in septembre 2020 Better scalability projectTrapped ions qubits summaryCold atoms qubitsCold atoms and Rydberg states Etat de Rydberg: etat tres energisantCold atoms qubits summaryPhoton qubitsPhotons qubits types and toolsQubitsInstrumentationQuantum dot photon sourceQuantum dot photon sourceDV and CV photon qubitsPhotons qubits summary" }, { "title": "TVID: 2D Motion Estimation", "url": "/cours/posts/tvid_motion_estimation/", "categories": "Image S9, TVID", "tags": "Image, S9, TVID", "date": "2021-10-25 10:00:00 +0200", "snippet": "Lien de la note HackmdScalable video recording Scalability referes to the capacity of recovering physically meaningful image or video information from deconding only partial compressed bitstreams Quality scalability: finer to finer quantizations Spatial scalability: different spatial resolutions (Laplacian, Pyramid, ‚Ä¶) Temporal scalability: we can jump frames and add the missing ones progressively Frequency scalability: lower frequencies to higher frequencies Combination of basic schemes Granularity: coarse vs fine ones Object-based scalability: different resolutions for different objects2D motion vs optical flowOn a une sphere en train de tourner sans illumination: dans le flux video, il n‚Äôy a pas de difference.Prenons ensuite une sphere dont la source lumineuse bouge: l‚Äôinformation visuelle changera. The observed of apparent 2D motion is called optical flowOptical flow equation and ambiguity in motion estimation Imaginons une sequence video $\\psi(x,y,t)$ On image un point $(x,y)$ deplace en $(x+d_x,y+d_y)$ au temps $t+d_t$ Under the constant intensity assumption, the images of the same object point at different times have the same luminance value \\(\\psi(x+d_x,y+d_y,t+d_t)=\\psi(x,y,t)\\)On fait un developpement de Taylor:\\[\\psi(x+d_x,y+d_y,t+d_t)=\\psi(x,y,t)+\\frac{\\partial\\psi}{\\partial x}d_x+\\frac{\\partial\\psi}{\\partial y}d_y+\\frac{\\partial\\psi}{\\partial t}d_t\\]On obtient:\\[\\frac{\\partial\\psi}{\\partial x}d_x+\\frac{\\partial\\psi}{\\partial y}d_y+\\frac{\\partial\\psi}{\\partial t}d_t = 0\\]Definisson $v_x=\\frac{d_x}{d_t}$, $v_y=\\frac{d_y}{d_t}$, $v_t=\\frac{d_xt}{d_t}=1$\\[\\frac{\\partial\\psi}{\\partial x}v_x+\\frac{\\partial\\psi}{\\partial y}v_y+\\frac{\\partial\\psi}{\\partial t} = 0\\]Qui peut etre ecrit:\\[\\nabla\\psi^Tv+\\frac{\\partial\\psi}{\\partial t}=0\\]Avec $\\psi^T$ le gradient spatialThe flow vector $v$ at any point $x$ can be decomposed into 2 orthogonal components:\\[v=v_ne_n+v_te_t\\] As we can observe, when a straight edge moves in the plane, we can only detect the normal $v_n$ of its motion vector !Because $\\nabla\\psi=\\Vert\\nabla\\psi\\Vert e_n$ the optical flow equation can be rewritten as:\\[v_n\\Vert\\nabla\\psi\\Vert+\\frac{\\partial\\psi}{\\partial t}=0\\]Avec $\\Vert\\nabla\\psi\\Vert$ la magnitude du vecteur gradient.Les consequences de ces equations sont: A chaque pixel $x$ We can compute\\[v_n=-\\frac{\\frac{\\partial\\psi}{\\partial t}}{\\Vert\\nabla\\psi\\Vert}\\] This ambuigity in estimationg the motion vector is known as the aperture problem The motion can be estimated uniquely only if the aperture contains at least 2 different gradient directionsGeneral methodologies We consider the ME between 2 given frames, $\\psi(x,y,t_1)$ and $\\psi(x,y,t_2)$ The problem is referred as to as forward motion estimationNotationComment encoder les vecteurs de mouvements ?Ils ne sont pas les memes en fonction de l‚Äôespace, il faut les encoder de facon parametrique. Fonction mapping: nouvelle position\\[w(x,a)=x+d(x,a)\\]Avec le parametre $a$ qui encode le mouvement, ca nous donne la nouvelle position.\\[a=[a_1,a_2,\\dots,a_n]^T\\]Motion representationDifferent representations de mouvement.Image b: pixel-based On a un vecteur pour chaque pixel de l‚ÄôimageImage c: on va la faire en TP On suppose qu‚Äôon fait un decoupage par bloc On fait un vecteur de mouvement par blocPour le champ de vecteur, comment est-ce qu‚Äôon parametrise ? TranslationsPolynomial motionsRotations‚Ä¶ On estime que l‚Äôimage est faite de pixel et on fait de la pixel-wise Ca fait 2 millions d‚Äôinconnues a trouverOn rajoute de la regularite. En general, on decoupe en regions.On estime d‚Äôabord le mouvement ou une region ?Approche par blocsOn decompose l‚Äôimage en blocs (ex: pour une image $100\\times100$, en $33\\times 33$) On a des blocs qui vont se superposer car le mouvement n‚Äôest pas uniforme Et on s‚Äôen fout !On a egalement des coins qui ont bouges. Il faut faire de la descente de gradient Les version les plus simples qu‚Äôon peut imaginer c‚Äôest en terme de translation Les blocs sont un bon compromis entre la precision et la complexite It can induce warping effectsMotion esimation criteria Displaced Frame Difference (DFD):\\[E_{DFD}(a)=\\sum_{x\\in\\Lambda}\\vert\\psi_2(w(x,a))-\\psi_1(x)\\vert^p\\] where $\\Lambda$ is the domain of all pixels in $\\psi_1$ and $p$ a positive number When $p=1$, the above error is called mean absolute difference (MAD) and when $p=2$ Mean Squared Error (MSE) The error image $e(x,a)=\\psi_2(w(x,a))-\\psi_1(x)$ is usually called displaced frame difference (DFD) image When $a$ is optimal ($p=2$)\\[\\frac{\\partial E_{DFD}}{\\partial a}=2\\sum_{x\\in\\Lambda}(\\psi_2(w(x,a))-\\psi_1(x))\\frac{d(w(x,a))}{da}\\nabla\\psi_2(w(x,a))=0\\]Prenons un cas plus simple\\[\\frac{\\partial\\psi}{\\partial t}d_t=\\psi_2(x)-\\psi_1(x)\\]It is equivalent to minimize:\\[E_{flow}=\\sum_{x\\in\\Lambda}\\vert\\nabla\\psi_1(x)^Td(x,a)+\\psi_2(x)-\\psi_1(x)\\vert^p\\]This solution verifies when $p=2$\\[\\frac{\\partial E_{flow}}{\\partial a}=2\\sum_{x\\in\\Lambda}(\\nabla\\psi_1(x)^Td(x,a)+\\psi_2(x)-\\psi_1(x))\\frac{\\partial d(x,a)}{da}\\nabla\\psi_i(x)\\]We can add a penalty term in our equation to enforce the smoothness of our vector field (i.e. must vary smoothly)\\[E_s=\\sum_{x\\in\\Lambda}\\sum_{y\\in N_x}\\Vert d(x,a)-d(y,a)\\Vert^2\\]We want to minimize:\\[E_{total}=E_{DFD}+w_sE_s\\]with $w$ the weighting coefficient. We have to regularize but not too much (to avoid over-blurring)Minimzation methodsOn va surtout regarder la methode exhaustive La methode de gradient La methode de Newton-Raphson Avec la descente de gradient et le probleme de dimensionnalite, on tombe souvent sur des minimums locaux et non globaux One important search strategy is to use a multi-resolution representation of the motion field and conduct the search in a hierarchical manner The basic idea is to first search the motion parameters in a coarse resolution, propagate this solution into a finer resolution, and then refine the solution in the finer resolution It can combat the slowness of exhaustive search methodsRegularization\\[E=\\sum_{x\\in\\Lambda}(\\frac{\\partial\\psi}{\\partial x}v_x+\\frac{\\partial\\psi}{\\partial y}+\\frac{\\partial\\psi}{\\partial t})^2 + w_s(\\Vert\\nabla v_x\\Vert^2+ \\Vert\\nabla v_y\\Vert^2)\\]Block matching algorithm (BMA) Les blocs peuvent etre de forme polygonale On prend en pratique des carres On suppose qu‚Äôon fait de la translationThe Exhaustive Search Block Matching Algorithm (EBMA)Under the block-wise translation model\\[w(x;a) = x+d_{m}\\quad x\\in B_m\\]Then the error can be written:\\[E(d_m,\\forall m\\in\\mathcal M)=\\sum_{m\\in\\mathcal M}\\sum_{x\\in B_m}\\vert\\psi_2 (x+d_m)-\\psi_1(x)\\vert^p\\]We can estimate the MV for each block individually\\[E_m(d_m)=\\sum_{x\\in B_m}\\vert\\psi_2 (x+d_m)-\\psi_1(x)\\vert^p\\]Deformable block matching algorithm\\[d_m(x)=\\sum_{k=1}^K\\Phi_{m,k}(x)d_{m,k}\\quad x\\in B_m\\]Le deplacement au bloc $m$ de $x$ est une somme ponderee des deplacements en 4 coinsNode-based motion representation Nodal MVs vs Polynomial coefficients Nodal Stabilite Motion estimation using node-based model\\[a=[d_k;k\\in\\mathcal K]\\]\\[E(a)=\\sum_{x\\in B}(\\psi_2(w(x,a))-\\psi_1(x))^2\\]where:\\[w(x,a)=x+\\sum_{k\\in\\mathcal K}\\phi_k(x)d_k\\]Mesh-based motion estimation Dans le cas des blocs: estime independants et deformes Mesh: maillage sur l‚Äôimage et on se permet de les deplacer en meme temps Tout est corrole Contrainte a connaitre: on ne veut pas que nos 2 carres s‚Äôinversent On a souvent des discontinuetes au niveau des edges Plus on augmente le nombre de noeuds, plus on a une estimation precise Mais la puissance de calcul explose Global motion estimationPlusieurs methodes existentEst-ce qu‚Äôon est dans le cadre ou pas d‚Äôavoir uniquement la camera qui bouge ? Au foot et tennis, une grande partie du decor est stableRegion-based motion estimationEst-ce qu‚Äôon separe en region ou on estime le mouvement ?3 approches possiblesMulti-resolution motion estimation Various ME approaches can be reduced to solving an error minimization problem Major difficulties Many local minima in the gradient-descent case Not easy to reach the global minimum Computation high Pyramide laplacienne: on decompose l‚Äôimage en bandes de frequence" }, { "title": "IMED2: X-Ray Imaging", "url": "/cours/posts/imed2_x_ray/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-20 09:00:00 +0200", "snippet": "Basic conceptsExponential BehaviorExponential Decay/Growth:\\[\\frac{\\delta N}{\\delta t} = \\pm\\lambda\\]X-Ray ProductionCoolidge Tube High-voltage Generator for heating ($U_h$) and cathode/anode ($U_a$) Filaments is heated and gives off electrons Electrons are accelerated from cathode to anode Electrons collide with the anode material and accelerate other electrons About $1\\%$ of the energy generated is emitted as X-Rays Tourner l‚Äôanode genere de la chaleurInteraction with Anode MaterialBremsstrahlungComplex model depending on: Path of electron in the target Change in direction at each interaction Change of ionization and radiation loss Direction of emission of the bremsstrahlung Attenuation and scattering inside the targetThin to thick target emission model:\\[I(E)=\\underbrace{C}_{\\text{constant}}\\cdot \\underbrace{Z}_{\\text{atomic number}}\\cdot (\\underbrace{E_{max}}_{\\text{energy of the} \\\\ \\text{bombarding} \\\\ \\text{electron}}-E)\\]Emitted SpectraPour un tungstene:X-Ray Interaction with MatterX-Ray photon life span: Photon is transmitted through the matter Photon is absorbed (end of life) Photon is scattered ($E_{new}\\le E$)If $E_{new}\\gt0$, then more 1, 2 or 3Photoelectric AbsorptionInteraction with an electron of the K, L, M, ‚Ä¶ atomic shell All energy is absorbed Ejects an photoelectron¬†¬ª ionizing radiation Vacancy is filled from a electron of a higher shell Produces either characteristic radiation (fluroescence) or an ‚ÄúAuger electron‚ÄùProbability of occurrence (or cross-section):\\[\\sigma_{photon}\\propto \\frac{Z^3}{E\\text{^}3}\\]Compton (Incoherent Scatter)Interaction with free electrons (outer shell): Part of photon energy is transferred to the electron (ionization) Photon is deflected with a certain angle and new energy $E_{new}\\lt E$ Energy loss depends on the scattering angle (energy conservation law) Scatter angle ($\\theta$) decreases with photon energy ($E$)Probability of occurenece (or cross-section) Almost independant of $Z$ &amp;amp; decreases with $E$ Energy conservation\\[\\frac{E}{E_{new}}=\\frac{E}{m_ec^2}(1-\\cos(\\theta))\\] Klein-Nishina coefficient\\[\\sigma_{compton}=f_{K-N}(E,\\theta)\\]Rayleigh (Coherent Scatter)Electromagnetic wave resonance: The incident electric wave makes electrons to oscillate in phase and emit radiation Energy is conserved $E_{new}=E$ Photon is deflected with a certain angle Scatter angle $\\theta$ decreases with photon energy $(E)$Probability of occurence (or cross-section): Mainly for large $Z$ Decreases rapidly with $E$ Atomic Form Factor (AFF)\\[\\sigma_{rayleigh}-f_{AFF}(E,\\theta)\\]Total attenuation\\[\\delta I = -\\sigma\\cdot\\rho\\cdot I_0\\cdot\\Delta T\\]Total Attenuation Cross Section, $\\sigma$ $[cm^2/g]$\\[\\sigma(E)=\\sigma_{photo}(E)+\\sigma_{compton}(E)+\\sigma_{rayleigh}(E)+\\dots\\]Linear Attenuation Coefficient, $\\mu$ $[cm^{-1}]$\\[\\begin{aligned}\\mu(E)=\\sigma(E)\\cdot\\rho &amp;amp;\\text{for a single atom}\\\\(\\frac{\\mu}{\\rho})(E)=\\sum_Z w_z\\cdot(\\frac{\\mu}{\\rho})_Z&amp;amp;\\text{for all atoms}\\end{aligned}\\]X-Ray DetectionPrimary X-ray imagePhotographic Film &amp;amp; Phosphor PlatesSolid State Detectors: Indirect DetectionSummary\\[Signal(i)=\\underbrace{k}_{\\text{Gain}}\\int\\underbrace{\\xi(E)}_{\\text{detector technology}}\\underbrace{\\eta(E)}_{\\text{efficiency}}\\biggr[\\underbrace{G}_{\\text{grid}}\\cdot I_{scatter}(E,i)+I_0(E,i)\\cdot e^{-\\int\\color{red}{\\mu}(E)\\cdot dl}\\biggr]dE\\]OverviewWhat characterizes an Imaging System ? Tube output (spectra, power) Beam geometry (narrow or wide beam) Detector technology (integration, electronics, ‚Ä¶) 2D vs 3D imagingWhat system Design vs Imaging Target ? Spatil resolution for specific diagnostic value Radiation dose vs image noisDigital Image FormationProjection ImageDisregarding scatter &amp;amp; non-idealities:\\[\\text{Object signal}(i) = k\\int\\biggr[E\\cdot I_0(E,i)\\cdot e^{-\\int\\mu(E)\\cdot dl}\\biggr]dE\\\\\\text{Air signal}(i)=k\\int E\\cdot I_0(E,i)dE\\]Image formation:\\[\\begin{aligned}\\text{Image}(i)&amp;amp;=-\\color{red}{\\log}(\\frac{\\text{Signal}(i)}{\\text{Air Signal}(i)})\\end{aligned}\\]3D ReconstructionProjection (Mono-E):\\[\\rho(\\beta, t)=\\int_{L_{i-s}}\\mu(x,y)dl\\]If $l=x\\cos(\\beta)+y\\sin(\\beta)$ then we have the Radon tranform Numeric Approximation (Filtered Back Projection, FPB)\\[\\mu(x,y)=\\frac{\\Delta\\beta}{2\\pi}\\sum_{\\beta}\\underbrace{w(\\beta, t)}_{\\text{weight} \\\\ \\text{(e.g. beam geometry)}}\\cdot(\\underbrace{h(t)}_{\\text{high-pass filter} \\\\ \\text{e.g., } H(f)=\\vert f\\vert} * p(\\beta, t))\\] Optimization problem (Iterative Recon)\\[\\text{arg}\\min_{\\mu(x,y)}\\Vert p(\\beta, t)\\underbrace{R}_{\\text{projection matrix with }w(\\beta,t) \\\\ \\text{(e.g. beam geometry)}}\\cdot\\mu(x,y)\\Vert\\]Practical IssuesBeam quantity and qualityBeam HardeningAnti-scatter gridsImage NoiseQuantum noise: Discrete nature of photon production (‚Äúrain drops‚Äù) Visible effects when Nb of particles are small Poisson distribution (Gaussian for large numbers)\\[\\mathcal P\\{k\\}=P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}\\\\SNR=\\frac{\\text{Av. Signal}}{\\text{noise}}=\\frac{N}{\\sqrt{N}}\\]\\[Signal(i)=k\\int E\\cdot\\mathcal P\\{\\eta(E)I(E\\}dE+\\mathcal N(\\sigma)\\]Modulation Transfer Function (MTF)\\[Mt=\\frac{\\text{Modulation of Output Signal}}{\\text{Modulation of Input Signal}} = \\frac{M_o(f)}{M_i(f)} = Fct(f)\\]Imaging System OptimizationNoise Power Spectrum (NPS)System PerformanceImaging Systems &amp;amp; ApplicationsMammographySpectral mammographyOn trouve un rassemblement de beaucoup de vaisseaux montres par l‚Äôiode, etant une indication d‚Äôun cancer.Chest X-RayComputed TomographyWrap-upX-ray physics X-ray production: Coolidge Tube, Bremsstrahlung, Characterisics X-Rays Interaction with matter: photoelectric, compton, Rayleigh X-ray detectors: films, image intensifiers, solid state detectorsRadiology Image formation Image quality 3D reconstruction Clinical application examples" }, { "title": "PRSTA: TD 3", "url": "/cours/posts/prsta_td3/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-14 14:00:00 +0200", "snippet": "Lien de la note HackmdFeuille 3 Exercice 1La variable aleatoire $X$ suit une loi $N(0, \\sigma^2)$ avec $\\sigma \\gt 0$.Nous etudierons le test $H_0 : \\sigma^2 = \\sigma^2_0$ contre $H_1 : \\sigma^2 = \\sigma_2^1$ avec $0 \\lt \\sigma_0 \\lt \\sigma_1$. Determiner la statistique de Neyman-Pearson que nous noterons $T_n$. Determiner $\\alpha$ en fonction du seuil du test. Determiner $\\beta$ en fonction du seuil du test. Determiner les courbes COR associees a ce test. Solution\\[\\begin{aligned}T&amp;amp;=\\frac{\\Pi_{i=1}^nf(X_i,\\sigma_1)}{\\Pi_{i=1}^nf(X_i,\\sigma_0)}\\\\&amp;amp;= \\frac{\\Pi_{i=1}^n\\frac{1}{\\sigma_1\\sqrt{2\\pi}}\\exp(\\frac{-X_i^2}{2\\sigma_1^2})}{\\Pi_{i=1}^n\\frac{1}{\\sigma_0\\sqrt{2\\pi}}\\exp(\\frac{-X_i^2}{2\\sigma_0^2})}\\\\&amp;amp;=(\\frac{\\sigma_0}{\\sigma_1})^n\\exp(-\\frac{1}{2}\\sum_{i=1}^nX_i^2(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2}))\\end{aligned}\\\\\\begin{aligned}\\ln(T)&amp;amp;=\\underbrace{n\\ln(\\frac{\\sigma_0}{\\sigma_1})}_{\\color{green}{a}}-\\frac{1}{2}\\sum_{i=1}^nX_i^2\\underbrace{(\\frac{1}{\\sigma_1^2}-\\frac{1}{\\sigma_0^2})}_{\\color{green}{b}}\\\\&amp;amp;= a-\\frac{b}{2}\\sum_{i=1}^nX_i^2\\end{aligned}\\] D‚Äôapres le lemme de Neyman-Pearson: L‚Äôhypothese $H_0$ est rejetee lorsque:\\[\\begin{aligned}T&amp;amp;\\gt C_{\\alpha}\\\\\\ln(T)&amp;amp;\\gt\\ln(C_{\\alpha})\\\\a-\\frac{b}{2}\\sum_{i=1}^nX_i^2&amp;amp;\\gt\\ln(C_{\\alpha})\\\\\\sum_{i=1}^nX_i^2&amp;amp;\\gt-\\frac{2}{b}(\\ln(C_{\\alpha}) - a)\\end{aligned}\\\\\\color{red}{\\boxed{\\sum_{i=1}^nX_i^2\\gt S_{\\alpha}}}\\\\T_n=\\sum_{i=1}^nX_i^2\\] On cherche $\\alpha$ et $\\beta$:\\[\\begin{aligned}\\alpha&amp;amp;= P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;=P(\\sum X_i^2\\gt S_{\\alpha}\\vert\\sigma=\\sigma_0)\\\\&amp;amp;=P(\\frac{T_n}{\\sigma_0^2}\\gt\\frac{S_{\\alpha}}{\\sigma_0^2})\\end{aligned}\\] Les variables aleatoires sont normales centrees et independantes donc\\[W_n:=\\frac{T_n}{\\sigma_0^2}\\sim\\chi_2(n)\\\\\\alpha=P(W_n\\gt\\frac{S_{\\alpha}}{\\sigma_0^2})\\] On prend $\\alpha=0.05$ et $n=33$\\[\\frac{S_{\\alpha}}{\\sigma_0^2}\\simeq 47,40\\] chi2.ppf(0.95, 33)chi2.isf(0.05, 33) s comme survie\\[\\alpha=1-F_N\\biggr(\\frac{S_{\\alpha}}{\\sigma_0^2}\\biggr)\\\\F_N\\biggr(\\frac{S_{\\alpha}}{\\sigma_0^2}\\biggr) = 1-\\alpha\\\\\\frac{S_{\\alpha}}{\\sigma_0^2} = F_N^{-1}(1-\\alpha)\\\\\\color{red}{\\boxed{S_{\\alpha}=\\sigma_0^2F_N^{-1}(1-\\alpha)}}\\]\\[\\begin{aligned}\\beta&amp;amp;=P(\\text{Accepte H_0}\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(T_n\\le S_{\\alpha}\\vert\\sigma^2=\\sigma_1^2)\\end{aligned}\\] Sous l‚Äôhypothese $H_1$: $W_n‚Äô:=\\frac{T_n}{\\sigma_1^2}\\sim\\chi^2(n)$\\[\\begin{aligned}\\beta &amp;amp;= P(W_n&#39;\\le\\frac{S_{\\alpha}}{\\sigma_1^2})\\\\&amp;amp;= F_n(\\frac{S_{\\alpha}}{\\sigma_1^2})\\\\\\end{aligned}\\\\\\color{red}{\\boxed{\\beta = F_n\\biggr(\\frac{\\sigma_0^2F_n^{-1}(1-\\alpha)}{\\sigma_1^2}\\biggr)}}\\]Feuille 3 Exercice 3La variable aleatoire $X$ suit une loi geometrique de parametre $p$. A l‚Äôaide du theoreme de Wilks, ecrire la zone de rejet du test $H_0 : p = 0, 25$ contre $H_1 : p = 0, 5$. Solution D‚Äôapres le theoreme de Wilks,\\[R_n=2\\log(T_n)\\sim\\chi^2(1)\\\\\\{R_n\\gt 3,84\\}\\] Il suffit d‚Äôexpliciter en $R_n$ Il suffit d‚Äôexpliciter $R_n$\\[\\begin{aligned}T_n&amp;amp;=\\frac{L(X_1,\\dots,X_n,0.5)}{L(X_1,\\dots,X_n,0.25)}\\\\&amp;amp;= \\frac{\\prod_{i=1}^n0.5\\times(1-0.5)^{X_i-1}}{\\prod_{i=1}^n0.25\\times(1-0.25)^{X_i-1}}\\\\&amp;amp;= 2^n\\times\\prod_{i=1}^n\\biggr(\\frac{0.5}{0.75}\\biggr)^{X_i-1}\\\\&amp;amp;= 2^n\\times\\prod_{i=1}^n\\biggr(\\frac{2}{3}\\biggr)\\\\&amp;amp;= 2^n\\times\\biggr(\\frac{2}{3}\\biggr)^{\\sum_{i=1}^n(X_i-1)}\\end{aligned}\\] Passons au logarithme neperien:\\[\\ln(T_n)=n\\ln(2)+\\ln\\biggr(\\frac{2}{3}\\biggr)\\sum_{i=1}^n(X_i-1)\\\\\\begin{aligned}R_n&amp;amp;=2\\ln(T_n)\\\\&amp;amp;= 2(n\\ln(2)+\\ln\\biggr(\\frac{2}{3}\\biggr)\\sum_{i=1}^n(X_i-1))\\end{aligned}\\\\\\alpha = 5\\%\\] Rappel: $R_n$ suit asymptotiquement $\\chi^2(1)$ Zone de rejet:\\[\\{R_n\\gt 3,84\\}\\] On veut resoudre l‚Äôequation pour isoler $\\sum_{i=1}^nX_i$\\[\\begin{aligned}2[n\\ln(2)+\\ln(\\frac{2}{3})\\sum_{i=1}^n(X_i-1)]&amp;amp;\\gt3.84\\\\\\ln(\\frac{2}{3})\\sum_{i=1}^n(X_i-1)&amp;amp;\\gt\\frac{3.84}{2}-\\ln(2)\\\\\\sum_{i=1}^nX_i-n&amp;amp;\\lt\\frac{\\frac{3.84}{2}-n\\ln(2)}{ln(\\frac{2}{3})}\\quad\\text{car }\\ln(\\frac{2}{3})\\lt0\\\\\\frac{\\sum_{i=1}^nX_i}{n}&amp;amp;\\lt\\frac{1.92-n\\ln(2)}{n\\ln(\\frac{2}{3})} +1\\\\\\bar X_n&amp;amp;\\lt\\frac{1.92-n\\ln(2)}{n\\ln(\\frac{2}{3})}+1\\end{aligned}\\]" }, { "title": "OCVX2 : Le retour de l&#39;optimisation avec contraintes - Exercices", "url": "/cours/posts/ocvx2_opti_contraintes_retour_exos/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-13 16:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1\\[\\begin{aligned}\\min f(x,y)&amp;amp;=2x+y\\\\\\text{tel que }3x^2+y^2&amp;amp;\\le4\\end{aligned}\\] Solution\\[\\begin{aligned}3x^2+y^2&amp;amp;\\le4\\\\3x^2+y^2-4&amp;amp;\\le0\\\\g(x,y)&amp;amp;=3x^2+y^2-4\\end{aligned}\\\\\\mathscr L(x,y,\\alpha)=2x+y+\\alpha(3x^2+y^2-4)\\\\\\begin{cases}\\frac{\\partial\\mathscr L}{\\partial x}=2+6\\alpha x=0&amp;amp;\\to x=-\\frac{1}{3\\alpha}\\\\\\frac{\\partial \\mathscr L}{\\partial y}=1+2\\alpha y=0&amp;amp;\\to y=-\\frac{1}{2\\alpha}\\end{cases}\\\\\\begin{aligned}\\mathscr L(\\equiv \\theta_D(\\alpha))&amp;amp;=2(-\\frac{1}{3\\alpha})+(-\\frac{1}{2\\alpha}) + \\alpha(3(-\\frac{1}{3\\alpha})^2 + (-\\frac{1}{2\\alpha})^2 - 4)\\\\&amp;amp;= -\\frac{2}{3\\alpha}-\\frac{1}{2\\alpha}+\\alpha(\\frac{1}{3\\alpha^2}+\\frac{1}{4\\alpha^2}-4)\\\\&amp;amp;= -\\frac{1}{3\\alpha}-\\frac{1}{2\\alpha}+\\frac{1}{3\\alpha}+\\frac{1}{4\\alpha}-4\\alpha\\\\&amp;amp;= -\\frac{1}{3\\alpha}-\\frac{1}{4\\alpha}-4\\alpha\\\\&amp;amp;= -\\frac{7}{12\\alpha}-4\\alpha\\end{aligned}\\\\\\begin{aligned}\\nabla_{\\alpha}\\theta_D(\\alpha)&amp;amp;=\\frac{7}{12\\alpha^2}-4=0\\\\&amp;amp;=\\frac{7}{12\\alpha^2}=4\\\\&amp;amp;=\\frac{1}{4}\\frac{7}{12}=\\alpha^2\\\\\\alpha&amp;amp;=\\frac{1}{2}\\sqrt{\\frac{7}{12}}=\\frac{1}{4}\\sqrt{\\frac{7}{3}}\\end{aligned}\\] Autre methode, en utilisant la complementarite:\\[\\begin{aligned}\\alpha^*g(x^*,y^*)&amp;amp;=0\\\\\\alpha^*=(3(-\\frac{1}{3\\alpha^*})+(-\\frac{1}{2\\alpha^*})^2)&amp;amp;=0\\\\\\alpha^*(\\frac{1}{3\\alpha^{*^2}}+\\frac{1}{4\\alpha^{*^2}}-4)&amp;amp;=0\\\\\\frac{1}{3\\alpha^*}+\\frac{1}{4\\alpha^*}-4\\alpha^*&amp;amp;=0\\\\\\frac{7}{12\\alpha^*}&amp;amp;=4\\alpha^*\\\\\\frac{1}{4}\\frac{7}{12}&amp;amp;=\\alpha^{*2}\\\\\\alpha^*&amp;amp;=\\frac{1}{4}\\sqrt{\\frac{7}{3}}\\end{aligned}\\]Exercice 2\\[\\begin{aligned}\\min_{x\\in\\mathbb R^3}&amp;amp;\\frac{1}{2}(x_1^2+x^2_2+x_3^2)\\\\\\text{tel que } &amp;amp;x_1+x_2+2x_3-1=0\\\\&amp;amp;x_1+4x_2+2x_3-3=0\\end{aligned}\\]Sous forme matricielle:\\[\\boxed{\\begin{aligned}\\min &amp;amp;\\frac{1}{2}x^Tx\\\\\\text{tel que } &amp;amp;Ax-b =0\\end{aligned}}\\\\x=\\begin{pmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{pmatrix}\\\\A=\\begin{pmatrix}1&amp;amp;1&amp;amp;2 \\\\ 1&amp;amp;4&amp;amp;2\\end{pmatrix}\\\\b=\\begin{pmatrix}1 \\\\ _3\\end{pmatrix}\\\\\\]Exercice 3$X={S_1,\\dots,S_N}$ avec proba discrete $p_i=\\mathbb P(X=S_i)$ et $\\sum_{i=1}^Np_i=1$. Entropie de Shannon\\[H(\\mathbb P=(p_1,\\dots,p_n))=-\\sum_{i=1}^Np_i\\log_2(p_i)\\\\\\log_2(x)=\\frac{\\ln(x)}{\\ln(2)}\\]La distribution qui maximise l‚Äôentropie est la distribution uniforme. Solution On cherche a maximiser\\[H(x)=-\\sum_{i=1}^nx_i\\log_2(x_i)\\quad\\text{pour }x=\\begin{pmatrix}x_1 \\\\ \\vdots \\\\ x_n\\end{pmatrix}\\in\\mathbb R^2\\\\\\text{tel que} \\sum_{i=1}^nx_i=1\\\\\\] On cherche a minimiser\\[-H(x)=\\sum_{i=1}^nx_i\\log_2(x_i)\\\\\\text{tel que }\\sum_{i=1}^nx_i-1=0\\\\\\to h(x)=\\sum_{i=1}^nx_i-1\\quad\\text{affine}\\\\\\begin{aligned}\\mathscr L(x,\\beta)&amp;amp;=-H(x)+\\beta h(x)\\\\&amp;amp;= \\sum_{i=1}^nx_i\\log_2(x_i)+\\beta(\\sum_{i=1}^nx_i-1)\\end{aligned}\\\\\\begin{aligned}\\nabla_x\\mathscr L(x,\\beta)=0&amp;amp;\\Leftrightarrow\\forall i,\\begin{cases}\\frac{\\partial \\mathscr L}{\\partial x_i}=0\\\\\\frac{\\partial\\mathscr L}{\\partial x_i}=\\frac{\\partial}{\\partial x_i}(x_i\\log_2(x_i))+\\beta\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}\\frac{d}{dx}(x\\log_2 x)=\\log_2x+x\\frac{d}{dx}\\log_2x\\\\\\frac{d}{dx}\\log_2x=\\frac{d}{dx}\\frac{\\ln(x)}{\\ln(2)}=\\frac{1}{x\\ln(2)}\\end{cases}\\end{aligned}\\\\\\begin{aligned}\\frac{\\partial \\mathscr L}{\\partial x_i}&amp;amp;=\\frac{\\partial}{\\partial x_i}(x_i\\log_2(x_i))+\\beta\\\\&amp;amp;=\\log_2(x_i)+x_i\\frac{1}{x_i\\ln(2)}+\\beta\\\\&amp;amp;=\\frac{\\ln(x_i)+1}{\\ln(2)}+\\beta=0\\end{aligned}\\\\\\begin{aligned}\\frac{\\ln x_i+1}{\\ln 2}&amp;amp;=-\\beta\\\\\\ln x_i+1&amp;amp;=-\\beta\\ln 2\\\\\\ln x_i &amp;amp;= -\\beta\\ln(2)-1\\\\x_i&amp;amp;=e^{-(\\beta\\ln 2+1)}\\quad\\forall i\\end{aligned}\\] Avec la contrainte:\\[\\begin{aligned}\\sum_{i=1}^nx_i&amp;amp;=1\\\\\\sum_{i=1}e^{-(\\beta\\ln2+1)}&amp;amp;=1\\\\ne^{-(\\beta\\ln 2+1)}&amp;amp;=1\\\\\\underbrace{e^{-(\\beta\\ln 2+1)}}_{x_i}&amp;amp;=\\frac{1}{n}\\end{aligned}\\] La distribution qui maximise l‚Äôentropie est donc $x_i=\\frac{1}{n}$ $\\forall i=1\\dots n$ $\\equiv$ distribution uniforme" }, { "title": "IMED2: Introduction", "url": "/cours/posts/imed2_introduction/", "categories": "Image S9, IMED2", "tags": "Image, S9, IMED2", "date": "2021-10-13 16:00:00 +0200", "snippet": "Agenda Introduction to Medical Imaging What is medical imaging ? Roles, Players, Modalities Anatomical vs Functional Imaging Ionizing vs Non-ionizing Radiation Nuclear medicine Basic concepts Tomorrow X-ray Physics Basic concepts X-ray production X-ray interaction with matter X-ray detectors Diagnostic RadiologyGE Healthcare+1800 employees R&amp;amp;D ($35\\%$) Production ($22\\%$) European Center for Maintenance ($16\\%$) Support Functions &amp;amp; Other ($27\\%$)IntroductionA recent history 1895: discory of X-rays, first applications 1958: First gamma camera, Nuclear Medicine 1962: First UV of fetus 1967: First CET head scanner 1972: First head MR scanner 1990: first PET scanner 2000‚Äôs-2010‚Äôs: Digital Age IA What is medical imaging ?ProcessRolesPlayersWho are diagnostic imaging customers ? Healthcar systemes, hospitals, and clinics Governmnent officials Pharmaceutical firms Genetics &amp;amp; Bio-science researchersModalities overviewIonizing vs non-ionizing radiationAnatomix vs Functional Imaging ?Contrast Agents Contrast agents are substances used to enhance visibility of internal structures in X-ray or MR-based imaging techniques Iodine-based Injected in the bloodstream to highlight blode vessels Gaolinium-based Vascular ferromagnetic contrast agent visible in MRI Baarium-based orally to help imaging digestive system, including esophagus, stomach and GI tracks Radioisotope Contrast Agents Radioisotope contrast agents are based on atmos with excess nuclear energy, making it unstable. They emit the excess energy to highlight body functions Tc-99m Injected in the bloodstream to study brain, myocardium, thyroid, lungs, liver, gallblader $^{18}$F-FDg Mark the glucose metabolism Nulcear imagingKey componentsNuclear MedicineAnatomical vs Functional ImagingGamma-rays PhysicsBasics ConceptsQuantaAtomic ModelCharacteristic RadiationProduct of electron transistions between 2 electric shells:Two steps: Electrons (or photons) collid with a shell electron, which is removed from orbit Electrons from higher energy shell fills the vacancy and an X-ray photon is emittedExponential BehaviorExponential decay/growth:\\[\\frac{\\Delta N}{\\Delta t}=\\pm\\lambda N\\\\\\text{provided: }\\lambda\\Delta t\\lt\\lt1\\\\\\text{then: } N=N_0e^{\\pm\\lambda\\Delta t}\\]AttenuationZ-ray photon life span: Photon is transmitted through the matter Photon is absorbed (end of life) Photon is scattered ($E_{new}\\le E$)If $E_{new}\\gt0$, then more A, B or CTransmitted photons:\\[I(E)=I_0(E)\\cdot e^{-\\mu(E)\\cdot t}\\quad\\text{Berr-Lambert lawa}\\]Isotopes DecayGlossary: IsotoPes = atoms with the same number of protons (Z) IsotoNes = atoms with the same number of neutrons Nuclides = nuclei with differing numbers of protons and neutrons are called nuclei Radioisotopes = atoms with unstable nuclei Isomeric Transition Nucleus in an excited state returns to the more stable state release of a photon (gamma, $\\sim88\\%$) Sometimes the nucleus energy may eject an electron (ionized radiation $\\sim12\\%$) which deposes radiation dose to the patientExample: $^{99m}{43}Tc\\to^{99}{43}Tc+\\gamma$ Beta-plus decayProton converted to a neutron by releasing positron $(\\beta)+$ and a neutrino Since positron is an antimatter analog Electron captureProton converted to a neutron by capturing an electron and releases a neutrino. It happens in nuclei with too few neutronsSince the electron is removed from the shell, it releases characteristic X-raysSummaryRadiopharmaceuticalsProductionIdeal characteristicsIdeal Characteristics Short-half life (but not too short) Monochromatic Gamma-ray production Gamma-ray energy high enough to easily cross patient body (deposing minimal dose) Gamma-ray energy low enough to be stopped by the detector Have minimal production of other particles (add noise to our measurements) Localize to the organ of interest, non toxic, ‚Ä¶ Inexpensive and readily availableTechnetium-99m Close to ideal characteristics Decays with $88\\%$ in emission of 140.5 keV photon $12\\%$ internal conversions (electrons, characteristic x-rays, ‚Ä¶)Transport IssuesCommon IsotopesDiagnostic RadiologyInstrumentationGamma Camera Nuclear Imaging $\\Leftrightarrow$ X-ray Imaging Radioctive isotope X-ray tube Collimator Anti-scatter grid Gamma camera X-ray detector Nuclear Medicine detector also measures not only the number of events, but the time and energy of each detected event Ideally imaging is performed from unscattered photons that undergo photoelectric absorption in the detector Scintillator + Electronics must be very fast to detect individual eventsPulse Height Analyzer with Nal CrystalCollimatorsEfficiency Resolution = bar patterns, MTF, FWHM of point source, ‚Ä¶ Sensitivity = fraction of gamma rays the pass through the holes (typically $0.01\\%$) Increasing blades/holes length: Res $\\uparrow$, Sen $\\downarrow$ Type (parallel, convergence, ‚Ä¶) modulates Res &amp;amp; Sen Increasing blades/holesClinical applicationSingle Photon Emission CTCharacteristics Long decay isotope Single photon emitted and captured by camera Tomography technique generates 3D volume of radioactivity density Multi-head cameras allows for faster acquisitions Poor spatial resolution VS excellent contrast resolution Noise is a major factorReconstruction (same as CT) Filtered Back-Projection Iterative techniquesApplicationsPositron Emission TomographyCharacteristics Positron emitter (F-18) Two 511 kEV annihilation photons $180^o$ apart No collimator neededApplicationWrap-upIsotopes Exponential Decay, half-life Isomeric Transition (Tc-99m), Electronic $\\to$ gamma rays, SPECT Beta-plus (F-18) $\\to$ PET Beta-minus $\\to$ TherapyApplications in medicine Radiopharmaceuticals $\\to$ fission, cyclotron, accelerators, generators Gamma cameras, collimators SPECT, single photon emission (gamma-rays: 70-400 keV) $\\to$ orthopedics PET, positron emission (511 keV) $\\to$ oncology" }, { "title": "OCVX2 : Le retour de l&#39;optimisation avec contraintes", "url": "/cours/posts/ocvx2_opti_contraintes_retour/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-10-13 14:00:00 +0200", "snippet": "Lien de la note Hackmd But Resoudre:\\[\\begin{matrix}(OPT)&amp;amp;\\text{minimiser } f(x)&amp;amp; \\\\\\text{tel que} &amp;amp;g_i(x)\\le0&amp;amp;i=1,\\dots,m\\\\&amp;amp;h_j(x)=0&amp;amp;j=1,\\dots,p\\end{matrix}\\]Avec $f, g_i$ convexes et $h_j$ affines$p^{*}=$ valeur optimale $=f(x^{*})$ point optimal avec\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto f(x)\\end{aligned}\\]$x$ est admissible ssi il verifie les contraintes Lagrangien de (OPT):\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta)=f(x)+\\sum_{i=1}^n\\alpha_ig_i(x)+\\sum_{j=i}^p\\beta_jh_j(x)\\end{aligned}\\\\\\begin{aligned}\\alpha\\in\\mathbb R^m\\\\\\beta\\in\\mathbb R^p\\end{aligned}\\biggr\\}\\text{variables duales/multiplicateurs de Lagrange}\\]Fonction primale et probleme primalFonction objective primale:\\[\\theta_p(x)=\\max_{\\alpha,\\beta \\\\ \\alpha\\ge0\\Leftrightarrow \\alpha_i\\ge0\\forall i}\\mathscr L(x,\\alpha,\\beta)\\]et probleme primal $(Q)$ \\(\\min_x\\theta_p(x)\\) $x$ est primal admissible ssi $g_i(x)\\le0$ $\\forall i$ $h_j(x)=0$ $\\forall j$ $x^{*}$ primal optimal et $p^{*}=\\theta_p(x^{*})$ valeur optimaleDans le cas ou on a une seule contrainte $g(x)\\le0$ et une seule contrainte $h(x)=0$\\[\\mathscr L(x,\\alpha,\\beta)=f(x)+\\alpha g(x)+\\beta h(x)\\\\\\begin{aligned}\\underbrace{\\theta_p(x)}_{\\text{fonction convexe}}&amp;amp;=\\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0}\\mathscr L(x,\\alpha,\\beta)\\\\&amp;amp;=\\max_{\\alpha, \\beta \\\\ \\alpha\\ge 0}[f(x)+\\alpha g(x)+\\beta h(x)]\\\\&amp;amp;= f(x) + \\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}[\\alpha g(x)+\\beta h(x)]\\end{aligned}\\] $g(x)\\gt0\\to\\alpha=+\\infty$ $h(x)\\neq0, \\beta=signe(h(x))\\infty$ $g(x)\\le0\\to\\alpha=0$ $h(x)=0,$ peu importe $\\beta$ \\[\\theta_p(x)=f(x)+\\begin{cases}0 &amp;amp;\\text{si } g(x)\\le0 \\text{ et } h(x)=0\\\\+\\infty &amp;amp;\\text{sinon}\\end{cases}\\\\\\Leftrightarrow x\\text{ primal admissible}\\]$y=x^2$:\\[\\begin{aligned}\\min f(x)&amp;amp;=\\infty^2\\\\x+1&amp;amp;\\le0\\end{aligned}\\]$\\color{red}{\\boxed{}}$ : lieu des points primaux admissibleFonction duale et probleme dualFonction objective duale \\(\\theta_D(\\alpha,\\beta)=\\min_x\\mathscr L(x,\\alpha,\\beta)\\)et probleme dual \\((D) \\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}\\theta_D(\\alpha,\\beta)\\) $(\\alpha, \\beta)$ dual admissible ssi $\\alpha\\le0$ ($\\alpha_i\\ge0$ $\\forall i$)$(\\alpha^{*}, \\beta^{*})$ dual optimal ssi solution de $(D)$ et $d^{*}=\\theta_D(\\alpha^{*},\\beta^{*})$\\[\\begin{aligned}\\underbrace{\\theta_D(\\alpha,\\beta)}_{\\text{fonction concave}} &amp;amp;=\\min_x\\mathscr L(x,\\alpha,\\beta)\\\\&amp;amp;= \\min_x[\\underbrace{f(x)+\\alpha g(x)+\\beta h(x)}_{\\text{affine (a } x \\text{) fixe relativement a }\\alpha\\text{ et }\\beta\\text{ et }\\min(\\text{fcts concaves}) = \\text{fct concave}}]\\end{aligned}\\] Lemme Si $(\\alpha,\\beta) \\ \\alpha\\ge0$ dual admissible, $\\theta_D(\\alpha,\\beta)\\le p^{*}$Preuve\\[\\begin{aligned}\\theta_D(\\alpha, \\beta) &amp;amp;=\\min_x\\mathscr L(x, \\alpha, \\beta)\\\\&amp;amp;\\le\\mathscr L(x^*,\\alpha,\\beta)=f(x^*)+\\underbrace{\\overbrace{\\alpha}^{\\ge0}\\overbrace{g(x^*)}^{\\le0}}_{\\le0} + \\overbrace{\\beta h(x^*)}^{=0}\\quad\\begin{matrix}\\text{avec }x^*\\text{ primal optimal} \\\\ \\to g(x^*)\\le0\\text{ et } h(x^*)=0\\end{matrix}\\\\&amp;amp;\\le f(x^*)=p^*\\end{aligned}\\] Toutes les valeurs du probleme dual minorent la valeur optimale du probleme primalProbleme dual \\(\\to\\max_{\\alpha,\\beta \\\\ \\alpha\\ge0}\\theta_D(\\alpha,\\beta)=d^*\\le p^*\\to p^*-d^*\\ge0\\) saut de dualite C‚Äôest le principe de dualite faible: vrai pour tout probleme primal et dualOn aimerait ici que le saut de dualite $p^*-d^*$ soit egaux a $0\\to p^*=d^*$ On peut resoudre le primal en resolvant le dualOn a cherche les conditions (‚Äúqualifications de contraintes‚Äù) pour que $p^*=d^*$.Dans le cas ou tout est convexe: Condition de SlaterLe saut de dualite est nul s‚Äôil existe un $\\tilde x$ qui est srictement admissible $(g(\\tilde x)\\lt0)\\Leftrightarrow$ l‚Äôensemble admissible doit avoir un point interieur Lemme (complementarite)Si la dualite forte est verifiee, on a $\\boxed{\\alpha^{*}g(x^{*})=0}$ Si on a plusieurs contraintes, $\\alpha^{*}_ig_i(x^{*})=0$ $\\forall i$ PreuveDualite forte:\\[\\begin{aligned}p^{*}=d^{*}&amp;amp;=\\theta_D(\\alpha^{*},\\beta^{*})\\\\&amp;amp;= \\min_x\\mathscr L(x,\\alpha^{*},\\beta^{*})\\\\&amp;amp;\\le\\mathscr L(x^*,\\alpha^*,\\beta^*)=\\underbrace{f(x^*)}_{p^*}+\\underbrace{\\overbrace{\\alpha^*}^{\\ge0}\\overbrace{g(x^*)}^{\\le0}}_{\\le0}+\\overbrace{\\beta^*\\underbrace{h(x^*)}_{=0}}^{=0}\\end{aligned}\\\\p^*\\le p^*+\\underbrace{\\alpha^*g(x^*)}_{\\le0}\\to\\alpha^*+g(x^*)=0\\\\\\begin{cases}\\alpha^*\\gt0&amp;amp;\\to g(x^*)=0\\\\g(x^*)\\lt0&amp;amp;\\to\\alpha^*=0\\end{cases}\\]Conditions de Karush-Kuhn-Tucker (KKT pour les intimes) Conditions KKT Conditions necessaires pour la resolution de (OPT):\\[\\begin{matrix}(OPT)&amp;amp;\\text{minimiser } f(x)&amp;amp; \\\\\\text{tel que} &amp;amp;g_i(x)\\le0&amp;amp;i=1,\\dots,m\\\\&amp;amp;h_j(x)=0&amp;amp;j=1,\\dots,p\\end{matrix}\\]Soient $x^{*}\\in\\mathbb R^n$, $\\alpha^{*}\\in\\mathbb R^m$ et $\\beta^{*}\\in\\mathbb R^p$ satisfait les conditions: Stationnarite de $\\mathscr L$: \\(\\nabla_x\\mathscr L(x^*,\\alpha^*,\\beta^*)=\\nabla_x f(x^*)+\\sum_{i=1}^n\\alpha_i^*\\nabla_x g_i(x^*)+\\sum_{j=1}^p\\beta_j^*\\nabla_x h_j(x^*)=0\\) Admissibilite primale: $g_i(x^{*})\\le0$ $\\forall i$ et $h_j(x^{*})=0$ $\\forall j$ Admissibilite duale: $\\alpha_i^{*}\\ge0$ $\\forall i$ Complementarite: $\\alpha_i^{*}g_i(x^{*})=0$ $\\forall i$Alors $x^{*}$ est optimal pour le probleme primal, et $(\\alpha^{*}, \\beta^{*})$ optimal pour le dual.Si de plus la dualite forte est verifiee, alors n‚Äôimporte quelles solutions du primal et du dual verifient $1)-4)$En pratiqueComment on s‚Äôen sort ? On ecrit le Lagrangien $\\mathscr L(x,\\alpha,\\beta)$ et on calcule $\\nabla_x\\mathscr L(x,\\alpha,\\beta)$ On utilise la stationnarite $\\nabla_x\\mathscr L(x,\\alpha,\\beta)=0$ pour trouver une relation entre $x$ et $\\alpha/\\beta$ On remplace $x$ par $\\alpha/\\beta$ dans le Lagrangien $\\to$ ecrire la fonction objective duale On resout le dual, eventuellement en se servant de la complementariteExemple\\[\\begin{aligned}\\min_{x\\in\\mathbb R^2}&amp;amp;\\frac{1}{2}(x_1^2+x_2^2)\\\\\\text{tel que }&amp;amp;\\underbrace{x_1-2x_2+2}_{g(x_1,x_2)}\\le0\\end{aligned}\\] \\[\\mathscr L(x,x_2,\\alpha_2)=\\frac{1}{2}(x_1^2+x_2^2)+\\alpha(x_1-2x_2+2)\\] \\[\\begin{aligned}\\nabla_x\\mathscr L = 0 &amp;amp;\\to \\frac{\\partial\\mathscr L}{\\partial x_1}=x_1+\\alpha=0\\to x_1=-\\alpha \\\\ &amp;amp;\\frac{\\partial \\mathscr L}{\\partial x_2} = x_2-2\\alpha=0\\to x_2=2\\alpha\\end{aligned}\\] \\[\\begin{aligned}\\mathscr L(\\alpha)(\\equiv\\theta_D(\\alpha))&amp;amp;=\\frac{1}{2}\\biggr((-\\alpha^2)+(2\\alpha)^2\\biggr) + \\alpha(-\\alpha-4\\alpha+2) \\\\ &amp;amp;= \\frac{5}{2}\\alpha^2-5\\alpha^2+2\\alpha \\\\ &amp;amp;=-\\frac{5}{2}\\alpha^2+2\\alpha\\end{aligned}\\] On resout\\[\\begin{aligned}\\max_{\\alpha\\ge0}\\theta_{D}(\\alpha)\\to\\nabla_{\\alpha}\\theta_D(\\alpha)&amp;amp;=-5\\alpha+2 = 0 \\\\\\alpha^*&amp;amp;=\\frac{2}{5}\\to x_1^*=-\\frac{2}{5}\\text{ et } x_2^*=\\frac{4}{5}\\end{aligned}\\]" }, { "title": "EPIQUANTI : Architecture d&#39;un ordinateur quantique et technologies habilitantes", "url": "/cours/posts/epiquanti_architecture/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-12 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du cours La correction d‚Äôerreur ‚Äúnormale‚Äù est tres differente de celle de l‚Äôinformatique quantiqueQEC ZooEnvoyer un Qubit Principe general Shor 9 error correction codeSurface code QEC QEC adapted to 2D bit architectures like with superconductors from Google Au-dessus de 20 qubits, on a trop d‚ÄôerreursAlissonBob, Amazon et UCI pretendent pouvoir reduire le nombre de qubits physiques necessaires pour faire des calculs.More on quantum computing speedQuand on fait une operation de portes sur des qubits intriques, c‚Äôest comme si on faisait cette operation sur plusieurs etats.On va prendre une porte de Hadamard: on a une vingtaine d‚Äôoperations.Or, d‚Äôapres IBM, comme le calcul quantique est probabiliste il faut l‚Äôexecuter plusieurs fois, cad $4000$ fois. $4000\\times20=80 000$ portes executees pour juste une porte de Hadamard ! Et c‚Äôest un cas simple De meme, pour les autres portes: On veut corriger le taux d‚Äôerreur pour utiliser le moins de qubits physiques possibleQubits connectivityIBMRocheser 53 qubits, october 201965 qubits, october 2020GoogleSycamore 53 qubits, october 2019Pourquoi un qubit blanc ? Parce qu‚Äôil marche pas ptdrIonQ Cas particulier des ions piegesIls sont tous connectes les uns aux autres 11 qubits, 2018‚ÄúRackability‚Äù examplesPasqualDouble depth racks Model of cold atoms computer with $100-100$ qubits, planned for $2021-2023$QuandelaSingle depth rack PrometheusData center constraintsCombien est-ce que ca consomme dans un data center ? Je sais pas / ca depend[name=Olivier Ezratty] [time=Tue, Oct 12, 2021 4:50 PM] [color=#907bf7]Ca depend du nombre de rackCooling Goal: reduce thermal noise affecting qubitsMicro-waves sources Chaque fils supra-conducteur coute $3000$$Details from a 15 mK cryostatSome companiesDilutions and systems Finland Bluefors IBM Rigetti CEA US: JanisULT Google UK: Oxford instruments Microsoft DWave France: CryoConcept Neel LPENS Netherlands: Leiden Cryogenics IBM Cabling Japan Coax Co. LTD Netherlands Delft Circuits France Radiall Pulse tubes and compressors US Cryomech Japan Sumitomo Available cooling power Cryostat pulse tubes minimum temperature 20mK stage 100 mK stage MC cold plate Bluefors lD250 XLF400 XLD1000 1 2 2 10mk 8 mK 8 mK $12\\mu$ W $12\\mu$ W $34\\mu$ W $250\\mu$ W $450\\mu$ W $1000\\mu$ W IBMGoldeneye fridge designed for 1121 qubits Condor completion planned for 2023.5 and 14 days to cool down.design shown is not fake Cabling paths shows they will use some sort of cryoCMOS using separate pulse tubes to and bottom" }, { "title": "PRSTA: Seance 3", "url": "/cours/posts/prsta_seance3/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-10-06 14:00:00 +0200", "snippet": "Lien de la note HackmdExemple $H_0:m=m_0$ contre $H_1:m=m_1$ ou $X$ suit une loi $\\mathcal N(m,1)$ et $m_0\\le m_1$ A. N.: $m_0=1$ et $m_1=2$ Calculer $\\alpha$ Calculer $\\beta$ Solution Determiner la statistique de NP\\[\\begin{aligned}\\frac{L(X_1,\\dots,X_n,2)}{L(X_1,\\dots,X_n,1)} &amp;amp;= \\frac{\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(X_i-2)^2}{2}}}{\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(X_i-1)^2}{2}}}\\\\&amp;amp;= e^{\\frac{1}{2}[-\\sum X_i^2-4X_i+4+\\sum X_i^2-2X_i+1]}\\\\&amp;amp;= e^{\\frac{1}{2}\\sum_{i=1}^n(1X_i-3)}\\\\&amp;amp;=e^{\\sum_{i=1}^nX_i}\\times \\underbrace{e^{-\\frac{3n}{2}}}_{\\color{red}{c}}\\end{aligned}\\] Passons au log\\[\\log(T)=\\sum_{i=1}^nX_i+\\log(\\color{red}{c})\\] L‚Äôhypothese $H_0$ est rejetee lorsque\\[\\begin{aligned}T&amp;amp;\\gt S_{\\alpha}\\\\\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\sum X_i+\\log(c)&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\end{aligned}\\\\\\color{red}{\\boxed{\\sum X_i\\gt\\log(S_\\alpha)-\\log(c)}}\\\\\\sum X_i\\gt C_{\\alpha}\\] On veut calculer $\\alpha$:\\[\\begin{aligned}\\alpha &amp;amp;= P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\sum X_i\\gt C_{\\alpha}\\vert m=1)\\end{aligned}\\] On veut se ramener a la loi centree-reduite:\\[\\begin{aligned}\\alpha&amp;amp;=P(\\underbrace{\\frac{\\sum X_i}{n}}_{\\color{green}{\\bar X_n}}\\gt\\frac{C_{\\alpha}}{n}\\vert m=1)\\\\&amp;amp;= P(\\bar X_n\\gt\\frac{C_{\\alpha}}{n}\\vert m=1)\\\\&amp;amp;= P(\\sqrt{n}(\\bar X_n-1)\\gt\\frac{\\sqrt{n}(C_{\\alpha}-1)}{n})\\end{aligned}\\] Sous l‚Äôhypothese $H_0$: $Z_n=\\sqrt{n}(\\bar X_n-1)\\sim\\mathcal N(0,1)$ Par definition, qu‚Äôest-ce que ce nombre ? On rejette combien a droite ? C‚Äôest un quantile au niveau $1-\\alpha$ \\[\\sqrt{n}(\\frac{C_{\\alpha}}{n}-1)=Z_{1-\\alpha}\\] ou $Z_{1-\\alpha}$ designe le quantile de $\\mathcal N(0,1)$ au niveau $1-\\alpha$. Maintenant on veut exprimer $\\beta$. De quoi on a besoin pour determiner $\\beta$ ?\\[\\begin{aligned}\\beta &amp;amp;= P(\\text{Accepter } H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(\\sum X_i\\le C_{\\alpha}\\vert m=2)\\end{aligned}\\] On veut exprimer $C_{\\alpha}$ en fonction de $Z_{1-\\alpha}$.\\[\\begin{aligned}\\sqrt{n}(\\frac{C_{\\alpha}}{n}-1)&amp;amp;=Z_{1-\\alpha}\\\\\\frac{C_{alpha}}{n}-1&amp;amp;=\\frac{Z_{1-\\alpha}}{\\sqrt{n}}\\\\\\frac{C_{\\alpha}}{n}=\\frac{Z_{1-\\alpha}}{\\sqrt{n}}+1\\\\\\end{aligned}\\\\\\color{red}{\\boxed{C_{\\alpha}=n\\biggr(\\frac{Z_{1-\\alpha}}{\\sqrt{n}}+1\\biggr)=\\sqrt{n}Z_{1-\\alpha}+n}}\\] Avant de continuer, essayons de trouver $C_{\\alpha}$ dans le cas ou $\\alpha=1\\%$ et dans le cas ou $\\alpha=5\\%$ Avant de calculer $\\beta$, on trouve les $C_{\\alpha}$.\\[\\begin{matrix}\\alpha=5\\%&amp;amp;C_{\\alpha}=1,64\\sqrt{n}+n\\\\\\alpha=1\\%&amp;amp;C_{\\alpha}=2,33\\sqrt{n}+n\\end{matrix}\\] Si $n=100$, $\\alpha=1\\%$, alors $C_{\\alpha}=123,3$ et pour $\\alpha=5\\%$, $C_{\\alpha}=116,4$. Maintenant on peut calculer $\\beta$.\\[\\begin{aligned}\\beta&amp;amp;=P(\\text{Ne pas rejeter } H_0\\vert H_0\\vert \\text{ fausse})\\\\&amp;amp;=P(\\sum X_i\\lt C_{\\alpha}\\vert m=2)\\\\&amp;amp;=P(\\bar X_n\\lt\\frac{C_{\\alpha}}{n}\\vert m=2)\\\\&amp;amp;=P(\\sqrt{n}(\\bar X_n-2)\\lt\\sqrt{n}(\\frac{C_{\\alpha}}{n}-2)\\vert m=2)\\\\\\end{aligned}\\] Sous l‚Äôhypothese $(H_1)$\\[Z_n=\\sqrt{n}(\\bar X_n-2)\\sim\\mathcal N(0,1)\\\\\\color{red}{\\boxed{\\beta=P(Z_n\\lt\\sqrt{n}(\\frac{C_\\alpha}{n}-2))}}\\] Pour $\\alpha=5\\%$ et $n=100$:\\[\\begin{aligned}\\sqrt{n}(\\frac{C_{\\alpha}}{n}-2)&amp;amp;=10(1,164-2)\\\\&amp;amp;=-8,36\\end{aligned}\\\\\\beta=P(Z_n\\lt-8,36)=3\\times10^{-17}\\] scipy.stats.norm.cdf(-8.36) norm: loi normale cdf: cumulative distribution function Pourquoi $\\beta$ est aussi petit ? Parce que $\\alpha$ est tres grand par rapport a $n$ Faisons la meme chose pour $n=25$ et $\\alpha=1\\%$Test du rapport de vraisemblance generalise (GLR) $H_0:\\theta\\in A$ contre $H_1:\\theta\\in B$ $T=\\frac{L(X_1,\\dots,X_n\\hat\\theta_1^{MV})}{L(X_1,\\dots,X_n\\hat\\theta_0^{MV})}$ $T=\\frac{\\sup_{\\theta\\in B}L(X_1,\\dots,X_n\\theta)}{\\sup_{\\theta\\in A}L(X_1,\\dots,X_n\\theta)}$ Rejet de $(H_0)$ ssi $T\\gt S_{\\alpha}$ ou $S_{\\alpha}$ est un seuil qui depend du niveau de confiance de $\\alpha$ Comment on le traduit ? $H_0:m\\in{0}$$H_1:m\\in\\mathbb R\\setminus{0}$Test de comparaison de 2 moyennes Deux populations Deux echantillons independants suffisamment grand $(X_1,\\dots,X_{n_1})$ et $(Y_1,\\dots,Y_{n_1})$ Statistique\\[Z=\\frac{\\bar X_{n_1}-\\bar Y_{n_2}}{\\sqrt{(\\frac{S^2_{n+1}}{n_1}+\\frac{S^2_{n_2}}{n_2})}}\\] $H_0:m_1=m_2$ contre $H_1:m_1\\neq m_2$ $H_0:m_1=m_2$ contre $H_1:m_1\\gt m_2$ $H_0:m_1=m_2$ contre $H_1:m_1\\lt m_2$Principe de Neyman Pearson Determination d‚Äôun model statistique Determination d‚Äôhypotheses Determination d‚Äôune statistique de test Determination de la forme de la region critique Determination des valeurs critiques Conclusion: rejet ou non de l‚Äôhypothese Calcul de la puissance du test Hypotheses simples $H_0:\\theta=\\theta_0$ $H_1:\\theta=\\theta_1$ExemplePremier exempleLa variable aleatoire $X$ suit une loi $\\mathcal N(m,1)$. Nous voulons tester $H_0:m=0$ contre $H_1:m\\neq0$ Solution Qu‚Äôest-ce que le maximum de vraisemblance ? C‚Äôest ce qui maximise la fonction de vraisemblance en fonction de $\\theta$ Maximum de vraisemblance pour une loi normale ?\\[L(x_1,\\dots,x_n,m)=\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x_i-m)^2}{2}}\\] Il n‚Äôy a pas de $\\sigma$ car $\\sigma=1$\\[L(x_1,\\dots,x_n,m)=\\Pi_{i=1}^n\\frac{1}{\\color{red}{\\sigma}\\sqrt{2\\pi}}e^{-\\frac{(x_i-m)^2}{2\\color{red}{\\sigma^2}}}\\] On a une fonction $f\\Rightarrow\\log(f‚Äô)$? Prenons un exemple:\\[\\begin{aligned}f(x) &amp;amp;= x^2-2x\\\\f&#39;(x)&amp;amp;=2x-2\\\\\\log(f&#39;(x))&amp;amp;=\\log(2x-2)\\\\\\log(f&#39;(x))=0&amp;amp;\\Leftrightarrow2x-2=1\\\\&amp;amp;\\Leftrightarrow \\color{red}{\\boxed{x=\\frac{3}{2}}}\\\\\\end{aligned}\\\\\\begin{aligned}f(x)&amp;amp;=x^2-2x\\\\\\log(f(x))&amp;amp;=\\log(x^2-2x)\\\\(\\log(f(x)))&#39;&amp;amp;=\\frac{2x-2}{x^2-1}\\\\(\\log(f(x)))&#39;=0&amp;amp;\\Leftrightarrow\\color{red}{\\boxed{x=1}}\\end{aligned}\\] Ce n‚Äôest pas le meme resultat La formule du maximum de vraisemblance est:\\[T=\\frac{L(X_1,\\dots,X_n,\\hat\\theta)}{L(X_1,\\dots,X_n,\\theta_0)}\\] Avec $\\hat\\theta$ l‚Äôestimateur du maximum de vraisemblance de $\\theta$. On cherche $\\bar X$.\\[\\begin{aligned}T&amp;amp;=\\frac{L(X_1,\\dots,X_n,\\bar X)}{L(X_1,\\dots,X_n,0)}\\quad \\text{car }m=0\\\\&amp;amp;= e^{-\\frac{1}{2}[\\sum_{i=1}^n(X_i-\\bar X)^2-\\sum_{i=1}^nX_i^2]}\\\\&amp;amp;=e^{-\\frac{1}{2}[e\\sum_{i=1}^nX_i+n\\bar X^2]}\\\\&amp;amp;=e^{-\\sum_{i=1}^nX_i-\\frac{n}{2}\\bar X^2}\\end{aligned}\\\\\\log(T)=-\\sum X_i-\\frac{n}{2}\\bar X^2\\] $(H_0)$ rejetee $\\color{red}{si}$ $T\\gt S_{\\alpha}$\\[\\begin{aligned}\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\-\\sum X_i-\\frac{n\\bar X^2}{2}&amp;amp;\\gt \\log(S_{\\alpha})\\\\\\sum_{i=1}^nX_i+\\frac{n\\bar X^2}{2}&amp;amp;\\lt\\log(S_{\\alpha})\\end{aligned}\\] PropositionSous des hypotheses techniques, en notant $\\hat\\theta_n$ l‚Äôestimateur du maximum de vraisemblance. $\\sqrt{nI(\\theta_0(\\hat\\theta_n\\theta_0))}$ converge en loi vers $\\mathcal N(0,1)$ Nous dirons que l‚Äôestimateur du maximum de vraisemblance est normal asymptotiquement efficace ou NAE. Nous supposerons que les hypotheses techniques evoquees sont verifiees. Theoreme de WilksSous l‚Äôhypothese $H_0$, $R_n:=2\\log(T_n)$ converge en loi vers une loi $\\chi^2(1)$ En revenant a nos calculs: \\(2\\biggr(\\sum_{i=1}^nX_i+n\\bar X^2\\biggr)\\sim\\chi^2(1)\\)Second exemple La variable aleatoire $X$ suit une loi $\\varepsilon(\\lambda)$ $H_0:\\lambda=1$ contre $H_1:\\lambda\\gt1$" }, { "title": "EPIQUANTI : Partie logiciel", "url": "/cours/posts/epiquanti_logiciel/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-10-05 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursRegisters n bits register n qubits register $\\color{red}{2^n\\text{ possible states } \\textbf{once at a time}}$ $\\color{green}{ 2^n \\text{possible states }\\textbf{linearly superposed}}$ evaluable partially evaluable independant copies no copies individually erasable non individualy erasable non destructive readout value changed after readout deterministic probabilistic GatesClassical logic gatesIrreversible gates: NAND NOR AND ORQuelle est leur consequence ? Comme on perd un bit, on a une perte d‚ÄôenergieDecouverte par Rolf Landauer Des gens travaillent aujourd‚Äôhui pour creer une informatique classique sans perte d‚ÄôenergieQuantum gates Matrix based reversible unitary transformations NOT: rotation $X$ Rotation $Y$\\[\\begin{bmatrix}0&amp;amp;-i\\\\i&amp;amp;0\\end{bmatrix}\\] Pauli-Z: rotation $Z$ Hadamard: superpositionPorte CNOT On va changer la valeur d‚Äôun qubit en fonction d‚Äôun autre Mathematiquement, a quoi ca ressemble ?\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\end{bmatrix}\\]Si on intrique des qubits a des portes a 2 qubits, est-ce que ca reste ? OuiC2NOT\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\end{bmatrix}\\]SWAP\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1\\end{bmatrix}\\]Fredkin Conditional SWAP\\[\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\]Single qubit operations visualizationCNOT gate effect\\[\\begin{matrix}\\color{blue}{\\text{control qubit}} &amp;amp;&amp;amp;\\color{blue}{\\text{tensor product of control and target qubits before CNOT}}\\\\\\alpha_1\\vert0\\rangle &amp;amp;&amp;amp;\\alpha_1\\alpha_1\\vert00\\rangle+\\alpha_1\\beta_2\\vert01\\rangle + \\alpha_2\\beta_1\\vert10\\rangle+\\beta_1\\beta_2\\vert11\\rangle\\\\\\bigotimes&amp;amp;\\Rightarrow&amp;amp;\\text{CNOT}\\\\\\alpha_2\\vert0\\rangle+\\beta_2\\vert1\\rangle&amp;amp;&amp;amp;\\alpha_1\\alpha_1\\vert00\\rangle+\\alpha_1\\beta_2\\vert01\\rangle + \\alpha_2\\beta_1\\vert11\\rangle+\\beta_1\\beta_2\\vert10\\rangle\\\\\\color{blue}{\\text{target qubit}}&amp;amp;&amp;amp;\\color{blue}{\\text{control and target qubits state after CNOT}}\\\\\\color{blue}{\\text{control qubit is }\\vert0\\rangle}\\\\\\alpha_1=1&amp;amp;&amp;amp;\\alpha_2\\vert00\\rangle+\\beta_2\\vert01\\rangle\\\\&amp;amp;\\Rightarrow&amp;amp;\\text{CNOT}\\\\\\beta_1=0&amp;amp;&amp;amp;\\alpha_2\\vert00\\rangle+\\beta_2\\vert01\\rangle\\\\\\end{matrix}\\] CNOT is not changing the qubitThe EPR pair entanglemet building blockPut control qubit into superposition state, then future gates act on 2 states simultaneously\\[\\frac{\\vert0\\rangle+\\vert1\\rangle}{\\sqrt 2}\\] \\(\\biggr\\}\\frac{\\vert00\\rangle+\\vert11\\rangle}{\\sqrt{2}}\\)Subsenquently, flipping a qubit in an entangled state modifies all of tis componentsControl-U gateOn prend une porte U qui est une porte arbitraire\\[\\begin{bmatrix}1&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots\\\\\\dots&amp;amp;1&amp;amp;\\dots&amp;amp;\\dots\\\\\\dots&amp;amp;\\dots&amp;amp;U_{11}&amp;amp;U_{12}\\\\\\dots&amp;amp;\\dots&amp;amp;U_{21}&amp;amp;U_{22}\\end{bmatrix}\\]Qubit lifecycle Initialization $\\vert0\\rangle$ Hadamard gate $\\frac{\\vert0\\rangle + \\vert1\\rangle}{\\sqrt{2}}$ Other gate aubit vector turning around in Bloch sphere Measurement Measurement returns $\\vert 0\\rangle$ qith a probability $\\alpha^2$ depending on the qubit state, then qubit state becomes $\\vert0\\rangle$ Measurement returns $\\vert1\\rangle$ with a probability $\\beta^2$ Universal gates sets Jeu de portes universelJeu de portes simples qu‚Äôon peut combiner pour recreer toutes les transformations unitaires Ex: CNOT peut etre recree avec HZHThree CNOT gates: one SWAP gate Universal quantum computing requires a T gate ($\\frac{\\pi}{4}$ rotation)Getting confused with phase rotations One round = $2\\pi$ $S=$ one quarter round $=\\frac{\\pi}{2}$ $T=$ one eight roungSolovay-Kitaev theorem Theorem Any desired gate can be approximated by a sequence of gates from an universal gates set. A quantum circuit of $m$ constant-qubit gates can be approximated to $\\varepsilon$ error by a quantum circuit of $O(m\\log^c(\\frac{m}{\\varepsilon}))$ gates from a desired finite universal gate set with $c=3,97$ For example, creating a $R_{15}$ gate requires $127$ H/Z/T gatesIn other words On veut appliquer a $n$ qubits n‚Äôimporte quelle operation generique $U$, on enchaine une serie de transformations unitaires.$SU(2^n)$ - Space of unitaries on $n$ qubits Espace contenant toutes les transformationsOn reversibility All quantum gates are mathematically reversible, this is a property of the matrix linear transformations We could theortically run an algorithm and rewinf it entirely to return to the initial state, which could help recover port of the energy spent in the systemOn a practical basis: The gates are not physically and thermodynamically reversible due to some irreversible processes like micro-wave generations and DACs (digital analog converters) The whole digital process taking place before micro-wave generation and after their readout conversion back to digital could be implemented in classical adiabatic\\thermodynamically reversible fashion Currently being investigated at Sandia Labs, Wisconsin University and with SeeQCInputs and outputsProbabilistic or deterministic readouts ? A single qubit measurement is probabilistic, ie: a qubit registered after a Hadamard gate applied to all qubits is a simple random numbers generatorOn a practical basis: the algorithm is executed many times, up to 8000 for IBM Q Experience an average of qubits results is computed, producing a real number the averahed result is theoratically deterministic modulo the error generated by noise and decoherenceBasis, pure and mixed statesExamples Normalement vous avez rien compris[name=Olivier Ezratty] [time=Tue, Oct 5, 2021 3:55 PM] [color=#907bf7] L‚Äôorigine aleatoire du photon provient de la physique classique et non quantiqueSingle qubit mixed stateToying with density matricesQubits measurement Measurement is using a collection ${M_m}$ of operators acting on the measured system state space $\\vert\\psi\\rangle$, with probability of $m$ being:\\[p(m)=\\langle\\psi\\vert M_m^‚úùM+m\\vert\\psi\\rangle\\]System state after measurement becomes:\\[\\frac{M_m\\vert\\psi\\rangle}{\\sqrt{\\langle\\psi\\vert M_m^‚úùM+m\\vert\\psi\\rangle}}\\]with:\\[\\sum_mM_m^‚úùM+m=1\\]Various qubits measurement methodsComputing semantics summary5 DiVienzo criteria (IBM, 2000)Main qubit typesFrom lab to packaged computersLes ordinateurs quantiques actuels d‚ÄôIBM:L‚Äôordinateur version commerciale: Il y a un cube derriere qui contient l‚ÄôordinateurIBM pense atteindre $1000$ qubits d‚Äôici 2 ans, mais ca a pas trop l‚Äôair possible car au-dessus de $28$ qubits il y a une enorme perte de qualite.Inside a typical quantum computerEn resume: 4 composantesAvec des atomes froids, on n‚Äôaurait pas des compresseurs mais des pompes a ultra-vide.Chez GooglePourquoi les fils tournent ? Pour passer plus de temps dans le froid ? Systeme de dilatation thermique du au changement de temperature hardcore Refroidit: contracte Rechauffement: dilate Pourquoi plusieurs etages ? On est a $300K$ a l‚Äôexterieur, on veut minimiser plusieurs pochesChaque etage = une temperatureChaque disque a une taille plus petite en descendant les etages, pour faire passer le moins de chaleur possibleChaque etage est isole de celui au-dessusLes fils sont des attenuateurs de puissance mais ils generent de la chaleur C‚Äôest l‚Äôisolation thermiqueQuantum computer architecturePhysical layout exampleError correction Each quantum gate and readout generate significant errorsComing form decoherence generated by: flip, phase and leakage error calibration errors thermal noise electric and magnetic noise gravity radioactivty vacuum quantum fluctuations cosmical rays It accumulates with the number of quantum gates and qubitsQEC zoo" }, { "title": "CMKV: Implementation d&#39;algorithme", "url": "/cours/posts/cmkv_algorithme/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-30 09:00:00 +0200", "snippet": "Lien de la note Hackmd\\[T_{t+1}\\leftarrow T_{t+1}\\times\\alpha\\] Evaluation : projetL‚ÄôalgorithmeOn fait une marche al√©atoireT_‚àÖ &amp;lt;- ?loop i_cond &amp;lt;- ? tirageOn tire un $x_{candidat}$, on preserve tous les $x\\neq x_{candidat}$\\(x=(x_1^{(t)},\\dots,\\color{blue}{x_{candidat}}, x_{candidat+1}^{(t)}, x_{N}^{(t)})\\)Au lieu de changer touT le vecteur, on ne change qu‚Äôune valeure (le $x_{candidat}$), l‚Äôalgorithme convergera plus vite\\[\\begin{matrix}&amp;amp;x_{candidat}=(&amp;amp;\\text{idem},&amp;amp;\\boxed{i_{random}},&amp;amp;\\text{idem},&amp;amp;\\boxed{i_{random}},&amp;amp;\\text{idem})\\\\&amp;amp;&amp;amp;\\updownarrow &amp;amp;\\searrow&amp;amp;\\updownarrow&amp;amp;\\swarrow&amp;amp;\\updownarrow\\\\&amp;amp;&amp;amp;&amp;amp;\\nearrow&amp;amp;&amp;amp;\\nwarrow&amp;amp;\\\\&amp;amp;x^{(t)} = (&amp;amp; &amp;amp;\\boxed{} &amp;amp; &amp;amp;\\boxed{} &amp;amp;)\\end{matrix}\\]Comment choisir alpha ? On le prend tr√®s proche de 1Algorithme de descente - principe : parcourir toutes les variables Et pour chacunes des variables on parcourt toutes les valeurs possibles et on minimise l‚Äôenergie (U) : Ca converge forcement mais ca converge vers un minimum local (et c‚Äôest pas ce qu‚Äôon cherche)\\[x^{(t+1)}=(\\text{arg}\\min_{\\omega_1\\in\\Omega_1}U(\\omega_1,x_2^{(t)}), x_2^{(t)})\\quad\\text{var #}1\\\\x^{(t+2)}=(x_1^{(t+1)}, \\text{arg}\\min_{\\omega_2\\in\\Omega_2}U(\\omega_2,x_2^{(t+1)}))\\quad\\text{var #}2\\\\\\]Ici, la solution (le x que l‚Äôon retient) est le x tel que $U_{courant} = min$ Tour statistique : si j‚Äôitere 1million de fois,c‚Äôest sur que j‚Äôai parcouru toutes mes variables‚àû loop Umin pour toutes les variables ... descente Ucourant si Ucourant = Umin conv. or sinon Umin = UcourantNotre algo n‚Äôest PAS une descente, c‚Äôest un optimiseur ! (On cherche minimum global, pas local)\\[P_{T_{\\varnothing}}=\\lim_{T\\to\\infty}P_T\\\\\\]Loi al√©atoire avec une marche uniforme : c‚Äôest le CHAOSComment on choisi $T_0$ ?On prend une grande et une petite valeur de temperature et on fait une dichotomie. On mesure le nombre de fois ou on a monte et descendu en energie, ces mesure doivent etre equivalentes.Si on a une temperature trop faible ?Alors ce n‚Äôest pas une loi uniforme.$‚Äî‚Äì&amp;gt;T$ Plus T √©lev√©e (on va vers la droite) plus on se rapproche d‚Äôune loi uniforme\\[\\begin{matrix}T_{min} &amp;amp;T_{cherche} &amp;amp;T_{max}\\\\&amp;amp;\\equiv&amp;amp;\\\\&amp;amp;\\text{uniforme}&amp;amp;\\end{matrix}\\]Si $T_{min}$ et $T_{max}$ loi uniforme alors on est trop a droite. Inversement, on sera trop √† gauche. On veut donc : $T_{max}$ grand et $T_{min}$ petit mais pas trop.Comment on fait la dichotomie ?Il ne faut pas uniforme ou pas uniforme, il faut du suffisemment uniforme.RecapOn cherche $T_0$ tq $P(T_0)$ suit une loi suffisemment uniformeIl faut donc prendre un $T_{min}$ et $T_{max}$ avec une loi pas uniforme pour le min et uniforme pour le max.On fait donc une dichotomie qui nous ramenera a 2 lois suffisemment uniforme pour trouver le $T_0$Peu de mont√©es par rapport aux descentes √©nerg√©tiques $=$ on convergeSi je n‚Äôarrive pu √† monter alors je suis proche de ma solutionComment on optimise des tirages aleatoires ?Ou\\[i_{\\text{candidat swap }1}\\quad i_{\\text{candidat swap }2}\\] On les precalcule Le precalcul a un biais On va utiliser un tableau circulaire.loop icandidat &amp;lt;- aleatoire C‚Äôest pas possible, on aura des valeurs enormesOn a un tableau de valeurs $x_{candidat}$ de longueur $L$: $\\dots$ $a_i$ $\\dots$ ¬† ¬† ¬† $L$ est tres grand et nombre premierOn va faire un damier, $x^{(t)}=$ $1$ $11$ $2$ $12$ $3$ $13$ $4$ $14$ $5$ $15$ $6$ $16$ $7$ ¬† $8$ ¬† $9$ ¬† $10$ ¬† Par exemple, $4$ depend des valeurs qui l‚Äôentoure: ¬† $11\\updownarrow$ ¬† $13\\leftrightarrow$ $4$ $\\leftrightarrow14$ ¬† $16\\updownarrow$ ¬† \\[P_T(X=x)=\\frac{1}{Z_T}e^{-\\frac{U(x)}{\\color{blue}{T}}}\\] Propriete MarkovienneLa probabilite d‚Äôavoir $X^i=(x_1,\\dots,x_{i-1},x_{i+1},\\dots,x_n) = X\\setminus X_i$\\[P(X_i=x_i\\vert X^i=x^i) = P(X_i=x_i\\vert X_{\\nu_i}=x_{\\nu_i})\\]\\[X_{\\nu_i}=(X_{\\nu_1^i},\\dots,X_{\\nu_w^i})\\] $\\nu_i$: voisinnage de $i$ Le voisinnage d‚Äôun graphe complet d‚Äôun noeud c‚Äôest tous les noeuds sauf lui-meme\\[\\to \\overbrace{X_{t-2}\\to \\underbrace{X_{t-1}\\to X_t}_{P(X_t=x_t\\vert X_{t-1}=x_{t-1})}}^{\\color{blue}{P(X_t\\vert X_{t-2})}}\\]La propri√©t√© Markovienne est √©quivalente √† celle des chaines de Markov\\[\\mathcal N(e)\\text{ verifie}\\begin{cases}e\\not\\in \\mathcal N(e)\\\\e\\in\\mathcal N(e&#39;)\\Rightarrow e&#39;\\in\\mathcal N(e)\\end{cases}\\] CliqueC‚Äôest un ensemble de sommets qui sont voisins soit:\\[E=\\{\\dots e_i\\dots\\}\\begin{cases}E\\neq\\emptyset\\\\\\text{et}\\\\\\forall e,e&#39;\\in E,e\\mathcal N e&#39;\\\\\\text{ou}\\\\\\bar E=1\\end{cases}\\] $e\\mathcal N e‚Äô$: $e$ et $e‚Äô$ sont voisinsE est un ensemble de sommet 2 √† 2 voisinsun singleton est une clique, on dit que c‚Äôest une clique d‚Äôordre 1Une clique d‚Äôordre n c‚Äôest un ensemble de n sommet 2 a 2 voisins4 ord 14 ord 21 ord 3----9Un graphe complet que l‚Äôon reduit aux voisins permet de reduire la dependance des variables.\\[P(X=x)=\\Pi_{\\text{c clique}}\\phi(x_c)\\] $\\phi(x_c)$: fonction potentiel pour la clique $c$Toujours vrai si $\\not\\exists x, P(X=x)=\\varnothing$\\[\\begin{aligned}P(X=x)&amp;amp;=\\frac{1}{Z}e^{-U(x)}\\\\&amp;amp;= \\frac{1}{Z}e^{-\\sum_{c}E_c(x_c)}\\end{aligned}\\] Avec $U_c=\\phi_c$ fonction potentielle pour la clique $c$Modele graphique qui est un champs de Gibbs ? On doit definir les fonctions $U_c$ et $\\phi_c$, avec:\\[U(x)=\\sum_{c}U_c(x_c)\\]$\\bar c$: ordre de la cliqueExempleSur une image en niveau de gris\\[P(X=x\\vert Y=y)=e^{-\\sum_cU_c(x_c,y)}\\]$X_i$ depend de $X_{i+1}$, $X_{i-1}$, $X_{i+nc}$, $X_{i-nc}$Probabilit√© √©quiprobable -&amp;gt; U vaut 0on a une vraissemblance quand on melange X et Y\\(L(X=x_i|Y=y_i) \\text{ proportionnelle √† } e^{-U_{L}(x_i,y_i)}\\)Avec $U_L(‚Ä¶)$ une clique d‚Äôordre 2\\[U(X_i=\\underbrace{x_i}_{\\text{ordre }1})=\\frac{1}{2}\\\\U_1(\\underbrace{\\text{noir}}_{\\text{dans }x})=\\frac{1}{2}\\\\U_1(\\text{blanc})=\\frac{1}{2}\\quad\\forall\\text{ probabilite}\\]\\[U_2(\\underbrace{x_i,x_j}_{\\text{ordre }2} = 1_{x_i\\neq x_j})\\]Avec $i$ et $j$: voisins independantsDefinissons $U_L$\\[U_L(x_i,y_i) = \\begin{cases}255-y_i&amp;amp;\\text{si } x_i=\\text{blanc et } j\\text{ voisins et inde}\\\\y_i&amp;amp;\\text{sinon}\\end{cases}\\]Tadaaa commande magique :clap: :clap: :cake: :cactus: :call_me_hand: :jack_o_lantern: :cat: :heart:\\[\\begin{aligned}U(x,y)&amp;amp;=\\sum_cU_c(x_c,y)\\\\&amp;amp;=\\sum_iU_1(x_i)+\\overbrace{\\sum_{i,j_{voisins}}U_2(x_i,x_j)}^{\\sum_i\\sum_{j\\in\\mathcal N(i)}U_2(x_i,x_j)}+\\sum_iU_2(x_i,y_i)\\\\&amp;amp;= \\sum_i\\biggr(\\overbrace{U_2(x_i,y_i)}^{\\color{blue}{L(X\\vert Y)}}+\\overbrace{\\underbrace{U_1(x_i)}_{\\text{ordre } 1}+\\underbrace{\\sum_{j\\in\\mathbb N(i)}U_2(x_i,x_i)}_{\\text{ordre } 2}}^{P_{(\\text{a priori})}}\\biggr)\\\\\\Rightarrow U(x,y)&amp;amp;=\\sum_iU_i(x_i,x_{\\nu_i},y_i)\\end{aligned}\\]Les √©nergies sont li√©es au proba P appriori = P sachant ‚Ä¶Produit de P = Somme U (Car exp)" }, { "title": "PRSTA: TD 2", "url": "/cours/posts/prsta_td2/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-29 15:00:00 +0200", "snippet": "Lien de la note HackmdExercice 9On etudie une grandeur suivant une loi normale $\\mathcal N (m, 1)$. Nous disposons de deux observations issues de variables aleatoires independantes $X_1$ et $X_2$ et souhaitons tester $H_0 : m = 0$ contre $H_1 : m = 1$ et prendre une decision avec un risque de premiere espece $\\alpha = 5\\%$. Considerons la regle de de decision : Rejeter $H_0$ si $X_1 + X_2 \\gt k$. Quelle loi suit $X_1 + X_2$ sous l‚Äôhypothese $H_0$ ? En deduire la valeur de $k$ sachant que $\\alpha = 5\\%$. Determiner la region critique du test et representer la graphiquement. Calculer le risque de seconde espece $\\beta$ et la puissance du test. Considerons un autre test defini par la regle de decision : Rejeter $H_0$ si $\\min(X_1, X_2) \\gt l$. D¬¥eterminer la valeur l sachant que $\\alpha = 5\\%$. D¬¥eterminer la region critique et representer la graphiquement. Calculer le risque de seconde espece $\\beta$ et la puissance du test. Solution 1. $X_1$ suit $\\mathcal N(m,1)$ et $X_2$ suit $\\mathcal N(m,1)$, on a $X_1$ ind√©pendant √† $X_2$ donc $X_1 + X_2$ suit $\\mathcal N(2m,2)$. 2.\\[\\alpha=P(\\underbrace{\\text{rejeter } H_0}_{\\color{red}{X_1+X_2\\gt k}} \\vert \\underbrace{H_{0} \\text{ vraie}}_{\\color{red}{X_1+X_2\\sim\\mathcal N(2m,2)}})\\\\\\color{red}{\\begin{aligned}V(X_1+X_2) &amp;amp;= E((X_1+X_2)^2)\\\\&amp;amp;= E(X_1^2)+E(X_2^2) + 2E(X_1X_2)\\\\&amp;amp;= \\color{black}{\\boxed{\\color{red}{2}}} + \\underbrace{2E(X_1)E(X_2)}_{\\color{black}{=0}}\\end{aligned}}\\] \\[\\color{red}{\\begin{aligned}\\alpha&amp;amp;= P(\\text{rejeter } H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(X_1+X_2\\gt k\\vert X_1+X_2\\sim\\mathcal N(0,2))\\\\&amp;amp;= P(\\frac{X_1+X_2}{\\sqrt{2}}\\gt\\frac{k}{\\sqrt{2}}\\vert X_1+X_2\\sim\\mathcal N(0,2))\\end{aligned}}\\] Sous l‚Äôhypothese $(H_0)$\\[\\frac{X_1+X_2}{\\sqrt{2}}\\sim\\mathcal N(0,1)\\\\0,05 =\\alpha=P(U\\gt\\frac{k}{\\sqrt{2}})\\]\\[\\frac{k}{\\sqrt(2)} = 1.64 \\text{ (par la table normale on cherche 0.95)} \\\\\\text{Donc, } k = 2.32\\] 3. On cherche la r√©gion critique tq on rejette $H_0$ soit $X_1 + X_2 \\gt 2.32$\\[\\{(x_1,x_2)\\in\\mathbb R^2\\vert x_1+x_2\\gt 2.32\\}\\] Qu‚Äôest-ce qu‚Äôon fait en premier ? On ouvre Geogebra xdd Comme en ocvx, on trace eq1: $x_1 + x_2 - 2.32 = 0$ 4. Rappel : Risque de second espece : $H_1$ soit vrai alors qu‚Äôon garde $H_0$On veut donc $X_1 + X_2 \\le k = 2.32$ et $X_1$ et $X_2$ suivent $\\mathcal N(m=1,1)$On cherche donc $\\beta = P(\\text{accepter} H_0 | H_1 vraie)$ \\(\\beta = P(X_1+X_2\\le k\\vert m=1)\\\\\\frac{X_1+X_2-2}{\\sqrt{2}}\\sim\\mathcal N(0,1)\\quad\\text{sou l&#39;hypothese } H_1\\)\\(\\begin{aligned}\\beta&amp;amp;=P(U\\le\\frac{k-2}{\\sqrt{2}})\\\\&amp;amp;=P(U\\le0.23)\\\\&amp;amp;=0.59\\end{aligned}\\\\\\color{green}{\\boxed{\\beta\\simeq 0.59}}\\) On a fait une erreur majeure du point de vue modelisation: on a prit un $\\alpha$ trop petit La puissance de test est $1-0.59=\\boxed{0.41}$ 2√®me partie 1.\\(\\begin{aligned}\\alpha&amp;amp;=P(\\text{rejeter } H_0\\vert H_0\\text{ vraie})\\\\&amp;amp;= P(\\min(X_1,X_2)\\gt l\\vert m=0)\\\\&amp;amp;= P(\\{X_1\\gt l\\}\\cap\\{X_1\\gt l\\}\\vert m=0)\\\\&amp;amp;= P(U\\gt l)^2 \\quad\\text{ou } U\\sim\\mathcal N(0,1)\\text{ car } X_1 \\text{ et } X_2\\sim\\mathcal N(0,1)\\end{aligned}\\\\\\color{red}{0.05 = P(U\\gt l)^2\\\\P(U\\gt l)=\\sqrt{0.05}\\simeq 0.22}\\) Donc, d‚Äôapres la table:\\[l\\simeq0.77\\] 2.\\[\\{(X_1,X_2)\\in\\mathbb R^2\\vert\\min(X_1,X_2)\\gt 0.77\\}\\] 3. On a un probleme: $P(\\min(X_1,X_2)\\le l)$\\[\\begin{aligned}\\beta&amp;amp;= P(\\text{Accepter }H_0\\vert H_1\\text{ vraie})\\\\&amp;amp;= P(\\min(X_1,X_2)\\le l\\vert H_1\\text{ vraie})\\\\&amp;amp;= 1-P(\\min(X_1,X_2)\\gt l\\vert H_1\\text{ vraie})\\end{aligned}\\]\\[color{red}{\\begin{aligned}\\beta&amp;amp;= 1-P(\\{X_1\\gt l\\}\\cap \\{X_2\\gt l\\}\\vert H_1\\text{ vraie})\\\\&amp;amp;= 1-P(X_1\\gt l\\vert H_1\\text{ vraie})^2\\quad X_1\\text{ et } X_2 \\sim\\mathcal N(1,1)\\end{aligned}}\\] Sous $(H_1)$, $X_1$ et $X_2$ suivent une loi $\\mathcal N(1,1)$ Donc $U=X_1-1\\sim\\mathcal N(0,1)$ sous $(H_1)$ \\(\\begin{aligned}\\beta &amp;amp;=1-P(X_1-1\\gt 0.77-1)^2\\\\&amp;amp;= 1-P(U\\gt -0.23)^2\\\\&amp;amp;\\simeq 1-0.59^2\\\\&amp;amp;\\simeq 0.65\\end{aligned}\\)La puissance du test est $1-\\beta = 1 - 0.65 = \\boxed{0.35}$" }, { "title": "PRSTA: Seance 2", "url": "/cours/posts/prsta_seance2/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-29 14:30:00 +0200", "snippet": "Lien de la note Hackmd Regle d‚ÄôechantillonA partir de nos observations, on decide si on rejette l‚Äôhypothese nulle ou nonRetour de la taille des epiteens: on rejette cette hypothese s‚Äôil y a un eleve qui fait plus de $1m70$. Risque de premiere espece$H_0$ soit vrai Risque de second espece$H_1$ soit vrai alors qu‚Äôon garde $H_0$Types de test test parametriqueon-parametrique test d‚Äôadequation test de comparaison Si l‚Äôhypothese nulle n‚Äôest pas rejetee: Elle n‚Äôest pas demontree pour autant Elle n‚Äôest pas contredite par les faits Test de comparaison d‚Äôune proportion Meme principe pour $n$ grand\\[\\sqrt{n}\\frac{\\hat p-p_0}{\\sqrt{p_0(1-p_0)}}\\]Test du rapport de vraisemblance $H_0:\\theta=\\theta_0$ contre $H_1:\\theta=\\theta_1$ $\\theta_0\\lt\\theta_1$Test de vraissemblance qui est le plus puissant\\[T=\\frac{L(X_1,...,X_n, \\theta_1)}{L(X_1,...,X_n, \\theta_0)}\\] Rejet de $(H_0)$ ssi $T\\gt S_{\\alpha}$, ou $S_{\\alpha}$ est un seuil qui depend du niveau de confiance $\\alpha$Example $X_i$ Poisson de parametre $\\lambda$ $H_0:\\lambda=\\lambda_0$ contre $H_1:\\lambda=\\lambda_1$ $\\lambda_0\\le\\lambda_1$Rejet de $H_0$ si\\[\\frac{\\Pi_{i=1}^ne^{-\\lambda_1}\\frac{\\lambda_1^{X_i}}{X_i!}}{\\Pi_{i=1}^ne^{-\\lambda_0}\\frac{\\lambda_0^{X_i}}{X_i!}}\\gt S_{\\alpha}\\\\-n(\\lambda_1-\\lambda_0)+\\sum_{i=1}^nX_i(\\log(\\lambda_1)-\\log(\\lambda_2))\\gt\\log S_{\\alpha}\\\\\\sum_{i=1}^nX_i(\\log(\\lambda_1)-\\log(\\lambda_0))\\gt \\log(S_{\\alpha})+n(\\lambda_1-\\lambda_0)\\\\\\sum_{i=1}^nX_i\\gt\\underbrace{\\frac{\\log(S_{\\alpha})+n(\\lambda_1-\\lambda_0)}{(\\log(\\lambda_1)-\\log(\\lambda_0))}}_{\\color{blue}{n\\alpha}}\\]Rejet de $H_0$ si $\\sum_{i=1}^n{x_i} &amp;gt; \\nu_{\\alpha}$Exemple: $n=2$, $\\lambda_1=1$, $\\lambda_2=2$, $\\alpha=0,05$ Sous $H_0$, $Y=X_1+X_2$ suit une loi $\\mathcal P(2)$ Si $\\mu_{\\alpha}\\in]0;1]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y=0)\\simeq 0.865$Suite de l‚Äôexemple precedent Rappel : fonction caract√©rique (SAVOIR FAIRE) d‚Äôune loi X est $\\phi(t) = E(e^{itX})$ Pour une loi de Poisson, $P(X=k) = \\frac{\\lambda^k}{k!}e^{-\\lambda}$ \\[\\begin{aligned}\\phi_x(t)&amp;amp;=\\sum_{k\\ge0}e^{itk}P(X=k)\\\\&amp;amp;= \\sum_{k\\ge 0}e^{itk}e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\&amp;amp;= e^{-\\lambda}\\sum_{k\\ge 0}\\frac{(\\lambda e^{it})^k}{k!} \\text{ : serie}\\\\&amp;amp;=e^{-\\lambda}e^{\\lambda e^{it}}\\end{aligned}\\\\\\color{red}{\\boxed{\\phi_x(t)=e^{\\lambda (e^{it}-1)}}}\\]Loi de $X_1+X_2$ ?\\[\\phi_{X_1+X_2}=\\phi_{X_1}(t)\\phi_{X_2}(t)\\]car $X_1$ et $X_2$ sont independantesOr $X_1$ et $X_2$ m√™me loi donc m√™me fonction caract√©rique, donc:\\(\\begin{aligned}\\phi_{X_1+X_2}&amp;amp;=\\phi_{X_1}(t)^2\\\\&amp;amp;=e^{(e^{it}-1)^2}\\\\&amp;amp;= e^{2(e^{it}-1)}\\end{aligned}\\) Continuer jusqu‚Äôa la premiere valeur inferieure a $0.05$ Si $\\mu_{\\alpha}\\in]3;4]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y\\le 3)\\simeq 0.0527$ donc $\\alpha=0.0527$ Si $\\mu_{\\alpha}\\in]4;5]$, $\\mathbb P(X_1+X_2\\gt\\mu_{\\alpha})=1-\\mathbb P(Y\\le 3)\\simeq 0.0166$ donc $\\alpha=0.0166$ Test le plus puissant de risque $\\alpha \\le 0.05$: rejet de $H_0$ si $x_1 + x_2 &amp;gt; 5$Exemple $H_0:m=m_0$ contre $H_1:m=m_1$ ou $X$ suit une loi $\\mathcal N(m,1)$ et $m_0\\le m_1$ A. N.: $m_0=1$ et $m_1=2$ Calculer $\\alpha$ Calculer $\\beta$A RENDRE 1er et 2eme EXO DE REFLEXION (moodle)" }, { "title": "RVAU: Moteur 3D", "url": "/cours/posts/rvau_moteur_3d/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 11:15:00 +0200", "snippet": "Lien de la note HackmdQu‚Äôest-ce qu‚Äôun moteur 3D ? Un logiciel qui permet de modeler un environnement 3DPermet de representer un environnement avec les interactions physiqueMoteur 3D Scene Objets Cameras Lumieres etc Graphe de scene: Pour manipuler les objets 3D de la scene Utilise une API 3D bas niveau ComposantsEditeur Editeur/environnement de developpementImport de modeles 3D C‚Äôest la jungle pour les extensions de format 3D Differentiation entre les formats 3D Infographie 3D CAOModelisation CAO Operations parametriques Extrusion Revolution Conge Chanfrein Operations booleennes Geometrie de constructions de solides (CSG) Tesselation Creation d‚Äôun maillage: passage d‚Äôun modele CAO a un modele trianguleImports de modeles 3D Import de modeles tessellesPour unity: Autodesk FBX .fbx Collada .dae Wavefront .obj Autodesk 3DS .3ds AutoCAD Drawig eXchange Format .dxfExemples de moteurs 3DUnityProjet Assets ProjectSettingsHierarchy Gestion du graphe de sceneGameObject Transform Ensemble de composantsComposant Derive de la classe MonoBehaviourMonobehavior Functions callback Start() Update() FixedUpdate() LateUpdate() OnGUI() Tous les appels dedies a l‚Äôinterface graphique/affichage C‚Äôest du mono-threadDocumentation UnityAssets Store" }, { "title": "RVAU: Collaboration en RV chez EDF", "url": "/cours/posts/rvau_collaboration_edf/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 11:00:00 +0200", "snippet": "Lien de la note HackmdCommuniquer en RVLe but: visualiser une maquette Chaque personne a sa position autour de la table Maquette tournante sur la table Chaque utilisateur puisse le voir sous tout ses angles Un pointeur par utilisateurs Collaboration asymetrique Une personne imergee avec son casque Une personne exterieure sur une tablette Z-space: ecran stereo (3D) Stylet permet d‚Äôinteragir Position Orientation La personne portant le casque peut voir ce qui est pointe par la personne sur la tabletteIndy: chasse au tresor virtuelle et collaborative dans un batiment reacteurPour former les jeunes embauches, leur apprendre a: se deplacer dans le batiment communiquer avec les autresPrincipes de conception Collaboration Gamification Entrainement a la navigation spatialeCollaborationDeux roles parmis les apprenants: radio chasseursChasse au tresor 1 formateur 12 stagiaires repartis en 4 equipes Le formateur cree la chasse Interface pour selectionner le point de depart Type de chasse Pointage d‚Äôun equipement (ex: trouver un equipement particulier) Presence dans une zone (ex: trouver la sortie) Les stagiaires preparent la chasse Ils se regroupent sur le PC du radio La chasse chasseurs immerges et radio a cote POV du radio Plan 2D Possibilite de passer dans la 3D Quand le radio est en 3D, il peut voir l‚Äôavatar des autres mais ne peut pas etre vu Il doit etre capable de verbaliser les instructions Le formateur voit les positions de toute le monde Les chasseurs pointent l‚Äôobjectif Fin de la chasse DebriefingRevue collaborative ne realite augmentee d‚Äôune preparation de chantierVisualisation de la maquette: Possibilite de changer l‚Äôechelle Position de l‚Äôautre utilisateur avec un cube sur sa teteLa Smart Home en RV mobile:::infoAffichage centralise et partage entre plusieur peersonnes dans le cadre de la Smart Home sur smartphone:::Generalisable: Creer, visualiser et partager des annotations contextualisees/geolocalisees comme des signes d‚Äôavertissement, communication, historique d‚Äôevenements‚Ä¶ Pour batiments tertiaires ou industriels pour la conduite et la maintenance ou encore des lieux urbains Utilisation des librairies natives sur smart phone" }, { "title": "RVAU: Collaboration en Realite Virtuelle", "url": "/cours/posts/rvau_collaboration_vr/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-29 09:00:00 +0200", "snippet": "Lien de la note HackmdCollaborationCe n‚Äôest pas necessairement au sens d‚Äôun jeu, c‚Äôest le fait d‚Äôetre a plusieurs dans un environnement virtuel.Pourquoi la collaboration ? Nous sommes des animaux sociauxEnvironnement virtuel collaboratif ‚ÄúLes environnements virtuel collaboratifs (CVEs) sont des systemes distribues de realite virtuelle qui offrent des univers graphiques numeriques potentiellement infinis. Au sein de ces univers, les utilisateurs peuvent partager des informations‚ÄùRappel: projectionIl faut voir ces systemes comme un trompe-l‚ÄôoeilCollaboration avec projectionCollaboration avec projection ?Du point de vue d‚Äôune personne:Du point de vue d‚Äôune seconde personne: On souhaite une projection pour chaque personneProjection pour 6 personnes: Possible grace a un affichage 360 Hz 60 Hz par personne Pour notre bus, cela permettrait de ne pas le voir deformeePour une personne exterieur, ca donne ca: On voit 12 images differrents en meme temps Problemes: Collisions Occultations Collaboration avec casques de RVModes de collaboration Collaboration co-localisee Collaboration distante Deux modes differentiables: Mode ‚Äúcoherent‚Äù Utilise quand on est sur place Mode ‚Äúindividuel‚Äù Chacun a son propre referentiel Collaboration co-localisee ‚Äúcoherente‚ÄùExemple: Paint 3D Besion d‚Äôun referentiel commun Systeme de tracking Detection de marqueur Collaboration en realite augmentee Soit on importe les personnes physiques dans le monde virtuel, soit on importe les elements virtuels dans le monde physiqueMetaphores d‚ÄôinteractionManipuler un objet a plusieurs ? Si une personne manipule un objet, personne ne peut manipuler cet objetUn objet est trop lourd, il faut qu‚Äôil soit deplacer par 2 personnesManipulation collaborative Faire la moyenne Manipulation conjointe Separation des degres de liberte Une personne manipule que la rotation Une personne manipule que le deplacement Translation et rotation a partir de la translation de 2 utilisateursNavigation collaborative En general, chacun se deplace separement Une personne dirige tout le groupeCollaboration asymetrique Asymmetry in scale Asymmetry in visualisation Asymmetry in interaction Modele en 5 dimensions pour modeliser ces interactions:Exemples:CommunicationConscience des autres utilisateurs Ou sont-ils ? Qui sont-ils ? Que font-ils ? Que regardent-ils ? Me regardent-ils ? Peuvent-ils voir ce que je leur montre ?PointageAnnotationsExempleVideoTelepresence Ce genre de problemes devient vite compliqueSi une personne est face a nous, on veut qu‚Äôelle nous regarde et pas a coteCapture de mouvement Communication non verbaleRV socialeFaceDisplayFacebook Social VR Demo" }, { "title": "EPIQUANTI : Qubits", "url": "/cours/posts/epiquanti_qubits/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-09-28 14:00:00 +0200", "snippet": "Lien de la note HackmdLien du livre du profSlide du coursGrotrian diagramQuantum vacuum fluctuationsAccording to quantum field theory and Heisenberg principle, vacuum contains harmonic oscillators with zero-point energy\\[E=\\frac{1}{2}hv\\\\\\Delta E\\cdot\\Delta t\\ge\\frac{h}{2}\\]with electrons/positrons spontaneously cretaed and annilihating, creating photons Feynmann diagram Lamb shift (1947)Energy shift observed between 2 levels hyperfine structure in hydrogen atom, explained by quantum vacuum fluctations impacting electronsCasimir effect (1997)Comparing classical and quantum physicsQuantum myths: HistoryEinstein was wrong about quantum mechanics He was a key founder of quantum physics with the photoeletric effect explanation and many other works; he asked the right questions about entanglement in 1935 which are still debatedWerner Heisenberg created his indeterminacy inequality It was created by Earle Hesse Kennard in 1927 and Hermann Weyl in 1928Erwin Schrodinger‚Äôs cat is both dead and alive He wanted to explain that the wave-particle duality didn‚Äôt work at macro scale, thus the cat can‚Äôt be both dead and alive. End of story, but I can elaborate. It‚Äôs a matter of uncertainty origin.Richard Feynmann invented the concept of quantum computing He imagined in 1981 the concept of quantum simulation of quantum physics phenomenon but, before, Yuri Manin invented in 1980 the concept of gate based quantum computing.Young‚Äôs slit experiment was done with electrons in 1927 Peux pas lire ptdrWhat happened during WWII ? La bombe atomiqueLa physique atomique est un champ different de la physique quantique mais on peut expliquer la desintegration du noyau d‚Äôuranium par la physique quantique. Les gens faisant de la physique quantique sont passes sur la physique nucleaire, il y a eu un trou dans la phyisque quantiquePost-WWII 1946-1952: Felix Bloc Sphere 1947-1956: William Shockley John Bardeen Walter Brattain Transistors 1957: John Bardeen, Leon Cooper, John RObert Schrieffer Superconductivity 1953 1960: Gordon Gould, Theodore Maiman, Nikolay Basov 1964: Alexander Prokhorov 1964: Charles Hard Townes 1962-1973: Brian Josephson Josephson effect 1964: John Stewart Bell Bell inaqualities and test 1970: Dieter Zeh Quantum decoherence 1980: Yuri Manin Quantum computing 1980: Tommaso Toffoli Toffoli gate 1981: Richard Feynman Quantum simulator 1982: Alain Aspect$1^{st}$ and $2^{nd}$ quantum revolutions Manipulating groups of quantum particles ($1947-*$) Photons, electrons and atoms interactions Transistors Lasers GPS Photovoltaic cell Atom clocks Medical imaging Digital photography LCD TV quantum dots Manipulating superposition and entanglement and/or individual particles ($1982-*$) Quantum computing Quantum telecommunications Quantum cryptography Quantum sensingSecond quantum revolution 1991: Anton Zellinger Neutrons duality 1992: Arthur Ekert QKD 1993: Umesh Vazirani Quantum complexity 1992: Serge Haroche Quantum decoherence Juan Cirac and Peter Zoller Trapped ions qubits Edward Farhi Adiabatic quantum computing David DiVincenzo Criterium 1997: Nicolas Gisin Non locality 1997 &amp;amp; 2002: Daniel Esteve Superconducting qubits 2001: Hans Briegel MBQC 2011: John Preskill Quantum supremacy concept 2012: D-Wave One First quantum annealing commercial computer 2016: IBM Q First cloud based quantum computer Quantum sensing On n‚Äôen parlera quasiment pas du tout lasers and frequency combs clocks Spectrographs ultra-sound mikes entengled photons radars ultra-sensing imaging cold atomsCapteurs quantiques Nami Entanglement iXblueClassical computing state of the art and limitationsMoore‚Äôs law: dead or alive ?C‚Äôest un papier ecrit par Gordon Moore. Il fait en observation empirique: Faire croitre le nombre de transistors dans une puce de maniere exonentielle Ce n‚Äôest pas une loi mathematique ou physiqueCela mettait la pression sur les constructeurs comme Intel. Elle est applicable aux: processeurs supercalculateurs espaces de stockage En quoi la loi de Moore s‚Äôest arretee ? La puissance d‚Äôhorloges n‚Äôa pas augmente exponentiellement depuis plus de 15 ans C‚Äôest lie a la fin de l‚Äôechelle de Dennard en 2006 L‚Äôenergie utilisee a explose.Pourquoi ? A cause de fuites sur les transistors Ca a fini sur le dark siliconA cause de ce mecanisme, on ne peut pas utiliser toute la surface d‚Äôun processeur de serveur sinon il va fondre.Comment on fait pour tout utiliser en entier ? Avec un isolant ?Avec un refroidissement ?CMOS technical challenges Extreme ultra violet (EUV) for $\\le10$ nm density Heat barrier processor clocks Quantum computingPromis and use casesProbleme intractable: probleme dont le temps de calcul va augmenter de maniere exponentielle avec sa taille. PromesseCertains problemes intractables vont etre solvable dans un temps humainement raisonable. Transports et logisitiques Healthcare Energy and materials Finance and insurance DefenseDifference Bits and QubitsFrom quantum physics to qubits wave function describes particles properties probabilities quantization discrete levels of wave functions, like energy, polarity, spin superposition linear combination of quantized states entanglement quantum objects correlated states, consequence of linear superposition of multiple quantum objects wave function &amp;amp; quantization: 2 levels of quantum objectsFrom computing to measurement Quantum gates actions on qubits and their superposed states Computational basis state vector:\\[\\begin{matrix}\\text{complex amplitude} &amp;amp;\\text{of all combinations of } 0 \\text{ and } 1\\\\\\begin{bmatrix}\\alpha_1\\\\\\vdots\\\\\\alpha_2N\\end{bmatrix} &amp;amp;\\begin{matrix}\\vert 00\\dots00\\rangle\\\\\\vdots\\\\\\vert 10\\dots01\\rangle\\\\\\vdots\\\\\\vert 11\\dots11\\rangle\\end{matrix}\\end{matrix}\\] $N$ qubits registers information in $2^N$ superposed state Qubits can‚Äôt be independently copied\\[\\sum_{i=1}^{2^N}\\alpha_i^2=1\\]handles $2^{N+1}-1$ real numbers measurement Ends superposition and entanglement outputs $N$ probabilistic classical bits computing has to be run many times and results average Adressing the noise challenge decoherence progressively ends superposition and entanglement coherence times between $100\\mu s$ and a couple seconds errors significant during computing $0.1\\%$ to $8\\%$ error rates per gate and for qubits readouts erros correction requires a very large number of additional qubits $1-100$ to $1-10000$ ratio between logical and physical qubits scalability challenges aulity qubits, cabling, control electronics, cryogenics abd energetics engineering Distributed quantum computing ?Complex numbers and phase $r$: amplitude, modulus, norm $\\theta$: phase angleEuler formula:\\[e^{i\\theta}=\\cos\\theta+\\sin\\theta\\]Phase angles add upqubit Bloch sphere representation Opposite vectors in sphere are mathematically orthogonal$\\alpha$ and $\\beta$ are complex numbers altitudes:\\[\\vert\\Psi\\rangle=\\alpha\\vert0\\rangle+\\beta\\vert1\\rangle\\]Probabilities and Born normalization constraint:\\(\\alpha+\\beta=1\\)Using polar coordinates $\\theta$ and $\\phi$ and no global phase:\\(\\vert\\Psi\\rangle=\\cos\\frac{\\theta}{2}\\vert0\\rangle+\\sin\\frac{\\theta}{2}e^{i\\phi}\\vert1\\rangle\\)Euler formula:\\(e^{i\\phi}=\\cos\\phi+i\\sin\\phi\\)Alternate ‚Äúsymetric‚Äù version with a global phase of $e^{-\\frac{i\\phi}{2}}$\\(\\vert\\Psi\\rangle=\\cos\\frac{\\theta}{2}e^{\\frac{-i\\phi}{2}}\\vert0\\rangle+\\sin\\frac{\\theta}{2}e^{\\frac{i\\phi}{2}}\\vert1\\rangle\\)The global phase doen‚Äôt change the probabilities $\\vert\\alpha\\vert^2$ and $\\vert\\beta\\vert^2$ for measurementOther representationsPoincare‚Äôs sphere:Linear algebra 101\\[f(\\lambda)\\]Vectors Dirac notation:\\[\\vert\\Psi\\rangle = \\begin{bmatrix}\\alpha \\\\ \\beta\\end{bmatrix} \\quad\\Psi\\text{ ket}\\\\\\bar\\alpha =\\alpha*\\quad\\langle\\Psi\\vert=[\\bar\\alpha,\\bar\\beta]\\quad\\psi\\text{ bra}\\]Bra-ket:\\[\\langle\\Psi_1\\vert\\Psi_2\\rangle=[\\bar\\alpha_1,\\beta_1]\\times\\begin{bmatrix}\\alpha_2 \\\\ \\beta_2\\end{bmatrix}\\]How to read that ?\\(\\langle\\Psi\\vert A\\vert\\phi\\rangle\\)Average valye in $\\Psi$ of the value\\[A^{‚úû}=(A^T)*\\underbrace{A^*}_{\\text{matrix conjugate}}+\\overbrace{A^T}^{\\text{matrix transpose}}\\Rightarrow \\begin{bmatrix}a &amp;amp;b \\\\ c&amp;amp;d \\end{bmatrix}^‚úû\\]\\[\\vert\\Psi\\rangle = \\bigotimes_{n=1}^N\\vert i\\rangle\\]" }, { "title": "OCVX2: Optimisation sous contrainte par la methode des multiplicateurs de Lagrangre et conditions KKT", "url": "/cours/posts/ocvx2_kkt_lagrange/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-27 16:00:00 +0200", "snippet": "Lien de la note Hackmd KKT: Karush-Kuhn-TuckerOn va s‚Äôattaquer a des problemes de la forme:\\[\\begin{matrix}&amp;amp;\\text{minimiser } f(x) &amp;amp;f:\\mathbb R^n\\to\\mathbb R &amp;amp;f\\text{ convexe}\\\\&amp;amp;x\\in C &amp;amp;x\\in\\mathbb R^n &amp;amp;C=\\text{ensemble convexe}\\end{matrix}\\]\\[x\\in C\\Leftrightarrow\\begin{cases}g_i(x)\\le 0 &amp;amp;\\forall i=1,\\dots,m&amp;amp;g_i\\text{ convexe}\\\\h_j(x)=0 &amp;amp;\\forall j=1,\\dots,p&amp;amp;h_j\\text{ affine}\\end{cases}\\]$C$ defini l‚Äôensemble des points admissibles.\\[\\boxed{\\begin{matrix}&amp;amp;\\text{minimiser } f(x) &amp;amp;\\text{equivalent a} &amp;amp;\\text{minimiser } f(x), x\\in\\mathbb R^n\\\\&amp;amp;x\\in C &amp;amp; &amp;amp;\\text{tq} \\begin{cases}g_i(x)\\le 0 &amp;amp;\\forall i=1,\\dots,n\\\\h_j(x)=0&amp;amp;\\forall j=1,\\dots,p\\end{cases}\\end{matrix}\\\\\\color{red}{\\text{(OPT)}}}\\] valeur optimale $p^{*}=f(x^{*})$ point optimal $x^{*}\\in\\mathbb R^n$Sans contrainte: $f$ convexe: $x^{*}$ optimal $\\Leftrightarrow\\nabla f(x^{*})=0$ Cette conditions d‚Äôoptimalite n‚Äôest plus vraie des lors que l‚Äôon a des contraintes. Dualite de Lagrange LagrangienOn definit le Lagrangien de (OPT) comme la fonction:\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta) = f(x)+\\sum_{i=1}^m\\alpha_ig_i(x)+\\sum_{j=1}^p\\beta_jh_j(x)\\end{aligned}\\\\\\begin{aligned}&amp;amp;\\text{variables duales}\\begin{cases}\\alpha=\\begin{pmatrix}\\alpha_1\\\\\\vdots\\\\\\alpha_m\\end{pmatrix}\\in\\mathbb R^m\\\\\\beta=\\begin{pmatrix}\\beta_1\\\\\\vdots\\\\\\beta_p\\end{pmatrix}\\in\\mathbb R^p\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\text{multiplications de Lagrange}\\\\&amp;amp;\\Leftrightarrow\\text{cout associe a chaque contrainte}\\end{aligned}\\] Lagrangien $\\equiv$ version sans contrainte du probleme (OPT)IntuitionIntuition: pour chaque probleme d‚Äôoptimisation avec contraintes, il existe un certain parametrage des variables duales tel que le minimum sans contrainte du Lagrangien par rapport a la variable primale $\\equiv x$ (a variables duales fixees) coincide avec la solution du probleme de contraintes.On appelle fonction objective primale\\[\\begin{aligned}\\theta_p:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\end{aligned}\\]On appelle probleme primal le probleme d‚Äôoptimisation sans contrainte: \\(\\min_{x\\in\\mathbb R^n}\\theta_{p}(x)\\)$x\\in\\mathbb R^n$ est primal admissible ssi\\[\\begin{cases}g_i(x)\\le 0&amp;amp;\\forall i\\\\h_j(x)=0 &amp;amp;\\forall j\\end{cases}\\] On va noter $p^{*}$ la valeur optimale de $(P)$ et $x^{*}$ le point optimal, $p^{*}=\\theta_{p}(x^{*})$On appelle fonction objective duale:\\[\\begin{aligned}\\theta_D:\\mathbb R^m\\times\\mathbb R^p&amp;amp;\\to\\mathbb R\\\\(\\alpha,\\beta)&amp;amp;\\mapsto\\min_{x\\in\\mathbb R^n}\\mathscr L(x,\\alpha,\\beta)\\end{aligned}\\]On appelle probleme dual le probleme d‚Äôoptimisation avec contrainte\\[(D)\\quad \\max_{\\alpha,\\beta \\\\ \\alpha_i\\ge 0}\\theta_D(\\alpha, \\beta) = \\max_{\\alpha, \\beta \\\\ \\alpha_i\\ge 0}\\min_{x}\\mathscr L(x,\\alpha, \\beta)\\]$(\\alpha,\\beta)$ est dual admissible ssi $\\alpha_i\\ge0$ $\\forall i$.On note egalement $(\\alpha^{*}, \\beta^{*})$ la solution de $(D)$ et $d^{*} = \\theta_D(\\alpha^{*}, \\beta^{*})$Interpretation du probleme primalDans le cas ou on a $g(x)\\le0$ convexe et $h(x)=0$ affine.Dans ce cas, le Lagrange est:\\[\\begin{aligned}\\mathscr L:\\mathbb R^n\\times\\mathbb R\\times\\mathbb R&amp;amp;\\to\\mathbb R\\\\(x,\\alpha,\\beta)&amp;amp;\\mapsto\\mathscr L(x,\\alpha,\\beta)=f(x)+\\alpha g(x)+\\beta h(x)\\end{aligned}\\]On a:\\[\\begin{aligned}\\theta_p:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\end{aligned}\\]Dans ce cas:\\[\\begin{aligned}x&amp;amp;\\mapsto \\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0\\forall i} \\mathscr L(x,\\alpha, \\beta)\\\\\\theta_{p}(x) &amp;amp;= \\max_{\\alpha, \\beta \\\\ \\alpha\\ge 0}[f(x)+\\alpha g(x)+\\beta h(x)]\\end{aligned}\\] $\\theta_p(x)$ est convexe car la somme ponderee de fonctions convexes est convexe, et le $\\max$ de fonctions convexes est convexe.\\[\\theta_p(x) = f(x)+\\max_{\\alpha,\\beta \\\\ \\alpha\\ge 0}[\\alpha g(x) + \\beta h(x)]\\] Si $g(x)\\gt 0$, le crochet est maximise pour $\\alpha=+\\infty$ et vaut $+\\infty$ Si $g(x)\\le 0$, le crochet est maximise pour $\\alpha=0$ Si $h(x)\\neq 0$, le crochet est maximiser pour $\\beta=(\\text{signe de }h(x))\\infty$ et vaut $+\\infty$ Si $h(x)=0$, le crochet vaut $0$ peu importe la valeur de $\\beta$ Donc si $x$ primal admissible $(g(x) \\le 0$ et $h(x)=0)$, alors le crochet vaut $0$. Si $x$ ne verifie pas les contraintes, alors le crochet vaut $+\\infty$.\\[\\theta_p(x)=f(x)+\\begin{cases}0 &amp;amp;\\text{si } x \\text{ primal admissible}\\\\+\\infty &amp;amp;\\text{si } x \\text{ pas primal admissible}\\end{cases}\\\\\\]\\[\\begin{aligned}(P):\\quad&amp;amp;\\min_{x\\in\\mathbb R^n}\\theta_p(x)\\\\&amp;amp;\\min_{x\\in\\mathbb R^n}f(x)+\\begin{cases}0 &amp;amp;\\text{si } x \\text{ primal admissible}\\\\+\\infty &amp;amp;\\text{si } x \\text{ pas primal admissible}\\end{cases}\\end{aligned}\\]" }, { "title": "OCVX2: Approche lineaire", "url": "/cours/posts/ocvx2_approche_lineaire/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-27 14:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1On considere la fonction differentiable\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto 3x^2+y^2\\end{aligned}\\] Representer les courbes de niveaux 2 et 4 de $f$ dans le plan euclidien A quel lieu correspond la condition $f(x,y)\\le4$ On s‚Äôinteresse au probleme d‚Äôoptimisation $(P)$ minimiser $f_0(x,y)=2x+y$ sujet a $3x^2+y^2\\le4$. Representer la courbe de niveau de la fonction objectif qui correspond a la valeur optimale de $(P)$ Comment trouver le point optimal correspondant a $(P)$? Faire le calcul Solution 1.\\[f(x,y)=3x^2+y^2\\\\\\begin{aligned}\\mathcal C_2&amp;amp;=\\{3x^2+y^2=2\\}\\\\&amp;amp;= \\{\\frac{3}{2}x^2+\\frac{1}{2}y^2=1\\}\\end{aligned}\\] Il s‚Äôagit de l‚Äôequation d‚Äôune elipse de: demi grand axe $a$ demi petit axe $b$ \\[\\biggr(\\frac{x}{a}\\biggr)^2+\\biggr(\\frac{y}{b}\\biggr)^2 =1\\] Rappel\\[2\\pi r\\to\\pi(a+b)\\\\\\pi r^2\\to\\pi a b\\] \\[\\mathcal C_2 (f)=\\{3x^2+y^2=2\\}\\] Ellipse de: demi grand axe $\\sqrt{2}$ sur $O_y$ demi petit axe $\\sqrt{\\frac{2}{3}}$ sur $O_x$ \\[\\mathcal C_4 (f)=\\{3x^2+y^2=4\\}\\] Ellipse de: demi grand axe $2$ sur $O_y$ demi petit axe $\\frac{2}{\\sqrt{3}}$ sur $O_y$ Zoli dessin 2. 3.\\[\\begin{aligned}(P) \\quad\\text{min} f_0(x,y)&amp;amp;=2x+y\\\\3x^2+y^2&amp;amp;\\le4\\Leftrightarrow \\mathcal C_{\\le 4}(f)\\end{aligned}\\]\\[\\mathcal C_0 = \\{2x+y=0\\}\\\\\\vec u=\\binom{-1}{2}\\\\\\vec n=\\binom{2}{1}\\] Pour minimiser, on part dans le sens inverse du vecteur normal. Notre point optimal: $p^{*} = (x^{*}, y^{*})$\\[p*\\in\\mathcal C_4(f)\\Leftrightarrow 3x^{*^2}+y^{*^2}=4\\\\p*\\in\\mathcal C_{f_0^*}\\Leftrightarrow 2x^*+y^*=f_0^*\\] Le gradient d‚Äôune fonction en un point donne est orthogonal a la courbe de niveau qui passe par ce point la. En $p^{*}$:\\[\\nabla \\vec f(p^*) = \\lambda\\vec n\\\\\\nabla \\vec f(p^*) + \\lambda\\vec n = 0\\quad\\lambda \\gt 0\\]\\[f(x,y)=3x^2+y^2\\\\\\nabla f = (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}) = (6x, 2y)\\\\\\begin{aligned}\\nabla f(p^* = (x^*, y^*)) = (6x^*, 2y^*) = \\lambda\\binom{2}{1}&amp;amp;\\Leftrightarrow \\begin{cases}6 x^* = 2\\lambda\\\\2y^* = \\lambda\\end{cases}\\\\&amp;amp;\\Leftrightarrow 6x^* = 4y^*\\\\&amp;amp;\\Leftrightarrow \\color{green}{\\boxed{y^* = \\frac{3}{2}x^*}}\\end{aligned}\\\\\\begin{aligned}3x^{*^2}+y^{*^2} = 4\\Rightarrow 3x^{*^2}+(\\frac{3}{2}x^*)^2&amp;amp;=4\\\\3x^{*^2}+\\frac{9}{4}x^{*^2}&amp;amp;=4\\\\\\frac{21}{4}x^{*^2}&amp;amp;=4\\\\x^{*^2}&amp;amp;=\\frac{16}{21}\\end{aligned}\\] Donc:\\[x^*=\\frac{4}{\\sqrt{21}}\\quad\\text{ou}\\quad\\color{green}{\\boxed{-\\frac{4}{21}}}\\\\\\text{et}\\quad \\color{green}{\\boxed{y^*=-\\frac{6}{\\sqrt{21}}}}\\]Exercice 2On considere le probleme d‚Äôoptimisation $(P)$ minimiser $f_0(x,y)=x+y$ sujet a $x+2y\\le3,x\\in B$ avec $B\\in\\mathbb R^2$ l‚Äôintersection de l‚Äôepigraphe de $x\\mapsto-\\sqrt{x}$. Dessiner le lieu admissible de $(P)$ Representer la courbe de niveau $f_0$ qui realise le minimum de $(P)$ Calculer le point optimal ainsi que la valeur optimale de $(P)$ Solution Rappel: Epigraphe Tout ce qu‚Äôil y a au-dessus du graphe de la fonction\\[\\text{epi}(f) = \\{(x,t)\\vert t\\ge f(x)\\}\\] 1. \\[x+2y-3=0 \\quad (D)\\\\(3,0)\\in D \\\\ \\vec u=\\binom{-2}{1}\\\\\\vec n =\\binom{1}{2}\\] Avec la courbe $\\mathcal C_0$: Avec $p^{*}=(x^{*}, y^{*})$: 2. Le vecteur normal au graphe va etre colineaire au vecteur normal de notre courbe de niveau. Gradient de quoi ? On est sur le graphe et pas la ligne de niveau Est-ce qu‚Äôon peut exprimer le graphe comme ligne de niveau ? Toutes les representations parametriques peuvent s‚Äôecrire en representation implicite (l‚Äôinverse n‚Äôetant pas vrai) Notre graphe de $y\\mapsto-\\sqrt{x}$ est:\\[\\{(x,y) \\text{ tq } y=-\\sqrt{x}\\}\\\\\\{(x,y)\\text{ tq } \\sqrt{x}+y=0\\}\\\\= \\mathcal C_0(g)\\] Avec:\\[\\begin{aligned}g: \\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto \\sqrt{x} + y\\end{aligned}\\] Condition d‚Äôoptimalite: en $p^{*}=(x^{*}, y^{*})$,\\[\\nabla g(p^*) = \\lambda \\vec n_0\\\\\\begin{aligned}\\nabla g(x,y) &amp;amp;= (\\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y})\\\\&amp;amp;= (\\frac{1}{2\\sqrt{x}}, 1)\\end{aligned}\\] En $p^{*}$:\\[\\begin{aligned}&amp;amp;\\begin{cases}\\frac{1}{2\\sqrt{x^*}} = \\lambda\\\\1 = \\lambda\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}\\lambda =1\\\\\\frac{1}{2\\sqrt{x^*}}=1\\\\\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}x^*=\\frac{1}{4}\\\\y^*=-\\frac{1}{2}\\end{cases}\\end{aligned}\\] Valeur optimale:\\[x^* + y^* = \\frac{1}{4}-\\frac{1}{2} = \\color{green}{\\boxed{-\\frac{1}{4}}}\\] " }, { "title": "AN3D: Interpolate position", "url": "/cours/posts/an3d_interpolate_position/", "categories": "Image S9, AN3D", "tags": "Image, S9, AN3D", "date": "2021-09-24 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du profAnimation in Computer Graphics2 main ways to describe animation Kinematics DynamicsWays to genre animation Descriptive animation Motion tracking Procedural generation Physically based simulation Leaning-based synthesisDescriptive Animation The artist/an algorithm fully describes the motion and deformation Pros Cons Full control on the result May introduce un-physical effects History of CG AnimationFirst production of animated films (Disney) Principle Animator in chief: create key frames Assistants: fill the in between (secondary drawings) Principle of Key Framing:Key framing in CG Create manually a set of key frames Interpolate positionsProduction pipeline: Interpolate position Given a set of key positions (pos + time), we want to find an interpolating space-time curve Input: $(p_i, t_i)$Linear Interpolation Pros Cons Simple Non smooth trajectory Constant speed between keyframes Generates straight segments Smooth curve $\\alpha_i$ polynomial basis function of degree $d$Which polynomial/degree choose ?Lagrange polynomial interpolation Interpolate all points at onceDegree of polynomial: $N-1$ Known solution: Lagrange polynomial Comparison En pratique, on n‚Äôutilise jamais cette interpolationSpline Idea Define each part a polynomial Smooth junctions between them How to choose the polynomial Sufficiently high degree to be smooth Sufficiently low degree to avoid oscillations In Graphics, cubic polynomials are often used Allow up to $\\mathcal C^2$ junctions Hermite interpolation Cubic curve interpolationg points and derivatives at extermitiesInterpolating curveInitial problem: set of multiple keyframes position+time2 solutions: Set explicitely derivatives for each keyframe - teadious Compute automatically plausible derivatives from surrounding samples - often usedCardinal spline:Set:\\[d_i=\\mu\\frac{p_{i+1}-p_{i-1}}{t_{i+1}-t_{i-1}}\\] $\\mu$ curve tension $\\in[0,2]$ $\\mu = 1$ is commonly used Catmull Rom Spline Wrap-up algorithmCompute $p(t)$ as a cubic spline interpolation Given keyframes $(p_i, t_i)_{i\\in[0,N-1]}$ Given time $t\\in[t_1,t_{N-2}]$ find $i$ such that $t\\in[t_i,t_{i+1}]$ Compute \\(d_i=\\mu\\frac{p_{i+1}-p_{i-1}}{t_{i+1}-t_{i-1}}\\) and \\(d_{i+1}=\\mu\\frac{p_{i+2}-p_{i}}{t_{i+2}-t_{i}}\\) Compute \\(p(t) = (2s^3-3s^2+1)p_i + (s^3-2s^2+s)d_i + (-2s^3+3s^3)p_{i+1} + (s^3-s^2)d_{i+1}\\) with $s=\\frac{t-t_i}{t_{i+1}-t_i}$ Limitation of cubic curve interpolation Only $\\mathcal C^1$, but not $\\mathcal C^2$ at junctions: curvature/acceleration discontinuity Non-constant peed along each polynomialCurve editing Animation software (Maya, 3DSMax, Blender, etc) always come with a curve editor Artists can manually ajust their position, time, and derivatives on curve editor One curve for each scalar parameter position $(x,t,z)$ scaling $(s_x,s_y,s_z)$ rotation/quaternion Can also use a wrapper function $w$ to change time $p(t) = f(w(t))$Usage of keyframes interpolation Interpolate every vertex of multiple meshesMulti-target blendingInterpolate between multiple key poses Interesting for facial animation Per-vertez formulation $p_i(t)=\\sum_{k}^{N_{poses}}$ Blend shapes\\[p_i(t) = b_i^0 + \\sum_k^{N_{poses}}\\omega_k(t)(\\underbrace{b_{ki}-b_i^0})\\]Physically-based simulationWhen physically based simulation is needed Accurate dynamics Teadious to model by hand or procedurally Multiple interacting elements Complex animated geometry Material model Elasticity Purely elastic models don‚Äôt loose energy when deformed Plasiticity Ductile material: can allow large amout of plastic deformation without breaking (plastic) Brittle - Opposite (glass) Viscosity Resistance to flow (usually for fluid, ex:honey) In reality Elasto-plastic materials Allow elastic behavior for small deformation, and plastic at larger one Visco-elastic materials Elastic properties with delay Rigid spheresSystem modelingParticles modeling the center of hard spheres Spheres can collide with surrounding obstacles Spheres can collide with each othersSystem: $N$ particles with position $p_i$, speed $v_i$, mass $m_i$, modeling a sphere of radius $r_i$ initial conditions: $p_i(0)=p_i^0,v_i(0)=v_i^0$Forces: $F_i=$\\[v^{k+1} = v^k+hg\\\\p^{k+1}=p^j+hv^{k+1}\\]Collision with a planePlane $\\mathcal P$: parameterized using a point $a$ and its normal $n$\\(\\{p\\in\\mathbb R^3\\in\\mathcal P\\Rightarrow (p-1)\\cdot n =0\\}\\) Sphere above plane: $(p_i-1)\\cdot n\\gt r_i$ Sphere in collision: $(p_i-a)\\cdot n\\le r_i$for (int i = 0; i &amp;lt; N; ++i) { float detection = dot(p[i]-a, n); if (detection &amp;lt;= r[i]) { // ... collision response }}Collision response with planeWhat should we do when a collision is detected ? On peut changer la vitesse On decompose la vitesse selon 2 composantes: la tangente et la normale\\[\\vec v\\begin{cases}v_n\\to &amp;amp;-v_n\\\\&amp;amp;+\\\\v_r\\to &amp;amp;v_t\\end{cases}\\\\\\text{composante normale: } (\\vec v\\cdot\\vec n)=v_n\\\\\\text{composante tangente: }\\vec v-v_n\\vec n\\] Collision response = Update speedResult Applying collision response on speed only Les boules tombent en-dessous du plan Quand notre sphere rebondit, il est possible qu‚Äôune partie passe au travers du plan, donc on considere en collision, donc on inverse sa vitesse, donc en collision, etcComment on contre ca ? Si ma sphere est dans le sol, on s‚Äôarrange pour qu‚Äôelle ne soit pas dans le solOn la ‚Äúrepousse‚Äù pour qu‚Äôelle soit en contact avec la surfaceCollision response with a plane: positionThree possibilities: Correct position in projecting on the constraint Pros: simple to implement Cons: Physically incorrect position Approximate the correct position Go backward in time to find exact instant of collision Continuouse collision detectino Pros: physically correct Cons: Computationally heavy Result Ca marche !\\[p_i^{new} = p_i+d_n\\]Collision between speheresGiven 1 spheres $(p_1, v_1, r_2, m_2), (p_2, v_2, r_2, m_2)$Collision when\\[\\Vert p_1-p_2\\Vert\\le r_1+r_2\\]What will happen with speeds ? $v_1\\to v_1^{new}, v_2\\to v_2^{new}$Notion of impulseAn impulse $J$ is the integrted force over time\\[J=\\int_{t_1}^{t_2}F(t)dt\\] Result in a sudden change of speed (momentum) in a discrete caseFor a particle with a constant mass\\[\\int_{t_1}^{t_2} F(t)dt=\\int_{t_1}^{t_2} ma(t)dt\\]2 spheres in collision J‚Äôecris pas ca vous etes fousSummary Detect collision $\\Vert p_1-p_2\\Vert\\le r_1+r_2$ if collision (relative speed$\\gt\\epsilon$) Elastic collision (bouncing) $v_{1/2}=\\alpha v_{1/2}\\pm\\beta \\frac{J}{m_{1/2}}$ If static contact (relative speed $\\le\\epsilon$) Friction $v_{1/2}=\\mu v_{1/2},\\mu\\in[0,1]$ Avoids jittering Correct position (project on contact surface) $p=p+\\frac{d}{2u}$ $d=r_1+r_2-\\Vert p_1-p_2\\Vert$: collision depth For small impacts, can use position based dynamics $v^{new} = \\frac{(p^{new}-p^{prev})}{\\delta t}$ Note on collision stackOptimiser ne pas avoir a simuler les spheres sur le sol et immobiles Faire des graphes des solides et les traiter comme des solides rigidesModeling elastic shapes with particles Spring mass systems Particles: samples on shape Springs: link closed-by particles in the reference shape Spring structureHow to model spring connectivity ? Structutal springs 1-ring neighbors springs ($\\simeq$ mesh edges) Pros: limit elongation/contraction Cons: Allows shearing, and bending Add extra springs connectivity Shearing springs Diagonal links Bending springs 2-ring neighborhood Cloth simulationMass-spring cloth simulation Particles are sampled on a $N\\times N$ grid Each particle has a mass $m$ Set structural, shearing and bending springsForces On each particle: gravity + drag + spring forces\\(F_i(p,v,t)=m_ig-\\underbrace{\\mu v_i(t)}_{\\text{facteur d&#39;attenuation}}+\\sum_{j\\in\\nu_i}K_{ij}(\\Vert p_j(t)-p_i(t)\\Vert-L_{ij}^0)\\frac{p_i(t)-p_i(t)}{\\Vert p_j(t) -p_i(t)\\Vert}\\) $\\nu_i$: neighborhood of particle $i$ $L_{ij}^0$: rest length of spring $ij$Associated ODE\\[\\forall i\\begin{cases}p_i&#39;(t) = v_i(t)\\\\v_i&#39;(t)=F_i(p,v,t)\\end{cases}\\]" }, { "title": "AN3D: Bases du rendu graphique", "url": "/cours/posts/an3d_bases_rendu/", "categories": "Image S9, AN3D", "tags": "Image, S9, AN3D", "date": "2021-09-23 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du profContexteOn a l‚Äôhabitude de voir des models 3D virtuelsConclusion: il est aise de concevoir et animer ses propres modeles 3D FAUX ! Outils: Blender MayaFormation de 3 a 5 ans dans les ecoles d‚Äôinfographie. Le cout/temp passe sur la 3D n‚Äôa jamais ete aussi elevve Films animations/VFX Cout moyen par sequence VFX ($\\lt10s$): 50k$ Cout animation 3D $\\gt$ cout dessin manuel Jeu videos AAA 100M$ 2 a 4 annees de dev Les outils 3D se sont ameliores Mais restent complexes et tres techniques (3 ans d‚Äôetude infographistes) Creation 3DLa quantite et la qualite demande a augmente plus rapidement que les outilsDessins/sculpture a la main restent plus efficace pour le prototypage/designEquipe: Geometric &amp;amp; visual computing Equipe informatique graphique et visionApplicationsDomaine d‚Äôapplications typiques Loisirs &amp;amp; creations artistiques Modelisation &amp;amp; visualisation en Sciences Naturelles Prototypage et fabricationNotre ‚Äúexpertise‚Äù Methode interactive pour l‚Äôaide a la creativite Simulation visuelles Analyses de formes et algorithmiqueAide: stages, emploi, poursuite en Informatique Graphique ?Rem. IG: Domaine technique, R&amp;amp;D avancee Lien fort sujets recherche et entreprise Theses IG - sujets appliques qui interessent les industriesSi le domaine vous interesse: AFIGPlan du cours Introduction et rappels d‚ÄôInfo Graphique Warm-up systeme de particules Animation descriptive Animation physique Animation de personnagesEvaluation Un compte rendu de tp Collision de spheres, tissus, ou personnage articule $\\simeq5$ pages Notre demarche, resultats et analyses Computer graphicsMain subfields Modeling Animation RenderingRepresenting 3D shapes for Graphics Application Computer graphics: mostly focus on representing surfaces Scientific visualization: volume dataSurfacesTwo main rpzRepresentation d‚Äôune sphere:Difficulty of surface representation using function C‚Äôest impossible, la forme est trop complexeObjective of surface representationMain idea: use piecewise approximationIdeal surface representation Approximate well any surface Require few samples Can be rendered efficiently (GPU) Can be manipulated for modelingExample of models: Mesh-based Triangular meshes, polygonal meshes, subdivision surfaces Polynomial Polynomial: bezier, spline NURBS Implicit grid, skeleton based, RBF, MLS Points sets For projective/rasterization render pipeline: always render triangular meshes at the end Pros Cons Simplest representation Requires large number of saples: complex modeling Fit to GPU Graphics render pipeline Tangential discontinuities at edges Mesh encodingExample of 3D Mesh FileAffine transforms and 4D vectors/matricesPerspective matrixPerspective space: allows perspective projection expressed as a matrix.Common constraints (in OpenGL): Wrap the viewing volume (truncated cone with rectangulare basis called frutsum) ($z_{near},z_{far},\\theta$) to a cube $\\theta: view angle$ $p=(x,y,z,1)\\in$ frutsum $\\Rightarrow p‚Äô=(x‚Äô,y‚Äô,z‚Äô,1)\\in[-1,1]^30$ \\[M=\\begin{pmatrix}f&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;f&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;C&amp;amp;D\\\\0&amp;amp;0&amp;amp;-1&amp;amp;0\\end{pmatrix}\\\\f=\\frac{1}{\\tan(\\frac{\\theta}{2})}\\\\L = z_{near}-z_{far}\\\\C= \\frac{z_{far}+z_{near}}{L}\\\\D= \\frac{2z_{far}z_{near}}{L}\\]In practice You must define $z_{near}, z_{far}$ $z_{far}-z_{near}$ should be as small as possible for max depth precsionTo which view space are mapped 3D world space points at $z_{near}, z_{far}$ ?Fractals IdeaRecursively add self-similar details Simple rule $\\to$ complex shape May look like complex natural detailsPerlin noise A widely used noise functionCreer une fonction pseudo-aleatoire continue MAIS deterministeOn prend des echantillons a des valeurs entiere Pour chaque on associe une tangente Utilise une fonction de hash float hash(float n) {return fract(sin(n)*1e4);} Fractal Perlin NoiseOn somme la fonction avec elle-meme en changeant ses parametres\\[g(x)=\\sum_{k=0}^N\\alpha^kf(\\omega^kx)\\] $f$: smooth Perlin noise function $N$: number of Octave $\\alpha$: persistency $\\omega$: frequency gainUsage Material texture Ridge effect Marble effect Animated textures Translation: $f(x,y+t)$ Smooth evolution: $f(x,y,t)$ Moutain-looking terrain $z=f(x,y)$ ApplicationsIn almost any complex shapeExercicePerlin Noise terrain\\[S(u,v)=\\begin{cases}x(u,v)=u\\\\x(u,v)=v\\\\z(u,v)=hg(s(u+o), s(v+o))\\end{cases}\\]The perlin noise\\[g(u,v)=\\sum_{k=0}^N\\alpha^kf(2^ku,2^kv)\\]\\[N=9\\\\\\alpha=0.4\\\\h=0.3\\\\s=1\\\\o=0\\] b: $N$ modifie a: $s$ modifie Les montagnes du fond sont des ‚Äúnouvelles‚Äù montagnes on voit plus loin f: $o$ modifie e: $h$ modifieAnimationReference surface function:\\[(u,v)\\in[0,1]^2, f(u,v)=(u,v,0)\\]How to generate the following animations ? HelpDimension of the Perlin noise ?Which parameter $(u,v,t-\\text{time})$ ? a: axe $z$ qui change $f(u,v)=(u,v,p(u+t))$ Faux! $u+t$ nous fait deplacer dans les $t$ negatifs $f(u,v)=(u,v,p(u-t))$ b: $f(u,v)=(u,v,p(u+t, v))$ c: piege ! On a le droit au bruit de Perlin 3D $(u,v,p(u,v,t))$ Quand on a des textures animees a partir de bruit de Perlin, il y a une dimension supplementaire: le temps d: similaire a la c e: $f(u,v)=(u,v,p(u-t)+up(u,v,t))$ Multiplication par $u$ car le bruit est plus important a la fin v: on ne change pas que $z$ cette fois $f(u,v)=(u+p(u,v,t),v+p(u,v,t), p(u,v,t))$ Geometry processing librariesDevelopment libraries LibIGL CGAL GeoGramViewer (+lib) Graphite MeshlabSoftware BlenderUseful CG programming libraryUseful libs Eigen GLM Assimpl DevILMinimalistic GUI ImGui NanoGui AnTweakBarFull framework QtParticle system DefinitionElement at a given position + extra parameters (mass, life time, etc)On appelle un systeme de particules en oppositionL Rigid bodies - Solid objects with static shape Deformable bodies - Continuum material that can deforms Pros Cons Lightweight rpz Simple model from physics point of view Generic flexible model (spatial deformation, no connectivity, etc) ¬† Particles systems in HistoryOne of the first animated model in CGExample of particle systemFree fall of sphere under gravity Geometrical rpz of each particle: sphere Equation of motion $p(t)=\\frac{1}{2}gt^2+v_0t+p_0$ Initial position and speed may be placed at random position Each particle may have a different life timeWhat are the parameters used for $p_0$ and $v_0$ in this example ?\\[p_0=(0,0,0)\\\\v_0=(\\sin(), 1,\\cos())\\]Si on a un $\\sin$ du temps, on aurait des particules emises suivant un cercle Genre comme caOr, nos particules ne suivent pas ce cerlce, elles suivent un nombre aleatoire $\\theta$:\\(v_0=(\\sin(\\theta), 1,\\cos(\\theta))\\) Par exemple, $\\theta\\in[-\\pi,\\pi]$Bouncing spheresWhat is the equation of motion (taking into account the bouncing) ? Considere a particle emited at time $t=0$ At what time $t_i$, the particle touch the floor ? What is the new speed after impact ? What is the complete equation of trajectory ?\\[t_i=\\\\p(t)=\\frac{1}{2}gt^2+v_0t\\\\p_g(t_i)=0\\\\\\begin{aligned}\\frac{1}{2}g_yt_i^2+v_{og}t_i=0&amp;amp;\\Rightarrow\\frac{1}{2}g_yt_i=-v_{oy}\\\\&amp;amp;\\Rightarrow=-2\\frac{v_{oy}}{g_y}\\end{aligned}\\\\p(t_i)\\quad v(t_i)\\to\\begin{pmatrix}V_x\\\\-V_y\\\\V_z\\end{pmatrix}\\\\p_2(t)=\\frac{1}{2}g(t-t_i)^2+v&#39;(t_i)(t-t_i)+p(t_i)\\]General motions Motion equation is not restricted to physics-based equations What are the parameters associated to each particle ? What are the corresponding equations of motions ? On dirait que les bulles sortantes bougent en forme de cercle\\[\\text{rand}\\to[0,1]\\\\p_0=(?,0,?)\\]Comment faisons-nous pour recreer le cercle ? On randomise $x$ et $y$ entre $-1$ et $1$Or ca nous fais un carre et on veut un cercleOn tire au hasard 2 rayons $r_1$ et $r_2$\\(\\sqrt{r_1^2+r_2^2}\\gt R\\\\\\begin{cases}R\\cos(\\theta)\\\\R\\sin(\\theta)\\end{cases}\\)Avec: $r_1, r_2\\in[0,R]$ On a donc $p_0,v_0,R,C$ \\(p(t) = p_0+v_0(t-t_0)+\\begin{pmatrix}r\\cos(\\theta t-t_0+\\gamma)\\\\r\\sin(\\theta t-t_0+\\gamma)\\\\0\\end{pmatrix}\\)Avec: $\\gamma$: un offset aleatoire Billboards, impostors, sprites Particle can be displayed as small images/thumbnailsIn practice: Each particle is displayed as a quadrangle A texture is mappe on the quad The texture can contains transparencyUsageLarge use of billboard for complex models vegetation, fire, etc.ExampleUse case in production Le seigneur des anneauxComment on ete fait ces chevaux liquides ? Comment a ete filme la scene ? Il n‚Äôy a que des vrais chevaux sur la scenePour l‚Äôeau, les chevaux ont ete fait a partir d‚Äôemission de particules Zoom sur une chute d‚Äôeau La base des tetes de chevaux Couches de particules emisent a partir des tetes Ensemble final La riviere Les vrais chevaux, qui ne meurent pas Faux chevaux et cavaliers modelises pour etre emporte par la riviere" }, { "title": "PRSTA: TD 1", "url": "/cours/posts/prsta_td1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-22 15:00:00 +0200", "snippet": "Exercice 1Une variable aleatoire suit une loi normale de moyenne $m$ et de variance inconnue. Nous voulons tester l‚Äôhypothtese $H_0:m=1$ contre $H_1:m\\gt 1$. Determiner la region critique de ce test pour $\\alpha=5\\%$ Solution Sous $(H_0)$:\\[T_n = \\frac{\\sqrt{n}(\\bar X_n-m_0)}{\\sqrt{S_n^2}}\\sim \\mathcal T_{n-1}\\] La zone d‚Äôacceptation: on rejette uniquement a droite, on accepte lorsque \\(\\{T_n\\le t_{0.95}\\}\\) Zone de rejet: \\(\\{T_n\\gt t_{0,95}\\}\\)Exercice 6Une variable aleatoire suit une loi de moyenne $2$ et de variance inconnue. Nous voulons tester l‚Äôhypothese $H_0:\\sigma^2=2$ contre $H_1:\\sigma^2\\lt2$. Pour ce faire, nous disposons des observations: $1.2$, $2.1$, $1.7$, $2$, $3$, $7$, $0$ et $1$. Determiner la $P_{valeur}$ puis decider avec un risque d‚Äôerreur de premiere espece de $1\\%$? Solution On obtient\\[\\begin{aligned}S_{n}^{*} &amp;amp;= \\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2\\\\&amp;amp;= \\frac{1}{8}(-(0.8)^2 + (0.1)^2 + (-0.3)^2 + 0 +1^2+5^2+(-2)^2+(-1)^2)\\\\&amp;amp;=3.9675\\end{aligned}\\] Nous obtenons:\\[nS_n^{*} = 31,74\\\\\\] Donc:\\[\\frac{nS_n^*}{2} = 15,87\\\\\\] On a donc $\\frac{nS_n^{*}}{\\sigma}\\sim\\chi^2_8$\\[P(\\frac{nS_n^*}{2}\\lt 15,87)\\simeq 0.96\\gt 0.01\\] Donc l‚Äôhypothese $(H_0)$ n‚Äôest pas rejetee. Exercice 8La variable aleatoire $X$ suit une loi exponentielle de parametre $\\lambda$. Determiner la region critique du test $H_0:\\lambda=1$ contre $H_1:\\lambda=2$ pour un risque de premier espece. Solution \\(X\\sim \\varepsilon(\\lambda)\\\\\\) $H_0:\\lambda=1$ $H_1:\\lambda=2$ \\[\\begin{aligned}T&amp;amp;=\\frac{L(X_n,\\dots,X_m,1)}{L(X_1,\\dots,X_m,2)}\\\\&amp;amp;=\\frac{\\Pi_{i=1}^n1e^{-1X_i}}{\\Pi_{i=1}^n2e^{-2X_i}}\\\\\\end{aligned}\\] Quelle formulle appliquons-nous ? Un $\\log$ \\[\\begin{aligned}T&amp;amp;=\\frac{e^{-\\sum X_i}}{2e^{-2ZX_i}}\\\\&amp;amp;=\\frac{1}{2^n}e^{\\sum}\\end{aligned}\\] Rejet de $(H_0)$: ${T\\gt9\\alpha}$ \\[\\begin{aligned}T&amp;amp;\\gt S_{\\alpha}\\\\\\log(T)&amp;amp;\\gt\\log(S_{\\alpha})\\\\-n\\log(2)+\\sum_{i=2}^nX_i&amp;amp;\\gt\\log(S_{\\alpha})\\\\\\sum_{i=1}^nX_i&amp;amp;\\gt n\\underbrace{\\log(2)+\\log(S_{\\alpha})}_{\\color{green}{c_{\\alpha}}}\\end{aligned}\\] On a en region critique:\\[\\color{green}{\\{\\sum_{i=1}^nX_i\\gt c_{\\alpha}\\}}\\] Or \\(\\sum_{i=1}^n X_i\\sim\\gamma(n,1)\\)" }, { "title": "PRSTA: Seance 1", "url": "/cours/posts/prsta_seance1/", "categories": "Image S9, PRSTA", "tags": "Image, S9, PRSTA", "date": "2021-09-22 14:30:00 +0200", "snippet": " Point de depart: hypothese formulee sur la population totale Jugement sur echantillon Tests d‚Äôhypothese 2 hypotheses: hypothese nulle notee $H_0$ Situation de reference Hypothese soumise au test hypothese alternative notee $H_1$ Objectif: prise de decision a partir des donnees de l‚Äôechantillon Ecarts eventuels entre l‚Äôechantillon et la population du au hasard de l‚ÄôechantillonageTypes de tests Test parametrique/non-parametrique Test d‚Äôadequation Est-ce que 2 valeurs sont egales ? Test de comparaisonPoint de depart En cas de rejet de l‚Äôhypothese nulle Les ecarts sont dits significatifsPlusieurs interpretation: Loi de distribution inadaptee Echantillon non homogene Melange des populations avec des caracteristiques differentes Ecart du a des variations Echantillonnage pas effectue au hasardQue faire ? isoler des echantillons plus homogenes preiciser les facteurs de variation influant sur les observations Si l‚Äôhypothese pas nulle n‚Äôest pas rejetee Elle n‚Äôest pas demontree pour autant Elle n‚Äôest pas contredite par les faitsExemple grossier Dans une foret, il y a $20\\%$ de serpents venimeux Francois preleve $100$ serpents et $38$ sont venimeux Intervalle de fluctuation au seuil $0.95$\\[\\biggr[p-\\frac{1}{\\sqrt{n}};p+\\frac{1}{\\sqrt{n}}\\biggr] = [0.10; 0.30]\\] TheoremePour $95\\%$ des echantillons, la proportion $f$ appartient a cet intervalle sous les conditions suivante: $n\\ge30$ $np\\ge5$ $n(1-p)\\ge5$ $f=0.38\\not\\in[0.10;0.30]$ On peut en deduire: Echantillon non representatif Variations pas dues au hasardAssertion sur la foret fausse ?Autre exemple $x_1,\\dots,x_n$ observations provenant d‚Äôune loi $\\mathcal N(m,\\sigma^2)$ $\\sigma^2$ suppose connu $n$ quelconque, variables aleatoires normales\\[\\frac{\\sqrt{n}}{\\sigma}(\\bar X-m)\\sim\\mathcal N(0,1)\\\\\\]Qu‚Äôest-ce qu‚Äôon doit retenir ? Un truc qui depend de l‚Äôechantillon$\\mathcal N(0,1)$ ne depend plus du parametre, on peut s‚Äôamuser sans connaitre $m$ La loi ne depend pas du parametreOn va tester: $H_0:m=m_0$ $H_1:m\\neq m_0$Prenons les etudiants d‚ÄôEpita. Leur taille suit une loi normale de moyenne $1.70m$ et variance $0.05m$ $H_0:m=1.7$ $H_1:m\\neq1.7$Hypothese $(H_0)$\\[\\frac{\\sqrt{n}(\\bar X_n-m_0)}{\\sigma}\\]suit une loi normale centree reduite.D‚Äôapres les cours precedents\\(\\mathbb P(-1,96\\le\\frac{\\sqrt{n}(\\bar X_n-m_0}{\\sigma}\\le1,96)\\simeq0,95\\) Calculons $\\bar x$ sur l‚Äôechantillon Si $\\frac{\\sqrt{n}(\\bar x-m_0)}{\\sigma}\\in[-1,96;1,96]$, l‚Äôhypothese $H_0$ est rejetee au seuil de signification $\\alpha=5\\%$ Sinon l‚Äôhypothese est acceptee Seuil de signification $\\alpha$: Proba de rejeter l‚Äôhypothese nulle lorsque celle-ci est vraie Appele risque de premiere espece cf faux negatifs en medecine Test covid negatif en etant malade Le risque de deuxieme espece $\\beta$ est l‚Äôinverse Proba d‚Äôaccepter l‚Äôhypothese nulle lorsqu‚Äôelle est fausse On ne peut pas baisser un risque sans augmenter l‚Äôautre Region critiqueC‚Äôest la region ou on accepteTest de comparaison d‚Äôune proportion Meme principe pour $n$ grand $\\sqrt{n}\\frac{\\hat p-p_0}{\\sqrt{p_0(1-p_0)}}$ suit approximativement une loi normale centree reduite Test bilateral $H_0:m=m_0$ et $H_1:m\\neq m_0$ Test unilateral $H_0:m=m_0$ et $H_1:m\\lt m_0$ Zone de rejet et region critique differentExemplesPremier exemple $X$ suit une loi $\\mathcal N(m,\\sigma^2)$ avec $\\sigma^2$ connu Test bilateral $H_0:m=m_0$ et $H_1:m\\neq m_0$ Statistique $Z_n:=\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sigma}$Sous l‚Äôhypothese $(H_0)$, $Z_n$ suit une loi normale centree reduite. Zone de rejet: $]-\\infty;z_{1-\\alpha}[\\cup]z_{1-\\alpha;+\\infty}[$ Region critique\\(\\biggr\\{\\frac{\\sqrt{n}\\vert \\bar X_n-m_0}{\\sigma}\\gt z_{1-\\alpha}\\biggr\\}\\) $z_{1-\\alpha}$: fractile d‚Äôordre $1-\\alpha$ de la loi normale centree reduiteSecond exemple $X$ suit une loi $\\mathcal N(m,\\sigma^2)$ avec $\\sigma^2$ inconnu Test unilateral $H_0:m=m_0$ et $H_1:m\\lt m_0$ Statistique\\[T_n=\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\]Sous l‚Äôhypothese $(H_0)$, $\\mathcal T_n$ suit une loi $T_{n-1}$ Zone de rejet: $]-\\infty;-t_{1-\\alpha}[$ Region critique:\\(\\biggr\\{\\sqrt{n}\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\le =t_{1-\\alpha}\\biggr\\}\\) $t_{1-\\alpha}$: fractile d‚Äôordre $1-\\alpha$ de la loi de Student a $n-1$ degre de liberteMethode de la valeur critique Methode due a Neyman et Pearson Approche ensembliste Ensemble des valeurs observees de la stat du test provoquant un rejet Zone de rejet Complementaire de cet ensemble: zone de non-rejet valeur separant ces 2 ensembles valeur critiqueMethode de la proba critique $\\alpha$ est fixe proba critique ou $P_{valeur}$: plus petite valeur du risque d‚Äôerreur pour laquelle la decision serait de rejeter $H_0$ Si $P_{value}\\le\\alpha$, $H_0$ est rejetee Si $P_{value}\\gt\\alpha$, pas de raison de rejeter $H_0$ au risque de premiere espece $\\alpha$ExempleDuree de vie des ampoules fabriquees par un industriel $H_0:m=8000$ $H_1:m\\neq8000$ $\\alpha=5\\%$On a un echantillon de $100$ ampoules.\\[Z_n:=\\sqrt n\\frac{\\bar X_n-m_0}{\\sqrt{S_n^2}}\\]suit approximativement une loi normale centree reduite $P_{value}=\\mathbb P(Z_n\\lt -1.51)\\simeq0.0655$ $P_{value} \\gt\\alpha$, pas de raison de rejeter l‚Äôhypothese $(H_0)$" }, { "title": "RVAU: Realite virtuelle pour la maintenance industrielle", "url": "/cours/posts/rvau_realite_virtuelle_edf/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 11:00:00 +0200", "snippet": "Lien de la note HackmdProjet I-BR (2013-2016)VVProPepa Visite virtuelle du batimenent reacteurPourquoi ? Chez EDF il y a un gros projet de maintenance pour prolonger la duree d‚Äôexploitation de nos centrales nucleaires actuelles Pour optimiser les preparations d‚Äôinterventions en BR pour augmenter le temps metal Numerisation d‚Äôun batiment reacteurBorne tactile VVProPrejobTirs radio Pour detecter les problemes de soudure Comme une radio sur un etre humainPlan de balisageVirage: Realite virtuelle et augmenteeKenny: chantier ecole en realite augmenteeVoir les donnees de capteurs de Vercors sur le terrain" }, { "title": "RVAU: Introduction a la Realite Virtuelle", "url": "/cours/posts/rvau_intro/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 10:00:00 +0200", "snippet": "Lien de la note HackmdRealite virtuelleC‚Äôest quoi ? C‚Äôest toutes les technologies utilisees pour immerser un humain dans un monde virtuel Contrairement au cinema, on est acteurTerme introduit par Jaron Lanier en 1988 Maybe we should go over what Virtual Reality is. We are speaking about a technology that uses computerized clothing to synthesize shared reality.Une definition ‚ÄúLa realite virtuelle est un domaine scientifique et technique, exploitant l‚Äôinformatique et des interfaces comportementales en vue de simuler dans un monde virtuel le comportement d‚Äôentite 3D, qui sont en interaction en temps reel entre elles et avec un ou des utilisateurs en immersion pseudo-naturelle par l‚Äôintermediaire de canaux sensori-moteurs‚ÄùP. Fuchs, Le traite de la realite virtuelle vol. 1 C‚Äôest un univers 100% virtuelRealite augmenteeIl faut la distinguer par rapport a la VR Le but est d‚Äôincruster sur le monde reel des elements du monde virtuelRealite mixteUn continuu, d‚Äôexperiences sensoriellesHistorique Stereoscope Premiere forme de la VR d‚Äôaujourd‚Äôhui C‚Äôetait pour les images fixes Sensorama (1962) The ultimate display (1965) Premiere reference a la VR Pas une invention, une vision du futur de l‚Äôinformatique The sword of Damocles (1968) Le premier casque VR Tellement lourd qu‚Äôil devait etre accroche au plafond GROPE Haptic display (1967-1988) Simule le toucher Dataglove Vived Combinait l‚Äôaffichage avec des gants Avec commandes vocales EyePhone (1989) Premier iPhone Coutait 10k$ View (1990) Cave (1992) Dispositif different Immersion avec des projecteurs SPIDAR (1992) Genere un retour de force Genre bague reliee a un fil Flock of Birds (1992) Casque pour le jeu video (90‚Äôs) Technologie encore balbutiante Annees 2000-2010 Casque de l‚Äôordre de 20k$ Plus grosse resolution: 6 millions de pixels par oeil Par comparaison: 1er occulus, 500k pixels par oeil Cave de Renault 5 faces $2\\times4k$ par face Plusieurs millions d‚Äôeuros Haption Virtuose 6D (2001) Depuis 2010 Leap motion (2013) Caracteristiques de RVImmersion Mesure selon laquelle le peripherique de RV est capable de remplacer les stimulations sensorielles du monde reel par celui du monde virtuel Pour chacun de nos sens, la simulation est panoramique Un appareil qui peut en simuler un autre est plus immersif que ce dernier Un casque peut simuler un ecran de PC, il est plus immersifPresence Le sentiment d‚Äôetre present dans l‚Äôenvironnement virtuel Sur l‚Äôimage a droite, pour passer de droite a gauche, tout le monde a fait le tour du trou au lieu de passer par-dessus (alors que le sol est en-dessous, il n‚Äôallait pas tomber)Affichage pour la realite virtuellePeripherique d‚Äôaffichage En haut a droite: workbench Ecran 3D avec dispositif d‚Äôinteractions Possibilite d‚Äôinteragir avec une maquette Donne une zone de travail Rendu 3D Model au monde: Projection: Pyramide de vue: Near clipping: distance minimale pour voir les objets Far clipping: distance max Z-Buffer Shaders Stereoscopie Bawi on veut de la 3D On a dans notre monde virtuel 2 camerasPlusieurs facons de le faire: Anaglyphe Filtre de couleurs Une couleur par oeil pb: rendu des couleurs fausse Ce n‚Äôest pas du tout utilise pour la RV Stereoscopie active Besoin d‚Äôelectricite Va occulter chaque verre l‚Äôun apres l‚Äôautre en permanence Pour du 60 fps, on va faire du 120 fps et afficher une fois pour l‚Äôoeil droit et une fois pour l‚Äôoeil gauche Seteroscopie passive Lunettes beaucoup plus legeres Filtres polarisants 2 projecteurs differents Certains rayons pour l‚Äôoeil gauche, d‚Äôautre pour l‚Äôoeil droit Ecrans auto-stereoscopiques Ce sont des ecrans qui n‚Äôont pas besoin de lunettes pour etre vus en 3DInconvenients: ca reduit la resolution de l‚Äôecran par 2 Il suffit de se deplacer un peu pour que la 3D saute C‚Äôest utilise pour la 3DS :0Dans un casque de RV On applique une correction avec les lentilles pour l‚Äôeffet vignetteCalibration Probleme pour les caves Les images doivent etre coherentes et geometriquement justesInteractions pour la RVPeripheriques d‚ÄôinteractionMetaphores d‚Äôinteraction Metaphore Au lieu d‚Äôexploiter un comportement sensori-moteur et acquis de la personne, nous lui proposons, visuellement en g√©n√©ral, une image symbolique de l‚Äôaction ou de la perception souhait√©e Manipuler un objet ? Utiliser une manette, un pointeur, etc. Utiliser une main virtuelle Co-localisation Que la main virtuelle apparaisse a l‚Äôendroit de notre main reelle GestesGizmos Des ‚Äúpoignees‚Äù utilisees pour deplacer les objets dans le monde virtuel Rayon Comme un rayon laser, on vise un objet pour interagir avec Portal-gun style TactileControles de l‚ÄôapplicationMetaphores de navigationComment se deplacer dans l‚Äôenvironnement virtuel ? On pointe et on se teleporteUn utilise un joystickUn tapis roulant dans toutes les directionsRoom scale Beaucoup utilise par les casques Utilise par HTC viveDeplacement continuTeleportation libreTeleportation point a pointMateriel dedieMonde en miniatureRedirected walkingOn tourne legerement l‚Äôenvironnement virtuel, pour faire un mouvement courbe IRL en allant tout droit IVLRealite augmenteeLe but est d‚Äôincruster des elements virtuel au monde reel.Mais comment ? Vue indirecte (video see-through) Aka pokemon go Vue indirecte (optical see-through) Donne l‚Äôimpression que l‚Äôobjet virtuel est reel Projection dans l‚Äôenvironnement Dans le cas d‚Äôune voiture Nouveaux peripheriques de realite augmentee Hololens Ces peripheriques peuvent embarquer differents capteurs" }, { "title": "RVAU: Organisation du cours", "url": "/cours/posts/rvau_organisation_du_cours/", "categories": "Image S9, RVAU", "tags": "Image, S9, RVAU", "date": "2021-09-22 09:00:00 +0200", "snippet": "Lien de la note HackmdParcoursArnaud Mas: chez EDF Ingenieur UTC Master recherche Arts et Metiers ParisTech These CIFRE Renault/Arts et Metiers ParisTech Ingenieur-chercheur en realite virtuelle chez EDFProgramme 22/09 - Introduction a la RV $\\frac{1}{2}$ 29/09 - Introduction a la RV $\\frac{2}{2}$ 06/10 - TP Unity 1 13/10 - Presentations intermediaires projets + TP Unity 2 08/12 - TP Unity 3 15/12 - TP Unity 4 12/01 - Facteurs humains de la RV 02/02 - Presentation projetsProjet Sujet: collaboration en RV Fight face a face, etc. Travail en groupe de 4 13/10: prez intermediaire 02/02: prez finale Pour le 29/09: formation des groupesRendu pour le 02/02 Presentation orale Support avec videoA installer Unity: 2020.3 (LTS) Passer par Unity Hub !" }, { "title": "ALGOREP: What is Model-Checking ? How to build a Model Checker ?", "url": "/cours/posts/algorep_model_checking/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-20 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursSi on a un ping pong, comment on verifie que l‚Äôalgo marche ? On lance et un espere que ca marche?Non ca c‚Äôest etre religieux Il faut check toutes les relations et entralecements possibles (effets de bord, etc). Il faut faire des preuves automatiquesOn va prendre des outils capables d‚Äôen faire, en utilisant La description $\\neq$ implementation du systeme distribue S‚Äôabstraire des pbs de langage Qu‚Äôest-ce qu‚Äôun systeme ?On veut qu‚Äôune fusee n‚Äôexplose pas en volWhy is a model required ?On va considerer que TOUS les systemes qu‚Äôon etudie soit un systeme infini.Le code suivant serveur peut etre considere un systeme:unsigned received_= 0;while (1){ accept_request(); received_ = received_ + 1 ; reply_request();} Avec un modele, on enleve le probleme de received_A more realistic exampleOn a une abstraction des differents comportements de notre systemeOn est capable de construire l‚Äôintegralite du systeme. On veut faire le produit cartesien de tout le monde.A l‚Äôetat initial du systeme, tout le monde est dans l‚Äôetat $1$.Pour passer de l‚Äôetat $111$ a l‚Äôetat $211$, on doit avoir en meme temps un message recu et en transit.Est-ce qu‚Äôon peut avoir 2 envois simultanement ?Kripke structureOn definit un alphabet, un etat, une transition.Example On utilise des booleens qu‚Äôon appelle des propositions atomiques On etiquete notre modele pour savoir si on peut atteindre un cheminHow to express finite behavior ?Combien de propositions atomiques ? 3 (rouge, orange, vert)Comment on exprime les comportements a l‚Äôinfini ? On utilise une logiqueLinear Temporal LogicOn s‚Äôinteresse aux operateurs: $U$: ‚Äúvrai jusqu‚Äôa qu‚Äôautre chose soit vrai‚Äù $X$: ‚Äúa la prochaine etape c‚Äôest vrai‚ÄùGloballyFinallyNextUntilRetour au feu rougeAutomata for model checking Buchi: Transformer une logique d‚Äôevenement en automate Express property automatonAutomata approach for model checkingOn a reussi a creer un modele pour Aut. A et Kripke. On fait un produit synchronise Produit synchroniseOn a l‚Äôautomate de la propriete On a l‚Äôautomate du systeme. Quand on lit $d_1$ et $r_1$, on doit s‚Äôassurer de lire la meme chose dans notre systeme, on supprime les chemins qui font diverger ces valeurs, par le produit cartesien.On regarde cette automate, si on trouve une pastille noir qui s‚Äôappelle en boucle, on a un contre-exemple a notre propriete. La reponse est oui" }, { "title": "OCVX2: Programme Lineaires", "url": "/cours/posts/ocvx2_prog_lineaire/", "categories": "Image S9, OCVX2", "tags": "Image, SCIA, S9, OCVX2", "date": "2021-09-20 10:00:00 +0200", "snippet": "Lien de la note HackmdOCVX2: Programme LineairesQuelques changements par rapport a ce qui etait prevu OCVX le retourOCVX qui ne va pas se passer comme prevuBashar doit reprendre une partie du boulot de Corinne, pour pas qu‚Äôil creve il ne fera pas OCVX2 et Guillaume fera tout $\\to$ OCVX2 allege :( On verra les bases Pas de TP Ex: pas de TP sur l‚Äôimplem d‚Äôun SVM Mais on aura tout le reste Evaluation: partiel Essaiera de le caler premiere quinzaine de Novembre Semaine prochaine: pas de cours jusqu‚Äôa 19h Programme lineaire On cherche a minimiser $f_0(x)$ $x\\in\\mathbb R^n$ tel que $f_i(x)\\le 0$ avec $i=1,\\dots,p$, $f_0, f_i$ $(i=1,\\dots,p)$ fonctions affine. On note ce probleme $P_1$.\\[\\begin{matrix}\\text{minimiser}&amp;amp;f_0(x)&amp;amp;x\\in\\mathbb R^n\\\\\\text{tel que}&amp;amp;f_i(x)\\le 0&amp;amp;f_0,f_i&amp;amp;\\text{fonctions affines}\\\\&amp;amp;i=1,\\dots,p\\end{matrix}\\]Exercice 1Soit $A_u$ le lieu de $\\mathbb R^2$ decrit par les contraintes\\[A_u\\begin{cases}-x+2y&amp;amp;\\le -1\\\\x+y&amp;amp;\\le 1\\end{cases}\\]Et $A_b$ le lieu decrit par les contraintes de $A_u$ auxquelles on ajoute $x-3y\\le 6$On va se donner un espace \\[A_u=\\biggr\\{(x,y)\\in\\mathbb R^2\\text{ tq } \\begin{aligned} -x+2y &amp;amp;\\le 1&amp;amp;(D_1) \\\\ x+y&amp;amp;\\le1&amp;amp;(D_2) \\end{aligned}\\biggr\\}\\] \\[A_b=A_u\\cap\\{(x,y)\\in\\mathbb R^2\\text{ tq } \\underbrace{x-3y\\le 6}_{(D_3)}\\}\\] Etudier le programme lineaire de lieu admissible $A_u$ et minimisant $y$. Que se passe-t-il si on remplace $y$ par $-y$ ? A-t-on toujours une valeur minimale pour un programme lineaire ayant pour lieu admissible $A_b$ ? Etudier le programme lineaire de lieu admissible $A_b$ et minimisant $x+y$. Effectuer cette meme etude pour la fonction objectif $-x-y$ Solution Question 1\\[\\text{min } f_0(x,y)=y\\quad x\\in A_u\\]\\[(D_1): -x+2y+1=0\\] Comment obtenir le vecteur directeur ?\\[ax+by+c=0\\\\\\vec u=\\binom{-b}{a}\\\\\\] Comment obtenir le vecteur normal ?\\[ax+by+c=0\\\\\\vec n=\\binom{a}{b}\\\\\\] Donc:\\((D_1):\\begin{cases}\\vec u_1 = \\binom{-2}{-1}\\\\\\vec n_1 = \\binom{-1}{2}\\end{cases}\\\\(1,0)\\in(D_1)\\) On obtient graphiquement: Maintenant avec le vecteur normal: Dans quel demi-espace sommes nous ? Le demi-espace positif est du cote du vecteur normal et le demi-espace negatif est de l‚Äôautre On s‚Äôinteresse a $-x+2y+1\\le0$ donc on s‚Äôinteresse au demi-espace negatif car la contrainte est $-x+2y\\le 1\\Rightarrow -x+2y-1\\le 0$. On fait la meme procedure pour $(D_2)$:\\[(D_2):x+y-1=0\\\\\\vec u_2 = \\binom{-1}{1}\\\\\\\\vec n_2 = \\binom{1}{1}\\\\(1,0)\\in(D_2)\\] On cherche notre programme lineaire sur l‚Äôintersection de ces 2 contraintes On cherche a minimiser $y$, on part donc ‚Äúvers le bas‚Äù. Notre lieu admissible n‚Äôest pas borne vers le bas donc dans ce cas, la valeur optimale est $-\\infty$. \\[(P_2): \\text{min }-y\\\\(x,y)\\in A_u\\] On veut minimiser $-y$ donc on veut maximiser $y$.\\[(x^+,y^+)=(1,0)\\quad\\text{et}\\quad f_0(x^+,y^+)=0\\] Question 2 On va faire exactement pareil en etudiant $(D_3): x-3y-6=0$\\[\\vec u_3=\\binom{3}{1}\\\\\\vec n_3=\\binom{1}{-3}\\\\(0,-2)\\in(D_3)\\] En intersection de ces 3 contraintes: Est-ce qu‚Äôon programme lineaire a toujours une valeur minimale sur $A_b$ ? Oui car le lieu admissible $A_b$ est borne Question 3 $(P_3)$: minimiser $f_0(x,y)=x+y, (x,y)\\in A_b$ $1^{ere}$ etape: on trace une ligne de niveau Rappel\\[\\mathcal C_0(f_0)=\\{(x,y)\\in\\mathbb R^2, \\begin{aligned} f_0(x,y)&amp;amp;=0 \\\\ x+y&amp;amp;=0 \\end{aligned}\\}\\] \\[\\vec u_0 = \\binom{-1}{1}\\\\\\vec n_0 = \\binom{1}{1}\\\\(0,0)\\in\\mathcal C_0 (f_0)\\] On a defini le gradient de notre fonction, on descend a l‚Äôoppose de notre vecteur normal pour trouver la solution. On fait une descente de gradient Graphiquement, la solution est l‚Äôintersection de la droite $(D_1)$ et la droite $(D_3)$. Pour determiner les coordonnees de ce point, il doit verifier les equations des 2 droites:\\[\\begin{aligned}&amp;amp;\\begin{cases}-x^*+2y^*+1 = 0\\\\x^*-3y^*-6=0\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\begin{cases}y^*=-5\\\\x^*=-9\\end{cases}\\end{aligned}\\] Point optimal \\[p^{*} = (-9,-5)\\] Valeur optimale: \\(\\begin{aligned} f_0^*&amp;amp;=f_0(x^*,y^*) \\\\ &amp;amp;= x^*+y^* \\\\ &amp;amp;=-14 \\end{aligned}\\) Exercice 2Donnez un exemple de programme lineaire:Non borne Solution\\[\\text{min}_{(x,y)\\in A_u} y\\]De lieu admissible non borne mais de solution finie Solution\\[\\text{max}_{(x,y)\\in A_u} y\\]Ayant une infinite de solutions/points optimaux Solution\\[\\text{max}_{(x,y)\\in A_b} x+y\\]Ayant une unique solution Solution\\[\\text{min}_{(x,y)\\in A_b}\\]Exercice 3On considere le programme lineaire suivant\\[\\begin{matrix}\\text{(P)}&amp;amp;\\text{minimiser}&amp;amp;f_0(x,y)=3x+2y\\\\&amp;amp;\\text{sujet a}&amp;amp;x-y\\le 0\\\\&amp;amp;&amp;amp;4x-y\\ge 1\\\\&amp;amp;&amp;amp;-x-y\\ge-5\\end{matrix}\\] Representer le lieu admissible de $(P)$ dans le plan euclidien Tracer $\\mathcal C_6(f_0)$ la courbe de niveau $6$ de la focntion objectif de $(P)$. Indiquer les demi-espcaes positifs et negatif definis par $\\mathcal C_6(f_0)$. Dans quelle direction translater $\\mathcal C_6(f_0)$ afin de minimiser $f_0$ ? Tracer la courbe de niveau qui realise le minimum de $(P)$ et calculer l‚Äôunique point optimal de $(P)$. Quelle est la valeur optimale de $(P)$ ? Methode Lieu admissible Courbe de niveau de $f_0$ Point optimal (geometriquement) Point optimal (analytiquement) Valeur optimale Solution Question 1 Question 2 On cherche a minimiser, on translate dans la direction opposee au vecteur normal. Question 3\\[p^{*}\\in(D_1)\\cap(D_2)\\\\p^{*}=\\biggr(\\frac{1}{3},\\frac{1}{3}\\biggr)\\\\f_0^{*}=f_0(x^*,y^*)=\\color{red}{\\frac{5}{9}}\\] Comment on trouve la courbe de niveau 6 ?\\[\\begin{aligned}C_6(f_0)=\\{(x,y)\\in\\mathbb R^2, f_0(x,y)&amp;amp;=6\\}\\\\3x+2y&amp;amp;=6\\\\3x+2y&amp;amp;=0\\end{aligned}\\]Exercice 4On considere le programme lineaire suivant\\[\\begin{matrix}\\text{(P_2)}&amp;amp;\\text{minimiser}&amp;amp;f_0(x,y)=x+2y\\\\&amp;amp;\\text{sujet a}&amp;amp;-1\\le x\\le 1\\\\&amp;amp;&amp;amp;-1\\le y\\le 1\\\\\\end{matrix}\\]Resoudre $(P_2)$ en suivant la demarche precedente Solution Sujet a\\[\\begin{aligned}\\begin{aligned}x&amp;amp;\\le1\\\\-x&amp;amp;\\le1\\end{aligned}\\Biggr\\} \\vert x\\vert\\le1\\\\\\begin{aligned}y&amp;amp;\\le1\\\\-y&amp;amp;\\le1\\end{aligned}\\Biggr\\}\\vert y\\vert\\le 1\\end{aligned}\\Biggr\\}\\Vert\\binom{x}{y}\\Vert_{\\infty}\\le1\\] \\[p^*=(-1,-1)\\\\f_0^*=-3\\]" }, { "title": "ALGOREP: Raft", "url": "/cours/posts/algorep_raft/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-17 16:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOverview GoalReplicate logs (commands) in a set of servers On va avoir des indexs Des informations qu‚Äôon va mettre sur chaque index/ligne On veut que tout le monde ait le meme log OverviewOnce all servers agree for a log entry, all server can run it $\\Rightarrow$ All server will then compute the same value (replication) C‚Äôest exactement le projetLimitations and restrictions On veut elire un chef a la majoriteComparaison avec Paxos Paxos est de l‚Äôapproche distribuee Raft non, il y a un leader et tout le monde communique avec le chef Avantage: une machine est chef que pendant un laps de temps Summary Election Operation normal Coherence de l‚Äôalgo Problemes qu‚Äôon peut avoirServer state3 roles: Leader Follower CandidateChaque server commence follower:Time divided into Terms On va faire par epoch On veut un chef par epoch En fonction des processus qui meurent et naissent, on peut avoir de l‚Äôinfo obsoleteRaft est un algo pessimiste qui va passer son temps a nettoyer.Heartbeats Leader can send heartbeat to keep authorityLeader changes Chacune des cases est remplie avec des actions L‚Äôinfo stockee sur $S_1$ a la premiere ligne du log a ete calculee pendant la $1^{ere}$ epoch Ensuite viennent les complicationsLe log est stable sur les 2 premieres colonnesMais apres ? L‚Äôinformation de $S_4$ n‚Äôa pas ete propagee Il faut faire attention a l‚Äôinformation locale et celle connue par tout le monde On ecrit l‚Äôinformation locale quand elle est acceptee par tout le mondeElection basics Increment current term Change to Candidate state Vote for self Send RequestVote RPCs to all other servers, retry until either Receive votes from majority of servers Become leader Send AppendEntries heartbeats to all other servers Receive RPC from valid leader Return to follower state No-one wins election (election timeout elapses) Increment term, start new election Properties of the electionSafety: allow one winner per term Each server gives out only one vote per term 2 different candidates can‚Äôt accumulate majorities in same termLiveness: some candidate must eventually winHow to replicate log entries ? On veut un log coherent par rapport aux differents serveursOn a: Des entrees Avec des commandes Le terms Des indexsNormal operationsL‚Äôalgorithme commence a tourner. Le client envoie une commande au leader Le leader prend la commande et le met dans son log Le leader envoie AppendEntries RPCs aux followers Une fois que l‚Äôentree est prise Leader passes command to its state machine, returns result to client I Leader notifies followers of committed entries in subsequent AppendEntries RPCs Followers pass committed commands to their state machines Crashed/slow followers ? ‚áí Leader retries RPCs until they succeedExample 1 $S_4$ et $S_5$ sont en retard Vu qu‚Äôil sont en retard, si on declenche une nouvelle epoch ils ne peuvent pas etre chefQuel probleme peut-on avoir ? Ca peut accentuer les gens en avance et en retard en fonction des epochsOn va avoir des sous-systemes qui vont se creer avec des logs pas coherentsExample 2On a un truc bizarre, $S_5$ n‚Äôa pas d‚Äôepoch 2. On a une divergence.Pour l‚Äôepoch 5, $S_5$ peut etre elu car il a un log long, mais pas coherent avec celui des autres. Il va donc demander des rollabacks jusqu‚Äôau dernier point d‚Äôintersection.New commitment rulesFor a leader to decide an entry is committed : Must be stored on a majority of servers At least one new entry from leader‚Äôs term must also be stored on majority of serversClient protocol" }, { "title": "ALGOREP: Consensus is possible ! Paxos", "url": "/cours/posts/algorep_paxos/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-17 15:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursA Word on Paxos ‚ÄúOn va abandonner les systemes distribues c‚Äôest trop chiant‚ÄùLamport: a prouve accidentellement que ca marcheEst-ce que Paxos c‚Äôest dur ? Ca depend des gens On veut arriver au consensus mais pas gagner Comme si tous les candidats a la presidentielle veulent que quelqu‚Äôun soit eluIntuitionOn veut aller manger, tout le monde a faim et on a pas de chef. On peut discuter que un a un. Des gens ont une idee initiale et des gens vont suivreQu‚Äôest-ce qu‚Äôil peut arriver ? Soit aucune idee n‚Äôest accepteeSoit on arrive pas a avoir une majorite (‚ÄúTu veux manger quoi ?‚Äù ‚ÄúM‚Äôen fou‚Äù)Problem: Split votesConsider 5 processes: P1, P2 accepts $\\color{red}{red}$ P3, P4 accepts $\\color{blue}{blue}$ P5 accepts $\\color{green}{green}$Comment on fait ? P5 rejoint un des groupes et tout le monde rejoint la majorite ?Comment P5 connait l‚Äôetat des autres ? On va les faire fight en 1v1 gare du nord On a rouge et noirOn va envoyer un message a tousAvec le delai de propagation des messages, on va dire oui a noir ou oui a rougeSi noir arrive en premier, noir sera choisi, sinon rouge le seraSi on a propose noir et qu‚Äôon dit oui a rouge, alors on transmet le message comme quoi on propose rouge maintenantExamplePaxosBasic Paxos2 phases On va envoyer des messages Prepare ‚ÄúJe vais bloquer toutes les anciennes propositions‚Äù Broadcast accept ‚ÄúJ‚Äôaccepte ta valeur‚Äù Conceptual Roles in Paxos Proposer Acceptors Learners: learn the outcomeOverviewPhase 1 $[Proposer]$ Choose a proposal number $n$ $[Proposer]$ Broadcast prepare(n) to all servers $[Acceptor]$ Response to prepare(n) if $n\\gt minProposal$ then $minProposal=n$ Return (accepted_proposal, accepted_value) $[Proposer]$ When responses received from majority if any accepted_value returned, replace value by accepted value for highest accepted_proposal Phase 2 $[Proposer]$ Broadcast accept(n, value) to all servers $[Acceptor]$ Response to accept(n, value) if $n \\ge minProposal$ then accepted proposal = min proposal = n, accepted value = value Return (min proposal) $[Proposer]$ When responses received from majority Any objection $(result \\gt n)$ ? restart Otherwise, value is chosen Example 2Example 3Liveness Competing processes can livelock ! Les processus se battent pour avoir le dernier de la majoriteSolutions Randomized delays before restartingMulti-Paxos Create a replicated log" }, { "title": "PBR: Real-time Implementation", "url": "/cours/posts/pbr_real_time_implementation/", "categories": "Image S9, PBR", "tags": "Image, S9, PBR", "date": "2021-09-17 10:00:00 +0200", "snippet": "Lien de la note HackmdSite du coursBefore we startComment on genere une image ? On a vu le raytracing On a vu la rasterization On va se focus sur le temps reel avec de la rasterizationOld TimesLambertOn a tous fait un Lambert model Plus l‚Äôangle est eleve entre la normal et la lumiere, moins il n‚Äôy a d‚Äôenergie Il n‚Äôy a pas de modele $100\\%$ diffus En une seule operation on a notre BRDF Il existe d‚Äôautres modeles mais la difference visuelle n‚Äôest pas assez bonne pour etre utilisesPhong Approximation pas tres bonne MAIS precurseur a son epoque ($‚Äô70s$)Pas de conservation d‚Äôenergie:PseudocodeLambertvoid main(){ vec3 diffuse = kD * dot(normal, lightDirection) * color; gl_FragColor.rgba = vec4(diffuse, 1.0);}Phongvoid main(){ vec3 r = reflect(- viewDirection, normal); vec3 diffuse = kD * dot(normal, lightDirection) * color; vec3 specular = kS * pow(max(dot(lightDirection, r)), exponent); gl_FragColor.rgba = vec4(diffuse + specular, 1.0);}What and whyIntroduction Non-physical model requires a lot of tweaking Si on a un artiste qui fait une scene en exterieur puis on lui dit qu‚Äôon doit aller dans un tunnel en voiture, l‚Äôartiste pleureIl doit tweaker les materiaux pour que ca ait l‚Äôair joli en fonction de la lumiere C‚Äôest pour ca qu‚Äôil y a eu l‚Äôavenement du Real Time Rendering vers 2013 C‚Äôest dur de definir le PBR Definition: PBRModele mathematiques et approximations que nous allons tous suivre pour decrire les interactions entre la lumiere et la matiereWhat is PBR ?Pourquoi c‚Äôest populaire ? Decrit le monde plus precisement, donne des rendus realistesTout le monde utilise plus ou moins les memes inputsMoins de tweaking Win-win pour les ingenieurs et artistesMicrofacets Theory Ce modele approxime ce qu‚Äôil se passe dans la vraie vie On dit que tous les materiaux sont composes de miroirs plus ou moins alignesC‚Äôest quoi la difference entre un miroir et un plastique ? Notre premier cas sera un miroirLe second est un materiaux super diffusDielectrics vs ConductorsConductorsLa couleur diffuse serait une approximation du sub-surface scattering Les conducteurs reflete $0-20\\%$ de la lumiere Les metaux n‚Äôont pas de sub-surface scattering Les conducteurs refletent $60-90\\%$ de la lumiere Certains conducteurs ont leur couleur propre due aux longueurs d‚Äôondes absorbeesBRDFBRDF Simplification\\[f_r(p,\\omega_0,\\omega_i)=f_d(p,\\omega_0,\\omega_i) + f_s(p,\\omega_0, \\omega_i)\\] Notre BRDF devient pulg &amp;amp; play On peut remplacer par ce qu‚Äôon veut du moment que $\\int\\le1$Implementation notes\\[f_r(p,\\omega_0,\\omega_i)=k_df_d(p,\\omega_0,\\omega_i) + k_sf_s(p,\\omega_0, \\omega_i)\\\\k_d+k_d\\le1\\]Diffuse Lobe\\[f_d(p,\\omega_0,\\omega_i) = \\frac{\\rho}{\\pi}\\] $\\rho$: reflectance spectrumSpecular Lobe\\[f_s(p,\\omega_0,\\omega_i)=\\frac{D(\\omega_0,\\omega_i)F(\\omega_0,\\omega_i)G(\\omega_0,\\omega_i)}{4(\\omega_0,\\omega_i)(\\omega_i\\times n)}\\]Specular BRDF\\[D_{GGX}(n,h,a)=\\frac{\\alpha^2}{\\pi((n\\times h)^2(\\alpha^2-1)+1)^2}\\\\\\vec h=\\frac{\\vec v+\\vec L}{\\Vert\\vec v+\\vec L\\Vert}\\] Normal distribution function $D(\\omega_0, \\omega_i)$ Estimates the area of microfacets aligned to give perfect specular As usual, lots of different NDF equations‚Ä¶ To be consistent, let‚Äôs implement the Trowbridge-Reitz equation Low roughness means few samples contributing a lot to specularShadowing term $G(\\omega_0,\\omega_i)$\\[G(n,v,l,k)=\\underbrace{G_{SchlickGGX}(n,v,k)}_{Obstruction}\\underbrace{G_{Schlik}(n,l,k)}_{Shadowing}\\\\G_{SchlickGGX}(n,v,k)=\\frac{n\\times v}{(n\\times v)(1-k)+k}\\] On va approximer $k=\\alpha$ Approximation de l‚Äôocclusion L‚Äôorientation des facettes peut pieger la lumiereEffet Fresnel On a un joli coucher de soleil sur la mer (ou ocean)L‚Äôeau est un miroir modulo les vagues Pour tout materiaux, la reflectance va etre maximale aux angles rasants L‚Äôeffet Fresnel c‚Äôest le poids du specular lobe $k_s$\\[F_{Schlik}(v,h,f_0,f_{90}) = f_0+(f_{90}-f_0)(1-v\\times h)^5\\\\F_{Schlik}(v,h,f_0) = f_0+(1-f_0)(1-v\\times h)^5\\\\F_0(ior)=\\frac{(1-ior)^2}{(ior+1)^2}\\] $f_0$: base reflectivity at normal incidence $f_{90}$: base reflectivity at grazing angle Almost always 1 for conductors Fresnel reflectance for common materials For dialectics, $f_0$ is often approximated with $0.04$ Some materials $f_0$ are tainted (gold, copper) Implementation note: For dielectics, pick $0.04$ $f_0$ For conductors, store $f_0$ in albedo texture Use metallic input to lerp between the 2 Demo !Direct-Lightning pseudocodevec3 radiance = vec3(0.0);for(int i = 0; i &amp;lt; NB_LIGHTS; ++i){ vec3 w_i = lights[i].direction; vec3 kS = FresnelShlick(f0, wi, w_o); vec3 specularBRDFEval = kS * f_s(p, w_i, w_o); vec3 diffuseBRDFEval = (1.0 - kS) * f_d(p, w_i, w_o); radiance += (diffuseBRDFEval + specularBRDFEval) * sampleLight(lights[i], p, w_i) * dot(normal, w_i);}Textures Les artistes font plusieurs texturesTo remember ! Diffuse is an approximation of sub-surface scattering La plupart des moteurs connus vont avoir des metallics workflow Ca simplifie beaucoup la viePonctual lightPoint light Infinitely small Isotropic Describe only by a position Simple to code and fast to sample Power unit should be set using Lumens How to select a proper value ? Not as accurate as Area Light\\[L_i(p,\\omega_i)=\\frac{\\phi}{4\\pi r^2}n\\times\\omega_i\\] Cette lumiere n‚Äôexiste pas dans la vraie vieNote On ne va pas parler de directionnal light (deja fait) Si on utilise une directionnal light, il faudra tweaker les parametres Ce n‚Äôest pas aussi fidele que les Area lightsImage Based Lightning 4 points lights Avec environnement\\[L_0(p,\\omega_0)=\\int_{\\Omega}(f_d(p,\\omega_0,\\omega_i) + f_s(p,\\omega_0,\\omega_i))L_i(p,\\omega_i)n\\times w_i\\\\L_0(p,\\omega_0)=\\int_{\\Omega}f_d(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i+\\int_{\\Omega}f_s(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]IBL Diffuse\\[\\int_{\\Omega}f_d(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]Mais c‚Äôest juste un flou gaussien ? C‚Äôest pas si faux que ca, c‚Äôest assez proche\\[L_0(p,n)=\\int_{\\Omega}\\frac{\\rho}{\\pi}L_i(p,\\omega_i)n\\times\\omega_id\\omega_i\\\\L_0(p,n)=\\frac{\\rho}{\\pi}\\int_{\\Omega}L_i(p,\\omega_i)n\\times\\omega_id\\omega_i\\]Il faut faire une integration par angle solide, et c‚Äôest complique. Utilisation des coordonnees spheriques pour l‚Äôintegration Discretiser l‚Äôintegrale avec la somme de Riemann Calculer pour chaque texel, avec la direction $N$ du centreIBL Specular\\[\\int_{\\Omega}f_s(p,\\omega_0,\\omega_i)L_i(p,\\omega_i)m\\times\\omega_i\\]\\[L_0(p,\\omega_0)=\\int_{\\Omega}L_i(p,\\omega_i)d\\omega_i\\times\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)n\\times\\omega_i d\\omega_i\\] Ca a ete teste et ca marche: c‚Äôest ca la 3DChanger le niveau de roughness c‚Äôest faire du downsampling, pourquoi par appliquer la roughness en faisant des images de plus en plus petitesPre-computed BRDF\\[\\begin{aligned}\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)n\\times\\omega_id\\omega_i &amp;amp;= F_0\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)(1-(1-\\omega_0\\times h)^5)n\\times\\omega_id\\omega_i\\\\&amp;amp;+\\int_{\\Omega}f_r(p,\\omega_0,\\omega_i)(1-\\omega_0\\times h)^5n\\times\\omega_id\\omega_i\\end{aligned}\\] Obtained bu substituting Fresnel ShlickOnly 2 inputs left: roughness, viewing angleAt runtime: Fetch pre-integrated BRDF texture Fetch convoluted environment Apply the above equation to get the full specular componentSpecular: compisistionc2 brdf = GetIntegratedBRDF(NdotV, roughness);vec3 prefilteredSpecular = GetPrefilteredSpecular((NdotV, roughness);vec3 specular = prefilteredSpecular * (F * brdf.x + brdf.y); F: Fresnel termTo remember C‚Äôest juste du pre-filteringColorspace and color precision sRGB vs Linear Monitors apply pow function to luminance Toute l‚Äôindustrie a du se base sur les ecran qui font ca donc ils ont cree le $sRGB$ Sur photoshop, une image sera encodee en sRGB pour retrouver les couleurs imaginees On va eviter de faire nos calculs en sRGB Soit on fait tout en sRGB Soit on fait tout en lineaire $\\Rightarrow$ OUI On applique a la fin la fonction sRGB pour convertir en lineaire HDR vs LDR HDR: High Dynamic RangeReinhard Tonemapping:\\[color_{final}=\\frac{c}{c+1}\\] HDR has larger range of values Units will create radiance color outside the $0\\dots1$ range Perform computation in HDR, tonemap to LDR is required HDR is required to get correct PBR result Especially important for IBLGoing furtherAdvanced materials Examples: hair, skin, cloud, etc." }, { "title": "PBR: Rendering Theory", "url": "/cours/posts/pbr_rendering_theory/", "categories": "Image S9, PBR", "tags": "Image, S9, PBR", "date": "2021-09-17 09:00:00 +0200", "snippet": "Lien de la note HackmdSlides du coursQui est-ce ? Epita 2018 Chez SiemensTOC Introduction Light-Matter Interactions Radiometry Rendering EquationLight-Matter InteractionsDisclaimer I am not a physicist, and Quantum Mechanics is a really complex topixRappel Champ magnetique et electrique transversal Equation de Maxwell Interactions avec la matiereMacroscopic Level: Interactions Emission In-scattering Out-scattering Absorption onde electromagnetique absorbee Emission Modele de Niels-Bohr Any vibrating charged particle converts energy into electromagnetic radiationAbsorption L‚Äôelectron va monter d‚Äôun niveau d‚Äôenergie puis reemettre une emissionScattering On va pouvoir reflechir et transmettre La trajectoire de la lumiere va changer Il va y avoir des interferences Interferences constructives: quand la lumiere va changer de milieu, il y a le principe de Fermat ‚Äúla lumiere suit toujours le chemin le plus court‚ÄùFinal notes Any charged particle can interact on electromagnetic radiation Quantum Theory and Quantum Electrodynamics can go really far I can only advise you to read more about this topic !RadiometryEnergy\\[Q=\\frac{hc}{\\lambda}\\] $h$: constant de Planck $c$: speed of light $\\lambda$: wavelengthRadiant Flux / Power\\[\\phi = \\frac{dQ}{dt}\\]Irradiance\\[E(p)=\\frac{d\\phi(p)}{dA}\\] $d\\phi(p)$: power $dA$: finite surface area\\[E = \\frac{\\phi}{4\\pi r^2}\\]\\[E_1=\\frac{\\phi}{A}E_2=\\frac{\\phi\\cos(\\theta)}{A}\\]Solid angle Area of a projected shape onto the Unit Sphere Radiant intensity\\[I=\\frac{d\\phi}{d\\omega}\\] $\\phi$: power $\\omega$: angleRadiance On va l‚Äôutiliser pour faire tout le rendu\\[L(p,w) = \\frac{dE_{\\omega}(p)}{d\\omega}=\\frac{d\\phi(p)}{d_{\\omega}dA^{\\bot}}\\]Rendering equationDisclaimer We assume that Light travels in vacuum We deal only with opaque surfaces Interactions at object surface Definition\\[L_0(p,\\omega_0)=\\int_{\\Omega}\\underbrace{f_r(p, \\omega_0,\\omega_i)}_{\\text{R√©flectivit√© bidirectionnelle}}L_i(p,\\omega_i)n\\times \\omega_i d\\omega_i\\]BRDF On peut voir ca comme un ratio. C‚Äôest la quantite d‚Äôenergie qui va etre emise en $\\omega_0$ quand elle provient de $\\omega_i$ C‚Äôest une grosse approximation de ce qu‚Äôil se passe Dans la vraie vie il y a de la transmissionCertaines boites utilisent de fonction plus avancees (BTDF, BSSRDF, etc.)Qui design ces BRDF ? Lambert c‚Äôest une BRDFPhong utilise une BRDFEn general la BRDF c‚Äôest la propriete des materiaux pour savoir comment c‚Äôest reflete. On ne veut pas que de l‚Äôenergie soit cree lors de la reflection Il faut normaliser sinon on a des surprisesFinal notes Rendering equation uses all quantities we have seen The rendering equation is what we solve when generating 3D images" }, { "title": "IMCO: Processing Color", "url": "/cours/posts/imco_processing_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-16 14:00:00 +0200", "snippet": "Lien de la note HackmdHow a camera worksHuman Eye vs a Camera Shutter: how long the camera is opened to let in lightThe imaging flow The camera pipeline for creating nice photos is a secret recipeThe color Imaging Flow SourceOther possible steps: ISO Gain Noise Reduction Etc.Sensor Temporal Mutliplexing Scan 3 times + use 1 sensor 3 real values per pixel Only for static scenes Slow Scan 1 time + Use 3 sensors 3 real values per pixel Costly Space Spatial Multiplexing Scan 1 times + Use 1 sensor Well-mastered technology 1 real value per pixel (interpolation) Loss of light Camera spectral sensitivity SourceSensor (from 110 years ago!)Using temporal multiplexingPreprocessing Dark Current Compensation Signal present even when the length is close, which adds noise How to compensate ? Capture a dark image for the given exposure time\\[C_i(x,y)=R_i(x,y) - D_i(x,y)\\] Vignetting/Lens Shading/Flat Field correction Image tends to darken on the corners/Non-uniform Illumination How to compensate ? You tell me ! Compute average RGB value of 15 White Patches ¬† Statistic Red Green Blue Before correction Mean 157.3 159.1 157.5 After correction Mean 249.5 \\ \\ If you are taking RAW images there is a chance your image software already does itColor Constancy Property of the Human Visual Sytem that allows adapting to different scene illuminationsWhite Balance to the rescue The eye cares more about the intrinsic color of the object, not the color of the light leaving the object Easy for our eyes to judge what is white under different illuminants, but not so straightforward to cameraWhite Balance The idea is to make white points the same between scenesWhite point is the $xyY$ (or $XYZ$) value of an ideal ‚Äúwhite reference‚Äù Hence, the camera is able to do the Chromatic AdaptationChromatic Adaptation: How ? $\\color{yellow}{\\text{Source}}$ color $(X_s, Y_s, Z_s)$ with white reference $(X_{WS}, Y_{WS}, Z_{WS})$ $\\color{blue}{Target}$ color $(X_T,Y_T,Z_T)$ with white reference $(X_{WT}, Y_{WT}, Z_{WT})$ Computing $[M]$ Transform $XYZ$ to cone response domain Scale using source/target white references Transform back form cone domain $XYZ$\\[[M] = [MA]^{-1}\\begin{bmatrix}\\frac{\\rho_T}{\\rho_S}&amp;amp;0&amp;amp;0\\\\0&amp;amp;\\frac{\\gamma_T}{\\gamma_S}&amp;amp;0\\\\0&amp;amp;0&amp;amp;\\frac{\\beta_t}{\\beta_s}\\end{bmatrix} [MA]\\]Where $\\rho, \\gamma,\\beta$ are the cone responses for the given source and target colorsExampleWhite balance: automaticWhat if we don‚Äôt help the camera ? The camera doesn‚Äôt know the illuminantThe camera will try to ‚Äúguess‚Äù the white point in the image, and then balance the color automatically. Unlike White Balance, the illuminant is very hard to estimateHow ? Gray world assumption The average of all colors in the image is gray Green channel is taken as ‚Äúgray‚Äù reference White-balanced image is: $k_{r}R,G,k_bB$ $k_r=\\frac{G_{mean}}{R_{mean}}$ $k_b = \\frac{G_{mean}}{B_{mean}}$ White patch algorithm Assumes that highlights = specular reflections of illuminant Maximum $R,G,B$ values are good estimation of white point White balanced image is: $k_{r}R,G,k_bB$ $k_r=\\frac{G_{max}}{R_{max}}$ $k_b = \\frac{G_{max}}{B_{max}}$ How does GIMP does it ? Discards pixels colors at the extremes of $R,G,B$ histograms Thresholds of $0.05\\%$ of total pixel count Do Histogram Stretching of remaining pixel colors, for each channel Plus some smart post-processing Smart Color Balance method Discards ‚Äúblack‚Äù and ‚Äúwhite‚Äù pixels Stretch the histogram of the remaining pixels Plus some smart post-processing Those are very basic algorithms.Modern cameras use sophisticated white-balance, based on data-driven solutions One Way Compute features from image Find similar images in databases of images with good white balance Use white balance from image Demosaic Each pixel has a different color filter Bayer Pattern is the most used Color Filter Array (CFA) Why More Green ? Frequency of the G color band is close to the peak of the human luminance frequency response $\\to$ better sharpness Linear interpolation Average of neighors Smoother kernels (bicubic) can also be usedTypical errorTaking a picture of striped pattern $\\to$ color artifact To overcome these problems, most demosaicing methods convert the image to the YCbCrSolution Each pixel has a different color filter Bayer Pattern is the moste used Color Filter Array (CFA) Interpolation methods are patented or proprietary And of course deep learning to the rescueColor Transform $RGB_c\\to RGB_u$Color Correction Cameras are meant to produce pleasing scenes rather than colorimetrically accurate scenes Spectral Sensitivities of the camera are not identical to human color matching functions To obtain colorimetric accuracy, we need to transform the image from the sensor‚Äôs color space to the colorimetrics $(XYZ)$ space By default Factory-computed Color Space Transforms (CST) are used When precision is needed, Color Charts are used to obtain a specific transform for the camera and scene We can use ICC color profileColor Correction ChartsColorChecker Digital SG (SG=Semi-gloss) 140 patches (96 uniques colors)Artist Paint TargetColorBuild 300 Patch TargetColor Correction Methods $30+$ years of continous research on how to transform form RGB to XYZ spaces A lot of ways to do it ! Most of them solve the following equation:\\(X=MP\\) $X$: Reference $XYZ$ values $[3\\times m]$ $P$: Camera $RGB$ values $[N\\times m]$ $M$: Correction matrix $[3\\times N]$ $m$: nb of data points $N$: nb of dimensions ¬† ColorChecker Classic ColorChecker Digital SG m 24 140 LinearLinear Mapping from $RGB$ to $XYZ$ $N=3$ Not affected by exposure changePolynomial Color CorrectionLinear Mapping From $RGB$ to $XYZ$ + add polynomial components to reduce errors $N=9$, if $2^{nd}$ order polynomial Affected by exposure changes High polynomial degree tends to do overfittingRoot Polynomial Color CorrectionLinear Mapping from $RGB$ to $XYZ$ + add root polynomial components $N=6$, if $2^{nd}$ Order Polynomial Not affected by exposure changeMeasuring with RGB Cameras: Recap Cameras ar not light measurement devices From the moment an image is captured by the sensor, there are a lot of steps which could impact the final color rendition. This processing is proprietaryFuture trends ?White balance: Mixed illumination The white balance fails if 2 illuminants are in the same imageDenoisingBest current solutions use Deep Learning Predict the noise instead of denoising the imageHDR Imaging HDR Imaging is quite mature Some challenges when acquiring moving scenes or shooting a video HDR from a single image using Deep Learning ?Multispectral Imaging Used mostly for quality inspection and classification of materials In principle, it could be used for measuring ReflectanceSpectra from RGB When measuring color with an RGB camera, we measure the ligth response in 3 wavelengths" }, { "title": "IMCO: Measuring Color", "url": "/cours/posts/imco_measuring_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-16 10:00:00 +0200", "snippet": "Lien de la note HackmdVideo timeKonica Minolta SensingHow can we measure colors ? Spectrophotometer Response through the entire visible spectrum Relatively small areas (few $cm^2$) - Resolution is 1 point ‚ÄúFalt surfaces‚Äù RGB Camera Response in 3 wavelengths (Red, Green Blue) Large areas - High Spatial Resolution ($\\lt50$MPixels) Any kind of surfaces Hyperspectral camera Response throughout the entier visible spectrum (and more) Large areas - Low Spatial Resolution ($\\le2$MPixels) Any kind of surfaces When NOT to Measure color Using instrument to measure color and compute differences objectively is not always needed For example: A company has a corporate color (possible $^{TM}$) Tour de France: Pantone 123C Veuve Cliequot: Pantone 137C Louboutin: Pantone 18.1663TP Products carrying the color are sold; however they are manufactured by different providersJudging by visual assessment Need consistent lightning Need consistent viewing Need to Check for Metamers Use a light booth ! Sufficient when there are few standard samples to be matched Sufficient when tolerance is judged visually by color experts Requires all manufacturers to have a physical copy of the standard, and to have the same hardware Because there are no measurements, we don‚Äôt know to adjust color workflow in case we need to match a colorMeasuring with SpectrophotometersRemember Light interaction Spectrometer can measure reflectance and transmittance (specular and/or diffuse) Time for another videoWhat is a Spectrophotometer? Light Reflection vs Material Matte Light is reflected in all directions equally Semiglossy Light is reflected in all direction but a small part is reflected orthogonal to the incident angle Glossy Light is reflected in all directions but a big part is reflected orthogonal to the incident angle Spectrophotometers: In a Nutshell Spectral reflectance The ratio of reflected light ($r$) to the incident light ($i$) under specific geometric conditions \\[R_{\\lambda}=\\frac{\\phi_{\\lambda}^r}{\\phi_{\\lambda}^i}\\] Spectral transmittance The ratio of transmitted light ($t$) to the incident light ($i$) under specific geometric conditions \\[T_{\\lambda} = \\frac{\\phi_{\\lambda}^t}{\\phi_{\\lambda}^i}\\] All measuring instrument need to be calibrated using White Tile made from Spectralon Spectrophotometers: reflectances ?Interlude: fluoresence Fluroescence can create colors we don‚Äôt see Use an instrument called a Bispectrometer to measure it Donaldson matrix obtained from a green sample emitting a more satured green lightColorimeter vs Spectrophotometers Colorimeters are used generally to calibrate screens They mimic the way our eyes perceive colorThey measure reflectance in 3 wavelengths (R, G, B)They do not provide a spectral responseSpectrophotometersTypes Bidirectionnal Non-structured and flat surfaces (paper, plastics) Sphere Structured and glossy surfaces (textiles, metallic) SPIN vs SPEX SPIN Specular Included (gloss is accounted for) Color is measured independent of the sample‚Äôs gloss or surface texture SPEX Specular ExcludedSpecifications Example: Automotive interior plaque (items produced using different materials) SPIN: looks at the material independant of surface texture SPEX: values which depend on gloss and surface conditions Different spectro modelsSpecifications Choose depending on what you need ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment geometry $45^o$ a:$0$ (ring illumination) $di:8^o$ $45^o$c:$0$ (circumferential) Light source Gas filled tungsten lamp and UV LED Gas-filled tungsten lamp 3 point circle, 7-LED chip GeometryReflectance of a semi-glossy object $di:8^o$ A high gloss sample with the same pigmentation is visually judged darker by the eye when compared to a matte sample $\\color{orange}{45^o:0}$: measure that color difference $\\color{green}{di:8^o}$ measure the same color in both cases $\\color{orange}{45^o:0^o}$ simulates normal behavior e.g. when we read a magazine Aperture ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment aperture $4.5mm$ $4$ or $8mm$ $2$,$6$ and $8mm$ Small aperture Measures quickly may miss relevant infoLarge aperture more accurate measurement takes longer needs larger sampleConditions ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Measurment conditions M0, M1, M2 N/A M0, M1, M2, M3 M0 legacy measurement (tungsten lamp, no standardization of UV content in illuminat, UV strength changes through time) M1 Spectral distribution of illuminant M2 UV is excluded M3 Polarized light Measurement conditions impact the colorSpectral range ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Spectral range $380-730nm$ $700-400nm$ $380-750nm$ Repeatability ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Short term repeatability $0.1$ $\\Delta E_{94}$ $0.05$ $\\Delta E_{ab}$ $0.05$ $\\Delta E_{00}$ 2 different i1Pro 2 spectro 10 measurements of the same object were taken for each instrument $\\Delta E$ between first and other 9 measurements were computed for each instrument ¬† X-RIte i1Pro 2 X-RITE Ci62 Barbieri LFP qb Inter-instrument agreement Average $0.4$ $\\Delta E_{94}$ Max $1.0$ $\\Delta E_{94}$ Average $0.4$ $\\Delta E_{ab}$ Max $1.0$ $\\Delta E_{ab}$ Average $0.4$ $\\Delta E_{00}$ Max $1.0$ $\\Delta E_{00}$ Transmittance Measurement When we need transmittance ? Light Filters Printed Ads Food Inspection Inter-instrument agreement Compared measurements of 16 samples used for printingRecap Many different (standardized) methods to measure Reflectance (and Transmittance) Unfortunately, measured Reflectance/Transmittance is not unique as it depends on the instrument you sued to measure it Type of instrument to used depends on what you want to measure, and how frequent you want to measure Only measurements tales under the same conditions can be truly compared. Therefore, it is necessary to note the following information in a color measurement report: Color instrument (geometry, aperture, measurement condition) Illuminant/observer standards, if you give $L\\times a\\times b$ values Future trends: beyond colorVisual appearance of materials Reflection Transmission AbsorbanceBRDF Measurement Bi-directional Reflectance Distribution Function (BRDF) gives a more complete characterization of light interaction with the surface We measure how light reflects in all directions BRDF allows characterizing the surface appearance at a microscopic level (used in Computer Graphics to render objects) Measurable with Goniophotometers How to measure BRDF faster and cheaper ?Sources Les boules Litteralement tout le cours Spectrophotometer Spectral measurment X-RITEMetamerismWhat‚Äôs that ? metamerism is a perceived matching of colors with different (nonmatching) spectral power distributions.Most important types Illuminant Metamerism Different spectral characteristic and same color when viewed under one light different color when view under another light Observer Metamersim Different spectral characterisic and same color when viewed by one observer different color when view by another observer Examples:Car industrySourceOtherSourceMetamerism vs Color Inconstancy Color inconstancy: A single object changing color with changes in the color of the illumination Metameric pair: Two objects having color inconstancyRecap Metamerism is an effect we need to consider if a pair of objects will be viewed under more than one type of illuminant In the printing industry, neutral (grayscale) colors are more susceptible to illuminant metamerism as a mix of inks is used In the case of displays, illuminant metamerism is not a problem as they create their own light" }, { "title": "CMKV: Introduction aux Chaines de Markov", "url": "/cours/posts/cmkv_intro_markov/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-15 14:00:00 +0200", "snippet": "Lien de la note Hackmd Savoir echantilloner c‚Äôest bien mais on veut optimiserRappels Quand on a une loi de proba $P(x)$\\[\\begin{aligned}P(X&amp;amp;=x)\\to P_{\\underbrace{T}_{\\text{temperature}}}(X=x)=\\frac{1}{Z_T}e^{-\\frac{U(x)}{T}}\\\\&amp;amp;\\downarrow\\\\P(X=x)&amp;amp;=\\frac{1}{Z}e^{-U(x)}\\end{aligned}\\]\\[\\color{red}{\\lim_{T\\to+\\infty}P_T=P_{\\text{uniF}}\\\\\\lim_{T\\to0^+} P_T=P_0\\\\P_0(X=x)\\begin{cases}1 &amp;amp;\\text{si } x=x_{\\text{solution}}\\\\\\varnothing &amp;amp;\\text{sinon}\\end{cases}}\\]Marche aleatoire Notre echantillonneur va realiser une marche aleatoireComment on affecte $x^{(t+1)}$ a partir du $x$ courant ? On a un √©chantiolloneur Metropolis-Hastings: $x^{(0)}\\leftarrow \\text{al√©atoire}$ Boucle: On se trouve un $x_{\\text{candidat}}$ $x^{(t+1)}\\leftarrow$ soit $x^{(t)}$ soit $x_{\\text{candidat}}$ $\\to\\color{red}{\\text{d√©pend de }} P_{\\color{blue}{T^{(t)}}}(X=x)$ $\\color{blue}{T^{(t+1)}\\leftarrow\\underbrace{\\alpha}_{\\equiv 1^-} T^{(t)}}$ $t\\leftarrow t+1$ C‚Äôest un algo de recuit simul√© Alterner entre cycle de refroidissement lent et r√©chauffement pour un m√©tal C‚Äôest quoi un algo brute force ? C‚Äôest un algo qui va explorer tout l‚Äôespace pour trouver la solution On cherche le minimum energetique $\\color{red}{{2,4}}$ $\\color{red}{{2,3,4}}$ ¬† ¬† ¬† $\\boxed{1}$ $\\boxed{2}$ ¬† ¬† ¬† ¬† ¬† $\\boxed{3}$ ¬† ¬† $\\boxed{4}$ D‚Äôapres le dernier cours, si on regarde l‚Äôechantilloneur, il y a une possibilite de faire un echantillonneur tres simple mais sous-optimal\\[\\color{red}{\\forall t, u(x^{(t+1)})\\le u(x^{(t)})}\\] loop: $x_{\\text{candidat}}\\leftarrow$ aleatoire si $x_{\\text{candidat}}$ ameliore on le garde comme $x^{(t+1)}$ Combien de temps ca va prendre pour atteindre la solution ? On peut viser la fin de l‚Äôunivers apres l‚Äôextinction des hommes Au final, le tirage aleatoire est moins efficace que le bruteforce C‚Äôest con hein ?BacktrackingOn va toujours empiler les boucles. Par exemple: On met $1$ dans la premiere case, sauf que ce n‚Äôest pas possible donc on break On met $2$ a la place On fait pareil pour la $2^e$ case, $1$ et $2$ ne sont pas possibles donc on met $3$ On fait pareil pour la $3^e$ case, on met $4$ $\\vdots$ On arrive a un blocage ! $2$ $3$ $4$ $1$ $4$ $\\boxed{1}$ $\\boxed{2}$ $3$ $1$ $2$ $3$ ¬† $\\boxed{3}$ ¬† ¬† $\\boxed{4}$ Mais ou est-ce qu‚Äôon s‚Äôest trompe ?? On backtrack et on change nos valeurs $1$, $2$, $3$ et $4$ ne sont pas possibles donc on supprime la valeur et on revient a la case precedente On change $2$, $3$ c‚Äôest pas possible donc on met $4$ $2$ $3$ $4$ $1$ $4$ $\\boxed{1}$ $\\boxed{2}$ $3$ $1$ $4$ ¬† ¬† $\\boxed{3}$ ¬† ¬† $\\boxed{4}$ Pour resoudre le sudoku, imaginons d‚Äôavoir une fonction $U$ a 16 variables:\\[U(\\begin{matrix}\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}&amp;amp;\\boxed{}\\\\\\end{matrix})\\] ${2, 4}$ ¬† ¬† ¬† ¬† $\\boxed{1}$ $\\boxed{2}$ ¬† ¬† ¬† ¬† ¬† $\\boxed{3}$ ¬† ¬† $\\boxed{4}$ Ici on reduit l‚Äôespace des possibilitesEn premiere iteration:\\(U(\\begin{matrix}\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\end{matrix})\\\\\\vdots\\\\U(\\begin{matrix}\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}&amp;amp;\\boxed{1}\\\\\\boxed{1}&amp;amp;\\boxed{2}&amp;amp;\\boxed{1,2,3,4}&amp;amp;\\boxed{1,2,3,4}\\\\\\end{matrix})\\\\\\) On obtient un arbre des possibilites Bruteforce: parcours en largeur Backtrack: parcours en longueur Il y a des problemes ou on ne peut pas backtrackerAutre methodeOn se donne une fonction $U_1(x)$\\[P(X=x)=\\frac{1}{Z}e^{-U(x)}\\\\\\downarrow +T\\\\P_T(X=x)=\\frac{1}{Z_T}e^{-\\underbrace{\\frac{U(x)}{T}}_{\\color{red}{U_T(x)}}}\\] On va chercher le $x$ qui maximismeOn a un espace discret. On chercher le $\\color{green}{P_{\\infty}}$ qui a la meme aire que notre fonction $\\color{blue}{P(X=x)}$ On dessine $\\color{blue}{P(5)}$On dessine $\\color{black}{P(1)}$\\[\\vdots\\]Imaginons qu‚Äôon a une bille. Il ne faut pas qu‚Äôelle se fasse coincer dans un minimum local et elle se deplace de proches en proches. La bille aura de plus en plus de mal a ‚Äúremonter‚Äù du creux et va se retrouver ‚Äúcoincee‚Äù dans le creux contenant la solutionQuel est le cout pour aller d‚Äôune position a une autre ? Dans ce cas la bille doit avoir assez d‚Äôenergie pour remonter la penteRatio\\[P(X_{t+1}=x_{t+1}\\vert X_t=x_t)=\\text{ratio}\\\\X_t\\color{green}{\\text{ influence }} X_{t+1}\\\\X_{t+1}\\color{red}{\\text{ depend de }} X_t\\] Si on a $P(A=a\\vert B=b,C=c)$, $B$ et $C$ influencent $A$.\\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\]La meteo de GulliEn supposant qu‚Äôon soit a Paris:\\[\\color{green}{P(X_{t+1}=\\text{pourri}) = 0.6\\\\P(X_{t+1}=\\text{pourri}) = 0.4}\\] $x_{t+1}$ \\ $x_t$ beau pourri total beau $\\color{red}{0.4}$ $\\color{red}{0.2}$ $\\color{green}{0.6}$ pourri $\\color{red}{0.1}$ $\\color{red}{0.3}$ $\\color{green}{0.4}$ \\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\\\\\color{red}{x_{t-2}\\leftarrow x_{t-1}\\overbrace{\\leftarrow}^{\\text{dependance}} x_t\\overbrace{\\leftarrow}^{\\text{dependance}} ?x_{t+1}}\\]Le modele ne semble pas simpliste ? On est influence que par le temps d‚Äôavant d‚Äôune facon directe Le temps de demain depend du temps qu‚Äôil fait aujourd‚Äôhui mais egalement du temps d‚Äôhier Le tableau devient 3DOn a defini:\\[P(X_{t+1}=x_{t+1}\\vert X_{t-1}=x_{t-1}, X_t=x_t)\\]On a decide d‚Äôignorer le temps d‚Äôavant avant-hier, et la journee encore avant, etc. Le modele le plus general pour connaitre le temps de demain est:\\[P(X_{t+1}=x_{t+1}\\vert X_t=x_t, X_{t-1}=x_{t-1},\\dots, X_0=x_0)\\quad\\text{(tous les jours)}\\]\\[P(\\underbrace{X_{t+1}}_{\\color{green}{\\text{var. alea}}}=x_{t+1}\\vert X_t=x_t, X_{t-1}=x_{t-1},\\underbrace{\\dots, X_0=x_0}_{\\color{green}{\\text{independante de}}})\\] On a ecrit des dependances indirectes qui ne vont pas etre modelisees\\[\\color{green}{X_0\\to X_1\\dots X_{t-2}\\to X_{t-1}\\to} \\overbrace{X_t\\to X_{t+1}}^{\\text{modele}}\\color{green}{\\to X_{t+2}}\\] En vert: dependances indirectes C‚Äôest une chaine de MarkovPrenons une chaine de niveau $2$:\\[\\color{green}{\\underbrace{X_{t-4}}_{\\to \\color{black}{X_{t-2}}}\\to \\underbrace{X_{t-3}}}_{\\color{black}{\\to X_t}}\\to \\underbrace{X_{t-2}}_{\\to X_t}\\color{green}{\\to} X_{t-1}\\to X_t\\]Prenons une image en niveaux de gris:\\[X=(X_1,\\dots,X_{\\underbrace{N}_{\\text{pixel}}})\\\\x = (x_1,\\dots,x_N)\\\\U_L(x_i, y_i)=\\begin{cases}y_i &amp;amp;\\text{si } x_i=\\text{noir}\\\\1-y_i&amp;amp;\\text{sinon}\\end{cases}\\]\\[\\begin{aligned}\\color{blue}{U_{\\text{prior}}(x_i,x_{i-l},x_{i-1},x_{i+1},x_{i+l})}&amp;amp;=\\sum_{v}\\vert x_i-x_{iv}\\vert\\\\&amp;amp;=\\sum_{v}\\delta_{x_i\\neq x_{iv}}\\end{aligned}\\] Qu‚Äôest-ce qu‚Äôun champ de Markov ?Un modele graphique avec des fleches $A- B$ ($A$ et $B$ sont dependantes mutuellement) On veut que notre graphe soit le plus incomplet possible cad avoir le moins de variables possibles\\[P(X_{t+1}=x_{t+1}\\vert \\{X_u=x_u\\}_{u\\le t})=-(\\{X_u=x_u\\}_{u\\in[t-h,t]})\\\\\\] Propriete Markovienne\\[P(X_i=x_i\\vert \\{X_j=x_j\\}_{[1,N]\\setminus {i}}) = P(X_i=x_i\\vert \\{X_j=x_j\\}_{\\text{ ou } j\\in V(i)})\\]" }, { "title": "EPIQUANTI : Histoire et fondamentaux de la physique quantique", "url": "/cours/posts/epiquanti_histoire/", "categories": "tronc commun S9, EPIQUANTI", "tags": "tronc commun, EPIQUANTI, S9", "date": "2021-09-14 09:00:00 +0200", "snippet": "Lien de la note HackmdSlides de coursAgenda Histoire et fondamentaux de la physique quantique Fondmentaux des qubits avec elements mathematiques Ingenierie du calcul quantique Architecture d‚Äôun ordinateur quanitque et technologies habilitantes Differents types de qubits et de calculateurs quantiques Algorithmie quantique - David Herrera-Marti Outils de developpement CAs d‚Äôusage metiers et offres clouds - Olivier ezratty avec Georges Usbelger Telecommunications et cryptographie quantique - Eleni Diamanti Questions societales, fausse sciences et fact-checking - Fanny Bouton et Olivier Ezratty Ecosysteme du marche, startup et opportunites - Christophe JurczakEvaluation $50\\%$: QCM a la fin $50\\%$: participation active et exercices avec David Herrera-MartiBackground CentraleSupelec 1982-1985 Sogitec 1985-1989 Informatique applique a l‚Äôimage (art graphique) Microsoft 1990-2005 Pour l‚Äôexperience dev A lance des programmes d‚Äôaccompagnement de startup ‚ÄúJe me presente comme un troubadour, un saltimbanque‚Äù Publie depuis 15 ans des livresOn quantum tech Est tombe dans le quantique il y a $\\sim 10$ans Comprendre l‚Äôinformatique quantique, $3^e$ edition, ebook gratuit de 684 pages septembre 2020 Un peu le syllabus du cours La $4^e$ edition sors dans quelques jours (et en anglais !) Alain Aspect A decouvert l‚Äôinformatique quantique Podcasts Quantum: podcast de l‚Äôactualite quanitque Decode quantum: les entretiens du quantique Dans la science fiction: Y‚Äôa plein de mondes paralleles partout :) Dans la physique quantique y‚Äôa de la teleportationQuantique ou pas ?Les quantum dots ? Oui ! Alors que ca existe depuis longtempsC‚Äôest une technique qui modifie la frequence d‚Äôun photon pour en changer sa couleur en couleur primaireFireforx quantum Non c‚Äôest que le nomSamsung quantum Oui et non (ah ca c‚Äôest bien quantique)Oui car n‚Äôimporte quel modele de processeur aujourd‚Äôhui a des transistors utilisant des phenomenes quantiquesNon car ca n‚Äôutilise par le quantique de $2^e$ generationQubole quantum ? NonFinish quantum max? NonWhat is to be ‚Äúquantum‚Äù ? Une forme finie qui ne peut pas etre divisee ?Meh, tu peux pas avoir un demi-bac C‚Äôest lie aux proprietes de la matiere Taille et/ou energie inferieure a un certain ?Oui Une propriete importante: la dualite des particules: une bivalence de comportement (onde ET particules)Un peu d‚ÄôhistoireConference de Solvay A eu lieu a Bruxelles, BelgiqueCette photo marque la fin de la periode mettant en place les bases de la physique quantique.Pourquoi Einstein a recu un prix nobel ? Grace a l‚Äôeffet photoelectrique et NON la theorie de la relativiteCe papier est l‚Äôun des fondement de la physique quantique, et l‚Äôa fait a 26 ansQui a recu 2 prix Nobel ? Marie Curie, qui est la seule personne a avoir recu $2$ prix nobels dans $2$ domaines differentsPrecursorsUn grand nombre de travaux du $19^e$ siecle ont ete les bases de la physique quantique: Thomas Young William Rowan Hamilton Niels Henrik Abel Charles Hermite James Clerck Maxwell Ludwig Boltzmann Henri Poincare David Hilbert Pieter Zeeman Hendrik LorentzYoung‚Äôs slit experiment - 1806Maxwell electro-magnetic waves - 1865Zeeman effect - 1896Founders Max Planck Emmy Noether Albert Einstein etc.Quantum physics beginnings$1^{er}$ date: decouverte - $2^e$ date: prix nobel $1900-1918$: Max Planck black body radiation energy quanta Un four Une etoile etc. Planck constant $1905-1921$: Albert Einstein photoeletric effect $1913-1922$: Niels Bohr hydrogen atom model $1922-1944$: Stern-Gerlach experiment atoms angular momentum experimentaliste On a majoritairement des theoriciens et non exerimentalistes $1924-1929$: Louis de Broglie wave-particle duality $1924-1945$: Wolfgang Pauli exclusion particle $1925$: Uhlenbeck-Goudsmith Electron spin $1926-1933$: Erwin Schrodinger wave function \\(ih\\frac{\\partial \\Psi(x,t)}{\\partial t} = H\\Psi(x,t)\\) $1926-1954$: Max Born quantume probability $1927-1932$: Werner Heisenberg indertemination $1935$ Einstein, Podolski, Rosen: EPR paradox Erwin Schrodinger: C H A T papier sur l‚Äôintrication quantique il n‚Äôy a que 9 lignes sur le chat $1937$: Etore Majorana fermion: particule sans masse Il manque au moins $50$ personnes dans cette chronologieHow old were they ? Einseiberg: $24$ ans Einstein: $26$ ans Schrodinger: $39$ ans Planck: $42$ ansQuantum physics basicsPhysics domain classification Tout ca forme la theorie du tout Souvent les physicien faisant ca sont mono-maniaquesFrom macro to nano physicsQuantum physics $101$ Qu‚Äôest-ce qui est quantique ? Quantification Particules massives et non-massives $\\to$ dualite particule/onde Superposition des etats L‚Äôintrication Consequence de la superposition L‚Äôindetermination: \\(\\Delta x\\Delta p\\ge \\frac{h}{4\\pi}\\) La mesure quantique Quand on a nos etats superposes: on mesure et on obtient une des valeurs et non la superposition L‚Äôeffet tunnel Non-clonage Theoreme demontre a partir des postulats de la physiques quantique qui peuvent etre faux un jour Ecouter de la musique est une addition d‚Äôondes La teleportation c‚Äôest mort :( Le theoreme de non-clonage n‚Äôest pas invalide par la teleportation de Start TrekQuantification Quantization = discountinued nanoscopic properties of nanoscale amtter and light\\[B(\\lambda, T) = \\frac{2hc^2}{\\lambda^5}\\frac{1}{e^{\\frac{hc}{\\lambda k_BT}}-1}\\quad\\text{Planck law}\\] Rayleigh-Jeans law‚ÄúUltraviolet catastrophe‚Äù spectrum prediction in classical theory\\[B_{\\lambda}(T)=\\frac{2ck_BT}{\\lambda^4}\\]Black Body Radiaton $\\lambda_{max}$: peak wavelength Wien‚Äôs displacement law - 1893 \\[\\lambda_{max} = \\frac{2898}{T}\\]Light Spectrum Continous spectrum Sun, black body Absorption spectrum cold gas illuminated from behind by continuous spectrum Emission spectrum by rarified hot gas Quantification atoms et ions electrons autour de leur noyau $n =$ principal $I =$ angulaire $m=$ moment magnetique $s=$ spin photons polarization longueur d‚Äôonde phase number photon de meme frequence et onde quantique qui peuvent s‚Äôadditionner ca creer un GROS photon $\\to$ etat de Fock orbital angular momentum used to create qubits with distincts states and at the particle scale (atoms, electrons, photons)Dualite onde-particule Interference observed with photons photons acting as particle interferences observed with electrons\\[\\text{particle energy}\\to E=h\\nu \\leftarrow \\text{wave frequency}\\\\\\text{particle momentum}\\to p=\\frac{h}{\\lambda}\\begin{aligned}\\leftarrow\\text{Planck constant}\\\\ \\leftarrow\\text{wavelength}\\end{aligned}\\]Young slit experiment detailsSchrodinger‚Äôs equation\\[\\begin{aligned}i\\hbar\\overbrace{\\frac{\\partial\\Psi(x,t)}{\\partial t}}^{\\text{total energy}}=-&amp;amp;\\underbrace{\\frac{\\hbar^2}{2m}\\overbrace{\\frac{\\partial^2\\Psi(x,t)}{\\partial x^2}}^{\\text{kinetic energy}}+\\overbrace{V(x)\\Psi(x,t)}^{\\text{potential energy}}}_{}\\\\&amp;amp;\\hat H=-\\frac{\\hbar^2}{2m}\\frac{\\partial^2}{\\partial x^2}+V(x)\\quad\\text{Hamiltonian}\\end{aligned}\\] $i$: $i^2=-1$ $m$: particle mass $\\hbar=\\frac{h}{2\\pi}$: constante de Dirac $\\Psi$: l‚Äôinconnue de l‚Äôequation de Schrodinger Probabilite de trouver une particule massive a un endroit $x$ et un temps $t$ La derivee dans le temps est l‚Äôenergie de la particule Hamiltonian: function applicable to the particle wave function to evaluate its total energyConstraints\\(z = a+ib\\quad\\vert z\\vert=\\sqrt{a^2+b^2}\\)Complex number module\\(\\vert\\Psi(x,t)\\vert^2\\)Wave function module square\\(\\int^{+\\infty}_{-\\infty} \\vert\\Psi(x,t)\\vert^2 dx =1\\)Integral of the probability to find the particle in any position equals oneIndetermination\\(\\Delta x\\Delta p\\ge\\frac{h}{4\\pi}\\) $\\Delta x$: location precision $\\Delta p$: momentum precision $h$: Planck constantAt a nanoscopic scale, the pseed and position measurement precision are the antinomic, the greater one is, the smaller is the other Heisenberg microscope thought experiment: a photon sent on the electron will hcnage its trajectory and measurement Derivation: at a nanoscopic scale, measurement apparatus impacts measurement output Used in ‚Äúsqueezing‚Äù like with photons to increse one precision against the other Quantum sensing to increase measurement precision Also indirectly explains quantum Planck time, distance and massShortest time measurement\\(\\text{Planck time}\\quad t_p=\\sqrt{\\frac{\\hbar G}{c^5}}=\\frac{l_p}{c}\\)Shortest distance measurement\\(\\text{Planck distance}\\quad l_p=\\sqrt{\\frac{\\hbar G}{c^3}}\\)Maximal mass of an elementary particle Sinon ca fait un trou noir\\(\\text{Planck mass}\\quad m_p=\\sqrt{\\frac{\\hbar c}{G}}\\)Quantum physics postulates Quantum state The state of the quantum mechanical system is completely specified by a psi wave function $\\psi(x,y,z,t)$ returning a complex number value that depends on the coordinates of the particle and on time, also denoted a ket: $\\vert\\psi\\rangle$ in Dirac‚Äôs notation Physical quantities A physical quantity is evaluated with an observable operator acting on the $\\vert\\psi\\rangle$ wave function, the observable is an Hermitian matrix, with real eigenvalues Measurement The only values that can be measured are the eignevalues of the observable, it‚Äôs always a real number. When the spectrum of the observable is discrete, the results are quantized Born rule Defnes the expectation values and probabilities for $\\vert\\psi\\rangle$ properties State collapse After measurement, the wave function $\\vert\\psi\\rangle$ becomes the eigenvector corresponding to the eigenvalue obtained, the state of $\\vert\\psi\\rangle$ is irreversibly changed unless Time evolutionState superposition Quantum objects can be in superposed states Consequence wave-particle duality Since the Schrodinger wave equation is linear, any linear combination of solutions is also a solution qubit example: $\\vert\\psi\\rangle=\\alpha\\vert 0\\rangle+\\beta\\vert 1\\rangle$ corresponds to a linear superposition of $\\vert 0\\rangle$ et $\\vert 1\\rangle$ with complex amplitudeIntrication 2 quantum particles, particularly photons, can be prepred in a state that is correlated even at a long distanceSome applications Teleportation Algorithme Cryptographie Communication quantique etc.State reduction and measurement Before measurement, quantums are in a superposed state 2 levelss quantum state $\\vert\\psi\\rangle=\\alpha\\vert0\\rangle+\\beta\\vert1\\rangle$ $\\alpha^2+\\beta^2=1$ Quantum state readout $\\vert\\psi\\rangle=\\vert0\\rangle$ $\\vert\\alpha^2\\vert$ probability to get $\\vert0\\rangle$ $\\vert\\psi\\rangle=\\vert1\\rangle$ $\\vert\\beta\\vert^2$ probability to get $\\vert1\\rangle$ Another measurement will yield the same result $\\frac{1}{\\sqrt{2}}\\vert0\\rangle+\\frac{1}{\\sqrt{2}}\\vert1\\rangle$ $50\\%\\to\\vert0\\rangle\\to$ measurement $100\\%\\to\\vert0\\rangle$ $50\\%\\to\\vert1\\rangle\\to$ measurement $100\\%\\to\\vert1\\rangle$ Also quantum decoherence is progressively disturbing superposition and entanglement, like being a ‚Äúpartial measurement‚Äù from the environmnent qubits measurements is done only at the end of computing cannot measure a qubit state in the middle of an algorithm to do some Photons primerOne photon wavelength/frequency right/left polarization = spin angular momentum $+\\hbar$ or $-\\hbar$ vector direction in space massless no electric charge Photon wavenumber\\[k=\\frac{2\\pi}{\\lambda}\\] Photon mode Orhtogonal solutions of the EM wave equations Glauber state\\[\\vert a\\rangle=e^{-\\frac{1}{2}\\vert\\alpha_i\\vert^2}\\sum_{n=0}^{+\\infty}\\frac{\\alpha_i^2}{\\sqrt{n!}}\\vert n_i\\rangle\\] Fock state Tensor product of groups of photons of the modes $k_j$ \\[\\vert n_{k_0}\\rangle\\circ\\dots\\circ\\vert n_{k_n}\\rangle\\]Fourier transforms\\[\\hat f(\\xi) = \\int_{-\\infty}^{+\\infty}f(x)e^{-2\\pi ix\\xi}dx\\quad\\text{Fourier transform}\\\\f(x) = \\int_{-\\infty}^{+\\infty} \\hat f(\\xi)e^{2\\pi ix\\xi}dx\\quad\\text{inversion Fourier transform}\\]Classical, semi-classical and non classical forms of lights and photons Sun and blackbody light single mode laser coherent light gaussian wave packet entangled photons photon squeezed state Photon number Photon number superposition Antibunching non gaussian states Doppler effectSuperconductivitySome materials have 0 resistivity below a threshold temperatureSuperfluidityAt a very low temperature, helium 3 and 4 become superfluid and have no viscosityBose-Einstein condensated" }, { "title": "ALGOREP: Concensus for Asynchronous Systems", "url": "/cours/posts/algorep_consensus_async/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 16:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursEst-ce qu‚Äôon est capable de creer un consensus asynchrone ? Oui on l‚Äôutilise tous les joursUn papier theorique dit non mais si c‚Äôetait le cas Facebook et machin ne fonctionneraient pasEn tout cas c‚Äôest impossible dans un mode completement asynchroneFLP Abstract of the paperThe consensus problem involves an asynchronous system ofprocesses,some of which may be unreliable. The problem is for the reliable processes to agree on a binary value. In this paper, it is shown that every protocol for this problem has the possibility of nontermination, even with only one faulty process. Impossibility resultNo completely asynchronous consensus protocol can tolerate even a single unannounced process death.Problem descriptionConfigurations" }, { "title": "ALGOREP: How to build a Failure Detectors", "url": "/cours/posts/algorep_failure_detector/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOn a un ensemble de machine. Comment monitorer pour savoir qu‚Äôune est morte ? Si quelqu‚Äôun dans la salle a une machine qui meurt, on va le savoirSupposons qu‚Äôon a un admin 6, pourquoi c‚Äôest pas une bonne solution ? Ca se scale pas bienOn centralise dans un seul data center pour un systeme distribueComment on pourrait faire pour detecter les machines qui meurent de maniere auto ?Si on a une mamie agee, coment on sait ? On la rappelle le matin, le midi, a 14hEt si la mamie est tres lente a repondre au telephone ? On appelle une premiere fois, une seconde fois, etc.Au bout de certaines sonneries on la suppose morte On se forge une conviction de si la machine est vivante ou morte On est pas sur a $100\\%$ Desirable properties Completness Accuracy Speed Scale Equal load on each member Network Message Load What real failure detectors prefer ? Success and accuracy Scale &amp;amp; SpeedStrategiesCentralized heartbeatingOn a une machine centrale qui envoie des messages a tout le monde, sauf que la machine ne fait que ca et doit faire d‚Äôautre decisions On peut avoir une machine avec superposition de couches Un chef pour les fautes, un chef pour les decisions, etc. On empile les couches jusqu‚Äôa contrer le theoreme d‚ÄôimpossibiliteRing HeartbeatingOn va regarder nos voisins a gauche et a droite, pour propager le message qu‚Äôune machine est morte on doit faire le tour de l‚Äôanneau.Si notre voisin de droite est mort, comment on fait ? On veut se connecter a son voisin de droiteEt si son voisin de droite est mort aussi ?Soit on est coupe du reseau, soit systeme de cascade de mort de machinesAll-to-all heartbeating A processus heartbeats periodically all its neighbours If heartbeat not received from a process within timeout, mark this process as failedGossiping heartbeatingOn envoie un heartbeat a quelqu‚Äôun, cette personne dit telle ou telle personne est vivante On prend un pool de personnes random a qui envoyer notre heartbeatConclusion Heartbeat is a fundamental of Failure detection" }, { "title": "ALGOREP: Global Snapshot", "url": "/cours/posts/algorep_global_snapshot/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursProblem statement No global clock No shared memory Unpredictable message delay On est dans un data center, EDF coupe l‚Äôelectricite $\\Rightarrow$ on est mort.Comment est-ce qu‚Äôon backup ? Etienne nous dit de backup, il y en a un qui est un peu lent. Il y a un crash et on a loupe le backup On definit un etat stableQu‚Äôest-ce qu‚Äôon fait de l‚Äôinfo entre nous (les messages) ? Si on definit un etat stable ou rien ne transite, sinon c‚Äôest pas un systeme distrib On doit definir un backup pendant que des messages passent, des apps tournent, etc.Global state and cutsCuts DefinitionA cut in a time diagram is a line joining an arbitrary point on each process line that slices the space-time diagram into a PAST and a FUTURE.Global state DefinitionThe global state of a distributed system is a collection of the local states of the processes and the channels.Consistent cutQu‚Äôest-ce qu‚Äôon pense de cette cut ? Le probleme est qu‚Äôil ne faut pas qu‚Äôon soit dans des moment ou il y a un envoie et un evenement qui risque de ne pas etre retrouveElle est mauvaise parce que la coupe se fait avant l‚Äôenvoie $e_2$ mais aussi apr√®s la r√©ception de $g_4$Consistent Global stateOn a des regles: Tout envoi a une reception Une reception implique que l‚Äôenvoi est dans l‚Äôetat globalVoila une coupure coherente:Snapshot for FIFO channelsOn veut envoyer un message puis un deuxieme, comment on fait pour que le premier message arrive avant le premier ? Envoyer un message a tout le monde $\\to$ broadcastArreter ce que font les machines n‚Äôest pas une bonne ideeOn flush les canaux grace a la propriete FIFO avec le broadcast $\\to$ plus aucun message en transitProbleme: le leader envoie un message a tout le monde ‚Äúfait la snapshot‚Äù. Une machine rapide relaie le message a une machine lente qui n‚Äôa pas recu le message original, elle va recevoir 2 fois le meme message. Comment on fait ? On essaie de numeroter de maniere unique les snapshotsDans un snapshot, on s‚Äôen fiche des messages applicatifs.Prenons l‚Äôexemple de $f_3$-$e_4$, a ce moment un message est en transit. Comment on enregistre le message ? Dans ce cas, seul $F$ peut enregistrerOn va stocker dans les messages envoyes depuis notre derniere snapshotChandy-Lamport Algorithm : InformalCorrectness When a process $j$ receives a message $m_{i,j}$Complexity Message complexity$O(e)$ for the record of a single instance of the algorithm, with $e$ the number of edges in the graph Time Complexity$O(d)$ time with $d$ the diameter of the graphRemarks The recorded global state may not correspond to any of the gloal states that occured during the computation\\[\\color{red}{\\text{BUT...}}\\] The recorded global state may not corresponds to any of the global states that occurred during the computation The recorded global state is a valid state in a equivalent executionSnapshot for non-FIFO channelsOn envoie $A$ puis $B$, on suppose qu‚Äôon peut recevoir $B$ avant $A$Lai Yang AlgorithmOn est tous initialement d‚Äôune couleur (ex: blanc). On se met en rouge si on fait une snapshot et on envoie des messages.Qu‚Äôest-ce qui se passe si on recoit un message rouge ? Quelqu‚Äôun a fait un snapshot et c‚Äôest en coursA partir de maintenant j‚Äôenvoie que des messages rougesComment on sait quels etaient les messages en transit ? Tous les messages blancsLe recepteur va sauvegarder les messages comme etant en transitOn n‚Äôest pas capable de: Borner les delais d‚Äôun message Avoir une file de messageAu moment de redemarrer le systeme, on ne renvoit pas de message blanc et on peut les integrer au snapshot directement au lieu de simuler leur reception.Pour ne pas faire $\\color{white}{\\text{blanc}}$ $\\color{red}{\\text{rouge}}$ $\\color{white}{\\text{blanc}}$, on fait plutot $\\color{white}{\\text{blanc}}$ $\\color{red}{\\text{rouge}}$ $\\color{purple}{\\text{violet}}$ $\\color{green}{\\text{vert}}$ etc.Si on recoit des messages blanch en snapshot violet, il y a un probleme dans le systeme. Ce n‚Äôest pas grave du moment que la couleur de la derniere snapshot est de la meme couleur pour toutes les machines.Mattern‚Äôs Algorithm Horloge de MatternComment on fait si on veut manger chez Glados jeudi soir ? On envoit un message ‚ÄúA 19h je mange chez Glados‚ÄùOn va faire pareil pour cete algoOn se dit ‚ÄúRDV a un million‚Äù pour un snapshot (au plus tard). Avant la reception du message a 1 million, les machines doivent faire leurs snapshots" }, { "title": "ALGOREP: Consensus (with failures) in synchronous systems", "url": "/cours/posts/algorep_consensus_sync/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-13 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursOn vote a la majorite pour pizza vs kebab. Ca suppose: Qu‚Äôon est impair Chaque voix a le meme poids Que la majorite est d‚ÄôaccordSupposons qu‚Äôon soit $11$, on ne peut pas arriver a un consensus si quelqu‚Äôun ne repond pas. Ca suppose: La machine est morte Le lien avec la machine est mortWhat is a consensus ? Defintion: consensusAll process must agree on a value even if inputs can be arbitrary. There is generally a validity condition describing the outputs values that are permitted for each patterns‚Äô input Agreement on wether to commit or abort transaction in a database Agreement on a specific value reading multiple captors (altitude for instance) Classification of a component as faulty On va construire des algos tolerants aux fautes.Link FailuresThe coordinated attack problemOn a un ensemble de generaux qui attaquent une ville. La seule facon qu‚Äôils aient de prendre la ville seraient de se coordonner. Ils peuvent communiquer avec des messagers Les messagers peuvent se faire tuer Est-ce que j‚Äôattaque ou pas ? Comment faire quand les communications ne sont pas fiables ? On sait qu‚Äôil faut 10 min pour faire le trajet entre 2 generauxOn demande aux messagers de revenirMais si le messaer a transmis le message mais ne revient pas ? On en renvoit un autreMais s‚Äôil se fait tuer aussi ? L‚Äôassassin a un tas de cadavreOn peut decouper les interactions de nos generaux en rounds.Fleche verte: message envoye0/1: ne pas attaquer/attaquerIl y a un moment ou on peut perdre un message ($\\color{green}{\\to}$)Comment faire ? On prend une valeur par defaut si on n‚Äôattend pas de consensus (spoiler: non) Supposons qu‚Äôon supprime un message.Est-ce qu‚Äôon a un changement pour le processus $P_2$ ? Non, pour lui ca ne change rien Or, pour un algorithme qui marche avec consensus, il faut que tous les processus soient en accord en meme temps.On peut toutefois tres bien dire qu‚Äôon s‚Äôarrete en $D-1$ round et que l‚Äôautre message peut etre perdu. On peut se limiter au round precedent, on baisse la complexite de l‚Äôalgo.On peut donc supprimer le message $P_2\\color{green}{\\to} P_1$ precedent, et de la meme maniere surprimer le message $P_1\\color{green}{\\to} P_2$Comment $P_1$ prend la meme decision que $P_2$ ? On sait qu‚Äôon a toujours une decision qui doit etre prise au plus tard qu round $D$Or, si on n‚Äôa pas envoye de message, la decision etait connue de tout le monde au round $D-1$On repete l‚Äôetape pour le round $D-1$ jusqu‚Äôa arriver aux premiers message On construit un algo sans envoi de messages Un algo commence avec $0$, $0$ est decideUn algo commence avec $1$, $1$ est decideQuelle est l‚Äôunique facon de changer de configuration ? De recevoir un message C‚Äôest une execution bivalenteRecapOn veut faire un consensus dans tous les systemes distribues. Dans un systeme synchrone, on suppose qu‚Äôon a des problemes avec des liens, on montre le theoreme de l‚Äôimpossibilite et qu‚Äôun message peut etre perdu indefiniment.On se base donc sur un etat pour tout le monde et le seul moyen de changer de configuration est de recevoir un message.Impossibility Result Let $G$ be a graph with 2 nodes connected by a single edge. Then, no algorithm solves the coordinated attack problem on $G$ Proof (by contraction) Suppose a solution exists, given by an algorithm $A$ Let $\\alpha$ be the execution when both processes starts with $1$ and eventually outputs $1$ with all messages delivered. Let $\\alpha_1$ be the same than $\\alpha$ except that all messages are lost after $r$ rounds. In $\\alpha_1$ both processes output $1$. Let $\\alpha_2$ be the same than $\\alpha_1$ except that the last (round $r$) message from process $1$ to process $2$ is not delivered. $\\alpha_1\\sim^1 \\alpha_2$ : $\\alpha_1$ is indistinguishable from Œ±2 from process $1$ point of view Since process $1$ outputs $1$ in $\\alpha_1$, then it outputs $1$ in $\\alpha_2$. By termination and agreement, process $2$ outputs $1$ Let $\\alpha_3$ be the same than $\\alpha_2$ except that the last message from process $2$ to process $1$ is not delivered. $\\alpha_2\\sim^1 \\alpha_3$ : $\\alpha_2$ is indistinguishable from $\\alpha_3$ from process $2$ point of view. Since process $2$ outputs $1$ in $\\alpha_2$, then it outputs $1$ in $\\alpha_3$. The same for process $1$ by termination and agreement. IMPOSSIBLE!Process failuresProblem Statement What if communications are reliable, but processes may fail ?2 kinds of failure models: Stopping failures: Processes may stop without warning Byzantine failures $1$ : fautly processes may exhibit completely unconstrained behaviors.FloodsetComment regler ca ? FloodSet: FloodingOn calcule le diametre de notre systemeExampleStopping Algorithm: EIG Etienne : ‚ÄúJ‚Äôexplique mal et vous comprenenez mal‚ÄùOn va se baser sur un EIG treeCet algo va marcher direct pour les fautes byzantines Etienne est vivant, envoie un message et creve.Comme ca on peut deduire a quel round Etienne est mortExampleLe processus $3$ echoue au round $1$ mais a envoye un message au processus $1$ mais pas au processus $2$.Comment $2$ peut etre au courant que $3$ a envoye un message a $1$ ? $1$ doit lui relayer le messageA la dernier ligne, on doit savoir quelle info a ete propagee par le processus $3$, le dernier etage de l‚Äôarbre doit etre le meme pour tous les processus corrects. Si on veut supporte $20$ fautes, il faut avoir $20$ lignes Construction On initie le $1^{er}$ etage de l‚Äôarbre avec sa propre valeur et on la propage aux autres Au $2^e$ etage on recoit la valeur initiale des autres processus Pour tous les autres rounds, le process $i$ diffuse une pair $(x,v)$ qui va etre un des labels de l‚Äôetage precedent Il se construit en se basant sur l‚Äôetage precedent et en recevant la valeur des autres elements Why byzantine is more complicated than stopping ? Three processes cannot solve the agreement problem if one of them is faulty !" }, { "title": "IMCO: Describing color", "url": "/cours/posts/imco_des_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-09 14:00:00 +0200", "snippet": "Lien de la note HackmdDescribing a relative color Need of a vocabulary to describe a color 2 (or more) objects may be all blue, but different Need additional descriptions within colors How do we organize colors ?Blue jacket ?All of this is blueThis is navy blueThis is dark navy blue What about colors that are hard to describe ?How ? - Desert Island ExperimentA person with normal color vision is on an island and need to group pebbles Think about colo in terms of common color names (red, blue, green, etc.) How to arrange achromatic samples ? Orders from darker to lighter How to arrange chromatics smaples ? By color (hue) Example: group all red pebbles together How to arrange chromatic samples of the same hue ? order by lightness order by how much color they contain (chroma) We know how to arrange chromatic samples of the same hueColor attributesWe found color attributes Pyschological attributes that describe colors: Hue Lightness Definition: HueAttribute of a visual sensation according to which an area appears to be similar to one of the perceived colors: red, yellow, green, and blue, or to a combination of 2 of them achromatic color: perceived with lacking hue chromatic color: perceived color with hue 11 primitives colors$\\color{white}{\\text{white}}, \\color{gray}{\\text{gray, }}\\color{black}{\\text{black, }} \\color{red}{\\text{red, }}\\color{green}{\\text{green, }} \\color{yellow}{\\text{yellow, }} \\color{blue}{\\text{blue, }} \\color{orange}{\\text{orange, }} \\color{purple}{\\text{purple, }} \\color{pink}{\\text{pink, }} \\color{brown}{\\text{brown}}$Elementary colors: white, black, red, green, yellow, blue unique hues according to opponent color theory Definition: Lightness Brightness: attribute of a visual sensation according to which an area appears to emit, or reflect, more or less light $\\to$ relative Lightness: the brightness of an area judged relative to the brightness of a similarity illuminated area that appears to be white or highly transmitting $\\to$ absolute \\[\\text{Lightness}=\\frac{\\text{Brightness}}{\\text{Brightness(white)}}\\] Definition: Chroma Colorfulness: Attribute of a visual sensation according to which the perceived color of an area appears to be more or less chromatic Chroma: Colorfulness of an area judged as a proportion of the brightness of a similarly illuminated area that appears white or highly transmitting \\[\\text{}Chroma = \\frac{\\text{Colorfulness}}{\\text{Brightness(white)}}\\]Color Order SystemsMunsell Color systemComposition: Hue 10 hues (each divided into 10 subhues) Lightness (called Value) 11 steps (0: ideal black, 10: ideal white) Chroma Range depending on the hue Eyes are all differently sensitiveNotation: H V/C H = Hue, V = Value, C = Chroma e.g. 5Y 7/12 or 5R 1/4 Munsell Color Tree from PantoneHow to communicate color ? Pantone and other organizarionsPantone Color-Naming System Used in the printing/manufactuing industry Swatches are used to specify colors Printed using 14 inks Useful for specifying communicating color Patented ! Need a license to use the listDescribing Relative ColorColor Mixing SystemsAmounts give a specification, not the resulting color RGB value ${100, 20,90}$ in your screen $\\neq$ RGB ${100, 20,90}$ in my screen CMY value ${90, 10,50}$ in your printer $\\neq$ CMY ${90, 10,50}$ on my printer RGB value ${100, 20,90}$ in my screen $\\neq$ CMY ${90, 10,50}$ on my printerHSV/HSL Spaces Hue: color Saturation: measure of chroma Value or Lightness: measure of lightnessHSV/HSL difference: HSL: maximum lightness = white HSV: maximum Value = ‚Äúintense‚Äù colorHSV $\\leftrightarrow$ RGBYCbCr Space Y is Luminance $\\simeq$ Brightness Cb is related to blue Chrominance Cr is related to red Chrominance Used a lot in color compressionDecompositionDivide image in RGBDivide Image in HSVDivide image in YCbCrUse Case - Color Segmentation HSV or YCbCr can be used in Image and Video Processing (e.g., skin segmentation)However, as RGB and CMYK, resulting color is only relative to capture conditionDescribing Standard Color Use an universal way (i.e., numbers) to communicate color instead of using names Need to standardize the color forming conditions Illuminant (viewing lighting) Observer (the human visual response to a given stimulus) Object reflectance ($\\lambda$-dependent spectral measurement) ColorimetryCIE Standard Observers Light sources (primaries): $435.8nm$, $546.1nm$, $700nm$ CIE 1931 Standard Colorimetric Observer $2^o$ visual angle ($2^o$ Observer) $17$ color normal observers CIE 1964 Standard Colorimetric Observer $10^o$ visual angle ($10^o$ Observer) 76 color normal observers CIE Standard Iluminants D: Different types of daylight D50 ($\\color{cyan}{5003K}$) (warm daylight) printing/graphic arts D65 ($\\color{blue}{6504K}$) (natural daylight) art/film/photography A: incandescent lamp ($\\color{orange}{2856K}$) F: Fluorescent light F2 (4230K), F11 (4000K) Color TemperatureTemperature uses as a reference an ideal object called ‚ÄúBlack Body‚Äù Definition: Black BodyAn object that absorbs completely heat and light, and radiates the energy back. It radiates light when heated.CIE Standard Iluminants Warm: $T \\lt 3300K$ Dormitory, Restaurant, Hotel, Coffee Shop Intermediate: $3300K\\lt T\\lt 5300K$ Stores, Shcool, Libraries Cold: $T\\gt 5300K$ Offices, Hospitals Computing XYZ Tristimulus Values $XYZ$ Tistimulus Value $\\to$ amounts of 3 specified stimuli required to match a color\\[\\begin{aligned}X &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar x_{\\lambda}d\\lambda\\\\Y &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar y_{\\lambda}d\\lambda\\\\Z &amp;amp;= k\\int_{\\lambda}I(\\lambda)R(\\lambda)\\bar z_{\\lambda}d\\lambda\\\\\\end{aligned} \\quad k =\\]Chromaticity Diagrams: CIE 1931All Hues are perceivable by the standard observer MacAdam EllipsesWhere are the grey ? Brown ? No light info !Uniform color spaces CIE XYZ Space is not perceptually uniform equal perceptual differences between colors $\\neq$ equal distances in the XYZ space CIE recommenced uniform color spaces CIE 1976 $L\\times u\\times v$ CIE 1976 $L\\times a\\times b$ ExampleIn matplotlib:CIE $L\\times a \\times b$ Space\\(L^* = 116f(\\frac{Y}{Y_n})-16\\begin{cases}a^* = 500[f(\\frac{X}{X_n})-f(\\frac{Y}{Y_n})]\\\\b^* = 200[f(\\frac{X}{X_n})-f(\\frac{Y}{Y_n})]\\end{cases}\\)$L\\times C\\times h$What‚Äôs left ? Modeling cognitive effects or phenomena How to obtain absolute color attributes (brightness and colorfulness) ? Debate about accuracy of $\\bar x, \\bar y, \\bar z$ Color Matching Functionc Representativeness of the population used for the experiments Limitaations of equipment used for the experiments How to understand color perception of ‚Äúcolor anomalous‚Äù observers ? " }, { "title": "IMCO: Defining colors", "url": "/cours/posts/imco_def_colors/", "categories": "Image S9, IMCO", "tags": "Image, S9, IMCO", "date": "2021-09-09 10:00:00 +0200", "snippet": "Lien de la note HackmdWho Am I ?Ricardo SAPAICO PhD in Computer Science, Tokyo Institute of Technology 10+ years of expereicneAbout DXO Labs ~18 years 50 people working in FranceProducts DxO PhotoLab LightRoom like DxO PureRaw Smaller version of PhotoLab Editing images quickly EISA award Nik Collection by DxO Plugin for Adobe DxO FilmPackBack to the courseWhy color matters ? Useful for quality inspection Rely on color for a small object Gives shape (shine color light on objects and create shadows) Cultural heritage Paintings If you take a picture of a painting, you want the photo to represents the painting well Same for printing a copy of the painting Printing Computer graphics Even tho not physical, you have to make sure you have the good colrs Photography Sometimes, it‚Äôs just a matter of doing the right thing to have a good picture From color to B&amp;amp;W is not easy Style Transfer IA on photography Hyperspectral images Evaluation Attendance Each class attended, you get $+0.5$ Writtent report Exercises using the data we will obtain during the TPs A litlle bit of investigation for solving a typical color-related probleme in cameras Group of 2 people Participation bonus: You can get up to $+2.0$ in your grade if: You ask me technical question by mail You ask technical questions in the IMCO group (Teams) You reply a technical question in the IMCO group (Teams) Defining colors White becomes pink with reflectionWhat is (not) color Color is NOT a property of an object Once in the dark, no more color Someone colorblind will see the color differently Color is NOT a particle Color is a sensation like touch Color is a sensation produced by a physical reality Grass is NOT green and sky is NOT blue,They are perceived as green and blueThey have physical properties that makes them look that way Color is in your HEADHow is color produced ? Sun: light Apple: object Human: sensorElectromagnetic spectrumHow can you see the black if it doesn‚Äôt reflect any light ? Because there is a shape (ex: a TV)Black isn‚Äôt a color but we can perceive itIf we have a white surface and a red beam of light coming in, it would reflect the red.ObjectSurface and subsurface interaction with light specular absorption diffuse transmittance refraction scattering To know of colors will work on this textile, you can only know it by printing hundreds of colors and extrapolate for the other onesColor is no ‚Äòpart‚Äô of an object Dimension, shape, material (what it‚Äôs made of), volume, density, porositySensorHuman vision system ReminderRefractive index:\\[n=\\frac{c}{\\nu}\\] Cornea The most significant image-forming element of the eye Eye problemes, such as nearsightedness, farsightedness, astigmastism, can be attributed to it Lens Serves the function of accomodation It is layered, flexible structure that varies in index of refraction. This feature serves to reduce some of the aberrations Distant object: it becomes ‚Äúflatter‚Äù resulting in the decreased optical power Nearby object: it becomes ‚Äúfatter‚Äù thus has increased power As we age, we lose flexibility. When we are about 50 years, the lens has completely lost its flexibility Iris + pupil controls the pupil size Pupil is the hole in the middle of the iris through which light passes. The pupil size is largely determined by the overall level of illumination Pigmentation in the iris is what gives us color Retina A thin layer of cells, approximately the thickness of tissue paper Contains the visual system‚Äôs photosensitive cells + initial signal processing and transmission ‚Äúcircuitry‚Äù Photoreceptios: Rods and Cones Fovea Area on the retina where we have the best spatial and color vision Optical nerve Transfer info from the retina to the brain 1 million fibers vs 130 million photoreceptors There is a compression of the visual system There are no photoreceptors where the nerve is blind spot Rods and conesCones: useful to perceive colorRods: useful in low-light3 types of cones: Long Medium Short Fun factMost mammals have only blue and green cones, only primates have redColor matching experiment The observer adjusts the intensity of the primary colors until the results matches the testThis test was like 100 years ago Chromaticity diagram Spectrum LocusChromaticity of monochromatic light at specified wavelengthSpatial properties of Color VisionIn JPEG we have an image divided in luminance and chromatic information. Our eyes are less sensitive to chromatic infos, so JPEG subsamples then reconstructs the imageHow to (re)produce color ? Additive process (RGB) Light mixing Substractive process (CMY) Used in printing Paint mixing Color frameworkBonusFacts about animals Most fish, frogs and turtle and 3 to 5 cones Most mammals have retinas where rods predominate Is it because the Earth was dark when first mammals appeared ? Nocturnal mammals like rats and mice have retinas dominated by rods (only 3 to 5% of cones) Snakes can see ultraviolet lightWhy the eyes reflect the light ? In the eyes, there are epithelial cells Epithelial cellsPrevents light from going back to the retina $\\to$ keeps the sharpness and contrastNocturnal animals exchange image quality for image power. Their cells reflects the light back $\\to$ the photoreceptors have a second chance to absorb energy Different than having red eyes !Structural color: IridiscenceUsed for camouflageFacts about humans Red-green color blindness $8\\%$ males (XY chromosome) $0.5\\%$ females (XX chromosome) of northern European descentAround $12\\%$ of the female population could be tetrachromaticTo think over What is fluorescence ? Why a banana stays yellow under 2 different light sources ?" }, { "title": "CMKV: Metropolis-Hastings et recuit simule", "url": "/cours/posts/cmkv_hal_recuit/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-08 14:00:00 +0200", "snippet": "Lien de la note HackmdRappels$P(X=x)$ =&amp;gt; variable aleatoire $x$: ne pas lister toutes les valeurs possibles pour $X$\\[P(X=x\\underbrace{,}_{\\text{et}} Z=z)\\]On le notait $\\cap$ au lycee\\[P(A\\cap B) = P(A).P(B)\\] $X = (X_1,\\dots,X_n)$ est un vecteur aleatoire $x = (x_1,\\dots,x_n)$ est une realisation SudokuIl existe une solution dediee mais on ne la connait pas $\\color{red}{x_1}$ $\\color{red}{x_2}$ ¬† ¬† $\\color{red}{x_4}$ $2\\color{green}{\\rightarrow y_1}$ ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† \\[P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=1\\\\x_4=1\\end{cases}\\]Dans ce cas, on ne regard que 3 realisations et on va les evaluer\\[P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=1\\\\x_4=3\\end{cases}\\\\P(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =1\\\\x_2=3\\\\x_4=4\\end{cases}\\\\P(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\end{vmatrix}) = ?\\begin{cases}x_1 =3\\\\x_2=1\\\\x_4=4\\end{cases}\\\\P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\end{vmatrix})\\color{green}{\\lt}P(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\end{vmatrix})\\color{green}{\\lt}P(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\end{vmatrix})\\color{green}{=}P(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\end{vmatrix})\\\\\\color{red}{\\boxed{L(X=x\\vert Y=y) = P(Y=y\\vert X=x)}}\\\\\\]On veut reecrire $f(x,y)=\\cos(x)\\sin(\\frac{1}{y})$ en $g(y,x)$\\[g(a,b)=\\cos(b)\\sin(\\frac{1}{a})\\]Retour au sudoku: on sait parler des probas et des vraisemblances On lit les donnees a un espace de recherchePour avoir des vraisemblances:\\[\\begin{aligned}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;1 \\\\ 3\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{}&amp;amp;L(\\begin{vmatrix}1\\vert&amp;amp;3 \\\\ 4\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\color{red}{=}&amp;amp;L(\\begin{vmatrix}3\\vert&amp;amp;1 \\\\ 4\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})\\\\&amp;amp;\\overbrace{L(\\begin{vmatrix}2\\vert&amp;amp;1 \\\\ 1\\vert&amp;amp;\\color{red}{2}\\end{vmatrix})}^{\\downarrow}&amp;amp;\\uparrow&amp;amp;&amp;amp;\\end{aligned}\\] Rappel : Bayes\\(\\begin{aligned}x_{\\text{sol}} = \\text{arg max}_x&amp;amp;\\underbrace{P(X=x\\vert Y=y)}\\\\&amp;amp;=\\color{blue}{\\frac{L(X=\\boxed{x}\\vert Y=y)P(X=\\boxed{x})}{P(Y=y)}}\\end{aligned}\\)La meteo de GulliLe retour de rand()\\[\\begin{cases}P(\\text{beau}) = 0.5 &amp;amp;\\color{red}{\\varnothing}\\\\P(\\text{pourri}) = 0.3 &amp;amp;\\color{red}{1}\\\\P(\\text{couvert}) = 0.2 &amp;amp;\\color{red}{2}\\end{cases} \\leftarrow P(T=t)\\quad t\\in{\\text{\\{beau}}, \\text{pourri}, \\text{couvert\\}}\\] $0 ¬† RANDMAX $\\varnothing\\dots\\varnothing$ $1\\vert\\color{red}{1}\\dots1$ $2\\dots2$ C‚Äôest pareil pour le sudoku: tout depend de toutOn va voir comment calculer des probas ou les variables ne sont pas independantes\\[\\begin{aligned}y&amp;amp;\\rightarrow\\\\u&amp;amp;\\rightarrow\\end{aligned}\\bigcirc\\rightarrow x_{\\text{sol}} = \\text{arg max}_xP(X=x\\vert Y=y)\\]\\[\\begin{cases}P(\\text{beau}) = 0.4 \\\\P(\\text{pluie}) = 0.1 \\\\P(\\text{couvert}) = 0.2 \\\\P(\\text{orage}) = 0.2 \\\\P(\\text{neige}) = 0.2\\end{cases}\\\\\\color{red}{x_{sol} = beau}\\]On a un echantilloneur:\\[P\\rightarrow \\bigcirc \\rightarrow x\\] Il y a plus de chances que l‚Äôechantilloneur ne nous donne pas la bonne solutionHypothese\\[U\\to P?\\\\\\text{hypothese}: \\not\\exists x, P(x)=\\varnothing\\\\P(X=x)=\\boxed{\\color{red}{\\frac{1}{Z}}e^{-U(x\\color{green}{,y})}}\\Rightarrow U(x)=-\\log(Z.\\underbrace{P(X=x)}_{\\color{red}{\\text{ouf}\\neq\\varnothing}})\\\\\\sum_xP(X=x)=1\\Rightarrow Z=\\sum_xe^{-U(x)}\\gt\\varnothing\\text{ une constante}\\]Un algo: Metropolis-HastingsIl a ete invente en meme temps par 2 chercheurs\\[x^{(0)} = \\begin{vmatrix}1&amp;amp;1\\\\1&amp;amp;\\not 2\\end{vmatrix} = \\color{red}{\\begin{pmatrix}1\\\\2\\\\1\\end{pmatrix}}\\\\x^{(1)} = \\begin{vmatrix}2&amp;amp;1\\\\3&amp;amp;\\not 2\\end{vmatrix} = \\color{red}{\\begin{pmatrix}2\\\\1\\\\3\\end{pmatrix}}\\\\\\vdots\\\\x^{(t)}=\\begin{vmatrix}\\bullet&amp;amp;\\bullet\\\\\\bullet&amp;amp; \\bullet\\end{vmatrix}\\] Initialisation: $x^{(0)}$ tire aleatoirement avec loi uniforme $t\\leftarrow\\varnothing$ Repeter jusqu‚Äôa l‚Äôinfini (un algo‚Ä¶ a l‚Äôinfini) On fait juste un tres grand nombre d‚Äôiterations Repeter jusqu‚Äôa l‚Äôinfini: \\(x_{\\text{rand}}\\) tire avec loi uniforme \\[P_{\\text{trans}} = \\frac{P(X=x_{\\text{candidat}})}{P(X=x^{(t)})}\\] Si \\(P_{\\text{trans}}\\gt 1\\color{red}{\\Leftrightarrow P(X=x_{\\text{candidat}})\\gt P(X=x^{(t)})}\\) Alors \\(x^{(t+1)}\\leftarrow x_{\\text{candidat}}\\color{green}{\\equiv\\text{ MIEUX = ON GARDE}}\\) Sinon on fait \\(\\color{green}{\\boxed{x^{(t+1)}\\leftarrow x_{\\text{candidat}}}}\\color{red}{\\Leftrightarrow P(x_{\\text{candidat}})\\lt P(x^{(t)})}\\) avec la proba \\(P_{\\text{trans}}\\le 1\\) Sinon $x^{(t+1)}\\leftarrow x^{(t)}$ $t\\leftarrow t+1$ Quel est cet algo ? C‚Äôest un algorithme de descenteCet algo est tel que la fonction $P(x^{(t+1)})\\ge P(x^{(t)})$, quand $t$ augmente, $P(x^{(t)})$ augmente aussi. C‚Äôest un optimiseur hyper sous-efficace Surtout compare a des algos de descenteExemple $0$ RANDMAX $1\\dots\\color{green}{\\boxed{1}}1$ $0\\dots0$ \\[i_{\\text{trans}} = 0.8 \\times \\text{RANDMAX}\\] Si rand() \\(\\lt P_{\\text{trans}}\\times\\) RANDMAX $x^{(t+1)}\\leftarrow x_{\\text{candidat}}$ Sinon $x^{(t+1)}\\leftarrow x^{(t)}$\\[\\begin{aligned}P(X=x) &amp;amp;= \\frac{1}{Z}e^{-U(x)}\\\\P_{\\text{trans}} &amp;amp;= \\frac{\\not{\\frac{1}{Z}}e^{-U(x_{\\text{candidat}})}}{\\not{\\frac{1}{Z}}e^{-U(x^{(t)})}}\\\\&amp;amp;= e^{-(\\underbrace{U(x_{\\text{candidat}}) - U(x^{(t)})}_{\\color{red}{\\Delta U}})}\\end{aligned}\\]Recuit simuleComme les forgerons qui chauffe la lame d‚Äôune epee, qui la mette dans l‚Äôeau le temps de manger, la rechauffe en revenant et la laisse refroidir lentement a l‚Äôair libre apres avoir ete formee Apres avoir ete dans l‚Äôeau, l‚Äôepee est cassante On atteint l‚Äôetat le plus stable possible en lassant refroidir lentement, l‚Äôepee est la plus solide possible C‚Äôest un etat de basse energie qui pourrait etre trouve dans la natureAlgorithme Initialisation $T^{(\\varnothing)}\\leftarrow$ elevee On repete: $\\not P\\to P_{T^{(t)}}$ $T^{(t+1)}\\simeq T^{(t)-}$ $t\\leftarrow t+1$ \\[P_{\\color{red}{T}}(X=x) = \\frac{1}{Z_{\\color{red}{T}}}e^{-U(x)}\\\\P(X=x)\\propto e^{-U(x)}\\\\P_{\\color{red}{T}}(X=x)\\propto e^{-\\frac{U(x)}{T}}\\\\U_T(x)=\\frac{U(x)}{T}\\]Exemples d‚Äôutilisation On prend une image en niveau de gris qu‚Äôon stylise On prend une image qu‚Äôon veut binariser, avec le moins de regions blanchesoires possibles mais les plus grandes possiblesEst-ce qu‚Äôon a la meilleure solution ? On en a pas la moindre ideeRetour sur l‚Äôalgo Initialisation: $\\not x^{(0)}$ tire aleatoirement (avec loi uniforme) $t\\leftarrow\\varnothing$ $\\quad\\color{blue}{T^{(0)}\\leftarrow \\text{elevee}}$ Repeter jusqu‚Äôa l‚Äôinfini (un algo‚Ä¶ a l‚Äôinfini) Repeter jusqu‚Äôa l‚Äôinfini: \\(x_{\\text{rand}}\\) tire avec loi uniforme \\[P_{\\text{trans}} = \\frac{P_{\\color{blue}{T}}(X=x_{\\text{candidat}})}{P_{\\color{blue}{T}}(X=x^{(t)})}=e^{\\frac{-(U(x_{\\text{candidat}}-U(x^{(t)})))}{\\color{blue}{T^{(t)}}}}\\] Si \\(P_{\\text{trans}}\\gt 1\\) Alors \\(x^{(t+1)}\\leftarrow x_{\\text{candidat}}\\color{green}{\\equiv\\text{ MIEUX = ON GARDE}}\\) Sinon on fait \\(\\color{green}{\\boxed{x^{(t+1)}\\leftarrow x_{\\text{candidat}}}}\\) avec la proba \\(P_{\\text{trans}}\\le 1\\) Sinon $x^{(t+1)}\\leftarrow x^{(t)}$ $\\color{blue}{T^{(t+1)}\\leftarrow\\propto T^{(t)}\\text{ ou } \\propto=1^{-}}$ $t\\leftarrow t+1$ Si on fait un tirage aleatoire, est-ce que c‚Äôest intelligent de mettre que des $1$ dans une grille vide d‚Äôun sudoku ? Non, c‚Äôest la meme proba de mettre des $1$ que n‚Äôimporte quel autre chiffre $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{2}$ $\\color{blue}{2}$ $\\boxed{2}$ $\\boxed{3}$ $\\color{blue}{2}$ $\\color{blue}{3}$ $\\color{blue}{3}$ $\\color{blue}{3}$ $\\boxed{4}$ $\\boxed{1}$ $\\color{blue}{4}$ $\\color{blue}{4}$ $\\color{blue}{4}$ C‚Äôest quoi l‚Äôinteret de ce tirage ‚Äúmoins con‚Äù? (et pas du tout aleatoire) On peut changer $x^{(t)}$ aleatoirement (en echangeant des cases par exemples) $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{blue}{1}$ $\\color{red}{\\boxed{3}}$ $\\color{blue}{2}$ $\\boxed{2}$ $\\boxed{3}$ $\\color{blue}{2}$ $\\color{blue}{3}$ $\\color{red}{\\boxed{2}}$ $\\color{blue}{3}$ $\\boxed{4}$ $\\boxed{1}$ $\\color{blue}{4}$ $\\color{blue}{4}$ $\\color{blue}{4}$ On met de l‚Äôintelligence dans cet algo qui a vraiment besoin d‚Äôetre aleatoire\\[P_{T\\to+\\infty}(X=x)=\\frac{1}{Z}e^{-\\frac{U(x)}{T}}\\\\\\color{red}{P_{+\\infty}(x) = \\frac{1}{Z}}\\quad\\text{uniforme}\\\\\\color{green}{P_1(x)=P(x)\\\\P_0(x)=\\varnothing\\quad\\forall x}\\] Ce n‚Äôest pas une loi de probabilite car la somme des probas $=0$On va determiner la loi de probas autrement, en regardant par exemple un ratio:\\[\\frac{P_T(X=x_{\\text{solution}})}{P_T(X=x)}=e^{\\boxed{\\frac{-(\\overbrace{U(x)-U(x_{\\text{solution}})}^{\\color{red}{\\text{positif}}})}{T\\color{green}{\\to 0^+}}}}_{\\color{blue}{\\to-\\infty}}\\to 0^+\\\\\\frac{P_0(x\\neq x_{\\text{solution}})}{P_0(x_{\\text{solution}})} = \\varnothing\\\\\\begin{cases}\\forall x\\neq x_{\\text{solution}}, P_0(x)=\\varnothing\\\\P_0(x_{\\text{solution}}) = 1\\end{cases}\\]\\[\\downarrow\\\\P_0(x)=\\begin{cases}1&amp;amp;\\text{si } x=x_{\\text{solution}}\\\\\\varnothing &amp;amp;\\text{sinon}\\end{cases}\\]" }, { "title": "ALGOREP: Logical Time", "url": "/cours/posts/algorep_logical_time/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-06 10:30:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursProblem statementDans la classe, qui s‚Äôest reveille avant qui ? $1^{ere}$ proposition: on demande l‚Äôheure du reveil de tout le mondeProbleme: il faut que tout le monde ait un horloge On ne peut pas faire l‚Äôhypothese qu‚Äôon a une horloge pour tout le monde, sinon on est synchroneLes horloges peuvent avoir des divergences Quelqu‚Äôun peut dire qu‚Äôil est debout depuis 5h alors qu‚Äôen fait il etait 8h $2^{eme}$ proposition: On envoie un message des qu‚Äôon se leve (ne le fait pas, c‚Äôest pas bon pour la sante)On ne doit pas avoir de delais de transmission du message Quel evenement a eu lieu avant quel evenement ?Est-ce qu‚Äôon a vraiment besoin de cette info ? $1^{ere}$ proposition: pour savoir quand est-ce qu‚Äôune faute est arrivee et on relance le systeme dans un etat precedent $\\Rightarrow$ c‚Äôest une snapshot On n‚Äôa pas de garanti sur le delais des messagesIl faudrait prendre en compte la latence des messages et c‚Äôest trop complique On va utiliser des horloges logiquesOn va essayer de construire un systeme ou on date les evenements par rapports a des evenements logique $\\Rightarrow$ les envois de messages ‚ÄúJ‚Äôai vu le message d‚ÄôEtienne avant de manger ma tartine‚ÄùConsider 3 processes $E$, $F$ et $G$ With some local events: $e_1$, $f_1$, $f_3$, $g_2$, $g_3$ With some send events: $g_1$, $f_2$, $e_2$ With some receive events: $e_3$, $f_4$, $g_4$Ces 2 executions sont impossibles a distinguer On va donner une notion de progresScalar Time: Lamport ClocksDefinitions Rule R1Before executing an event (send, receive, or internal), process pi executes the following\\[C_i:=C_i+d\\quad\\text{with } d\\gt0\\text{, typically 1}\\] Rule R2Each message piggybacks the clock value of its sender at sending time. When a process $p_i$ receives a message with timestamp $C_{msg}$ , it executes the following actions : $C_i := max(C_i, C_{msg} )$ Execute R1 and deliver message Example1.2.3.4.5.6.7.Remarques On peut utiliser l‚Äôhorloge de Lamport pour l‚Äôordre Il suffit de dire $e_1 \\lt g_1$ Si on incremente toujours de $1$, $h-1$ sera toujours le temps requis pour atteindre le process $e_h$ No Strong ConsistencyProblem The main problem in totally ordering events is that two or more events at different processes may have identical timestamp !Vector Time: Mattern Clocks On va toujours maintenir un compteur On va avoir une horloge local par processus On gere comme une horloge de Lamport On maintient son horloge et celle de tout le mondeComment est-ce qu‚Äôon peut connaitre l‚Äôetat d‚Äôun processus ? En envoyant un message On echange avec une $3^e$ personne qui n‚Äôa jamais echange avec EtienneOn lui transmet l‚Äôavancement d‚ÄôEtienneSi cette 3e personne envoie un message a Etienne, elle connaitra son avanceePourquoi une personne tierce ? Si on est que 2, on echange des messages qu‚Äôa 2 et on ne peut pas mettre en avant des horloges complexesEn pratique, comment est-ce qu‚Äôon fait passer notre compteur local ? Quand on structure un programme distribue, on incremente l‚Äôhorloge local a des points stables (barre de progression de chargement, etc.)Example On envoie un message a $G$, on veut savoir s‚Äôil l‚Äôa recu mais il ghostIndirectement, on apprend que $G$ a avance de $5$ elements donc il est vivant, mais est-ce qu‚Äôil a recu le message ?On sait que $F$ n‚Äôavait pas d‚Äôinformation de notre part au departLe $2$ envoye par $E$ a $G$ a ete renvoyee par $F$, sachant que $E$ n‚Äôa pas envoye de message a $F$ auparavantOn sait donc que $F$ a recu le message de $E$RemarquesEfficient Implementation of Vector ClocksComment on implemente ca de maniere efficace ? ImplementationOn peut garder les $n$ derniers messages avec nos voisins, on peut juste envoyer le differentiel de la derniere heure envoyer par quelqu‚Äôun et l‚Äôhorloge couranteProblem Qu‚Äôest-ce qu‚Äôil se passe si j‚Äôai une inversion de messages ?Est-ce qu‚Äôon est capable de gerer ce cas avec les horloges precedentes ? Non. On va utiliser les ragots $\\Rightarrow$ des matrices d‚Äôinformations On m‚Äôa dit que tu m‚Äôas dit que‚Ä¶\\[\\begin{vmatrix}E&amp;amp;F_E&amp;amp;G_E\\\\E_F&amp;amp;F&amp;amp;G_F\\\\E_G&amp;amp;F_G&amp;amp;G\\end{vmatrix}\\]La machine qui a le plus de communication serait-elle celle qui a le plus de chance d‚Äôetre a jour sur la timeline des processus sur chaque machine ? Oui.Virtual Time System DefinitionVirtual time system is an (optimistic) paradigm for organizing and synchronizing distributed systems Relies on Time Warp mechanism, i.e. lookahead-rollback mechanism When a conflict is discovered, the offending processes are rolled back to the time just before the conflict Processes are then executed forward along the revised pathConclusion Different kind of logical time Virtual time system (Jefferson) is a paradigm for organizing and synchronizing distributed systems" }, { "title": "ALGOREP: Leader Election", "url": "/cours/posts/algorep_leader/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-06 09:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursLeader Election in a Synchronous RingProblem statement The netwok digraph is a ring with $n$ nodes All processes are identical Each process can only communicate with clockwise neighbors and counterclockwise neighbors One process outputs ‚ÄúI‚Äôm the leader‚Äù while the other process output ‚ÄúI‚Äôm note the leader‚ÄùSi tu prend 2 robots identiques, ils divergent lors de la connexion au reseauImpossibility Result for Identical Processes TheoremLet $S$ be a system of $n$ processes, $n \\gt 1$, arranged in a bidirectionnal ring. If all the processes are identical then $S$ does not solve the leader-election problem.Sketch of proof Suppose there is a system $S$ that solves this problem Without loss of generality, we can assume that each process of $S$ have a unique initial state. By induction on the number $r$ of rounds, all the processes are in identical states immediately after $r$ rounds. Then if a process reaches a state where it considers to be the leader, all the other processes do so. But this violates the uniqueness requirementProblem Statement $\\color{red}{Revisited}$ The network digraph is a ring with $n$ nodes All processes are identical $\\color{red}{\\text{except for a UID}}$ Each process can only communicate with clockwise neighbour and counterclockwise neighbourPropositions: Envoyer un message disant ‚ÄúJe suis peut-etre leader‚Äù Mais beaucoup de messages Anneau unidirectionnelLCR Algorithm Chaque processus envoie son UID Quand il recoit un UID, il le compare avec le sien Si l‚ÄôUID est plus grand, il l‚Äôenvoie a son voisin Sinon discard $n$ machines = $n$ roundsComplexity Meilleur cas: $O(n)$ messages Pire cas: $O(n^2)$ messages Quand un noeud est elu, $n$ rounds et $n$ messages sont necessairesHS Algorithm (comparison-based) Bidirectionnal Ring The size of the ring is unknown Comparison-based algo $\\color{red}{\\text{It elects the process with the maximum UID}}$Algorithm On a des phases de process $i$ Dans chaque phase $l$ Process $i$ send out tokens containings its $UID_i$ in both directions Tokens travel distance $2^l$ and return to their origin $i$ When a process $i$ receive a token $t$ containing $UID$ $t_{uid}$ if $t_{uid}$ $\\lt$ $UID_i$ then the token is discarded if $t_{uid}$ $\\gt$ $UID_i$ then the process $i$ relays the token if $t_{uid}$ $=$ $UID_i$ then the process is the leader If both tokens come back safely, process $i$ starts a new phase Otherwise the process considers itself as a non-leader Communication Complexity Phase 0: tout le monde envoie un message a gauche et a droite et recoit un message des 2 cotes On envoit 4 messages par noeud: $4\\times n$ messages Phase $l$: On a survecu a la phase $l-1$, il y a $2^{l-1}+1$ qui sont morts autour de moi, il y a $\\lfloor\\frac{n}{2^{l-1}+1}\\rfloor$ process qui envoient un messgae a cette phase. Le nombre de message est $4\\times 2^l \\lfloor\\frac{n}{2^{n-1}+1}\\rfloor\\le8n$ How many phases are executed before a leader is elected ?\\[1+\\lceil\\log n\\rceil\\] The number of messages is at most $8n(1 + \\lceil\\log n\\rceil)$Time Complexity The time complexity for phase $l$ is $2^{l+1}$ $\\color{red}{\\text{The complexity of all but the final phase is }2\\times2^{\\log n}}$ In the final phase takes $n$ since tokens only travels outbound The final complexity is at most $3n$ (if $n$ is power of $2$) $5n$ otherwise.Summary $O(n)$ $O(n\\log n)$TimeSlice AlgorithmLower Bounds Comparison-basedThe best case is $\\Omega(n \\log n)$ messages. Non-Comparison-based$O(n)$ messages can be reached but only at the cost of large time complexity (Ramsey Theorem).Leader Election in otherFlooding AlgorithmBreadth-First Search We want to build the directed spanning tree for the networkExample Children pointersLeader ElectionMinimum Spanning TreesComment est-ce qu‚Äôon construit un arbre courant en sequentiel ? ‚ÄúOn enfile des noeuds‚Äù (mais c‚Äôest un BFS ca)Problem StatementHow to find the minimum/maximum spanning tree ? A minimum-weight spanning tree minimizes the total cost for any source process to communicate with all the other process in the network$\\color{red}{\\text{Let us assume that } n \\text{ is known}}$Est-ce qu‚Äôon a besoin d‚Äôun leader ? Minorite de oui: on aurait besoin de quelqu‚Äôun qui synchro tou, mais c‚Äôest trop sequentielMajorite de non On peut synchroniser avec les process avec les rounds Imaginons que Mael est un process, qu‚Äôil a un lien avec Etienne et tout le mondeImaginons qu‚Äôon peut ponderer les liens (Etienne$\\leftrightarrow$Mael $=$ fibre, les autres wifi)Imaginons que quelqu‚Äôun a une connexion encore plus rapide avec MaelComment est-ce qu‚Äôon se met d‚Äôaccord ?$1^{ere}$ suggestion: tableau de booleens pour savoir qui se co a qui $\\Rightarrow$ Mais qui stock le tableau ?$2^{eme}$ suggestion: tout le monde a le tableau de boolens $\\Rightarrow$ infernal de synchro tout le monde Reprenons naivement:2 process s‚Äôenvoient des messages mutuellement, le composant est creeMaintenant il faut elire un chefSi tous les process sont synchro par 2, maintenant on peut synchroniser 2 pairesOn continue jusqu‚Äôa synchro tous les composants Avec cette strategie, on aura un temps de propagation plus long pour un message (2 messages au lieu de 1)2 interets: Le BFS est complique a faire, on lancais $n$ BFS Beaucoup de messages sequentiels en parallele Maximiser le fait qu‚Äôon soit en distribueQu‚Äôest-ce qu‚Äôon va faire apparaitre avec cette methode ? Du $\\log$ car on divise par 2 a chaque foisComment faire pour savoir les liens d‚Äôun composant avec le reste du monde ? Quand on creer une paire, les process peuvent echanger leurs listes de voisinsOn peut faire une phase de flooding dans le composantComment ca genere un arbre courant ? 2 process creent un arbre courant entre euxOn rajoute une paire, on a un arbre courant a 4etc.Ou est-ce que l‚Äôarbre courant va etre stocke ? Chacun va avoir une vision localeSi jamais un composant a 2 voisins avec le meme degre minimal, comment faire ? Si ce composant ne repond pas a un des 2 voisins dans le temps imparti, c‚Äôest qu‚Äôil s‚Äôest mis avec l‚Äôautre Avec cette methode, on perd les performance de notre systeme On a un composant qui peut faire des aggregations simultanees pour avoir des performances resonnablesComplexity Time: $O(n\\log n)$ Communication: $O((n+\\vert E\\vert)\\times\\log(n))$ $O(n)$ messages sent per level Remarks Non-unique edge weightWe can define a lexicographic order using UID of processes Leader electionWhen building the MST a leader is elected naturally !" }, { "title": "ALGOREP: Introduction", "url": "/cours/posts/algorep_intro/", "categories": "Image S9, ALGOREP", "tags": "Image, SCIA, S9, AlGOREP", "date": "2021-09-03 14:00:00 +0200", "snippet": "Lien de la note HackmdLes slides du coursIntroduction to Distributed AlgorithmsSupposons qu‚Äôon soit tous des machines, avec CPU, GPU, etc.On interroge quelqu‚Äôun qui repond vite, et un autre qui repond lentement. Si on a pas de reponse, on envoie une 2e message.Comment tu determines la difference entre un etudiant mort et un etudiant lent ?En tant que machine on ne sait pas.Forewords A distributed system is a collection of independant computers that appears to its users as a single coherent systemAndrew S. Tanenbaum A distributed system is one in which the failure of a computer you didn‚Äôt even know can rend you computer unusableLeslie LamportMais pourquoi ?L‚Äôutilite: La securite La stabilite Un ordi qui crash $\\neq$ tout qui casse Probleme de matos Google ne peut pas tout stoquer sur un ordi Si une machine apprend quelque chose, on peut la transmettre Si le prof meurt mais nous a transmis ses infos, on peut continuer son cours C‚Äôest la replicationWhat is a distributed system ? DefinitionA distributed system is: A collection of autonomous computer connected through a network which enables computers to coordinate their activities so that users perceive the system as a single one Exemple Grid/Cluster computing World Wide Web Network File Server Banking Network Bosser la-dedans pour se faire de la moula Peer-to-peer Network Process Control System Sensors NetworkParallel versus Distributed ?ParallelDistributedPitfalls in Distributed Systems ! The network is reliable The network is secure The network is homogeneous The topology does not change Latency is zero Bandwith is infinite Transport cost is zero There is one administrator pas d‚Äôadministrateur tout-puissant Challenges distributed systems ? Scalability Avoid Bottlenecks, Good Performances, Physical Ressources Heterogeneity Network, hardware, OS, programming language, implem Concurrency Managing shared ressources Failures Detect, masking, tolerating, recovery, redundancy Communications Synchronous, asynchronous In this class Systeme distrib point de vue theorique et pratique Concepts generaux Passer de programmes complexes a une abstraction algorithmes analyse de complexite presenter les resultats d‚Äôimpossibilite Practical through a project Un bon gros projet sa mere Groupe de 4 Specs faibles pour appliquer le cours Model Assumptions Modeles IPCs Notion de temps On a pas tous la meme frequence/horloge Modele synchrone Modele asychrone c dur resume a un modele partiellement synchrone Model partiellement synchroneAbstractionsComment avoir une vue d‚Äôensemble ? Il faut monter en abstractionForewords Success really depends on the conception of problems, the design of the system, not on the details of how it‚Äôs coatedLeslie LamportMaximal AbstractionOn va se donner un graphe noeud: unite de calcul lien: topologieProcesses (informally) Local event: je calcule fibonnacci Send message: j‚Äôai fini de calculer fibonnacci Receive message: mon voisin a fini de calculer fiboVarious Timing models Synchronising processes is one of the most difficult part of distributed systemAsynchronous model No timing assumption about processes and channels, i.e. no physical assumptions about delays. Each process have local view of time called logical time Any time an event occurs (local or global) at process p, its logical clock is updated: local event increase logical time by one unit global event requires more complex strategies (details in a later lecture). Synchronous modelIl y a un tick La tout le monde est vivant La tout le monde est mortAu moment du tick: evenements locaux envois de messages recevoir des messagesEst-ce que c‚Äôest realiste ? D‚Äôapres la majorite de la classe, non On est capable de simuler ce tickComplexity in Synchronous ModelQu‚Äôest-ce qui nous ralentit ? On peut avoir un algo en tete qui marche hyper bien mais une fois implemente pas du tout, juste a cause de l‚Äôenvoie de messages DefinitionUn tick s‚Äôappelle un round (espace entre 2 pointilles rouges) Pour determiner le tick: Utiliser l‚Äôhorloge interne Avoir le meme temps envoye aux machines2 measures of complexity are considered for synchronous distributed algorithms Time Complexity: measured in term of number of rounds until all the required outputs are produced. Communicatin Complexity: measured in term of non-null messages that are sent. (We may also sometime consider the number of bits in these messages).Partially Synchronous modelQuand on effectue une tache, on sait par avance le temps qu‚Äôelle prend. Ca nous permet de faire de la detection de fautes (programme qui a crash, etc.)Process Failures Model Process Failures: Until it fails, a process is supposed to execute the algorithm assigned to it On a une hierarchie de problemes. Quand on parle de tolerance aux fautes, on dit qu‚Äôon est tolerable jusqu‚Äôa $n$ fautes. Arbitrary fault (Byzantines) Je peux supporter n‚Äôimporte quel type de faute, meme les actes de malveillance Omissions On ne va pas recevoir un message C‚Äôest un black-out Revenir peut etre dur Lies A process that does not send expected responses Often due to malicious behavior Crashes RecoveryLink failure Crash, Loss, Duplicate can be addressed by some lower level protocol, for instance TCP As long as the network remains connected, link crashes may be masked by routing Link Crashes reveal a lot of impossibility results (see later lectures)Link Abstraction Fair-loss Links Stubborn links Perfect links Le monde ideal Combining AbstractionsClassical combinations Fail Stop Fail Noisy Fail RecoveryAbstracting PropertiesBasic properties of Distributed Systems Safety states that the algorithm should not do anything wrong Liveness On sait qu‚Äôon va finir par obtenir une certaine ressource states that eventually something good happens Conclusion L‚Äôunique facon de faire des systemes distribues est d‚Äôutiliser des abstractions" }, { "title": "CMKV: Introduction", "url": "/cours/posts/cmkv_intro/", "categories": "Image S9, CMKV", "tags": "Image, SCIA, S9, CMKV, sudoku, pastis", "date": "2021-09-02 14:00:00 +0200", "snippet": "Lien de la note Hackmd DefinitionStatistiques: comptage et representation de donnees DefinitionProbabilite: phenomene dont on extrait un modeleOptimisation combinatoireOn a une grille, on veut la remplir pour que ca devienne un echequier via un algorithme Est-ce que notre algo est deterministe ?Oui, car on a toujours le meme resultat avec la meme entree.Si la couleur d‚Äôune case est aleatoire, l‚Äôalgo n‚Äôest plus deterministe. DefinitionUn algo est stochastique si a l‚Äôinterieur il y a de l‚Äôaleatoire # algorand()#algo L‚Äôaleatoire provient de l‚ÄôentreeIl existe des programmes stochastisques et deterministes.rand() est-il deterministe ? Oui. C‚Äôest dingue, hein ?\\[\\Omega=\\{A,B,C,D\\}\\\\\\begin{cases}P(A)\\in[0,1], \\text{idem pour } B,C\\text{ et } D\\\\P(A)+P(B)+P(C)+P(D) = 1\\end{cases}\\]ExempleNous sommes une population, on mesure la probabilite d‚Äôavoir 20 ans.\\[\\underbrace{P(20)}_{P(A)}=0.36\\]Maintenant avec la meteo:\\[\\Omega=\\{\\text{beau},\\text{pluie},\\text{couvert}\\}\\\\\\begin{cases}P(\\text{beau}) = 0.51\\\\P(\\text{pluie}) = 0.01\\\\P(\\text{couvert}) = 1 - 0.21 - 0.01\\end{cases}\\]Faire action avec la proba $P$\\[P(\\varnothing)=P(1)=P(2)=...=\\frac{1}{\\text{RANDMAX}}\\]Retour sur la meteo:\\[\\begin{cases}P(\\text{beau}) = 0.3\\\\P(\\text{pluie}) = 0.5\\\\P(\\text{couvert}) = 0.2\\end{cases}\\] Le probleme: certaines variables aleatoires ne sont pas independante (salaire, categorie pro, etc.)SUDOKUOn doit ecrire un programme qui resout le sudoku ¬† 1 ¬† ¬† ¬† ¬† 2 ¬† ¬† ¬† 3 ¬† 2 ¬† ¬† $\\square$ On a \\(4^{12}=16,7M\\) de valeur possibles.On va bruteforce, cad visiter plein de chemins possibles pour remplir. Les $16$ millions de possibilites de remplissage vont baisser mais vont rester elevees. La resolution prend du temps :(Mais, au lieu de faire un algo bete, on fait quoi ? On rentre dans un probleme d‚Äôoptimisation combinatoire. On enumerait les nombres de remplissage possibleMais pourquoi un probleme d‚Äôoptimisation ?On obtient un espace a 12 axes, la solution est quelque part dans l‚Äôespace On cherche le minimum ou le maximum de la fonction \\(x_{\\text{sol}}=\\text{arg min}_xf(x)\\)Ah et evidemment pas moyen que ce soit une fonction convexe.Pour les gens du fond:Resolution de Sudoku . . . . . 2 3 . 1 . . . . . . 4 \\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\frac{1}{4^{12}}\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\frac{1}{4^{12}}\\] Quand on ne sait pas, on fait de l‚ÄôequiprobableMais on sait, c‚Äôest un sudoku:\\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 1\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = \\varnothing\\]\\[P(x_{\\text{sol}})=1\\\\\\forall x\\neq x_{\\text{sol}}, P(x)=0\\] On peut pas juste ecrire notre solution comme ca‚Ä¶ ‚ÄúCertaines solutions sont plus vraies que d‚Äôautres‚ÄùLe camarade qui a dit un truc important Par ‚Äúvrai‚Äù, on veut dire proche de la solution $\\equiv$ peu d‚Äôerreur\\[P(\\begin{matrix}\\begin{vmatrix}3 &amp;amp;1\\\\4&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}4 &amp;amp;2\\\\3&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;4\\\\2&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}2 &amp;amp;3\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 0.00001\\\\P(\\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;2\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}) = 0.0\\dots 01\\] La prob est plus elevees que le resteLa meteo de Gulli\\(\\begin{matrix}P(A&amp;amp;\\cap&amp;amp;B)\\\\\\text{beau} &amp;amp;&amp;amp;\\text{Londres}\\\\\\text{temps} = \\{\\text{pourri, ...}\\} &amp;amp;&amp;amp;\\text{lieu} = \\{\\text{Londres, Paris, ...}\\}\\end{matrix}\\) $T$ VA pour rpz le temps $P(T=\\text{beau})=0.6$, $P(T=\\text{pourri})=0.1$, ‚Ä¶\\[\\color{red}{\\boxed{P(T=t)}}\\] $V$ vecteur aleatoire, \\(V=(V_1,...,V_n)\\), \\(V_i\\) var aleatoire\\[P(T=t\\color{red}{\\underbrace{,}_{\\text{et}}}L=l)\\color{green}{\\equiv f(t,l)\\in]\\varnothing,1]}\\begin{cases}t\\in\\{\\text{beau, pourri,}\\dots\\}\\\\l\\in\\{\\text{Londres, Paris,}\\dots\\}\\end{cases}\\]\\[P(A\\cap B)=P(A)+P(B)-P(A\\cup B)\\\\\\bar A+\\cap + \\cap + \\bar B-\\bar A-\\cap -\\bar B\\]Exemple$W$ weather, $L$ location, $N$ thune de Xavier NIEL.$P(W=w,L=l)\\equiv$ proba qu‚Äôil fasse \\(\\color{red}{\\underbrace{\\boxed{\\text{w a l}}}_{\\text{beau a Londres}}}\\)\\[\\begin{aligned}P(A\\cap B)&amp;amp;=P(A\\vert B).P(B) \\\\= P(B\\cap A) &amp;amp;= P(B\\vert A).P(A)\\\\&amp;amp;\\Rightarrow P(A\\vert B)=\\frac{P(A\\cap B)}{P(B)}\\end{aligned}\\]\\[\\begin{aligned}x_{\\text{sol}}=\\text{arg max}_x P(X=x&amp;amp;\\vert Y=y)\\\\&amp;amp;\\downarrow\\end{aligned}\\\\\\frac{\\overbrace{P(Y=y\\vert X=x)}^{\\color{blue}{f(x,y)}}.P(X=x)}{\\underbrace{P(Y=y)}_{\\color{red}{\\text{terme constant}}}}\\\\\\underbrace{L(X=x\\vert Y=y)}_{\\color{green}{\\text{VRAISEMBLANCE}}}.\\underbrace{P(X=x)}_{\\color{green}{\\text{A PRIORI}}})\\]Retour au SUDOKU\\[y=\\begin{matrix}\\begin{vmatrix}y_1 &amp;amp;\\\\&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix} &amp;amp;\\\\2&amp;amp;x_p\\end{vmatrix}\\\\\\begin{vmatrix}3 &amp;amp;\\\\&amp;amp;\\end{vmatrix}&amp;amp;\\begin{vmatrix} &amp;amp;\\\\&amp;amp;4\\end{vmatrix}\\\\\\end{matrix}\\\\y=(0,0,0,0,0,\\color{red}{1},\\color{green}{2},0,\\color{blue}{3},0,0,0,0,0,0,\\color{orange}{4})\\\\y=(y_1,...,y_{15})\\\\y_6=1\\\\x=(x_1,x_2,x_3,x_4,x_6,\\color{red}{0},\\color{green}{0},x_p,\\color{blue}{0},\\dots)\\\\x&#39;=(1,1,1,1,1,\\color{red}{0},\\color{green}{0},1,\\color{blue}{0},\\dots)\\]En solution:\\[\\color{green}{P(}x&#39;\\color{green}{)}= \\begin{matrix}\\begin{vmatrix}1 &amp;amp;1\\\\1&amp;amp;0\\end{vmatrix}&amp;amp;\\begin{vmatrix}1&amp;amp;1\\\\0&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}0&amp;amp;1\\\\1&amp;amp;1\\end{vmatrix}&amp;amp;\\begin{vmatrix}1&amp;amp;1\\\\0&amp;amp;1\\end{vmatrix}\\\\\\end{matrix}\\color{green}{=?}\\\\\\color{green}{P(}x&#39;&#39;\\color{green}{)}= \\begin{matrix}\\begin{vmatrix}1&amp;amp;2\\\\3&amp;amp;0\\end{vmatrix}&amp;amp;\\begin{vmatrix}3&amp;amp;4\\\\0&amp;amp;1\\end{vmatrix}\\\\\\begin{vmatrix}0&amp;amp;1\\\\4&amp;amp;3\\end{vmatrix}&amp;amp;\\begin{vmatrix}4&amp;amp;3\\\\2&amp;amp;0\\end{vmatrix}\\\\\\end{matrix}\\color{green}{=?}\\\\\\]Recap\\[\\color{red}{P_{\\color{pink}{T}}(X=x)=\\frac{1}{Z}e^{\\frac{-U(x)}{\\color{pink}{T}}}\\quad(z=\\sum_xe^{-U(x)})}\\\\\\color{green}{P_{\\color{pink}{T}}(X=x_{\\text{sol}})\\gt P_{\\color{pink}{T}}(X=x)\\quad\\forall x\\neq x_{\\text{sol}}}\\\\\\color{blue}{P(X=x_{\\text{sol}}) = 0.000001\\quad\\text{ECHANTILLONEUR }\\bullet\\to x\\text{ suivant }P(x)}\\\\\\color{pink}{\\lim_{T\\to0^+}P_T=\\begin{cases}\\color{green}{P_{\\color{pink}{0}}(X=x_{\\text{sol}})=1}\\\\\\color{green}{P_{\\color{pink}{0}}(X=x_{\\text{sol}})=\\varnothing}&amp;amp;\\text{sinon}\\end{cases}}\\]" }, { "title": "Kickoff Image", "url": "/cours/posts/kickoff_image_S9/", "categories": "Image S9, Kickoff", "tags": "Image, S9", "date": "2021-09-02 10:00:00 +0200", "snippet": "Lien de la note HackmdI‚Äôm a bee I‚Äôm a bee I‚Äôm a bee I‚Äôm a bee I‚Äôm a bee I‚Äôm a bee bee beeRetour sur le S8C‚Äôetait long et eprouvant‚Ä¶ Mais au moins pas de rendu en Septembre, donc plein de rendu en Juin/Juillet.Les notes Toutes les notes ont ete rendues Quelques couac dans le traitement des notes (IML disparu, PRST que les SCIAs ont mais pas nous) Les mono-groupes Pourquoi faire seul un travail a 2 ? Beaucoup plus de temps a corriger pour le prof car plus de groupes Pas OK pour les intervenants exterieurs PLUS DE MONOMES Ne sous-estimez pas AlgoRep en termes de charge de travail Le S9 est plus interessant Beaucoup d‚Äôintervenants exterieurs Point de vue industriel et applique Mais le semestre est celui ou on a le plus marre (recherche de stage, fatigue‚Ä¶) Il faut s‚Äôaccrocher (‡∏á‚ÄôÃÄ-‚ÄòÃÅ)‡∏áPresentation du S9 Le PFEE compte pour $2.5$ ECTS 1 ECTS = 30 heures de travail (cours inclu) Ca veut dire 75h de travail pour le PFEE (Presque) Tous les cours sont TP et TD dans les heures (pas que des cours magistraux)Champs de Markov Par Theo En commun avec les SCIAs On fini le cours tot mais le projet vient tard l‚Äôan dernier: fini fin Septembre mais projet debut Janvier Notion de proba stats, d‚Äôoptimisation pour resoudre les problemes ProjetAlgo Rep Par Etienne Demande BEAUCOUP de travail perso Projet mastoc 80h de travail par groupe Le genre de projet infinissable (RIP) Projet qui ne se rush pas on peut utiliser la semaine entreprise pour bien avancer le projet Un peu hors du scope de la majeureIMCO Par Ricardo, intervenant exterieur de DXO Normalement cours du S8 mais Ricardo ne pouvait pas Besoin de matos pour les TPs Presentiel OBLIGATOIRE TP note Ces 3 cours finissent en SeptembreVirtualite Virtuelle et Augmentee Ingenieur de EDF Commence plus tot que prevu (conge partenite de l‚Äôintervenant) QUE 7 casques (il faut reserver) NE SURTOUT PAS RESERVER UN CASQUE 48H AVANT LA DEADLINE Projet fun, c‚Äôest LE projet pour craquer son slipRendu Physique Realiste Sera peut-etre fusionne avec POGL2 Nouveau cours yay! Avec WebGLOCVX2 Guillaume et Bashard Complement d‚ÄôOCVX1 Optimisation avec contrainte Prob partielProbabilites et Statitisques Avancees Avec Noe PRST2 PartielAnimation 3D Cours et TP Super intervenant exterieur Fin des cours de Septembre ! On passe a OctobreTraitement video Comment le son est traite dans les videos Les 2021 avaient regrettes que les cours ne traitent pas le son La surprise de YvesImagerie Medicale 2 3 intervenants exterieurs Cours en 3 partiesImagerie Satellitaire On sait pas s‚Äôil aura lieu Et s‚Äôil a lieu, quand il aura lieu Par le directeur de These de Guillaume (wow !) Fin des cours d‚ÄôOctobre ! C‚Äôest l‚Äôheure de la semaine bullshit entreprise On passe a NovembreVision par ordinateur Intervenant exterieur OpenCV Ils envoient des robots sur Mars :0Deep Learning pour l‚Äôimage Joseph - Nicolas - Oliver Rajoute une seance par rapport a l‚Äôan dernier Veulent rajouter les GANs cette annee TRES dur d‚Äôavoir des cours a jour Les reseaux evoluent vite C‚Äôest pas top de donner un cours sur un truc qu‚Äôon a jamais manipule (temps de formation) Et des fois c‚Äôest bien de revenir aux reseaux de base :)Traitement Numerique du Signal TERASSE Guillaume de chez EDF PartielAnalyse Temps-Frequence Par Nicolas Domaine du traitement du signal au sens large Pas oublier qu‚Äôune image c‚Äôest un signal POGL2 Par Jonathan Pas que OpenGL avance TP sur Blender Cours probable: Mobilisation 3DCelui-la est VRAIMENT pas surPour la fin du semestre Janvier: c‚Äôest une blague Les partiels peuvent etre avant certains cours Sur le S9 c‚Äôest complique d‚Äôavoir les deadlines autant espacees que le S8Le mois de Janvier sera surtout TPs On essaie de finir tous les cours en DecembrePour les assistants Moins de cours pendant la piscine Mais des cours quand meme G&amp;amp;E ont ete prevenus de pas mettre de cours pendant la piscine‚Ä¶ jeudi dernier Pas de TPs notes Les cours ne sont pas deplacables Cours communs Image/SCIA Intervenants exterieurs bookes des mois a l‚Äôavance Cours enregistres ‚ÄúDispenses‚Äù de cours On va essayer alterner Image/SRS Peut-etre le mardi‚Ä¶ au pif‚Ä¶ parce que c‚Äôest du tronc commun La seule solution ca serait d‚Äôavoir cours le soir et le week-end‚Ä¶ Et c‚Äôest non.Commodal/PresentielPas encore fixes Directive de l‚Äôecole: 100% presentiel G&amp;amp;E sont pas giga d‚Äôaccord Encore un peu tot Anticiper un durcissement des regles Si pb (confinement), avec comodal pas de panique MAIS G&amp;amp;E aimeraient qu‚Äôon viennent presentiel le plus possible Pas normal de decouvrir de nouveaux noms/visages maintenant Mais G&amp;amp;E comprennent qu‚Äôil y a certaines contraintes et que certains preferent le comodal Ex: avoir cours a 9h et avoir 1h30 de transport On veut eviter de ravoir 4 eleves avec un intervenant exterieur Le presentiel pourra etre obligatoire On track les absences injustifiees 3/4 jokers Apres ca impact sur la note finale On veut au moins la moitie de la classe en presentielSi cas contact/contaminesSi on est positifs (vaccines ou pas), on reste chez soit.Les stagesQue 5 eleves pour la meilleure soutenance de stage :( On devrait rendre nos slides de soutenance de stage Pour eviter les catastrophes (cf. cette soutenance) Avoir une idee de ce qu‚Äôon presente Ca sera pour les 2023 pour assister a nos soutenances G&amp;amp;E valident les sujets de stage Ils sont en droit de ne pas valider Le stage doit etre en lien avec la majeureEn dessus de 12, on ne valides pas la soutenance Plus de soutenances confidentiellesRapports de stageSIEMENS a des droits d‚Äôauteur sur le rapport de stage S‚Äôy prendre a l‚Äôavance pour la soutenance Se renseigner sur le rapport de stage dans une entrepriseLe rapport de stage n‚Äôest pas une doc de ce qui a ete faitTrouver un stageLes stages se decantent vers Octobre-Novembre Pas de panique ! Y‚Äôa le temps Les entreprises font leurs budget vers Octobre-Novembre Les offres de stage vont commencer a arriverSalaireEntre 1000 et 1200 c‚Äôest bien, 600 c‚Äôest le minimum" }, { "title": "DBRE: Masterclass V2", "url": "/cours/posts/dbre_masterclass_v2/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-06-27 20:00:00 +0200", "snippet": "Introduction Le coeur de la protection d‚Äôun logiciel se fait via les droits d‚Äôauteurs. On n‚Äôa aucune solution dont on puisse etre sur a 100%.La solution la plus probable est celle retenue par les juges. C‚Äôest pas bon pour la securite juridique mais on ne peut pas faire autrementPropriete intellectuellesPour qu‚Äôune invention soit brevetable, il faut que l‚Äôinventeur ait une activitee inventive, cad trouver une solution pas evidente pour ‚Äúl‚Äôhomme du metier‚Äù. L‚Äôinventivite et l‚Äôevidence sont subjectifs.On doit aussi avoir un peu de personnalite de l‚Äôauteur, que l‚Äôoeuvre soit originale $\\rightarrow$ subjectifFair use Le ‚Äúfair use‚Äù n‚Äôa pas d‚Äôequivalents en droit francais.Une autre difficulte vient de la recherche constante du compromis entre ‚Äúaccordons suffisemment de droits pour que les gens creent‚Äù mais ‚Äúpas trop pour pas bloquer‚Äù.Exceptions Dans les proprietes intellectuelles, il y a des tonnes d‚Äôexceptions.Le but est de contrebalancer un monopole necessaire pour retablir un equilibre, mais cela cause des incertetitudes juridiques.Exemple Apres le premier sequencage du genome humain, le president des US a precise qu‚Äôil n‚Äôetait pas brevetable car ce sont des genes (de meme avec le genome du COVID-19)Il est tout a fait possible de depose un vaccin libre de droits (mais cela ne se fait pas car pas viable economiquement)Certaines personnes ne deposent pas de brevets car l‚Äôinvention peuvent vite devenir obsolete ou pour mettre l‚Äôinvention a disposition de la communaute.Monsanto n‚Äôa pas brevete du mais, mais une facon de le cultiverDiffusion d‚Äôune oeuvre Selon de la ou une oeuvre est diffusee, ce ne sont pas les memes droits qui s‚Äôappliquent $\\rightarrow$ cela ne depend pas de la nationalite de l‚Äôauteur.De meme pour le droit du travail.Exemple Nous utilisons teams conformement aux droits d‚Äôauteur francais. Si on vend des chaussures sur Internet, qu‚Äôon s‚Äôaddresse au public d‚Äôun pays, qu‚Äôon livre la-bas, etc. on est soumis au droit de consommation du pays en questionRecapLe monopole est confere pour favoriser la creation/innovation mais comporte un certain nombre d‚Äôexceptions pour ne pas avoir de blocage du marche.Le droit international prevoit une harmonisation pour qu‚Äôune oeuvre soit utilisee dans plusieurs pays, l‚Äôoeuvre depend des regulations de chacune des pays.La condition de protection La condition de protection est etudiee uniquement lorsqu‚Äôon veut faire valoir ses droits. Pourquoi me reprocher d‚Äôavoir copie quelquechose qui n‚Äôest pas protege ? Code de la propriete intellectuelle: une oeuvre est protegee si elle est originale. Mais ce n‚Äôest pas la seule condition de protection d‚Äôune oeuvre ! Est-ce que mon oeuvre est elligible au droit d‚Äôauteur ? Qu‚Äôest-ce qui, dans mon oeuvre, est considere comme protegeable? Ce ne sont pas les mots prits un a un Parmi la liste des oeuvres elligibles, je regardes quels elements sont originaux.$\\Rightarrow$ ce sont les etapes suivies par un juge lors d‚Äôun proces en contrefacon. Volet penal: passible d‚Äôune peine jusqu‚Äôa 3 ans de prison Volet civile: demander des dedomagemments ont consid√©r√©s notamment comme oeuvres de l‚Äôesprit au sens du pr√©sent code : 1¬∞ Les livres, brochures et autres √©crits litt√©raires, artistiques et scientifiques ; 2¬∞ Les conf√©rences, allocutions, sermons, plaidoiries et autres oeuvres de m√™me nature ; 3¬∞ Les oeuvres dramatiques ou dramatico-musicales ; 4¬∞ Les oeuvres chor√©graphiques, les num√©ros et tours de cirque, les pantomimes, dont la mise en oeuvre est fix√©e par √©crit ou autrement ; 5¬∞ Les compositions musicales avec ou sans paroles ; 6¬∞ Les oeuvres cin√©matographiques et autres oeuvres consistant dans des s√©quences anim√©es d‚Äôimages, sonoris√©es ou non, d√©nomm√©es ensemble oeuvres audiovisuelles ; 7¬∞ Les oeuvres de dessin, de peinture, d‚Äôarchitecture, de sculpture, de gravure, de lithographie ; 8¬∞ Les oeuvres graphiques et typographiques ; 9¬∞ Les oeuvres photographiques et celles r√©alis√©es √† l‚Äôaide de techniques analogues √† la photographie ; 10¬∞ Les oeuvres des arts appliqu√©s ; 11¬∞ Les illustrations, les cartes g√©ographiques ; 12¬∞ Les plans, croquis et ouvrages plastiques relatifs √† la g√©ographie, √† la topographie, √† l‚Äôarchitecture et aux sciences ; 13¬∞ Les logiciels, y compris le mat√©riel de conception pr√©paratoire ; 14¬∞ Les cr√©ations des industries saisonni√®res de l‚Äôhabillement et de la parure. Sont r√©put√©es industries saisonni√®res de l‚Äôhabillement et de la parure les industries qui, en raison des exigences de la mode, renouvellent fr√©quemment la forme de leurs produits, et notamment la couture, la fourrure, la lingerie, la broderie, la mode, la chaussure, la ganterie, la maroquinerie, la fabrique de tissus de haute nouveaut√© ou sp√©ciaux √† la haute couture, les productions des paruriers et des bottiers et les fabriques de tissus d‚Äôameublement. Article L112-2 Il n‚Äôy a pas de site web, jeux videos, etc. mais d‚Äôapres la jurisprudence ils en font partie. La jurisprudence a exclu a plusieurs reprises des textes sans originalite (definitions, lettre de l‚Äôalphabet, etc.).L‚Äôoriginalite qu‚Äôest-ce que c‚Äôest ? C‚Äôest l‚Äôempreinte de la personnalite de l‚Äôauteur. Ex: un style (en peinture, litterature, etc.).La titularite2 Hypotheses: Un oeuvre a un auteur unique La pluralite d‚Äôauteurs Article L111-1Modifi√© par LOI n¬∞2020-1674 du 24 d√©cembre 2020 - art. 35 (V) L‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit jouit sur cette oeuvre, du seul fait de sa cr√©ation, d‚Äôun droit de propri√©t√© incorporelle exclusif et opposable √† tous. Ce droit comporte des attributs d‚Äôordre intellectuel et moral ainsi que des attributs d‚Äôordre patrimonial, qui sont d√©termin√©s par les livres Ier et III du pr√©sent code. L‚Äôexistence ou la conclusion d‚Äôun contrat de louage d‚Äôouvrage ou de service par l‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit n‚Äôemporte pas d√©rogation √† la jouissance du droit reconnu par le premier alin√©a, sous r√©serve des exceptions pr√©vues par le pr√©sent code. Sous les m√™mes r√©serves, il n‚Äôest pas non plus d√©rog√© √† la jouissance de ce m√™me droit lorsque l‚Äôauteur de l‚Äôoeuvre de l‚Äôesprit est un agent de l‚ÄôEtat, d‚Äôune collectivit√© territoriale, d‚Äôun √©tablissement public √† caract√®re administratif, d‚Äôune autorit√© administrative ind√©pendante dot√©e de la personnalit√© morale, de la Banque de France, de l‚ÄôInstitut de France, de l‚ÄôAcad√©mie fran√ßaise, de l‚ÄôAcad√©mie des inscriptions et belles-lettres, de l‚ÄôAcad√©mie des sciences, de l‚ÄôAcad√©mie des beaux-arts ou de l‚ÄôAcad√©mie des sciences morales et politique. Les dispositions des articles L. 121-7-1 et L. 131-3-1 √† L. 131-3-3 ne s‚Äôappliquent pas aux agents auteurs d‚Äôoeuvres dont la divulgation n‚Äôest soumise, en vertu de leur statut ou des r√®gles qui r√©gissent leurs fonctions, √† aucun contr√¥le pr√©alable de l‚Äôautorit√© hi√©rarchique. Article L111-1 L‚Äôexistence ou la conclusion d‚Äôun contrat de louage d‚Äôouvrage ou de service par l‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit n‚Äôemporte pas d√©rogation √† la jouissance du droit reconnu par le premier alin√©a, sous r√©serve des exceptions pr√©vues par le pr√©sent code.Il faut imperativement avoir un contrat de cession de droits si on sous-traite la creation d‚Äôune oeuvre. (ex: creation d‚Äôun jeu video) Le simple fait de commander une oeuvre ne veut pas dire qu‚Äôon est investi des droits sur l‚Äôoeuvre, il faut un transfere de titularite.Il y a une exception: Les droits des salaries appartiennent aux salaries.Ce n‚Äôest pas parce qu‚Äôun salarie est paye pour creer quelque chose que l‚Äôoeuvre appartient a l‚Äôemployeur, il faut une passation de droits.Et si on fait un projet a Epita, a qui appartient les droits ? L‚Äôoeuvre nous appartient car nous n‚Äôavons jamais signe de passation de droits MAIS il nous appartient sous reserve qu‚Äôon l‚Äôai fait entierement seul (cad pas de sujet, encadrement, etc.). Article L131-1Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La cession globale des oeuvres futures est nulle.Pluralite d‚ÄôauteursCas de la pluralite d‚Äôauteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelqu‚Äôun d‚Äôautre, on peut remunerer l‚Äôauteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de l‚Äôauteur original est proportionnelle aux recettes.Si on utilise l‚Äôimage de quelqu‚Äôun dans un manuel de 1000 pages, il est plus rentable de s‚Äôacquitter d‚Äôun forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation d‚Äôune oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de l‚Äôoeuvre et qui vont se concerter entre elles. Ex: le developpement d‚Äôun logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il n‚Äôy a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent l‚Äôoeuvre en ayant passe un contrat entre eux Chacun cede ses droits a l‚Äôun d‚Äôentre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a l‚Äôinitative d‚Äôune personne (physique ou morale).Cette personne est invastie des droits d‚Äôauteurs, et va sous son nom: L‚Äôediter La publier La divulguer Ce qui distingue l‚Äôoeuvre collective et la collaboration, c‚Äôest les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise n‚Äôarrive pas a prouver les conditions pratiques de la realisation d‚Äôun projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue d‚Äôun jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention d‚Äôun tiers pour harmoniser les apports communs).Duree des droits d‚Äôauteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits d‚Äôauteurs) aussi lorsque l‚Äôauteur meurt jeune Disney: utilisent des ‚Äúruses‚Äù Peut egalement etre raccourcie Si chanson d‚Äôun artiste-interprete, retombera plus vite dans le domaine publique Droits d‚Äôune oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire qu‚Äôune oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui n‚Äôutiliserai pas son droit moral ne l‚Äôa pas perdu et peut le faire valoir a tout moment. L‚Äôauteur ne peut pas ceder de facon generale son droit d‚Äôauteur car contraire a un principe d‚Äôordre publique. Attendu que l‚Äôinali√©nabilit√© du droit au respect de l‚Äôoeuvre, principe d‚Äôordre public, s‚Äôoppose √† ce que l‚Äôauteur abandonne au cessionnaire, de fa√ßon pr√©alable et g√©n√©rale, l‚Äôappr√©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait √† ce dernier de proc√©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas d‚Äôadaptation, de changement de support ou de genre qu‚Äôil y a le plus de probleme avec le droit au respect.Representation et reproduction Ce que l‚Äôon dit aujourd‚Äôhui peut varier d‚Äôici un an ou 2En entreprise, qu‚Äôon soit auteur, salarie, manageur, etc. il faudra faire attention a la problematique de la titularite des droits.Avec les droits moraux, il y a les droits patrimoniaux. Article L122-1Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 Le droit d‚Äôexploitation appartenant √† l‚Äôauteur comprend le droit de repr√©sentation et le droit de reproduction. On distingue les droits pendant sur l‚Äôensemble des oeuvres et ceux lies specifiquement au logiciel (L 122-6 et L122-6-1 du CPI) Article L122-4Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 Toute repr√©sentation ou reproduction int√©grale ou partielle faite sans le consentement de l‚Äôauteur ou de ses ayants droit ou ayants cause est illicite. Il en est de m√™me pour la traduction, l‚Äôadaptation ou la transformation, l‚Äôarrangement ou la reproduction par un art ou un proc√©d√© quelconque. Article L122-2Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La repr√©sentation consiste dans la communication de l‚Äôoeuvre au public par un proc√©d√© quelconque, et notamment: Par r√©citation publique, ex√©cution lyrique, repr√©sentation dramatique, pr√©sentation publique, projection publique et transmission dans un lieu public de l‚Äôoeuvre t√©l√©diffus√©e ; Par t√©l√©diffusion. La t√©l√©diffusion s‚Äôentend de la diffusion par tout proc√©d√© de t√©l√©communication de sons, d‚Äôimages, de documents, de donn√©es et de messages de toute nature. Est assimil√©e √† une repr√©sentation l‚Äô√©mission d‚Äôune oeuvre vers un satellite.Remarques La repr√©sentation consiste dans la communication de l‚Äôoeuvre au public par un proc√©d√© quelconque, et notamment d‚Äôautres proc√©d√©s qui n‚Äôexistaient pas lors de la r√©daction de cette article On considere qu‚Äôa chaque fois qu‚Äôon a touche un public, on represente l‚Äôoeuvre Ex: un concert tele-diffuse (la salle de concert + telespectateurs) Si tele-diffuse dans un bar, les clients du bar sont un public Si j‚Äôutilise quelque chose qui va me rapporter quelque chose (utiliser l‚Äôoeuvre d‚Äôun autre), on doit partager avec l‚ÄôauteurExemple: Diffuser la tele dans un bar Augmenter le chiffre d‚Äôaffaire Soumis sous autorisation et remuneration Exception (L122-5) Article L122-5Modifi√© par LOI n¬∞2018-771 du 5 septembre 2018 - art. 81 Lorsque l‚Äôoeuvre a √©t√© divulgu√©e, l‚Äôauteur ne peut interdire : 1¬∞ Les repr√©sentations priv√©es et gratuites effectu√©es exclusivement dans un cercle de famille ; 2¬∞ Les copies ou reproductions r√©alis√©es √† partir d‚Äôune source licite et strictement r√©serv√©es √† l‚Äôusage priv√© du copiste et non destin√©es √† une utilisation collective, √† l‚Äôexception des copies des oeuvres d‚Äôart destin√©es √† √™tre utilis√©es pour des fins identiques √† celles pour lesquelles l‚Äôoeuvre originale a √©t√© cr√©√©e et des copies d‚Äôun logiciel autres que la copie de sauvegarde √©tablie dans les conditions pr√©vues au II de l‚Äôarticle L. 122-6-1 ainsi que des copies ou des reproductions d‚Äôune base de donn√©es √©lectronique ; 3¬∞ Sous r√©serve que soient indiqu√©s clairement le nom de l‚Äôauteur et la source : a) Les analyses et courtes citations justifi√©es par le caract√®re critique, pol√©mique, p√©dagogique, scientifique ou d‚Äôinformation de l‚Äôoeuvre √† laquelle elles sont incorpor√©es ; b) Les revues de presse ; c) La diffusion, m√™me int√©grale, par la voie de presse ou de t√©l√©diffusion, √† titre d‚Äôinformation d‚Äôactualit√©, des discours destin√©s au public prononc√©s dans les assembl√©es politiques, administratives, judiciaires ou acad√©miques, ainsi que dans les r√©unions publiques d‚Äôordre politique et les c√©r√©monies officielles ; d) Les reproductions, int√©grales ou partielles d‚Äôoeuvres d‚Äôart graphiques ou plastiques destin√©es √† figurer dans le catalogue d‚Äôune vente judiciaire effectu√©e en France pour les exemplaires mis √† la disposition du public avant la vente dans le seul but de d√©crire les oeuvres d‚Äôart mises en vente ; e) La repr√©sentation ou la reproduction d‚Äôextraits d‚Äôoeuvres, sous r√©serve des oeuvres con√ßues √† des fins p√©dagogiques et des partitions de musique, √† des fins exclusives d‚Äôillustration dans le cadre de l‚Äôenseignement et de la recherche, y compris pour l‚Äô√©laboration et la diffusion de sujets d‚Äôexamens ou de concours organis√©s dans la prolongation des enseignements √† l‚Äôexclusion de toute activit√© ludique ou r√©cr√©ative, d√®s lors que cette repr√©sentation ou cette reproduction est destin√©e, notamment au moyen d‚Äôun espace num√©rique de travail, √† un public compos√© majoritairement d‚Äô√©l√®ves, d‚Äô√©tudiants, d‚Äôenseignants ou de chercheurs directement concern√©s par l‚Äôacte d‚Äôenseignement, de formation ou l‚Äôactivit√© de recherche n√©cessitant cette repr√©sentation ou cette reproduction, qu‚Äôelle ne fait l‚Äôobjet d‚Äôaucune publication ou diffusion √† un tiers au public ainsi constitu√©, que l‚Äôutilisation de cette repr√©sentation ou cette reproduction ne donne lieu √† aucune exploitation commerciale et qu‚Äôelle est compens√©e par une r√©mun√©ration n√©goci√©e sur une base forfaitaire sans pr√©judice de la cession du droit de reproduction par reprographie mentionn√©e √† l‚Äôarticle L. 122-10 ; 4¬∞ La parodie, le pastiche et la caricature, compte tenu des lois du genre ; 5¬∞ Les actes n√©cessaires √† l‚Äôacc√®s au contenu d‚Äôune base de donn√©es √©lectronique pour les besoins et dans les limites de l‚Äôutilisation pr√©vue par contrat ; 6¬∞ La reproduction provisoire pr√©sentant un caract√®re transitoire ou accessoire, lorsqu‚Äôelle est une partie int√©grante et essentielle d‚Äôun proc√©d√© technique et qu‚Äôelle a pour unique objet de permettre l‚Äôutilisation licite de l‚Äôoeuvre ou sa transmission entre tiers par la voie d‚Äôun r√©seau faisant appel √† un interm√©diaire ; toutefois, cette reproduction provisoire qui ne peut porter que sur des oeuvres autres que les logiciels et les bases de donn√©es ne doit pas avoir de valeur √©conomique propre ; 7¬∞ Dans les conditions pr√©vues aux articles L. 122-5-1 et L. 122-5-2, la reproduction et la repr√©sentation par des personnes morales et par les √©tablissements ouverts au public, tels que les biblioth√®ques, les archives, les centres de documentation et les espaces culturels multim√©dia, en vue d‚Äôune consultation strictement personnelle de l‚Äô≈ìuvre par des personnes atteintes d‚Äôune ou de plusieurs d√©ficiences des fonctions motrices, physiques, sensorielles, mentales, cognitives ou psychiques et emp√™ch√©es, du fait de ces d√©ficiences, d‚Äôacc√©der √† l‚Äô≈ìuvre dans la forme sous laquelle l‚Äôauteur la rend disponible au public ; Ces personnes emp√™ch√©es peuvent √©galement, en vue d‚Äôune consultation strictement personnelle de l‚Äô≈ìuvre, r√©aliser, par elles-m√™mes ou par l‚Äôinterm√©diaire d‚Äôune personne physique agissant en leur nom, des actes de reproduction et de repr√©sentation ; 8¬∞ La reproduction d‚Äôune ≈ìuvre et sa repr√©sentation effectu√©es √† des fins de conservation ou destin√©es √† pr√©server les conditions de sa consultation √† des fins de recherche ou d‚Äô√©tudes priv√©es par des particuliers, dans les locaux de l‚Äô√©tablissement et sur des terminaux d√©di√©s par des biblioth√®ques accessibles au public, par des mus√©es ou par des services d‚Äôarchives, sous r√©serve que ceux-ci ne recherchent aucun avantage √©conomique ou commercial ; 9¬∞ La reproduction ou la repr√©sentation, int√©grale ou partielle, d‚Äôune oeuvre d‚Äôart graphique, plastique ou architecturale, par voie de presse √©crite, audiovisuelle ou en ligne, dans un but exclusif d‚Äôinformation imm√©diate et en relation directe avec cette derni√®re, sous r√©serve d‚Äôindiquer clairement le nom de l‚Äôauteur. Le premier alin√©a du pr√©sent 9¬∞ ne s‚Äôapplique pas aux oeuvres, notamment photographiques ou d‚Äôillustration, qui visent elles-m√™mes √† rendre compte de l‚Äôinformation ; 10¬∞ Les copies ou reproductions num√©riques r√©alis√©es √† partir d‚Äôune source licite, en vue de l‚Äôexploration de textes et de donn√©es incluses ou associ√©es aux √©crits scientifiques pour les besoins de la recherche publique, √† l‚Äôexclusion de toute finalit√© commerciale. Un d√©cret fixe les conditions dans lesquelles l‚Äôexploration des textes et des donn√©es est mise en ≈ìuvre, ainsi que les modalit√©s de conservation et de communication des fichiers produits au terme des activit√©s de recherche pour lesquelles elles ont √©t√© produites ; ces fichiers constituent des donn√©es de la recherche ; 11¬∞ Les reproductions et repr√©sentations d‚Äô≈ìuvres architecturales et de sculptures, plac√©es en permanence sur la voie publique, r√©alis√©es par des personnes physiques, √† l‚Äôexclusion de tout usage √† caract√®re commercial. Les reproductions ou repr√©sentations qui, notamment par leur nombre ou leur format, ne seraient pas en stricte proportion avec le but exclusif d‚Äôinformation imm√©diate poursuivi ou qui ne seraient pas en relation directe avec cette derni√®re donnent lieu √† r√©mun√©ration des auteurs sur la base des accords ou tarifs en vigueur dans les secteurs professionnels concern√©s. Les exceptions √©num√©r√©es par le pr√©sent article ne peuvent porter atteinte √† l‚Äôexploitation normale de l‚Äôoeuvre ni causer un pr√©judice injustifi√© aux int√©r√™ts l√©gitimes de l‚Äôauteur. Les modalit√©s d‚Äôapplication du pr√©sent article, notamment les caract√©ristiques et les conditions de distribution des documents mentionn√©s au d du 3¬∞, sont pr√©cis√©es par d√©cret en Conseil d‚ÄôEtat. Lorsque l‚Äôoeuvre a √©t√© divulgu√©e, l‚Äôauteur ne peut interdire : Les repr√©sentations priv√©es et gratuites effectu√©es exclusivement dans un cercle de famille ; Ex: examen de musique avec une musique pas encore dans le domaine public, mais examen peut etre considere comme publiqueDroit de reproduction Article L122-3Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La reproduction consiste dans la fixation mat√©rielle de l‚Äôoeuvre par tous proc√©d√©s qui permettent de la communiquer au public d‚Äôune mani√®re indirecte. Elle peut s‚Äôeffectuer notamment par imprimerie, dessin, gravure, photographie, moulage et tout proc√©d√© des arts graphiques et plastiques, enregistrement m√©canique, cin√©matographique ou magn√©tique. Pour les oeuvres d‚Äôarchitecture, la reproduction consiste √©galement dans l‚Äôex√©cution r√©p√©t√©e d‚Äôun plan ou d‚Äôun projet type.Qu‚Äôest-ce que reproduire une oeuvre? Prendre une photo d‚Äô‚Äòun tableau Enregistrer un cours Ces notes de cours (ptdr) Une reproduction meme partielle est une reproduction. Toute reproduction doit etre autorisee par l‚Äôauteur.On a le droit de reproduire l‚Äôoeuvre dans un but prive (copie privee). photocopieLa photocopie a apporte de nouvelles difficultes, ca a fait baisser les ventes de certains livres et surtout manuel scolaires. La photocopie apporte des copies de tres bonne qualiteEn France, pour contrer ce probleme, on a instaure une taxe sur les support vierges (copie techniquement interdites mais reellement impossible a interdire). Origine de la taxe pour copie privee legaliser le dispositif anti-copie $\\Rightarrow$ contradiction majeure ‚Äúj‚Äôaccepte de payer la taxe qui se je peux copier‚Äù Epita paye un forfait pour copier un certain nombre de manuelsSi un entreprise achete beaucoup de supports vierges pour stocker ses propres information, elle peut etre exonerer de la taxe. DADVSI aout 2006 (L122-5)3¬∞ Sous r√©serve que soient indiqu√©s clairement le nom de l‚Äôauteur et la source : a) Les analyses et courtes citations justifi√©es par le caract√®re critique, pol√©mique, p√©dagogique, scientifique ou d‚Äôinformation de l‚Äôoeuvre √† laquelle elles sont incorpor√©es$\\Rightarrow$ c.a.d une revue de presse Ce n‚Äôest pas ce que Google fait actuellement (L122-5)4¬∞ La parodie, le pastiche et la caricature, compte tenu des lois du genre ;Exeptions DANS une exception Les exceptions √©num√©r√©es par le pr√©sent article ne peuvent porter atteinte √† l‚Äôexploitation normale de l‚Äôoeuvre ni causer un pr√©judice injustifi√© aux int√©r√™ts l√©gitimes de l‚Äôauteur. Article L122-6Modifi√© par Loi n¬∞94-361 du 10 mai 1994 - art. 4 () JORF 11 mai 1994 Sous r√©serve des dispositions de l‚Äôarticle L. 122-6-1, le droit d‚Äôexploitation appartenant √† l‚Äôauteur d‚Äôun logiciel comprend le droit d‚Äôeffectuer et d‚Äôautoriser : 1¬∞ La reproduction permanente ou provisoire d‚Äôun logiciel en tout ou partie par tout moyen et sous toute forme. Dans la mesure o√π le chargement, l‚Äôaffichage, l‚Äôex√©cution, la transmission ou le stockage de ce logiciel n√©cessitent une reproduction, ces actes ne sont possibles qu‚Äôavec l‚Äôautorisation de l‚Äôauteur ; 2¬∞ La traduction, l‚Äôadaptation, l‚Äôarrangement ou toute autre modification d‚Äôun logiciel et la reproduction du logiciel en r√©sultant ; 3¬∞ La mise sur le march√© √† titre on√©reux ou gratuit, y compris la location, du ou des exemplaires d‚Äôun logiciel par tout proc√©d√©. Toutefois, la premi√®re vente d‚Äôun exemplaire d‚Äôun logiciel dans le territoire d‚Äôun Etat membre de la Communaut√© europ√©enne ou d‚Äôun Etat partie √† l‚Äôaccord sur l‚ÄôEspace √©conomique europ√©en par l‚Äôauteur ou avec son consentement √©puise le droit de mise sur le march√© de cet exemplaire dans tous les Etats membres √† l‚Äôexception du droit d‚Äôautoriser la location ult√©rieure d‚Äôun exemplaire. Article L122-6Modifi√© par Loi n¬∞94-361 du 10 mai 1994 - art. 4 () JORF 11 mai 1994 Sous r√©serve des dispositions de l‚Äôarticle L. 122-6-1, le droit d‚Äôexploitation appartenant √† l‚Äôauteur d‚Äôun logiciel comprend le droit d‚Äôeffectuer et d‚Äôautoriser : 1¬∞ La reproduction permanente ou provisoire d‚Äôun logiciel en tout ou partie par tout moyen et sous toute forme. Dans la mesure o√π le chargement, l‚Äôaffichage, l‚Äôex√©cution, la transmission ou le stockage de ce logiciel n√©cessitent une reproduction, ces actes ne sont possibles qu‚Äôavec l‚Äôautorisation de l‚Äôauteur ; 2¬∞ La traduction, l‚Äôadaptation, l‚Äôarrangement ou toute autre modification d‚Äôun logiciel et la reproduction du logiciel en r√©sultant ; 3¬∞ La mise sur le march√© √† titre on√©reux ou gratuit, y compris la location, du ou des exemplaires d‚Äôun logiciel par tout proc√©d√©. Toutefois, la premi√®re vente d‚Äôun exemplaire d‚Äôun logiciel dans le territoire d‚Äôun Etat membre de la Communaut√© europ√©enne ou d‚Äôun Etat partie √† l‚Äôaccord sur l‚ÄôEspace √©conomique europ√©en par l‚Äôauteur ou avec son consentement √©puise le droit de mise sur le march√© de cet exemplaire dans tous les Etats membres √† l‚Äôexception du droit d‚Äôautoriser la location ult√©rieure d‚Äôun exemplaire. copie de sauvegarde et copie priv√©e sont diff√©rentesToute stipulation contraire aux dispositions pr√©vues aux II, III et IV du pr√©sent article est nulle et non avenue.Regime du droit R√©gime du droit des contrats date de 1804ordonnance du 10 f√©vrier 2016 Article 1101Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Le contrat est un accord de volont√©s entre deux ou plusieurs personnes destin√© √† cr√©er, modifier, transmettre ou √©teindre des obligations. Le contrat est la Loi des parties au contrat Article 1103Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats l√©galement form√©s tiennent lieu de loi √† ceux qui les ont faits. Force obligatoire du contrat peut saisir le juge pour faire rectifierLa libert√© contractuelle ne permet pas de d√©roger aux r√®gles qui int√©ressent l‚Äôordre public. (Article 1102) Article 1104Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats doivent √™tre n√©goci√©s, form√©s et ex√©cut√©s de bonne foi. Cette disposition est d‚Äôordre public. Article 1105Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats, qu‚Äôils aient ou non une d√©nomination propre, sont soumis √† des r√®gles g√©n√©rales, qui sont l‚Äôobjet du pr√©sent sous-titre. Les r√®gles particuli√®res √† certains contrats sont √©tablies dans les dispositions propres √† chacun d‚Äôeux. Les r√®gles g√©n√©rales s‚Äôappliquent sous r√©serve de ces r√®gles particuli√®res. Les contrats, qu‚Äôils aient ou non une d√©nomination propre, sont soumis √† des r√®gles g√©n√©rales, qui sont l‚Äôobjet du pr√©sent sous-titre.Est-ce qu‚Äôun mariage est une forme de contrat ?C‚Äôest plus une instution qu‚Äôun contrat Pour qu‚Äôun contrat soit valable, il faut qu‚Äôil soit valablement forme.Est-ce que le contrat est valablement forme ? Article 1128Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Sont n√©cessaires √† la validit√© d‚Äôun contrat : 1¬∞ Le consentement des parties ; 2¬∞ Leur capacit√© de contracter ; 3¬∞ Un contenu licite et certain.Si un contrat n‚Äôest pas valablement forme, il peut etre conteste. Un qui a pris l‚Äôascendant sur l‚Äôautre Un qui a trompe l‚Äôautre etc.Consentement des partiesCe consentement doit √™tre juridiquement intact, c‚Äôest √† dire ne pas √™tre vici√© Quelque chose qui altere le consentement Article 1130Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur, le dol et la violence vicient le consentement lorsqu‚Äôils sont de telle nature que, sans eux, l‚Äôune des parties n‚Äôaurait pas contract√© ou aurait contract√© √† des conditions substantiellement diff√©rentes. Leur caract√®re d√©terminant s‚Äôappr√©cie eu √©gard aux personnes et aux circonstances dans lesquelles le consentement a √©t√© donn√©. Article 1132Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur de droit ou de fait, √† moins qu‚Äôelle ne soit inexcusable, est une cause de nullit√© du contrat lorsqu‚Äôelle porte sur les qualit√©s essentielles de la prestation due ou sur celles du cocontractant. Article 1136Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur sur la valeur par laquelle, sans se tromper sur les qualit√©s essentielles de la prestation, un contractant fait seulement de celle-ci une appr√©ciation √©conomique inexacte, n‚Äôest pas une cause de nullit√©. Article 1137Modifi√© par LOI n¬∞2018-287 du 20 avril 2018 - art. 5 Le dol est le fait pour un contractant d‚Äôobtenir le consentement de l‚Äôautre par des man≈ìuvres ou des mensonges. Constitue √©galement un dol la dissimulation intentionnelle par l‚Äôun des contractants d‚Äôune information dont il sait le caract√®re d√©terminant pour l‚Äôautre partie. N√©anmoins, ne constitue pas un dol le fait pour une partie de ne pas r√©v√©ler √† son cocontractant son estimation de la valeur de la prestation. Article 1145Modifi√© par LOI n¬∞2018-287 du 20 avril 2018 - art. 6 Toute personne physique peut contracter sauf en cas d‚Äôincapacit√© pr√©vue par la loi. La capacit√© des personnes morales est limit√©e par les r√®gles applicables √† chacune d‚Äôentre elles. Article 1146Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Sont incapables de contracter, dans la mesure d√©finie par la loi : 1¬∞ Les mineurs non √©mancip√©s ; 2¬∞ Les majeurs prot√©g√©s au sens de l‚Äôarticle 425. Article 1148Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Toute personne incapable de contracter peut n√©anmoins accomplir seule les actes courants autoris√©s par la loi ou l‚Äôusage, pourvu qu‚Äôils soient conclus √† des conditions normales. Les incapacit√©s prot√®gent l‚Äôincapable Article 425Modifi√© par Loi n¬∞2007-308 du 5 mars 2007 - art. 7 () JORF 7 mars 2007 en vigueur le 1er janvier 2009 Toute personne dans l‚Äôimpossibilit√© de pourvoir seule √† ses int√©r√™ts en raison d‚Äôune alt√©ration, m√©dicalement constat√©e, soit de ses facult√©s mentales, soit de ses facult√©s corporelles de nature √† emp√™cher l‚Äôexpression de sa volont√© peut b√©n√©ficier d‚Äôune mesure de protection juridique pr√©vue au pr√©sent chapitre. S‚Äôil n‚Äôen est dispos√© autrement, la mesure est destin√©e √† la protection tant de la personne que des int√©r√™ts patrimoniaux de celle-ci. Elle peut toutefois √™tre limit√©e express√©ment √† l‚Äôune de ces deux missions. Utiliser un preambule pour definir clairement ce qu‚Äôon veut faire Description de l‚Äôoeuvre et de ce que l‚Äôon entend faire en des termes ‚Äúnormaux‚Äù Obligation d‚Äôun √©crit Attention √©crit obligatoire pour la preuve et pas pour la validit√©Chaque droit c√©d√© doit faire l‚Äôobjet d‚Äôune mention, ce qui n‚Äôest pas mentionn√© est sens√© √™tre conserv√© par l‚Äôauteur.On doit pr√©ciser √©tendue g√©ographique, la dur√©e, l‚Äôexcluivit√©, ‚Ä¶,L‚ÄôoeuvrePr√©ambuleCirconstances de la ‚Äúrencontre‚ÄùDescription de l‚Äô≈ìuvre : tous ses √©l√©mentsExpliquer ce que l‚Äôon va faire : les droits vis√©s par le contrat (reproduction, adaptation, ex√©cution, etc), dur√©e, √©tendue g√©ographique, √©ventuellement le public vis√© par l‚Äôexploitation Description pr√©cise de l‚Äô≈ìuvre objet du contrat Article L131-1Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La cession globale des oeuvre Article L131-3Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La transmission des droits de l‚Äôauteur est subordonn√©e √† la condition que chacun des droits c√©d√©s fasse l‚Äôobjet d‚Äôune mention distincte dans l‚Äôacte de cession et que le domaine d‚Äôexploitation des droits c√©d√©s soit d√©limit√© quant √† son √©tendue et √† sa destination, quant au lieu et quant √† la dur√©e.Lorsque des circonstances sp√©ciales l‚Äôexigent, le contrat peut √™tre valablement conclu par √©change de t√©l√©grammes, √† condition que le domaine d‚Äôexploitation des droits c√©d√©s soit d√©limit√© conform√©ment aux termes du premier alin√©a du pr√©sent article.Les cessions portant sur les droits d‚Äôadaptation audiovisuelle doivent faire l‚Äôobjet d‚Äôun contrat √©crit sur un document distinct du contrat relatif √† l‚Äô√©dition proprement dite de l‚Äôoeuvre imprim√©e.Le b√©n√©ficiaire de la cession s‚Äôengage par ce contrat √† rechercher une exploitation du droit c√©d√© conform√©ment aux usages de la profession et √† verser √† l‚Äôauteur, en cas d‚Äôadaptation, une r√©mun√©ration proportionnelle aux recettes per√ßues. Article L131-2Modifi√© par LOI n¬∞2016-925 du 7 juillet 2016 - art. 7Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 6Les contrats de repr√©sentation, d‚Äô√©dition et de production audiovisuelle d√©finis au pr√©sent titre doivent √™tre constat√©s par √©crit. Il en est de m√™me des autorisations gratuites d‚Äôex√©cution.Les contrats par lesquels sont transmis des droits d‚Äôauteur doivent √™tre constat√©s par √©crit.Dans tous les autres cas, les dispositions des articles 1359 √† 1362 du code civil sont applicables. Les contrats par lesquels sont transmis des droits d‚Äôauteur doivent √™tre constat√©s par √©crit. Article L131-3Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992La transmission des droits de l‚Äôauteur est subordonn√©e √† la condition que chacun des droits c√©d√©s fasse l‚Äôobjet d‚Äôune mention distincte dans l‚Äôacte de cession et que le domaine d‚Äôexploitation des droits c√©d√©s soit d√©limit√© quant √† son √©tendue et √† sa destination, quant au lieu et quant √† la dur√©e.Lorsque des circonstances sp√©ciales l‚Äôexigent, le contrat peut √™tre valablement conclu par √©change de t√©l√©grammes, √† condition que le domaine d‚Äôexploitation des droits c√©d√©s soit d√©limit√© conform√©ment aux termes du premier alin√©a du pr√©sent article.Les cessions portant sur les droits d‚Äôadaptation audiovisuelle doivent faire l‚Äôobjet d‚Äôun contrat √©crit sur un document distinct du contrat relatif √† l‚Äô√©dition proprement dite de l‚Äôoeuvre imprim√©e.Le b√©n√©ficiaire de la cession s‚Äôengage par ce contrat √† rechercher une exploitation du droit c√©d√© conform√©ment aux usages de la profession et √† verser √† l‚Äôauteur, en cas d‚Äôadaptation, une r√©mun√©ration proportionnelle aux recettes per√ßues. Article L131-4Modifi√© par Loi n¬∞94-361 du 10 mai 1994 - art. 6 () JORF 11 mai 1994La cession par l‚Äôauteur de ses droits sur son oeuvre peut √™tre totale ou partielle. Elle doit comporter au profit de l‚Äôauteur la participation proportionnelle aux recettes provenant de la vente ou de l‚Äôexploitation.Toutefois, la r√©mun√©ration de l‚Äôauteur peut √™tre √©valu√©e forfaitairement dans les cas suivants :1¬∞ La base de calcul de la participation proportionnelle ne peut √™tre pratiquement d√©termin√©e ;2¬∞ Les moyens de contr√¥ler l‚Äôapplication de la participation font d√©faut ;3¬∞ Les frais des op√©rations de calcul et de contr√¥le seraient hors de proportion avec les r√©sultats √† atteindre ;4¬∞ La nature ou les conditions de l‚Äôexploitation rendent impossible l‚Äôapplication de la r√®gle de la r√©mun√©ration proportionnelle, soit que la contribution de l‚Äôauteur ne constitue pas l‚Äôun des √©l√©ments essentiels de la cr√©ation intellectuelle de l‚Äôoeuvre, soit que l‚Äôutilisation de l‚Äôoeuvre ne pr√©sente qu‚Äôun caract√®re accessoire par rapport √† l‚Äôobjet exploit√© ;5¬∞ En cas de cession des droits portant sur un logiciel ;6¬∞ Dans les autres cas pr√©vus au pr√©sent code.Est √©galement licite la conversion entre les parties, √† la demande de l‚Äôauteur, des droits provenant des contrats en vigueur en annuit√©s forfaitaires pour des dur√©es √† d√©terminer entre les parties. La loi pose le principe de la r√©mun√©ration proportionnelleIl faut prevoir les Les modes d‚Äôexploitation futurs Garantir que l‚Äôon est titulaire des droits Afin d‚Äôassouplir la licence GPLv3, il est possible d‚Äôins√©rer des ¬´ permissions additionnelles ¬ª ce sont des termes qui compl√®tent les termes de la licence en stipulant des exceptions √† l‚Äôune ou plusieurs de ses conditions. Ces termes additionnels doivent √™tre trait√©s comme les termes de la licence et, doivent √™tre respect√©es sauf s‚Äôils sont contraires √† la loi applicable. De plus, lors de la distribution des exemplaires du logiciel, il est possible de supprimer toute permission additionnelle sur cet exemplaire ou sur une partie de celui-ci. Au contraire, des permissions additionnelles peuvent √™tre stipul√©es, sur une contribution ajout√©e par un contributeur qui dispose des droits pour le faire. Les termes additionnels peuvent porter sur : Le refus de toute garantie ou limiter la responsabilit√© diff√©remment des termes (exon√©ration de garantie et de responsabilit√©) d√©j√† contenu dans la licence.L‚Äôexigence du maintient de certaines mentions sp√©cifiques.L‚Äôinterdiction d‚Äôindication d‚Äôorigine erron√©e des contributions.La limitation √† des fins publicitaires des noms des conc√©dants ou des auteurs de la contributions.Refuser d‚Äôaccorder des droits aux termes du droit des marques pour l‚Äôutilisation des noms commerciaux, marques commerciales ou marques de services.Exiger que l‚Äôindemnisation des conc√©dants et des auteurs de cette contribution par quiconque transmettant la contribution (ou des versions modifi√©es de celle-ci) avec des acceptations contractuelles de responsabilit√© au b√©n√©fice du r√©cipiendaire (b√©n√©ficiaire), pour toute responsabilit√© que ces acceptations contractuelles imposent directement √† ces conc√©dants et auteurs . https://faq.adullact.org/index.php/juridique/31-presentation-de-la-licence-gpl-v3Les bases de donnees, deux niveaux de protection La base Les donnees Cr√©ation Loi n¬∞98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1999Qu‚Äôest-ce qu‚Äôon peut injecter dans la protection des donnees ? D‚Äôou elle vient Comment elle a ete recuperee Droit de vie privee Droit a l‚Äôimage Loi Informatique et Libert√©s du 6 janvier 1978.Les donn√©es peuvent √™tre prot√©g√©es aussi par le droit d‚Äôauteur ou un autre droit Article L112-3Modifi√© par Loi n¬∞98-536 du 1 juillet 1998 - art. 1 () JORF 2 juillet 1998Les auteurs de traductions, d‚Äôadaptations, transformations ou arrangements des oeuvres de l‚Äôesprit jouissent de la protection institu√©e par le pr√©sent code sans pr√©judice des droits de l‚Äôauteur de l‚Äôoeuvre originale. Il en est de m√™me des auteurs d‚Äôanthologies ou de recueils d‚Äôoeuvres ou de donn√©es diverses, tels que les bases de donn√©es, qui, par le choix ou la disposition des mati√®res, constituent des cr√©ations intellectuelles.On entend par base de donn√©es un recueil d‚Äôoeuvres, de donn√©es ou d‚Äôautres √©l√©ments ind√©pendants, dispos√©s de mani√®re syst√©matique ou m√©thodique, et individuellement accessibles par des moyens √©lectroniques ou par tout autre moyen. Double syst√®me de protection : Droit du producteur de la base de donn√©es et le droit d‚Äôauteur Droit d‚Äôauteur si originale originalit√© ne r√©side pas dans les donn√©es mais dans le choix et/ou l‚Äôordonnancement des donn√©es Titre IV : Droits des producteurs de bases de donn√©es (Articles L341-1 √† L343-7) Article L341-1Cr√©ation Loi n¬∞98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur d‚Äôune base de donn√©es, entendu comme la personne qui prend l‚Äôinitiative et le risque des investissements correspondants, b√©n√©ficie d‚Äôune protection du contenu de la base lorsque la constitution, la v√©rification ou la pr√©sentation de celui-ci atteste d‚Äôun investissement financier, mat√©riel ou humain substantiel.Cette protection est ind√©pendante et s‚Äôexerce sans pr√©judice de celles r√©sultant du droit d‚Äôauteur ou d‚Äôun autre droit sur la base de donn√©es ou un de ses √©l√©ments constitutifs.Le producteur d‚Äôune base de donn√©es b√©n√©ficie d‚Äôun protection du contenu SI il atteste d‚Äôun investissement financier, mat√©riel ou humain substantiel. Article L342-1Cr√©ation Loi n¬∞98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur de bases de donn√©es a le droit d‚Äôinterdire :1¬∞ L‚Äôextraction, par transfert permanent ou temporaire de la totalit√© ou d‚Äôune partie qualitativement ou quantitativement substantielle du contenu d‚Äôune base de donn√©es sur un autre support, par tout moyen et sous toute forme que ce soit ;2¬∞ La r√©utilisation, par la mise √† la disposition du public de la totalit√© ou d‚Äôune partie qualitativement ou quantitativement substantielle du contenu de la base, quelle qu‚Äôen soit la forme.Ces droits peuvent √™tre transmis ou c√©d√©s ou faire l‚Äôobjet d‚Äôune licence.Le pr√™t public n‚Äôest pas un acte d‚Äôextraction ou de r√©utilisation. Article L342-2Cr√©ation Loi n¬∞98-536 du 1 juillet 1998 - art. 5 () JORF 2 juillet 1998 en vigueur le 1er janvier 1998Le producteur peut √©galement interdire l‚Äôextraction ou la r√©utilisation r√©p√©t√©e et syst√©matique de parties qualitativement ou quantitativement non substantielles du contenu de la base lorsque ces op√©rations exc√®dent manifestement les conditions d‚Äôutilisation normale de la base de donn√©es. Article L342-3Modifi√© par LOI n¬∞2016-1321 du 7 octobre 2016 - art. 38Lorsqu‚Äôune base de donn√©es est mise √† la disposition du public par le titulaire des droits, celui-ci ne peut interdire :1¬∞ L‚Äôextraction ou la r√©utilisation d‚Äôune partie non substantielle, appr√©ci√©e de fa√ßon qualitative ou quantitative, du contenu de la base, par la personne qui y a licitement acc√®s ;2¬∞ L‚Äôextraction √† des fins priv√©es d‚Äôune partie qualitativement ou quantitativement substantielle du contenu d‚Äôune base de donn√©es non √©lectronique sous r√©serve du respect des droits d‚Äôauteur ou des droits voisins sur les oeuvres ou √©l√©ments incorpor√©s dans la base ;3¬∞ L‚Äôextraction et la r√©utilisation d‚Äôune base de donn√©es dans les conditions d√©finies au 7¬∞ de l‚Äôarticle L. 122-5, au 1¬∞ de l‚Äôarticle L. 122-5-1 et √† l‚Äôarticle L. 122-5-2 ;4¬∞ L‚Äôextraction et la r√©utilisation d‚Äôune partie substantielle, appr√©ci√©e de fa√ßon qualitative ou quantitative, du contenu de la base, sous r√©serve des bases de donn√©es con√ßues √† des fins p√©dagogiques et des bases de donn√©es r√©alis√©es pour une √©dition num√©rique de l‚Äô√©crit, √† des fins exclusives d‚Äôillustration dans le cadre de l‚Äôenseignement et de la recherche, √† l‚Äôexclusion de toute activit√© ludique ou r√©cr√©ative, d√®s lors que le public auquel cette extraction et cette r√©utilisation sont destin√©es est compos√© majoritairement d‚Äô√©l√®ves, d‚Äô√©tudiants, d‚Äôenseignants ou de chercheurs directement concern√©s, que la source est indiqu√©e, que l‚Äôutilisation de cette extraction et cette r√©utilisation ne donne lieu √† aucune exploitation commerciale et qu‚Äôelle est compens√©e par une r√©mun√©ration n√©goci√©e sur une base forfaitaire ;5¬∞ Les copies ou reproductions num√©riques de la base r√©alis√©es par une personne qui y a licitement acc√®s, en vue de fouilles de textes et de donn√©es incluses ou associ√©es aux √©crits scientifiques dans un cadre de recherche, √† l‚Äôexclusion de toute finalit√© commerciale. La conservation et la communication des copies techniques issues des traitements, au terme des activit√©s de recherche pour lesquelles elles ont √©t√© produites, sont assur√©es par des organismes d√©sign√©s par d√©cret. Les autres copies ou reproductions sont d√©truites.Toute clause contraire au 1¬∞ ci-dessus est nulle.Les exceptions √©num√©r√©es par le pr√©sent article ne peuvent porter atteinte √† l‚Äôexploitation normale de la base de donn√©es ni causer un pr√©judice injustifi√© aux int√©r√™ts l√©gitimes du producteur de la base.le droit du producteur de la BDD s‚Äôapplique m√™me si la BDD n‚Äôest pas prot√©g√©e par un droit d‚Äôauteur et m√™me si les donn√©es ne sont pas prot√©g√©es" }, { "title": "MLRF: Lecture 06", "url": "/cours/posts/mlrf_sixth_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-25 10:00:00 +0200", "snippet": "Lien de la note HackmdPractice 5: Take home messages BoVW is linear classification friendly And linear classifier are to be prefered whenever possibleData preparation is tedious An important part of the time is dedicated to data analysis Plus we prepared a lot of things for you in the previsous sesssionsScikit-learn is easy and super powerful Calssifier evaluation in 1 line But there is more: parameter tuning, cross-validation, etc. in 1 or 2 lines Data preprocessing + classification (pipelines) in 1-3 linesSome classifiers ‚Äì part 2How to build non-linear classifiers ?2 solutions: Preprocess the data - seen last time Ex: explicit embedding, kernel trick‚Ä¶ Change the input to make it linearly separable Combine multiple linear classifiers into nonlinear classifier - current topic Ex: boosting, neural networks‚Ä¶ Split the input space into linear subspaces Non-linear classification using combinations of linear classifiersMulti-layer Perceptron Combine features linearly, apply a linear activation function $\\phi$, repeatUniversal approximation theoremWhat if $\\phi$ not linear ? Universal approximation theorem (Cybenko 89, Hornik 91)Decision treeWorks on categorical (like, ‚Äúred‚Äù, ‚Äúblack‚Äù) and numerical (both discrete and continuous) random variablesTrain by optimizing classification ‚Äúpurity‚Äù at each decision (threshold on a particular dimension in numerical case)Very fast training and testing. Non parametric.No need to preprocess the featuresBUT: very prone to overfitting without strong limits on depthRandom Forests Average the decision of multiple decision treesRandomize in 2 ways: For each tree, pick a bootstrap sample of data For each split, pick random sample of features More trees are always betterEnsemble methods‚ÄúBagging‚Äù or ‚Äúbootstrap aggregating‚Äù Underlying idea: part of the variance is due to the specific choice of the training data set Let use create many similar training data sets using bootstrap For each of them, train a new classifier The final function will tbe the average of each function ouptuts If generalization error is decomposed into bias and variance terms then bagging reduces variance (averag of large number of random error $\\simeq 0$)Random forest = a way of bagging trees‚ÄúBoosting‚Äù, AdaBoost variantCombinaison of weak classifiers $\\sum_m\\alpha_mG_m(x)$$\\alpha_m$ increases with precision (less errors, bigger $\\alpha_m$)The classifier $G_m$ is trained with increased error cost for the observatins which were misclassified by $G_{m-1}$A quick comparisonMore tricksData augmentationAdd realistic deformations to your input in order to improve domain coverage.For image data, depending on what is possible in productin: rotations, horizontal &amp;amp; vertical dlips, scaling, translation, illumination change, warping, noise, etc.For vector data: intersting problem. Possible approach: train/fit PCA then add random noise in low-energy featuresRejectSeveral options: Improve the model of class boundary In 1-vs-all training, add noise to the ‚Äúothers‚Äù samples Adjust the decision function dependinf on your application Look at the prediction probabiblity of your classifier, and threshold it as per your need using a ROC curve Model the noise Add a ‚Äúnone‚Äù class to your classifier, with samples for real life cases of negatives samples More theory on MLWhat is our goal ? Given samples (described by features) and true labels,find a good functionwhich wil correctly predict labelsgiven new data samplesProblems: Which family for our function? What is ‚Äúgood‚Äù? How to train / find such function?What are the sources of error ? Noise Your data is not perfect. (or ‚ÄúEvery model is wrong.‚Äù) Even if there exist an optimal underlying model, the observations are corrupted by noise (e.g. multiple y for a given x). - Even the optimal solution could be wrong. Bias You need to simplify to generalize. You classifier needs to drop some information about the training set to have generalization power. The set of solutions explored does not contain the optimal solution. Variance You have many ways to explain your training dataset It is hard to find an optimal solution among those many possibilities. If we draw another training set from the same distribution, we would obtain another solution. 2 big issuesUnder-fitting Caused by bias Your model assumptions are too strong for the data, so the model won‚Äôt fill well Over-fitting Caused by variance Your algorithm has memorized the data including the noise, so it can‚Äôt generalize. The theoryBias (statistical definition)Let $T$ be a statistic used to estimate a parameter $\\theta$.If $E[T] = \\theta + bias(\\theta)$ then $bias(\\theta)$ is called the bias of the statistic $T$, where $E[T]$ represents the expected value of the statistics $T$.If $bias(\\theta) = 0$, then $E[T] = \\theta$. So, $T$ is an unbiased estimator of the true parameter, say $\\theta$.Expected RiskLet $D_n$ be a training set of examples $z_i$ drawn independently from an unknown distribution $p(z)$We need a set of functions F. Example: linear functions $f(x) = a \\times x + b$We need a loss function $L(z, f)$. Example: $L((x, y), f ) = (f (x) ‚àí y)^2$ The Expected Risk, i.e. the expected generalization error, is: But we do not know $p(z)$, and we cannot test all $z$!Empirical Risk Because we cannot measure the real Expected Risk, we have to estimate it using the Empirical Risk: $D_n$ is our datasetAnd our training procedure then relies on Empirical Risk Minimization (ERM):And the training error is given by:Does this make sense? The empirical risk is an unbiased estimate of the risk, i.e. the more test samples we have, the more accurate our estimate is, under iid assumption.But the training risk is biasedThe training error is a biased estimate of the risk, i.e. the solution $f^‚òÖ (D_n)$ found by minimizing the training error is better on $D_n$ than on any other set $D‚Äô_n$ drawn from $p(z)$.However, under certain assumptions, the difference between the expected and the empirical risks can be bounded. This is an important result from the work of VapnikNote that the empirical risk on the test set is an unbiased estimate of the risk.Estimate the Expected Risk with the Empirical RiskFor a given capacity, using more samples to train and evaluate your predictor should make your Empirical Risk converge toward the best possible Expected Risk, if the ERM is consistent for $F$, given your training set $D_n$.The difference between Expected Risk and Empirical Risk is bounded but depends on the capacity of $F$ (set of possible functions).There is an optimal capacity for a given number of training samples $n$.CapacityThe capacity $h(F)$ is a measure of its size, or complexity (or VC dimension)For classification, the capacity of $F$ is defined by Vapnik &amp;amp; Chervonenkis as: the largest $n$ such that there exist a set of examples $D_n$ such that one can always find an $f \\in F$ which gives the correct answer for all examples in $D_{n‚Äô}$ for any possible labeling.The Bias-Variance DilemmaIntrinsic dilemma: when the capacity $h(F)$ grows, the bias goes down, but the variance goes up!Decomposing the bias-variance-error for MSEFor a regression problem with a mean square loss, we have the following decomposition. Let $Y = f(X) + \\varepsilon$, with $\\varepsilon \\sim N(0, \\sigma_{\\varepsilon}^2)$ and $f_D(X)$ an estimator of $f(X)$, learned over the training set $D$. The error at a particular point $X = x_0$ is:In practiceEmpirical Risk and Expected Risk Measure train and test errorUse hold-out sets, cross-validations, etc. to get a test error.Train error: Empirical Risk.Can my model learn something (by heart)?Test error: Coarse estimate of the Expected Risk.Can my model generalize to unseen data?Detect under-fitting and over-fittingSome solutions / hintsHow to get started? Get enough data in the right format from your customer (hard) Check and split data (boring but mandatory) Agree on a loss function and minimum performance goal (moderate) Try to overfit a predictor on some samples (train set loss), increase complexity only if needed (capacity check) Fit on more data (more = better) Check for overfitting (val set loss) and add regularization if needed Evaluate performance thoroughly (test set loss) (reports, identify failure cases, etc.) Do some hyper-parameter optimization, try other models‚Ä¶ ‚Ä¶Introduction to practice session 6Using classification to segment imagesUntil now 1 image $\\to$ many vectors (instance recognition) 1 image $\\to$ 1 vector (image retrieval, image classification)Today / next practice session : 1 pixel ‚Üí1 vector (pixel classification, image semantic segmentation)Brain Anatomy and ImagingHuman brain = Where human OS is stored and runTo investigate brain malfunction, two options:Magnetic Resonance Imaging (MRI)Everything you always wanted to know about MRIHydrogen atoms are naturally abundant in humans, particularly in water and fat.Pulses of radio waves excite the nuclear spin energy transition, and macroscopic polarization that is detected by antennas.Magnetic field gradients localize the polarization in space. By varying the parameters of the pulse sequence, different contrasts may be generated between tissues based on the relaxation properties of the hydrogen atoms therein.What you actually need to knowMRI is a large family of imaging techniquesThey can produce 3D scans of various appearances in order to emphasize some human tissues versus others.BraTS: Brain Tumor Segmentation CompetitionOriginal segmentation taskGiven a 3D scan (skull-stripped, registered) of a patient with T1, T2, T1C and FLAIR modalities, predict a tumor class for each voxel (the patient suffers from a glioma):Avec: edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core (blue).Original datasetThe 2018 competition we use the data from originally contains 285 brain scans.Your MissionA simplified competitionBecause dealing with 3D and data normalization would take you much time and pain, we: already performed data normalization extracted 2D (axial) slices that you have to processActual taskGiven a $240\\times240$ image with $4$ modalities (already normalized), predict for each pixel whether it belongs to a tumor or nor.Actual datasetTrain set $256$ normalized slices, one per patient, containing $240\\times240$ images with $4$ channels ($1$ for each modality), float32 $256$ target segmentations, one per patient, containing $240\\times240$ images with $1$ channel (indicating tumor or clean region), uint8Test set $29$ normalized slices, one per patient (not in the training set), containing $240\\times240$ images with $4$ channels ($1$ for each modality), float32 Ground truth kept secret for gradingSuggested PipelineData preprocessing We already did this step.Choose and train a classifierThere are several suggestions in the reference notebook: SVM, neural network, etc. Input = 1 vector of 4 components for each pixels Output = 1 for tumor, 0 for ‚Äúnot tumor‚Äù Do not use background (‚Äúblack‚Äù) pixels for training, they would ruin your classification Deep nets can work but they are harder to train well. And don‚Äôt use deep nets, we‚Äôll play with them next semesterValidate your trainingCreate and use a validation set extracted from the full training set.To not train on the samples it contains.sklearn.model_selection.train_test_split may be your friend. Check visually results from both train and val sets!Interpret your resultsAdd some context to each pixelYou can get better results by looking at the neighborhood of a pixel to classify it better: train with vectors of size $N\\times M$ instead of $1\\times M$.Fighting underfitting and overfitting You do not have much data to train onIf you pick a classifier which is too simple, you may underfit: you will get low and similar scores both on the train and test setsChoosing another classifier may be a good idea here.You may also easily overfit your classifier, especially if you use one with a large capacity: you will get excellent scores on the train set, and bad ones on the test set.Regularization may be necessary.Post processingWe suggest in the notebook to ‚Äúclean up‚Äù the results by removing very small isolated pixels marked as tumor.You may have many other ideas hereGoing FurtherMany options Data augmentation to increase train set Larger / better neighborhood for each pixel Better ANN structure than the one suggested in the notebook Change the representation space? (Fourier, wavelets‚Ä¶) As the tumors under consideration may not have ‚Äúholes‚Äù, improve the post-processing Super heavy classifiers (UNet, Gradient Boosted Trees‚Ä¶) ‚Ä¶ConclusionCourse overview: a very small glimpse of CV/PR/MLWelcome to 2012AlexNet by A. Krizhevsky, I. Sutskever, G. E. Hinton halved error rate on ImageNet competitionDeep learningWill be there for a few years!Is a natural extension of what we saw: feature extraction, encoding, pooling, classification in a single, integrated, globally optimized pipeline.Requires skills you learned: dev, math, data preparation, evaluation.Input data still need to be properly normalized, for instance.Requires a lot of practice: read papers, don‚Äôt be impressed by the math, implement them.If not applicable, then pick one of the good old technique we talked about." }, { "title": "TIFO: Cours recalage", "url": "/cours/posts/tifo_recalage/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, recalage", "date": "2021-06-23 10:00:00 +0200", "snippet": "Lien de la note HackmdComment extraire une frequence cardiaque quand on a une oscillation ? Stabiliser l‚Äôimage Quand on fait du recalage, on fait des estimations donc par moment l‚Äôimage ‚Äúvibre‚ÄùLa video recalee est plus petite car on prend la plus grande translation de chaque cote.ContextAn example Ptit poisson, grozyeuxGeneral principle What is the transformation between 2 frames ?For 2 frames $I_2$ and $I_2$, Find $\\mathcal T$ to minimize \\(\\mathcal V = Variance(I_1,\\mathcal T(I_2))\\) Hyper important de verifier2 frames The reference frame ($I_1$ in our presentation) is the frame we will not modify, considered as the ‚Äútrue‚Äù image The studied frame ($I_2$ in our presentation) is the frame we try to minimize $\\mathcal V$ModelChoixe of the model to have the best estimation: Fourier domain Image Graph Multi-modality Un peu complique Usual transformationsRigid transformation Transfo rigide: on ne change pas la structure (les distances) dans l‚ÄôimageNon-rigid transformation On ne veut surtout pas faire de transformation non-rigidePourquoi ?On risque de creer des deformations locales (dans notre exemple: corriger le mouvement du coeur)Transformation estimationClassical estimation for the entire image analysis:\\[\\mathcal T = (\\mathcal R, T)\\]with:\\[\\mathcal R=\\begin{pmatrix}\\alpha a &amp;amp;\\alpha b\\\\\\alpha c&amp;amp;\\alpha d\\end{pmatrix} = \\alpha\\mathcal R&#39;\\\\T=(d_x, d_y)\\]Case of $\\mathcal R$:If there is a rotation:\\[\\mathcal R=\\begin{pmatrix}\\alpha \\cos(\\theta) &amp;amp;-\\alpha \\sin(\\theta)\\\\\\alpha \\sin(\\theta)&amp;amp;\\alpha \\cos(\\theta)\\end{pmatrix} = \\alpha\\mathcal R&#39;\\]$\\alpha$ is the scale factor\\[(I_2\\mathcal R+T)-I_1 = min(\\mathcal V)\\\\S = \\mathcal T(I_2)=(I_2\\mathcal R + T)\\\\\\forall (x,y)\\in I_2: S(x,y)=I_2(x&#39;,y&#39;)\\]with the estimated $\\mathcal R$ and $T$, $[x‚Äô\\quad y‚Äô]=[x\\quad y]\\mathcal R+T$Key-pointsPrinciple Objectives Points which are interesting $I_1$ Find their equivalent in $I_2$ Estimate the transform between the 2 sets of points We want to solve\\[P_2=P_2\\times\\mathcal R+\\mathcal T\\] Where $P_1$ and $P_2$ are the sets of points of the 2 frames we seek to match, $\\mathcal R$ is the ‚Äúrotation‚Äù matrix. $\\mathcal T=(d_x, d_y)$ is the translation The solution En fonction de la version d‚ÄôOpenCV il peut y avoir un soucis avec la matrice $\\mathcal M$ (elle peut etre $3\\times 3$ au lieu de $2\\times 3$)Applications Sequence stabilization Reconstruction Optical flow Similarity Comparison (evolution of a tumor etc.)Recalagekeuwa ?Deux images $S$ et $C$: cherche $T$ tel que $T(S)$ ressemble a $C$ Les notations sont pourries iciApplications Outil fondamental en analyse d‚Äôimages medicales, mais pas uniquement Ou ailleurs en imagerie ? Creation d‚Äôimages panoramiques Mosaiques Astronomie On ne cherche pas sur toute l‚Äôimage les points-cles, on se restreint a une certaine zoneSystemes par mosaiqueCe type d‚Äôapproche consiste a construire les images panoramiques a partir d‚Äôune serie d‚Äôimages prises avec le meme systeme optique. On peut, par exemple, utiliser une camera en rotation autour de son centre optiqueEvidemment, un nombre arbitraire d‚Äôimages peut etre utiliseExemples en imagerie medicaleRecalage DefinitionConsiste a trouver une transformation spatiale permettant d‚Äôaligner une image (source ou flottante) sur une autre (cible ou reference)En anglais: Image registration Image matchingRecalage monomodal ou multimodal: Monomodal: meme modalites Multimodale: modalites differentesRecalage intra ou inter-sujetsExemplesIntra-patient, mono-modaliteExemple: evolution de lesions (images IRM d‚Äôun patient atteint de SEP a quelques mois d‚Äôintervalle) C‚Äôest flou !Pour trouver quelles sont les zones qui ont evolueIntra-patien, multi-modaliteExemple: fusion d‚Äôinformations provenant de 2 modalites differentesInter-patient, intra-modaliteExemple: segmentation a partir d‚Äôun atlas anatomiqueExtension en 3DRecalage en imagerie medicaleReconstruction d‚Äôun volume 3D A partir d‚Äôune serie de coupes 2D contigues (microscopie, epaisseur de coupe de 60nm environ)Evolution temporelle Brain-shift Developpement cerebralComparaison entre differents sujets:Fusion de modaliteRecapPrincipe des methodes de recalageCritere de similariteSupposons que l‚Äôon se donne un critere de similarite: $Simil(I, J)$ qui mesure la ‚Äúressemblance‚Äù entre 2 images $I$ et $J$On choisit egalement une famille de transformation $\\mathcal F$ Le probleme de recalage s‚Äôecrit alors comme: \\(argmin_{T\\in\\mathcal F} Simil(T(I), J)=?\\)Methode de recalage Structures (primitives) a mettre en correspondance Critere de similarite Transformation OptimisationPrimitives geometriques Structures particulieres dans l‚Äôimage Points, courbes, surfaces Extraits automatiquement ou manuellement Detection des primitives: ici points de forte courbure Primitives intrinseques Primitives extrinseques Primitives intrinseques Structurent intrinseques au patient Information pertinente presente dans les 2 jeus de donnees Points Courbes (contours) Surfaces segmenteees Volumes Points anatomiques Identifies manuellement par l‚Äôoperateur Isole automatiquement Primitives extrinsequesReperes externes, visibles dans les 2 modalites fixees au patient ou a la table d‚Äôexamen Invasifs Cadre stereitaxique Vis dans la boite cranienne Non invasifs Cadre non visse Moule Repere colles a la peau Avantages Permet de recaler des donnees tres differentesInconvenients Les marqueurs doivent etre positionnes avant l‚Äôacquisition Le recalage retrospectif n‚Äôest pas possibleAutres reperes exterenes, contentionOn fait des moules du patient pour faire des recalagesPrimitives Pas de structures particulieres: tous les voxels de l‚Äôimage sont utilisesCritere de similariteDependance lineaire ou affineCoefficient de correlationHistogramme conjoint Quand il est parfait, on a le meme nombre de points a la meme valeurA quel histogramme correspond les images ? Conservation de l‚Äôintensite - SSDInformation mutuelleExemplesSommaireOptimisationApproches geometriquesEvaluationEvaluation qualitativeEvaluation semi-quantitativeEvaluation quantitative" }, { "title": "MLRF: Lecture 05", "url": "/cours/posts/mlrf_fith_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-18 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda Introduction Image classification overview Some classifiers - part 1 Classifier evaluationSummary of last lectureContent-based image retrieval 2 strategies: keep all local descriptors for all images vs 1 descriptor per image Bag of Visual Words pipeline Focus on encoding Evaluation of image retrieval systems Precision Recall F-Measure mAPTexture descriptors (on les a pas du tout vu) What is a texture ? Fast and classic approaches Descripteurs a l‚ÄôanciennePractice session 4: Take home messagesBoVW Usually requires some preprocessing of the descriptors: centering, rotation/axes permutation, dimensionality reduction‚Ä¶ Is based on a quantization step (assign descriptors to clusters) Is just a histogram, like the color histogram of sessino 2 We can compute more advanced statistics to get better results (VLAD, FVs) Best practices: Test arrays shapes and types as soon as possible Make a small change, test, fix, tes, validate, repeat Get a complete, basic pipeline ASAP and improve it until time is over Next practice sessionImplement a simple image classifier: Will be gradedSteps Load resources Train a BoVW model Split the dataset into training and validation sets Compute the BoVW descriptor for each image We will make a small change here (sqrt + L2-norm) Prepare training structures Train a classifier and evaluate its performance Training and evaluating is easy with scikit learn Display some results Test on meme image Compute the results on the test set and export themImage classification overviewInstance recognition vs Class recognitionInstance recognitionRe-recognize a known 2D or 3D rigid object, potentially being viewed from a novel viewpoint, against a cluttered background, and with partial occlusionsEx: practice session 3Class recognitionRecognize any instance of a particular general class such as ‚Äúcat‚Äù, ‚Äúcar‚Äù or ‚Äúbicycle‚ÄùAka category-level or generic object recognition More challengingThis lecture and next practice sessionPipeline overviewOur image classification pipelineThis is a supervised machine learning task We need a dataset with samples Images will be represented as BoVW vectors of fixed size Targets will be encoded as integers 0: Muffin 1: Chihuahua This is a very usual data representation for a classification problem Classifier inputs = ‚Äúsamples‚Äù with ‚Äúfeatures‚ÄùClassifier outputs = ‚Äúlabels‚ÄùNow we just need to select an appropriate method, prepare our data, run some training, test the results, adjust some parameters, compare approaches, display results, ‚Ä¶Data preparationNumPy formattingTraining/validation/test separation You cannot estimate the generalization performance of your predictor/estimator/classifier on its training set You need to keep some samples aside for later evaluationOther ‚Äúfunny‚Äù things to do IRL Collect data Clean data Check data Clean again Annotate Check Compute/convert/scale featuresFeature selection Consists in dropping some data columnsCan help later stages: Less data to process Better properties (like decorrelated features, etc.)Which columns ? Hard problem in general Because features may be informative as a group Some simpler and helpful techniques: Remove features with low variances Dimensionality reduction techniques are not exactly feature selection, but can still have a similar effect Some classifiers - part 1Disclaimer What follows is a very limited selectionOnly classifiers suitable for image classification as we present it today input = feature vectoroutput = labelMany other approachesWhat is our goal ? Given samples (described by features) and true lables, find a good function which will correctly predict labels given new data samplesParametric vs Non Parametric ClassifiersParametric examplesLogisitic regression, Linear Discriminant Analysis, naive Bayes, Perceptrion, Simple Neural Networks.. A learning model that summarizes data with a set of parameters of fixed size (independant of the number of training examples) is called a parametric model. No matter how much data you throw in natureNon-parametric examplesk-Neares Neighbors, Decision Trees, SVMs ‚ÄúNon-parametric models differ from parametric models int that hte model structure is not specified a priori but is instead determined from data. The term non-parametric is not meant to imply that such models completely lack parameters but that the number and nature of the parameters are flexible and not fixed in advance‚ÄùWikipedia ‚ÄúNonparametric methods are good when you have a lot of data and no prior knowledge‚ÄùDummy classifiersSay you have a dataset with 9 muffins and 1 chihuahua.You have a new sample to classify.Which class should you bet on ?If your class prior probabilities $P(C_1), P(C_2),\\dots$ are not equal, then you should bet on the most frequent class! ($g(x)=argmax_yp(y)$)Without such information, you can just pick at randomWaht is the expected accuracy (true predictions / total predictions) if you have N classes an pick one at random ? Scikit-learn offers a DummyClassifier class which helps testing such a strategyWhat‚Äôs the point ? Quickly build and test your complete pipeline with a mockup classifier Quickly get a baseline for the performance (look for obvious bias in the dataset, but you should have cleaned it before !)K Nearest Neighbor (kNN)Keep all training samplesView new samples as quieries over the previously learned / indexed samplesAssign the class of the closest(s) samples\\[f(x) = y_i, i = argmin_j\\Vert x_j-x\\Vert\\]We can check more than one sampleRemember thi bias/variance compromise ?Pros very simple to implement Capacity easily controlled with k Can be tuned to work on large datasets: indexing, data cleaning, etc. Good baseline Non parametric Lazy learnerCons In high dimension, all samples tend to be very close (for Euclidean dimension) Large memory consumption on large datasets Requires a large amount of samples and large k to get best performance Setting K:\\[K\\simeq\\sqrt{\\frac{m}{C}}\\] $\\frac{m}{C}$: average number of training sample/classOther distance-based classifierMinimal euclidean distanceVery basic classifierDistance to the mean $m_i$ of the classIt does not take into account differencesin variance for each classPredicted class for x:\\[g(x) = argmin_iD_i(x)\\]Minimal quadratic distance (Mahalanobis)For each class $i$, the mean $m_i$ and covariance matrix $S_i$ are computed from the set of examplesThe covariance matrix is taken into account when computing the distance from an image to the class $i$The feature vector of the image $x$ is projected over the eigenvectors of the class\\[g(x) = argmin_iD_i(x)\\]A quick introduction to Bayesian Decision TheoryExample - RoboCupGeneral case: maximum a posteriori (MAP) General case: need to tale into consideration $p(y)$ and $p(x)$ $p(x\\vert y)$: class conditional density (here: histograms) $p(y)$: class priors, e.g. for indoor RoboCup $p(floor) = 0.6$, $p(goal) = 0.3$, $p(ball) = 0.1$ $p(x)$: probability of seeing data $x$Optimal decision rule (Bayes classifier): maximum a posteriori (MAP):\\[g(x) = argmax_{y\\in Y}p(y\\vert x)\\]How to compute $p(y\\vert x)$ ?\\[p(y\\vert x) = \\frac{p(x\\vert y)p(y)}{p(x)}\\quad\\text{Bayes&#39; rule}\\]If classes are equiprobables and error cost is the same, then, because $p(x)$ is constant, we get the maximum likelihood estimation:\\[g(x) = \\underbrace{argmax_{y\\in Y}p(y\\vert x)}_{\\text{MAP}}\\simeq\\underbrace{argmax_{y\\in Y}p(x\\vert y)}_{\\text{ML}}\\]Generative, discriminant and ‚Äúdirect‚Äù classifiersGenerative Probabilistic ModelsSome classical Generative Probabilistic ModelsTraining data $X={x-1,\\dots,x_n}$, $Y={y_1,\\dots,x_n}$. $X\\times Y\\in\\mathcal X\\times\\mathcal Y$For each $y\\in\\mathcal Y$, build model for $p(x\\vert y)$ of $X_y:={x_i\\in X:y_i=y}$ Histogram: if $x$ can have only a few discrete values Kernel Density Estimator Gaussian Mixture of Gaussians Typically, $\\mathcal Y$ small (few possibles lables), $\\mathcal X$ low dimensionalClass conditional densities and posteriorsNaive Bayes ClassifiersLinear discriminant classifiersGeneral idea for binary classificationLearn w and b you can compute $p(y\\vert x)\\simeq\\hat y$ Problem: how to learn w and b ?Logistic RegressionLinear classifier, $f$ is logistic function\\(\\sigma(x) = \\frac{1}{(1+e^{-x})} = \\frac{e^x}{(1+e^x)}\\) Maps all real $\\to[0,1]$Optimize $\\sigma(w^Tx+b)$ to find best $w$Trained using gradient descent (no closed form solution)Gradient descentFormally:\\[w_{t+1}=w_t-\\eta\\nabla L(w)\\]Where $\\eta$ is step size, how far to step relative to the gradientFrom 2 classes to C classes: 2 strategies\\[\\hat y = argmax_{i\\in Y}w_ix\\]Maximum Margin classificationWhat is the best $w$ for this dataset ?Trade-off:large margin vs few mistakes on training setSupport Vector Machin (SVM)Logistic Regression vs SVMOptimization problems:About the regularizerEffect of cost parameter C (regularization, again)Non-linear discriminant classifiersNon-linear classificationWhat is the best linear classifier for this dataset? None. We need something nonlinear!2 solutions: Preprocess the data (explicit embedding, kernel trick‚Ä¶) Combine multiple linear classifiers into nonlinear classifier (boosting, neural networks‚Ä¶)Non-linear classification using linear classifiers with data preprocessingData preprocessing ideaTransform the dataset to enable linear separabilityLinear separation is always possibleThe original input space can always be mapped to some higher-dimensional feature space where the training set is separable.Explicit embeddingCompute $\\phi(x)$ for all $x$ in the dataset.Then train a linear classifier just like before Used to be avoided because of computation issues, but it is a hot topic again.Kernel trickLinear classification requires to compute only dot products $\\phi(x_i),\\phi(x_j)$The function $\\phi(x)$ does not need to be explicit, we can use a kernel function\\[k(x,z)=\\phi(x)\\phi(z)\\]which represents a dot product in a ‚Äúhidden‚Äù feature space. This gives a non-linear boundary in the original feature space.Popular kernel functions in Computer VisionLinear kernel‚Äù: identical solution as linear SVM‚ÄúHellinger kernel‚Äù: less sensitive to extreme value in feature vector‚ÄúHistogram intersection kernel‚Äù: very robust‚Äú$X^2$-distance kernel‚Äù: good empirical results‚ÄúGaussian kernel‚Äù: overall most popular kernel in Machine LearningExplicit embedding for the Hellinger kernelUsing simple square root properties, we have:\\[k(x,x‚Äô) = \\phi(x)\\phi(x‚Äô) = \\sqrt{x} \\sqrt{x&#39;}\\]Tricks for next practice session: given a BoVW vector, L1 normalize it (neutralizes effect of number of descriptors) Take its square root (explicit Hellinger embedding) L2 normalize it (more linear-classifier friendly)MetricsConfusion matrix and AccuracyProblems with AccuracyAll the following classifiers have a 90% accuracyDo all errors have the same cost?Precision, recall, F-scorePlotting a Precision/Recall for classification dataFor binary classificationInstead of $\\hat y = argmax_yp(y\\vert x)$, take all possible thresholds for $p(y\\vert x)$TPR, FPR, ROCROC: ‚ÄúReceiver Operating Characteristic‚ÄùKind of signaloise measure under various tuningsLigne rose: random resultsMore about ROC curves:Adjusting the thresholdhttp://www.navan.name/roc/Class overlapSplit the dataset to assess generalization performanceBootstrapDraw randomly, with replacement samples from the training set.Enables us to estimate the variance of estimators we use in the classification rule.HoldoutJust keep a part of the dataset for later validation/testingCross validationwith meta parameter tuningStratifiedKFold (best)Missing things Cost of misclassification Multiclass classification evaluation ‚Ä¶" }, { "title": "ASE3: TD 2", "url": "/cours/posts/ase3_td2-1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, ACP", "date": "2021-06-16 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Soit \\(X=\\begin{pmatrix} 16 &amp;amp; 2 &amp;amp;0 \\\\ 8&amp;amp;12&amp;amp;10 \\\\ 12&amp;amp;16&amp;amp;14 \\\\ 20&amp;amp;8&amp;amp;14 \\\\ 16&amp;amp;4&amp;amp;10 \\\\ 0&amp;amp;6&amp;amp;12 \\end{pmatrix}\\)On donne le meme poids a tous les individus: $p_i=\\frac{1}{6}$ $\\forall i$ et $M=I_3$ Calculer la moyenne des variables et le centre de gravite Donner la matrice $Y$ Calculer la matrice de var-covariance $V$ Diagonaliser sur $MV=V$ Calculer le $\\%$ d‚Äôinertie Facteurs principaux Determiner les composantes principales et calculer les coefficients de correlation Solution\\[\\begin{aligned}&amp;amp;\\begin{matrix}X^{(1)}&amp;amp;X^{(2)}&amp;amp;X^{(3)}\\end{matrix}\\\\X=&amp;amp;\\begin{pmatrix} 16 &amp;amp; 2 &amp;amp;0 \\\\ 8&amp;amp;12&amp;amp;10 \\\\ 12&amp;amp;16&amp;amp;14 \\\\ 20&amp;amp;8&amp;amp;14 \\\\ 16&amp;amp;4&amp;amp;10 \\\\ 0&amp;amp;6&amp;amp;12 \\end{pmatrix}\\end{aligned}\\] 1. $p_i=\\frac{1}{6}$ $\\forall i=1,2,4,5,6$ poids de chaque individu et $M=I_3$ metrique La moyenne des variables:\\[\\bar X^{(1)}=\\sum_{i=1}^6p_iX_i^{(1)} = \\frac{1}{6}\\sum_{i=1}^6X_i^{(1)}=\\frac{72}{6}=12\\\\\\bar X^{(2)}=\\frac{1}{6}\\sum_{i=1}^6X_i^{(2)}=\\frac{1}{6}\\bullet 48=8\\\\\\bar X^{(3)}=\\frac{1}{6}\\sum_{i=1}^6X_i^{(3)}=\\frac{60}{6}=10\\] Donc $\\bar X^{(1)}=12$, $X^{(2)}=8$, $X^{(3)}=10$. Le centre de gravite du nuage forme par les 3 individus:\\[g^T=(12, 8, 10)\\] 2. Tableau des donnees centrees $Y$\\[y_i^{(j)}=X_i^{(j)}=\\bar X^{(j)}\\\\Y=\\begin{pmatrix}4&amp;amp;-6&amp;amp;-10\\\\-4&amp;amp;4&amp;amp;0\\\\0&amp;amp;8&amp;amp;4\\\\8&amp;amp;0&amp;amp;4\\\\4&amp;amp;-4&amp;amp;0\\\\-12&amp;amp;-2&amp;amp;2\\end{pmatrix}\\] 3. Matrice de var-covariance $V=Y^TDY$ avec $D=\\frac{1}{6}I_6$\\[\\Rightarrow V=\\frac{1}{6}Y^TY=\\begin{pmatrix}\\frac{128}{3}&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{68}{3}&amp;amp;\\frac{44}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}\\end{pmatrix}\\] 4. Diagonalisation de $MV=V$ $M=I_3$: metriques de l‚Äôespaces des individus $P_V(\\lambda)=det(V-\\lambda I_3)$ polynome caracteristiques de $V$\\[\\begin{aligned}P_v(\\lambda)&amp;amp;=\\begin{vmatrix}\\frac{128}{3}-\\lambda&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{68}{3}-\\lambda&amp;amp;\\frac{44}{3}\\\\-\\frac{16}{3}&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}-\\lambda\\end{vmatrix}\\\\C_1\\to C_1&amp;amp;+C_2+C_3\\\\P_v(\\lambda)&amp;amp;=(32-\\lambda)\\begin{vmatrix}1&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\1&amp;amp;\\frac{68}{3}-\\lambda&amp;amp;\\frac{44}{3}\\\\1&amp;amp;\\frac{44}{3}&amp;amp;\\frac{68}{3}-\\lambda\\end{vmatrix}\\quad\\text{par linearite}\\\\L_2\\to L_2-L_1&amp;amp;\\text{ et }L_3\\to L_3-L_1\\\\P_v(\\lambda)&amp;amp;=(32-\\lambda)\\begin{vmatrix}1&amp;amp;-\\frac{16}{3}&amp;amp;-\\frac{16}{3}\\\\0&amp;amp;28-\\lambda&amp;amp;20\\\\0&amp;amp;20&amp;amp;28-\\lambda\\end{vmatrix}\\\\&amp;amp;= (32-\\lambda)((28-\\lambda)^2-(20)^2)\\\\&amp;amp;= (32-\\lambda)(28-\\lambda-20)(28-\\lambda+20)\\end{aligned}\\\\\\color{red}{\\boxed{P_V(\\lambda) = (32-\\lambda)(8-\\lambda)(48-\\lambda)}}\\] Les valeurs propres de $V$: $\\lambda_1=48$, $\\lambda_2=32$, $\\lambda_3=8$ (ordre decroissant) 5. Le $\\%$ d‚Äôinertie Le $1^{er}$ axe: $\\frac{\\lambda_1}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{48}{88}=0,54 = 54\\%$ Le $2^{e}$ axe: $\\frac{\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{32}{88}=0,36=36\\%$ Le $3^{e}$ axe: $\\frac{\\lambda_3}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{8}{88}=0,09=9\\%$ Le plan factoriel: $\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3}=\\frac{80}{88}=90\\%$ 6. Les facteurs principaux sont les deux vecteurs propres associes aux valeurs propres $\\lambda_1=48$ et $\\lambda_2=32$.\\[E_{48}=Ker(V-48I_3)\\\\\\forall u=\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}\\in E_{48} \\Leftrightarrow (V-48I_3)\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix} = \\vec 0\\\\\\begin{cases}-\\frac{16}{3}x-\\frac{16}{3}y-\\frac{16}{3}z=0\\\\-\\frac{16}{3}x - \\frac{76}{3}y+\\frac{44}{3}z=0\\\\-\\frac{16}{3}x + \\frac{44}{3}-\\frac{76}{3}z=0\\\\\\end{cases}\\Leftrightarrow\\begin{cases}x+y+z=0\\quad(1)\\\\-16x-76y+44z=0\\quad(2)\\\\-16x+44y-76z=0\\quad(3)\\end{cases}\\\\(2)-(3)\\Rightarrow -120y+120z=0\\Rightarrow\\color{green}{\\boxed{y=z}}\\\\(1)\\Rightarrow\\color{green}{\\boxed{x=-2z}}\\\\E_{48}=Vect(\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix})\\quad\\text{Droite vectorielle}\\\\u^{(1)}=\\frac{1}{\\sqrt{4+1+1}}\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}\\\\\\color{red}{u^{(1)}\\text{ est norme}}\\\\\\Biggr\\Vert\\begin{pmatrix}2 \\\\ -1 \\\\ -1\\end{pmatrix}\\Biggr\\Vert=\\sqrt{4+1+1} = \\sqrt{6}\\\\E_{32}=Ker(V-32I_3)\\\\\\forall u=\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}\\in E_{32}\\Leftrightarrow (V-32I+3)\\begin{pmatrix}x \\\\ y \\\\ z\\end{pmatrix}=\\vec 0\\\\\\begin{cases}32x-16y-16z=0\\quad(1)\\\\-16x-28y+44z=0\\quad(2)\\\\-16x+44y-28z=0\\quad(3)\\end{cases}\\\\\\begin{cases}(2)-(3)&amp;amp;\\Rightarrow\\color{green}{\\boxed{y=z}}\\\\(1)&amp;amp;\\Rightarrow\\color{green}{\\boxed{y=x}}\\end{cases}\\\\\\color{red}{\\boxed{E_{32}=Vect\\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix}\\quad\\text{Droite}}}\\\\u^{(2)}=\\frac{1}{\\sqrt{3}}\\begin{pmatrix}1 \\\\ 1 \\\\ 1\\end{pmatrix}\\quad\\text{norme}\\] $(u^{(1)},u^{(2)})$ base orthonormee 7. Composantes principales\\[C^{(i)}=Yu^{(i)}\\quad i=1,2\\] La $1^{ere}$ composante:\\[\\begin{aligned}C^{(1)}&amp;amp;=Yu^{(1)}=\\begin{pmatrix}4&amp;amp;-6&amp;amp;-10\\\\-4&amp;amp;4&amp;amp;0\\\\0&amp;amp;8&amp;amp;4\\\\8&amp;amp;0&amp;amp;4\\\\4&amp;amp;-4&amp;amp;0\\\\-12&amp;amp;-2&amp;amp;2\\end{pmatrix}\\bullet\\frac{1}{\\sqrt{6}}\\begin{pmatrix}2\\\\-1\\\\-1\\end{pmatrix}\\\\&amp;amp;= \\begin{pmatrix}4\\sqrt{6}\\\\-2\\sqrt{6}\\\\-2\\sqrt{6}\\\\2\\sqrt{6}\\\\2\\sqrt{6}\\\\-4\\sqrt{6}\\end{pmatrix}\\quad\\text{variable centree}\\end{aligned}\\]\\[C^{(2)}=Yu^{(2)}=\\begin{pmatrix}-4\\sqrt{3}\\\\0\\\\4\\sqrt{3}\\\\4\\sqrt{3}\\\\0\\\\-4\\sqrt{3}\\end{pmatrix}\\quad\\text{variable centree}\\] RemarqueCes composantes principales contiennent les projections des individus sur les 2 axes factoriels. Calcul des coefficients de correlation:\\[\\rho(X_1^{(1)}, C^{(1)})=\\frac{Cov(X^{(1)},C^{(1)})}{\\sigma_{X^{(1)}}\\sigma_{C^{(1)}}}\\\\Cov(X^{(1)},C^{(1)})=&amp;lt;y^{(1)},C^{(1)}&amp;gt;={y^{(1)}}^TD.C^{(1)}\\quad\\text{produit scalaire de l&#39;espace des variables}\\\\D=\\frac{1}{6}I_6\\quad\\text{Metriques dans l&#39;espace des variables}\\\\\\color{green}{\\boxed{Cov(X^{(1)},C^{(1)}) = \\frac{1}{6}{y^{(1)}}^TC^{(1)}}}\\]\\[\\begin{aligned}Cov(X^{(1)},C^{(1)})&amp;amp;=\\frac{1}{6}(16\\sqrt{6}+8\\sqrt{6}+16\\sqrt{6}+8\\sqrt{6}+48\\sqrt{6})\\\\&amp;amp;= \\frac{96\\sqrt{6}}{6}=\\color{green}{\\boxed{16\\sqrt{6}}}\\end{aligned}\\\\\\sigma_{X^{(1)}} = \\sqrt{V(X^{(1)})} = \\sqrt{\\frac{128}{3}}\\\\\\begin{aligned}\\sigma_{C^{(1)}}=\\Vert C^{(1)}\\Vert&amp;amp;=\\sqrt{&amp;lt;C^{(1)},C^{(1)}&amp;gt;}\\\\&amp;amp;= \\sqrt{\\frac{1}{6}(96+24+24+24+24+96)}\\\\&amp;amp;=\\color{green}{\\boxed{4\\sqrt{3}}}\\end{aligned}\\\\\\rho(X^{(1)}, C^{(1)}) =\\frac{16\\sqrt{6}}{\\sqrt{\\frac{128}{3}}\\bullet 4\\sqrt{3}} = \\color{green}{\\boxed{\\frac{\\sqrt{3}}{2}}}\\] Tableau des correlations: ¬† $C^{(1)}$ $C^{(2)}$ $X^{(1)}$ $\\frac{\\sqrt{3}}{2}=0,87$ $\\frac{1}{2}=0,5$ $X^{(2)}$ $-\\sqrt{\\frac{6}{17}}=-0,59$ $\\frac{2\\sqrt{34}}{17}=0,69$ $X^{(3)}$ $-0,59$ $0,69$ Exercice 2\\[X=\\begin{pmatrix}2&amp;amp;2&amp;amp;3\\\\3&amp;amp;1&amp;amp;2\\\\1&amp;amp;0&amp;amp;3\\\\2&amp;amp;1&amp;amp;4\\\\2&amp;amp;1&amp;amp;3\\end{pmatrix}\\] Calculer $\\bar{X^{(1)}}$, $\\bar{X^{(2)}}$, $\\bar{X^{(3)}}$ et le centre de gravite Calculer la matrice $Y$ Calculer $V$ Diagonaliser $V$ et calculer le $\\%$ d‚Äôinertie Facteurs principaux et composantes principales Solution 1.\\[P_i=\\frac{1}{5}\\quad\\forall i\\\\\\bar{X^{(1)}}=2, \\bar{X^{(2)}}=1, \\bar{X^{(2)}}=3\\\\g^T=(2,1,3)\\] 2.\\[Y=\\begin{pmatrix}0 &amp;amp;1&amp;amp;0\\\\1&amp;amp;0&amp;amp;-1\\\\-1&amp;amp;-1&amp;amp;0\\\\0&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\end{pmatrix}\\] 3.\\[V = Y^TDY\\\\D = \\frac{1}{5}I_5\\\\\\begin{aligned}V &amp;amp;= \\frac{1}{5}Y^TY\\\\&amp;amp;=\\frac{1}{5}\\begin{pmatrix}2&amp;amp;1&amp;amp;-1\\\\1&amp;amp;2&amp;amp;0\\\\-1&amp;amp;0&amp;amp;2\\end{pmatrix}\\end{aligned}\\\\\\begin{aligned}P_{Y^TY}(\\lambda)&amp;amp;=\\begin{vmatrix}2-\\lambda &amp;amp;1&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-1&amp;amp;0&amp;amp;2-\\lambda\\end{vmatrix}\\quad C_2\\to C_2+C_3\\\\&amp;amp;=\\begin{vmatrix}2-\\lambda &amp;amp;0&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-1&amp;amp;2-\\lambda&amp;amp;2-\\lambda\\end{vmatrix}\\quad L_2\\to L_3-L_2\\\\&amp;amp;= \\begin{vmatrix}2-\\lambda &amp;amp;0&amp;amp;-1\\\\1 &amp;amp;2-\\lambda&amp;amp;0\\\\-2&amp;amp;0&amp;amp;2-\\lambda\\end{vmatrix}\\\\&amp;amp;= (2-\\lambda)((2-\\lambda)^2-2)\\\\&amp;amp;=(2-\\lambda)(2-\\lambda-\\sqrt{2})(2-\\lambda+\\sqrt{2})\\\\\\end{aligned}\\\\\\begin{cases}\\Gamma_1 = 2+\\sqrt{2}\\\\\\Gamma_2 = 2\\\\\\Gamma_3=2-\\sqrt{2}\\end{cases}\\Rightarrow\\begin{cases}\\lambda_1=\\frac{2+\\sqrt{2}}{5}\\\\\\lambda_2 = \\frac{2}{5}\\\\\\lambda_3 = \\frac{2-\\sqrt{2}}{5}\\end{cases}\\]\\[\\%\\quad\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3} = ?\\] Facteurs principaux:\\[E_{2+\\sqrt{2}}=Ker(Y^TY-(2+\\sqrt{2})I) = Vect\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\ 1\\end{pmatrix}\\\\\\color{green}{\\boxed{u^{(1)}=\\frac{1}{\\sqrt{4}}\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}-\\sqrt{2} \\\\ -1 \\\\1\\end{pmatrix}}}\\\\\\%\\quad\\frac{\\lambda_1+\\lambda_2}{\\lambda_1+\\lambda_2+\\lambda_3} = 90\\%\\quad\\text{(inertie maximale)}\\\\E_2=Ker(Y^TY-2I_3)=Vect\\begin{pmatrix}0 \\\\ 1 \\\\1\\end{pmatrix}\\\\\\color{green}{\\boxed{u^{(2)}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\ 1 \\\\1\\end{pmatrix}}}\\] Composantes principales:\\[C^{(1)}=Yu^{(1)}=\\begin{pmatrix}-\\frac{1}{2}\\\\-\\frac{\\sqrt{2}}{2}-\\frac{1}{2}\\\\\\frac{\\sqrt{2}}{2}+\\frac{1}{2}\\\\\\frac{1}{2}\\\\0\\end{pmatrix}\\quad\\text{centrees}\\\\C^{(2)}=Yu^{(2}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}\\\\-\\frac{1}{\\sqrt{2}}\\\\-\\frac{1}{\\sqrt{2}}\\\\\\frac{1}{\\sqrt{2}}\\\\0\\end{pmatrix}\\]" }, { "title": "ASE3: Analyse en composantes principales", "url": "/cours/posts/ase3_composantes_principales/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, ACP", "date": "2021-06-09 09:00:00 +0200", "snippet": "Lien de la note HackmdDonnees et leurs caracteristiquesTableau des donneesLes observations de $p$ variables sur $n$ individus sont regroupes en une matrice $X$ a $n$ lignes et $p$ colonnes\\[X=\\begin{matrix}te_1 \\\\ \\vdots \\\\ te_i \\\\ \\vdots \\\\te_n\\end{matrix}\\begin{pmatrix}X^{(1)} &amp;amp;\\dots &amp;amp;X^{(j)} &amp;amp;\\dots &amp;amp;X^{(p)}\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots\\\\\\dots&amp;amp;\\dots &amp;amp;\\color{red}{X_i^{(j)}} &amp;amp;\\dots &amp;amp;\\dots\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\vdots\\\\\\dots&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots&amp;amp;\\dots\\end{pmatrix}\\\\te_i=(X_i^{(1)},X_i^{(2)},\\dots,X_i^{(j)},\\dots,X_i^{(p)})\\\\e_i=\\begin{pmatrix}X_i^{(1)} \\\\ \\vdots \\\\ X_i^{(j)} \\\\ \\vdots \\\\ X_i^{(p)}\\end{pmatrix}\\]\\(X_i^{(j)}\\) est la valeur prise par la variable $X$ sur le ieme individu.Matrice des poidsOn associe a chaque individu un poids $p_i\\ge0$ (probabilite de choisir l‚Äôindividu)\\[\\sum_{i=1}^np_i=1, D=\\begin{pmatrix} p_1 &amp;amp;0&amp;amp;\\dots&amp;amp;0 \\\\ 0 &amp;amp;p_2&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots &amp;amp;\\vdots &amp;amp;\\ddots&amp;amp;\\vdots\\\\ 0 &amp;amp;0 &amp;amp;\\dots &amp;amp;p_n \\end{pmatrix}\\]Si $p_i=\\frac{1}{n}\\Rightarrow D=\\frac{1}{n}I_n$ ou $I_n$ matrice identite \\(\\begin{pmatrix} 1&amp;amp;0&amp;amp;\\dots &amp;amp;0 \\\\ 0&amp;amp;1&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots&amp;amp;\\vdots&amp;amp;\\ddots &amp;amp;\\vdots \\\\ 0 &amp;amp; 0&amp;amp;\\dots&amp;amp;1 \\end{pmatrix}\\) $\\forall i=1,\\dots,n$Centre de graviteLa vecteur $g$ des moyennes arithmetiques de chaque variable $X^{(j)}$ est definie par $g=(\\bar X^{(1)},\\bar X^{(2)},\\dots,\\bar X^{(p)})$\\[\\bar X^{(j)}=\\sum_{i=1}^np_iX_i^{(j)}\\quad\\text{moyenne de } X^{(j)}\\quad\\forall j\\in [1,p]\\] Le tableau des donnees centrees est la matrice Y telle que\\[y_i^{(j)}=X_i^{(j)}-\\bar X^{(j)}\\quad\\forall j\\in[1,p], \\forall i\\in[1, n]\\]Matrice de variance-covariance et matrice de correlation Definition:On appelle matrice de variance-covariance: \\[V=Y^TDY\\] Si on note $D_{\\frac{1}{S}}$ la matrice diagonale des inverses des ecarts-types:\\[D_{\\frac{1}{S}} = \\begin{pmatrix}\\frac{1}{S_1} &amp;amp;\\dots &amp;amp;0\\\\\\vdots &amp;amp;\\ddots &amp;amp;\\vdots \\\\0&amp;amp;\\dots&amp;amp;\\frac{1}{S_p} \\end{pmatrix}\\]ou: $S_j=\\sqrt{V(X^{(j)})}=\\sqrt{\\sum_{i=1}^np_i(X_i^{(j)}-\\bar X^{(j)})^2}$ $V(X^{(j)})$: variance de $X^{(j)}$ $S_j$: ecart-type de $X^{(j)}$On appelle la matrice des donnees centrees et reduite: $Z$ telle que:\\[Z_i^{(j)}=\\frac{y_i^{(j)}}{S_j}\\] Matriciellement:\\[Z=Y\\bullet D_{\\frac{1}{S}}\\]La matrice regroupant les coefficients de correlation lineaire entre les $p$ variables est $R$:\\[R=\\begin{pmatrix}1&amp;amp;\\dots&amp;amp;p_{ij}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\p_{ij}&amp;amp;\\dots&amp;amp;1\\end{pmatrix}\\quad\\text{symetrique}\\\\r_{ij}=\\underbrace{p_{ij}}_{\\text{coefficient de correlation}}=\\frac{Cov(X^{(i)}, X^{(j)})}{S_iS_j}\\]Ou: $Cov(X^{(i)}, X^{(j)})$: covariance\\[Cov(X^{(i)}, X^{(j)})=\\sum_{k=1}^np_k\\underbrace{y_k^{(i)}y_k^{(j)}}_{\\text{produit scalaire des variables centrees}}\\]Remarque:\\[\\begin{aligned}R&amp;amp;=D_{\\frac{1}{S}}VD_{\\frac{1}{S}}\\\\&amp;amp;=D_{\\frac{1}{S}}Y^TDYD_{\\frac{1}{S}}\\\\&amp;amp;\\Leftrightarrow\\color{red}{\\boxed{R=Z^TDZ}}\\end{aligned}\\]Espaces des individusChaque individu etant un vecteur defini par $p$ coordonnees est considere comme un element d‚Äôun espace vectoriel $F$ appele l‚Äôespace des individus.Les $n$ individus forment alors un nuage de points dans $F$ et $g$ en est le barycentre (ou centre de gravite).On munit l‚Äôespace $F$ d‚Äôune metrique (distance):\\[\\underbrace{&amp;lt;e_i, e_j&amp;gt;}_{\\text{produit scalaire}}=e_i^TMe_j\\]ou: $M$ est une matrice symetrique et definie positive (S.D.P)Remarque: si $M=I$ (matrice identite), on se retrouve avec le produit scalaire usuel.Si \\(M=D_{\\frac{1}{S^2}}=\\begin{pmatrix}\\frac{1}{S_1^2}&amp;amp;\\dots&amp;amp;0 \\\\ \\vdots &amp;amp;\\ddots &amp;amp;\\vdots \\\\ 0 &amp;amp;\\dots &amp;amp;\\frac{1}{S_p^2} \\end{pmatrix}\\) cela revient a diviser chaque caractere par son ecart-type.Inertie Definition:On appelle inertie totale du nuage de points la moyenne ponderee des carres des distances des points au centre de gravite:\\[\\begin{aligned}I_g&amp;amp;=\\sum_{i=1}^np_i(e_i-g)^TM(e_i-g)\\\\&amp;amp;=\\sum_{i=1}^np_i\\Vert e_i-g\\Vert^2\\end{aligned}\\]Proprietes de l‚ÄôinertieOn peut montrer que l‚Äôinertie du nuage est egale a la trace de la matrice $MV$:\\[I_g=Trace(MV)=Trace(VM)\\]Espace des variablesOn note $E$: l‚Äôespace des variables\\[X^{(j)}=\\begin{pmatrix}X_i^{(j)} \\\\ \\vdots \\\\ X_n^{(j)} \\end{pmatrix}\\]On munit $E$ de la metrique $M=D$ avec D la matrice des poids\\[\\underbrace{&amp;lt;X^{(j)}, X^{(k)}&amp;gt;}_{\\text{produit scalaire}}=(X^{(j)})^TDX^{(k)}\\]Si les variables sont centrees:\\[\\begin{aligned}(X^{(j)})^TDX^{(k)}&amp;amp;=\\sum_{i=1}^np_iX^{(j)}_iX^{(k)}_i\\\\&amp;amp;=Cov(X^{(j)}, X^{(k)})\\end{aligned}\\]La norme de $X^{(j)}$ (variable centree)\\[\\begin{aligned}\\Vert X^{(j)}\\Vert^2&amp;amp;=&amp;lt;X^{(j)}, X^{(j)}&amp;gt;\\\\&amp;amp;=\\sum_{i=1}^np_i(X_i^{(j)})^2=S_j^2\\\\\\Rightarrow\\Vert X^{(j)}\\Vert&amp;amp;=S_j\\quad\\text{ecart-type}\\end{aligned}\\]On mesure l‚Äôangle entre 2 variables $X^{(j)}$ et $X^{(k)}$ (centrees):\\[\\cos(\\theta_{jk})=\\frac{&amp;lt;X^{(j)}, X^{(k)}&amp;gt;}{\\Vert X^{(j)}\\Vert\\Vert X^{(k)}\\Vert}\\quad\\text{similarite cosinus}\\\\\\color{red}{\\boxed{\\cos(\\theta_{jk}) = \\frac{Cov(X^{(j)}, X^{(k)})}{S_jS_k} = p_{jk}}}\\] On retrouve le coefficient de correlation lineaire.Variables engendree par un tableau des donneesA une variable $X^{(j)}$, on peut associer un axe de l‚Äôespace des individus $F$ et un vecteur de l‚Äôespace des variable et on peut egalement deduire $X^{(1)}, X^{(2)},\\dots,X^{(j)}, \\dots, X^{(p)}$ de nouvelles variables par combinaison lineaire.Soit $\\triangle$ un axe de $F$. $\\triangle$ est engendre par un vecteur unitaire $a$ \\((a^T\\underbrace{M}_{\\text{metriques}}a=1)\\) et projetons les individus sur $\\triangle$ (projection $M$-orthogonale)\\[\\begin{aligned}c_i=a^TMe_i&amp;amp;=e_i^TMa\\\\&amp;amp;=&amp;lt;e_i,a&amp;gt;\\quad\\text{produit scalaire}\\end{aligned}\\]La liste des coordonnees $c_i$ des individus sur $\\triangle$ forme une nouvelle variable artificielle $C$\\[C=\\begin{pmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n\\end{pmatrix}=X\\underbrace{Ma}_{=u}=Xu\\]On pose $u=Ma$: facteur\\[\\Rightarrow C=Xu=\\sum_{j=1}^pu_jX^{(j)}\\] Donc la nouvelle variable $C$ est une combinaison lineaire des variables initiales.L‚Äôensemble des variables $C$ que l‚Äôon peut engendrer par combinaison lineaire des vecteurs colonnes de $X$ forme un sous-espace vectoriel (s.e.v.) de $E$ de dimension $\\le p$Remarque: Si $M=I\\Rightarrow u=a$On suppose que les variables sont centrees ($X=Y$) pour simplifier Proposition: \\[V(C) = u^TVu\\quad\\text{variance de }C\\] Demonstration:\\(\\begin{aligned}V(C) &amp;amp;=c^TDc\\\\&amp;amp;= (Xu)^TDXu=u^T\\underbrace{X^TDX}_{V}u\\\\&amp;amp;\\Rightarrow V(C)=u^TVu\\end{aligned}\\)Le but de la methode est d‚Äôobtenir une representation approchee du nuage des $n$ individus dans un s.e.v de dimension faible. Ceci s‚Äôeffectue par projectionIl faut deformer le moins possible les distances en projection, ce qui signifie que l‚Äôinertie du nuage projete sur le s.e.v. $F_k$ soit maximale.Soit $P$: la projection $M$-orthogonale sur le s.e.v. $F_k$\\[Pe_i=f_i\\\\P^2=P\\quad\\text{et}\\quad P^TM=MP\\]Le nuage projete est associe au tableau: $XP^T$ car:\\[\\underbrace{f_i=Pe_i}_{\\text{vecteur colonne}}\\Rightarrow \\underbrace{f_i^T=e_i^TP^T}_{\\text{vecteur ligne}}\\]On determine la matrice de var-covariance du tableau $XP^T$:\\[(XP^T)^TD(XP^T)\\quad\\text{(les var sont centrees)}\\\\=PX^TDXP^T\\\\=\\color{red}{\\boxed{PVP^T}}\\]On determine l‚Äôinertie du nuage projete: $Trace(PVP^TM)$\\[\\begin{aligned}Tr(PVP^TM)&amp;amp;=Tr(PVMP)\\\\&amp;amp;=Tr(VMP^2)\\quad\\text{car }Tr(AB)=Tr(BA)\\\\&amp;amp;=Tr(VMP)\\end{aligned}\\] Donc l‚Äôinertie du nuage projete est $Trace(VMP)$Le probleme est donc de trouver $P$: projection $M-$orthogonale de rang $k$ maximisant la trace de $VMP$, ce qui determinera $F_k$ ($\\text{dim } F_k=k$)Theoreme Theoreme:Soit $F_k$ un s.e.v. portant l‚Äôinertie maximale, alors le s.e.v. de dimension $k+1$ portant l‚Äôinertie maximale est la somme directe de $F_k$ et du s.e.v. de dimension $1$ $M$-orthognal a $F_k$ portant l‚Äôinertie maximale. \\[F_{k+1}=F_k+\\underbrace{b\\mathbb R}_{\\text{dimension }1}\\] Pour obtenir $F_k$ on pourra proceder de proche en proche en cherchant d‚Äôabord le s.e.v. de dimension $1$ d‚Äôinertie maximale puis le s.e.v. de dimension $1$ $M-$orthogonal au premier d‚Äôinertie maximale.On chercher la droite de $\\mathbb R^2$ passant par $g$, maximisant l‚Äôinertie du nuage projete sur cette droite, On rappelle la projection $M$-orthogonale sur la droite dirigee par $a$:\\[P=a(a^TMa)^{-1}a^TM\\]Inertie du nuage projete sur cette droite:\\[\\begin{aligned}Tr(VMP)&amp;amp;=Tr(VMa(a^TMa)^{-1}a^TM)\\\\&amp;amp;= \\frac{1}{a^TMa}Tr(VMaa^TM)\\\\&amp;amp;= \\frac{1}{a^TMa}Tr(a^TMVMa)\\\\&amp;amp;=\\frac{a^TMVMa}{a^TMa}\\end{aligned}\\\\\\frac{d}{da}(\\frac{a^TMVMa}{a^TMa})=0\\quad\\text{(*)}\\]Rappel\\[\\frac{d}{da}(\\underbrace{a^TAa}_{\\text{forme quadratique}})=Aa+A^Ta\\] Si $A$ est symetrique:\\[\\frac{d}{da}(a^TAa)=2Aa\\]\\[\\begin{aligned}\\text{(*)} &amp;amp;\\Rightarrow \\frac{(a^Tma)2MVMa-(a^TMVMa)2MA}{(a^TMa)^2}=0\\\\&amp;amp;\\Rightarrow MVMa=\\biggr(\\frac{a^TMVMa}{a^TMa}\\biggr)Ma\\\\&amp;amp;\\Rightarrow VMa=\\biggr(\\frac{a^TMVMa}{a^TMa}\\biggr)a\\\\&amp;amp;\\Rightarrow \\color{red}{\\boxed{VMa=\\lambda a}}\\quad\\text{avec }\\lambda=\\frac{a^TMVMa}{a^TMa}\\end{aligned}\\] Donc $a$ est un vecteur propre de $VM$ associe a $\\lambda$ (valeur propre). Il faut que $\\lambda$ soit maximale.Donc le s.e.v. $F_k$ de dimension $k$ est engendre par les $k$ vecteurs propres de $VM$ associes aux $k$ plus grandes valeurs propres. On appelle composantes principales: \\[C^{(i)}=Yu^{(i)}\\quad u^{(i)}\\text{: facteur}\\] Si les variables initiales sont centrees alors $C^{(i)}=Xu^{(i)}$\\[V(C^{(i)}) = \\lambda i\\quad\\forall i\\]Qualites des representations sur les plans principauxLe but de l‚ÄôA.C.P. etant d‚Äôobtenir une representation des individus dans un espace de dimension plus faible que $p$. Le critere le plus utilise est celui du pourcentage d‚Äôinertie totale expliquee on mesure la qualite de $F_k$ par:\\[\\frac{\\lambda_1+\\lambda_2+\\dots+\\lambda_k}{\\lambda_1+\\lambda_2+\\dots+\\lambda_p}\\] Inertie totale:\\[\\lambda_1+\\lambda_2+\\dots+\\lambda_p=I_{tot}\\]Si par exemple $\\frac{\\lambda_1+\\lambda_2}{I_{tot}}=90\\%$, on concoit qu‚Äôune representation du nuage dans le plan des 2 premiers axes principaux sera tres satisfaisante.Correlations entre composantes principales et variables initialesLa methode la plus naturelle pour donner une signification a une composante principale $C^{(i)}$ est de la relier aux variables $X^{(j)}$ (variables intiales) en calculant les coefficients de correlation lineaire\\[\\rho(X^{(j)}, C^{(i)})\\]et en s‚Äôinteressant aux plus forts coefficients en valeur absolue\\[\\rho(X^{(j)}, C^{(i)})=\\frac{Cov(X^{(j)}, C^{(i)})}{\\sigma_{X^{(j)}}\\sigma_{C^{(i)}}}\\]\\[Cov(X^{(j)}, C^{(i)}) = &amp;lt;y^{(j)}, C^{(i)}&amp;gt;\\quad\\text{ou }y^{(j)}\\text{ : var centree}\\]" }, { "title": "MLRF: Lecture 04", "url": "/cours/posts/mlrf_fourth_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 4 Introduction Content-based image retrievalasl (CBIR) using bags of features Evaluating CBIR / Ranked Retrieval (RR) systems Texture descriptors Character descriptorsSummary of last lecture Descriptor matching 1-way Cross check Ratio test Radius threshold Descriptor indexing Indexing pipeline: train/query Linear matching kD-Trees FLANN/hierarchical k-Means LSH Aproximate NN problem Projective transformations Translation Rotation Scaling ‚Ä¶ Projective Homography estimation Least square RANSAC Geometric validationPractice session 3: Take home messagesTwin it!: Extracting descriptors, matching them by hand Detect keypoints and extract surrounding pixels to flat vector Normalize them and compare them using cross correlation ($\\sum_if_i\\bullet g_i$)Augmented Documents: Use an off-the-shelf detector/descriptor: ORBAugmented Documents: Projective transforms and Homography estimation OpenCV provides the solver for machinery: list of matches $to$ $3\\times 3$ matrix Just som coordinate transform (2D $\\to$ 2D transform) Remember the classical matrix forms: translation, rotation, ‚Ä¶Next practice session Implement a simple image search engine Will be gradedLocal feature descriptorsIntroductionGiven some keypoints in image 1, what are the more similar ones in image 2 ? This is a nearest neighbor problem in descriptor spaceThis is also a geometrical problem in coordinate space Local feature detectors give use the same feature under several perturbations: perspective, illumination, blur‚Ä¶Local feature descriptors will associate a vector to each local feature.Such description vector should be: Compact - to enable fast indexing and matching Discriminative - to enable object recognition Robust to perturbations - to tolerate real conditionsWe will focus on 2 widely used descriptors for their pedagogical interest HOG (Histogram of gradients), used im SIFT BRIEF (Binary Robust Independent Elementary Features), used in ORBHistogram of GradientAlgorithm overview (optional) global image normalization Compute the gradient image in $x$ and $y$ Compute gradient hisograms Normalise across blocks Flatten into a feature vector (quantify to integers)Exemple Cette sensation quand tu cogne ton coude au niveau du nerfSummaryPros Very stable over illuminations changes perpectives changes, blurCons Slow to compute Quite large (128 bytes for original SIFT)BRIEFGeneral idea: Sample pairs of points \\(\\{p(x), p(y)\\}\\) in the smoothed (very spiky otherwise, like derivatives) keypoints neighborhood Compute a simple binary test: $p(x)\\lt p(y)$ Accumulate the results of $n_d$ tests to form a binary vector of $n_d$ bits (256 in ref.)Sampling strategies GI: $(x_i, y_i)\\sim$ i.i.d. Uniform($-\\frac{S}{2}$, $+\\frac{S}{2}$) GII: $(x_i, y_i)\\sim$ i.i.d. Gaussian($0$, $\\frac{1}{25}S^2$) GII: $x_i\\sim$ i.i.d. Gaussian($0$, $\\frac{1}{25}S^2$) $y_i\\sim$ i.i.d. Gaussian($x_i$, $\\frac{1}{100}S^2$) GIV: $(x_i, y_i)$ randomly sampled from discrete locations of a coarse polar grid introducing a spatial quantization GV: $x_i=(0,0)$ $y_i$ takes all possible values on a coarse polar grid containing $n_d$ points What is the best approach ? C‚Äôest la strategie 2SummaryPros Very fast to compute Very fast to match Very compact to store Cons Less robust than HoG(SIFT), DoH(SURF) on several real casesInvariance checkRotation invariance Add an angle measure Take the main gradient orientation (Take the averga around the keypoints) We now have for each keypoint: Coordinates OrientationDescriptor: computed over normalized patchScale invarianceMulti scale feature detection and computation: Add a keypoint for each relevant scale Possibly several keypoints at the same positionWe now have for each keypoint: Coordinates Orientation ScaleDescriptor: computed on a scaled patchReminder: Gaussian sigma vs window sizeIllumation invarianceSIFT approach: Normalize the vector Solves Affine but what non-linear sources like camera saturation? Cap the vector elements to $20\\%$ (!) and renormalize Now we have some illumination invariance Viewpoint invarianceBetter, but more complex approaches can tolerate extreme viewpoint changeComplete pipelinesSIFT (Scale invariant feature tr.) Construct scale space Take difference of Gaussians Locate DoG Extrema Sub pixel locate potential feature points Filter edge and low contrast responses Assigne keypoints orientations Build keypoint descriptors Matching, etc.ORB (oriented FAST and rotated BRIEF) Use FAST in pyramids to detect stable keypoints Select the strongest features using FAST or Harris response Finds their orientation using first-order moments Computes the descriptors using BRIEF Where the coordinates of random point pairs are rotated according to the measured orientation Conclusion about feature extractionSelection of appropriate features: It is a critical decision Depends on the specific applicationFeatures must: Be invariant to data variations (depending on the application) rotation perpective noise etc. Have low dimensionality for fast training, matching, reasonable storageFeatures determine the type of info to work with: gray-level, binary, color image contours, vectorization, skeletonFeatures also determine the type of classifier / indexerContent based image retrievalTwo strategies using local descriptorsKeep all local descriptorsPros: Enables geometric validation better part detection in theoryCons: Huge memory requirements Like what we did in practice session 3 to match parts of an image (useful to validate geometric constraints and classify an image at the same time)Build a global descriptor using local ones Inspired by text retrieval Compact representation Tricks to embed spatial information Limited memory requirements Like what we did in practice session 2 with the color histogram, at the bubble level Bag of Feature approachPipeline with local descriptors (prev. lecture)Pipeline with bag of features (current lecture)Features extractionSparse vs Dense detection For dense detection, we usually filter regions with low varianceDimensionality reductionOften used before encoding to: limit dictionary sizes facilitate quantizationSeveral techniques: Principal Component Analysis Signualr-Value DecompositionEncodingBag of Visual Words Modern approaches are derived from this one Reuses ideas of text/we search to images From a set of descriptor, build a histogram of quantized descriptors much alike a color histogramQuantization Discretization of some signal - Lossy process! Vectorial formulation: $f:R^d\\to F$, with $F={1,2,‚Ä¶,k}$ Defines a Voronoi diagram, ie a decomposition of a metric space determined by the distances to a discrete set of pointsBag of Visual Words (continued) Cluster centers are determined using k-Means (once for all on a training set) Each descriptor is quantized: store the code of the closest centroid Build a histogram of descriptor count for each cluster The set of cluster centers is called the dictionary, the codebook or also the visual vocabulary We can choose the number of words !Vector sizeThe resulting vector size for a given image is given by:\\[D=\\text{vocabulary size}\\]Usually, the bigger the vocabulary the better the results.Several thousands of words are common.NormalizationPremiere methodeProblem: The values in the histogram are absolute: each bin count the number of occurence of each visual word This make the descriptor sensitive to the variation of number of descriptorsSolution: Normalize the histogramSeconde technique Like for text retrieval, it is common to reweight the BOVW vectors using the TFDIF technique Goal: give more importance to rare words than to frequent ones For each dimension of the histogram, compute a new value $t_i$Variant: Soft BoVWUse soft assignment to clusters, add counts to neighbor binsOther variantsBoVW is only about counting the number of local descriptorsVLAD: vector of locally aggregated descriptorsFisher vectorIR evalutationHow to evaluate a retrieval system ?We need a set of queries for which we know the expected results ‚ÄúGround truth‚Äù, aka ‚Äútargets‚Äù, ‚Äúgold standard‚ÄùPrecision and recallUsed to measure the balance between Returning many results, hence a lot of the relevant results present in the database, but also a lot of noise Returning very few results, leading to less noise, but also less relevant results Precision ( P ) is the fraction of retrieved documents that are relevant: Recall ( R ) is the fraction of relevant documents that are retrieved F-measure F-measure is the wighted harmonic mean of precision and recallHow to evaluate a ranked retrieval system ?When results are ordered, more measures are availables.Common useful measure are: Precision-recall ROC graph nd the area under it (AUC)Precision-recall graphMean-average precisionExample: Compute the AP for a given queryFor this query and the followinf results, plot the precision/recall graph 1, 3 et 9 sont pertinents iciIs the first result relevant ?Oui compute current precision: 1 relevant / 1 retrieved = 1 Recall: 1 relevantRepeter pour chaque resultat Construction du graphe en dent de scie Certaines librairies garde les valeurs superieures, c‚Äôest pas bienCase 2: what if $\\vert e_i\\vert=4$ ? Ce qu‚Äôon veut c‚Äôest l‚Äôaire sous la courbe" }, { "title": "POGL: Second class", "url": "/cours/posts/pogl_second_course/", "categories": "Image S8, POGL", "tags": "Image, POGL, S8", "date": "2021-06-02 14:00:00 +0200", "snippet": "Lien de la note HackmdFrame buffer objectQuand on veut faire un rendu de l‚Äôoffscreen rendering:Calcul final au dernier moment Avantage: ce calcul n‚Äôest pas faut pour les points qui ne sont pas visiblesOn va faire un rendu par buffer qui n‚Äôest pas visible un pour la couleur un pour la profondeur etcEn tout les points du quadrilateres du rendu on a les couleurs, normales, etc. et on peut en deduire les combinaisons pour le calcul effectif de l‚Äôillumination Les combinaisons sont calculees une seule fois pour les points visibles sur un quadrilatere C‚Äôest utilise dans les jeux videos pour economiser du tempsOff-screen renderingOn a besoin de pouvoir ecrire pour notre premier rendu similutanement la profondeur, couleur, etc. Pour cela on defini plusieurs variables out dans notre shader (Multi-Render target)Depth shadow maps Avant de faire le rendu final, pour savoir quels sont les objets visibles, on fait le rendu depuis la source lumineuse Faire le rendu en tenant compte de parties visibles ou pas depuis la source lumineuseInitialise FBORendu depuis la source lumineuseRendu depuis la cameraVertex shaderFragment shaderResultatsOn a le z-buffer depuis la source lumineuse On s‚Äôattendait a un super resultat mais la partie pas a l‚Äôombre a mal renduePourquoi ?Quand on fait le rendu, on discretise la scene: peut-etre que quand on verifie un pixel on est trop a droite ou trop a gauche, donc des pixels sont consideres a l‚Äôombre alors qui ne le sont pas.Solution: ajout d‚Äôun biais Ce biais n‚Äôest pas facile a fixer car depend de notre scene, sa taille, la taille des objets, etc. Le lapin profite du soleil avant d‚Äôavoir trop chaudSecond depth shadow map Faire le rendu de la scene depuis la lumiere en regardant les faces arrieres des objets On inverse le backface culling On n‚Äôa plus besoin du biais Le biais est toutefois plus facile a mettreResultats Il n‚Äôy a ni anti-aliasing, ni ombres doucesOn n‚Äôa plus d‚Äôartefacts et on a un rendu temps reel qui fonctionne tres bien.Pour aller plus loin: sampler2DShadow/textureProj() soft shadow map etc.Rendu finalFrame buffer objectsOn a plusieurs images, a t-1, t et t+1 (par exemple) Rendu d‚Äôune position dans une texture/un render buffer Accumulation dans une texutre (Type float sinon les valeurs sont clampees) Copies dans l‚Äôimage finaleNous en train de courir vers le lapin, ca donne : Au lieu de faire un rendu, on en fait 3Post processingOn a un quadrilatere affiche dont on peut modifier la texture comme on souhaite.Rendu dans une textureOn deforme l‚Äôimage Notre lapin a trouve des champignons, les a mange mais c‚Äôetait des champignons hallucinogenesOpenGLObject Picking L‚Äôidee: on va faire un rendu intermediaire off-screen, on associe a chaque objet un identificateurs dans les FBOsLe brouillard ObjectifModifier la couleur en fonction de la distance choisir la fonction On retrouve notre lapin perdu dans le brouillardMoteur de particulesSystemes a base de particules Permet de modeliser des elements difficiles a modeliser avec des solides classiques ou des surfaces feu fumee etc Fonctionnement Caracteristiques position couleur taille forme ‚Ä¶ Lois creation destruction Regles (Evolution) Modifications des caracteristiques Le feuUtilisation de particules Creation Plusieurs centaines Apparaissent dans une zone precise Avec une couleur proche du blanc Forme Point Sphere Evolution Changement de couleur Deplacement vers le haut avec perturbations Destruction Atteint la couleur noir Evolution: changement de couleurResultat:Si on est flemmards: utilisation d‚Äôun billboard Affichage d‚Äôun feu en 2DEtinceles/feu d‚Äôartifice/explosionResultat:C‚Äôest les memes regles que pour le feuOn fait des bulles qui grossissent de plus en plusBillboardUtilisation d‚Äôun BillboardConclusionLes effets intermediares qu‚Äôon peut faire pour le rendu final." }, { "title": "ASE3: TD 1 - 3", "url": "/cours/posts/ase3_td_1_3/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple, loi conjointe, loi marginale", "date": "2021-06-02 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 6Le nombre de clients arrivants dans un magasin est une v.a. $N$ suivant une loi de Poisson $\\mathcal P(\\lambda)$. Les clients se repartissent entre les $m$ caisses du magasin de facon independante et chaque client choisit sa caisse au hasard.$X_1$ v.a.: nombre de clients qui passent a la caisse n$^o1$. Determiner la loi conditionelle de $X_1$ sachant que ($N=n$) Determiner la loi marginale de $X_1$ Solution 1.\\[\\forall 0\\le k\\le n\\quad P(X_1=k/N=n) = \\binom{n}{k}p^k(1-p)^{n-k}\\quad\\text{ou } p=\\frac{1}{m}\\] Donc $X_1/N\\hookrightarrow\\mathcal B(n,p)$ 2.\\[X_1(\\Omega)=\\mathbb N\\\\\\begin{aligned}\\forall k\\in X_1(\\Omega)\\quad P(X_1=k)&amp;amp;=\\sum_{n=0}^{+\\infty}P((X_1=k)\\cap(N=n))\\\\&amp;amp;=\\sum_{n=0}^{+\\infty}P(X_1=k/N=n)P(N=n)\\\\&amp;amp;=\\sum_{n=k}^{+\\infty}P(X_1=k/N=n)P(N=n)\\end{aligned}\\] Rappel: La loi Poisson\\(P(N=n)=e^{-\\lambda}\\frac{\\lambda^n}{n!}\\quad\\forall n\\in\\mathbb N\\) \\[\\begin{aligned}P(X_1=k)&amp;amp;=\\sum_{n=k}^{+\\infty}\\frac{n!}{k!(n-k)!}p^k(1-p)^ke^{-\\lambda}\\frac{\\lambda^n}{n!}\\\\&amp;amp;= \\frac{p^ke^{-\\lambda}}{k!}\\sum_{n=k}^{+\\infty}\\frac{(1-p)^{n-k}\\lambda^n}{(n-k)!}\\end{aligned}\\] Rappel\\[\\sum_{n=0}^{+\\infty}\\frac{x^n}{n!}e^x\\quad\\forall x\\in\\mathbb R\\] \\[P(X_1=k)=\\frac{p^ke^{-\\lambda}\\lambda^k}{k!}\\sum_{n=k}^{+\\infty}\\frac{((1-p)\\lambda)^{n-k}}{(n-k)!}\\] Posons $j=n-k$\\(\\begin{aligned}P(X_1=k)&amp;amp;=\\frac{(\\lambda p)^ke^{-\\lambda}}{k!}\\sum_{j=0}^{+\\infty}\\frac{((1-p)\\lambda)^j}{j!}\\\\&amp;amp;=\\frac{(\\lambda p)^{k}}{k!}e^{-\\lambda}e^{\\lambda(1-p)}\\\\&amp;amp;=\\frac{(\\lambda p)^k}{k!}e^{-\\lambda p}\\end{aligned}\\\\\\forall k\\in\\mathbb N\\quad\\color{green}{P(X_1=k)=\\frac{(\\lambda p)^k}{k!}e^{-\\lambda p}}\\)Exercice 7$a\\in]0,1[$, $b\\in]0,+\\infty[$$X$ et $Y$ 2 v.a. dont la loi conjointe est donnee par:\\[\\begin{cases}P_{ij}=P((X=i)\\cap(Y=j))=\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!} &amp;amp;\\text{si } i\\ge j\\\\P_{ij}=0&amp;amp;\\text{si } i\\lt j\\end{cases}\\\\X(\\Omega)=Y(\\Omega)=\\mathbb N\\] Determiner les lois marginales ainsi que $E(X)$, $V(X)$, $E(Y)$, $V(Y)$ $X$ et $Y$ sont-elles independantes ? Determiner la loi de $Z=X-Y$ $Y$ et $Z$ sont-elles independantes ? Solution 1.\\[\\begin{aligned}\\forall i\\in\\mathbb N\\quad P(X=i)&amp;amp;=\\sum_{j=0}^iP((X=i)\\cap(Y=j))\\\\&amp;amp;=\\sum_{j=0}^i\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=b^ie^{-b}\\sum_{j=0}^i\\frac{a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=\\frac{b^ie^{-\\lambda}}{i!}\\sum_{j=0}^i\\frac{i!}{j!(i-j)!}a^j(1-a)^{i-j}\\\\&amp;amp;=\\frac{b^ie^{-b}}{i!}\\sum_{j=0}^i\\binom{i}{j}a^j(1-a)^{i-j}\\quad\\text{Fomule du binome de Newton}\\\\&amp;amp;=\\frac{b^ie^{-b}}{i!}(a+1-a)^i\\\\\\end{aligned}\\\\\\color{green}{P(X=i)=e^{-b}\\frac{b^i}{i!}}\\quad\\forall i\\in\\mathbb N\\] Donc $X\\hookrightarrow\\mathcal P(b)$ et $E(X)=V(X)=b$ \\[\\begin{aligned}\\forall j\\in\\mathbb N, P(Y=j)&amp;amp;=\\sum_{i=0}^{+\\infty}P((X=i)\\cap(Y=j))\\\\&amp;amp;= \\sum_{i=j}^{+\\infty}\\frac{b^ie^{-b}a^j(1-a)^{i-j}}{j!(i-j)!}\\\\&amp;amp;=\\frac{e^{-b}a^j}{j!}\\sum_{i=j}^{+\\infty}\\frac{b^i(1-a)^{i-j}}{(i-j)!}\\\\&amp;amp;= \\frac{e^{-b}(ab)^j}{j!}\\sum_{i=j}^{+\\infty}\\frac{(b(1-a))^{i-j}}{(i-j)!}\\\\&amp;amp;=e^{-b}\\frac{(ab)^j}{j!}e^{b(1-a)}=\\frac{(ab)^j}{j!}e^{-ab}\\end{aligned}\\\\\\] Donc $Y \\hookrightarrow\\mathcal P(ab)$ et $E(X)=V(X)=ab$ 2.\\[P_{0,1}=P((X=0)\\cap(Y=1))=0\\\\P(X=0)P(Y=1)=e^{-b}e^{-ab}ab\\neq 0\\] Donc $X$ et $Y$ ne sont pas independantes. 3. La loi de $Z=X-Y=g(X,Y)$ $Z(\\Omega)=\\mathbb N$ car $P_{i,j}=0$ si $i\\lt j$\\[\\begin{aligned}\\forall k\\in\\mathbb N\\quad P(Z=k)&amp;amp;=\\sum_{(i,j) \\\\ i-j=k}P((X=i)\\cap(Y=j))\\\\&amp;amp;=\\sum_{i,j \\\\ j=i-k}P((X=i)\\cap(Y=i-k))\\\\&amp;amp;=\\sum_{i=k}^{+\\infty}\\frac{b^ie^{-b}a^{i-k}(1-a)^k}{(i-k)!}\\\\&amp;amp;=\\frac{e^{-b}}{k!}(1-a)^k\\sum_{i=k}^{+\\infty} \\frac{b^ia^{i-k}}{(i-k)!}\\\\&amp;amp;=\\frac{e^{-b}(1-a)^k}{k!}b^k\\sum_{i=k}^{+\\infty}\\frac{(ab)^{i-k}}{(i-h)!}\\\\&amp;amp;= \\frac{e^{-b}(1-a)^k}{k!}b^ke^{ab}\\\\&amp;amp;=\\frac{((1-a)b)^k}{k!}e^{-(1-a)b}\\end{aligned}\\] Donc $Z\\hookrightarrow\\mathcal P((1-a)b)$ 4. Independances entre $Y$ et $Z$\\[\\begin{aligned}P((Y=j)\\cap(Z=k))&amp;amp;=P((Y=j)\\cap(X=k+j))\\\\&amp;amp;=P((Y=j)\\cap(X=k+j))\\\\&amp;amp;=\\frac{b^{j+k}e^{-b}a^j(1-a)^k}{j!k!}\\end{aligned}\\\\\\begin{aligned}P(Y=j)P(Z=k)&amp;amp;=e^{-ab}\\frac{(ab)^j}{j!}e^{-(1-a)b}\\frac{((1-a)b)^k}{k!}\\\\&amp;amp;=\\frac{e^{-b}a^j}{j!k!}b^{j+k}(1-a)^k\\\\&amp;amp;=P((Y=j)\\cap(Z=k))\\end{aligned}\\]" }, { "title": "VTK-ITK: Traitement d&#39;Image avec ITK", "url": "/cours/posts/vtk_first_course/", "categories": "Image S8, VTK", "tags": "Image, VTK, S8", "date": "2021-05-31 10:00:00 +0200", "snippet": "Lien de la note HackmdInsight Toolkit (ITK) Open source Ecrite en C++ Existe depuis 2000 Environ 267 developpeurs Plus de 500k telechargements Investissement de la part du NIH: ~14M Algorithmes de traitement d‚Äôimage seulement Pas de UI ou visualisation www.itk.org A chaque fois qu‚Äôon utilise une bibliotheque open source. il faut le mentionner3 grandes famille de modalites: IRM Rapide et non nocif (a notre connaissance) On voit tres bien la matiere blanche/grise du cerveau Scanner CB scanner, radio (rayons X) Attentions aux rayons X On voit tres biens les os Ultrasons Si on attend un enfant par exemple Non nocifs a notre connaissance MAIS besoin de signer pour une echographie une decharge (au cas ou) Visible humanUn condamne a mort aux US a donne son corps a la science A ete scanner en HD avec les rayons X (apres sa mort) Son corps a ete congele et decoupe en tranche Chaque tranche a ete photographiee Vraie tranche d‚ÄôHumain Projet tres controverseMAIS Tout le monde a acces aux images Tres utile pour la science 500 Go (pour les annees 2000, quantite enorme de donnees)Pourquoi CMAKE a ete cree Utilisation des images ci-dessus par tout le monde Chacun fait son algo dans son coin Gouvernement US a voulu tout centraliser ‚Äúvisible human toolkit‚Äù (aujourd‚Äôhui ITK) ITKBoite a outils d‚Äôalgorithmes de traitement d‚Äôimage Il n‚Äôy a pas d‚Äôoutils de visualisation/interface graphique dans ITKCa reste une boite a outils et c‚Äôest pour que ce soit portableDeveloppeurs initiaux d‚ÄôITKCombinaison industriels/academiqueTraitement d‚ÄôimageSegmentationAujourd‚Äôhui, le traitement d‚Äôimage sert a ameliorer le traitement d‚Äôimage.Pourquoi extraire la taille des ventricules ?La taille des ventricules c‚Äôest important Lie a l‚Äôautisme Evolution de la taille des ventricules: predire l‚Äôautisme rapidement chez l‚Äôenfant Verifier que les ventricules grandissent correctement Plus tot on arrive a diagnostique, plus tot on arrive a traiter Exemple d‚Äôune tumeur: permet de detecter la tumeur + pour le traitement pour l‚ÄôenleverRecalage Le probleme, c‚Äôest que le patient est vivantIntegrer ITK dans une application On ne va pas fair d‚Äôinterface graphique pendant le TPGeneric programming ITK utilise beaucoup les template et est tres tres generique Ca le rend un peu dur a utiliser La STL en C++ Abstraction des types et actionsC++ Utilisation de namespaces Utilisaiton de smart pointers Propre pointeurs de ITK Gestion des exceptionsPython TypesIl faut connaitre le type de pixel sur lequel on travailleStreaming ITK permet de traiter des images qui ne rentrent pas en memoireLe streaming d‚ÄôITK partitionne notre grille et applique nos filtres Si on a besoin de quelque chose (bordure, etc) coupe par un filtre En maillage: les ghost cells Similaire en ITK Exemple: convolution sur chaque partie partitionnee mais bordure coupee entre 2Quelle taille pour une image d‚Äôun scanner ?Entre 10 et 25 Mo (meme decompresse, rentre largement en memoire) Nos donnees nous appartiennent, les hopitaux sont obliges de nous donner nos scanner/IRM etc.Pour le TP On va travailler en TP sur DICOM Pas en 3DGestion de la memoirePipeline de traitementUn filtre prend une image en entree et une autre en sortieOn combine les filtres entre euxEn tant que traiteur d‚Äôimage, soit: On creer un nouveau filtre On utilise ce qui existe deja et on combine les filtresSegmentationComment segmenter cette tumeur ? La tranche est a l‚Äôenvers car le patient est sur le dosConfidence ConnectedOn defini un point (un germe) On agrandit le point Croissance de regionQu‚Äôest-ce qui est problematique sur ce genre d‚Äôalgo ?Le seed point a ete mis a la main Pour un point ca va Mais pour + (genre 15) c‚Äôest plus durConnected Threshold A nous de definir upper bound et lower boundIsolated connectedDemande 2 seeds (un germe a l‚Äôexterieur et un a l‚Äôinterieur) Calcul la moyenneQuelle methode est la meilleure ?Tout depend de notre image, ce que veut le practicien, etc.Watershed concept Algo qui prend en consideration les intensites mais aussi les contours ITK ne gere pas le streaming sur les algos iteratifsShape detectionRecalage Mise en correspondance d‚Äôimages afin de pouvoir agreger leurs informationsExactement le meme cas pour les scanners La machine a gauche vaut ~60M d‚ÄôeurosSi on veut combiner des scanners Rayons X et IRM, il faut faire du recalage Sauf dans le scanner PET-CTRecalage d‚Äôune eclipse de Lune (fait a la main sur PowerPoint par Julien Jommier)Composants du recalage Transformation Si on a 2 images, comment est-ce qu‚Äôon transforme une image qui boufe pour l‚Äôaligner avec une autre image ? Metrique (de mise en correspondances) Quand est-ce qu‚Äôon est alignes ou non Optimiseur Descente de gradient Transformation Translations (deplacements) conserve distances et angles orientes 2 parametres Rotations (isometrie) conserve distances et angles Homotheties (similitude) conserve les rapports entre les distances Affinites conserve le parallelisme 6 parametres Non-lineairesTransformationsAffineQuelle tranformation ?Quelle transformation a ete faite sur cette image ?Homothetie avec juste un parametreTransformations Non-Lineaires Transformations elastiques ou non-rigides Exemples: B-Splines (Combinaison lineaire de Spline) Thin-plate splines Metrique Mesures de similarite(s) entre la cible fixe et la source en mouvement Recalage iconique Somme des differences au carre Coefficient de correlation SSD ProblemeLes 2 images doivent avoir la meme intensite (relation lineaire)Cross-Correlation Convolution sans inverser le signal $\\bar f=$ moyenne de $f$ $\\sigma f=$ ecart type de $f$ Relation affine entre les intensitesInformation mutuelle Issue de la theorie de l‚Äôinformation Relation statistique entre les intensites des 2 images Densite conjointe de probabilite des niveaux de gris Calcul d‚Äôun histogramme conjoint Mesure d‚ÄôentropieHistogramme conjoint: EntropieOu est presente l‚Äôinformation dans notre volume Tres serree: peu d‚Äôentropie Un peu partout: beaucoup d‚ÄôentropieOn a 2 images qui ont bouge, l‚Äôhistogramme commence a etre diffus:Soit $g(x,y)$ la valeur de l‚Äôhistogramme conjoint au point [x,y]:Si on a 2 images alignees (meme patient):Optimiseur Descente de gradient Gradient conjugue Algo genetiques Powell LBFGSInterpolateur QuizPremiere questionOn a 2 images du meme patientDeuxieme question a) 2.0 b) 1.0 c) 0.5 Toujours reflechir dans le domaine physique, le patient a toujours le meme cerveau" }, { "title": "MLRF: Lecture 03", "url": "/cours/posts/mlrf_third_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-28 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 3 Introduction Finish lecture about local feature detectors Local feature descriptors Descriptor matching and indexing Projective transformations Homography estimationA word about Divise clusteringHAC is bottom-up, divisive clustering is performed top-downClassical approach: Start with all data Apply flat clustering Recursively apply the approach on each cluster until some terminationPros: can have more than 2 sub-treesSummary of last lectureGlobal image descriptors Color histogram Limited descriptive power Which distance function ?Clustering K-means Hierarchical Agglomerative ClusteringLocal feature detectors Image gradients Edge detector: Sobel, Canny Corner detector: Harris Large image gradient in 2 directions Corner detector: FAST Corner detectors: LoG, DoG, DoH Blob detector: MSERNest practice sessionsCompute and match descriptors for max. 1 hour (from practice session 2)Play with ORB keypoint mathcing to implement a simple AR technique (practice session 3)IntroductionHow are panorama pcitures created from multiple pictures? Detect small parts invariant under viewpoint change: keypoints Find pairs of mathcing keypoints using a description of their neighborhood Compute the most likely transformation to blend images togetherLocal feature descriptorsHarris &amp;amp; Stephen conclusionHarris-Stephens trick to avoid computing eigenvalues: Nowadays linear algebra is cheap, so compute the real eigenvalues.Thein filter using $\\min(\\lambda_1, \\lambda_2)\\gt\\lambda$, $\\lambda$ being a threshold This is the Shi-Tomasi variantBuild your own edge/corner detectorWe need the eigenvalues $\\lambda_1$ and $\\lambda_2$ of the structure tensor (hessian matrix with block-wise summing)dst = cv2.cornerEigenValsAndVecs(src, neighborhood_size, sobel_aperture)dst = cv2.cornerMinEigenVal(src, neighborhood_size, sobel_aperture)Harris summaryProsTranslation invariant Large gradients in both directions = stable pointsConsNot so fast Avoid to compute all those derivativesNot scale invariant Detect corners at different scalesCorner detectors, binary tests FASTFeatures from accelerated segment test (FAST)Keypoint detector used by ORB Segment testCompare pixel $P$ intensity $I_p$ with surrounding pixels (circle of 16 pixels) If $n$ contiguous pixels are either: all darker than $I_p-t$ all brighter than $I_p+t$ then $P$ is detected as a cornerTricks Cascading If $n=12$ ($\\frac{3}{4}$ of the circle) Machine learning How to perform non-maximal suppressionFAST summaryProsVery fast 20 times faster than Harris 40 times faster than DoGVery robust to transformations (perspective in particular)ConsVery sensitive to blurCorner detectors at different scales LoG, DoG, DoHLaplacian of Gaussian (LoG) The theoretical, slow way Band-pass filterIt detects objects of a certain sizeLaplacian = second derivativeLike sobel with 1 more derivationTaylor, again:New filter $I_{xx} = \\begin{bmatrix}&amp;amp;1 &amp;amp;-2 &amp;amp;1\\end{bmatrix} \\times I$Laplacian filter $\\nabla^2I(x,y)$Edge detector, like Sobel but with second derivativesLaplacian of Gaussian mexican hatLoG = detector of circular shapes Detector of circular shapes:LoG filter extrema locates ‚Äúblobs‚Äù maxima = dark blobs on light background minima = light blobs on dark backgroundDetecting corners/blobsBuild a scale space representation: stack of images (3D) with increasing $\\sigma$Difference of Gaussian (DoG)Fast approximation of LoG (Used by SIFT) LoG can be approximate by a Difference of 2 Gaussians (DoG) at different scales DoG filterIt is a band-pass filter L‚Äôidee est : ‚Äúest-ce que mes bosses sont comprises entre telles ou telles longueurs d‚Äôonde‚ÄùDoG filterIntuition Gaussian (g) is a low pass filterDoG computation in practiceTake an imageBlur itTake the differenceDoG scale generation trick DoG computation use ‚Äúoctaves‚Äù ‚ÄúOctave‚Äù because frequency doubles/halves between octaves If $\\sigma=\\sqrt{2}$, then $3$ levels per octave Downsample images for next octave (like double sized kernel) Compute the DoG between imagesDoG: Corner selection Throw out weak responses and edgesEstimate gradients Similar to harris, look at nearby responses Not whole image, only a few points! faster Throw out weak responsesFind cornery things Same deal, structure matrix, use dete and trace info (SIFT variant)Determination of Hessian (DoH) Faster approximationLoG vs DoG vs DoH On prefere un ‚ÄúLaplacian of Gaussian‚Äù pour detecter les petites etoilesLoG, DoG DoH summaryProsVery robust to transformations Perspective BlurAdjustable size detectorConsSlowBlob detectors MSERMaximally Stable Extremal Regions (MSER) Detects regions which are stable over thresholds Create min &amp;amp; max-tree of the image Tree of included components when thresholdinf the image ar each possible level Le cerveau a une tumeur Select most stable regions between $t-\\triangle$ and $t+\\triangle$ $R_{t*}$ is maximally stable iif $q(t)=\\vert R_{t-\\triangle}\\text{\\ } R_{t+\\triangle}\\vert/\\vert R_t\\vert$ as local minimum at $t^{*}$ SummaryProsVery robust to transformations Affine transformations Intensity changesQuite fastConsDoes not support blurLocal fetaure detectors: Conclusion Harris Stephens: can be very stable when combined with DoG Shi-Tomasi: Assumes affine transformation (avoid it with perspective) DoG: slow but very robust (perspective, blur, illumination) DoH: faster than DoG, misses small elements, better with perspective FAST: very fast, robust to perspective change (like DoG), but blur quickly kills it MSER: fast, very stable, good choice when no blurIntroduction Given som keypoints in image 1, what are the more similar ones in image 2 ? This is a nearest neighbor problem in descriptor space This is also a geometrical problem in coordinate spaceMatchingMatching problem Goal: given 2 sets of descriptors, find the best matching pairsNeed a distanceorm: depends on the descriptor Distribution (histogram)? Stats? Data type ? Float, integers: Euclidean, cosine Binary: Hamming 1-way matching For each $x_i$ in the set of descriptors $D_1$, find the closest element $y_i$ in $D_2$ We have a match $m(x_i, y_i)$ for each $x_i$Symmetry test aka cross check aka 2-way matching For each $x_i$ in the set of descriptor $D_1$, find the closest element $y_i$ in $D_2$ such as $x_i$ is also the closest element to $y_i$Ratio test For each $x_i$ in $D_1$, find the 2 closest elements $y_i$ and $y_j$ in $D_2$Calibrate the ratio Adjust it on a training set !For each correct/incorrect match in your annotated database, plot the next to next closest distance PDF.What is a good ratio in D. Lowe‚Äôs experiment ?Geometric validationSummaryIndexingIndexing pipelineUse case: We have a database of images and we want to find an object from itBruteforce matching aka linear matching Simply scan all data and keep the closest elementsDoes not scale to large databases, but can be faster on small oneskD-Trees binary tree in which every leaf node is a k-dimensional pointFLANN - Efficient indexing Original version: hierarchical k-means Construction: repetitive k-means on data (then inside clusters) until minimum cluster size is reached Lookup: traverse the tree in a best-bin-first manner with backtrack queue, backtrack until enough point are returnedLocally Sensitive Hasing (LSH) Hash items using family of hash function which project similar items in the same bucket with high probability Not cryptographic hashing !En fonction de quel cote notre separatrice se trouve par rapport au point, on met notre bit a 1 ou 0 Approximation de la distance $\\cos$ en binaireLocality Sensitive Hashing (LSH) Fast and efficient with large spaces and lot of data Return a ‚Äúgood match‚Äù, maybe not the best one kNN can be costlyWhich indexing ? ExperimentAdvices for practice session:Projective transformationsA linear transformation of pixel coordinatesImage Mappings OverviewMath. foundations &amp;amp; assumptions For planar surfaces, 3D to 2D perspectives projection reduces to a 2D to a 2D transformation This is just a change of coordinate system This transformation is invertibleTranslationScaleRotationNotation: Partitioned matricesAffineProjectiveMore on projective transform Each point in 2D is actually a vector in 3D Equivalent up to scaling factor Have to normalize to get back to 2D Using homogrpahy to project point Multiply $\\tilde x$ by $\\tilde H$SummaryHomography estimation, Geometric validationWe want to recover H from keypoint matchesRecover the parameters of a perspective transformHow many correspondences are needed ?Depends on the type of transform: How many for translation ? For rotation ? ‚Ä¶ For general projective transform ? Reminded: we have 2 knowns for each matchLinear systemUse Linear Least Square to solve $Ma=b$Solve the systemHow reliable is the estimate ?Even worseIs our data perfect ?On a pas mal de bruitOvercoming Least Square Limitations We need a robust estimationRANSAC: RANdom SAmple ConsensusAlgorithmRANSAC works well with extreme noises" }, { "title": "ASE3: TD 1 - 2", "url": "/cours/posts/ase3_td_1_2/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-26 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 3On considere $n$ boites numerotees de $1$ a $n$.La boite $n^{o}k$ contient $k$ boules numerotees de $1$ a $k$. On choisi au hasard une boite puis une boule dans cette boite.Soit: $X$ v.a.: numero de la boite $Y$ v.a.: numero de la boule Determiner la loi conjointe de $(X,Y)$ Calculer $P(X=Y)$ Determiner la loi de $Y$ et $E(Y)$ Solution 1. Loi conjointe\\[X(\\Omega) = [[1,n]]\\\\Y(\\Omega) = [[1,n]]\\]\\[\\begin{aligned}\\begin{matrix}\\forall i\\in X(\\Omega)\\\\\\forall j\\in Y(\\Omega)\\end{matrix}\\Biggr\\}P((X=i)\\cap(Y=j))&amp;amp;=P_{(X=i)}(Y=j)P(X=i)\\quad\\text{Loi conditionnelle}\\\\&amp;amp;=\\frac{1}{i}\\times\\frac{1}{n}\\quad\\text{si } j\\le i\\end{aligned}\\\\\\begin{cases}P((X=i)\\cap(Y=j))=\\frac{1}{in} &amp;amp;\\text{si }j\\le i\\\\P((X=i)\\cap(Y=j))=0 &amp;amp;\\text{si } j\\gt i\\end{cases}\\] 2.\\[\\underbrace{(X=Y)}_{\\text{evenement}} = \\cup_{i=1}^n\\biggr((X=i)\\cap(Y=i)\\biggr)\\\\\\begin{aligned}P(X=Y)&amp;amp;=\\sum_{i=1}^nP((X=i)\\cap(Y=i))\\\\&amp;amp;=\\sum_{i=1}^n\\frac{1}{in}=\\color{green}{\\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}}\\end{aligned}\\] 3. Loi marginale de $Y$\\[\\begin{aligned}\\forall j\\in[[1,n]]\\quad P(Y=j)&amp;amp;=\\sum_{i=1}^nP((X=i)\\cap(Y=j))\\\\&amp;amp;= \\sum_{i=j}^n\\frac{1}{in}=\\color{red}{\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}}\\end{aligned}\\]\\[\\begin{aligned}E(Y)&amp;amp;=\\sum_{j=1}^njP(Y=j)\\\\&amp;amp;= \\sum_{j=1}\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\\\&amp;amp;= \\frac{1}{n}\\sum_{j=1}^nj\\sum_{i=j}^n\\frac{1}{i}\\end{aligned}\\] \\(P(Y=j)=\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\quad\\forall j\\in\\mathbb N^*=Y(\\Omega)\\\\\\) \\[\\begin{aligned}E(Y)&amp;amp;=\\sum_{j=1}^njP(Y=j)\\\\&amp;amp;= \\sum_{j=1}^nj\\frac{1}{n}\\sum_{i=j}^n\\frac{1}{i}\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}\\sum_{j=1}^ij\\quad\\text{inversion des sommes et } i\\ge j\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\frac{1}{i}\\frac{i(i+1)}{2}\\\\&amp;amp;=\\frac{1}{2n}\\sum_{i=1}^n(i+1)\\\\&amp;amp;=\\frac{1}{2n}\\biggr(\\frac{n(n+1)}{2}+n\\biggr)\\end{aligned}\\] \\(E(Y) = \\frac{1}{4}(n+3)=\\frac{n+3}{4}\\) Exercice 4Une urne contient une boule blanche et une boule noire, les boules etant indiscernables au toucher. On y preleve une boule, chaque boule ayant la meme probabilite d‚Äôetre tiree. On note sa couleur et on la remet dans l‚Äôurne avec $c$ boules de la meme couleur.On repete cette experience, on realise une succession de $n$ tirages ($n\\ge 2$).Soit $X_i$ la v.a.\\[1\\le i\\le n\\begin{cases} X_i = 1&amp;amp;\\text{si on obtient une boule blanche au }i\\text{-eme tirage}\\\\ X_i=0&amp;amp;\\text{sinon}\\end{cases}\\\\Z_p=\\sum_{i=1}^pX_i\\quad 2\\le p\\le n\\] Determiner la loi du couple $(X_1,X_2)$. En deduire la loi de $X_2$ Determiner la loi de $Z_2$ Determiner $Z_p(\\Omega)$ Soit $p\\le n-1$. Determiner \\(P_{(Z_p=k)}(X_{p+1}=1)\\) $\\forall k\\in Z_p(\\Omega)$ et montrer que $P(X_{p+1}=1)=\\frac{1+cE(Z_p)}{2+pc}$ Montrer que $\\forall p\\in[[1,n]]$, $P(X_p=1)=\\frac{1}{2}=P(X_p=0)$ Solution 1. $X_1$ suit la loi de Bernouilli $\\mathcal B(\\frac{1}{2})$. On cherche $P((X_1=i)\\cap(X_2=j))$.\\[X_1(\\Omega)=[[0,1]]\\\\X_2(\\Omega)=[[0,1]]\\\\\\] $1^{er}$ cas: $i\\neq j$\\[\\begin{aligned}P((X_1=i)\\cap(X_2=j))&amp;amp;=P(X_2=j/X_1=i)P(X_1=i)\\quad P(X_1=i)=\\frac{1}{2}\\\\&amp;amp;=\\frac{1}{2+c}\\times\\frac{1}{2}\\end{aligned}\\] $2^e$ cas: $i=j$\\[\\begin{aligned}P((X_1=i)\\cap(X_2=j))&amp;amp;=P(X_2=j/X_1=i)P(X_1=i)\\\\&amp;amp;= \\biggr(\\frac{1+c}{2+c}\\biggr)\\times\\frac{1}{2}\\end{aligned}\\] $X_2$ \\ $X_1$ $0$ $1$ Loi de $X_1$ $0$ $\\frac{1+c}{2(2+c)}$ $\\frac{1}{2(2+c)}$ $\\frac{1}{2}$ $1$ $\\frac{1}{2(2+c)}$ $\\frac{1+c}{2(2+c)}$ $\\frac{1}{2}$ Loi de $X_2$ $\\frac{1}{2}$ $\\frac{1}{2}$ $1$ Donc $X_2\\to\\mathcal B(\\frac{1}{2})$ 2.\\[Z_2=X_1+X_2\\\\Z_2(\\Omega)=[[0,2]]\\\\\\]\\[\\begin{aligned}P(Z_2=0)&amp;amp;=P((X_1=0)\\cap(X_2=0))\\\\&amp;amp;=\\color{green}{\\frac{1+c}{2(2+c)}}\\\\P(Z_2=1)&amp;amp;=P((X_1=0)\\cap(X_2=1)) + P((X_1=1)\\cap(X_2=0))\\\\&amp;amp;= \\color{green}{\\frac{1}{2+c}}\\\\P(Z_2=2)&amp;amp;=P((X_1=1)\\cap(X_2=1))\\\\&amp;amp;=\\color{green}{\\frac{1+c}{2(2+c)}}\\end{aligned}\\] 3.1.\\[Z_p=\\sum_{i=1}X_i\\\\Z_p(\\Omega)=[[0,p]]\\] 3.2.\\[p\\le n-1\\quad P_{(Z_p=k)}(X_{p+1}=1)= \\quad \\forall k\\in\\mathbb Z_p(\\Omega)\\] Sachant que $(Z_p=k)$ est realise: $k$ boules blanches ont ete tirees au cours des $p$ premiers tirages (donc on a remis $kc$ boules blanches dans l‚Äôurne) et $p-k$ boules noires ont ete tirees (donc on a remis $(p-k)c$ boules noires).Donc au total l‚Äôurne contient $2+kc+(p-k)c=2+pc$ boules dont $(1+kc)$ boules blanches. \\[P_{(Z_p=k)}(X_{p+1}=1)=\\frac{1+kc}{2+pc}\\] \\[\\begin{aligned}(X_{p+1}=1)&amp;amp;=U_{k=0}^p((X_{p+1}=1)\\cap(Z_p=k))\\\\P(X_{p+1}=1)&amp;amp;=\\sum_{k=0}^pP((X_{p+1}=1)\\cap(Z_p=k))\\\\&amp;amp;=\\sum_{k=0}^pP_{(Z_p=k)}(X_{p+1}=1)P(Z_p=k)\\\\&amp;amp;= \\sum_{k=0}^p\\biggr(\\frac{1+kc}{2+pc}\\biggr)P(Z_p=k)\\\\&amp;amp;= \\frac{1}{2+pc}\\biggr(\\sum_{k=0}^pP(Z_p=k)+c\\sum_{k=0}^pkP(Z_p=k)\\biggr)\\\\&amp;amp;=\\color{green}{\\frac{1}{2+pc}(1+cE(Z_p))}\\end{aligned}\\] 4.\\[\\forall p\\in [[1,n]]\\quad P(X_p=1)=\\frac{1}{2}=P(X_p=c)\\] Matrices resultat par recurrence sur slurp sur $p$: Soit $R(p)$ la propriete: $P(X_p=1)=\\frac{1}{2}$, $R(1)$, $R(2)$ vraies ($1^{ere}$ question) Hypothese: Supposons que $R(1)$, $R(2)$,‚Ä¶, $R(p)$ vraies.\\[\\begin{aligned}P(X_{p+1}) = \\frac{1+cE(Z_p)}{2+pc}\\quad\\text{or } E(Z_p)&amp;amp;=E(\\sum_{i=1}^pX_i) \\\\&amp;amp;= \\sum_{i=1}^pE(X_i)\\\\&amp;amp;=\\sum_{i=1}^p\\frac{1}{2}\\quad\\text{car } X_i\\to\\mathcal B(\\frac{1}{2})\\quad 1\\le i\\le p \\text{ (hypothese)}\\\\&amp;amp;=\\color{red}{p\\times\\frac{1}{2}=\\frac{p}{2}}\\\\\\end{aligned}\\\\\\begin{aligned}P(X_{p+1})&amp;amp;=\\frac{1+cE(Z_p)}{2+pc}\\\\&amp;amp;=\\frac{1+c\\frac{p}{2}}{2+pc}\\\\\\end{aligned}\\] \\[P(X_{p+1}=1)=\\frac{1}{2}\\] Exercice 5$X$ et $Y$ 2 v.a. independantes suivant la meme loi de Bernoulli $\\mathcal B(p)$ ($p\\in]0,1[$).On pose $U=X+Y$, $V=X-Y$. Quelle est la loi conjointe de $(U,V)$ ? Calculer $Cov(U,V)$ U,V sont-elles independantes ? Solution 1. $U(\\Omega)=[[0,2]]$, $V(\\Omega)=[[-1,1]]$\\[P((U=i)\\cap(V=j))\\quad\\begin{cases}&amp;amp;\\forall i\\in[[0,2]]\\\\&amp;amp;\\forall j\\in[[-1,1]]\\end{cases}\\\\\\begin{cases}U=X+Y\\Rightarrow X=\\frac{U+V}{2}\\\\V=X-Y\\Rightarrow Y=\\frac{U-V}{2}\\end{cases}\\\\\\begin{aligned}P((U=i)\\cap(V=j))&amp;amp;=P\\biggr(\\biggr(X=\\frac{i+j}{2}\\biggr)\\cap\\biggr(Y=\\frac{i-j}{2}\\biggr)\\biggr)\\\\&amp;amp;= P\\biggr(X=\\frac{i+j}{2}\\biggr)P\\biggr(Y=\\frac{i-j}{2}\\biggr)\\color{red}{\\text{ car } X\\text{ et }Y\\text{ sont independantes}}\\end{aligned}\\] $U$ / $V$ $-1$ $0$ $1$ Loi de $U$ $0$ $0$ $q^2$ $0$ $q^2$ $1$ $qp$ $0$ $pq$ $2pq$ $2$ $0$ $p^2$ $0$ $p^2$ Loi de $V$ $qp$ $p^2+q^2$ $pq$ $1$ Exemple:\\[\\begin{cases}U\\Rightarrow1=i\\\\V\\Rightarrow-1=j\\end{cases}\\Rightarrow\\begin{cases}\\frac{i+j}{2}=\\frac{1-1}{2}=0\\\\\\frac{i-j}{2}=\\frac{1+1}{2}=1\\\\\\end{cases}\\Rightarrow\\begin{cases}P(X=0)=q\\\\P(Y=1)=p\\end{cases}\\biggr\\}qp\\] 2. RappelLa covariance est une forme bilineaire symetrique definie positive (produit scalaire sur l‚Äôespace des v.a.) \\[\\begin{aligned}Cov(U,V)&amp;amp;=Cov(X+Y,X-Y)\\quad\\color{red}{\\text{bilineaire}}\\\\&amp;amp;=Cov(X,X)-\\underbrace{Cov(X,Y) + Cov(Y,X)}_{0 = \\text{ par symetrie}} - Cov(Y,Y)\\\\&amp;amp;= Cov(X,X)-Cov(Y,Y)\\quad\\end{aligned}\\\\\\begin{aligned}\\text{or: } Cov(X,Y)&amp;amp;=E(X.Y)-E(X)E(Y)\\\\\\Rightarrow Cov(X,X)&amp;amp;=E(X.X)-(E(X))^2\\\\&amp;amp;=V(X)\\end{aligned}\\\\\\begin{aligned}Cov(U,V)&amp;amp;=V(X)-V(Y)\\\\&amp;amp;=0\\quad\\color{red}{\\text{car meme loi}}\\end{aligned}\\] Independantes $\\Rightarrow$ $Cov(X,Y)=0$ $Cov(X,Y)\\Rightarrow$ independantes 3. Independance ?\\[P((U=0)\\cap(V=-1))=0\\neq P(U=0)P(V=-1)=q^3p\\] Donc $U$ et $V$ ne sont pas independantes. " }, { "title": "RSE: Deuxieme cours", "url": "/cours/posts/rse_2/", "categories": "tronc commun S8, RSE", "tags": "tronc commun, S8, RSE", "date": "2021-05-25 14:00:00 +0200", "snippet": "Lien de la note HackmdEvaluation - A rendre et a presenter Le 15/06 avant 14h sur MoodleAnalyse de la politique RSE de votre entreprise Consignes: groupes de MAX 4 personnes (1 une entreprise). Citez votre ou vos sources. Format PDF. 10 min de prez Quels sont les principaux enjeux RSE de l‚Äôentreprise Reprenez les 7 questions centrales de la RSE Identifiez au moins 2 actions par question centrale dans votre entreprise Identifiez les indicateurs de mesure retenus pour ces actions ? A quel(s) Objectif(s) de Developpement Durable (ODD) ces actions contribuent-elles ? Selon vous, en tant que partie prenante de cette entreprise, quel est le principal dilemme de responsabilite societale auquel elle a a faire faceRSEDefinition de la RSE (ISO 26000)La responsabilite d‚Äôune organisation vis-a-vis des impacts de ses decisions et activites sur la societe et l‚Äôenvironnement se traduisant par un comportement tranparent et ethique qui contribue au developpement durable, y compris a la sante et au bien-etre de la societe prend en compte les attentes des parties prenantes respecte les lois en vigueur et est en accord avec les normes internationales de comportement et qui est integre dans l‚Äôensemble de l‚Äôorganisation et mis en oeuvre dans ses relationsDe quelles reponsabilites parle-t-on ?RSE: De quoi parle-t-on ? ‚ÄúContribution volontaire et obligatoire‚Äù des organisation aux enjeux du developpement durable Contribution: car l‚Äôentreprise ne peut pas a elle seule regler les maxu de notre societe et que le ‚ÄúDeveloppement Durable‚Äù depend avant tout des Etats Volontaire: parce que la premiere responsabilite d‚Äôune entreprise est economique et que l‚Äôaction RSE ne se decrete pas, qu‚Äôelle doit respecter les valeurs de l‚Äôentreprise, ses ressources et etre pertinente au regard de sa strategie Obligatoire: le droit a operer sur un territoire, l‚Äôacces aux marches et a la commande publique, le reporting extra-financierVideo YouTube C‚Äôest quoi la RSE ?Progression des enjeux cle de l‚ÄôentrepriseBut: remplir les casesUn levier de performanceRenforcement du capital financierExemples Depot d‚Äôun brevet Capital intellectuel Diminution du poids des emballages et suremballages Capital nature Amelioratoin de l‚Äôisolation des locaux Capital physique Rappel immediat d‚Äôun produit defectueux Capital image Nomination d‚Äôun manager manquant de leadership Capital humain Paiement aux fournisseurs d‚Äôun prix inferieur au conditions generales Capital relationnel Le cadre reglementaire en FranceLa loi NRE et la loi Grenelle 22001: loi NRE (Nouvelles Regulations Economiques), article 116 imposait aux societes cotees: la publication, au sein de leur rapport de gestion annuel, des informations sur les consequences sociales et environnementales de leurs activitesArticle 225 de la loi Grenelle 2 de Juillet 2010La transposition de la directive europeenne sur le reporting extra-financierLes entreprise concernees sont: les societes cotees: celles des plus de 500 salaries avec un total de bilan depassant 20M d‚ÄôeurosLa declaration doit fournir des informations concernant:La loi sur le devoir de vigilance La loi relative au ‚Äúdevoir de vigilance des societes meres et des entreprises donneurses d‚Äôordre‚Äù, promulguee le 27 mars 2017, permet desormais de responsabiliser les grandes societes meres et entreprises donneuses d‚Äôordre dans l‚Äôensemble de leurs filiales et le long de leur chaine de production 150 a 200 entreprises seraient concernees. Il s‚Äôagit de societes, ayant plus de 5 000 salaries et dont le siege est situe en France, ou bien 10 000 salaries et un siege a l‚Äôetranger Les ‚Äúplans vigilance‚Äù sont attendus en 2018 et le bilan de leur mise en oeuvre en 2019La loi Pacte Introduire la notion de raison d‚Äôetre et d‚Äôentreprise a la mission Augmenter le nombre d‚Äôadministrateurs salaries dans les conseils d‚Äôadministration (y compris dans les mutuelles, unions et federations)ISO 26000: Lignes directrices de la RSEParties prenantesRelever les interets partagesRSE: le cadre de referenceLe cadre de referenceCadre normatif et regelementairePrincipes et thematiques centrales de la RSEQuestion centrale 1: Gouvernance de l‚Äôorganisation La gouvernance de l‚Äôorganisation est le systeme par lequel une organisation prend des decisions et les applique en vue d‚Äôatteindre ses objectifsDomaines d‚Äôaction Principes, vision et valeurs Approche strategique et objectifs Planification de l‚Äôintegration et du deploiement de la responsabilite societale Deploiement de la responsabilite societale Surveillance des performances Amelioration de l‚Äôorganisation Application du principe de redevabilite Relation avec les parties prenantes Respect des loisQuestion centrale 2: Droits de l‚ÄôHomme Les droits de l‚ÄôHomme sont les droits fondamentauxDomaines d‚Äôaction DA1: devoir de vigilance DA2: Situations presentant un risque pour les droits de l‚ÄôHomme DA3: Prevention de la complicite DA4: Remedier aux atteintes aux droits de l‚ÄôHomme DA5: Discrimination et groupes vulnerable DA6: Droits civils et politiques DA7: Droits economiques, sociaux et culturels DA8: Principes fondamentaux et droits au travailQuestion centrale 4: EnvironnementDomaines d‚Äôactions DA1: La prevention de la pollution DA2: L‚Äôutilisation durable des ressources DA3: Attenutation des changements climatiques DA4: Protection de l‚Äôenvironnement et rehabilitation des habitats naturelsQuestion centrale 5: Loyaute des pratiquesDomaines d‚Äôactions DA1: Lutte contre la corruption DA2: Engagement politique responsable DA3: Concurrence loyale DA4: Promotion de la responsabilite societale dans la chaine de valeur DA5: Respect des droits de la proprieteQuestion centrale 6: Questions relatives aux consommateursDomaines d‚Äôactions DA1: Pratiques loyales en matiere de commercialisation, d‚Äôinformations et de contrats DA2: Protection de la sante et de la securite des consommateurs DA3: Consommation durable DA4: Servie apres-vente, assistance et resolution des reclamations et litiges pour les consommateurs DA5: Protection des donnees et de la vie privee des consommateurs DA6: Acces aux services essentiels DA7: Education et sensibilisationQuestion centrale 7: Communautes et developpement localDomaines d‚Äôactions DA1: Implication aupres des communautes DA2: Education et culture DA3: Creation d‚Äôemplois et developpement des competences DA4: Developpement des technologies et acces a la technologie DA5: Creation de richesses et de revenus" }, { "title": "MLRF: Lecture 02", "url": "/cours/posts/mlrf_second_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-21 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda for lecture 2 Introduction Global image descriptors Clustering Local feature detectorsIntroductionSummary of last lectureMachine learning Machine learning = searching for the best model in a hypothesis space Inductive machine learning, optimization-based Inductive bias, bias/vairance compromise Supervised, reinforcement, unsupervised learning Regression, classification, density estimation Model validation: test generalisation, separate/decorrelate test &amp;amp; training setsTemplate matching Sum of squared differences $(T-I)^2$, or correlation-based methodes ($T\\times I$) Normalization needed for correlation-based methods Tolerates translation and small noise, but not rotation, intensity shift, ‚Ä¶Debrief of practice session 1PS1 content Jupyter tricks NumPy reminders Intro to image manipulations Twin it! part 1: template matching (Bonus level: segmentation)Take home messages How annoying was it to manually adjust color thresholds to select the duck ?How could have we automated it ?Results with method SQDIFF_NORMED (lower is better) Strengths and weaknesses of template matching for the Twin It! case ?Effects of normalization ?Next practice sessionTwin it! again, with a slightly more elaborated approach Pre-selected bubbles based on their colors $\\Rightarrow$ color histogramsColor histogram: in details1.1 Color quantization: reduce the colors of the bubbles1.2. Compute the color histogram of each bubble1.3. Compute the distance matrix between each bubble, using its color histogram1.4 Visualize the bubbles in an interesting way using hierarchical clustering2.For the pre-selected bubbles, check their content is similar $\\Rightarrow$ Detect stable points and extract the patches around them Compare (match) those patches Image descriptorsIssues with method based on pixel comparisonWhat is important ? What do they consider? Raw pixels! We want to be able to make use of domain knowledge Like sensitivity to shape, or dominant color information OverviewDifferent sizes and contents Different kinds of descriptorsDifferent problems $\\Rightarrow$ Different choices Computation/memory constraints Which perturbations do we have to tolerate ?Global image descriptorsTwo approachesGlobal image descriptors Compute statistics about the content of the image Produce a single global vector Very attractive because they are very fast to compute and match, but‚Ä¶Bag of Features techniques (lecture 4) Select regions of interest in the image (may be a variable quantity) Compute descriptors for each region Index each part separately (like a text seach engine which indexes words) It is always possible to build a sing descriptors from multiple onesColor histogramsHigh invariance to many transformation rotation, scaling thanks to normalization, perspectiveBut limited discriminative powerEasy to implement Reduce the colors (opt. when performing backprojection) Compute a reduced color histogram on each image Use a distribution distance to compare the descriptorsSome results on Twin It!Steps by step1: Color reduction use K-Means or any other clustering technique to find N useful colors Project each pixels One possible result on the Twin It! poster2: Histogram computationYou already know it (Normalize it)3: Descriptor comparisonOther global image descriptorMore global descriptorsGIST of a scene: Oliva, Torralba, ‚ÄúModeling the shape of the scene‚ÄùGlobal descriptorsDrawbackAccordin to F. Perronnin:Highly efficient to compute and to match $\\Rightarrow$ perfect in theory But robusteness vs informativeness tradeoff is hard to set(personal conclusion) Approache based on global image descriptors are confined to near-duplicate detection applications until now Modern search engine uses local representations and leverage themClusteringFinding groups in dataMany techniques: Connectivity models hierarchical clustering,‚Ä¶ clustering = set of neighbors Centroid models: k-means cluster = centroid point Distribution model Gaussian mixtures models est. w. Expection maxim cluster = statistical distribution Density models Graph-based modelsAlways the same goal: Minimise the differences between elements within the same cluster Maximise the differences between elements within different clusterNumber of clusters: Many methods require to choose it beforehand Several techniques to adjust the number of clusters automaticallyOutliers rejection: Some techniques do not assign lonely points to any cluster Focus on HAC and K-Means todayHierarchical Agglomerative ClusteringSome linkage types Single linkage minimizes the distance between the closest observations Maximum or complete linkage Average linkage Centroid linkage Waard criterionDivisive clusteringHAC is bottom-up, divisive clustering is top-downClassical approach: Start with all data Apply flat clustering Recursively apply the approach on each cluster until some terminationPros: can have more than 2 sub-trees, must faster than HACCons: same issues as flat clustering, non-determinismK-meansK-Mean clustering (again) The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion it does not maximizes inter-cluster disantce it puts centers so as to get the best coverage (may not be on a density peak !)AlgorithmInitialization: Randomly selected cluster centers Calculate distance oiunts $\\Leftrightarrow$ centers Assign each point to closest center Update cluster centers: avg of pointsResult: centroid centers local maximax tessellation / Voronoi set over the datasetThe previous algorithm is called ‚ÄúBatch K-Means‚Äù or simply ‚ÄúK-Means‚Äù because it considers the whole dataset at each iteration.Batcj K-Means is not only sensible to outliers and initialization, it is also very slow to compute on large datasets..It is possible to avoid this speed/memory issue by randomly smapling the dataset at each step. Results are only slightly worse Speed and memory requirements make it usable on bigger datasets This approach is call ‚ÄúOnline K-Means‚Äù or ‚ÄúMiniBatch K-Means‚ÄùApplication: Color quantizationMany clustering techniques to play with !Evaluation of clusteringNeed some supervision ?By construction, clustering algorithms are optimal as they are expect to find some optimal balance between high intra-cluster similarity and low inter-cluster similarity, on their training set.How do these internal criteria translate into good effectiveness for applications ?A common approach is to rely on labeled data to compute new indicators: Purity: sort of ‚Äúagreement‚Äù inside each cluster Normalized Mutual Information (NMI) and Entropu: information measures Rand Index (RI) and F measure: error countsModern density estimation point of viewBut what about if we leave some samples out for testing the generalization ?HAC or K-Means ‚Äúoverfit‚Äù the underlying data distribution.It does not alway make sense, but if we are interested in density estimation, then we can assess how well our model estimates the probability $P(x)$ of unseen data. The ‚ÄúE‚Äù step of the EM algo is based on this idea.Local feature detectorsIntroduction How are panorama pictures created from multiple pictures ? Detect small parts invariant under viewpoint change: ‚ÄúKeypoints‚Äù Find pairs of amthcing keypoints using a description of their neighborhood Compute the most likely transformation to blend images togetherSome classical detectorsEdge (gradient detectors) Soble CannyEdge detectorsWhat‚Äôs an edge ? Image is a function Edges are rapid changes in thi function The derivative of a function exhibits the edges Gris = elevation comme dans le watershedImage derivativesRecall: We don‚Äôt have an ‚Äúactual‚Äù function, must estimate Possibility: set $h=1$ Apply filter -1 0 +1 to the image ($x$ gradient) We get terribly spiky resultsWe need to interpolate/smooth Gaussian filterWe get a sobel filterSobel filterGradient magnitude with SobelCanny edge detection Extract real lines !Non-maximum suppressionFinalizationCorner detectorsGood featuresGood features are unique! Can find the ‚Äúsame‚Äù feature easily Not mistaken for ‚Äúdifferent‚Äù featuresGood features are robust under perturbation Can detect them under translation, rotation Intensity shift NoiseHow can we find unique patches ?Sky? Bad! Very little variationEdge? OKCorners? Good!Self-differenceHarris corner detector Naive computation: Bon a partir de maintenant c‚Äôest que des screens parce que le prof traceThis allows us to ‚Äúsimplify‚Äù the original equationand more important making it faster to compute, thanks to simpler derivatives which can be computed for the whole image.If we developp the equation and write it as usual matrix form, we get:where $A(x,y)$ is the structure tensor:This trick is useful because $I_x$ and $I_y$ can be computed very simply. The need for eigenvaluesIf the edge is rotated, so are the values of $I_x$ and $I_y$.Eigenvalues give us the ellipsis axis lens.Summary" }, { "title": "ASE3: TD 1", "url": "/cours/posts/ase3_td_1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-19 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Soit $X$ et $Y$ deux v.a. telles que $Y=X^2$.La loi de $X$ est donnee par $X_i$ $-2$ $-1$ $0$ $1$ $2$ $P(X=X_i)$ $\\frac{1}{6}$ $\\frac{1}{4}$ $\\frac{1}{6}$ $\\frac{1}{4}$ $\\frac{1}{6}$ Determiner la loi du couple $(X,Y)$ (Loi conjointe) Determiner la loi de $Y$ $X$ et $Y$ sont-elles independantes ? Calculer $Cov(X,Y)$ Solution $Y=X^2$, $Y(\\Omega)={0,1,4}$ 1. $X/Y$ $0$ $1$ $4$ Loi de $X$ $-2$ $0$ $0$ $\\frac{1}{6}$ $\\frac{1}{6}$ $-1$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{6}$ $0$ $0$ $\\frac{1}{6}$ $1$ $0$ $\\frac{1}{4}$ $0$ $\\frac{1}{4}$ $2$ $0$ $0$ $\\frac{1}{6}$ $\\frac{1}{6}$ Loi de $Y$ $\\frac{1}{6}$ $\\frac{1}{2}$ $\\frac{1}{3}$ $1$ $P((X=i)\\cap(Y=j)) = 0$ si $j\\neq i^2$ Avec $j=i^2$, $P((X=i)\\cap(Y=i^2))=P(X=i)$ car \\(\\underbrace{(X=i)}_{A}\\subset\\underbrace{(Y=i^2)}_{B}\\) $A\\cap B=A$ 2. Loi de $Y$ (Loi marginale) D‚Äôapres le tableau $P(Y=0)=\\frac{1}{6}$, $P(Y=1)=\\frac{1}{2}$ et $P(Y=4)=\\frac{1}{3}$ 3. Independance?\\[P((X=i)\\cap(Y=j))=P(X=i)P(Y=j)\\quad\\forall (i,j)\\]\\[P((X=-2)\\cap(Y=4))=\\frac{1}{6}\\\\P(X=-2)P(Y=4)=\\frac{1}{6}\\times\\frac{1}{3}=\\frac{1}{18}\\neq\\frac{1}{6}\\] $X$ et $Y$ ne sont pas indendantes 4.\\[Cov(X,Y)=E(XY)-E(X)E(Y)\\\\E(XY)=\\sum_{i,j}ijP((X=i)\\cap(Y=j))\\\\\\color{red}{E(XY)=\\sum_{i,j}ijP_{i,j}}\\] $X/Y$ $0$ $1$ $4$ Loi de $X$ $-2$ $0$ ($\\times 0$) $0$ ($\\times -2$) $\\frac{1}{6}$ ($\\times -8$) $\\frac{1}{4}$ $-1$ $0$ ($\\times 0$) $\\frac{1}{4}$ ($\\times -1$) $0$ ($\\times 0$) $\\frac{1}{6}$ $0$ $\\frac{1}{6}$ ($\\times 0$) $0$ ($\\times 0$) $0$ ($\\times 0$) $\\frac{1}{6}$ $1$ $0$ ($\\times 0$) $\\frac{1}{4}$ ($\\times 1$) $0$ ($\\times 4$) $\\frac{1}{4}$ $2$ $0$ ($\\times 0$) $0$ ($\\times 2$) $\\frac{1}{6}$ ($\\times 8$) $\\frac{1}{6}$ Loi de $Y$ $\\frac{1}{6}$ $\\frac{1}{2}$ $\\frac{1}{3}$ $1$ \\(E(X,Y)=-\\frac{8}{6}-\\frac{1}{4}+\\frac{1}{4}+\\frac{8}{6}=0\\)\\(\\begin{aligned}E(X) &amp;amp;=\\sum_ix_iP(X=x_i)\\\\&amp;amp;=-\\frac{2}{6}-\\frac{1}{4}+\\frac{1}{4}+\\frac{2}{6}=0\\end{aligned}\\\\\\Rightarrow \\color{green}{Cov(X,Y)=0}\\)Exercice 2$a\\in\\mathbb R^{*}_+$$X,Y$ un couple de v.a. a valeurs dans $\\mathbb N$\\[\\underbrace{P((X=k)\\cap(Y=j))}_{\\text{Loi conjointe}}=\\frac{a}{2^{k+1}(j!)}\\quad\\forall (k,j)\\in\\mathbb N\\] Determiner $a$ $X$ et $Y$ sont-elles independantes $Cov(X,Y)$ Solution 1.\\[\\sum_{k,j}P_{k,j}=1\\\\\\sum_{k=0}^{+\\infty}\\sum_{j=0}^{+\\infty}\\frac{a}{2^{k+1}(j!)}=1\\\\a\\sum_{k=0}^{+\\infty}\\frac{1}{2^{k+1}}\\sum_{j=0}^{+\\infty}\\frac{1}{j!}=1\\] Rappel \\(e^X=\\sum_{j=0}^{+\\infty}\\frac{x^j}{j!}\\\\X=1\\quad\\color{red}{e=\\sum_{j=0}^{+\\infty}\\frac{1}{j!}}\\\\\\) \\[\\color{red}{ae\\sum_{k=0}^{+\\infty}\\frac{1}{2^{k+1}}=1}\\] Rappel (Serie geometriques) \\(\\color{red}{\\sum_{k=0}^{+\\infty}X^n=\\frac{1}{1-X}\\quad\\vert X\\vert\\lt1}\\) \\[ae\\frac{1}{2}\\sum_{k=0}^{+\\infty}\\biggr(\\frac{1}{2}\\biggr)^k=1\\\\\\begin{aligned}ae\\frac{1}{2}\\frac{1}{\\frac{1}{2}}=1&amp;amp;\\Rightarrow ae=1\\\\&amp;amp;\\Rightarrow \\color{green}{a=\\frac{1}{e}}\\end{aligned}\\] 2. Independance ?\\[P((X=k)\\cap(Y=j))=P(X=k)P(Y=j)\\] Loi marginale de $X$ \\(\\forall k\\in\\mathbb N\\quad P(X=k)=\\sum_{j=0}^{+\\infty}P_{k,j}\\)\\(\\begin{aligned}P(X=k)&amp;amp;=\\sum_{j=0}\\frac{a}{2^{k+1}(j!)}=\\frac{a}{2^{k+1}}\\sum_{j=0}^{+\\infty}\\frac{1}{j!}\\\\&amp;amp;=\\frac{ae}{2^{k+1}}=\\frac{1}{2^{k+1}}\\\\\\end{aligned}\\\\\\color{green}{P(X=k)=\\frac{1}{2^{k+1}}\\quad\\forall k\\in\\mathbb N}\\) Loi marginale de $Y$\\[\\forall j\\in\\mathbb N\\quad\\\\\\begin{aligned}P(Y=j)&amp;amp;=\\sum_{k=0}^{+\\infty}\\frac{a}{2^{k+1}(j!)}\\\\&amp;amp;=\\frac{a}{j!}\\frac{1}{2}\\sum_{k=0}^{+\\infty}\\biggr(\\frac{1}{2}\\biggr)^k=\\frac{a}{j!2}2=\\color{green}{\\frac{1}{ej!}}\\end{aligned}\\] La loi de $Y$:\\[\\forall j\\in\\mathbb N\\quad \\color{green}{P(Y=j)=\\frac{1}{ej!}}\\] Independance ?\\[\\begin{aligned}P(X=k)P(Y=j)=\\frac{1}{2^{k+1}}\\times\\frac{1}{ej!}\\\\P((X=k)\\cap(Y=j))=\\frac{1}{e2^{k+1}j!}\\end{aligned}\\Biggr\\}=\\text{ donc OK}\\] 3. $X$ et $Y$ etant independantes donc $Cov(X,Y)=0$" }, { "title": "ASE3: Couple de variables aleatoires discretes et analyse des donnees - 2", "url": "/cours/posts/ase3_couple_va_1/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-19 09:00:00 +0200", "snippet": "Lien de la note HackmdRappels \\(\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma_x\\sigma_y}\\)avec: $\\sigma_X=\\sqrt{V(X)}$ $\\sigma_Y=\\sqrt{V(Y)}$ \\[Cov(X,Y)=\\underbrace{&amp;lt;X-E(X),Y-E(Y)&amp;gt;}_{\\text{produit scalaire}}\\\\\\sigma_X=\\sqrt{V(X)}=\\Vert X-E(X)\\Vert\\\\\\rho(X,Y)=\\frac{&amp;lt;X-E(X), Y-E(Y)&amp;gt;}{\\Vert X-E(X)\\Vert\\Vert Y-E(Y)\\Vert}\\]\\[\\cos(\\theta)=\\frac{&amp;lt;u,v&amp;gt;}{\\Vert u\\Vert\\Vert v\\Vert}\\] \\(\\rho(X,Y) = \\cos(\\theta)\\\\\\vert\\rho\\vert\\le 1\\) Proposition \\(V(X+Y)=V(X)+V(Y)+2Cov(X,Y)\\) Demonstration\\[\\begin{aligned}V(X+Y)&amp;amp;=E((X+Y)^2) - (\\underbrace{E(X+Y)}_{E(X) + E(Y)})^2\\\\&amp;amp;=E(X^2+2XY+Y^2)-E^2(X)-2E(X)E(Y)-E^2(Y)\\\\&amp;amp;= E(X^2)+2E(XY) + E(Y^2)-E^2(X)-2E(X)E(Y)-E^2(Y)\\\\&amp;amp;=V(X) +V(Y)+2(E(XY)-E(X)E(Y))\\\\&amp;amp;=\\color{red}{V(X)+V(Y)+2Cov(X,Y)}\\end{aligned}\\]Remarque: Si $X$ et $Y$ sont independantes $\\Rightarrow$ $Cov(X,Y)=0\\Rightarrow\\color{red}{V(X+Y) = V(X)+V(Y)}$" }, { "title": "MLRF: Lecture 01", "url": "/cours/posts/mlrf_first_course/", "categories": "Image S8, MLRF", "tags": "Image, SCIA, MLRF, S8", "date": "2021-05-14 10:00:00 +0200", "snippet": "Lien de la note HackmdScope of this course Apply Machine Learning (ML) techniques to solve some practical Computer Vision (CV) problems About Computer Vision (CV) It should be called CV-ML, ML4CV or so‚Ä¶We need some definitions: What is Computer Vision ? What is Pattern Recognition ? Shape Recognition ? What is Machine Learning ? How do those concepts relate together ?Agenda for lecture 1 Some definitions and basic notions Course outline Introduction to Twin it ! Pattern MatchingSome definitionsComputer Vision DefinitionThe automation of visual tasks with the goal of producing results directly or indirectly usable by humans Input: image(s) in machine format (image acquisition of a subpart of CV) Output: some piecesExemple How would you process image pixels to get those results ? Les photos de chats sur Internet c‚Äôest important Some applications are direct (like the insect recognition app): a human reads and uses the output Some applications are indirect (like bank checking reading) The output is fed to a business system Some applications extend what humans can naturally do Either by extending our range Pattern Recognition DefinitionThe field of a pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take action such as classifying the data into different categories Bishop, 2006 IAPR: pattern recognition, computer vision and image processing in a broad senseExamples OCR Computer vision Pedestrian detection Computer Vision Credit fraud detection Not computer vision $\\Rightarrow$ CV$\\cap$PR$\\neq\\emptyset$Pattern Recognition is an inverse problem OCR example - Why Pattern Recognition is hard‚ÄúShapes‚Äù DefinitionA way to designate meaningful visual patterns.Sometimes used to describe ‚Äúvisual percepts‚ÄùLet S and S‚Äô be 2 shapes observed in 2 different images which happen to be similar. Some statistics can help us making better decisions‚Ä¶ Idea: learn the distance threshold under which shapes can be deemed identicalMachine LearningMany forms of Machine Learning Focus on inductive learning (generalize from examples) We will consider both supervised (a ‚Äúteacher‚Äù provides labels for examples) and unsupervised (only samples) Focus on optimization-based learning techniques (examples are represented as numerical vectors)Examples of optimization-based learning techniques Linear classifiers, SVMs Neural networks(‚ÄúStatistical‚Äù) Machine Learning Learning means changing in order to be better (according to a given criterion) when a similar situation arrivesLearning IS NOT learning by heartAny computer can learn by heart, the difficulty is to generalize a behavior to a novel situationQuoting S. BengioFrom an engineer‚Äôs POV Machin Learning is about building programs with tunable parameters (typicalyy an array of floating point values) that are adjusted automatically so as to improve their behavior by adapting to previously seen data.Machine Learning can be considered a subfield of AI since those algorithms can be seen as building blocks to make computer learnScikit Learn DocumentationWhy is learning difficult ?Given a finite amount of training data, you have to derive a relation for an infinite domain.In fact, there is an infinite number of such relationsWhich relation is the most appropriate ?‚Ä¶ the hidden test points‚Ä¶Learning biasIt is always possible to find a model complex enough to fit all the examplesBut how would this help us with new samples ? It should not generalize well.We need to define a family of acceptable solutions to search from. It forces to learn a ‚Äúsmoothed‚Äù representationSo in practice we need Examples (data!) A tunable algorithm (model) A evalutation of the model fitness to examples (risk, loss) A definition of the model search space (not too big, not too small) An optimization strategy The bias/variance compromiseSmall search space: Easier to find the best (available) solution But it may be far from the ideal one Large search space: It is hard to find the best (available) solution 3 kinds of problemsRegression\\[x=\\underbrace{\\begin{pmatrix} \\vdots \\end{pmatrix}}_{\\in\\mathbb R^T}\\\\y=\\underbrace{\\begin{pmatrix} \\vdots \\end{pmatrix}}_{\\in\\mathbb R^5}\\]Classification\\[x=\\mathbb R^5\\\\y=\\mathbb R^T\\]Density estimation\\[x\\in\\mathbb R^5\\\\\\mathbb P(x)\\in[0,1]\\]3 types of learning Supervised learning $(x,y)$ The training contains the desired behavior (desired class, outcome, etc.) Reinforcement learning $(x,\\tilde y)$ The training data contains partial targets (for instance, simply whether the machines did well or not) Unsupervised learning The training data is raw, no class or target is given There is often a hidden goal in that task (compression, maximum likelihood, etc.) Model validationMore on that later You need to test the generalization power of your approach So you need data not seen during the training: a test set For which you know the expected output (‚Äúground-truth‚Äù, ‚Äúgold standard‚Äù, ‚Äútarget‚Äù,‚Ä¶)Benefits of MLA duck exampleHow to filter the grass to keep only the duckshape, using threshold domain ?Why using Machine Learning in computer Vision ?To avoid knob turning. It‚Äôs complex. It‚Äôs unsafeBut beware of the Machine Learning MagicActual goals of this course Teach you that you can (and should whenever possible) optimize the parameters of your CV/PR product Show some simple tools to try to do it Address practical problem describe a pattern look for a pattern match a pattern classify a pattern describe a set of patterns (an object/an image) retrieve an object given a query, segment objects‚Ä¶ and face the unavoidable work surrounding them Course agenda6 ‚Äúweeks‚Äù (Friday to Friday)See the web page for complete agendaWeekly tests + assignments (practice sessions). No final examWeekly wokflow should be: Friday, 09:30-10:00: answer the weekly quiz on Moodle (starting next Friday) Friday, 10:00-12:00: attend the lecture using Teams Friday, 14:00-17:00: Work on the practice session and join the discussion using Teams Before next Friday: Complete the assignement and submit your results using Moodle (for sessions 4, 5 and 6 only)No deep learning ! We need a course about basic techniques There are cases where setting upPratice sessions: setup your dev. env.Basically: Python with: Jupyter Numpy Matplotlin Scikit-image: RGB Scikit-learn OpenCV: BGRWhy I love Scikit-LearnNumpy-friendly3-way documentation: User guide, API ref, ExamplesSuper smart API Decomposition, level of detail, default values, consistency, etcIntroduction to Twin it!OverviewA poster game $X$ bubbles, all different but $Y$ bubbles, which have 1 (and only 1) twinYour goals: Find the pairs Discussion (3 minutes): How can we decompose the problem ? How can we make sure our solution works ? What should we focus on ? Already done: Scan the poster Stitch the tiles Normalize the contrastUndelying problems Isolate each bubble $\\Rightarrow$ Segmentation We provide pre-computed results for this step Compare image pairs $\\Rightarrow$ Matching We will focus on this one We will use Template Matching Identify pairs $\\Rightarrow$ Calibration Template matchingWhy template matching ?A simple method which will be useful to understand Evaluation challenges The ideas behind keypoint detection (next lecture)It can work on the Twin it! case Twice the same texture Textures are the same scale, without rotation nor intensity change Only need to cope with translation (and some small noise)Step by step: Compare 2 images 2 arrays of intensities Take the absolute difference\\[R(x,y) = \\vert I_1(x,y) - I_2(x,y)\\vert\\] Sum the differences\\[S=\\sum_{x,y}(I_1(x,y) - I_2(x,y))^2\\](Opt.) Normalize so the results belongs to $[0,1]$Template Matching: Sliding comparison $I_1$ is a small template $T$ to match against $I_2$ (just $I$ after) We rewrite the preceding formula to compute a map $R$ of the shape of $I$ Each pixel of $R$ will have the value of the SSD when the top-left pixel of $T$ in on the pixel $(x,y)$ of $I$Several approaches $\\Leftrightarrow$ Practice sessionAbout the denominatorCross correlation: 2 things to knowMore robust to intensity shiftIdeal goalFor each bubble, retunr only a mathcin pair, if it exists" }, { "title": "ASE3: Couple de variables aleatoires discretes et analyse des donnees - 1", "url": "/cours/posts/ase3_couple_va/", "categories": "tronc commun S8, ASE3", "tags": "tronc commun, ASE3, S8, couple", "date": "2021-05-12 10:00:00 +0200", "snippet": "Lien de la note HackmdCouple de variables aleatoires reelles et discretesSoient $X$ et $Y$ 2 v.a reelles discretes. On appelle couple $(X,Y)$ l‚Äôapplication de $\\Omega\\to\\mathbb R^2$ definie par $(X,Y)(\\omega)=(X(\\omega), Y(\\omega))$$X$ et $Y$ sont definis sur un meme espace probabilite (\\(\\underbrace{\\Omega}_{\\text{univers}}, \\underbrace{\\mathcal C}_{\\text{tribu}}, \\underbrace{P}_{\\text{probabilite}}\\))La loi d‚Äôun couple $(X,Y)$ (Loi conjointe) DefinitionOn appelle loi de $(X,Y)$ l‚Äôensemble des couples $((x_i,y_j), P_{i,j})$ ou $x_i\\in X(\\Omega)$ l‚Äôensemble des valeurs de $X$ $y_j\\in Y(\\Omega)$ l‚Äôensemble des valeurs de $Y$ \\(P_{ij} = \\mathbb P((X=x_i)\\cap(Y=y_j))\\) Si $I = [[1, r]]$ et $J = [[1,s]]$ (ensemble discret, ensemble des indices). Les $P_{i,j}$ sont souvent donnes dans le tableau a double entres. $X /Y$ $y_1$ $\\dots$ $y_j$ $\\dots$ $y_s$ $x_1$ $P_{1,1}$ $\\dots$ $P_{1,j}$ $\\dots$ $P_{1,s}$ $\\vdots$ $\\vdots$ ¬† $\\vdots$ ¬† $\\vdots$ $x_i$ $P_{i,1}$ $\\dots$ $P_{i,j}$ $\\dots$ $P_{1,s}$ $\\vdots$ $\\vdots$ ¬† $\\vdots$ ¬† $\\vdots$ $x_r$ $P_{r,1}$ $\\dots$ $P_{r,j}$ $\\dots$ $P_{r,j}$ \\[P_{i,j} \\gt 0 \\quad\\text{et}\\quad\\sum_{i\\in I\\\\ j\\in J}P_{ij} = 1\\]Lois marginales DefinitionLes v.a $X$ et $Y$ sont appelees variables marginales du couple $(X,Y)$. La loi de $X$ (resp. de $Y$) est appelee loi marginale de $X$ (resp. de $Y$)Notation:\\[\\forall i\\in I, P(X=x_i)=P_{i\\circ} \\text{ et } P(X=y_j)=P_{\\circ j} \\\\P_{i\\circ} = P(X=x_i) = \\sum_{j\\in J}P((X=x_i)\\cap(Y=y_j)) = \\sum_{j\\in J}P_{ij}\\\\\\forall j\\in J\\quad P_{\\circ j}=\\sum_{i\\in I}P((X=x_i)\\cap(Y=y_j)) = \\sum_{i\\in I}P_{ij}\\]Exemple$(X,Y)$ un couple de v.a. dont la loi conjointe est donnee par le tableau: $X / Y$ 1 2 3 4 $P_{i\\circ}$ (Loi marginale de $X$) 1 $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 2 0 $\\frac{2}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 3 0 0 $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{1}{4}$ 4 0 0 0 $\\frac{4}{16}$ $\\frac{1}{4}$ $P_{\\circ j}$ (Loi marginale de $Y$) $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{5}{16}$ $\\frac{7}{16}$ 1 Loi conditionnelles Definition Soit $X$ une v.a reelle sur $(\\Omega, \\mathcal C, P)$\\[X(\\Omega) = \\{x_i\\vert i\\in I\\}, \\text{soit } A\\text{ un evenement }/P(A)\\neq 0\\] La loi conditionnelle de $X$ sachant $A = {(x_i, P_A(X=x_i)), i\\in I}$ \\[P_A(X=x_i) = \\frac{P((X=x_i)\\cap A)}{P(A)}\\] En particulier, $A$: ¬´$Y=y_i$¬ª\\[P_{(Y=y_i)}(X=x_i)=\\frac{P((X=x_i)\\cap(Y=y_i))}{P(Y=y_j)}=\\frac{P_{i,j}}{P_{\\circ j}}\\]\\[P_{(Y=y_j)}(X=x_i) = \\frac{P_{i,j}}{P_{\\circ j}}\\]ExempleOn reprend l‚Äôexemple precedent $X_i$ 1 2 3 4 $P_{(Y=3)}(X=x_i)$ $\\frac{1}{5}$ $\\frac{1}{5}$ $\\frac{3}{5}$ $0$ \\[P_{(Y=3)}(X=1)=\\frac{P((X=1)\\cap(Y=3))}{P(Y=3)}=\\frac{\\frac{1}{16}}{\\frac{5}{16}} = \\frac{1}{5}\\]Independantes Definition$X$ et $Y$ sont 2 v.a. independantes ssi \\[P((X=x)\\cap(Y=y)) = P(X=x)P(Y=y)\\quad\\forall x\\in X(\\omega), \\forall y\\in Y(\\omega)\\\\\\Leftrightarrow P_{ij} = P_{i\\circ} \\circ P_{\\circ j}\\] Soit g une fonction de $\\mathbb R^2\\to\\mathbb R$, definie sur l‚Äôensemble des valeurs prises par $(X,Y)$Soit $Z=g(X,Y)$, $Z_h=g(x_i,y_j)\\in Z(\\Omega)$\\[(Z=Z_k) = \\cup_{(i,j) \\\\ Z_k = g(x_i,y_j)}((X=x_i)\\cap(Y=y_j))\\Rightarrow\\color{red}{P(Z=Z_k)=\\sum_{(i,j) \\\\ Z_k = g(x_i,y_j)}P((X=x_i)\\cap(Y=y_i))}\\]En particulier $Z=X+Y=g(X,Y)$\\[P(Z=z) = \\sum_{(x,y) \\\\ x+y=z}P((X=x)\\cap(Y=y))\\]Si $Z=X.Y=g(X,Y)$\\[P(X.Y=z) = \\sum_{(x,y) \\\\ x.y=z}P((X=x)\\cap(Y=y))\\]Exemple$(X,Y)$ couple defini par $X / Y$ 1 2 3 4 1 $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ 2 0 $\\frac{2}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ 3 0 0 $\\frac{3}{16}$ $\\frac{1}{16}$ 4 0 0 0 $\\frac{4}{16}$ Determiner la loi de $Z=X+Y$ Solution\\[Z=\\{2,3,4,5,6,7,8\\}\\] $Z_k$ 2 3 4 5 6 7 8 $P(Z=Z_k)$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{2}{16}$ $\\frac{4}{16}$ $\\frac{1}{16}$ $\\frac{4}{16}$ \\[\\begin{aligned}P(Z=5) &amp;amp;= P(X+Y=5)\\\\&amp;amp;= P((X=1)\\cap(Y=4)) P((X=2)\\cap(Y=3)) + P((X=3)\\cap(Y=2)) + P((X=4)\\cap(Y=1))\\\\&amp;amp;= \\frac{1}{16} + \\frac{1}{16} + 0 + 0 =\\frac{2}{16} = \\frac{1}{8}\\end{aligned}\\]Determiner la loi de $Z=X.Y$ Solution\\[Z(\\Omega) = \\{1,2,3,4,6,8,9,12,16\\}\\] $Z_k$ 1 2 3 4 6 8 9 12 16 $P(Z=Z_k)$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{1}{16}$ $\\frac{3}{16}$ $\\frac{1}{16}$ $\\frac{4}{16}$ \\[\\begin{aligned}P(Z=4) &amp;amp;= P((X=1)\\cap(Y=4)) + P((X=2)\\cap(Y=2)) + P((X=4)\\cap(Y=1))\\\\&amp;amp;= \\frac{1}{16} + \\frac{2}{16} + 0 = \\color{red}{\\frac{3}{16}}\\end{aligned}\\]Esperance d‚Äôune fonction de 2 v.a.r discretes\\[\\begin{aligned}X(\\omega)=\\{x_1,...,x_i\\}\\\\Y(\\omega)=\\{y_1,...,y_j\\}\\end{aligned}\\biggr\\}Z=g(X,Y)\\\\E(Z) = E(g(X,Y)) = \\sum_{i,j}g(x_i,y_j)P((X=x_i)\\cap(Y=y_i))\\]\\[E(Z) = \\sum_{i,j}g(x_i,y_j)P_{i,j}\\]Exemple$g(X,Y) = X,Y$\\[\\begin{aligned}E(X.Y) &amp;amp;= \\sum_{i,j}x_iy_jP((X=x_i)\\cap(Y=y_j)) \\\\&amp;amp;= \\sum_{i,j}x_iy_jP_{i,j}\\end{aligned}\\]Proposition PropositionSi $X$ et $Y$ sont 2 v.a. independantes alors \\[E(X.Y) = E(X)E(Y)\\] Demonstration\\[E(X.Y) = \\sum_{i=1}^r\\sum_{j=1}^sx_iy_jP_{i,j}\\]or $X$ et $Y$ sont independantes $P_{i,j} = P_{i\\circ}\\circ P_{\\circ j}$\\[\\begin{aligned}E(X.Y) &amp;amp;=\\sum_{i=1}^r\\sum_{j=1}^sx_iy_jP_{i\\circ}P_{\\circ j}\\\\&amp;amp;= \\sum_{i=1}^rx_iP_i\\biggr(\\sum_{j=1}^sy_jP_{\\circ j}\\biggr)\\\\&amp;amp;= \\sum_{i=1}^rx_iP_{i\\circ}E(Y)=E(X)E(Y)\\end{aligned}\\]\\[E(X.Y) = E(X)E(Y)\\] La reciproque est fausseContre-exemple$(X,Y)$ couple de loi conjointe $X / Y$ 0 1 2 $P_{i\\circ}$ (Loi de $X$) 0 $\\frac{1}{20}$ $\\frac{1}{4}$ 0 $\\frac{3}{10}$ 1 $\\frac{17}{60}$ $\\frac{1}{4}$ $\\frac{1}{6}$ $\\frac{7}{10}$ $P_{\\circ j}$ (Loi de $Y$) $\\frac{1}{3}$ $\\frac{1}{2}$ $\\frac{1}{6}$ $1$ \\[\\begin{aligned}E(X.Y) &amp;amp;= \\sum_{i=0}^1\\sum_{j=0}^2i.jP_{i,j}\\\\&amp;amp;= 1\\times\\frac{1}{4}+2\\times\\frac{1}{6} = \\frac{1}{4} + \\frac{1}{3} = \\frac{7}{12}\\\\E(X) &amp;amp;= \\sum_{i=0}^1iP_{i\\circ}=\\frac{7}{10}\\\\E(Y) &amp;amp;= \\sum_{j=0}^2jP_{\\circ j} = \\frac{1}{2} + \\frac{2}{6} = \\frac{5}{6}\\\\E(X.Y) &amp;amp;= \\frac{7}{12} = E(X)E(Y)\\end{aligned}\\\\\\]et pourtant $X$ et $Y$ ne sont pas independantes car\\[P((X=0)\\cap(Y=2)) = 0\\\\P(X=0).P(Y=2) = \\frac{3}{10}\\times\\frac{1}{6}=\\frac{1}{20}\\]Covariance et coefficient de correlation lineaire Definition$X$ et $Y$ 2 v.a. discretes.On appelle covariance de $(X,Y)$ le nombre reel \\[Cov(X,Y)=E((X-E(X)(Y-E(Y))))\\] Proposition\\[Cov(X,Y)=E(X.Y) - E(X)E(Y)\\]Demonstration\\[\\begin{aligned}Cov(X,Y) &amp;amp;= E(\\overbrace{(X-E(X))}^{\\text{var centree}}\\overbrace{(Y-E(Y))}^{\\text{var centree}})\\\\&amp;amp;= E(XY-XE(Y) - E(X)Y + E(X)E(Y))\\\\&amp;amp;= E(X.Y) - E(Y)E(X) - E(X)E(Y) + E(X)E(Y)\\end{aligned}\\]Cat $E$ est lineaire\\[Cov(X,Y) = E(XY) - E(X)E(Y)\\]Remarque: Si $X$ et $Y$ sont independantes alors $Cov(X,Y)=0$ DefinitionOn appelle coefficient de correlation lineaire \\[\\mathcal C(X,Y)=\\frac{Cov(X,Y)}{\\sigma_x\\sigma_y}\\] $\\sigma_x=\\sqrt{V(X)}$ $\\sigma_y=\\sqrt{V(Y)}$ " }, { "title": "OCVX: Espaces tangents", "url": "/cours/posts/ocvx_espaces-tangents/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-05-11 09:00:00 +0200", "snippet": "Lien de la note HackmdDedramatiser les espaces tangentsPour une fonction \\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ x&amp;amp;\\mapsto f(x)\\end{aligned}\\)\\[Gr(f) = \\{(x,f(x)), x\\in\\mathbb R\\} \\subseteq \\mathbb R^2\\]Une droite affine est un sous-espace de dimension 1\\[\\begin{aligned}\\color{red}{\\mathcal T_{Gr(f), p}} &amp;amp;= (a,f(a)) + \\color{red}{\\underbrace{\\{\\lambda(1,f&#39;(a)),\\lambda\\in\\mathbb R\\}}_{vect((1,f&#39;(a))) = span((1,f&#39;(a)))}}\\\\&amp;amp;= \\{((a+\\lambda), f(a) + \\lambda f&#39;(a),\\lambda\\mathbb R)\\}\\quad\\text{representation parametrique de } \\mathcal T_{Gr(f), p}\\end{aligned}\\]$Gr(f)$ $\\to$ courbe $y=f(x)\\equiv$ courbe \\(\\underbrace{f(x)-y}_{g(x,y)}=0\\)On va introduire \\(\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto f(x)-y \\end{aligned}\\)$Gr(f)$ $\\to$ courbe $y=f(x)\\equiv$ coubre \\(\\underbrace{f(x)-y}_{g(x,y)}=0 \\equiv\\{(x,y)\\in\\mathbb R^2, g(x,y) = 0\\}=\\mathcal C_0(g)\\) On passe a la courbe de niveau 0Que vaut $\\nabla g(p)$ ?\\[\\nabla g(x,y) = (\\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y}) = (f&#39;(x), -1)\\\\\\nabla g(p=(a,f(a))) = (f&#39;(a), -1)\\]On a trouve precedemment un vecteur directeur de l‚Äôespace tangent $(1, f‚Äô(a))$. On obtient 2 vecteurs orthogonaux\\[\\nabla g(p=(a,f(a))) = (f&#39;(a), -1) \\to \\vec n\\\\&amp;lt;\\vec n,\\vec u&amp;gt; = 0\\] Le gradient d‚Äôune fonction en un point donne est orthogonal aux lignes de niveau de cette fonction.Cas generalDans le cas general $f:\\mathbb R^n\\to\\mathbb R$Notre ‚Äúbol‚Äù est:\\[Gr(f) = \\{(x,y,f(x,y)), (x,y)\\in\\mathbb R^2\\} \\subseteq\\mathbb R^3\\]On veut calculer l‚Äôespace tangent dans un point donne de l‚ÄôespaceOn a deux directions de pentes Qu‚Äôest-ce qui se passe selon $x$ ? Si on se deplace de $1$ en $x$, $\\frac{\\delta f}{\\delta x}(x_0,y_0)$ en $z$ Qu‚Äôest-ce qui se passe selon $y$ ? Si on se deplace de $1$ en $y$, $\\frac{\\delta f}{\\delta y}(x_0,y_0)$ en $z$ Zoomons au niveau du point $p$:Ces vecteurs generent l‚Äôespace tangent\\[\\begin{aligned}\\mathcal T_{Gr(f), p} &amp;amp;= p + vect\\biggr(\\underbrace{(\\overbrace{1,0}^{e_x},\\frac{\\partial f}{\\partial x}(x_0, y_0)}_{\\in\\mathbb R^3}), \\underbrace{(\\overbrace{0,1}^{e_y},\\frac{\\partial f}{\\partial y}(x_0,y_0))}_{\\in\\mathbb R^3}\\biggr)\\\\&amp;amp;= p + vect\\underbrace{((e_x, \\frac{\\partial f}{\\partial x}), (e_y, \\frac{\\partial f}{\\partial y}))}\\\\&amp;amp;\\{\\lambda(e_x, \\frac{\\partial f}{\\partial x}) + \\mu(e_y, \\frac{\\partial f}{\\partial y}),(\\lambda,\\mu\\in\\mathbb R^2)\\}\\end{aligned}\\]Le vrai cas general $f:\\mathbb R^n\\to\\mathbb R$ $n$ pertes $\\frac{\\partial f}{\\partial x}$ selon chaque vecteur de base $e_i=(0,‚Ä¶0,1,‚Ä¶,0)$ $n$ vecteurs de perte \\(\\underbrace{(\\underbrace{e_i}_{\\in\\mathbb R^n},\\frac{\\partial f}{\\partial x_i})}_{\\in\\mathbb R^{n+1}}, i=1,...,n\\)\\[\\mathcal T_{Gr(f)} = vect\\biggr((e,\\frac{\\partial f}{\\partial x_1}),...,(e_n,\\frac{\\partial f}{\\partial x_i})\\biggr)\\quad\\text{sous espace de dim }n\\text{ d&#39;un espace de dimension }n+1\\\\T_{Gr(f),p}=\\{\\lambda(e_1,\\frac{\\partial f}{\\partial x_1}) + ... + \\lambda_n(e_n,\\frac{\\partial f}{\\partial x_n}), (\\lambda_1,...,\\lambda_n)\\in\\mathbb R^n\\}\\]$Gr(f)=$ surface $y=f(x_1,‚Ä¶,x_n)$\\[f(x_1,...,x_n)-y=0 \\equiv \\{(x_1,...,x_n,y)\\text{ tel que } \\underbrace{f(x_1,...,x_n)-y}_{g(x_1,...,x_n,y)}=0\\} = \\mathcal C_0(g)\\\\\\begin{aligned}g:\\mathbb R^{n+1}&amp;amp;\\to\\mathbb R\\\\(x_1,...,x_n,y) &amp;amp;\\mapsto f(x_1,...,x_n)-y\\end{aligned}\\\\\\nabla g(x,y) = (\\frac{\\partial g}{\\partial x_1},...,\\frac{\\partial g}{\\partial x_n},\\frac{\\partial g}{\\partial y}) = (\\frac{\\partial f}{\\partial x_1},...,\\frac{\\partial f}{\\partial x_n},-1)\\]Implicitement: \\(\\mathcal T_{C_0(g),p} = \\{x\\in\\mathbb R^{n+1}, \\nabla g^T x = 0\\}\\)ExerciceSoit \\(\\begin{aligned} f:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto ax^2+by^2 \\quad (a,b)\\in\\mathbb (R_{*}^+)^2 \\end{aligned}\\) Decrire l‚Äôespace tangent en tout point du graph de $f$ Decrire l‚Äôespace tangent a la courbe de niveau $1$ de $f$ Exo 4.531.En un point $(x,y,f(x,y))\\in Gr(f)$ perte selon $x$: $(1,0,\\frac{\\partial f}{\\partial x}) = \\color{blue}{(1,0,2ax)}$ perte selon $y$: $(0,1,\\frac{\\partial f}{\\partial y}) = \\color{green}{(0,1,2by)}$\\[\\begin{aligned}\\mathcal T_{Gr(f), p} = vect\\biggr(&amp;amp;\\underbrace{(1,0,2ax), (0,1,2by)}_{}\\biggr) + p\\\\\\{\\lambda(1,0,2ax) &amp;amp;+ \\mu(0,1,2by), (\\lambda,\\mu)\\in\\mathbb R^2\\} = {(\\lambda,\\mu,2ax\\lambda + 2by\\mu), (\\lambda, \\mu)\\in\\mathbb R^2}\\end{aligned}\\]2.$\\mathcal C_1(f) = {(x,y)\\in\\mathbb R^2, f(x,y)=ax^2+by^2=1}$On commence par regarder que vaut le gradient de cette fonction::\\[\\nabla f(x,y) = \\begin{pmatrix} 2ax \\\\ 2by \\end{pmatrix}\\]Dans quel sens pointe le gradient ?Quel est l‚Äôespace par rapport au gradient ?\\[\\begin{aligned}\\mathcal T_{\\mathcal C_1(f),p} = p + \\{(x,y), \\nabla f(x_0, y_0)^T\\begin{pmatrix}x \\\\ y \\end{pmatrix} &amp;amp;= 0\\}\\\\(2ax_0, 2by_0)\\begin{pmatrix}x \\\\ y \\end{pmatrix} &amp;amp;= 0\\\\2ax_0x + 2by_0y &amp;amp;= 0\\\\y&amp;amp;=-\\frac{ax_0}{by_0}x\\end{aligned}\\\\\\mathcal T_{\\mathcal C_1(f),p} = (x_0, y_0) + \\{(x,y)\\in\\mathbb R^2, \\underbrace{y = -\\frac{ax_0}{by_0}x}_{\\nabla f(x_0, y_0)^T\\begin{pmatrix}x \\\\ y \\end{pmatrix} = 0}\\}\\]3.Ou est le minimum de $f$ ? Quel point minimise $ax^2 + by^2$ ?C‚Äôest $(0,0)$.\\[argmin f(x,y) = ax^2 + by^2 = (0,0)\\]Dans quel sens pointe le gradient en tout point de la courbe de niveau par rapport au point minimal? En tout point des courbes de niveau de $f$, $Df$ point a l‚Äôoppose du point optimal $(x^+=0, y^+=0)$Caracterisation au premier ordre de la convexiteGraphiquement, quelque soit $x$, $Gr(f)\\ge \\mathcal T_{Grf(x,f(x))}$, le point est toujours au-dessus de la tangente.Si $f$ est convexe, $\\forall x,y$, $f(y) - f(x)\\ge f‚Äô(x)(y-x)$ Pour une fonction $f:\\mathbb R^n\\to\\mathbb R$, $f$ convexe $\\Leftrightarrow$ $\\forall x,y\\in\\mathbb R^n$ \\(\\color{red}{f(y)-f(x)\\ge \\nabla \\underbrace{f(x)^T}_{\\in\\mathbb R^n}\\underbrace{(y-x)}_{\\in\\mathbb R^n}}\\)" }, { "title": "OCVX: Hyperplan d&#39;appui", "url": "/cours/posts/ocvx_hyperplan/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-05-07 10:00:00 +0200", "snippet": "Lien de la note HackmdRappels Hyperplan d‚Äôappui a une partie $A$ de $\\mathbb R^n$ en un point $p\\in A$, est un hyperplan affine de $\\mathbb R^n$ qui laisse $A$ dans un des deux demi-espaces definis par $H$Etant donne un vecteur normal $\\vec \\nu$ definissant $H\\in\\mathbb R^n$ et $p$ un point dans $H\\cap A$ on a\\[\\forall x\\in A; &amp;lt;\\vec\\nu, x-p&amp;gt;\\le 0\\] On a definit par ailleurs la notion de gradient d‚Äôune fonction differentiable $f:\\mathbb R^n \\to \\mathbb R$ en un point $a$, determinee par la relation:\\[\\forall h\\text{ assez petit}\\\\f(a+b) = f(a) + \\nabla f(a)^Th + \\underbrace{\\varepsilon(h)\\Vert h\\Vert}_{\\varepsilon(h) \\to 0 \\\\ h\\to0}\\]Plan du cours Objectif d‚Äôaujourd‚Äôhui Etendre la notion de droite tangente au graphe d‚Äôune fonction $f:\\mathbb R\\to\\mathbb R$ Au cas des fonctions $\\phi:\\mathbb R^n\\to\\mathbb R$ au cas des parties de $\\mathbb R^n$ decrites comme courbes de niveaux de fonctions Utiliser le point 1. pour obtenir une lieuristique, permettant de construire des methodes iteratives d‚Äôoptimisation Revoir la notion de droite tangente dans le cas $\\mathbb R$ (une dimension) $f:\\mathbb R\\to\\mathbb R$ Graphe On va definir une maniere de generaliser la notion de droite tangente $f:\\mathbb R\\to\\mathbb R$ Graphe On adapte cette definition au cas de courbes de niveaux $g:\\mathbb R^2\\to\\mathbb R$ zeros de $g$ (courbes de niveau de $g$) Conclusion pour le cas general $\\phi:\\mathbb R^n\\to\\mathbb R$ Espace tangentLe gradient en dimension 1 correspond a la notion de derivee, qui permet de definir la notion de droite tangente au graphe d‚Äôune fonction en un point. Dans ce contexte, l‚Äôinterpretation geometrique de la notion de gradient est connue. En particulier le fait que vous soyez croissants ou decroissant vous est donne par le signe de votre gradient; cela vous permet de savoir dans quelle direction aller si vous cherchez des points ou votre fonction a des plus petite ou plus grandes valeurs.Que signifie un nombre positif ou negatif pour un vecteur de $\\mathbb R$ ?Si on est positif (resp. negatif), on est dans la moitie positive(resp. negative) de notre droite reelle.\\(Q: \\min_{x\\in\\mathbb R}f(x)\\)On cherche a minimiser la fonction $f$Dans ce dessin, le signe de la derivee vous dit que si vous voulez chercher des points $x$ avec $f(x)\\le f(a)$, il faut aller dans le sens oppose a $f‚Äô(a)$.La droite $D_{f,p}$ est derivee parametriquement par\\[\\begin{aligned}\\mathbb R&amp;amp;\\to^{\\lambda}\\mathbb R^2\\\\t&amp;amp;\\mapsto (a+t, f&#39;(a)t + f(a))\\color{green}{= (a, f(a)) + t(1, f&#39;(a))}\\color{red}{=P}\\end{aligned}\\]On est en train de dire que $D_{f,p}$ est la droite passant par $p$, de direction $Vect\\biggr((1,f‚Äô(a))\\biggr)$Cette notion de droite tangente ne semble pas, telle quelle, facilement generalisable au cas de fonctions de $\\mathbb R^n\\to\\mathbb R$ DefinitionSoit $A$ une partie de $\\mathbb R^n$, soit $p\\in A$. On appelle \\(\\color{red}{\\text{germe d&#39;une courbe (derivable) } \\gamma:\\underbrace{]-\\varepsilon,\\varepsilon[}_{\\varepsilon\\gt0}\\to A\\text{ tel que }\\gamma(0)=p}\\), la derivee de $\\gamma$ en $0$Cela correspond au vecteur vitesse en $p$ d‚Äôun point materiel passant par $p$ a l‚Äôinstant 0, si $\\gamma$ decrit la position de ce point en fonction du temps $t$. L‚Äôensemble des germes de courbes en $p$ definit un sous-espace vectoriel de $\\mathbb R^n$. $\\color{orange}{\\text{On le note }T_{A,p}\\text{, il s‚Äôappelle espace tangent a }A\\text{ en }p}$.Que donne $\\color{orange}{T_{A,p}}$ dans le cas du graphe de $f$?Si $A$ est $\\Gamma_f$ (graphe de $f$) toute courbe passant par $p$ $\\gamma:]-\\varepsilon,\\varepsilon[\\to\\Gamma_f$ est de la forme:\\(\\gamma(t) = \\underbrace{(\\psi(t), f(\\psi(t)))}_{\\color{orange}{\\psi(t), \\phi(t)}} \\quad \\text{pour }\\psi:]-\\varepsilon,\\varepsilon[\\to\\mathbb R\\)avec $\\psi(0) = a$Si $\\gamma$ est derivable en 0:\\[\\gamma&#39;(0) = (\\psi&#39;(0),\\psi&#39;(0)f&#39;(a)) = \\psi&#39;(0)(1,f&#39;(a))\\]\\[\\Rightarrow \\gamma&#39;(0)\\in Vect\\biggr((1,f&#39;(a))\\biggr)\\Rightarrow T_{A,p}\\subseteq Vect\\biggr((1,f&#39;(a))\\biggr)\\] Conclusion\\[T_{A,p} = Vect\\biggr((1, f&#39;(a))\\biggr)\\] autrement dit: $D_{f,p} = p + T_{A,p}$ DefinitionEtant donne une partie $A\\subseteq\\mathbb R^n$ et $p\\in A$, on appelle espace tangent a $A$ en $p$ l‚Äôespace vectoriel $T_{A,p}$ compose des germes de courbes dans $A$ passant par $p$.Remarque: Geometriquement, on represente souvent $p+T_{A,p}$ et non $T_{A,p}$Notre prochaine etape est de reinterpreter $p+T_{A,p}$ de maniere implicite de facon a faire apparaitre la notion de gradient d‚Äôune fonction $\\mathbb R^n\\to\\mathbb R$.On a $D_{f,p}: (a,f(a)) + t(1,f‚Äô(a))$ pour $t\\in\\mathbb R$.Comment obtenir une ecriture implicite de $D_{f,p}$ ?Si $(x,y)\\in D_{f,p}$ alors\\[\\begin{cases}x = a + t\\\\y = f(a) + f&#39;(a)t\\end{cases}\\Leftrightarrow f&#39;(a)(x-a) = y - f(a)\\]Questions Comment ecrit-on $\\Gamma_f$ comme zeros d‚Äôune fonction ? Quel est le gradient de cette fonction au point $p$ ? Quel est $\\perp$ de ce gradient au point $p$ ?Premiere question$\\Gamma_f$ est zeros de la fonction:\\[\\begin{aligned}\\phi:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y) &amp;amp;\\mapsto f(x)-y\\end{aligned}\\\\\\begin{aligned}z(\\phi) = \\{(x,y)\\vert f(x)-y=0\\} &amp;amp;= \\{(x,y)\\vert f(x)=y\\}\\\\&amp;amp;= \\{(x,f(x))\\vert x\\in\\mathbb R\\}\\\\&amp;amp;= \\Gamma_f\\end{aligned}\\]Deuxieme question\\[\\nabla\\phi((a,f(a))) = \\begin{pmatrix}\\frac{\\partial\\phi}{\\partial x}(a,f(a)) \\\\ \\frac{\\partial\\phi}{\\partial y}(a,f(a)) \\end{pmatrix} = \\begin{pmatrix}f&#39;(a) \\\\ -1\\end{pmatrix}\\\\\\phi(x,y) = f(x) - y\\]Ce qui genere notre droite tangente c‚Äôest $(1, f‚Äô(a))$ et on a obtenu le vecteur $(f‚Äô(a), -1)$. On a obtenu un vecteur orthogonal a notre droite tangenteTroisieme questionL‚Äôorthogonal a $\\nabla\\phi(p)$ au point $p$:\\[\\nabla\\phi(p)^T\\begin{pmatrix}x - a \\\\ y-f(a)\\end{pmatrix} =\\begin{pmatrix}f&#39;(a) \\\\ -1\\end{pmatrix}\\begin{pmatrix}x - a \\\\ y - f(a)\\end{pmatrix} = f&#39;(a)(x-a)- ( y - f(a))\\] $\\perp\\nabla\\phi(p): f‚Äô(a)(x-a) = y-f(a)$ ($\\perp$ passant par $p$)‚ÄúVectorialise‚Äù: $f‚Äô(a)x = y \\Leftrightarrow\\nabla\\phi(p)^T \\begin{pmatrix}x \\ y\\end{pmatrix} = 0$ $\\nabla\\phi(p)$ nous donne $T_{\\Gamma_{f,p}}$, Autrement dit: \\(D_{f,p}:p + \\underbrace{\\nabla\\phi(p)^{\\perp}}_{\\color{orange}{T_{\\Gamma_{f,p}}}}\\) PropSoit $f:\\mathbb R^n\\to\\mathbb R$ une fonction differentiable en un point $p\\in\\mathcal C_{f,r}$. L‚Äôespace tangent a $\\mathcal C_{f,r}$ au point $p$ est donne par l‚Äôhyperplan orthogonal ($\\perp$) a $\\nabla f(p)$.Question: Calculer l‚Äôespace tangent au point $(1, 1)$ de $\\mathcal C_{f,r}$ pour \\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R \\\\ (x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\)\\[\\begin{aligned}\\nabla f(x,y) = \\begin{pmatrix}2x \\\\ 2y\\end{pmatrix}; \\quad \\nabla f(1,1)^T\\begin{pmatrix}x \\\\ y\\end{pmatrix} &amp;amp;= 0\\\\\\Leftrightarrow 2x+2y &amp;amp;=0\\\\\\Leftrightarrow x+y&amp;amp;=0\\end{aligned}\\]Apport de la convexiteRappel Une fonction $f:\\mathbb R^n\\to\\mathbb R$, differentiable, est convexe si $\\forall x,y\\in\\mathbb R^n$ \\(f(y)- f(x) \\ge\\nabla f(x)^T(y-x)\\qquad \\text{(E)}\\)Hypothese Hypothese$f:\\mathbb R^n\\to\\mathbb R$ une fonction convexeDans ce cas $\\forall r\\in\\mathbb R$, $\\mathcal C_{f\\le r}$ est convexe $\\subseteq\\mathbb R^n$Ici, \\(\\forall y\\in\\mathcal C_{f_1\\le v}\\), $\\nabla f(x)^T(y-a)\\le0$. Donc $x+\\nabla f(x)^{\\perp}$ est un hyperplan d‚Äôappui a \\(\\mathcal C_{f_1\\le v}\\) Convexite: $f(y)-f(x)\\ge\\nabla f(x)^T(y-x)$Donc le demi-espace positif est a exclure si l‚Äôon souhaite chercher un point $x^+$ tel que $f(x^+)\\le f(x)$ On vient d‚Äôeliminier toute une partie de l‚Äôespace de nos recherches.Question: Dans quelle direction chercher ? PropSoit $f:U\\subset\\mathbb R^n\\to\\mathbb R$ une fonction differentiable. Soit $x\\in\\mathcal C_{f,r}$, si $\\nabla f(x)\\neq 0$ $\\exists x^+=x+\\Delta x$ tel que $f(x)\\ge f(x^+)$ detour, par un deplacement $\\Delta x$ a l‚Äôoppose de la direction de $\\nabla f(x)$Remarques On ne connait pas a priori l‚Äôamplitude par laquelle on doit additioner $\\nabla f(x)$ a $x$, pour obtenir $x^+$ Ce resultat est vrai meme si $f$ n‚Äôest pas convexe, on ne garantit plus la recherche d‚Äôun minimum globalQuestion: Il se passe quoi si $\\nabla f(x) = 0$ ?Questions des elevesJ‚Äôai pas compris la particule a une vitese constante sur x? Comment on d√©fini la ‚Äúvitesse‚Äù? Tu images que la courbe gamma repr√©sente le d√©placement de la particule le long de la courbe A -&amp;gt; gamma(t) = abscisse de la particule le long de la courbe. Avec en t=0, ta particule qui passe par le point p La vitesse instantan√©e = d√©riv√©e de la position. Vitesse instantan√©e de la particule en p = d√©riv√©e de gamma en 0 Ta particule peut adopter plusieurs profils de vitesse le long de la courbe (acc√©l√©rer, d√©c√©l√©rer, etc), mais elle est contrainte de suivre le profile de la courbe Donc la valeur du vecteur vitesse gamma‚Äô(0) peut effectivement varier selon le profil de vitesse Mais la direction de ce vecteur vitesse sera toujours la m√™me, et c‚Äôest ce qui d√©fini l‚Äôespace tangent (en dim 1)Mais du coup on fait tout √ßa juste pour trouver un vecteur qui appartient a l‚Äôespace tangent? En fait cette id√©e est tr√®s g√©n√©rale, et ind√©pendante de la dimension de l‚Äôespace dans lequel on travaille.En dim 1, √ßa peut para√Ætre un peu overkill de faire tout √ßa ‚Äújuste‚Äù pour avoir la direction de la tangente.Mais quand on va passer sur des dimensions sup√©rieurs (donc des surfaces, etc), l√† tu auras plusieurs directions possibles de te balader sur la surface et d‚Äôapprocher ton point p. Imagine $f(x,y) = x^2 + y^2$, donc une surface en forme de bol. En (0,0), tu as plusieurs directions pour approcher (0,0) en restant sur la surface. Pour chacune de ces courbes possibles, tu vas avoir un vecteur vitesse associ√©. Et c‚Äôest l‚Äôensemble de ces vecteurs vitesse (enfin, l‚Äôespace g√©n√©r√© par ces vecteurs vitesse) qui va d√©finir le plan tangentJ‚Äôai encore du mal √† voir en quoi c‚Äôest diff√©rent d‚Äôune diff√©rentielle Il y a effectivement un lien entre les deux notions, mais ce ne sont pas du tout les m√™mes objets : une diff√©rentielle est une application lin√©aire, un espace tangent est une sous-partie de ton espace de travail." }, { "title": "IRGPU: Patterns for massively parallel programming", "url": "/cours/posts/irgpu_patterns/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-05 14:00:00 +0200", "snippet": "Lien de la note HackmdIRGPU: Patterns for massively parallel programmingProgramming patterns &amp;amp; memory optimizationsThe programming patterns Map Map + Local reduction Reduction ScanThe IP algorithms LUT applications Local features extraction Histogram Integral imagesMap patternMap pattern overview Un pixel en entree et sortie La dependance est nulle Map replicated a function over every element of an index set.The computation of each pixel is independant wrt the othersout(x,y) = f(in(x,y))What do you think about k‚Äôs impact of the performance ?Le premier fait threadIdx.x + k et l‚Äôautre fait threadIdx.x * k A gauche, le thread numero i est le thread numero i+1: c‚Äôest continue au niveau des addresses memoire (lineaire) A droite: acces stride (palier) Linear sequential access with offset c‚Äôest bien Strided access c‚Äôest po bien Strided access patternSur le kernel numero 2, un grand temps du process est passe pour la gestion memoire (acces memoire mal fait)Memory performanceMemory bandwithWhat you think about memoryReality:Memory access hierarchy Memoire L2: cache intermediaire Memoire sur le chip low-latency Registres Shared memory L1 (meme zone que shared memory) Dire au processeur de gerer la memoire ou la gerer nous-meme Dans ce cas on configure nous meme la shared memory Sers de cache entre le L2 et la shared memory Cached Loads from L1 low-latency2 choses a prendre en compte: acces memoire alignes ou non acces memoire coalesced (stride) ou non2 types of global memory loads: cached or uncachedAligned vs MisalignedA load is aligned if the first address of a memory access in 32 bytes Memory addresses must be type-aligned (typeof(machin)) Otherwise poor perf cudaMalloc = alignement on 256 bits at leastCoalesced vs uncoalescedA load is coalesced if a warp access is non-continuousMisaligned cached loads from L1We need a load strategy: 32 threads of warp access a 32-bit word = 128 bytes 128 bytes = L1 bus (single load - bus utilization = 100%) Access permutation has no (or very low) overheard If data are not 128-bits aligned, 2 loads are requiredAdresses 96-224 required.. but 0-256 loaded If data is accessed stridedPas possible d‚Äôaugmenter la taille du bus ?Le bus est fixe (hardware)Loads from gloabl (uncached) memorySame idea but memory is split in segments of 32 bytesCoalesced Memory Access (summary)How memory works for real DRAM is organised in 2D Core array Each DRAM core array has about 16M bitsExample A 4x4 memory cell With 4 bits pin interface widthDRAM BurstLa memoire est lente DDR = 1/2 interface speed DDR2 = 1/4 interface speed DDR3 = 1/8 interface speed Solution: BurstingLoad N x interface width of the same rowAu lieu d‚Äôavoir 1/4, on renvoit 3 x 1/4Better, but not enough to saturate the memory busSummary Use coalesced (contiguous and aligned) accessed to memoryHow to make coalesced loads with 2D arrays ? Ca correspond au pitchPitch: taille des lignes pour que le debut des lignes correspond a un multiple de 32Using shared memoryTranspositionWhere are non-coalesced access ?Sur un warp, les x sont lineaire (0 - 31). Ici, ce qui est lineaire selon x c‚Äôest la lecture dans in.32 threads vont ecrire 32 elements non-continus a[x][y]Tiling and memory privatization On decoupe le travaille en sous-block (tuile) Ca marche bien sur les images !For each block: Read the tile from global to private block memory process the block (used shared memory) write the tile from the private (shared) block memory to global memoryCollaborative loading and writing then BLOCKDIM = TILEDIM All threads load one or more data Access must be coalesced Use barrier synch to make sure that all threads are ready to start the phaseEst-ce que ecrire dans la tile c‚Äôest lineaire ?Pour chaque ligne y, x va varier le plus rapidement possible: c‚Äôest lineaireTiled transposition in shared memoryL‚Äôalgorithme pour transposer en utilisant la shared memory commence par copier la taille en shared memory, transpose en shared memory et transpose les acces coalesced en memoire globaleA quel moment on fait des acces aligned dans la shared memory ?On lit de maniere alignee en global, on ecrit en aligne partout sauf la derniere ligne ou c‚Äôest un acces non-alignePerformance (GB/s on TESLA K40)Speed up de 2 entre la version qui utilise la shared memory et celle qui ne l‚Äôutilise pasAbout shared memoryComment on peut combler le gap (encore) entre les GB/s de la TESLA ?DRAM banks Bursting: access multiple locations of a line in the DRAM core array (horizontal parallelism) Permet d‚Äôutiliser d‚Äôavantage la memoire a sa capacite totaleBank conflits in shared memory If 2 threads try to perform 2 different loads in the same bank $\\to$ Bank conflict Evert bank can provide 64 bits every cycle Only 2 modes: Change after 32 bits Change after 64 bits Demander la meme adresse par 2 threads differents ne pose pas de problemesLes addresses consecutives ne sont pas dans les memes banques.2-way conflicts:On fait 2 loads en shared memory Conflict = serialized access po bienConcrete example for shared memory Bank size: 4B = 4 uint8 32 Banks - Many channels Warp size = 32 threadsPour le premier cas du tableau:Est-ce qu‚Äôil a des threads qui demandent des addresses differentes dans une meme banque ?NonQuel est le nombre de loads (requetes memoire) qu‚Äôon va effectuer ?Une seule requete memoire op Items Bank used Conflict Free #Loads load M[tid.x] $[0,1,‚Ä¶,31]$ $[0,1,‚Ä¶,7]$ Oui 1 load M[tid.x % 4] $[0,1,2,3,0,1,2,3‚Ä¶]$ $[0]$ Oui 1 load M[tid.x + 1] $[1,2,3,‚Ä¶32]$ $[0,1,‚Ä¶,8]$ Oui 1 load M[tid.x * 2] $[0,1,2,3,‚Ä¶62]$ $[0,1,‚Ä¶,15]$ Oui 1 load M[tid.x * 8] $[0,8,‚Ä¶248]$ $[0,2,‚Ä¶,30]$ Non (conflits sur toutes les banques) 2 load M[tid.x * 12] $[0,8,‚Ä¶248]$ $[0,1,‚Ä¶,31]$ Oui 1 load M[tid.x * 8]:load M[tid.x * 12]:Bank conflicts in TransposeSi on a 32 banques, on utilisent que 2 banques sur 32 et on a plein de conflits. Reading a column may cause bank conflictSolution to bank conflictsWith padding (to WRAP_SIZE + 1)Comment se passe la lecture des columns ?Avec le padding, on decale la lecture de 1 (on se decale d‚Äôune banaque). En lisant la 1ere column, on tombe toujours dans une banque differente, evitant ainsi les conflits.Index mapping functionPerformances (GB/s on TESLA K40)Shared memory (summary) Super fast access (almost as fast as registers) But limited resourcesOccupancyStencil PatternUse case: Dilation/erosion Box (Mean) / Convolution Filters Bilateral Filter Gaussian Filter Sobel Filter Il y a une dependance entre les pixelsNaive Stencil ImplemLocal average with a rectangle of radius $r$ (Ignoring border problems for now)Naive Stencil PerformanceSay we have this GPU: Peak power: 1 500 GFlops and Memory Bandwith: 200 GB/sAll threads access global memory 1 memory access for 1 FP addition Requires 1500 x sizeof(float) = 6 TB/s of data But only 200 GB/x mem bandwith $\\to$ 50 GLFOPS (3% the peak) Problem: too many access to global memory Solution: tiling, copy data in shared memory to global memoryHandling Border Add border to the image to have in-memory access Copy tile + border to shared memoryThe bad wayEach thread copies one value and border threads are then idleThe good wayA thread may copy several pixelsStencil pattern with tiling performanceReduction PatternIntuition for reduction pattern Reduction combines every elemet in a collection into one element using an associative operatorReduction pattern: solution 1Est-ce que c‚Äôest correct ?Non, on va avoir des acces concurentiels (data race)Data race Plusieurs parties d‚Äôun programme qui essaie d‚Äôacceder sans ordre predefini a la meme donneeWe need to ensure that each of those read-compute-write sequences are atomic.Atomics reminderAtomics Read, modify, write in 1 operation Cannot be mixed with accesses from other threads On global memory and shared memory Atomic operations to the same address are serializedOperationsReduction Pattern CorrectedAccumulation in global memoryAnalysisTime: 5.619 msCorrect result but high contention on the global atomic variable The execution is actually sequential !Global atomics: is this really parallel ?This version will produce the right result. However, is it really parallel ?How our global atomic instruction is executed: lock memory cell read old value compute new value write new value release the memory cellMemory cell = cache line burstOur kernel generates a lot of collisions on global memoryLeverage Shared MemoryAtomic operations are muchMotivation for output privatizationUsing shared memoryReduction pattern V2: Output privatizationWith syncReduction functions and treesOn peut reduire en parallele plusieurs fragmentsComplexity in steps and operationsThe tree parallel version is: work efficient not resource efficient Average number of thread $((N-1/\\log_2(N))$ ¬´¬†peak requirement ($N/2$) Proof of number of operationsReduction pattern: tree reduction without atomics Use a local sum without atomics Map reduction tree to compute units (threads) Add to a global atomic once for each blockWhat is happening ?The (naive) tree version is slower than the locally sequential versionSp starvationIn each iteration, 2 control flow paths will be sequentiall traversed for each warp Threads that perform addition and threads that do not Threads that do not perform addition still consume execution resourcesResource efficient versionTous les threads vont etre utilise sauf a la fin. On va avoir que des warps actifs, a chaque iterations on libere la moitie des warps.A quick analysisFor a 1024 thread block No divergence on the first 5 steps 1024, 512, 256, 128, 64, 32 consecutive threads are active in each step All threads in each warp either all active or all inactive The final 5 steps will still have divergence Can use warp-level optimization then (warp suffle) Limit global collisionWhat happens with very large input arrays ?Lot of global atomicsHow to avoid this ?Global array, one cell for each block No more locks But requires a second level of reductionMore work per thread Just fire enough blocks to hide latency Sequential reduction, then tree reduction ‚Äúalgorithm cascading‚ÄùAlgorithm cascadingPerform first reduction during the collaborative loading Warning: kernel launch parameters must be scaled accordingly !Last optimizationsLoop unrolling Unroll tree reduction loop for the last warp (less sync needed) Unroll all tree reduction loops (need to know block size) Unroll the sequential reduction loop (knowing the work per thread)Histogram computationMandelbrot practice sessionDuring the practice session, you will have to compute the cumulated histogram of the image. Compute the histogram $H$ Count the number of occurences of each value Computed the cumulated histogram $C$ Inefficient, non-coalesced memory accessFirst sample codeWhat is the issue ?Ajouter un data arrayParallel algorithm using output privatizationLocal histogramInitializationShared memory must be initializedThis can be done with the ‚Äúcomb-like‚Äù pattern We need synchronization after this stageComputationLike previous code, but with local atomics We need synchronization after this stageCommit to global memoryint n = blockDim.x * threadIdx.y + threadIdx.xSummaryPerformance boosters: Coalesced accesses Output privatizationRequirements: atomics synchronizationScan patternWhat is a scan ? Scan computes all partial reductions of a collectionUsage: Integration (cumulated histogram) Resource allocation (memory to parallel threads, camping spots‚Ä¶) Base building block for many algorithms (sorts, strings comparisons)Performance baselinesSequential versionNaive parallel versionHave every thread to add up all x elements needed for the y elementScan pattern at the warp or block levelKogge-Stone Number of steps: $\\log N$ (bien) Ressource efficiency (bien) Work efficiency $\\sim N\\log N$ (pas bien)Brent-Kung Number of steps: $2\\log N$ Ressource efficiency: all warps remain active till the end (pas bien) Work efficiency: $2N$ (bien)Sklansky Number of steps: $\\log N$ Ressource efficiency: bien Work efficiency: $\\frac{N}{2}\\log N$ (bien)Scan Pattern at the Block or Grid LevelThe patterns before can be applied: At the warp level (no sync until Volta) At the block level (thread sync)At the global level: multi-level kernel app in global memory Scan then propagate Reduce then scanScan then propagateReduce then scanSummary" }, { "title": "RSE: Premier cours", "url": "/cours/posts/rse_1/", "categories": "tronc commun S8, RSE", "tags": "tronc commun, S8, RSE", "date": "2021-05-04 14:00:00 +0200", "snippet": "Lien de la note HackmdIntroductionValerie Schneider Conseil et formation pour une performance durable Intervient a l‚ÄôISEP, ECE, EPITA, SUP RH RSE, economie circulaire, numerique responsable Startegie, modeles economiques, sensibilisation, projetDu developpement durable a la RSELe developpement durable Le developpement durable est le developpement qui satisfait les besoins de la generation actuelle sans priver les generations futures de la possibilite de satisfiare leurs propres besoinsRapport Brundtland, 1987Une population en augmentationDes ressources limitees Le 22 aout 2020 est, cette annee, le ‚ÄúEarth Overshoot Day‚Äù (le jour du depassement) Cela signifie que nous avons deja consomme depuis le debut de l‚Äôannee les ressources naturelles que peut fournir la Terre en un anNos reserves de metaux s‚ÄôepuisentUne consommation de biens en augmentationNous possedons de plus en plus d‚Äôobjets, des nouvelles technologies apparaissent et nous voulons en profiter.La fabrication de cette multitude d‚Äôobjets necessite des matieres premieresLa consommation energetique du numeriqueLe changement climatique Le climat se rechauffe et cree un risque pour l‚Äôhumanite et pour les entreprisesLes principaux gaz ‚Äúa effet de serre‚Äù:La biodiversite 1 million d‚Äôespeces menacees d‚Äôextinction, et beaucoup pourraient disparaitre ‚Äúdans les prochaines decennies‚ÄùLes causes de l‚Äôerosion de la biodiversite: La destruction et la fragmentation des milieux naturels (urbanisation) La surexploitation d‚Äôespeces sauvages Les pollutions de l‚Äôeau, de l‚Äôair, des sols L‚Äôintroduction d‚Äôespeces exotiques envahissantes Le changement climatiqueLa RSE, effet de mode ou reelle vague de fond ?La RSE: des concepts du siecle dernierL‚Äôentreprise comme realite societale L‚Äôentreprise influence la societe Elle a une contribution non economique, notamment dans le social Howard R. Bowen Edward Freeman Karl PolyaniHoward R. BowenResponsabilities of the Businessman - 1953 Definition: ‚Äúelle renvoie aux obligations de l‚Äôhomme d‚Äôaffaire de poursuivre telles politiques, de prendre telles decisions ou de suivre telles lignes d‚Äôaction qui sont desirables en fonction des obejctifs et des valeurs de notre societe‚Äù 20 ans apres, il juge idealiste l‚Äôidee d‚ÄôuneEdward Freeman Licence to operate - 1970 Satisfaire les attentes des parties prenantes Business Case: il y a tout interet a engager l‚Äôentreprise dans des demarches volontaires de RSE, parce que c‚Äôest l‚Äôattente des opinions publiques occidentales et parce que les entreprises qui ne s‚Äôy soumettrons pas seront a termes sortie des marchesKarl Polyani (1886 - 1964)L‚Äôentreprise est ‚Äúen marche et en societe‚Äù Se developpe dans un environnement sain, viable et fertile L‚Äôentreprise est redevable a la Societe Assumer les consequences et les risques Re-internaliser les couts supportes par la collectiviteSoutenabilite - la prise de conscienceRSE (CSR en anglais)Definition de la Responsabilitie Societale (ISO 26000)La responsabilite d‚Äôune organisation vis-a-vis des impacts de ses decisions et activites sur la societe et sur l‚Äôenvironnement se traduisant par un comportement transparent et ethique qui: contribue au developpement durable, y compris a la sante et au bien-etre de la societe prend en compte les lois en vigueur et est en accord avec les normes internationales de comportement qui est integre dans l‚Äôensemble de l‚Äôorganisation et mis en oeuvre dans ses relations" }, { "title": "IRGPU: Getting started with CUDA", "url": "/cours/posts/irgpu_getting-started/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-03 14:00:00 +0200", "snippet": "Lien de la note HackmdCUDA overviewWhat is CUDA ?A product It enables to use NVidia GPUs for computationA C/C++ variant Mostly C++ 15 compatible, with extensions and also some restrictions !A SDK A set of compilers and toolchains for various architectures Performance analysis toolsA runtime An assembly specification Computation libraries (linear algebra, etc.)A new industry standard Used by every major deep learning framework Replacing OpenCL as Vulka is replacing OpenGLThe CUDA ecosystem (2021)Libraries or Compiler Directives or Programming Language ?CUDA is mostly based on a ‚Äúnew‚Äù programming language: CUDA C (or C++, or Fortran) This grants much flexibility and performanceBut is also exposes much of GPU goodness through librariesAn it supports a few compiler directives to facilitate some constructsThe big idea: Kernels instead of loops No more for loop !Arrays of parallel threadsA CUDA kernel is executed by a grid (array) of threads All threads in grid run the same kernel code (Single Program Mutliple Data) Each thread has indexes that is used to compute memory addresses and compute decisionsThreads blocksThreads are grouped into thread blocks Threads witihin a bloc cooperate via shared memory atomic operations barrier synchronization Threads in different blocks do not interactA multidimensional grid of computation threadsEach thread uses indices to decide what data to work on:Each index has $x$, $y$ and $z$ attributesGrid and blocks can have different dimensions, but they usually are 2 levels of the same work decompositionExamplesBlock decomposition enable automatic scalabilityArchitectureProgramming modelingBlockA set of threads that cooperate: Synchronisation Shared memory Block ID = ID in a gridGridArray of blocks executing same kernel Access to global GPU memory Sync. by stop and start a new kernelMapping Programming model to hardwarethe SMsZoom on the SM warp: 32 unites de calcul SM organize blocks into warps 1 warp = group of 32 threadsGTX 920: 128 cores = 4 x 32 cores Quad warp scheduler selects 4 warps (TLP) And 2 independant instructions per warp can be dispatched each cycle (ILP) Ex: 1 (logical) block of 96 threads maps to: 3 (physical) warps of 32 threadsZoom on the CUDA cores A warp executes 32 threads on the 32 CUDA cores The threads executes the same instructions (DLP) All instructions are SIMD (width = 32) instructionsEach core: FLoating point &amp;amp; integer unit Fused multiply-add (FMA) instruction Logic unit Move, compare unit Branch unit The first IF/ID of the pipeline is done by the SM SIMT allows to specify the executionThe SIMT Execution Model on CUDA coresSIMT: on programme comme si on avait un thread qui execute une donnees mais ca se cache derriere des instructions SIMD (a + b devient la somme du vecteur a avec le vecteur b) Chaque thread va executer le meme kernel et instructions Divergent code paths (branching) pile up!If/else: tous les threads vont effectuer en meme temps le if et elseIf/elseWhat is the latency of this code in the best and worst case ? Best case: $a\\gt0$ is false for every thread. For all threads: inst-d Worst case: $a\\gt0$ and $b\\gt0$ is true for some but not all threads. For all threads: inst-a, inst-b, inst-c, inst-dLoopsFinal note about terminologyGPU memory modelComputation cost vs. memory costPower measurements on NVIDIA GT200With the same amount of energy: Load 1 word from external memory (DRAM) Compute 44 flops Must optimize memory firstExternal memory: discrete GPUClassical CPU-GPU model Split memory space Highest bandwith from GPU memory Transfers to main memory are slower Intel i7 4770 / GTX 780External memory: embedded GPUMost GPUs today: Same memory May support memory coherence (GPU can read directly from CPU caches) More contention on external memoryGPU: on-chip memoryCache area in CPU vs GPU:But if we include registers: GPU has many more registers but made of simpler memoryMemory model hierarchyHardwareCache hierarchy: Keep frequently-accessed data Core Reduce throughtput demand on main memoru L1 Managed by hardware (L1, L2) or software (shared memory)On CPU, caches are designed to avoid memory latencyOn GPU, multi-threading deals with memory latencySoftwareBuilding and running a simple programWhat you need to get started NVidia GPU hardware NVidia GPU drivers, properly loaded CUDA runtime libraries CUDA SDK (NVCC compiler in particular)Summary Host vs Device $\\leftrightarrow$ Separate memory GPU are computation units which require explicit usage, as opposed to a CPU Need to load data and fetch result from device Replace loops with kernels Kernel = Function computed in relative isolation on small chunks of data Divide the work Compile and run using CUDA SDKHost view of GPU computationSequential and parallel sections We use the GPU(s) as co-processor(s)CUDA memory primitivesWhy 2D and 3D variants ? Strong alignment requirements in device memory Enables correct loading of memory chunks to SM caches (correct bank alignment) Proper striding management in automated fashionHost $\\leftrightarrow$ Device memory transferAlmost complete codeChecking errorsIn practice check for API errorsIntermission: Can I use memory management functions inside kernels ?No: cudaMalloc(), cudaMemcpy() and cudaFree() shall be called from host onlyHowever, kernels may allocate, use and reclaim memory dynamically using regular malloc()Fix the kernel invocation lineWe want to fix this line:Kernel invocation syntax:How to set gridDim and blockDim properly ?Lvl 0: Naive trial with as many threads as possible Will fail with large vectors Hardware limitation on the maximum number of thread per block (1024 for compute capability 3.0-7.5) Will fail with vectors of size which is not a multiple of warp sizeLvl 1: It works with just enough blocksLvl 2: Tune block size given the kernel requirements and hardware constraintsBut wait‚Ä¶ This code prints nothing ! Kernel invocation is asynchronous Host code synchronization requires cudaDeviceSynchronize() because kernel invocation is asynchronous from host perspective.On the device, kernel invocations are striclty sequential (unless you schedule them on different streams)Intermission: Can I make kernels inside kernels ?Yes. This is the basic of dynamic parallelismSome restrictions over the stack size apply.Remember that the device runtime is a functional subset of the host runtime, ie you can perform device management, kernel launching, device memcpy, etc. but with some restrictionsThe compiler may inline some of those calls.Conclusion about the host-only viewA host-only view of the computation is sufficient for most of the cases: upload data to the device fire a kernel download output data from the deviceAdvanced CUDA requires to make sure we saturate the SMs, and may imply some kernel study to determine the best: amount of threads per blocks amount of blocks per grid work per thread (if applicable) ‚Ä¶This depends on: hardware specifications: maximum gridDim and blockDim, etc. kernel code: amount of register and shared memory used by each threadKernel programmingSeveral API levelsWe now want to program kernelsThere are several APIs available: PTX assembly Driver API (C) Runtime C++ API $\\leftarrow$ let‚Äôs use this oneFunction Execution Space Specifiers __global__ defines a kernel function Each __ consists of 2 underscore characters A kernel function must return void It may be called from another kernel for devices of compute capability 3.2 or higher (Dynamic Parallelism support) __device__ and __host__ can be used together __host__ is optional if used aloneBuilt-in Vector TypesThey make it easy to work with data like imagesAlignement mus be respected in all operations They all are structuresThey all come with a constructor function of the form make_&amp;lt;type name&amp;gt;The 1st, 2nd, 3rd and 4th components are accessible through the fields $x$, $y$, $z$ respectivelyBuilt-in variableExampleMemory hierarchyTypes of Memory Registers Used to store parameters, local variables, etc. Very fast Private to each thread Lots of thread $\\Rightarrow$ little memory per threads Shared Used to store temp data Very fast Shared among all threads in a block Constant A special cach for read-only values Global Large and slow Caches Transparent uses LocalSalient features of Device MemoryCost to access memoryVariable Memory Space SpecifiersHow to declaring CUDA variablesRemarks: __device__ is optional when used with __shared__ or __constant__ Automatic variables reside in a registerWhere to declare variables ?Can host access it ? Yes No global and constant, declare outside of any function register and shared, use of declare in the kernel Who can be shared by who ?Possible memory access: Among threads in the same grid (a kernel invocation) Global memory Among threads in the same block Global memory Shared memory Relaxed consistency memory modelThe CUDA programming model assumes a device with a weakly-ordered memory model, that is the order in which a CUDA thread writes data to shared memory or global memory, is not necessarily the order in which the data is observed being written by another CUDA or host threadExamplePossible outcomes for thread 2 ?Memory Fence FunctionsMemory fence functions can be used to enforce some ordering on memory accessesEnsures that: All writes to all memory made by the calling thread before the call to __threadfence_block() All reads from all memorySynch functions Stronger than __threadfence() because it also synchronizes the executionAtomic functions Atomic functions perform a read-modify-write atomic operation on one 32-bit or 64-bit word residing in global or shared memoryMost of the atomic functions are available for all the numerical typeArithmetic functionsDebugging, performance analysis and profilingprintfPossible since Fermi devices (Compute Capability 2.x and higher)Limited amount of lines: circular buffer flushed at particular timesGlobal memory writeTo dump then inspect a larger amount of intermediate dataAnalysis code should be removed for productionExampleCUDA toolsThe complete compilation trajectory" }, { "title": "IRGPU: Introduction", "url": "/cours/posts/irgpu_introduction/", "categories": "Image S8, IRGPU", "tags": "Image, S8, IRGPU", "date": "2021-05-03 10:00:00 +0200", "snippet": "Lien de la note HackmdAgenda GPU and architectures (2h) Programming GPUs with CUDA (2h) TP 00 CUDA (3h) Efficient programming with GPU (2h) TP 01 CUDAGPU and architecturesWhy using GPU ? On veut faire de la programmation rapide.Un programme rapide est un programme qui consomme moins. C‚Äôest important de consommer moins Ex: nos smartphones consomment enormement d‚Äôenergie, avoir des programmes qui consomment le moins possible permet d‚Äôeconomiser la batterieOn est aujourd‚Äôhui dans l‚Äôere du big data, on veut traiter rapidement un tres gros volume de donnees. Sinon on aurait jamais ete capable d‚Äôavoir des techs comme les reseaux de neurones.On veut que les programmes s‚Äôexecutent dans un temps borne. On est pas des gistres‚Ä¶ Mais quand memeOn veut pas une reponse d‚Äô1h avec des systemes critiques embarques (voitures, fusees, etc.)Power Consumption on SmartphonesCPU is a major source of power in smartphones (even with graphical-oriented app) Une bonne partie de la batterie est consommee par le CPU et GPUAujourd‚Äôhui, on essaie de tout transferer sur le GPU car ca consomme moins que le CPUPower Consumption of Some ProcessorsQu‚Äôest-ce qu‚Äôon remarque du prix par Gigaflops ? Le GPU est beaucoup plus rentable que le CPU. Tous les calculs ne sont pas basculables du CPU au GPU.Scientific ComputingA bit of history - The first GPUCe qui a motive la creation des GPU c‚Äôetait la medecine, etc. (meme si le gaming en a prit l‚Äôavantage). Back in 70‚Äôs GPU were for Image Synthesis First GPU: Ikonas RDS-3000 A l‚Äôepoque: tres difficile de programmer en GPU N. England &amp;amp; M. Witton founded Ikonas Graphics SystemsThe first GPGPU General Purpose GPUFirst programmable GPU: Vertex Shaders: programmable vertex transforms, 32-bits float Pipeline graphics Shaders: etapes de la pipeline qu‚Äôon pouvait remplacer A ouvert la voie vers le scientific computic Data-dependent, configurable texturing + register combinersEnabled early GPGPU results: Hoff (1999): Voronoi diagrams on NVIDIA TNT2 Larsen &amp;amp; MacAllister (2001): first GPU matrix multiplication (8-bit) Rumpf &amp;amp; Strzodka (2001): first GPU PDEsGPGPU for physics simulation on Geforce 3Approximate simulation of natural phenomenonGEFORCE FX (2003): floating pointTrue programmability enabled broader simulation research Ray Tracing Radiosity PDE solvers Physically-base simulation FFT (2003) High-level language: Brook for GPU (2004)GPGPU becomes a trend (2006)2 factors for the massive surge in GPGPU dev: Architecture Nvidia G80 Dedicated computing mode - threads rather than pixels/vertices General, byte-addressable memory architecture Software support C and C++ languages and compilers for GPUs (spoiler.. it‚Äôs CUDA) Le graphique a droite veut rien dire (c‚Äôest du marketing)2010‚ÄôsAccelerating discoveries Without GPUs, supercomputer would like 5x more timesAnd data center gave birth to Deep-Learning Les reseaux de neurones existaient deja dans les annees 80 mais on n‚Äôavait pas la puissance de calcul avant 2010‚ÄôsEmbedded systems - The real-time constraintsNeed both of the 2 worlds: Need ultra-performance computing With limited resourcesGPU vs CPU for parallelismHow to get things done quicker Do less work Do some work better (i.e. the one being he more time-consuming) Do some work at the sane time Distribute work between different workers Choose the most adapted algorithms, and avoid re-computing thing Choose the most adapted data structures ParallelismWhy parallelism ? Moore‚Äôs law: processors are not getting twice as powerful every 2 years anymore So the processor is getting smarter Out-of-order execution / dynamic register renaming Speculative execution with branch prediction And the processor is getting super-scalar Executer des choses en meme temps Nos CPUs sont des processeurs super-scalaires Toward data-oritented programmingThe burger factory assembly lineHow to make several sandwiches as fast as possible ? Avoir plusieurs personnes qui travaillent en meme temps sur le meme sandwich et vont executer les taches independantes en meme temps, avoir un worker maitre qui s‚Äôoccupe d‚Äôassembler tout Avoir plusieurs workers qui travaillent en meme temps sur des sandwichs differents Mix entre les 2 strategies precedente: un worker qui peut bosser sur un sandwich ou plusieurs en meme temps Pipeline: un worker fait une etape et passe le sandwich a un autre worker Un worker a plusieurs brasA prendre en compte: La latence Le debitAvec la 1ere strategie:2 cycles optimisation en latence et debit Pas la plus efficace car etape de synchronisationAvec la 2e strategie Optimisation en debit mais pas en latenceAvec la 3e strategie: Tres lourd niveau synchronisationData-oriented programming parallelismFlynn‚Äôs Taxonomy SISD: no parallelism SIMD: same instruction on data group (vector) MISD: rare, mostly used for fault tolerant code MIMD: usual parallel mode (multithreading) SPMT: Single Programm Multiple Thread Execute le meme programme Optimize for latency (MIMD with collaborative workers)4 super-workers (4 CPU cores) collaborate to make 1 sandwich Manu gets the bread and wait for the othersTime to make 4 sandwicches: $s$ (400% speed-up)Optimize for throughtput (MIMD Horizontal with multiple jobs)Time to make 4 sandwiches: s (400% speed-up)Optimize for throughput (MIMD Vertical Pipelining)Optimize for throughput (SIMD DLP) Un seul optimise en latenceMore cores is trendyData-oriented design have changed the way we make processors (even CPUs) Lower clock rate Large vector-size, more vector-oriented ISA More cores (processing units) Parallelisme: SIMDDepuis 2005/2006, on a des ‚Äúfaux‚Äù coeurs pour faire du multi-threadingCPU vs GPU performanceAnd you see it with HPC apps:Towards Heterogeneous ArchitecturesBut don‚Äôt forget, you may need to optimize both latency and throughputWhat is the bounds speedup attainable on a parallel machine with a program which is parallelizable at $P\\%$ (i.e. must run sequentially for $(1-P)$) Utiliser la bonne architecture pour le bon travailGPU vs CPU architecturesIt‚Äôs all about the data‚Ä¶ The CPU: optimized for low-latency access (many memory caches) Control logic for out-of-order and speculative executionIt‚Äôs all about data.. the GPU:Hiding latency with thread parallelism &amp;amp; pipeliningSo‚Ä¶ you want to hide the latency of getting data from from global memory‚Ä¶ how ?1 CPU Core:1 GPU SMP (Streaming Multiprocessor)CPU: low-latency memory to get data ready each thread context switch has a costGPU: memory latency hidden by pipelining context switch is freeLatency hiding: = do other operations when waiting for data = having a lot of parallelism = having a lot of data will run faster but not faster than the peak what is the peak btw ? Peak: Peak de la memoire Donnee par un nombre Peak du compute Nombre d‚Äôinstructions qu‚Äôon peut executer par secondes It‚Äôs all about data‚Ä¶ Little‚Äôs law‚ÄùLa latence est typiquement la longueur de la pipelineHiding latencyWith thread parallelism &amp;amp; pipeliningNote that pipeline exists on CPUs (cycle de Von Neumann)More about forms of parallelism (the why!)More about forms of parallelism (the how!)Pourquoi on a un TLP horizontal sur les CPUs ?MulticoeursPourquoi on a un TLP vertical sur les CPUs ?Les hypercoeurs (coeurs logiques). Ce ne sont pas des vrais coeurs mais des threads capables de switch sur les coeurs.Extracting parallelismParallel architectures and parallelism All processors use hardware to turn parallelsim into performance" }, { "title": "PFEE - Sujet 6.1 et 6.2: Smiths group", "url": "/cours/posts/pfee_smiths/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-30 15:00:00 +0200", "snippet": "Lien de la 1ere note HackmdLien de la 2nd note HackmdSujets 6.1IntroductionPresentation psr Clement Fang Ancien Image 2020Serge Maitrejean Responsable de l‚Äôinnovation Doctorat en physiqueEric Garrido Doctorat en physique nucleaireGroupe Smiths Cote en bourse a Londres 4 divisions Smith detection: scanner et detection Detection de choses illicites ou non-declarees En france: Base a Vitry-sur-Seine A peu pres 200 personnes IA / traitement d‚Äôimage‚Ä¶Les techs au sein de SmithGlobal presenceVehicle, cargo &amp;amp; mobile screeningHigh energy X-ray imagingWhich target / threat we are looking for ?SD Paris Partnerships Epita est cense etre laCigarettes detectionSome big seizures made thanks to our iCmore in the newsiCmore Weapons detectionMore in-depthTruck Radioscopy Imaging with X-Rays but with a scanning principle Pulsed X-ray source: X-Ray pulses (flash) oh three $\\mus$ every 2 or 3 milliseconds One vertical line of detectors/pixels (5 or 20 mm width, 5 mm height): one column of image is recorded for each X-ray pulses Truck speed is limited: &amp;lt; displacement of detector width between 2 pulses (typically 5-7 km/h) Or resolution is bad (large detectors)A new tech: Matrix detector Multicolumn detector (column) Large resolution improvement (Left one line, Right Matrix detector)But noting or nobody is perfect First problem: missing part Easy to solve by slowing down the speed but‚Ä¶ Superposition: le meme point se voit 2 fois The problem of depth at low speed: rearranging data ? The way of ordering data is depending on the depth where objects are located.. But we don‚Äôt know the depth ! It‚Äôs a stereo effectOrdering data is depending on the depth We have to assume where in depth the object are located, if we are wrong strong artifacts appearsTurning a drawback onto an advantage Minimizing the artifacts $\\Leftrightarrow$ Finding the depth of the objects and providing a optimum high resolution imageCurent status Proof of concept has been done using energy minimization technics Work on this approach is pursuing A comprehensive set of data has been acquired from which the ‚Äúexact images‚Äù can be extracted We want to test another approach, neural networks and deep learning are good candidatesThe work Getting familiarized with the problem (not so easy) Getting familiarized with the current method Initating Matrix Detector Deep Learning process for: Building the best radioscopic planar images Finding the depth where objects are located Sujets 6.2IntroductionPresentation psr Clement Fang Ancien Image 2020Serge Maitrejean Responsable de l‚Äôinnovation Doctorat en physiqueEric Garrido Doctorat en physique nucleaireGroupe Smiths Cote en bourse a Londres 4 divisions Smith detection: scanner et detection Detection de choses illicites ou non-declarees En france: Base a Vitry-sur-Seine A peu pres 200 personnes IA / traitement d‚Äôimage‚Ä¶High energy discrimination Same principle as an X-ray It looks like and X-ray but with an X-ray we only have grayscale informationPlus un objet et dense et epais, plus il sera noirWork to doImproving the performance of the material discrimination project by: Better management of the overlay problem Creatin better quality of scansOverlay 2 ojects that overlay make the material detection wrong Find a method to segment the objects, then assign their atomic numberImprove scan qualityCreate a neural network to convert acquisition from low device to highAn AI that assigns the atomic number of objectsCreate a color scale image with only the grayscale imageProvided Reference method Database Script to help for you for your tasks" }, { "title": "PFEE - Sujet 2: IMCCE - Caviar", "url": "/cours/posts/pfee_imcce/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-30 15:00:00 +0200", "snippet": "Lien de la note HackmdImages spatialesReduction astrometriqueexemple dune image ISS-CASSINILogiciel CAVIAR (IDL)Preversion Python" }, { "title": "PFEE - Sujet 3: Projet for event", "url": "/cours/posts/pfee_for-event/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-28 14:00:00 +0200", "snippet": "Lien de la note HackmdPFEE - Sujet 3: Projet for eventFiltres graphiques avances pour des team builiding et animations evenementielles Developpe des jeux digitaux d‚Äôequipe Team building Sur tablette tactile2 applications:E-comicsE-QUESTLes participantsExemples de rendusObjectifsLa tech actuelle" }, { "title": "PFEE - Sujet 7: DXOMARK - Custom QT Video Player", "url": "/cours/posts/pfee_dxomark/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-26 16:00:00 +0200", "snippet": "Lien de la note HackmdIntroductionLaurent Chanas Product owner Partie creation/suivie des mesuresClaudio Ingenieur traitement d‚ÄôimageLoris Software developer pour l‚Äôequipe Analyzer Integration traitement d‚ÄôimageA reference for the press and the industry Score DXOMARK de la camera lors de l‚Äôannonce d‚Äôun nouveau smartphone Grande expertise en traitement d‚ÄôimageRenowned for camera tests and scores for 12 years, DXOMARK also tests audio and displayAnalyzer, the measurement reference solution The reference for reliable image quality evaluation and optimizationA turn-key and modular solutionAnalyse la photo de l‚Äôappareil photo pour trouver des defautsEasy-to-use software Un peu old schoolAnalyzer, a standards compliant solution Important que tous les produits suivent les normesL‚Äôequipe Une equipe hardware Une equipe traitement d‚Äôimage/software Suivi hebdomadaireLe projetContexte du projetAujourd‚Äôhui, il y a plusieurs facon de decoder une video. Il faut determiner la librairie qui correspondL‚ÄôexistantInspiration d‚Äôun logiciel existant Le logiciel doit utiliser du GPUDescription du projet Les demo seront toujours en Python, en utilisant la partie cree en C++Il faut qu‚Äôil y ait quelque chose d‚Äôaboutit a chaque fin de mois, faire une demonstration de quelque chose de fonctionnelleOrganisation du projetPourquoi utiliser du Python ?Beaucoup de mesures dev en PythonQuestionsLe projet est que pour les etudiants ou il y a une equipe ? Que les etudiantsLes attentes: quelles attentes en terme de temps pour un lecteur en C++? On ne nous demande pas de refaire un decodeur video, on utilisera FFMPEG, bonnes inspirations sur des projets existants." }, { "title": "PFEE - Sujet 5: Breast cancer detection - GE", "url": "/cours/posts/pfee_ge/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-23 14:00:00 +0200", "snippet": "Lien de la note HackmdX-ray breast imaging worldwide breast cancer account for $25.2\\%$ of all female cancers and 16% of cancer deaths in adult women mammography uses low-energy X-ray Il faut detecter des lesions tres petites Certaines lesions sont begninesLesionsArtificial intelligence applications AI tools are becoming a must-have for mammography screening systems They can provide significant speed increase of radiologist workflow and more importantly improve quality of their job Possible applications: Negative Triage AI algorithm triage of negative cases in order to allow radiologist to concentrate on more important points AI CAD Detect cancer at very early stages which can not be identified by radiologist Project description Perform analysis of object detection state-of-the-art methods Define model architecture on the example of public dataset Digital Database for Screening Mammography Implement pipeline for model training Perform training and optimization of the modelQuestionC‚Äôest en python ? OuiSi j‚Äôai bien compris le projet est a r√©alis√© depuis le tt d√©but ? Il y a rien de fait ? A deja un prototype, le deep learning se developpe tres vite et veut investiguer des nouvelles propositions" }, { "title": "PFEE - Sujet 1: Mihaly", "url": "/cours/posts/pfee_mihaly/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-23 11:00:00 +0200", "snippet": "Lien de la note HackmdProjet githubAucun travail n‚Äôa ete fait encore, le but est de commencer a coder des shaders.PresentationLouis Image 2021 ‚ÄúLe mec a cheveux longs et aux lunettes‚Äù Le sujet: creer un voxelisateur multi-materiaux Soit Mihaly soit Dassault pour faire du Typescript en stage de fin d‚Äôannee A choisi Mihaly Le projet sera notre projet de A a Z, qu‚Äôon arrive a faire des trucs ou pas Suivi regulier ‚ÄúEn soit on attend rien‚Äù Questions ?Genre ca ca tourne sur Android ? Google mon poteOn est plus sur la cr√©ation des mat√©riaux qui peuvent fonctionner sur des mod√®les √† imprimer plut√¥t que de travailler dans le moteur lui-m√™me si j‚Äôai bien comprit, c‚Äôest √ßa? On nous donne une table de materiaux avec des proprietes physiques, le but est de voir comment on peut passer de l‚Äôun a l‚ÄôautreJe ne comprends pas forc√©ment l‚Äôint√©ret de l‚Äôautomatisation On connait tout un tas de materiaux, on veut savoir si en donnant une liste de proprietes on peut creer le materiel. On voudrait avoir une table exhaustive avec tous nos materiaux et voir si on est capable de dire que tel materiel a telle propriete et etre capable de relier ca avec un materiel qu‚Äôon a deja et creer un shader.C‚Äôest quoi comme genre de materiaux ? Genre des resines qui rendent comme du metal/bois ? Oui, c‚Äôest que de la resine qui rende comme ils veulent. Le but est de modifier la resine pour qu‚Äôelle ressemble a tel ou tel materiel.Est-ce qu‚Äôil peut pr√©senter l‚Äôentreprise? L‚Äôentreprise se porte bien ? Mihaly est une societe qui fait de la numerisation 3D et impression 3D. Ils travaillent aujourd‚Äôhui sur de la reproduction et numerisation de tableauxCarte de Paris avec des details 3DTableau avec les traces de spatule, etc.La boite a uniquement 2 ans.Ils arrivent a faire de l‚Äôimpression sur pleins de materiaux differents (metal, verre, tissu, etc). Ce sont les seuls a faire ca au monde et egalement de l‚Äôimpression 3D en couleurs directement.La boite se porte plutot biem, elle a recemment gagne un concours de Saclay pour les startups les plus innovantes.Quel type de clientele ? Probleme: le produit est tres jeune, le modele economique est pas encore setup (et la crise du Covid). Les cartes de Paris pour les particuliers (qui peuvent y mettre le prix).Le sujet sera encadre ? Encadre par Louis et Christophe (jusqu‚Äôa la fin du stage de Louis pour lui)" }, { "title": "PFEE : Presentation Sujet 4 Zeiss/EPITA", "url": "/cours/posts/pfee_zeiss/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-04-22 14:45:00 +0200", "snippet": "Lien de la note HackmdAvec Daniel Godin, ancien image Simon Franchini, PhD et ingenieurIntroductionAbout Zeiss: Founded in 1849 Leading actor in imaging solutions 30000+ collaborators Represented in 50+ countriesAbout Apeer: Project part of the research for microscopy solutions department Cloud based platform for image analysisEPITA student project ApeerML: automated ML segmentation platform Processed &amp;gt; 100 different use cases in very different domains Constantly improving automation in the development of degmentation algorithmsThe challengeThe taskReduction of memory footprint by separtion and merging within smaller spatial domainProject organization and general setup Project will be divided between Research and Implementation Starts with state-of-the-art review of current solutions Docker image ready with problem statements and Test images Programming language: Python Communication: English Development on private Zeiss Github repo Acces to experts in microscopy and image processing" }, { "title": "Conference IBM: Quantum computing et machine learning", "url": "/cours/posts/conf_IBM/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-22 10:00:00 +0200", "snippet": "Lien de la note HackmdPresentationGeorges Usbelger Advanced Analytics &amp;amp; Quantum Computing Leader Development of Academic / Research RelationsNotre perception de la realite 3 phenomenes importantsSuperposition d‚Äôetat: Exemple: on est dans un cinema et avant de choisir une place, on est sur toutes les places en meme temps. (chat de Schrodinger)En passant a l‚Äôechelle macroscopique, on perd toutes ces proprietes. (decoherence)Intrication:Si on rapproche 2 particules, elles vont echanger des informations et devenir la particule AB. Si une perturbation arrive sur une des particules, peu importe la distance entre les 2 particules, l‚Äôautre particule aura la meme perturbation. (contredit la vitesse max qui est la vitesse de la lumiere)Histoire de l‚Äôordinateur quantiqueA partir de 2016, IBM a pu developper le premier processeur quantique.Information binaireRajouter un Qbits multiplie le nombre de configurations possibles par 2.D‚Äôun point de vue algorithmiqueSi on ecrit un algo capable d‚Äôexploiter les capacites quantique, l‚Äôalgorithme va se ‚Äúdiffuser‚Äù le long des chemins possiblesApplications types d‚Äôevaluation/decision eligibles avec l‚Äôinformatique quantiqueApport de l‚ÄôIA et de l‚Äôinformatique quantique pour la valeur metierApplications eligibles par industrie R&amp;amp;D Molecular Simulation et Quantum Chemistry Material Sciences Banques Risques (Methode de Monte Carlo) Gestion de portefeuilles Energie/Telecom/Transport Sante Defense &amp;amp; securiteElaboration de molecules de syntheseLe qubit et ses proprietesPrincipales portes quantiquesLe qubit et sa representatin sur la sphere de BlochPort de Hadamard Permet d‚Äôengendrer la superposition d‚ÄôetatPort CNOT Permet d‚Äôassocier 2 qubitsLe ‚Äúparallelisme‚Äù quantique C‚Äôest l‚Äôassociation des 2 portes precedentesCriteres de David DiVincenzoTechnologie quantiqueDevelopement Roadmap IBMQuantum volumeIBM is builiding the larger ecosystem to ensure sucessIBM Q experienceIBM Q Quantum ExperienceUne nouvelle ereDu descriptif au prescriptifLa classification non hierarchique de type k-meansLes SVMReseau de neuronesFormations" }, { "title": "Conference Google: Construire des solutions plus intelligentes sans expertise en machine learning", "url": "/cours/posts/conf_google/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-20 14:00:00 +0200", "snippet": "Lien de la note Hackmd Sans expertise en ML != Sans MLIntroWho are we ?Laurent Picard Developer advocate - Google Cloud Ebook pioner Any sufficiently advanced technology is indistiguishable from magic Arthur C. Clarke What is machine learning ?Why is machine learning now possible ?Three ways we can benefit from ML today Ne reiventez pas la roue !Nouveau champ: auto-ML on peut construire nos propres models sans expertiseMachine learning APIReady-to-use modelsVision APIComputer vision before ML:Landmark detection: Capable de determiner ou a ete prise la photo (quel endroit)La photo originale a ete modifiee (symetrie horizontale) Toujours capable de determiner l‚Äôorigine de la photoObject detection:Face detection:Vue 3D de Gollum donc pas un vrai visage humain (mais marche quand meme !)Text detection:Meme avec une legere rotation, on detecte toujours le texteDetecte egalement l‚Äôecriture manuscrite (quelques erreurs)Web entity detection and image matching:La photo ci-dessus de Tolkien est totalement inedite pour l‚ÄôAPI utilisee, capable de reconnaitre Tolkien + determiner que l‚Äôorigine est un journal espagnolOSS Client librariesLibrairies clientes en open-source sur GitHub dans plusieurs langages.Video Intelligence APIDemo:OSS Client librariesNatural Language APIAnalyze text with a simple requestSyntax analysis:Entity detectionContent classificationSentiment analysis: Le ML se plante totalement sur la detection du sarcasme.Translation API Google Translate par exemple! On peut les ameliorer regulierement en fournissant de plus en plus d‚Äôexemples et de contre-exemples.Speech-to-Text APIConvert text to speech in 120 languages with a simple request. Fonctionne en temps reel. Ex: il y a quelques annees repeter a un bot en appelant une banque ‚ÄúJe veux un conseiller‚Äù en esperant qu‚Äôil comprenne.Consequence sympa des reseaux neuronaux: aujourd‚Äôhui les speech-to-text API sont resistants aux bruits car ils apprennent a partir de vrais echantillon.Speech timestamps:Search for text within your audioOSS Client librariesText-to-speech (TTS) APIGenerate natural speech with a simple requestWaveNet natural voices, par Deepmind C‚Äôest le modele le plus avance de tous, qui reproduit le mieux une voix humaine.Demo: ‚ÄúQuelle est la temperature a Paris ?‚Äù avec un accent anglaisTadaaaaaaOSS Client librariesTuto pour generer des voixAutoMLBuild your custom model with no expertiseGeneric results with the Vision APICloud AutoMLDemo:Utilisation de ~250 images en moyennes ‚ÄúJuste‚Äù 3h de calculs.Auto-generate a custom model from your dataUnified in AI PlatformDemoEvaluationTransfert learningHyperparameter tuningConlusionHow can I build smarter solutions ?Liens utiles‚Üí Pr√©sentation‚Üí BD Google AI‚Üí ML codelabs" }, { "title": "Conference Talan", "url": "/cours/posts/conf_talan/", "categories": "Image S8, conference", "tags": "Image, conference, S8", "date": "2021-04-19 14:00:00 +0200", "snippet": "Lien de la note HackmdAnimateurLaurent Cervoni Directeur de la Recherche et de l‚ÄôInnovation du Group Talan Ingenieur de ESIEE Paris Docteur en informatique (IA)TalanSecteurs Energie Service publique Telecom Finance Assurance Transport Industrie RetailImplantations France InternationalDomaines expertisePiliers technologiqueQu‚Äôest-ce que l‚ÄôIA ? C‚Äôest pas magique, c‚Äôest de l‚Äôinformatique.$\\to$ Cloner le cerveau humain/animal Apprentissage Apprend au fil du temps et des donnees Perception Interprete la signification des donnees, notamment le texte, la voix et les images Cognition Aboutit a des conclusions decisives, actions voire interactions Machine learning, une des branches de l‚ÄôIAHistoire de l‚ÄôIAEn 2012: tournant dans l‚ÄôIA, ce n‚Äôest plus de l‚ÄôIA mais de l‚Äôinformatique avancee Les reseaux de neurones reviennent au gout du jourPanorama (subjectif) de l‚ÄôIAIA numerique: IA actuelle Machine Learning: pas que reseaux de neuronesSeparation IA symbolique et numerique un peu fausse: s‚Äôinteresectent beaucoupIA et consommation energetiqueQuel est l‚Äôimpact ecologique de l‚ÄôIA ? Demande energetique importante Le deep learning ca consomme Tres dur de mesurer l‚Äôimpact objectif de l‚ÄôIA dans la conso globaleImpact environnementalIA Inscrire l‚ÄôIA dans une demarche de developpement durable Depuis 5 ou 6 ans deja, les GAFA essaient de rendre leurs propres installations plus ‚Äúvertes‚ÄùNumerique Penurie de ressources (hors energie fossile) Emission de gaz a effet de serre (rutile, mineral de fer, cobalt) Obsolescence Le vrai sujet = les equipements numeriquesLe numerique en exergue L‚ÄôIA ne consomme pas tant que ca par rapport au reste du numeriqueConsommation dans l‚ÄôIAL‚ÄôIA numerique a une activite polluante directe et indirecteCadrage de projet IA: Prendre en compte l‚Äôimpact environnemental et socialIA pour optimiser la gestion centralisee des centres commerciauxKlepierre, un acteur majeure de la gestionAugmenter la production d‚Äôenergie renouvelableOptimiser les reseauxLa data pour l‚ÄôIAGros volume de donneesLa data-isation du mondeBig data, smart data, small dataExplosion de la capacite a gerer les donnees‚Ä¶ avec une recherche de reduction de la puissance CPUTransfert learning Apprentissage supervise uniquement sur la couche de sortieLes ‚Äúformes‚Äù d‚ÄôIA sont multiplesSi on ‚Äúmixe‚Äù les formes d‚ÄôIA, on a une meilleure approche niveau consommation.Conclusions Q&amp;amp;AL‚ÄôIA n‚Äôest pas la seule solution Stockage ADN L‚Äôintelligence artificielle represente une part infime de la consommation electrique mondiale et elle peut contribuer a optimiser les depenses energetiques mais elle doit s‚Äôappliquer a elle-meme la voie de la frugaliteQuestionsPouvez-vous nous parler de votre entreprise et de l‚Äôinter√™t que vous pourriez avoir pour notre √©cole ? Cad en termes de stages ou dans quelles branches recruteriez-vous ? Talan travaille avec Epita/Epitech et recrute des doctorants. Talan va essayer d‚Äôavoir une participation plus active aux cotes de l‚Äôecole (stage/dev). 4 structures: Talan operation, Talan Labs, Talan Solution (recrute profils de l‚ÄôEpita)" }, { "title": "IML: Supervised learning", "url": "/cours/posts/iml_supervised_learning/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8", "date": "2021-04-16 14:00:00 +0200", "snippet": "Lien de la note HackmdSupervised learning Supervised learning: process of teaching a model by feeding it input data as well as correct output data. The model will (hopefully) deduce a correct relationship between the input and output An input/output pair is called labeled data All pairs form the training set Once training is completed, the model can infer new outputs if fed with new inputs.Given some training data ${x_i,y_i}^n_{i=1}$, supervised learning aims at finding a model $f$ correctly mapping input data $x_i$ to their respective output The model can predict new outputs The learning mechanism is called regression or classificationManaging data for supervised learningHide some data out during training ($\\simeq20\\%$ data) to further evaluate model performances $\\Rightarrow$ train/test splitUse validation set ($\\simeq15\\%$ data) if parameters are iteratively adjusted $\\Rightarrow$ tain/validation splitStratified sampling For classification purposesCLasses might be imbalanaced $\\Rightarrow$ use stratified sampling to guarantee a fair balance of train/est samples for each classRegression The art of predicting values Regression: the output value to predict $y$ is quantitative (real number)$\\Rightarrow$ How to mathematically model the relationship between predictor variables $x_i$ and their numerical output $y_i$ ?Linear regressionSometimes, there‚Äôs no need for a complicated model‚Ä¶Ordinary Least SquaresAnscombes‚Äô quartetFor all 4 datasets ${(x_1,y_1),(x_2,y_2),‚Ä¶,(x_{11},y_{11})}$Le 3e regression a une donnee aberrante, cad une donnee tres eloignee des autres qui risque de fausser la regression (probablement du au capteur qui s‚Äôest chie dessus)$\\Rightarrow$ Linear regression line $y=3+0.5x$ and $R^2=0.67$ are the SAME for all 4 datasetsLeast absolute deviationLinear regression by OLS is sensitive to outliers (tj=hank you $L_2$ norm‚Ä¶)Is it a good idea ? $\\beta_{LAD}$ is the MLE estimator of $\\beta$ when noise follows a Laplace distribution No analyticial formula for LAD Harder to find the solution Must use gradient descent approach Solution of LAD may not be unique Toutes les droites dans le cone sont optimalesAdding some regularizationAdd apenalty term to OLS to eforce particular properties to $\\hat\\beta$From regression to classificationLogistic regressionLinear regression predicts a real value $\\hat y$ based on predictor variables $x=(x^{(1)},‚Ä¶,x^(k))$ Does not work is $y$ is boolean $P(y=1)=p$ and $P(y=0)=1-p$ Use logistic regression insteadLinear relationship between predictor variables and logit of event:k-nearest neighborsk-NN classifier simply assigns test data points to the majority class in the neighborood of the test points no real training stepResult:Choosing k small k: simple but noisy decision boundary large k: smoothed boundaries but computationally intensive $k=\\sqrt{n}$ can also serve as a starting heuristic, refined by cross-validation $k$ should be odd for binary classificationk-nearest neighbors for regressionUse the k nearest neighbors (in terms of features only) and average to get predicted valueSupport Vector MachineLinear SVMTraining set: \\(\\{x_i,y_i\\}_{i=1}^n\\) with $x_i\\in\\mathbb R^p$ and $y_i\\in{-1,+1}$Goal: find hyperplane that best divide positive sample and negative samplesQu‚Äôest-ce qu‚Äôon a envie de faire ici ?Une moyenne On cherche la droite qui passe le plus au centre Rappel: produit scalaire de 2 vecteurs colineaires:\\[&amp;lt;\\vec w, \\vec{AB}&amp;gt; = \\Vert \\vec w\\Vert.\\Vert \\vec{AB}\\Vert\\]Soft margin SVMData may not be fully linearly separableKernel SVM Remember the kernel trick ?Kernel trick: map data points into high dimesional space where they would become linearly separable Effortlessly interfaced with the SVM by replacing dot product $&amp;lt;.,.&amp;gt;$ by kernelizes version $k(.,.)$Widely used kernel functions: Polynomial kernel Gaussian RBF kernel Sigmoid kernel Choosing the right kernel with the right hyperparametersKernel $\\Rightarrow$ Try linear first. If does not work, RBF is probably the best kernel choice (unless you have some prior information on the geometry of your dataset)Hyperparameters ($C$ + kernel parameter(s)) $\\Rightarrow$ grid search and cross-validationMutliclass SVMWhat if we have more than 2 classes ?2 possible strategiesone vs all: One SVM model per class $\\to$ separate the class from all other classes Assign new points with winner takes all rule if no outright winner, assign point to the class of closest hyperplane (Platt scaling)One versus one: one SVM model per pair of classes $\\to$ separate 2 classes at a time, ignoring the other data assign new points with majority voting ruleDecision trees Decision trees use recusrive partitioning to create a sequence of decision rules on input features that nested split of data pointsInput features can be numeric (decision $\\le$) or categorical (decision $==$)Decision node $=$ decision rule for one featureClassification tree $\\to$ predict classRegression tree $\\to$ predict real numberOn the current node, try to apply all the possible decision rules for all features and select the decision that best split the dataClassification tree $\\to$ impurity riterionRegression tree $\\to$ variance reductionFinal decision boundaries $\\equiv$ overlapping orthogonal half planesDecision on new data $\\to$ running it down through the branches and assign classesHow to split a nodeWhich split should we choose between La reponse est goche Stop recursive partitionning if node is purePros and cons of decision treesPros Simple decision rules Surprisingly computationally efficient Handle multiclass problems Handle numeric and categorical features at the same timeCons Strongly overfit data Bad predictive accuracy Potential solutionRestrain the growth of the tree by imposing a maximal tree depthRandom forests Bagging several decision treesDecision trees are weak classifiers when considered individually Average the decision of several of them Compensate their respective errors (wisdom of crowds) Useless if all decision trees see the same data introduce some variability with bagging (bootstrap aggregating) Introduce more variability by selecting only $p$ out of $m$ total features for each split in each decision tree (typically $p=\\sqrt{m}$)Final decision is taken by majority voting on all decision tree outputsDecision boundaries comparisonEvaluating regression/classification performancesCross-validation$k$-fold cross validation Divide whole data into $k$ non-overlapping sample blocks Train $k$ models on $(k-1)$ training blocks and test on remaining block Compte perf metrics of each model + avergae &amp;amp; standard deviation of all $k$ modelsConfusion matrix" }, { "title": "OCVX: TD Differentielle", "url": "/cours/posts/ocvx_differentielle_exercices/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-15 10:00:00 +0200", "snippet": "Lien de la note HackmdOCVX: TD Differentielle But de la seance: comprendre les differentiellesRappels Definition premiere de la differentielleUne fonction \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^n \\\\ x=(x_1,...,x_n)&amp;amp;\\mapsto (f_1(x),...,f_n(x))\\end{aligned}\\) est differentiable en un point $x_0$ si on peut ecrire\\[f(x_0+h)=f(x_0)+\\color{red}{d_{x_0}f(h)}+\\Vert h\\Vert\\varepsilon(h)\\] $d_{x_0}f:h\\mapsto d_{x_0}f(h)$ est une application lineaire: $d_{x_0}f(h_1+\\lambda h_2)=d_{x_0}f(h_1)+\\lambda d_{x_0}f(h_2)$Notation: $d_{x_0}f$ / $df_{x_0} / Df(x_0)$$1^{ere}$ maniere de calculer la differentielle$1^{ere}$ maniere de calculer la differentielle en $x_0$ de $f$: ecrire et lineariser \\(f(x_0+h)=f(x_0)+d_{x_0}f(h)+\\underbrace{\\Vert h\\Vert\\varepsilon(h)}_{\\mathcal O_o(h)}\\)$2^{ere}$ maniere de calculer la differentielleSi 1.\\(\\begin{aligned} f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ d_{x_0}f:h&amp;amp;\\mapsto hf&#39;(x_0)\\\\ \\end{aligned}\\)2.\\(\\begin{aligned} f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ d_{x_0}f:h&amp;amp;\\mapsto &amp;lt;\\nabla_{x_0}f, h&amp;gt; = \\nabla_xf^Th\\\\ \\end{aligned}\\\\\\nabla_{x_0}f=\\begin{pmatrix} \\frac{\\partial f}{\\partial x_1}(x_0) \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n}(x_0) \\end{pmatrix}\\)3.\\(\\begin{aligned} f:\\mathbb R^n&amp;amp;\\to\\mathbb R^m \\\\ d_{x_0}f:h&amp;amp;\\mapsto Jac_{x_0}f\\times h\\\\ \\end{aligned}\\\\Jac_{x_0}f=\\text{matrice jacobienne}\\\\[Jac_{x_0}f]_{ij} = \\frac{\\partial f_i}{\\partial x_j}(x_0)\\\\Jac_{x_0}f=\\begin{bmatrix}\\frac{\\partial f_1}{\\partial x_1}(x_0) &amp;amp; \\dots &amp;amp; \\frac{\\partial f_1}{\\partial x_n}(x_0)\\\\\\vdots &amp;amp; \\ddots &amp;amp;\\vdots\\\\\\frac{\\partial f_n}{\\partial x_1}(x_0) &amp;amp; \\dots &amp;amp; \\frac{\\partial f_m}{\\partial x_n}(x_0)\\\\\\end{bmatrix} = \\begin{pmatrix}\\nabla_{x_0}f_i^T \\\\ \\vdots \\\\ \\nabla_{x_0}f_m^T\\end{pmatrix}\\) $f$ differentiable $\\Rightarrow$ existence et continuite des $\\frac{\\partial f}{\\partial x_i}$ Existence et continuite des $\\frac{\\partial f_i}{\\partial x_j}$ $\\Rightarrow$ $f$ differentiableExemple\\[f:(x,y)\\mapsto \\frac{xy}{x^2+y^2}\\quad (x,y)\\neq(0,0); 0\\quad(x,y) = 0\\\\f:(x,y)\\mapsto \\frac{xy}{\\sqrt{x^2+y^2}}\\quad (x,y)\\neq(0,0); 0\\quad(x,y) = 0\\] Fonction ou ca se passe malDifferentielle de 2 fonctions RappelPour des fonctions $f,g:\\mathbb R\\to\\mathbb R$ $(f+\\lambda g)‚Äô=f‚Äô+\\lambda g‚Äô$ $(fg)‚Äô=f‚Äôg+g‚Äôf$ $(f\\circ g)‚Äô(x)=f‚Äô(g(x))\\times g‚Äô(x)$ Pour la differentielle: $d_x(f+\\lambda g)=d_xf+\\lambda d_xg$ $d_x(fg)=g(x)d_xf+f(x)d_xg$ $d_x&amp;lt;f,g&amp;gt;=&amp;lt;d_xf,g(x)&amp;gt; + &amp;lt;f(x),d_xg&amp;gt;$ $\\to$ pas ouf comme ecriture $d_x&amp;lt;f,g&amp;gt;:f\\mapsto &amp;lt;d_xf(h),g(x)&amp;gt; + &amp;lt;f(x),d_xg(h)&amp;gt;$ $d_xg\\circ f=d_{g(x)}f\\circ d_xg$ $\\to$ pas ouf comme ecriture \\[\\begin{aligned} d_xg\\circ f:h&amp;amp;\\mapsto d_{g(x)}f\\circ d_xg(h) \\\\ &amp;amp;=d_{g_x}f(d_xg(h)) \\end{aligned}\\] ExercicesExercice de coursDifferentielle de \\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R \\\\ x&amp;amp;\\mapsto \\frac{\\sin(x)}{x^2+1}\\end{aligned}\\) en tout point $x$ Solution Rappel \\(\\biggr(\\frac{u(x)}{v(x)}\\biggr)&#39; = \\frac{u&#39;(x)v(x)-u(x)v&#39;(x)}{v^2(x)}\\) Seconde methode: Moyen memo technique si(mple) $\\to$ $\\cos$ co(mplique) $\\to$ $-\\sin$ \\[\\begin{aligned}f&#39;(x) &amp;amp; =\\frac{\\cos(x)(x^2+1)-\\sin(x)2x}{(x^2+1)^2}\\\\&amp;amp;=\\frac{(x^2+1)\\cos(x)-2x\\sin(x)}{(x^2+1)^2}\\end{aligned}\\\\d_xf:h\\mapsto hf&#39;(x)\\] Premiere methode (mode bourrin):\\(f(x+h)=\\frac{\\sin(x+h)}{(x+h)^2+1}=\\frac{\\sin(x)\\cos(h)+\\cos(x)\\sin(h)}{x^2+2xh+h^2+1}\\\\\\underbrace{\\frac{\\sin(x)\\cos(h)}{(x^2+1)(1+\\frac{2x}{x^2+1}h+\\frac{h^2}{x^2+1})}}_{\\text{premier terme}} + \\underbrace{\\frac{\\cos(x)\\sin(h)}{(x^2+1)(1+\\frac{2x}{x^2+1}h+\\underbrace{\\frac{h^2}{x^2+1}}_{\\mathcal o(h)})}}_{\\text{second terme}}\\\\\\begin{aligned}\\text{Second terme }=&amp;amp;\\frac{\\cos(x)\\sin(h)}{x^2+1}\\underbrace{\\frac{1}{(x^2+1)(1+\\frac{2x}{x^2+1}h+o(h))}}_{1-\\frac{2xh}{x^2+1}+o(h)}\\quad\\color{red}{\\frac{1}{1+u}\\sim 1-u+o(u)}\\\\&amp;amp;\\frac{\\cos(x)\\sin(h)}{x^2+1}\\biggr(1-\\frac{2xh}{x^2+1}+o(h)\\biggr)\\quad\\color{red}{\\sin(u)\\sim u+o(u)}\\\\&amp;amp;\\frac{\\cos(x)(h+o(h))}{x^2+1}\\biggr(1-\\frac{2xh}{x^2+1}+o(h)\\biggr)\\\\&amp;amp;= \\frac{\\cos(x)(h+o(h))}{x^2+1}-\\underbrace{\\frac{2xh}{x^2+1}\\frac{\\cos(x)(h+o(h))}{x^2+1}}_{o(h)}+o(h)\\\\&amp;amp;= h\\frac{\\cos(x)}{x^2+1}+o(h)\\end{aligned}\\) C‚Äôest que le second terme, on fait pas le premier parce qu‚Äôon a pas envie de crever.Exercice 2-37 Solution 1.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^m &amp;amp;A\\in\\mathcal M_{m,n}(\\mathbb R)\\\\x&amp;amp;\\mapsto Ax+b &amp;amp;b\\in\\mathbb R^m\\end{aligned}\\\\f(x+h)=A(x+h)+b=\\underbrace{Ax+b}_{f(x)} + \\underbrace{Ah}_{\\text{lineaire en }h}\\\\\\begin{aligned}d_xf:h&amp;amp;\\mapsto Ah\\\\d_xf(h)&amp;amp;=Jac_xf\\times h\\end{aligned}\\biggr\\} Jac_xf=A\\] 2.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\quad A\\in\\mathcal M_{n}(\\mathbb R) \\text{ symetrique}\\\\x&amp;amp;\\mapsto x^TAx\\end{aligned}\\\\\\begin{aligned}f(x+h)&amp;amp;=(x+h)^TA(x+h)\\\\&amp;amp;= \\underbrace{x^TAx}_{f(x)} + \\underbrace{x^TAh}_{\\in\\mathbb R} + \\underbrace{h^TAx}_{\\in\\mathbb R} + \\underbrace{h^TAh}_{= (h^TAx)^T=x^TA^Th=x^TAh}\\\\&amp;amp;= f(x) + \\underbrace{2x^TAh}_{d_xf(h)}+\\underbrace{hTAh}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_xf:h&amp;amp;\\mapsto 2x^TAh\\\\d_xf(h)&amp;amp;=2x^TAh = &amp;lt;\\nabla_xf,h&amp;gt; = \\nabla_xf^Th\\\\&amp;amp;\\to \\nabla_xf^T=2x^TA\\\\&amp;amp;\\to \\nabla_xf = 2A^Tx\\end{aligned}\\\\\\] 3.\\[\\begin{aligned}f:\\mathcal M_n(\\mathbb R)&amp;amp;\\to\\mathbb R\\\\X&amp;amp;\\mapsto tr^2(X)\\end{aligned}\\\\\\begin{aligned}f(X+H) &amp;amp;= tr^2(X+H) = (tr(X+H))^2 = (tr(X)+tr(H))^2\\\\&amp;amp;= \\underbrace{tr^2(X)}_{f(X)} + \\underbrace{2tr(X)tr(H)}_{d_Xf(H)}+\\underbrace{tr^2(H)}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_Xf:H&amp;amp;\\mapsto 2tr(X)tr(H)\\\\d_Xf(H)&amp;amp;=\\nabla_Xf^TH=2tr(X)tr(H)\\end{aligned}\\] 4.\\[\\begin{aligned}f:\\mathcal M_n(\\mathbb R)&amp;amp;\\to M_n(\\mathbb R)\\\\B&amp;amp;\\mapsto tr(AB)B\\end{aligned}\\\\\\begin{aligned}f(B+H)&amp;amp;= tr(A(B+H))(B+H) = tr(AB+AH)(B+H)\\\\&amp;amp;= \\underbrace{tr(AB)B}_{f(B)} + \\underbrace{tr(AB)H + tr(AH)B}_{d_Bf(H)} + \\underbrace{tr(AH)H}_{o(h)}\\end{aligned}\\\\\\begin{aligned}d_Bf:H&amp;amp;\\mapsto tr(AB)H + tr(AH)B\\\\d_Bf(H)&amp;amp;=Jac_B(f)\\times H\\end{aligned}\\]Exercice 2-38 Solution\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^n &amp;amp;A\\in\\mathcal M_n(\\mathbb R\\\\X&amp;amp;\\mapsto &amp;lt;\\color{blue}{\\underbrace{AX+b}_{f_1(X)}}, \\color{red}{\\underbrace{tr(A)X}_{f_2(X)}}&amp;gt; &amp;amp;b\\in\\mathbb R^n\\end{aligned}\\] Rappel \\(d_x&amp;lt;f,g&amp;gt;:h\\mapsto&amp;lt;d_xf(h),g(x)&amp;gt; + &amp;lt;f(x),d_xg(h)&amp;gt;\\) \\[d_xf_1:h\\mapsto \\color{green}{Ah}\\\\f_2(x+h) = tr(A)(x+h)=tr(A)x+\\underbrace{tr(A)h}_{d_xf_2:h\\mapsto \\color{orange}{tr(A)h}}\\] Donc:\\[\\begin{aligned}d_xf:h\\mapsto d_x&amp;lt;f_1,f_2&amp;gt;(h)&amp;amp;= &amp;lt;\\color{green}{d_xf_1(h)},\\color{red}{f_2(x)}&amp;gt; + &amp;lt;\\color{blue}{f_1(x)},\\color{orange}{d_xf_2(h)}&amp;gt;\\\\&amp;amp;= &amp;lt;Ah,tr(A)x&amp;gt; + &amp;lt;Ax+b,tr(A)h&amp;gt;\\end{aligned}\\\\d_xf:h\\mapsto &amp;lt;Ah,tr(A)x&amp;gt; + &amp;lt;Ax+b,tr(A)h&amp;gt;\\]Exercice 2-39 Solution 1.\\[\\begin{aligned}g:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\frac{1}{x^Tx+1}\\end{aligned}\\\\\\] Rappel \\(d_xf\\circ g = d_{g(x)}f\\circ d_xg\\\\d_xf\\circ g(h) = d_{g(x)}f(d_xg(h))\\) \\[g(x) = b\\circ a(x)\\\\\\begin{aligned}a:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto x^Tx+1\\\\d_xa:h&amp;amp;\\mapsto 2x^Th \\end{aligned}\\\\\\begin{aligned}b:\\mathbb R&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\frac{1}{x}\\\\d_xb:h&amp;amp;\\mapsto hb&#39;(x) = -\\frac{1}{x^2}h \\end{aligned}\\\\d_xb(h) = -\\frac{1}{x^2}h \\quad d_xa(h)=2x^Th\\\\\\begin{aligned}d_xb\\circ a(h)&amp;amp;=d_{a(x)}b(\\underbrace{d_xa(h)}_{y})\\\\&amp;amp;= d_{a(x)}b(y)\\\\&amp;amp;= -\\frac{1}{(a(x))^2}y\\\\&amp;amp;= -\\frac{1}{(x^Tx+1)^2}y\\\\&amp;amp;= -\\frac{1}{(x^Tx+1)^2}2x^Th\\\\\\to d_xg:h&amp;amp;\\mapsto-\\frac{2x^Th}{(x^tx+1)^2}\\equiv \\biggr(\\frac{1}{u(x)}\\biggr)&#39; = -\\frac{u&#39;(x)}{u(x)}\\end{aligned}\\] 2.\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\cos^2(x^TAx)\\end{aligned}\\\\f(x) = b\\circ a(x)\\\\\\begin{aligned}a:\\mathbb R^n&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto x^TAx\\\\d_xa:h&amp;amp;\\mapsto 2x^TAh\\\\b:\\mathbb R&amp;amp;\\to \\mathbb R\\\\x&amp;amp;\\mapsto \\cos^2(x)\\\\d_xb:h&amp;amp;\\mapsto hb&#39;(x) = -2\\cos(x)\\sin(x)h = -sin(2x)h\\end{aligned}\\\\\\begin{aligned}d_xf(h) = d_xb\\circ a(h) = d_{a(x)}b(\\underbrace{d_xa(h)}_{y}) = d_{a(x)}b(y) &amp;amp;= -\\sin(2a(x))y\\\\&amp;amp;= -\\sin(2x^TAx)y\\\\&amp;amp;= -\\sin(2x^TAx)2x^TAh\\end{aligned}\\]Exercice 3-42On calcule un gradient ou une jacobienne ? Solution Gradient Jacobienne Jacobienne Gradient Gradient Gradient Exercice 3-43$f:\\mathbb R^3\\to\\mathbb R$ differentiable en tout point de $\\mathbb R^3$Soit \\(\\begin{aligned} g:\\mathbb R^3&amp;amp;\\to\\mathbb R \\\\ (x,y,z)&amp;amp;\\mapsto f(x-y,y-z,z-x) \\end{aligned}\\)Montrer que\\[\\frac{\\partial g}{\\partial x}(\\alpha) + \\frac{\\partial g}{\\partial y}(\\alpha) + \\frac{\\partial g}{\\partial z}(\\alpha) = 0 \\quad\\forall \\alpha=(a,b,c)\\in\\mathbb R^3\\] Solution\\[\\begin{aligned}g(x,y,z) &amp;amp;=f(x-y,y-z,z-x)\\\\&amp;amp;=f\\circ u(x,y,z)\\end{aligned}\\] avec \\(\\begin{aligned} u:\\mathbb R^3&amp;amp;\\to\\mathbb R^3 \\\\ (x,y,z)&amp;amp;\\mapsto (x-y,y-z,z-x) \\end{aligned}\\) On vient de voir que\\[d_{\\alpha}g:h\\mapsto d_{\\alpha} f\\circ u(h)=\\underbrace{d_{u(\\alpha)}f(d_{\\alpha}u(h))}_{Jac_{\\alpha}g\\times h=Jac_{u(\\alpha)}f\\times Jac_{\\alpha}u\\times h\\mapsto Jac_{\\alpha}g=Jac_{\\underbrace{u(\\alpha)}_{\\beta\\in\\mathbb R^3=u(\\alpha)}}f\\times Jac_{\\alpha}(u)}\\\\u(x,y,z)=(\\overbrace{x-y}^{u_1}, \\overbrace{y-z}^{u_2}, \\overbrace{z-x}^{u_3})\\\\Jac_{(x,y,z)}u=\\begin{bmatrix} \\frac{\\partial u_i}{\\partial x_j} \\end{bmatrix} = \\begin{bmatrix} 1 &amp;amp;-1&amp;amp;0 \\\\ 0 &amp;amp; 1 &amp;amp;-1 \\\\ -1&amp;amp;0&amp;amp;1 \\end{bmatrix}\\\\\\begin{aligned}Jac_{\\beta}f&amp;amp;=\\nabla_{\\beta}f^T\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x}(\\beta), \\frac{\\partial f}{\\partial y}(\\beta), \\frac{\\partial f}{\\partial z}(\\beta))\\\\Jac_{\\alpha}g&amp;amp;=\\nabla_{\\alpha}g^T \\\\&amp;amp;=(\\frac{\\partial g}{\\partial x}(\\alpha), \\frac{\\partial g}{\\partial y}(\\alpha), \\frac{\\partial g}{\\partial z}(\\alpha))\\\\\\nabla_{\\alpha}g^T&amp;amp;=\\nabla_{\\beta}f^T\\begin{bmatrix}1 &amp;amp;-1 &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp;-1\\\\-1 &amp;amp; 0 &amp;amp; 1\\end{bmatrix}\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z})\\begin{bmatrix}1 &amp;amp;-1 &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp;-1\\\\-1 &amp;amp; 0 &amp;amp; 1\\end{bmatrix}\\\\&amp;amp;= (\\frac{\\partial f}{\\partial x} - \\frac{\\partial f}{\\partial z}, \\frac{\\partial f}{\\partial y} - \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial z}- \\frac{\\partial f}{\\partial y})\\\\&amp;amp;= \\frac{\\partial g}{\\partial x} + \\frac{\\partial g}{\\partial y} + \\frac{\\partial g}{\\partial z} = 0\\end{aligned}\\]" }, { "title": "OCVX: Differentielles (le retour)", "url": "/cours/posts/ocvx_differentielle_le_retour/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-12 10:00:00 +0200", "snippet": "Lien de la note HackmdLa differentielle en TOP-DOWNLa semaine derniere, vous avez cherche a generaliser la notion de derivabilite d‚Äôune fonction $\\phi:\\mathbb R\\to\\mathbb R$ a celle de differentiabilite d‚Äôune fonction $f:\\mathbb R^n\\to\\mathbb R$.Le point de vue aborde: on sait deriver le long d‚Äôun vecteur $v\\in\\mathbb R^n$, cad qu‚Äôon sait deriver la fonction\\[t\\mapsto f(\\overbrace{a}^{\\text{le pt qu&#39;on} \\\\ \\text{cherche a deriver}}+tv)\\]A partir de la on cherche a construire un objet multidimensional qui va remplacer la derivee dans le cas unidimensionnel.On sait deriver une fonction de $\\mathbb R\\to\\mathbb R$ $\\to$ On sait donc deriver une fonction de $\\mathbb R^n\\to\\mathbb R$ le long d‚Äôun vecteur $v$ (en particulier le long des axes).$\\to$ On regroupe les derivees le long des axes dans un objet qu‚Äôon appelle le gradient$\\to$ Definition de la differentielle en un point C‚Äôest la demarche BOTTOM-UPAujourd‚ÄôhuiOn va generaliser la notion de derivabilite d‚Äôune fonction de $\\mathbb R\\to\\mathbb R$ a l‚Äôaide des normes sur $\\mathbb R^n$$\\to$ Analyser ‚Äúl‚Äôobjet differentiel‚Äù qu‚Äôon obtient et decrire une partie des proprietes qu‚Äôil a$\\to$ retrouver les derivees partielles comme ecriture en coordonnnees de la differentielle en un point C‚Äôest la demarche TOP-DOWNRappel sur $\\mathbb R$ Etant donne une fonction $\\phi:\\mathbb R\\to\\mathbb R$ on dit que $\\phi$ est derivable en $a\\in\\mathbb R$ si \\(\\lim_{h\\to a}\\frac{\\phi(a+h)-\\phi(a)}{h}\\) existe. Dans ce cas cette limite est appelee le nombre derivee de $\\phi$ en $a$ et on le note $\\phi‚Äô(a)$De maniere equivalente $\\phi$ est derivable en $a$ s‚Äôil existe un nombre reel $\\alpha$ tel que pour $h$ assez petit (h proche de 0)\\[\\phi(a+h)=\\phi(a)+\\alpha h + h\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\] Dans ce cas $\\alpha$ est le nombre derivee de $\\phi$ en $a$ et on le note $\\phi‚Äô(a)$ Dans $\\mathbb R$: si $\\phi$ est derivable en $a$ alors \\(\\forall h\\text{ assez petit}\\quad \\phi(a+h)=\\phi(a)+\\phi&#39;(a)h+h\\varepsilon(h)\\)Proposition d‚Äôextension au cas d‚Äôune fonction $f:\\mathbb R^n\\to\\mathbb R$f est differentiable en $a$ si\\[\\forall \\underbrace{h}_{\\in\\mathbb R^n}\\underbrace{\\text{ assez petit}}_{\\exists\\eta\\gt0\\text{ tq }h\\in\\mathcal B(0,\\eta)}\\quad f(a+h)=f(a) +\\overbrace{\\lambda_a(h)}^{\\text{lineaire en }h}+ \\Vert h\\Vert\\overbrace{\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}}^{\\text{pas lineaire en }h}\\]$h$ varie de tel sorte a ce qu‚Äôon reste dans la boule $\\mathcal B(0,\\eta)$ Definition: une fonction $f:\\mathbb R^n\\to\\mathbb R$ est differentiable en un point $a\\in\\mathbb R^n$ s‚Äôil existe une application lineaire $\\lambda_a:\\mathbb R^n\\to\\mathbb R$ telle que \\(\\forall h\\text{ assez petit}:\\quad f(a+h)=f(a)+\\lambda_a(h)+\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\quad\\color{orange}{(D_1)}\\) On ne precise pas la norme car elles sont equivalentes.Question: Pour $f$ donne, combien y a-t-il d‚Äôapplications lineaires qui satisfait $\\color{orange}{D_1}$ ?Il n‚Äôy a qi‚Äôune seule, qu‚Äôon appelle la differentielle en $a$. Lemme: Si $\\lambda_a$ existe, elle est unique.PreuveOn suppose qu‚Äôil existe 2 applications lineaires $\\lambda_a$ et $\\mu_a$ qui satisfont $\\color{orange}{(D_1)}$, cad\\[\\begin{aligned}\\forall h\\text{ assez petit}:\\quad f(a+h)&amp;amp;=f(a)+\\lambda_a(h)+\\Vert h\\Vert\\varepsilon_1(h)\\\\-f(a+h)&amp;amp;=f(a)+\\mu_a(h)+\\Vert h\\Vert\\varepsilon_2(h)\\\\\\overbrace{\\underbrace{(\\lambda_a-\\mu_a)}_{\\text{Une app lineaire en }h}}^{\\text{On va montrer que} \\\\ \\text{c&#39;est l&#39;app lineaire nulle}}(h)&amp;amp;=\\Vert h\\Vert(\\underbrace{\\varepsilon_1(h)-\\varepsilon_2(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}})\\end{aligned}\\]On est dans la situation suivante:\\[\\forall h\\in\\mathcal B(0,\\eta)\\text{ pour }\\eta\\gt0\\quad\\underbrace{\\psi}_{\\text{lineaire}}(h)=\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned} \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\]Demonstration: Ma $\\psi$ est nulleOn va prendre un vecteur \\(\\overbrace{v\\in\\mathbb R^n}^{\\Vert v\\Vert=1}\\), soit $t\\in]-\\eta,\\eta[$ (donc $tv\\in\\mathcal B(0,\\eta)$)On a:\\[\\begin{aligned}\\psi(tv)=\\Vert tv\\Vert\\varepsilon(tv)&amp;amp;\\Leftrightarrow t\\psi(v)=\\Vert t\\Vert\\Vert v\\Vert\\varepsilon(tv)\\\\&amp;amp;\\Leftrightarrow signe(t)\\frac{\\psi(v)}{\\Vert v\\Vert}=\\varepsilon(tv)\\end{aligned}\\]Si on se limite a $t\\in[0,\\eta[$, on a $\\frac{\\psi(v)}{\\Vert v\\Vert}=\\varepsilon(tv)$Dans la relation\\[\\forall t\\in[0,\\eta]\\quad \\frac{\\psi(v)}{\\underbrace{\\Vert v\\Vert}_{\\text{constant}}}=\\underbrace{\\varepsilon(tv)}_{\\begin{aligned}\\varepsilon(tv)&amp;amp;\\to0\\\\t&amp;amp;\\mapsto0\\end{aligned}}\\\\\\Rightarrow\\psi(v)=0\\]Etant donne un vecteur $v\\in\\mathbb R^n$, $\\Vert v\\Vert=1$, $\\psi(v)=0$.En particulier, $\\forall i\\in{1,‚Ä¶,n}$; $\\psi(e_i)=0$Donc la matrice de $\\psi$ dans la base canonique est nulle, i.e. $\\psi = 0$ Donc $\\lambda_a=\\mu_a$ Definition: On appelle differentielle de $f:\\mathbb R^n\\to\\mathbb R$ au point $a$, l‚Äôunique application lineaire (si elle existe) qui satisfait: \\(\\color{orange}{D_{abs}}: \\quad f(a+h)=f(a)+Df(a)(h)+\\Vert h\\Vert\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\)Dans ce contexte, $Df(a)$ a une matrice dans la base canonique de taille $(1,n)$Exemple1.On note \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ h&amp;amp;\\to \\underbrace{A}_{A\\text{ est une matrice ligne}}h+n\\end{aligned}\\)\\[\\begin{aligned}f(a+h)&amp;amp;=A(a+h)+b\\\\&amp;amp;= Aa + Ah +b\\\\&amp;amp;=(\\underbrace{Aa+b})+Ah\\\\&amp;amp;=f(a) + \\underbrace{Ah}_{\\text{lineaire en }h} + \\underbrace{o}_{\\Vert h\\Vert\\varepsilon(h) \\\\ \\varepsilon \\text{ est nul la}}\\end{aligned}\\]D‚Äôapres la definition:\\[Df(a)(h) = Ah\\\\Df(a):h\\to Ah\\]2.\\(f:\\mathbb R^n\\to\\mathbb R\\\\x\\to x^Tx\\\\\\begin{aligned}f(a+h)&amp;amp;=(a+h)^T(a+h)\\\\&amp;amp;=aTa+h^Ta+a^Th+\\overbrace{h^Th}^{\\Vert h\\Vert_2\\Vert h\\Vert_2}\\\\&amp;amp;=f(a) +\\underbrace{2a^Th}_{\\text{lineaire en }h} +\\Vert h\\Vert \\varepsilon(h)\\end{aligned}\\\\\\) Definition (rappel): \\(\\Vert h\\Vert_2+\\sqrt{h^Th}\\)Remarque: $h^Ta\\in\\mathbb R$, $(h^Ta)^T=h^Ta\\Rightarrow a^Th^{T^T}=a^Th$ car ce sont des reels. Donc $Df(a):h\\to2a^Th$Dans le cas $n=1$\\[\\begin{aligned}f:x&amp;amp;\\to x^2\\\\D f(a):h&amp;amp;\\mapsto Df(a)(h)\\\\f&#39;(a)&amp;amp;=2a\\end{aligned}\\]Proprietes usuellesLes proprietes usuelles de derivabilites et de calcul des derivees s‚Äôetend au cas des fonctions de $\\mathbb R^n\\to\\mathbb R$. Soient $f,g:\\mathbb R^n\\to\\mathbb R$ et $a\\in\\mathbb R^n$, on suppose $f,g$ differentiable en $a$.\\[\\begin{aligned}\\forall h\\text{ AP}\\quad f(a+h)&amp;amp;=f(a)+D f(a)(h)+\\Vert h\\Vert\\varepsilon_1(h)\\\\g(a+h)&amp;amp;=f(a)+D g(a)(h)+\\Vert h\\Vert\\varepsilon_2(h)\\\\(+):(f+g)(a+h)&amp;amp;=(f+g)(a)+(\\underbrace{D f(a)+D g(a)}_{\\text{lineaire en }h})(h)+\\Vert h\\Vert (\\underbrace{\\varepsilon_1(h)+\\varepsilon_2(h)}_{\\varepsilon(h)})\\end{aligned}\\] \\(D(f+g)(a)=D f(a)+D g(a)\\)\\[(\\times):(fg)(a+h)=(fg)(a) + f(a)D g(a)(h)+g(a)D f(a)(h)\\\\+D f(a)(h)D g(a)(h)+\\\\\\Vert h\\Vert\\varepsilon_1(h)D g(a)(h) + \\Vert h\\Vert\\varepsilon_2(h)D f(a)(h) +\\\\\\Vert h\\Vert^2\\varepsilon_1(h)\\varepsilon_2(h) + \\Vert h\\Vert(\\varepsilon_1(h)g(a) + \\varepsilon_2(h)f(a))\\\\\\color{red}{D(fg)(a)=f(a)D g(a)+g(a)D f(a)}\\\\\\color{orange}{D (fg)(a):h\\to f(a)D g(a)(h) + g(a)D f(a)(h)}\\]Matrice ligneLa differentielle de $f:\\mathbb R^n\\to\\mathbb R$ en $a$ quand elle existe est une matrice ligne: comment en decrire les coeffs ? Definition(temporaire): Quand $f$ est differentiable au point $a$ on appelle gradient de $f$ en $a$ le vecteur $v$ (colonne) $\\nabla f(a)$ dont la transposee est la marice de $Df(a)$ dans les bases canoniquesOn a donc: pour tout $h$ assez petit\\[f(a+h)=f(a)+\\nabla f(a)^Th+\\Vert h\\Vert \\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\]On est interesse par calculer $\\nabla f(a)^Te_i$ $\\forall i\\in{1,‚Ä¶,n}$Soit $t\\in\\mathbb R$\\[f(a+t_{e_i})=f(a)+\\nabla f(a)^T(te_i)+\\Vert te_i\\Vert\\varepsilon(te_i)\\\\\\Leftrightarrow f(a+t_{e_i})-f(a)=t\\nabla f(a)^Te_i+\\Vert te_i\\Vert\\varepsilon(te_i)\\\\\\frac{\\Leftrightarrow f(a+t_{e_i})-f(a)}{t}=\\nabla f(a)^Te_i+\\Vert e_i\\Vert\\varepsilon&#39;(te_i)\\quad t\\neq0\\\\\\Leftrightarrow\\nabla f(a)^Te_i=\\underbrace{\\frac{f(a+te_i)}{t}}_{\\to_{t\\to 0}\\delta e_if(a)=\\frac{\\delta}{\\delta x_i}f(a)}-\\underbrace{\\Vert e_i\\Vert\\varepsilon&#39;(te_i)}_{t\\to0 \\\\ \\to 0}\\]En prenant la limite on vient de constater (avec la definition temporaire de $\\nabla f(a)$) que $\\nabla f(a)^Te_i=\\frac{\\delta}{\\delta x_i}f(a)$Cad que la ieme coordonnee de votre gradient c‚Äôest la derivee partielle par rapport a $x_i$ Defintion: Le gradient d‚Äôune fonctino $f$ en un point $a\\in\\mathbb R^n$ c‚Äôest le vecteur $v$ des derivees partielles:\\[\\nabla f(a)=\\biggr(\\frac{\\delta f}{\\delta x_i}(a)\\biggr)_{1\\le i\\le n}\\] Les definitions ‚Äútemporaire‚Äù et definitives de gradient ne sont pas equivalentes: on peut admettre des derivees partielles sans etre differentiable Prop: Si une fonction $f:\\mathbb R^n\\to\\mathbb R$ admet un gradient en un point $a$, et si $x\\to\\nabla f(x)$ est continue au voisinage de $a$, alors $f$ est differentiable en $a$, cad qu‚Äôon peut ecrire \\(\\forall h \\text{ assez petit}\\\\f(a+h)=f(a)+\\nabla f(a)^Th+o_a(h)\\)Remarque: si $f$ est differentiable en $a$:\\[\\underbrace{\\delta_v f(a)}_{\\color{red}{\\text{derivee directionnelle de } f\\\\ \\text{en } a \\text{ le long de } v}}=\\nabla f(a)^Tv\\]Derivee d‚Äôune composeePour parler de composee on va generaliser un petit peu le cadre avec lequel on a travaille jusque la.On s‚Äôinteresse donc aux fonctions\\[f:\\mathbb R^n\\to\\mathbb R^n\\]On note $f_1,‚Ä¶,f_n$ les fonctions coordonnees de $f$, $f=(f_1,‚Ä¶,f_n)$Exemple\\[\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R^3\\\\(x,y)&amp;amp;\\mapsto \\begin{pmatrix}\\cos(xy) \\\\ x^2+y \\\\ 2y\\end{pmatrix}\\\\g_1:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto \\cos(xy)\\\\g_2:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y\\\\g_3:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto 2y\\\\\\end{aligned}\\]Une fonction $f:\\mathbb R^n\\to\\mathbb R^m$ va etre dite differentielle si on a une ecriture:\\[f(a+h)=f(a)+\\underbrace{Df(a)}_{\\text{differentielle de } f\\\\ \\text{en } a,\\text{de matrice}\\\\ \\text{dans les bases canoniques}\\\\ \\text{de taille: }(m,n)}(h)+\\underbrace{\\Vert h\\Vert}_{\\text{une norme sur }\\mathbb R^n}\\underbrace{\\varepsilon(h)}_{\\begin{aligned}\\varepsilon:\\mathbb R^n&amp;amp;\\to\\mathbb R^m \\\\ \\varepsilon(h)&amp;amp;\\to0\\\\h&amp;amp;\\mapsto0\\end{aligned}}\\] La matrice de $\\lambda f(a)$ dans les bases canoniques est appellee la jacobienne de $f$ en $a$. \\(J_f(a)=\\begin{pmatrix}\\frac{\\delta f_1(a)}{\\delta x_1}&amp;amp;\\dots &amp;amp;\\frac{\\delta f_1(a)}{\\delta x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\delta f_m(a)}{\\delta x_1}&amp;amp;\\dots &amp;amp;\\frac{\\delta f_m(a)}{\\delta x_n}\\\\\\end{pmatrix}\\\\=\\begin{pmatrix}\\nabla f_1(a)^T\\\\\\vdots\\\\\\nabla f_m(a)^T\\end{pmatrix}\\\\= (\\nabla f_1(a),...,\\nabla f_m(a))^T\\\\\\)Pour $f:\\mathbb R^n\\to\\mathbb R^m$ si on est differentiable en $a\\in\\mathbb R^n$On a $\\forall h$ AP:\\[f(a+h)=f(a)+J_{f}(a)h+o_a(h)\\]Question:Soit $f,g$, $f:\\mathbb R^n\\to\\mathbb R^m$, $g:\\mathbb R^m\\to\\mathbb R^p$, si $f$ et $g$ sont differentiable respectivement $f$ en $a$ et $g$ en $b=f(a)$ alors\\[D(g\\circ f)(a)=D g(\\color{red}{f(a)})\\circ D f(\\color{red}{a})\\]Matriciellement:\\[J_{g\\circ f}(a) = J_g(f(a))\\times J_f(a)\\]" }, { "title": "IMED: L&#39;imagerie par resonance magnetique (IRM)", "url": "/cours/posts/imed_irm/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-09 14:00:00 +0200", "snippet": "Lien de la note HackmdIMED: L‚Äôimagerie par resonance magnetique (IRM)Les bases de l‚ÄôIRMOn qualifie la densite du champ magnetique par des Tesla, entre 1,5 et 3 Tesla (par comparaison, le soleil est a moins de 1 Tesla)Principe physique de l‚ÄôIRM1933: Otto Stern (55 ans) mesure le moment magnetique du protonEntre 1938-1946: on observe les premiers spectres RMN, on decouvre le phenomene de resonnance magnetique interaction entres 2 ondes ayant la meme frequence effet boule de neige Ex: les militaires marchants en pas cadences, qui ne peuvent pas traverser des ponts sous risque de ruptureBeaucoup de prix Nobel associes ! Mais‚Ä¶ on parle de quoi en fait ?Un proton a un spin, il dessine un cone lors de sa rotation.On a une composante horizontale et verticaleChaque proton est oriente dans un sens propreLa resultante de toutes ces forces = 0Imaginons on applique un champ magnetique $B_0$ Les protons s‚Äôalignent dans le sens de $B_0$Certains protons sont paralleles a $B_0$, d‚Äôautre anti-paralelles (parallele et dans le sens inverse)Si on applique des ondes de radio frequences (generalement perpendiculaire), tout le monde va se tourner dans le meme sens et tourner en meme temps (tourner en resonance)On a une composante magnetique et une onde radio On mesure les ondes ‚Äúliberees‚Äù et le temps necessaire a nos protons pour revenir a leur etat initial (non-initie)La decouverte 1933: Stern demontre que le proton possede un moment magnetique 1945: les premiers spectres de RMN 1971: Damadian a l‚Äôidee d‚Äôutiliser la RMN pour realise une image de tissu biologique 1977: Lauterbur reprend les principes de calcul des images du scanner pour creer une image medicale a partir du signal RMN des tissus Le nom d‚ÄôIRM n‚Äôa ete donne que plus tard a la RMN car le terme ‚Äúnucleaire‚Äù inquietait le publique Passer une IRM n‚Äôest pas nocif, contrairement a un scanner.L‚ÄôevolutionImages en coupe multiplanaireImage anatomie: on a decoupe quelqu‚Äôun en morceaux (oui oui c‚Äôest pas une blague‚Ä¶) Fallait pas etre condamne a mort quand on a commence a faire des dissections/vivisections (le corps finissait souvent decoupe par la science, peu importe les dernieres volontes)Image multiparametriqueParametres de l‚ÄôIRMLa morphologie du signal emis par des protons depend essentiellement du temps (appele temps de relaxation) que ceux-ci mettent a revenir dans l‚Äôaxe de l‚Äôaimant (temps n$^o$ 1 ou T1) et du temps qu‚Äôils mettent a se dephaser de nouveau (temps n$^o$ 2 ou T2)T1: SB blanche, SG grise, LCR en hyposignalT2: l‚Äôinverse !Les evolutionsSequences rapides: IRM dynamiqueIg Nobel: prix nobel pour des trucs debilesA droite: kecece ?: on est 9 mois avant un accouchement Il y a 2 colonnes vertebralesAngio-IRM IRM pour les veines et les arteres avec du liquide de contraste On a la difference entre plusieurs TeslaBilan Base sur les proprietes magnetiques des molecules d‚Äôeau Champ magnetiqueArtefacts Il y a pas mal de mouvement a l‚Äôinterieur du corps Susceptibilite magnetique Certaines zones sont plus sensibles que d‚Äôautres Varie en fonction des personnes Aliasing/troncature Gibbs Meme problematique que le traitement du signal classique Deplacement chimique Notre sang qui fait son taf par exemple L‚ÄôIRM de diffusion Meme pricinpe que l‚ÄôIRM de baseL‚ÄôIRM fonctionnelle Visualise les zones du cerveau activees par stimulus Echange de l‚Äôoxygene entre le sang et les neurones modifient le signal Rehausse les zones d‚Äôactivite du cerveau" }, { "title": "IMED: Les Rayons X", "url": "/cours/posts/imed_rayons_x/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-09 10:00:00 +0200", "snippet": "Lien de la note HackmdLes os apparaissent !La decouverteUne nouvelle forme de matiere 1838: Faraday s‚Äôinteresse aux decharges electriques dans les gaz rarefies Appareil de Faraday: cathode et anodee dans un tube en verre. Quand la cahode recoit de la tension, cela provoque une etincelle Variation de pression dans le gaz: l‚Äôetincelle se transforme en emanation violette si la pression diminue Quatrieme etat de la matiere nomme ‚Äúmatiere radiante‚ÄùLes rayons cathodiques $XIX^e$s: experience reprise mais reste incomprise Plucker observe qu‚Äôune augmentation de la pression dans le tube n‚Äôentraine plus qu‚Äôune fluorescence verte sur certaines parois du tube, en face de la cathode En 1869, son eleve Hittorf decouvre des rayons qui se propagent en ligne droite depuis la cathode (mise en evidence a l‚Äôaide d‚Äôune crois metallique face a la cathode) Ces rayons sont nommes les rayons cathodiques Crookes perfectionne le tube en verre Thompson decouvre l‚Äôelectron en 1897Une decouverte due au hasard‚Ä¶.1895: Wilhelm Rontgen etudie le rayonnement cathodique avec des tubes de Crookes. Le 8 novembre, il decouvre un truc‚Ä¶ Experience: il met le tube de Crookes dans du carton noir Resultat: une plque de platinocyanure de baryum a cote du tube devient fluo, et reste fluo une fois ecartee.Il intercale des objets entre l‚Äôampoule et la plque, la fluorescence reste Il nomme ce rayonnement les ‚ÄúRayons X‚Äù (comme tout bon mathematicien qui a une inconnue‚Ä¶)Proprietes Faiblement absorbes par la matiere Diffuses par la matiere Origine du rayonnement fluo Impressionnent une plaque photo Dechargent les corps charges electriquement Si on met la main devant, on peut voir les os et les tissus apparait sur la plaque Tout premier cliche en Rayon X On peut voir que les bagues restent La premiere radio dentaire au monde !L‚Äôexplosion de la radiographieEn medecineEn medecine de guerreMarie Curie a concu 18 voityres radiologiques et installe 250 postes fixes de radio dans les hopitauxAujourd‚Äôhui nos os sont blancs et fond noir, a l‚Äôepoque c‚Äôetait l‚Äôinverse. Plus ca traverse, plus c‚Äôest blanc. Aujourd‚Äôhui, nos radios numeriques sont le negatif de nos radios originales.Au douanesA l‚Äôepoque on le faisait aussi pour les gens et pas seulement les valises.Dans les grands magasinsEn particulier les magasins de chaussures pour montrer qu‚Äôelle nous va parfaitement.Ou meme comme spectacle !Les gens se faisait bombarder de Rayons X et radiations, pas fifou‚Ä¶Effet therapeutiqueOn se disait que ca marchait contre les migraines au bout de 15 min d‚Äôexposition (il n‚Äôy avait surtout plus beaucoup de tissus vivants mais bon‚Ä¶)On utilisait quand meme les rayons X contre les cancers, ce qu‚Äôon fait toujours aujourd‚Äôhui (pour bruler la tumeur). Probleme: ca crame tout sur son passage. De nos jours, on fait ‚Äútourner‚Äù les rayons pour qu‚Äôils se croisent au niveau de la tumeur. Donc a l‚Äôepoque, ils savaient que ca cramait des tumeurs mais pensaient pas que ca cramait le cerveau ? (Oui mes c‚Äôest des doses differentes, ca paaaassse)Effets biologiqueNovembre 1896: Premier article ‚Äúles mefaits des rayons X‚Äù. Le temoi a ete demonstrateur en rayons X pendant l‚Äôete a Londres. On abuse pas des mammographies car ca risque de declencher des cancer (le diagnostic qui cause la maladie, c‚Äôest balot‚Ä¶) Si une femme doit absolument passer une radio, on lui met un ‚Äútablier‚Äù en plomb pour eviter au plus les radiatoinsLa fluoroscopieLa radiographie Repose sur l‚Äôutilisation de rayons X Les rayons traversent les tissus de maniere plus ou moins important selon leur densite Fonctionne a l‚Äôaide d‚Äôune source emettrice et d‚Äôune plaque de detection La quantite de photons atteignant la plaque ‚Äúdessine‚Äù les tissus Pas de champs magnetique Dangereux a haute dose L‚Äôavenir des rayons X, c‚Äôest d‚Äôetre de moins en moins nocifs pour les humains tout en gardant la qualite de l‚ÄôimageAgiographieInjection d‚Äôun liquide de contraste, qui permet de verifier l‚Äôecoulement du sang.Le scanner Ca serait cool de pouvoir faire du 3DLa decouverteLes appareils On a reussi a ameliorer la resolution avec les acquisitions spiralees.L‚ÄôevolutionAu gauche: premier scanner cerebralImagerie multiplanaire Il n‚Äôy a pas tant de differences entre la matiere grise et la matiere blancheReconstruction tomographiqueBilan Repose sur l‚Äôutilisation de rayons X Les rayons traversent les tissus de maniere plus ou moins importante selon leur densite Le capteur et l‚Äôemetteur effectuent une rotation autour du corps" }, { "title": "IMED: Histoire et enjeux", "url": "/cours/posts/imed_hisoire_et_enjeux/", "categories": "Image S8, IMED", "tags": "Image, IMED, S8, histoire, imagerie medicale", "date": "2021-04-08 14:30:00 +0200", "snippet": "Lien de la note Hackmd Histoire de l‚Äôimagerie medicale Formats, problemes et interetHistoire de l‚Äôimagerie medicaleQuelle medecine a l‚Äôeqoque prehistorique ?Pas d‚ÄôIRM ou de radio, mais deja des notions de medecine a l‚Äôecole (bah oui, on etait deja malade a l‚Äôepoque‚Ä¶) Pathologies de l‚Äôepoque caries fractures maladies virales et bacterienne migraines etc. Notions de soins par les plantes Usage externe et interne Grosse influence des coyances/spiritualites Role important du Chaman A l‚Äôepoque, on avait l‚Äôecorce de saule, cad l‚Äôaspirine L‚Äôobservation est la premiere source de savoir. Des connaissances plus poussees qu‚Äôon ne le pense‚Ä¶ Maitrise de coutures et tests de soins dentaires Maitrise des notions de fractures Ateles en bois et immobilisation du membre Notions de ‚Äúchirurgie‚Äù Survie aux trepanations (meme si leur raison reste flou) Trepanations: trou dans le crane Le trou est ‚Äúlisse‚Äù, cad que la personne est restee en vie assez longtemps pour que ca cicatrise La transmission des savoirs se fait de generations en generationsLa medecine durant l‚ÄôantiquiteMesopotamie1750 avant JC: texte de loi sur la medecine et la chirurgie: Mise en place de protocole medical d‚Äôauscultation en melant medecine et religion (‚Äúdouleur ? mensonge ?‚Äù etc.) On sait analyser l‚Äôhalene, l‚Äôurine, prendre le pouls et la temperature On ne sait pas encore le role du coeur Avec l‚Äôurine on detecte le diabete Urine sucree (pour certains types de diabete) La creation du Fanta Remedes a la base de prieres et de plantes (sirops, onguent, etc.) On sait soigner les fractures: ateles et chirurgie Partage du savoir avec un bibliotheque regroupant tous les ecrits medicauxPar contre, se faire soigner coute tres cher !EgypteLe papyrus Edwin Smith, 1500 avant JC, est le premier document ecrit parlant de traitement chirurgicaux (fractures, plaies, ecrasements, etc.) Il s‚Äôagirait en realite d‚Äôune copie Aspect pratique des traumatismes: sans le cote magique !750-332 avant JC, la medecine redevient religieuseMise en place d‚Äôun systeme medical complexe avec la hierarchie public et gratuitGreceAu $VII^e$s avant JC, les medecins sont sedentaires, restent dans les cites Leurs statuts varient Certains sont fonctionnaires Visites a domicile ou chez le medecin Pythagoriens: c‚Äôest le cerveau qui dirige Dissections sur des animaux (interdit sur l‚Äôhomme) Hippocrate divin $\\neq$ maladie compilation de toutes les informations medicales de l‚Äôepoque apport d‚Äôune procedure, d‚Äôune ethique, de diagnostic theorie des humeurs La lymphe La bile noire Le sang La bile blance Empire RomainA Rome, la medecine est mal consideree jusqu‚Äôau $II^e$s avant notre ereDeveloppement par la suite: notoriete des medecins, reunions de medecins, corporations, etc. suite a l‚Äôarrivee des medecins grecques.Premier proctologues, avec le doux nom de berger de l‚Äôanus :) Premiere specialisationsInstitutions militaires = gros developpement de la medecine. Hopitaux autour de jardins medicaux Jardins contenant des plantes medicinales Hygiene: separation des salles Separation salle d‚Äôattent/salle de chirurgie/morge/etc. les outils bouillis Galien pose les bases de la medecine occidentaleLe Moyen-AgeMedecine occidentaleLa medecine au Moyen-Age en occident connait un recul en arriere suite a la chute de l‚Äôempire romain Pertes de connaissances ecrites Pas de traductions existantes Soigner des gens avec des plantes au Moyen-Age = sorcieres Retour de la medecine mystico-religieuse Melange des traditions et croyances Diktats des textes religieux Les moines sont les garants des textes ecrits, et donc sont les medecins.Les plantes medicinales sont dans les jardins des monastere (et liqueurs de plante aussi‚Ä¶)Medecine orientale La medecine arabe, elle, est en plein essort‚Ä¶ Elle se base sur les textes d‚ÄôHippocrate et Galien Nombreuses avancees $XI^e$s en occident Traduction des ecrits arabes mais perte d‚Äôinformation jusqu‚Äôa la fin du $XIII^e$s Ecole de medecine (Salerne) En France, il faudra attendre 2 siecles de plus pour ouvrir une universite de medecine Au $XIV^e$s, la dissection est autorisee dans les ecoles Theories de Galien sont remises en cause au milieu du $XIV^e$s‚Ä¶La peste au Moyen AgeLa peste, la maladie emblematique des pandemies meurtrieres du Moyen-Age, est restee un mystere pour les gens de l‚ÄôepoqueMeconnaissance et croyancesChretiens et Musulmans pensent que la peste est une punition divine. processions, prieres, etc. pour tenter d‚Äôendiguer l‚ÄôepidemieCette pandemie est originaire d‚Äôun siege Mongol a Constantinople, en catapultant des cadavres morts de la peste sur la ville. Les habitants ont fui et ont propage la peste PARTOUT. Pareil que les parisiens qui se barrent durant le 1er confinement avec le coronaOn accuse les lepreux, les juifs, les etrangers, les sorcieres‚Ä¶ bref on accuse tout le monde d‚Äôetre des vecteurs de la peste (meme si le Pape rejette ces accusations!) Probleme: peu d‚Äôincineration car contraire a la religion !Qu‚Äôest-ce que la peste ?Bacterie: Yersinia pestis, indentifiee en 1894 par Alexandre YersinLes rongeurs sont un reservoir naturel, et les puces sont un vecteur.3 formes: bubonique, pulmonaire et septique.Les medecins ne savent tout simplement pas ce qu‚Äôest ce fleau. La peste est considere comme un ‚Äúpoison‚Äù.Les traitements habituels de l‚Äôepoque: saignee, transpiration, incision du bubon, lavements, etc. La seule methode qui semble porter ses fruits pour eviter une propagation est‚Ä¶ la quarantaine. (ou confinement pour l‚Äôactualite)3 niveaux de quarantaine: quarantaine a domicile les malades n‚Äôont pas le droit de sortir de chez eux mais leur famille peuvent lieux d‚Äôisolements hopitaux specifiques pour les malades toujours de la contamination car les malades ont touche des trucs chez eux et contamine leur famille expulsion des malades hors des villes Oh bah ca marche ! Remaniement social important: passe du moyen age a l‚Äôepoque moderne.La fin du Moyen-Age A partir du $XII^e$ Moines-medecins: uniquement dans les campagnes (sur papier) Creation d‚Äôhopitaux Peste noire: 2 courants de pensees helleniste arabisant A partir du $XV^e$ Ecoles d‚Äôanatomie De plus en plus de decouvertes Andre Vesale: hors Eglise, grosse liberte Les $XVII^e$ et $XVIII^e$ siecles Vivisection sur des animaux Dissection mais sur des animaux‚Ä¶ vivants. Decouverte du role du corps par William Harvey en 1628 Theorie de la circulation du sang enseignees dans les ecoles francaises Invention du microscope Debuts de la microbiologie Apparition de la variolisation en Europe Ancetre de la vaccination A injecte la variole de vache dans quelqu‚Äôun, cette personne a ete immunisee contre la variole humaine Pensait que ca marchait que pour la variole Louis Pasteur fait le lien entre maladie et microorganismesLa medecine au $XIX^e$ siecle Professionnalisation des medecins (internat, diplome) Cours d‚Äôanatomie se developpent Evolution chirurgicales importantes Naissance des procedures d‚Äôauscultations des patients Les hommes commencent a arriver dans l‚Äôobstetrique et la gynecologie Premieres maternites mais mortalite plus importante qu‚Äôa la maison Meurent toutes a la maternite d‚Äôune forme de fievre Un homme meurt de la meme maladie suite a une dissection dans une morgue Decouverte d‚Äôun lien entre passer directement de la salle d‚Äôaccouchement depuis la morgue A commence a se laver les mains entre 2, chute drastique du taux de mortalite des femmes a la maternite La toute premiere image medicale1897: Installation du premier service de radiologieL‚Äôevolution de la medecine$XX^e$ siecle Premieres machines de visualisation de l‚Äôinterieur du corps Connaissances sur les micro organismes, infections, etc. Decouverte de la peniciline Deja connue avant le $XX^e$ siecle avant par les bergers Un berger a decide un jour de se mettre de la moisissures de Rocquefort sur une plaie infectee ‚Ä¶ Et ca marche! La moisissure de Rocquefort et la peniciline sont de la meme famille Developpement des medicaments Developpement de toutes les techniques d‚Äôimgerie Il serait impossible de commercialiser l‚Äôaspirine si elle etait decouverte aujourd‚Äôhui car elle cree des tumeurs chez les souris En un siecle, les principales techniques d‚Äôimagerie anatomiques ont ete developpees et sont toujours utilisees aujourd‚Äôhui (et ameliorees)Une acceleration Echographie 4D: 3D+t (video en 3D) Ne sert techniquement a rien a part faire plaisir aux parents N‚Äôapporte rien medicalement parlant Formats, problemes et interetPrincipe generalTout ce qui est ‚Äúa droite‚Äù de la lumiere visible sont mauvais pour le corps humain (Radiographie, Imagerie Nucleaire). N‚Äôallez pas mettre votre tete dans un micro-onde Pour savoir ce qui est bon ou non, voir ce qui est bon pour les femmes enceintes.Format: Qu‚Äôest-ce qu‚Äôune image ? D‚Äôapres les cours de Maxime DescoteauxLe plus important:Formats: Grr‚Ä¶ Pas de standard et normalement, on insulte tous les dieux quand on s‚Äôy met Effort de la communaute mrtrix nibabel (les 2 sont des package python) Un format ? Non.En imagerie medicale, il y a une infinite de formats differents‚Ä¶Les plus connus: .dcm DICOM .nii NIFTI .hdr .img Analyze .ima .dim Gis (France) .mnc Minc (Montreal Neurological Institute (MNI)) .nrrd Nrrd (USA) .mhd Beaucoup de soucis en perspective‚Ä¶Des problemes ? Oui. Spoiler: imread(monimage.XXX) ne marche pas!Il faut des bibliotheques speciales pour pouvoir les ouvrir.Quelques bibliotheques python: medpy, nibabel‚Ä¶A la base, une bonne idee: une image = un header et des donnees‚Ä¶Mais pourquoi donc ? DICOM Format le plus repandu dans les hopitaux (tous les nouveaux appareils cliniques supportent le format DICOM) Probleme‚Ä¶ plus qu‚Äôun format bien defini Boite a fourre-tout Les constructeurs definissent leur ‚Äútag‚Äù ou etiquette maisons Cauchemar pour les traiteurs d‚Äôimage Pour etre ethique $\\rightarrow$ denormalisation necessaire ! Du coup, c‚Äôest quoi un DICOM ?Information importante dans l‚Äôentete: Taille du voxel Taille de l‚Äôimage Matrice de transformation Type des donnees Change pour chaque DICOM!Matrice de transformation ?3 plans principaux: axial, coronal et sagittalSauf que des fois, l‚Äôacquisition n‚Äôest pas si simple‚Ä¶Taille du voxel? Rappel: un pixel/voxel a une taille qui correspond a des longueurs physiques ! Plus cette taille est petite, meilleure est la resolution! $x$, $y$ et $z$ peuvent etre identiques (isotrope) ou differents (anisotorpe). En general, c‚Äôest $z$ qui fait n‚Äôimporte quoi.Quelles consequences ? Difficile de determiner les contours Pertes d‚Äôinformations Cela pose des soucis en terme de precision de mesure !En conclusion Medecin: ‚ÄúJe veux plus de precision. (sans tuer le patient, c‚Äôest mieux)‚Äù Informaticien: ‚ÄúJe veux plus de puissance.‚ÄùRealite: ‚ÄúMollo les gens, ca va pas se passer comme ca‚Ä¶‚ÄùQuel type d‚Äôimagerie ? Imagerie fonctionnelle Se base sur l‚Äôactivite d‚Äôun organe ou d‚Äôune partie On mesure l‚Äôactivite electrique de l‚Äôorgane en question Imagerie anatomique Permet de visualiser l‚Äôanatomie du corps et des organes Pour faire quoi ?Et pas que !Neuro: encephale" }, { "title": "OCVX: Differentielles", "url": "/cours/posts/ocvx_differentielle/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-08 10:00:00 +0200", "snippet": "Lien de la note HackmdBienvenue dans le merveilleux monde de la differentielle &amp;lt;3 BUT: Etudier les extrema d‚Äôune fonction convexeExemple\\[f(x) = ax^2+bx+c\\quad a\\gt 0\\] On derive $f$, $f‚Äô(x)=2ax+b$ On cherche $x^{*}$ tel que $f‚Äô(x^*)=0$\\[f&#39;(x^*) = 0 = 2ax^*+b\\]Point optimal:\\[x^*=-\\frac{b}{2a}\\]Valeur optimale:\\[\\begin{aligned}f^*=f(x^*)&amp;amp;=a(-\\frac{b}{2a})^2+b(-\\frac{b}{2a})+c\\\\&amp;amp;=\\frac{b^2}{4a}-\\frac{b^2}{2a}+c\\\\&amp;amp;=-\\frac{b^2}{4a}+c\\end{aligned}\\] \\(f^*=\\min_{x\\in\\mathbb R}f(x)\\\\x^*=argmin_{x\\in\\mathbb R}f(x)\\)On a envie de faire pareil pour \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R \\\\ x=(x_1,x_2,...,x_n)&amp;amp;\\mapsto f(x) \\end{aligned}\\) On a besoin de generaliser la notion de derive pour des fonctions de plusieurs variables.RappelOn dit que $f:\\mathbb R\\to\\mathbb R$ est derivable en $x_0$ ssi \\(\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{x-x_0}\\) existe et est finie.Si c‚Äôest le cas, \\(f&#39;(x_0)=\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{x-x_0}\\) est le nombre derive de $f$ en $x_0$.$f‚Äô(x_0)\\equiv$ pente de la tangente au point $(x_0,f(x_0))$. Equation de la tangente: Elle passe par le point $(x_0,f(x_0))$ et $\\vec u=(1,f(x_0))$ est un vecteur directeur\\[\\rightarrow y=f(x_0)+(x-x_0)f&#39;(x_0)\\] Si $f$ est convexe $\\rightarrow$ le graphe de $f$ est toujours au dessus de la tangente, quelque soit le point ou on trace la tangente\\[\\forall x_0\\in\\mathbb R,\\quad f(x)\\ge f(x_0)+(x-x_0)f&#39;(x_0)\\] C‚Äôest la caracterisation a l‚Äôordre 1 de la convexite.On peut reecrire le nombre derive comme \\(f&#39;(x_0)=\\lim_{h\\to 0}\\frac{f(x_0+h)-f(x_0)}{h}\\) en posant $h=x-x_0$ Petit rappel: On dit que $f\\theta_{a}(g)$ s‚Äôil existe $\\varepsilon:\\mathbb R\\to\\mathbb R$ avec $\\varepsilon(x)\\to_{x\\to a}0$ et $f(x)=g(x)\\varepsilon(x),x\\in \\mathcal V(a)$\\[\\begin{aligned}\\frac{f(x)}{g(x)}&amp;amp;\\to_{x\\to a}0\\\\\\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)}{h} = f&#39;(x_0) &amp;amp;\\Leftrightarrow \\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)-hf&#39;(x_0)}{h} = 0\\\\&amp;amp;\\Leftrightarrow f(x_0+h)-f(x_0)-hf&#39;(x_0)=\\begin{cases}\\theta_a(h)\\\\h\\varepsilon(h)\\end{cases}\\\\&amp;amp;\\Leftrightarrow\\underbrace{\\color{red}{f(x_0+h)=f(x_0)+\\overbrace{hf&#39;(x_0)}^{h\\to hf&#39;(x_0)\\text{ lineaire en }h}+h\\varepsilon(x)}}_{\\text{DL a l&#39;ordre 1 en 0}}\\end{aligned}\\]Comment generaliser la notion de derivee pour $f:\\mathbb R^n\\to\\mathbb R$ ?En quoi c‚Äôest faux ?\\[\\lim_{x\\to x_0}\\frac{f(x)-f(x_0)}{\\underbrace{x-x_0}_{\\in\\mathbb R^n}} = \\lim_{h\\to 0}\\frac{f(x)-f(x_0)}{\\underbrace{x-x_0}_{\\in\\mathbb R^n}}\\] On divise par des vecteurs ! Wait that‚Äôs illegal On pourrait regarder axe par axe (coordonnee par coordonnee) $\\Rightarrow$ derivees partielles Definition: Si la fonction $\\phi:t\\mapsto f(x_1,‚Ä¶,x_k+t,‚Ä¶,x_n)$ est derivable en $0$, on dit que la $k^e$ derivee partielle de $f$ existe en $x=(x_1,‚Ä¶,x_n)$, et $\\phi‚Äô(0)=\\frac{\\delta f}{\\delta x_k}(x)$ (se note $\\delta_nf(x)$)\\[\\phi(t) = f(x_1,...,x_k+t,...,x_n) = f(x+t(0,...0,1,0,...0))\\]On regarde ce qu‚Äôil se passe pour la $k^e$ coordonnee en ‚Äúbloquant‚Äù les autres.Pour $f:\\mathbb R\\to\\mathbb R$, $f‚Äô(x_0)$ existe $\\Leftrightarrow$ $f$ derivable en $x_0$ $\\Rightarrow$ f continue en $x_0$ Manque de bol, l‚Äôexistence des derivees partielles en un point donne $\\not\\Rightarrow$ continuite de $f$Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases}\\frac{xy}{x^2+y^2} &amp;amp;(x,y)\\neq(0,0)\\\\0 &amp;amp;(x,y)=(0,0)\\end{cases}\\end{aligned}\\]On va regarder \\(\\begin{aligned}\\phi_x:t&amp;amp;\\to f((0,0)+t(1,0)) \\\\ \\phi_x(t)&amp;amp;=f(t,0)=0\\forall t \\\\ &amp;amp;\\rightarrow\\phi_x&#39;(0)=0\\frac{\\delta f}{\\delta x}(0,0)\\end{aligned}\\)Idem pour $y$\\[\\begin{aligned}\\phi_y:t&amp;amp;\\to f((0,0)+t(0,1)) = f(0,t)=0\\forall t\\\\&amp;amp;\\rightarrow \\phi_y&#39;(0)=0=\\frac{\\delta f}{\\delta y}(0,0)\\end{aligned}\\] $\\frac{\\delta f}{\\delta x}$ et $\\frac{\\delta f}{\\delta y}$ existent en $(0,0)$, mais $f$ n‚Äôest pas continueDerivee directionnelle On peut generaliser la notion de derivee en un vecteur$\\rightarrow$ On dit que $f$ est derivable en $x_0$ selon un vecteur $v\\in\\mathbb R^n\\setminus{0}$ si la fonction $\\phi:t\\mapsto f(x_0+tv)$ est derivable en $0$. On note $\\phi‚Äô(0)=\\lim_{t\\to0}\\frac{f(x_0+tv)-f(x_0)}{t} = \\color{red}{D_vf(x_0)}$\\[\\frac{\\delta f}{\\delta x_i}(x_0)=D_{e_i}f(x_0)\\]Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\]Que vaut la derivee selon $v=(2,0)$ et $x_0=(1,0)$ ?\\[\\begin{aligned}\\phi:t\\to f(x_0+tv) &amp;amp;= f((1,0)+t(2,0))\\\\&amp;amp;= f(1+2t,0)\\\\&amp;amp;= (1+2t)^2+0^2\\\\&amp;amp;= 4t^2+4t+1\\end{aligned}\\\\\\rightarrow\\phi(t) = 4t^2+4t+1\\rightarrow \\phi&#39;(t)=8t+4\\rightarrow phi&#39;(0)=D_vf(x_0)=4\\\\\\text{Et } D_{e_1}=\\frac{\\delta f}{\\delta x}(x_0) = 2\\\\\\begin{cases} D_{(2,0)}f(x_0)=4\\\\ D_{(1,0)}f(x_0)=\\frac{\\delta f}{\\delta x}(x_0)=2\\end{cases}\\text{D&#39;une maniere generale, } D_{\\alpha v}f(x_0)=\\alpha D_v f(x_0)\\]Si $\\Vert v\\Vert=1\\rightarrow$ derivee en $x_0$ en vecteur $v$ $\\equiv$ derivee directionnelle en $x_0$ selon $v$Est-ce que les derivees directionnelles sont la solution ?Est-ce que l‚Äôexistence des derivees directionnelles en $x_0$ selon tout vecteur $v\\in\\mathbb R^n\\setminus{0}$ garantit la continuite ? Nope, toujours pas.Exemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases}\\frac{y^2}{x} &amp;amp;x\\neq0\\\\y &amp;amp;x=0\\end{cases}\\end{aligned}\\]En $(0,0)$ selon $v=(v_1,v_2)\\neq{(0,0)}$\\[\\begin{aligned}\\phi:t&amp;amp;\\to f(x_0+tv)=f((0,0)+t(v_1,v_2)) = f(tv_1,tv_2)\\\\\\phi(t)&amp;amp;=\\begin{cases}\\frac{(tv_2)^2}{tv_1} &amp;amp;v_1\\neq0\\\\tv_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi(t)&amp;amp;=\\begin{cases}t\\frac{v_2^2}{v_1} &amp;amp;v\\neq 0\\\\tv_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi&#39;(t)&amp;amp;=\\begin{cases}\\frac{v_2^2}{v_1} &amp;amp;v_1\\neq0\\\\v_2 &amp;amp;v_1=0\\end{cases}\\\\\\phi&#39;(0)&amp;amp;=\\begin{cases}\\frac{v_2^2}{v_1} &amp;amp;v_1\\neq0\\\\v_2 &amp;amp;v_1=0\\end{cases}\\rightarrow\\text{ existe }\\forall v\\in\\mathbb R^2\\setminus\\{0\\}\\end{aligned}\\] $f$ admet une derivee en $0$ quelque soit le vecteur $v\\in\\mathbb R^2\\setminus{0}$ Pourant, $f$ n‚Äôest pas continue en $(0,0)$.Si on regarde le parametrage $\\psi:t\\to(t^2,t)$\\[f\\circ\\psi(t)=f(\\psi(t)) = f(t^2,t)=\\begin{cases}\\frac{t^2}{t^2} &amp;amp;t\\neq0\\\\0 &amp;amp;t=0\\end{cases}\\]$\\rightarrow$ $f\\circ\\psi$ n‚Äôest pas continue en $0$$\\rightarrow$ $f$ n‚Äôest pas continue en 0Nouvelle approcheOn va changer l‚Äôangle d‚ÄôattaquePour $f:\\mathbb R\\to\\mathbb R$, on a vu: $f$ derivable en $x_0$ \\(\\begin{aligned}&amp;amp;\\Leftrightarrow \\lim_{h\\to0}\\frac{f(x_0+h)-f(x_0)}{h} \\\\ &amp;amp;\\Leftrightarrow f(x_0+h)=\\underbrace{f(x_0)}_{\\text{la variable c&#39;est }h}+\\underbrace{hf&#39;(x_0)}_{\\text{fonction lineaire par rapport a }h}+\\underbrace{\\theta_a(h)}_{h\\varepsilon(h)}\\end{aligned}\\) Definition: On dit que $f$ est differentiable en $x_0$ s‚Äôil existe une application lineaire \\(\\underbrace{d_{x_0}f}_{\\text{se note aussi }df(x_0), df_{x_0}}:\\mathbb R^n\\to\\mathbb R\\) telle que \\(\\color{red}{f(x_0)+d_{x_0}f(h)+\\underbrace{\\theta_a(\\Vert h\\Vert)}_{\\Vert h\\Vert\\varepsilon(h)}}\\)Pour $f:\\mathbb R\\to\\mathbb R$, $f$ derivable en $x_0$ $\\Leftrightarrow$ \\(f(x_0+h)=f(x_0) + \\underbrace{hf&#39;(x_0)}_{d_{x_0}f\\text{ avec } d_{x_0}f:h\\to hf&#39;(X_0)} + h\\varepsilon(h)\\) $d_{x_0}f$ s‚Äôappelle la differentielle de $f$ en $x_0$ differentielle = application lineaire = fonction $\\neq$ $f‚Äô(x_0)$ = valeur Proposition: Si $f$ est differentiable en $x_0$, $f$ est continue en $x_0$preuve $\\rightarrow$ admiseExemple\\[\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto x^2\\end{aligned}\\]En $x_0$\\[f(x_0+h)=(x_0)^2=\\underbrace{x_0^2}_{f(x_0)}+\\overbrace{2hx_0}^{\\text{fonction lineaire par rapport a }h \\\\ \\rightarrow d_{x_0}f(h)=2hx_0 \\\\ \\rightarrow d_{x_0}h\\mapsto\\underbrace{2x_0h}_{f(x_0)}}+\\underbrace{h^2}_{\\theta_a(h)\\to\\frac{h^2}{h}=h\\to_{h\\to0}0}\\\\\\]\\[\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x&amp;amp;\\mapsto x^Tx\\end{aligned}\\]En $x_0$:\\[\\begin{aligned}f(x_0+h)&amp;amp;=(x_0+h)^T(x_0+h) = x_0^Tx_0+x_0^Th+\\underbrace{h^Tx_0}_{(h^Tx_0)^T=x_0^Th}+h^Th\\\\&amp;amp;= \\underbrace{x_0^Tx_0}_{f(x_0)} + 2x_0^Th+\\underbrace{h^Th}_{\\theta_a(\\Vert h\\Vert)}\\end{aligned}\\\\h^Th=&amp;lt;h,h&amp;gt;=\\Vert h\\Vert^2\\\\\\frac{h^Th}{\\Vert h\\Vert}=\\frac{\\Vert h\\Vert^2}{\\Vert h\\Vert}=\\Vert h\\Vert\\to_{h\\to0}0\\]Et $2x_0^Th$ est lineaire $\\color{red}{(2x_0^T(h_1+\\lambda h_2))=2x_0^Th_1+2\\lambda x_0^Th}$ Propriete: Si $f$ differentielle en $x_0$, alors f admet des derivees selon tout vecteur $h\\in\\mathbb R^n\\setminus{0}$ et $D_hf(x_0)=d_{x_0}f(h)$Lien entre differentielle et vecteur gradientf differentielle en $x_0$, $f$ admet des derivees selon tout vecteur $h\\in\\mathbb R^n\\setminus{0}$, en particulier selon les vecteurs de la base canonique $(e_1,‚Ä¶,e_n)$$\\rightarrow$ toutes les derivees partielles $\\frac{\\delta f}{\\delta x}(x_0)$ existent\\[h\\in\\mathbb R^n\\\\h=\\begin{pmatrix}h_1\\\\\\vdots\\\\h_n\\end{pmatrix}\\quad h=\\sum_{i=1}^nh_ie_i\\\\\\begin{aligned}d_{x_0}f(h) &amp;amp;= d_{x_0}f(\\sum_{i=1}^nh_ie_i) \\begin{cases}h_i\\in\\mathbb R\\forall i\\\\e_i\\in\\mathbb R^n\\end{cases}\\quad f\\text{ lineaire } f(\\lambda x+\\mu y) = \\lambda f(x) + \\mu f(y)\\\\&amp;amp;= \\sum_{i=1}^nh_id_{x_0}f(e_i)\\\\&amp;amp;= \\sum_{i=1}^nh_iD_{e_i}f(x_0) = \\sum_{i=1}^nh_i\\frac{\\delta f}{\\delta x_i}(x_0)\\end{aligned}\\] Definition: On appelle vecteur gradient de $f$ en $x_0$\\[\\nabla_{x_0}f=\\nabla f(x_0)=\\begin{pmatrix}\\frac{\\delta f}{\\delta x_i}(x_0)\\\\\\vdots\\\\\\frac{\\delta f}{\\delta x_n}(x_0)\\end{pmatrix}\\]\\[\\begin{aligned}d_{x_0}f(h) &amp;amp;= \\sum_{i=1}^nh_i\\frac{\\delta f}{\\delta x_i}(x_0) = (\\underbrace{\\frac{\\delta f}{\\delta x_1}(x_0),...,\\frac{\\delta f}{\\delta x_n}(x_0)}_{\\nabla_{x_0}f^T})\\begin{pmatrix} h_1 \\\\ \\vdots \\\\ h_n \\end{pmatrix}\\\\&amp;amp;=\\nabla_{x_0}f^Th=&amp;lt;\\nabla_{x_0},h&amp;gt;\\end{aligned}\\]$f$ differentielle en $x_0$, $d_{x_0}=&amp;lt;\\nabla_{x_0}f,h&amp;gt;=\\nabla_{x_0}f^Th$ La differentielle est donc \\(d_{x_0}f:h\\mapsto&amp;lt;\\nabla_{x_0}f,h&amp;gt;=\\nabla_{x_0}f^Th\\)Comment s‚Äôetend la differentielle pour \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R^p \\\\ x=(x_1,...,x_n)&amp;amp;\\mapsto f(x) = (f_1(x_1,...,x_n),...,f_p(x_1,...,x_n))\\end{aligned}\\)\\[\\begin{aligned}f:\\mathbb R&amp;amp;\\rightarrow \\mathbb R^3\\\\x&amp;amp;\\mapsto(2x, x^2, 3x+2)\\end{aligned}\\]$f$ differentiable en $x_0$ $\\Leftrightarrow$ $f_1,‚Ä¶,f_p$ sont differentiables en $x_0$\\[\\begin{aligned}f(x_0+h)&amp;amp;=\\begin{pmatrix} f_1(x_0+h) \\\\ \\vdots \\\\ f_p(x_0+h) \\end{pmatrix}\\\\&amp;amp;= \\begin{pmatrix}f_1(x_0) + d_{x_0}f_1(h)+\\theta_a(\\Vert h\\Vert)\\\\\\vdots \\\\f_p(x_0) + d_{x_0}f_p(h)+\\theta_a(\\Vert h\\Vert)\\end{pmatrix}\\\\&amp;amp;= \\underbrace{\\begin{pmatrix}f_1(x_0)\\\\\\vdots\\\\f_p(x_0)\\end{pmatrix}}_{f(x_0)} + \\underbrace{\\begin{pmatrix}d_{x_0}f_1(h)\\\\\\vdots\\\\d_{x_0}f_p(h)\\end{pmatrix}}_{?} + \\underbrace{\\theta(\\Vert h\\Vert)}_{\\in\\mathbb R^p}\\end{aligned}\\]Les $f_i, i = 1,‚Ä¶,p$ sont des fonctions differentiables de $\\mathbb R^n\\to\\mathbb R$\\[d_{x_0}f_i(h) = &amp;lt;\\nabla_{x_0}f_i,h&amp;gt; = \\nabla_{x_0}f_i^Th=\\biggr(\\frac{\\delta f_1}{\\delta x_1}(x_0),...,\\frac{\\delta f_n}{\\delta x_n}(x_0)\\biggr)h\\\\\\begin{pmatrix}d_{x_0}f_1(h) \\\\ \\vdots \\\\ d_{x_0}f_p(h) \\end{pmatrix}_{\\mathbb R^p} = \\begin{pmatrix}\\nabla_{x_0}f_1^Th \\\\ \\vdots \\\\ \\nabla_{x_0}f_p^Th \\end{pmatrix}_{\\mathbb R^p} = \\begin{pmatrix} (\\frac{\\delta f_1}{\\delta x_1},...,\\frac{\\delta f_1}{\\delta x_n})h \\\\ \\vdots \\\\ (\\frac{\\delta f_p}{\\delta x_1},...,\\frac{\\delta f_p}{\\delta x_n})h \\end{pmatrix}_{\\mathbb R^p} = \\underbrace{\\begin{bmatrix} \\frac{\\delta f_1}{\\delta x_1},...,\\frac{\\delta f_1}{\\delta x_n} \\\\ \\vdots \\\\ \\frac{\\delta f_p}{\\delta x_1},...,\\frac{\\delta f_p}{\\delta x_n} \\end{bmatrix}_{\\mathbb R^{p\\times n}}}_{\\text{matrice jacobienne}}h_{\\mathbb R^n}\\] Pour une fonction $f:\\mathbb R^n\\to\\mathbb R^p$, on appelle matrice jacobienne en $x_0$, et on note $Jac_{x_0}f$, la matrice des derivees partielles $[Jac_{x_0}f]_{ij}=\\frac{\\delta f_i}{\\delta x_j}$\\(\\color{red}{d_{x_0}f(h) = Jac_{x_0}f\\times h}\\) La differentielle de $f:\\mathbb R^n\\to\\mathbb R^p$ en $x_0$ est l‚Äôapplication lineaire $d_{x_0}f:h\\mapsto Jac_{x_0}f\\times h$$f$ differentielle en $x_0$, \\(f(x_0+h)=f(x_0)+\\underbrace{d_{x_0}}_{d_{x_0}f\\text{ application lineaire}}+\\theta_a(\\Vert h\\Vert)\\) \\[\\begin{aligned} f:\\mathbb R&amp;amp;\\rightarrow \\mathbb R^3\\\\ d_{x_0}f:h&amp;amp;\\mapsto hf&#39;(x_0) \\end{aligned}\\] \\[\\begin{aligned} f:\\mathbb R^n&amp;amp;\\rightarrow \\mathbb R\\\\ d_{x_0}f:h&amp;amp;\\mapsto &amp;lt;\\nabla_{x_0}f, h&amp;gt;=\\nabla_{x_0}f^Th \\end{aligned}\\] \\[\\begin{aligned} f:\\mathbb R^n&amp;amp;\\rightarrow \\mathbb R^p\\\\ d_{x_0}f:h&amp;amp;\\mapsto Jac_{x_0}f\\times h \\end{aligned}\\] " }, { "title": "COIN: Communication Interpersonnelle", "url": "/cours/posts/coin_coin/", "categories": "tronc commun S8, COIN", "tags": "tronc commun, COIN, S8", "date": "2021-04-07 10:00:00 +0200", "snippet": "Lien de la note HackmdPlan du cours: Temperament Cycle de resolution de problemes LeadershipRappels: les axes Introversion/extroversion $\\rightarrow$ Orientation de l‚Äôenergie Sensation/intuition $\\rightarrow$ Modes de perception Thinking/feeling $\\rightarrow$ Criteres de decision Judgement/perception $\\rightarrow$ OrganisationLes temperamentsModes d‚ÄôapprentissageExerciceEn distanciel: exercice discordRapport a l‚Äôargent ? Econome/depensier ?Un mot qui nous defini ?Un animal qui nous ressemble ?Methodique - SJ Quoi Organise - Etapes definies Methode eprouvees Exercices structures Pratique Respect du statut Discipline clairePendant l‚Äôexercice: Econome Pas depensier On sait se faire plaisir Pas investissement Lea elle aime le bitcoin Curieux/connaissance Le dauphin Parce qu‚Äôil est curieux :3 La gerboise Petit animal curieux En bref Style de leadership Sens de la hierarchie Ferme Impartial Planificateur Relation du temps Ponctuel Fait des listes Sait jeter Style professionnel Sens des responsabilites Relation a l‚Äôargent A l‚Äôaise avec l‚Äôargent Specificites Ponctualite Precipitation Impatience critique SJ: DEVOIR - Gardiens du temps Risque: surmenage, rigidite/obstination La cigale de la cigale et la fourmiPragmatique - SP Quand et comment Improvise Experimentation pratique Observateur En fonction de l‚Äôutilite Discipline souple et continueSP en bref Style de leadership Supporte mal l‚Äôautorite Agit en negociateur SP LIBERTE - Artisans Sens pratique Realisme Flexibilite Action Debrouillard Infatigable si plaisir Style decontracte Risque: versatile, insouciant, imprevisible La fourmi de la cygale et la fourmiConceptuel - NT Pourquoi Analyse Lectures personnelles Respect de la competence Discipline selon les objectifsEn bref Style de leadership Supporte autorite de competences Relation du temps Usage rationnel Plannification Style professionnel Logique Accorde une grande importance au travail Relation a l‚Äôargent Gere rationnellement Prend des risques Specificites Elabore des modeles Voit l‚Äôensemble Perfectionniste NT SAVOIR - Rationnel Theorie Innovation Competence Concepteur Curieux Rationalite Direct, concis Risque: froid, cynique, critique, blessantN‚Äôassure pas l‚Äôexecution Le gars qui a amene le feu a l‚Äôhumanite et qui se fait maintenant bouffer les organes a l‚ÄôinfiniRationnel - NF Qui Comprendre Discussion de groupe En fonction du lien personnel Discipline personnaliseeEn bref Style de leadership Charismatique Relation au temps Sensible au besoin des autres Donne de son temps Style pro Communicateur Creatif Transmettre d‚Äôidees Relation a l‚Äôargent Considere comme un moyen pour une fin Specificites Chaleureux NF DEVENIR - Idealistes Lucidite Idealisme Recherche de sens Empathie Communication Catalyseurs Persuasif Risque: hypersensibilite, dependance, confusion des roles, ignore les problemes pratique Le gars partit tabasser des moulins a ventCycle de resolution de problemesExercice - truc de la NASAOn est dans un bateau qui coule et on doit estimer des objets par ordre de croissance. ‚ÄúCe sont les experts hein, pas moi‚ÄùEn premier lieu, vous devez r√©aliser le classement sur une base individuelle et, dans un second temps, effectuer un classement de groupe. Par la suite, nous vous communiquerons le classement type r√©alis√© par des experts et vous pourrez comptabiliser les scores obtenusLe but: avoir le score le plus basResultat:La strategie: Se faire reperer La plupart des sauvetages arrives pendant les 36 premieres heures Survivre Le rhum peut servir d‚ÄôantiseptiqueModele typologiqueUn peu associer chaque pole a chaque etape: Analyse: T Motivation: F Solution: N Diagnostic: S E: chercher a l‚Äôexterieur Discuter avec des gens exterieur I: Chercher a l‚Äôinterieur Trouver la solution par soi-meme P: Passer son temps sur le diagnostic/solutions J: Passer son temps sur la motivation/analyse On a TOUS des etapes qu‚Äôon court-circuite (qui nous interesse moins que d‚Äôautres).C‚Äôest quoi les outils pour faire un diagnostic ?Questionnaires et interviews Diagramme de Pareto: 80/20 Exemple: si 80% des clients se plaignent du meme bug, on repare ce bug en priorite, les 20% restants sont moins prioritairesC‚Äôest quoi les outils pour chercher des solutions ? Le brainstorming Le tour de table Le benchmark Envoyer un stagiaire faire le faux client dans une autre entreprise Piquer leurs idees Amenager les banques pour acceuillir les ‚Äúclients‚Äù (et non utilisateurs) Se sont benchmarker avec les hotels Matrice combinatoire Melanger 2 objets pour en creer un nouveau Comment on fait de l‚Äôanalyse ?La matrice multi-criteresMotivation ?Informer, communiquer, formerLe leadership en situationExercice Quelles caracteristiques pour un manager ? Dessinez un manager et son equipe4 Styles de leadershipDirectifDirecteur d‚Äôusine : structurer la tache Mode de management precis, detaille, centre sur des resultats. Le manafer decide et controle. Structurant Envahissant PersuasifGuide de haute montage Mode de management centre sur un engagement personnel. Recherche de l‚Äôimplication de tous, vigilance sur les modes operatoires et les resultats Convaincant Paternaliste Participatif Le manager anime des talents et des initiatives, au sein d‚Äôune equipe. Il se contractualise ses rapports avec des collaborateurs Ouvert Manipulateur (dans le cas du ‚Äúfaux‚Äù participatif) Animateur Prend du temps Legitime Incertain DeleguatifChef de projet Le manager donne des objectifs et controle dans un cadre contractuel, avec des echeances a moyens terme. Responsabilise Laisse faire Soutient Abandonne Developpe ¬† Savoir adapter son style en fonction: Des personnalites en presence De l‚Äôautonomie des collaborateurs Autonomie tres faible: style directif Autonomie faible: style persuasif Autonomie moderee: style participatif Autonomie forte: style deleguatif La culture de l‚Äôorganisation Conditions d‚Äôefficacite Autonomie des collaborateursRemarques L‚Äôautonomie varie un peu en fonction des personnes, beaucoup en fonction des situations Le degre d‚Äôautonomie change dans le tempsCycle progressif/regressif" }, { "title": "IML: Unsupervised clustering", "url": "/cours/posts/iml_dimensionality_clustering/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8, clustering", "date": "2021-04-02 13:00:00 +0200", "snippet": "Lien de la note HackmdWhy do we care Group the input data into clusters that share some characteristics Find pattern in the data (data mining problem) Visualize the data in a simpler way Infer some properties of a given data point based on how it relates to other data point (satistical learning)Why is it trickyBelongs to unsupervised learning No grounds truth available to learn/evaluate quality of the algorithmHow to assess how much data points are related to each other? Which criteria (features) are the most relevant Which metrics make the most senseHow to assess the soundness of the resulting cluster? Is it relevant ?Families of clustering approaches Distance-based clustering centroid-based approach (k-mean) connectivity-based approaches (based on distance) Density-based clustering set of dense points Distribution-based clustering likelihood of point to belong to the same distribution Fuzzy clustering Relaxed clustering paradigm where a data point can be assigned to multiple clusters with a quantified degree of belongingness metric (fuzzy $c$-means clustering,‚Ä¶). $k-$means clusteringPartition $n$ observations $x_1,‚Ä¶,x_n$ int $k$ clusters $C={C_1,‚Ä¶,C_k}$ where each observations $x_i$ belongs to the cluster $C_{j*}$ whose mean $\\mu_{j*}$ is the closest: $x_i\\in S_{j*}$ with $j^{*}=argmin_j\\Vert x_i-\\mu_j \\Vert_2$La croix represente le centre, on veut la plus petite distance depuis un centre pour ajouter un point dans un cluster: Minimize within-cluster sum of squares (variance) Overall optimization problem: NP-hard problem, no guarantee to find the optimal value Stochastic and very sensitive to initial conditions Sensitive to outliers (thank you $L_2$ norm) Probably the most used clustering algorithm$k-$means and Voronoi tesselation Voronoi tesselationparition of the Euclidean space relatively to discrete points/seeds. Each region/Voronoi cell is composed of all the points in the space that are closer to the cell seed than any other seed $k$-mean provides a way to obtain a Voronoi tesselation of the input space, where seeds are the final cluster means Alternatively, one case use some pre-computer Voronoi tesselation seeds as initial clusters for $k$-meansDetermining the optimal number of clusterCombien de clusters a vue de nez pour cette image ? 2, 3, 4, 14‚Ä¶.Compute explained variance for an increasing number of clusters $k$ Plot and find the bend of the elbow Sometimes it does not work :( Sometimes, $k$-means works‚Ä¶But most of the time not as expected. Probably because the $L_2$ norm that $k$-means tries to minimize Sensible of curse of dimensionality Form ‚Äúnormalized Gaussian‚Äù clusters Does not adapt to manifold geometry Sensible to class imbalance Sensible to outliersSimple Linear Iterative Clustering A kick-ass image segmentation algorithm using $k$-means SLIC superpixels uses a modified $k$-means clustering in the $Labxy$ space to produce $k$ clusters regurlaly sampled and perceptually coherent from a color point of view.k-medoids clustering Possible extension to $k$-means Cluster centroids are not initial data points $\\Rightarrow$ can be problematic$\\Rightarrow$ Replace centroids by medoid (points with the smallest distance to all other points in the cluster)$\\Rightarrow$ $k$-medoid algorithmOverall objective: find $k$ medoids $m_1, . . . , m_k$ that minimize the partitioning costFuzzy $c$-means clustering $k$-means is a hard clustering method: each data point 100% belongs to the cluster Soft clustering methods allow each data points to belong to several clusters with various degrees of membershipGaussian mixture models $k$-means on steroids$k$-means works for spherical clusters, but fails in any other cases $\\Rightarrow$ try harder Model probability density function $f$ of data as a mixture of multivariate GaussianCette courbe est une superposition de plusieurs Gaussiennes: Il faut pouvoir estimer les facteurs de proportions de ces gaussiennes dans la sommeThe EM algorithmInitialization Select $k$ random points as initial means $\\hat\\mu_1,‚Ä¶,\\hat\\mu_k$ Init all covariance matrices $\\hat\\sum_1,‚Ä¶,\\hat\\sum_k$ as whole data sample covariances matrix $\\hat\\sum$ Set uniform mixture weight $\\hat\\phi_1,‚Ä¶,\\hat\\phi_k=\\frac{1}{k}$Alternate until convergenceExpectation stepCompute membership weight $\\hat\\gamma_{ij}$ of $x_i$ with respect to $j^{th}$ component $\\mathcal N(x\\vert\\mu_j,\\sum_j)$Maximization stepUpdate weights (in that ordre) Tadaaaa $k$-means vs GMM Let the fight begin!Kernel Density Estimation Nonparametric estimation GoalEstimate probability density function $f$ based on observations $x_1,‚Ä¶,x_n$ only, assumed to derive from $f$ otherwise wtf are we doing here The kernel density estimator with bandwith $h$ at given point $x$ is given byExemplesMean shift clustering shift each point to the the local density maximum of its KDE, and assign to the same cluster all points that lead to the same maximum ExemplesOn peut faire la meme chose sur les images en couleurs:DBSCAN Density-base spatial clustering of applications with noise Divide points into 3 categories (core, boundary, outliers) whether there are at least $minPts$ in their $\\epsilon$-neighborhood or not Find the connected component of core points (ignore all non-core points) Assign non-core points to nearby clusters if it is less than $\\epsilon$ away, otherwise assign to noiseSpectral clustering View clustering task as a min-cut operation in a graph Compute similarity graph (but which one?) of data $x_1,‚Ä¶,x_n$ Compute (weighted) adjacency matrix $W$, degree matrix $D$ and Laplacian matrix $L=D-W$ Perform eigendecomposition of $L=(E,\\triangle)$ Fact #10 is and eigenvalue of $L$ with multiplicity $\\sim#$ connected components in graph, its eigenvectors are identity vectors of those connected components Fact #2Eigenvector of smallest non-zero eigenvalue (Fiedler vector) gives the normalized min-cut of graph Performs $k$-means clustering of the $k$ smallest eigenvectors $[e_1,‚Ä¶,e_k]_{n\\times k}$Hierarchical clustering A very natural way of handling data GoalGenerate a sequence of nested clusters and ordre them in a hierarchy, represented by a dendogram Leaves the dendogram = initial data Inner nodes of the dendogram = clustersExempleAgglomerative vs Divise clusteringAgglomerative: merge clusters from fine to coarse (bottom-up approach)Divisive clustering: split clusters (top-down approach) Needs some heuristics to avoid the $O(2^n)$ ways of spitting each cluster‚Ä¶ Not so used in practiceBestiarityOverall comparison of all methods" }, { "title": "TIFO: Introduction a la morphologie mathematique, exemples", "url": "/cours/posts/tifo_morpho_maths_exemples/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique", "date": "2021-04-02 10:00:00 +0200", "snippet": "Lien de la note HackmdImagerie medicale Parties blanches dans le cerveau: lesionsLa combinaison des modalites avec l‚Äôimage tophat permet de mettre en evidence ces petits strucuturesSuivi de particulesSequences en 2D+tDans des images en 3D+t (3D video)Avec l‚ÄôIMCEEOn cherche des satellites qui bougent entre 2 imagesPipeline: C‚Äôest moche mais ca marcheOn utilise la loi de Khi-DeuxLa suite Base de donneees alimententee quotidienement par Maya Mise en place d‚Äôun algo de classification des imagettes base sur le machine learning 97% a 98% de bonne classifications actuellement" }, { "title": "TIFO: Introduction a la morphologie mathematique, partie 2", "url": "/cours/posts/tifo_morpho_maths_suite/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique, niveau de gris, minima, maxima, watershed", "date": "2021-04-02 09:00:00 +0200", "snippet": "Lien de la note HackmdRappels erosion et dilatation z erosions de taille y = une erosion de taille $z\\times y$ z ouverture de taille y $\\neq$ une ouverture de taille $z\\times y$Niveau de grisOn peut voir l‚Äôerosion et la dilatation comme une etude des niveaux de gris presents dans une fenetre glissante representee par l‚Äôelement structurantOn regarde le ixel de l‚Äôorigine de l‚Äôelement structurant. On attribue le min ou max pour les pixels correspondants a l‚Äôelement structurant de leurs niveaux de grisFiltres alternes sequentiels Une repetetition des compositions (fermeture et ouverture) pour debruiter progressivemenent en perdant le moins d‚Äôinfos possible alternes: on alterne les filtres sequentiel: on augmente la taille de l‚Äôelement structurant au fur et a mesureTop hatExemple pas du tout scientifique J‚Äôai pris Harry et je l‚Äôai ouvertHarry en gris - Harry en gris ouvert = Dindon is that you ??La dinde a un niveau de gris d‚Äôecart avec l‚Äôimage originaleBilan Le nom ‚Äúmorphologie mathematiques‚Äù a ete choisi dans un bar Morpho = considerer les images commes des paysages Minecraft Non-lineaire: insensible au contraste Erosion et dilatation sont amis pour la vie On peut selectionner des objets grace a leur forme/taille (geometrie) La morpho est tres utile pour le filtrage d‚Äôimage LES DINDES ONT PRIS LE CONTROLE DU MONDEDe nouveaux outilsRetournons sur Harry et son patronusOn augmente la taille de l‚Äôelement structurant = tout est plus visible (image incoming)Simple dilatationGradients morphologiquesDinde binaire: La dilatation va ‚Äúaugmenter les bords‚Äù Soustraire les 2 images, c‚Äôest le gradient externeAvec une erosion: L‚Äôerosion va ‚Äúgrignoter les bords‚Äù C‚Äôest le gradient interneEn niveau de gris:Bilan du gradient Ces gradients se ressemblent beaucoup!Il faut choisir le gradient au cas par cas.La squeletisation On va chercher le squelette de notre objet.L‚Äôidee c‚Äôest de prendre la position des centres des boules max inclues dans l‚Äôobjet etudie On fait grossir des boules au fur et a mesure (ray marching style) A partir du moment ou l‚Äôobjet touche le bord, ca fait n‚Äôimporte quoiCarte des distance Attribuer a chaque pixel de l‚Äôojet concerne sa distance au bordOutil de segmentation: le Watershed Ou ligne de partage des eaux On ‚Äúinonde‚Äù les vallees (minima locaux) au fur et a mesure que l‚Äôon ‚Äúmonte‚Äù en niveau de gris. Quand 2 vallees se recontrent, cela cree une ligne qui est la limitation entre 2 objets. En fonction de l‚Äôimplem, il faut des marqueurs ou non Toujours lire la doc de la fonction de Watershed qu‚Äôon utilise S‚Äôil n‚Äôy a pas de marqueurs et que l‚Äôimage a beaucoup de minima locaux, on a une sur-segmentationLes minima/maxima locaux Extrema local: point ou groupe de point dont la valeur est extreme dans un voisinage donneLes maxima locauxOn peut definir des profondeurs de maxima On peut selectionner les maxima qui se ‚Äúdistinguent‚Äù vraiment du reste On calcule sa profondeur pour chaque maxima Niveaux de gris necessaire pour qu‚Äôil n‚Äôy a plus de maxima On vide l‚Äôeau qui a inonde partout sous la courbe On regarde quand les regions fusionnent C‚Äôest l‚Äôinverse du WatershedReconstruction geodesique Recuperer uniquement certains objets a l‚Äôaide de marqueursImplem: dilatations successives jusqu‚Äôa idempotenceBouchage de trousRectangle rouge = marqueur du fondElimination d‚Äôobjets touchant les bords" }, { "title": "TIFO: Introduction a la morphologie mathematique", "url": "/cours/posts/tifo_morpho_maths/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, morphologie mathematique, dilatation, erosion, ouverture, fermeture, composition, connexe", "date": "2021-04-01 14:00:00 +0200", "snippet": "Lien de la note Hackmd Par Elodie cette fois TP en Python (wouhou!) Evaluation: commun avec IMEDPlan du coursY‚Äôen a pasBut du cours Savoir ce qu‚Äôest la morphologie mathematiques Comprendre son interet Acquerir les bases de la morphologie mathematiques Savoir utiliser les outils de morphologie mathematique pour traiter divers probleme de traitement d‚Äôimage. On fait mieux que des reseaux de neurones ! (environ)Qu‚Äôest-ce que c‚Äôest ?HistoireInvention francaise (cocorico)Nee en 1964 a MINES PariTech (ENSMP a Fontainebleau) par Georges Matheron Le nom morphologie mathematiques est ete choisi‚Ä¶ dans un bar 1982: publication du livre Serra en Anglais 1987: premiers articles dnas IEEE PAMI faire en sorte que la morphologie mathematiques soit reconnue mondialement Depuis, elle est utilisee dans le monde entier Conference internationale tous les 2 ans Journal specialiseSTOOOPOn va parler d‚ÄôOpenCV Attention a OpenCV C‚Äôest genial et horrible en meme temps Pour importer OpenCV1: import cv Pour importer OpenCV2: import cv2 Pour importer OpenCV3: import cv2 wot RGB devient BGR xyz? non zyx‚Ä¶Retour a qu‚Äôest-ce que c‚ÄôestUne image devient une fonction On considere l‚Äôimage comme un paysage ! (un peu comme Minecraft)En quelques mots La morpho maths fait partie de la categorie de traitement d‚Äôimage non lineaire Toutes les parties de l‚Äôimage ne vont pas reagir de la meme maniere a l‚Äôapplication d‚Äôoutils de morpho maths Permet d‚Äôetre beaucoup plus generique et efficace En particulier: on est invariant au contraste La base des basesConcept de base: l‚ÄôordreOn doit pouvoir etbalir une relation d‚Äôordre entre chaque element considere (pixels, groupes de pixels,etc.) Le treillisStructure de bases: treillis complet structure ordoneeLa connexite La connexite, c‚Äôest le voisinage des pixelsTous les voisins qu‚Äôon considere comme connectes.En 3D: connexite 6, 18, 26 Voir a quoi ca correspond: imaginer un Rubik‚Äôs cubeComposante connexe Ensembles de pixels connectesOperateurs en morpho mathsProprietesSoit $\\Omega$ un operateur morpho, $x$ et $y$ deux parties de treillis $x\\le y\\Rightarrow\\Omega(x)\\le\\Omega(y)$ Croissance $x\\le\\Omega(x)$ ou $\\Omega(x)\\le x$ Extensivite ou Anti-Extensivite $\\Omega(\\Omega(x))=\\Omega(x)$ IdempotenceElements structurants On veut comparer ce qu‚Äôon veut traiter avec un objet de geometrie connue: element structurant forme connue taille connue origineOperateursL‚Äôerosion Rappel: on est dans un paysageOn considere une image binaire avec un fond noir et un objet blanc. L‚Äôerosion va venir ‚Äúgrignoter‚Äù l‚Äôobjet blanc!On considere un element structurant $B_z$, avec une origine $z$. L‚Äôerosion est definie par:\\[\\epsilon(X)_B=\\{z/B_z\\in X\\}\\]Une video pour mieux comprendreLa dilatationEn prenant les memes notations et ca devient:\\(\\delta(X)_B=\\{z/B_z\\cap X\\neq\\emptyset \\}\\)Une video pour mieux comprendreBilanErosion: agrandit les trous deconnecte les objets ‚Äúaugment le noir‚ÄùDilatation: rempli les trous connecte les objets ‚Äúaugment le blanc‚ÄùLa forme de l‚Äôelement structurant va ‚Äúselectionner‚Äù les formes qu‚Äôon garde $\\rightarrow$ on filtre en fonction de la taille/forme La croissance n‚Äôest valables que si les elemens structurants sont identiquesAssocier et composerPremiere compositionQue se passe-t-il si on fait une erosion suivi d‚Äôune dilatation ?\\[\\gamma(X)=\\delta_B(\\epsilon_B(X))\\] Il s‚Äôagit d‚Äôune ouvertureDeuxieme compositionQue se passe-t-il si on fait une dilatation suivi d‚Äôune erosion ?\\[\\phi(X)=\\epsilon_B(\\delta_B(X))\\] Il s‚Äôagit d‚Äôune fermetureL‚Äôouverture et la fermetureCe sont des outils tres puissants en morpho Ils permettent de garder les objets plus grands que l‚Äôelement structurant Ideales dans des problemes de filtrage/debruitage!" }, { "title": "OCVX: Norme", "url": "/cours/posts/ocvx_norme/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-04-01 10:00:00 +0200", "snippet": "Lien de la note Hackmd Norme: \\(\\begin{aligned}\\Vert.\\Vert.\\mathbb R^n&amp;amp;\\to\\mathbb R^1\\\\x&amp;amp;\\mapsto\\Vert x\\Vert\\end{aligned}\\) separation: $\\Vert x\\Vert=0\\Rightarrow x=0$ homogeneite: $\\Vert\\lambda x\\Vert=\\vert\\lambda\\vert\\Vert x\\Vert$ inegalite triangulaire: $\\forall x,y\\in\\mathbb R^n, \\Vert x+y\\Vert\\le\\Vert x\\Vert+\\Vert y\\Vert$ inegalite triangulaire inversee: $\\forall x,y\\in\\mathbb R^n,\\biggr\\vert\\Vert x\\Vert-\\Vert y\\Vert\\biggr\\vert\\le\\Vert x-y\\Vert$\\[\\Vert x\\Vert=\\Vert x+y-y\\Vert\\le\\Vert x-y\\Vert+\\Vert y\\Vert\\\\\\Leftrightarrow \\Vert x\\Vert-\\Vert y\\Vert\\le\\Vert x-y\\Vert\\\\\\Vert y\\Vert=\\Vert y-x+x\\Vert\\le\\underbrace{\\Vert y-x\\Vert}_{\\Vert x-y\\Vert}+\\Vert x\\Vert=\\Vert x-y\\Vert + \\Vert x\\Vert\\\\\\Leftrightarrow\\Vert y\\Vert -\\Vert x\\Vert\\le\\Vert x-y\\Vert\\\\\\Rightarrow \\biggr\\vert\\Vert x\\Vert-\\Vert y\\Vert\\biggr\\vert\\le\\Vert x-y\\Vert\\] A partir d‚Äôune norme, on peut definir une distance \\(d_{\\Vert.\\Vert}=\\Vert x.y\\Vert\\) Tout produit scalaire permet de definir une norme \\(\\Vert x\\Vert=\\sqrt{&amp;lt;x.x&amp;gt;}\\)En particulier: $p=1$, $\\Vert x\\Vert_1=\\sum_{i=1}^n\\vert x_i\\vert$ $p=2$, $\\Vert x\\Vert_2=\\sqrt{\\sum_{i=1}^nx_i^2}$ $p=\\infty$, \\(\\Vert x\\Vert_{\\infty} = \\max_{i=1,...,n}\\vert x\\vert\\)Question 3.30\\(\\begin{aligned}\\Vert x-y\\Vert_1&amp;amp;=\\vert x_1.y_1\\vert+\\vert x_2.y_2\\vert\\\\&amp;amp;= \\vert 1-3\\vert+\\vert2-1\\vert\\\\d_{\\Vert.\\Vert_1}(xy)&amp;amp;=3\\end{aligned}\\)Distance de Manhattan\\[\\begin{aligned}\\Vert x-y\\Vert_2&amp;amp;=\\sqrt{(x_1-y_1)^2+(x_2-y_2)^2}\\\\d_{\\Vert.\\Vert_2}&amp;amp;= \\sqrt{4+1}\\\\&amp;amp;=5\\end{aligned}\\]\\[d_{\\Vert.\\Vert_{\\infty}}=\\Vert x-y\\Vert_{\\infty} = \\max(2,1)=2\\]Notion de voisinageNotion de voisinnage/boule ouverte$\\rightarrow$ generalise la notion d‚Äôintervallle pour $\\mathbb R^n$, $n\\ge2$Boule ouverte centree sur un point $x_0$ de rayon $r$\\[\\mathcal B_{\\Vert\\Vert}(x_0,\\varepsilon)=\\{y\\in\\mathbb R^n\\vert\\Vert x_0-y\\Vert &amp;lt; \\varepsilon\\} \\text{ boule ouverte}\\\\\\]\\[\\bar{\\mathcal B}_{\\Vert\\Vert}(x_0,\\varepsilon)=\\{y\\in\\mathbb R^n,\\Vert x_0-y\\Vert\\le \\varepsilon\\} \\text{ boule fermee}\\]Voisinnage de $x_0$:\\(\\mathcal V(x_0)\\subseteq\\mathbb R^n \\text{ tq } \\exists\\varepsilon\\gt0\\\\\\mathcal B_{\\Vert\\Vert}(x_0,\\varepsilon)\\in \\mathcal V(x_0)\\)Question 3.31\\[\\mathcal{\\bar B_2}(0,1):\\\\x\\in(\\delta\\mathcal B_2(0,1))\\\\\\{x\\in\\mathbb R^1,\\underbrace{\\Vert x\\Vert_1=1\\}}_{x_1^2+x_2^2=1}\\]\\[\\mathcal{\\bar B_1}(0,1):\\\\x\\in\\delta\\mathcal B_1(0,1)\\\\\\{x\\in\\mathbb R^2,\\underbrace{\\Vert x\\Vert_2=1}_{\\vert x_1\\vert+\\vert x_2\\vert=1}\\}\\]Si $x_1\\gt0$, $x_2\\gt0$, $x_2=1-x_1$\\[\\mathcal{\\bar B_{\\infty}}:\\\\x\\in\\delta\\mathcal B_{infty}(0,1)\\\\\\{x\\in\\mathbb R^2, \\max(\\vert x_1\\vert,\\vert x_2\\vert)=1\\}\\]Nos formes s‚Äôemboitent:$0\\lt p\\lt 1?$$\\Vert.\\Vert_p$ est une quasi norme $\\rightarrow$ inegalite triangulaire$p=0?$$\\Vert x\\Vert_0=$ nombre de coordonnees non nulles du vecteur $x$$\\mathcal B_p(0,1)$ convexe ? $A$ convexe: $\\forall x,y\\in A, \\forall t\\in[0,1]$, $tx+(1-ty)\\in A$\\[x,y\\in\\mathbb B_p(0,1)\\Leftrightarrow \\Vert x\\Vert_p-\\Vert y\\Vert_p\\lt1\\\\\\begin{aligned}t\\in[0,1], \\Vert \\underbrace{tx+(1-t)y}_{\\in\\mathbb B_p(0,1)}\\Vert_p &amp;amp;\\le\\Vert tx\\Vert_p + \\Vert(1-t)y\\Vert \\text{ inegalite triangulaire}\\\\&amp;amp;\\le t\\underbrace{\\Vert x\\Vert_p}_{\\le 1} + (1-t)\\underbrace{\\Vert y\\Vert_p}_{\\le 1}\\\\&amp;amp;\\le t + (1-t)\\\\&amp;amp;\\le 1\\end{aligned}\\]$\\mathcal B_p(0,1)=\\mathcal C_{\\lt 1}\\Vert.\\Vert_p=$ lien de sous niveau (strict) 1.Donc si $\\Vert.\\Vert_p:x\\mapsto\\Vert x\\Vert_p$ est une fonction convexe, $\\mathcal B_p(0,1)=\\mathcal C_{\\lt 1}\\Vert.\\Vert_p$ est une partie convexe.$\\rightarrow(1-t)y\\le tf(x)+(1-t)f(y)$Continuite d‚Äôune fonction de $\\mathbb R^n\\to\\mathbb R^p$$f$ continue en $a$\\[\\forall\\varepsilon\\gt0,\\exists\\eta\\gt0, \\vert x-a\\vert\\lt\\eta\\Rightarrow\\vert f(x)-f(a)\\vert\\lt\\varepsilon\\]Continuite d‚Äôune fonction de $\\overbrace{\\mathbb R^n}^{\\Vert.\\Vert_n}\\to\\overbrace{\\mathbb R^p}^{\\Vert.\\Vert_p}$ $f$ continue en $a$ $\\Leftrightarrow$\\(\\forall\\varepsilon\\gt0,\\exists\\eta\\gt0, \\underbrace{\\Vert x-a\\Vert\\_{\\alpha}lt\\eta}_{x\\in \\mathcal B_{\\alpha}(a,\\eta)}\\Rightarrow\\underbrace{\\Vert f(x)-f(a)\\Vert_{\\beta}\\lt\\varepsilon}_{x\\in \\mathcal B_{\\beta}(f(a),\\varepsilon)}\\)Equation de normes $\\Vert.\\Vert_{\\alpha}$ et $\\Vert.\\Vert_{\\beta}$ sont equivalentes ssi $\\exists A,B\\gt0$ tels que \\(\\forall x\\in\\mathbb R^n, A\\Vert x\\Vert_{\\beta}\\le\\Vert x\\Vert_T\\le B\\Vert x\\Vert_{\\beta}\\) TheoremeToutes les normes sont equivalentes en dimension finie Fonctions lipschitzienne Definition: Fonctions lipschitzienneUne fonction est $K-$lipschitzienne s‚Äôil existe $K\\gt0$ tel que\\[\\forall x,y\\in\\mathbb R^n, \\Vert f(x)-f(y)\\Vert\\le K\\Vert x-y\\Vert\\] TheoremeToute fonction lipschitzienne est continue.Exemple\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\x=\\begin{pmatrix}x_1\\\\ x_2\\end{pmatrix}&amp;amp;\\mapsto x_1+x_2\\end{aligned}\\\\\\begin{aligned}\\begin{cases} x\\in\\mathbb R^2\\\\ y\\in\\mathbb R^2\\end{cases}\\quad \\Vert f(x)-f(y)\\Vert&amp;amp;=\\vert(x_1+x_2)-(y_1+y_2)\\vert\\\\&amp;amp;= \\vert(x_1-y_1)+(x_2-y_2)\\vert\\le\\vert x_1-y_1\\vert+\\vert x_2-y_2\\vert\\end{aligned}\\\\\\Vert x- y\\Vert=\\biggr\\Vert\\begin{pmatrix}x_1\\\\ x_2\\end{pmatrix}-\\begin{pmatrix}y_1\\\\ y_2\\end{pmatrix}\\biggr\\Vert=\\biggr\\Vert\\begin{pmatrix}x_1 - y_1\\\\ x_2-y_2\\end{pmatrix}\\biggr\\Vert_1=\\vert x_1-y_1\\vert+\\vert x_2-y_2\\vert\\)Fonctions continues Toutes les fonctions polynomiales sont continues. Toutes les fractions rationnelles $\\frac{f(x)}{g(x)}, x\\in\\mathbb R^n$ sont continues partout ou $g(x)\\neq0$ Si $f:\\mathbb R^n\\to\\mathbb R^p$ continue, $g:\\mathbb R^n\\to\\mathbb R^p$ continue, $\\lambda,\\mu\\in\\mathbb R$ alors $\\lambda f-\\mu g$ continue. Si $p=1$, $fg$ continue, $\\frac{f}{g}$ continue partout ou $g$ ne s‚Äôannule pas. Si $f:\\mathbb R^n\\to\\mathbb R^p$ continue, $f:\\mathbb R^p\\to\\mathbb R^n$ continue, alors $g\\circ f:\\mathbb R^n\\to\\mathbb R^m$ continueExemple\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x+y\\end{aligned}\\]Est-ce que $x\\mapsto f(x,0)$ et $y\\mapsto f(0,y)$ continues $\\Rightarrow$ $f$ continue ?Bah non ca sera trop beau.\\[\\underbrace{x\\mapsto f(x,0)}_{f\\circ g(t)\\text{ avec } g:t\\mapsto(t,0)}\\\\\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto\\begin{cases} \\frac{xy}{x^2+y^2} &amp;amp;(x,y)+(0,0)\\\\ 0 &amp;amp;(x,y)=(0,0)\\end{cases}\\end{aligned}\\] Si $g:t\\to(t,0)$, $f\\circ g(t)=0$ $\\forall t\\in\\mathbb R$ Si $g:t\\to(0,t)$, $f\\circ g(t)=0$ $\\forall t\\in\\mathbb R$ Si $g:t\\to(t,t)$,\\[f\\circ g(t)=\\begin{cases}\\frac{1}{2} &amp;amp;t\\neq0\\\\0 &amp;amp;t=0\\end{cases}\\forall t\\in\\mathbb R\\]Exercice 3.34 Rappel\\(\\Vert x\\Vert_1 = \\sum_{i=1}^n\\vert x\\vert\\\\\\Vert x\\Vert_2=\\sqrt{\\sum_{i=1}^nx^2}\\\\\\Vert x\\Vert_{\\infty}=\\max_{i=1,..,n}\\vert x_i\\vert\\)\\[\\Vert x\\Vert_1=\\Vert x\\Vert_{\\infty}+\\sum\\vert\\underbrace{\\text{toutes les valeurs qui ne sont pas le max}}_{\\ge 0}\\vert\\\\\\Vert x\\Vert_{\\infty}\\le \\Vert x\\Vert_1\\le n\\Vert x\\Vert_{\\infty}\\\\\\begin{aligned}\\Vert x\\Vert_2\\le\\Vert x\\Vert_1\\quad \\Vert x\\Vert_2^2&amp;amp;=\\sum_{i=1}^nx_i^2=\\sum_{i=1}^n\\vert x_i\\vert^2\\\\\\Vert x\\Vert_1^2&amp;amp;=(\\sum_{i=1}^n\\vert x_i\\vert)^2= \\sum_{i=1}^n\\vert x_i\\vert^2 + 2\\sum_{1\\le i\\le j\\le n}\\vert x_i\\vert \\vert x_j\\vert\\end{aligned}\\\\\\begin{aligned}\\Vert x\\Vert_{\\infty}&amp;amp;=\\max_i\\vert x_i\\vert=\\vert x_{\\underbrace{j}_{\\text{index ou le max est atteint}}}\\vert\\\\&amp;amp;= \\sqrt{x_j^2}\\\\\\Vert x\\Vert_2 &amp;amp;= \\sqrt{\\sum_{i=1}^nx_i^2}\\\\&amp;amp;=\\sqrt{x_j^2+\\underbrace{\\sum_{i\\neq j}x_i^2}_{\\ge0}}\\\\&amp;amp;\\ge\\sqrt{x_j^2}\\\\&amp;amp;\\ge\\vert x_j\\vert\\\\&amp;amp;\\ge\\Vert x\\Vert_{\\infty}\\end{aligned}\\]\\[\\Vert x\\Vert_{\\infty}\\le\\Vert x\\Vert_2\\le\\Vert x\\Vert_1\\le n\\Vert x\\Vert_{\\infty}\\]" }, { "title": "DBRE: Regime de droit", "url": "/cours/posts/dbre_regime_droits/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-31 12:00:00 +0200", "snippet": "Lien de la note HackmdPartielPoints positifs et negatifs Bonne reponse: $100\\%$ des points Mauvaise reponse: $-0,1$pt a $-0,75$pt En fonction de l‚Äôincomprehension de la question Regime du droit R√©gime du droit des contrats date de 1804ordonnance du 10 f√©vrier 2016 Article 1101Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Le contrat est un accord de volont√©s entre deux ou plusieurs personnes destin√© √† cr√©er, modifier, transmettre ou √©teindre des obligations. Le contrat est la Loi des parties au contrat Article 1103Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats l√©galement form√©s tiennent lieu de loi √† ceux qui les ont faits. Force obligatoire du contrat peut saisir le juge pour faire rectifierLa libert√© contractuelle ne permet pas de d√©roger aux r√®gles qui int√©ressent l‚Äôordre public. (Article 1102) Article 1104Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats doivent √™tre n√©goci√©s, form√©s et ex√©cut√©s de bonne foi. Cette disposition est d‚Äôordre public. Article 1105Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Les contrats, qu‚Äôils aient ou non une d√©nomination propre, sont soumis √† des r√®gles g√©n√©rales, qui sont l‚Äôobjet du pr√©sent sous-titre. Les r√®gles particuli√®res √† certains contrats sont √©tablies dans les dispositions propres √† chacun d‚Äôeux. Les r√®gles g√©n√©rales s‚Äôappliquent sous r√©serve de ces r√®gles particuli√®res. Les contrats, qu‚Äôils aient ou non une d√©nomination propre, sont soumis √† des r√®gles g√©n√©rales, qui sont l‚Äôobjet du pr√©sent sous-titre.Est-ce qu‚Äôun mariage est une forme de contrat ?C‚Äôest plus une instution qu‚Äôun contrat Pour qu‚Äôun contrat soit valable, il faut qu‚Äôil soit valablement forme.Est-ce que le contrat est valablement forme ? Article 1128Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Sont n√©cessaires √† la validit√© d‚Äôun contrat : 1¬∞ Le consentement des parties ; 2¬∞ Leur capacit√© de contracter ; 3¬∞ Un contenu licite et certain.Si un contrat n‚Äôest pas valablement forme, il peut etre conteste. Un qui a pris l‚Äôascendant sur l‚Äôautre Un qui a trompe l‚Äôautre etc.Consentement des partiesCe consentement doit √™tre juridiquement intact, c‚Äôest √† dire ne pas √™tre vici√© Quelque chose qui altere le consentement Article 1130Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur, le dol et la violence vicient le consentement lorsqu‚Äôils sont de telle nature que, sans eux, l‚Äôune des parties n‚Äôaurait pas contract√© ou aurait contract√© √† des conditions substantiellement diff√©rentes. Leur caract√®re d√©terminant s‚Äôappr√©cie eu √©gard aux personnes et aux circonstances dans lesquelles le consentement a √©t√© donn√©. Article 1132Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur de droit ou de fait, √† moins qu‚Äôelle ne soit inexcusable, est une cause de nullit√© du contrat lorsqu‚Äôelle porte sur les qualit√©s essentielles de la prestation due ou sur celles du cocontractant. Article 1136Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 L‚Äôerreur sur la valeur par laquelle, sans se tromper sur les qualit√©s essentielles de la prestation, un contractant fait seulement de celle-ci une appr√©ciation √©conomique inexacte, n‚Äôest pas une cause de nullit√©. Article 1137Modifi√© par LOI n¬∞2018-287 du 20 avril 2018 - art. 5 Le dol est le fait pour un contractant d‚Äôobtenir le consentement de l‚Äôautre par des man≈ìuvres ou des mensonges. Constitue √©galement un dol la dissimulation intentionnelle par l‚Äôun des contractants d‚Äôune information dont il sait le caract√®re d√©terminant pour l‚Äôautre partie. N√©anmoins, ne constitue pas un dol le fait pour une partie de ne pas r√©v√©ler √† son cocontractant son estimation de la valeur de la prestation. Article 1145Modifi√© par LOI n¬∞2018-287 du 20 avril 2018 - art. 6 Toute personne physique peut contracter sauf en cas d‚Äôincapacit√© pr√©vue par la loi. La capacit√© des personnes morales est limit√©e par les r√®gles applicables √† chacune d‚Äôentre elles. Article 1146Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Sont incapables de contracter, dans la mesure d√©finie par la loi : 1¬∞ Les mineurs non √©mancip√©s ; 2¬∞ Les majeurs prot√©g√©s au sens de l‚Äôarticle 425. Article 1148Modifi√© par Ordonnance n¬∞2016-131 du 10 f√©vrier 2016 - art. 2 Toute personne incapable de contracter peut n√©anmoins accomplir seule les actes courants autoris√©s par la loi ou l‚Äôusage, pourvu qu‚Äôils soient conclus √† des conditions normales. Les incapacit√©s prot√®gent l‚Äôincapable Article 425Modifi√© par Loi n¬∞2007-308 du 5 mars 2007 - art. 7 () JORF 7 mars 2007 en vigueur le 1er janvier 2009 Toute personne dans l‚Äôimpossibilit√© de pourvoir seule √† ses int√©r√™ts en raison d‚Äôune alt√©ration, m√©dicalement constat√©e, soit de ses facult√©s mentales, soit de ses facult√©s corporelles de nature √† emp√™cher l‚Äôexpression de sa volont√© peut b√©n√©ficier d‚Äôune mesure de protection juridique pr√©vue au pr√©sent chapitre. S‚Äôil n‚Äôen est dispos√© autrement, la mesure est destin√©e √† la protection tant de la personne que des int√©r√™ts patrimoniaux de celle-ci. Elle peut toutefois √™tre limit√©e express√©ment √† l‚Äôune de ces deux missions. Utiliser un preambule pour definir clairement ce qu‚Äôon veut faire Description de l‚Äôoeuvre et de ce que l‚Äôon entend faire en des termes ‚Äúnormaux‚Äù Obligation d‚Äôun √©crit Attention √©crit obligatoire pour la preuve et pas pour la validit√©Chaque droit c√©d√© doit faire l‚Äôobjet d‚Äôune mention, ce qui n‚Äôest pas mentionn√© est sens√© √™tre conserv√© par l‚Äôauteur.On doit pr√©ciser √©tendue g√©ographique, la dur√©e, l‚Äôexcluivit√©, ‚Ä¶," }, { "title": "ASE2: TD 4", "url": "/cours/posts/ase2_td4/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, estimateur, Fisher, FDCR, maximum de vraisemblance", "date": "2021-03-31 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 16Soit une variable aleatoire $X$ de loi de Poisson de parametre $\\lambda$ ($\\lambda\\gt0$). Le but de cet exercice est de trouver une estimation de $\\theta=e^{-\\lambda}$.$(X_1,X_2,‚Ä¶,X_n)$ un echantillon de $X$ et $Y_1,Y_2,‚Ä¶,Y_n$ des v.a. definies par $Y_i=1$ si $X_i=0$ et $Y_i=0$ sinon, $\\forall i \\in[[1,n]]$.\\[S_n=\\sum_{i=1}^nX_i\\\\\\bar Y_n=\\frac{1}{n}\\sum_{i=1}^nY_i\\\\T_n=\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\] Montrer que $\\bar Y_n$ est un estimateur sans biais et convergent de $\\theta=e^{-\\lambda}$ Montrer que $T_n$ est un estimateur sans biais et convergent de $\\theta$ a) Etuder le sens de variation de $f$ definie sur $\\mathbb R_+$ par $f(t)=ne^{\\frac{t}{n}}-e^{t}-n+1$ et deduire son signe b) En deduire que $T_n$ est un estimateur de $\\bar Y_n$ Solution 1. $Y_i$ suit la loi de Bernoulli, le parametre de $Y_i$ est $P(Y_i=1)=P(X_i=0)=e^{-\\lambda}=\\theta$ donc $Y_i\\sim\\mathcal B(0)$\\[E(\\bar Y_n)=\\frac{1}{n}\\sum_{i=1}^nE(Y_i)=\\frac{1}{n}\\sum_{i=1}^n\\theta=\\frac{n\\theta}{n}=\\theta\\] $\\bar Y_n$ est sans biais.\\[V(\\bar Y_n)=\\frac{1}{n^2}\\sum_{i=1}^nV(Y_i)=\\frac{n\\theta(1-\\theta)}{n^2}=\\frac{\\theta(1-\\theta)}{n}\\to_{n\\to+\\infty}0\\\\V(\\bar Y_n)\\to_{n\\to+\\infty}0\\] En appliquant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert\\bar Y_n-E(\\bar Y_n)\\vert\\ge\\varepsilon)\\le\\frac{V(\\bar Y_n)}{\\varepsilon^2}=\\frac{\\theta(1-\\theta)}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\] Donc $\\bar Y_n\\to_{n\\to+\\infty}^P\\theta$ 2.\\[T_n=\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\\\\\begin{aligned}E(T_n) &amp;amp;= E\\biggr(\\biggr(\\frac{n-1}{n}\\biggr)^{S_n}\\biggr)\\\\&amp;amp;=\\sum_{k=0}^{+\\infty}\\biggr(\\frac{n-1}{n}\\biggr)^kP(S_n=k) \\text{ (car } E(\\phi(X))=\\sum_k\\phi(k)P(X=k))\\\\&amp;amp;=\\sum_{k=0}^{+\\infty}\\biggr(\\frac{n-1}{n}\\biggr)^ke^{-n\\lambda}\\frac{(n\\lambda)^k}{k!} \\text{ (car } S_n=\\sum_{i=1}^nX_i\\text{ somme independantes de Poisson }\\mathcal P(\\lambda))\\end{aligned}\\] Donc $S_n\\sim\\mathcal P(n\\lambda)$\\[\\begin{aligned}E(T_n)&amp;amp;=e^{-n\\lambda}\\sum_{k=0}^{+\\infty}\\frac{((n-1)\\lambda)^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}e^{(n-1)\\lambda}\\\\&amp;amp;=e^{-\\lambda}=\\theta\\end{aligned}\\] Rappel:\\[\\sum_{0}^{+\\infty}\\frac{x^k}{k!}=e^x\\] $T_n$ est sans biais\\[\\begin{aligned}E(T_n^2)&amp;amp;=E((\\frac{n-1}{n})^{2S_n})\\\\&amp;amp;= \\sum_0^{+\\infty}(\\frac{n-1}{n})^{2k}P(S_n=k)\\\\&amp;amp;= \\sum_0^{+\\infty}(\\frac{n-1}{n})^{2k}e^{-n\\lambda}\\frac{(n\\lambda)^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}\\sum_{k=0}^{+\\infty}\\frac{(\\frac{(n-1)^2\\lambda}{n})^k}{k!}\\\\&amp;amp;= e^{-n\\lambda}e^{(n-1)^2\\frac{\\lambda}{n}}\\\\&amp;amp;= e^{-n\\lambda}e^{(n^2-2n+1)\\frac{\\lambda}{n}}\\\\&amp;amp;= e^{-2\\lambda+\\frac{\\lambda}{n}}=\\theta^2e^{\\frac{\\lambda}{n}}\\end{aligned}\\] Donc\\[E(T_n^2)=\\theta^2e^{\\frac{\\lambda}{n}}\\] \\[\\begin{aligned}V(T_n)&amp;amp;=E(T_n^2)-E^2(T_n)\\\\&amp;amp;= \\theta^2e^{\\frac{\\lambda}{n}}-\\theta^2\\\\&amp;amp;=\\theta^2(e^{\\frac{\\lambda}{n}}-1)\\end{aligned}\\\\\\lim_{n\\to+\\infty}V(T_n)=0\\] En utilisant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-\\theta\\vert\\ge\\varepsilon)\\lt\\frac{V(\\bar Y_n)}{\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\Rightarrow T_n\\to_{n\\to+\\infty}^P\\theta\\] 3.a)\\[f(t)=ne^{\\frac{t}{n}}-e^t-n+1\\quad\\forall t\\in\\mathbb R_+\\\\f&#39;(t)=e^{\\frac{t}{n}}-e^t\\\\\\begin{cases}\\forall n\\ge1\\quad \\frac{t}{n}\\le t\\Rightarrow e^{\\frac{t}{n}}\\le e^t\\Rightarrow f&#39;(t)\\le0 &amp;amp;\\forall t\\in\\mathbb R_+\\\\\\forall t\\gt0\\quad f(t)\\text{ est decroissante et comme } f(0)=0&amp;amp;\\begin{aligned}&amp;amp;\\Rightarrow \\forall t\\ge0, f(t)\\le f(0)=0\\\\&amp;amp;\\Rightarrow\\color{green}{f(t)\\le0\\quad\\forall t\\ge0}\\end{aligned}\\end{cases}\\] b)\\[E(T_n)=\\theta\\\\E(\\bar Y_n)=\\theta\\] Les deux estimateurs sont sans biais. Comparons leurs variances\\[V(\\bar Y_n)=\\frac{\\theta(1-\\theta)}{n}, V(T_n)=\\theta^2(e^{\\frac{\\lambda}{n}}-1)\\\\\\begin{aligned}V(T_n)-V(\\bar Y_n)&amp;amp;=\\theta^2(e^{\\frac{\\lambda}{n}}-1)-\\frac{\\theta(1-\\theta)}{n}\\\\&amp;amp;= \\frac{\\theta^2}{n}(ne^{\\frac{\\lambda}{n}}-n-\\frac{1}{\\theta}+1)\\\\&amp;amp;= \\frac{\\theta^2}{n}(ne^{\\frac{\\lambda}{n}}-n-e^{\\lambda}+1)\\\\&amp;amp;= \\frac{\\theta^2}{n}f(\\lambda)\\\\\\text{Or } f \\text{ est negative}&amp;amp;\\Rightarrow V(T_n)-V(\\bar Y_n)\\le 0\\\\&amp;amp;\\Rightarrow\\color{green}{V(T_n)\\le V(\\bar Y_n)}\\end{aligned}\\] $T_n$ est un meilleur estimateur que $\\bar Y_n$ Exercice 17Soit $X$ une v.a. de loi $\\mathcal B(n,p)$ ou $p$ est inconnu..On veut estimer le parametre $p$.On considere un echantillon de $X$: $(X_1,X_2,‚Ä¶,X_n)$. Determiner la vraisemblance de l‚Äôechantillon Determiner l‚Äôestimateur de maximum de vraisemblance de $p$ Cet estimateur est-il sans biais ? Est-il convergent ? Montrer que cet estimateur est efficace Solution $X\\sim\\mathcal B(N,p)$, $\\theta=p$ inconnu. 1.\\[L(x_1,x_2,...,x_n,p)=\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}p^{\\sum_{i=1}^nx_i}(1-p)^{nN-\\sum_{i=1}^nx_i}\\] d‚Äôapres l‚Äôexercice 14. 2. L‚Äôequation de la vraisemblance:\\[\\frac{\\delta \\ln L}{\\delta p}=0\\\\\\ln L(x_1,...,x_n,p)=\\ln\\biggr(\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}\\biggr)+\\sum_{i=1}^nx_i\\ln(p)+(nN-\\sum_{i=1}^nx_i)\\ln(1-p)\\\\\\begin{aligned}\\frac{\\delta \\ln L}{\\delta p}&amp;amp;=\\frac{1}{p}\\sum_{i=1}^nx_i+(nN-\\sum_{i=1}^nx_i)\\frac{-1}{1-p}=0\\\\&amp;amp;\\Leftrightarrow (1-p)\\sum_{i=1}^nx_i-p(nN-\\sum_{i=1}^nx_i)=0\\\\&amp;amp;\\Leftrightarrow \\sum_{i=1}^nx_i-pnN=0\\\\&amp;amp;\\Leftrightarrow \\color{green}{\\hat p=\\frac{1}{nN}\\sum_{i=1}^nx_i} \\text{ estimation ponctuelle de }p\\end{aligned}\\] L‚Äôestimateur de maximum de vraisemblance est\\[T_n=\\frac{1}{nN}\\sum_{i=1}^nX_i\\] 3. $Tn$ sans biais ?\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{nN}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;=\\frac{1}{nN}\\sum_{i=1}^nNp\\\\&amp;amp;= \\frac{nNp}{nN}=\\color{green}{p}\\end{aligned}\\] \\[E(T_n) = p\\] $T_n$ est sans biais. 4. Convergence ? Rappel:\\[V(aX) = a^2\\times V(X)\\] \\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2N^2}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{1}{n^2N^2}\\sum_{i=1}^nNp(1-p)\\\\&amp;amp;= \\frac{nNp(1-p)}{n^2N^2}\\\\&amp;amp;=\\frac{p(1-p)}{nN}\\to_{n\\to+\\infty}0\\end{aligned}\\] D‚Äôapres Tchebychev $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-E(T_n)\\vert\\ge\\varepsilon)\\le\\frac{V(T_n)}{\\varepsilon^2}\\\\\\Rightarrow P(\\vert T_n-p\\vert\\ge\\varepsilon)\\le\\frac{p(1-p)}{nN\\varepsilon^2}\\to_{n\\to+\\infty}0\\] Donc\\[T_n\\to_{n\\to+\\infty}^Pp\\] $T_n$ converge en probabilite vers $p$. 5. Efficacite\\[\\underbrace{I_n(p)}_{\\text{information de Fisher}}=-E(\\frac{\\delta^2\\ln L}{\\delta p^2})\\\\\\frac{\\delta\\ln L}{\\delta p}=\\frac{1}{p}\\sum_{i=1}^nx_i-(nN-\\sum_{i=1}^nx_i)\\frac{1}{1-p}\\\\\\frac{\\delta^2\\ln L}{\\delta p^2}=-\\frac{1}{p^2}\\sum_{i=1}^nx_i+(nN-\\sum_{i=1}^nx_i)\\frac{-1}{(1-p)^2}\\\\\\begin{aligned}E(\\frac{\\delta\\ln L}{\\delta p^2}) &amp;amp;=-\\frac{1}{p^2}\\sum_{i=1}^nE(x_i)+(nN-\\sum_{i=1}^nE(x_i))\\frac{-1}{(1-p)^2}\\\\&amp;amp;=-\\frac{1}{p^2}nNp+\\frac{1}{(1-p)^2}(-nN+nNp)\\\\&amp;amp;= \\frac{-nN}{p}+\\frac{(-nN)}{1-p}\\\\&amp;amp;= \\frac{-nN(1-p)-nNp}{p(1-p)}\\\\&amp;amp;= \\frac{-nN}{p(1-p)}\\end{aligned}\\\\I_n(p) = -E(\\frac{\\delta\\ln L}{\\delta p^2})=\\frac{nN}{p(1-p)}\\] Donc \\(I_n(p)=\\frac{nN}{p(1-p)}\\) information de Fisher. Or:\\[V(T_n)=\\frac{p(1-p)}{nN}\\Rightarrow \\color{green}{V(T_n)=\\frac{1}{I_n(p)}}\\] Conclusion: $T_n$ est efficaceExercice 18Soit $X$ une distribution de Poisson $\\mathcal P(\\theta)$ ou $\\theta$ inconnu.$(X_1,‚Ä¶,X_n)$ un echantillon de $X$. Determiner la vraisemblance Determiner un estimateur de $\\theta$ Est-il sans biais ? Convergent ? Est-il efficace ? Solution $X\\sim\\mathcal P(\\theta)$ Poisson de parametre $\\theta$, $\\theta$: inconnu. 1.La vraisemblance est:\\[\\begin{aligned}L(x_1,x_2,...,x_n)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!} \\text{cf. exercice 14.}\\end{aligned}\\] 2.Methode du maximum de vraisemblance\\[\\frac{\\delta\\ln L}{\\delta\\theta}=0 \\text{ (eq. de la vraisemblance)}\\\\\\ln L(x_1,...,x_m,\\theta)=-n\\theta+\\sum_{i=1}^n\\ln \\theta-\\ln(\\Pi_{i=1}^nx_i!)\\\\\\begin{aligned}\\frac{\\delta\\ln L}{\\delta\\theta}=0&amp;amp;\\Leftrightarrow -n+\\frac{1}{\\theta}\\sum_{i=1}^nx_i=0\\\\&amp;amp;\\Leftrightarrow\\hat \\theta=\\frac{1}{n}\\sum_{i=1}^nx_i\\text{ estimation ponctulle de }\\theta\\end{aligned}\\] L‚Äôestimateur de $\\theta$ est $T_n=\\frac{1}{n}\\sum_{i=1}^nX_i$ 3.$Tn$ sans biais ?\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n\\theta\\\\&amp;amp;= \\frac{n\\theta}{n}=\\color{green}{\\theta}\\end{aligned}\\] \\[E(T_n)=\\theta\\] $T_n$ est sans biais. Convergence?\\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{n\\theta}{n}\\\\&amp;amp;=\\frac{\\theta}{n}\\end{aligned}\\\\V(T_n)=\\frac{\\theta}{n}\\to_{n\\to+\\infty}0\\] Donc en utilisant Tchebychev: $\\forall\\varepsilon\\gt0$\\[P(\\vert T_n-E(T_n)\\vert\\ge\\varepsilon)\\le\\frac{V(T_n)}{\\varepsilon^2}\\\\\\Rightarrow P(\\vert T_n-\\theta\\vert\\ge\\varepsilon)\\le\\frac{\\theta}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\] Donc\\[T_n\\to_{n\\to+\\infty}^P\\theta\\] 4.Efficacite On calcule l‚Äôinformation de Fisher:\\[I_n(\\theta)=-t(\\frac{\\delta^2\\ln L}{\\delta \\theta^2})\\\\\\frac{\\delta \\ln L}{\\delta\\theta}=-n+\\frac{1}{\\theta}\\sum_{i=1}^nx_i\\\\\\begin{aligned}I_n(\\theta)&amp;amp;=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\&amp;amp;=\\frac{1}{\\theta^2}\\sum_{i=1}^nE(x_i)\\\\&amp;amp;=\\frac{n\\theta}{\\theta^2}=\\color{green}{\\frac{n}{\\theta}}\\end{aligned}\\] \\[V(T_n)=\\frac{\\theta}{n}=\\frac{1}{I_n(\\theta)}\\] $T_n$ est efficace. Exercice 19Soit $X$ une v.a. continue de densite\\[f(x)=\\frac{A}{x^{1+\\frac{1}{\\theta}}}\\quad \\forall x\\ge 1, \\theta\\gt0\\] Determiner $A$ en fonction de $\\theta$ Soit $(X_1,X_2,‚Ä¶,X_n)$ un echantillon de $X$, Determiner la vraisemblance de cet echantillon Determiner l‚Äôestimateur du maximum de vraisemblance de $\\theta$ Est-il sans biais ? Convergent ? Est-il efficace ? Solution 1.$f$ etant une densite: $\\int_{\\mathbb R}f(x)dx=1$\\[A\\int_{1}^{+\\infty}\\frac{1}{x^{1+\\frac{1}{\\theta}}}dx=1\\\\A\\biggr[\\frac{-\\theta}{x^{\\frac{1}{\\theta}}}\\biggr]\\\\\\Rightarrow A\\theta=1\\Rightarrow\\color{green}{A=\\frac{1}{\\theta}}\\] 2.\\[\\begin{aligned}L(x_1,x_2,...,x_n,\\theta)&amp;amp;=\\Pi_{i=1}^nf(x_i)\\\\&amp;amp;=\\Pi_{i=1}^n\\frac{1}{\\theta}\\frac{1}{x_i^{1+\\frac{1}{\\theta}}}\\\\&amp;amp;=\\frac{1}{\\theta^n}\\frac{1}{\\Pi_{i=1}^nx_i^{1+\\frac{1}{\\theta}}}\\end{aligned}\\] 3.\\[\\ln L(x_1,x_2,...,x_n,\\theta)=-n\\ln\\theta-(1+\\frac{1}{\\theta})\\sum_{i=1}^n\\ln x_i\\] Equation de la vraisemblance:\\[\\frac{\\delta\\ln L}{\\delta\\theta}=0\\] \\[\\begin{aligned}\\frac{\\delta\\ln L}{\\delta\\theta}&amp;amp;=\\frac{-n}{\\theta}+\\frac{1}{\\theta^2}\\sum_{i=1}^n\\ln x_i=0\\\\&amp;amp;\\Rightarrow\\color{green}{\\hat\\theta=\\frac{1}{n}\\sum_{i=1}^n\\ln x_i}\\end{aligned}\\] L‚Äôestimateur de vraisemblance:\\[T_n=\\frac{1}{n}\\sum_{i=1}^n\\ln x_i\\] 4.\\[\\begin{aligned}E(T_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(\\ln x_i)\\\\&amp;amp;=\\frac{nE(\\ln x)}{n}\\\\&amp;amp;=E(\\ln x)\\end{aligned}\\] or:\\[\\begin{aligned}E(\\ln x)&amp;amp;=\\int_{1}^{+\\infty}\\ln xf(x)dx\\\\&amp;amp;=\\int_{1}^{+\\infty}\\frac{\\ln x}{\\theta ^{1+\\frac{1}{\\theta}}}dx\\end{aligned}\\] On integre par parties:\\[\\begin{cases}v=\\ln x &amp;amp;v&#39;=\\frac{1}{x}\\\\u&#39;=\\frac{1}{\\theta}x^{-1-\\frac{1}{\\theta}} &amp;amp;u=-x^{-\\frac{1}{\\theta}}\\end{cases}\\\\\\begin{aligned}E(\\ln x)&amp;amp;=\\underbrace{[-x^{-\\frac{1}{\\theta}}\\ln x]_1^{+\\infty}}_{=0 \\text{ quand }x\\to+\\infty}+\\int_1^{+\\infty}x^{-1-\\frac{1}{\\theta}}dx\\\\&amp;amp;=[-\\theta x^{-\\frac{1}{\\theta}}]_1^{+\\infty}=\\theta\\end{aligned}\\] Donc $E(T_n)=\\theta$ sans biais. Convergence ?\\[\\begin{aligned}V(T_n)&amp;amp;=\\frac{1}{n^2}\\sum_{i=1}^nV(\\ln x_i)\\\\&amp;amp;= \\frac{nV(\\ln X)}{n^2}\\\\&amp;amp;=\\frac{V(\\ln X)}{n}\\end{aligned}\\\\\\begin{aligned}E(\\ln^2x)&amp;amp;=\\int_1^{+\\infty}\\frac{\\ln^2x}{\\theta x^{1+\\frac{1}{\\theta}}}dx\\\\&amp;amp;=\\underbrace{[-x^{-\\frac{1}{\\theta}}\\ln^2x]_1^{+\\infty}}_{=0 \\text{ quand }x\\to+\\infty}+\\int_1^{+\\infty}\\frac{1\\ln x}{x^{1+\\frac{1}{\\theta}}}dx\\end{aligned}\\\\\\begin{cases}v=\\ln^2x &amp;amp;v&#39;=2(\\ln x)\\frac{1}{x}\\\\u&#39;=\\frac{1}{\\theta}x^{-1-\\frac{1}{\\theta}}, &amp;amp;u=-x^{-\\frac{1}{\\theta}}\\end{cases}\\\\\\begin{aligned}E(\\ln^2x)&amp;amp;=1\\theta\\int_1^{+\\infty}\\frac{\\ln xdx}{\\theta x^{1+\\frac{1}{\\theta}}}\\\\&amp;amp;=2\\theta E(\\ln x)\\\\&amp;amp;=2\\theta^2\\end{aligned}\\\\\\begin{aligned}V(T_n)&amp;amp;=\\frac{E(\\ln^2x)-E^2(\\ln x)}{n}\\\\&amp;amp;=\\frac{1}{n}(2\\theta^2-\\theta^2)\\\\&amp;amp;=\\frac{\\theta^2}{n}\\end{aligned}\\\\V(T_n)=\\frac{\\theta^2}{n}\\to_{n\\to+\\infty}0\\] D‚Äôapres Tchebychev $T_n\\to_{n\\to+\\infty}^P\\theta$ 5.Efficacite\\[I_n(\\theta)=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\\\frac{\\delta\\ln L}{\\delta\\theta}=-\\frac{n}{\\theta}+\\frac{1}{\\theta^2}\\sum_{i=1}^n\\ln x-i\\\\\\frac{\\delta^2\\ln L}{\\delta\\theta^2}=\\frac{n}{\\theta^2}-\\frac{2}{\\theta^3}\\sum_{i=1}^n\\ln x_i\\\\\\begin{aligned}I_n(\\theta)&amp;amp;=-E(\\frac{\\delta^2\\ln L}{\\delta\\theta^2})\\\\&amp;amp;=-\\frac{n}{\\theta}+\\frac{2}{\\theta^3}\\sum_{i=1}^nE(\\ln x_i)\\\\&amp;amp;=-\\frac{n}{\\theta^2}+\\frac{2}{\\theta^3}nE(\\ln x)\\\\&amp;amp;=-\\frac{n}{\\theta^2}+\\frac{2}{\\theta^3}n\\theta=\\color{green}{\\frac{n}{\\theta^2}}\\end{aligned}\\] Or $V(T_n)=\\frac{\\theta^2}{n}=\\frac{1}{I_n(\\theta)}$ Donc $T_n$ est efficace. " }, { "title": "PRST: Feuille de revisions", "url": "/cours/posts/prst_feuille_revisions/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-29 10:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1Question 10 Cet exercice est aussi present sur la feuille pour le 17/03/2021La loi du demi-cercle de Wigner de parametre $R$ a une densite nulle en dehors de $] ‚àí R; R[$. Sur $] ‚àí R; R[$, sa densite est donnee par\\[f(x)=\\frac{2}{\\pi R^2}\\sqrt{R^2-x^2}\\]Nous admettrons que sa variance est donnee par $\\frac{R^2}{4}$.En deduire un estimateur du parametre $R$ par la methode des moments. Solution\\[V(X)=\\frac{R^2}{4}\\\\\\Leftrightarrow R^2=4V(X)\\\\\\Leftrightarrow R=2\\sqrt{V(X)}\\] Donc:\\[\\hat R=2\\sqrt{S^2}\\] \\[S=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X)^2\\] On sait que $E(X)=0$ (symetrie). En effet, $E(X)=\\int_{-R}^Rx\\times\\frac{2}{\\pi R^2}\\sqrt{R^2-x^2}dx=0$. La fonction devient impaire car $\\times x$. On integre une fonction impaire sur l‚Äôintervalle $] ‚àí R; R[$. $V(X)=E(X^2)$ donc $E(X^2)=\\frac{R^2}{4}$\\[R=2\\sqrt{E(X)}\\Rightarrow\\hat R=2\\sqrt{\\frac{1}{n}\\sum_{i=1}^nx_i^2}\\]Question 11Soient $X$ et $Y$ deux variables aleatoires independantes et suivant toutes deux une loi normale centree reduite.Considerons les variables aleatoires $U = X + 2Y$ et $V = X ‚àí 3Y$ Montrer que le vecteur aleatoire $(U, V )^T$ est un vecteur gaussien. Les variables aleatoires U et V sont-elles independantes ? Solution 1. $X$ et $Y$ sont independants $\\Rightarrow(X,Y)^T$ vecteur gaussien\\[\\begin{pmatrix}U\\\\V\\end{pmatrix}=\\begin{pmatrix}1 &amp;amp; 2\\\\1&amp;amp;-3\\end{pmatrix}\\] $(U,V)^T$ gaussien comme image d‚Äôun vecteur gaussien comme application lineaire 2. On calcule la covariance et $Cov(U,V)=0$ \\[\\begin{aligned}Cov(X)&amp;amp;=E(UV)-\\underbrace{E(U)E(V)}_{=0}\\\\&amp;amp;= E((X+2Y)(X-3Y))\\\\&amp;amp;= E(X^2-3XY+2XY-6Y^2)\\\\&amp;amp;= E(X^2)+\\underbrace{E(XY)}_{=0}-6E(Y^2)\\\\&amp;amp;= E(X^2)-6E(Y^2)\\text{ car } V(X)=E(X^2)=1\\\\&amp;amp;=1-6=\\color{green}{5}\\end{aligned}\\] Donc elles ne sont pas independantes. Exercice 5La variable aleatoire $X$ suit une loi uniforme sur $[0;\\theta]$ avec $\\theta$ inconnu.Sa densite est par definition donnee par $f(x,\\theta)=\\frac{1}{\\theta}ùüô_{[0;\\theta]}(x)$ i.e. $f(x,\\theta)=1$ si $0\\le x\\le\\theta$ sinon 0. Montrer que sa densite peut etre ecrite $f(x,\\theta)=\\frac{1}{\\theta}ùüô_{[0;1]}(\\frac{x}{\\theta})$ En deduire que la fonction de vraisemblance definie sur $[0;+\\infty[\\times]0;+\\infty[$ s‚Äôecrit:\\(L(x_1,...,x_n,\\theta)=\\begin{cases}\\frac{1}{\\theta^n}&amp;amp;\\text{si} \\max x_i\\le\\theta \\\\ 0&amp;amp;\\text{sinon}\\end{cases}\\) ou encore \\(L(x_1,...,x_n,\\theta)=\\frac{1}{\\theta^n}ùüô_{[\\max 1\\le i\\le n;+\\infty]}(\\theta)\\) En deduire l‚Äôestimateur du maximum de vraisemblance du parametre $\\theta$ Quelle loi suit la v.a. $\\frac{X_1}{\\theta}$ On pose \\(T=\\max_{1\\le i\\le n}\\frac{X_i}{\\theta}\\). Determiner sa fonction de repartition $F_T$ Montrer que $\\mathbb P(\\alpha\\le T\\le1)=1-\\alpha^n$ En deduire un reel $\\alpha$ tel que $\\mathbb P(T\\in[\\alpha;1])=0,95$ Considerons des observations $x_1,‚Ä¶,x_n$. Notons \\(M=\\max_{1\\le i\\le n}x_i\\). Deduire des questions precedentes un intervalle de confiance pour le parametre $\\theta$ de niveau de confiance 0, 95. Solution 1.\\[\\begin{aligned}x\\in[0;\\theta]&amp;amp;\\Leftrightarrow0\\le x\\le\\theta\\\\&amp;amp;\\Leftrightarrow0\\le\\frac{x}{\\theta}\\le1\\\\&amp;amp;\\Leftrightarrow \\frac{x}{\\theta}\\in[0;1]\\end{aligned}\\] Donc \\(ùüô_{[0;\\theta]}(x)=ùüô_{[0;1]}(\\frac{x}{\\theta})\\) 2.\\[\\begin{aligned}L(x_1,...,x_n,\\theta)&amp;amp;=\\Pi_{i=1}^nf(x_i,\\theta)\\\\&amp;amp;= \\Pi_{i=1}^n\\frac{1}{\\theta}ùüô_{[0;\\theta]}(x_i)\\\\&amp;amp;= \\frac{1}{\\theta^n}\\Pi_{i=1}^nùüô_{[0;\\theta]}(x_i)\\end{aligned}\\] Pour que ce ne soit pas egale a $0$, $x_i\\in[0;\\theta]$\\[\\begin{aligned}L(x_1,...,x_n,\\theta)&amp;amp;=\\frac{1}{\\theta^n}ùüô_{[0;\\theta]}(\\max(x_i))\\\\&amp;amp;= \\frac{1}{\\theta^n}ùüô_{[\\max x_i;+\\infty]}(\\theta)\\end{aligned}\\] 3. EMV: $\\hat\\theta=\\max_{1\\le i\\le n}(x_i)$ 4. Loi uniforme sur $[0;1]$\\[F_{\\frac{X}{\\theta}}(x)=P(\\frac{X}{\\theta}\\le x)=P(X\\le\\theta x)\\\\\\color{red}{X\\sim U([0;\\theta])}=\\begin{cases}0 &amp;amp;\\text{si } x\\le0\\\\\\int_0^{\\theta x}\\frac{1}{\\theta}dt=x &amp;amp;\\text{si } \\theta x\\in[0;\\theta]\\color{red}{\\Leftrightarrow x\\in[0;1]}\\\\1 &amp;amp;\\text{si } \\color{red}{\\theta x\\lt\\theta\\text{, i.e. } x\\gt1}\\end{cases}\\\\=F_U(x) \\text{ avec } U=\\frac{X}{\\theta}\\sim U([0;1])\\] 5.\\[\\begin{aligned}F_T(x)&amp;amp;=P(\\max\\frac{X_i}{\\theta}\\le x)\\\\&amp;amp;= P(\\cap_{i=1}^n\\{X_i\\le x\\})=\\Pi_{i=1}^nP(\\frac{X_i}{\\theta}\\le n) \\text{ car les v.a. } x_i \\text{ sont independantes}\\\\&amp;amp;= P(\\frac{X}{\\theta}\\le x)^n\\text{ car les }\\frac{x_i}{\\theta}\\text{ ont les memes lois}\\end{aligned}\\\\F_T(x)=\\begin{cases}0 &amp;amp;x\\lt0\\\\x^n &amp;amp;x\\in[0;1]\\\\1 &amp;amp;x\\gt1\\end{cases}\\] 7. Resolution d‚Äôequation:\\[\\begin{aligned}1-\\alpha^n&amp;amp;=0,95\\\\\\alpha^n&amp;amp;=0,05\\\\\\alpha&amp;amp;=\\sqrt[n]{0,05}\\end{aligned}\\\\\\] 8. $T=\\max\\frac{x_i}{\\theta}$, $M=\\max x_i$, donc $T=\\frac{M}{\\theta}$ (car $\\theta\\gt0$)\\[P(\\sqrt[n]{0,05}\\le T\\le1)=095\\Rightarrow P(\\sqrt[n]{0,05}\\le\\frac{M}{\\theta}\\le 1)=0,95\\\\P(1\\le\\frac{\\theta}{M}\\le(0,05)^{-\\frac{1}{n}})=0,95\\Leftrightarrow P(M\\le\\theta\\le M(0,05)^{-\\frac{1}{n}})=0,95\\] \\[I\\subset[M, M(0,05)^{-\\frac{1}{n}}]\\] " }, { "title": "PRST: Feuille 2, suite - Exercices", "url": "/cours/posts/prst_feuille_2_suite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-29 09:00:00 +0200", "snippet": "Lien de la note HackmdExercice 14Considerons une variable aleatoire $X$ suivant une normale centree reduite et une variable aleatoire $\\varepsilon$ independante de la variable aleatoire $X$ telle:\\[P(\\varepsilon=-1)=P(\\varepsilon=1)=\\frac{1}{2}\\]Considerons la variable aleatoire $Y := \\varepsilon X$. Montrer que la variable aleatoire $Y$ suit une loi normale centree reduite Calculer $Cov(X,Y)$ Determiner la loi de la v.a. $X+Y$ Si c‚Äôest trop difficile, calculer $P(X+Y=0)$ En deduire que le vecteur aleatoire $(X,Y)^T$ n‚Äôest pas un vecteur gaussien. Bonus: determiner la fonction de repartition de $X+Y$ Solution 1. Pour $Y\\sim\\mathcal N(0,1)$, il faut montrer que $Y$ suit la meme loi que $X$ Soit $a$ et $b$ deux reels tels que $a\\le b$\\[\\begin{aligned}P(Y\\in[a;b]) &amp;amp;= P(\\{Y\\in[a;b]\\}\\cap\\{\\varepsilon=-1\\}) + P(\\{Y\\in[a;b]\\}\\cap\\{\\varepsilon=1\\})\\\\&amp;amp;= P(\\{-X\\in[a;b]\\}\\cap\\{\\varepsilon=-1\\}) + P(\\{X\\in[a;b]\\}\\cap\\{\\varepsilon=1\\})\\end{aligned}\\] Or les v.a. $\\varepsilon$ et $X$ sont independantes\\[\\begin{aligned}P(Y\\in[a;b]) &amp;amp;= P(-X\\in[a;b])\\times P(\\varepsilon=-1) + P(X\\in[a;b])\\times P(\\varepsilon=1)\\\\&amp;amp;= \\frac{1}{2}P(-X\\in[a;b]) + \\frac{1}{2}P(X\\in[a;b])\\\\X&amp;amp;\\sim\\mathcal N(0,1)\\\\\\alpha X&amp;amp;\\sim\\mathcal N(\\alpha m,\\alpha\\sigma^2)\\\\&amp;amp;= \\frac{1}{2}P(X\\in[a;b]) + \\frac{1}{2}P(X\\in[a;b])\\\\&amp;amp;= P(X\\in[a;b])\\end{aligned}\\] Y suit la meme loi que $X$ donc $Y\\sim\\mathcal N(0,1)$ Avec la fonction caracterisitique:\\[\\begin{aligned}\\phi_Y(X) &amp;amp;= E(e^{it\\psi})\\\\&amp;amp;= E(e^{-it\\psi}\\underbrace{ùüô_{\\varepsilon=-1}}_{\\text{fonction indicatrice}} + e^{it\\psi}ùüô_{\\varepsilon=1})\\\\&amp;amp;= E(e^{-itX}ùüô_{\\varepsilon=-1} + e^{itX}ùüô_{\\varepsilon=1})\\\\&amp;amp;= E(e^{-itX} ) E(ùüô_{\\varepsilon=-1}) + E(e^{itX})E(ùüô_{\\varepsilon=1})\\\\\\end{aligned}\\] 2.\\[\\begin{aligned}Cov(X,Y)&amp;amp;=E(XY)-\\underbrace{E(X)}_{=0}\\underbrace{E(Y)}_{=0}\\\\&amp;amp;=E(XY)=E(\\varepsilon X^2)\\end{aligned}\\] Les v.a. $\\varepsilon$ et $X$ sont independnates donc $\\varepsilon$ et $X^2$ aussi.\\[Cov(X,Y)=E(\\varepsilon)E(X^2)\\\\E(\\varepsilon)=\\frac{1}{2}\\times-1+\\frac{1}{2}\\times1 =0\\] 3.\\[P(X+Y=0)=P(X=-Y)=P(\\varepsilon=-1)=\\frac{1}{2}\\\\P(X+Y=2X)=\\color{red}{P(Y=X)}=P(\\varepsilon =1)=\\frac{1}{2}\\] Ecrit ‚Äúsavamment‚Äù:\\[\\delta_{a}(A)=\\begin{cases}0 &amp;amp;\\text{si } a\\not\\in A\\\\1 &amp;amp;\\text{si } a\\in A\\end{cases}\\] \\[\\mu_Y=\\frac{1}{2}\\delta_0+\\frac{1}{2}\\mu_X\\] Mais c‚Äôest pas ce qui nous interesse lul 4. Deux types de v.a.: discrete et continue Y n‚Äôest pas continue car la probabilite d‚Äôetre egale a un certain nombre et toujours egal a $0$. On cherche pas un nombre mais un intervalle. Si $X+Y$ etait gaussienne $P(X+Y=0)=0$ car dans le cas continue la probabilit√© d‚Äôun √©v√©nement en particulier vaut toujours 0. D‚Äôapres la question precedente, $P(X+Y=0)=\\frac{1}{2}$ la combinaison lineaire $X+Y$ n‚Äôest pas guassienne donc le vecteur n‚Äôest pas gaussien Bonus: On pose $Z=X+Y$.\\[\\begin{aligned}P(Z\\le z)&amp;amp;= P(\\{Z\\le z\\}\\cap\\{\\varepsilon=-1\\})+P(\\{Z\\le z\\}\\cap\\{\\varepsilon=1\\})\\\\&amp;amp;= P(\\{0\\le z\\}\\cap\\{\\varepsilon=-1\\})+P(\\{2X\\le z\\}\\cap\\{\\varepsilon=1\\})\\text{ les v.a. sont independantes}\\end{aligned}\\] Si $z=0$, $F_Z(z)=\\frac{1}{2}\\times F_X(\\frac{z}{2})$ Si $z\\ge0$, $F_Z(z)=\\frac{1}{2}+\\frac{1}{2}F_X(\\frac{z}{2})$ \\[F_Z(z)=\\begin{cases}\\frac{1}{2}F_X(\\frac{z}{2}) &amp;amp;\\text{si }z\\lt0\\\\\\frac{1}{2}+\\frac{1}{2}F_X(\\frac{z}{2}) &amp;amp;\\text{si } z\\ge0\\end{cases}\\]" }, { "title": "PRST: Exos pour le 24/03", "url": "/cours/posts/prst_exercice_du_24_03/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-24 15:30:00 +0100", "snippet": "Lien de la note HackmdExercice 1Considerons une variable aleatoire $X$ suivant une loi de Poisson de parametre $0, 2$. Calculer $P(X = 4)$. Calculer $E(X)$ et $V(X)$. Solution $P(X=4) e^{-0,2}\\frac{0,2^4}{4!}=5,45\\times10^{-5}$ $E(X)=0,2$ $V(X)=0,2$Exercice 2La variable aleatoire $U$ suit une loi uniforme sur l‚Äôintervalle $[2; 7]$. Calculer $P(U \\in [3; 5])$ puis $E(U)$. Solution $P(U\\in[3,5])=\\frac{5-3}{7-2}=\\frac{2}{5}$ $E(U)=\\frac{a+b}{2}=\\frac{2+7}{2}=4,5$Exercice 3La loi de Skellam est definie sur $N$ comme la difference de deux variables aleatoires independantes suivant des lois de Poisson $\\mathcal P(\\lambda_1)$ et $\\mathcal P(\\lambda_2)$ avec $\\lambda_1 \\ge 0$ et $\\lambda_2 \\ge 0$.Soient $N_1$ et $N_2$ des variables aleatoires independantes suivant respectivement des lois de Poisson $\\mathcal P(\\lambda_1)$ et $\\mathcal P(\\lambda_2)$.Par definition, la variable aleatoire $X := N_1 ‚àí N_2$ suit une loi de Skellam de parametres $\\lambda_1$ et $\\lambda_2$ Montrer que $E(X) = \\lambda_1 ‚àí \\lambda_2$ et $V(X) = \\lambda_1 + \\lambda_2$ Consid√©rons un echantillon $(X_1, . . . , X_n)$ de la loi de $X$. Determiner, a l‚Äôaide de la methode des moments, des estimateurs des parametres $\\lambda_1$ et $\\lambda_2$. Solution\\[\\begin{aligned}E(X) &amp;amp;= E(N_1-E(N_2))\\\\&amp;amp;= E(N_1)-E(N_2)\\\\&amp;amp;= \\lambda_1-\\lambda_2\\end{aligned}\\]\\[\\begin{aligned}V(X) &amp;amp;= V(N_1-N_2)\\\\&amp;amp;= \\underbrace{V(N_1) + V(-N_2)}_{N_1\\text{ et }N_2\\text{ sont independantes}}\\\\&amp;amp;= \\lambda_1+(-1)^2V(N_2)\\\\&amp;amp;=\\lambda_1+\\lambda_2\\end{aligned}\\] On sait que\\[\\begin{cases}E(X)=\\lambda_1-\\lambda_2\\\\V(X)=\\lambda_1+\\lambda_2\\end{cases}\\\\\\begin{cases}E(X)=\\lambda_1-\\lambda_2\\\\E(X) + V(X)=2\\lambda_1\\end{cases}\\\\\\begin{cases}\\lambda_2=\\lambda_1-E(X)=\\frac{V(X)-E(X)}{2}\\\\\\lambda_1=\\frac{E(X)+V(X)}{2}\\end{cases}\\] D‚Äôou, par la methode des moments:\\[\\begin{cases}\\hat\\lambda_1=\\frac{\\bar X+S^2}{2}\\\\\\hat\\lambda_2=\\frac{S^2-\\bar X}{2}\\\\\\end{cases}\\]" }, { "title": "PRST: Seance 5 - Intervalle de confiance, suite", "url": "/cours/posts/prst_seance_5_suite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-24 14:30:00 +0100", "snippet": "Lien de la note Hackmd $X_1$ suit une loi normale $S_n^{2*}:=\\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2$ $\\frac{nS_n^{2*}}{\\sigma^2}$ suit une loi $\\mathcal X^2(n)$ A connaitre\\(\\begin{aligned}X_i&amp;amp;\\sim\\mathcal N(m,\\sigma^2)\\\\X_i-m&amp;amp;\\sim\\mathcal N(0,\\sigma^2)\\\\\\frac{X_i-m}{\\sigma}&amp;amp;\\sim\\mathcal N(0,1)\\end{aligned}\\)\\[\\sum_{i=1}^n\\frac{(X_i-m)^2}{\\sigma^2}\\sim\\mathcal X^2(n)\\\\S_n^{2*}=\\frac{1}{n}\\sum_{i=1}^n(X_i-m)^2\\\\\\frac{nS_n^{2*}}{\\sigma^2}\\sim\\mathcal X^2(n)\\\\\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2*}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}\\\\\\frac{1}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}}\\le\\frac{\\sigma^2}{nS_n^{2*}}\\le \\frac{1}{\\mathcal X^2_{\\frac{\\alpha}{2}}}\\\\\\frac{nS_n^{2*}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}}\\le\\sigma^2\\le\\frac{nS_n^{2*}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}\\]\\[P(\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2*}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}) = 1 - \\alpha\\] La loi $\\mathcal X^2$ n‚Äôest pas symetrique. L‚Äôintervalle de confiance au niveau $1-\\alpha$ pour la variance $\\sigma^2$ est:\\[[\\frac{nS_n^{2*}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}};\\frac{nS_n^{2*}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}]\\] $X_1$ suit une loi normal $\\bar X_n$ est un estimateur sans biais de $m$ $S_n^2:=\\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar X_n)^2$ $\\frac{(n-1)S_n^2}{\\sigma^2}$ suit une loi $\\mathcal X^2(n-1)$ \\[P(\\mathcal X^2_{\\frac{\\alpha}{2}} \\le \\frac{nS_n^{2}}{\\sigma^2} \\le\\mathcal X^2_{1-\\frac{\\alpha}{2}}) = 1 - \\alpha\\] L‚Äôintervalle de confiance au niveau $1-\\alpha$ pour la variance $\\sigma^2$ est:\\[[(n-1)\\frac{s_n^{2}}{\\mathcal X^2_{1-\\frac{\\alpha}{2}}};(n-1)\\frac{s_n^{2}}{\\mathcal X^2_{\\frac{\\alpha}{2}}}]\\]" }, { "title": "DBRE: Masterclass", "url": "/cours/posts/dbre_masterclass/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-24 12:00:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Cours n¬∞1 (01/10/2019)Pr√©sentation du cours 12h de module. 4h rajout√©es ou non, pour aller aux prud‚Äôhommes. Si on peut aller aux prud‚Äôhommes, des questions g√©n√©rales sur le d√©roulement des prud‚Äôhommes peuvent appara√Ætre dans les exams ou QCM. Les conflits en droit du travail ne seront pas √©tudi√©s. Focus sur ce qu‚Äôest un contrat de travail, les clauses importantes et les modes de rupture des contrats de travail, ainsi que leurs cons√©quences, comment on recourt √† un mode plut√¥t qu‚Äôun autre‚Ä¶ L√©gifrance : site √† jour contenant les lois.Quels sont les textes que l‚Äôon va utiliser en droit du travail¬†?On a d‚Äôabord la loi (au sens large) : Tous les droits fondamentaux La convention europ√©enne des droits de l‚Äôhomme (aucune loi ne peut aller contre ces libert√©s mais elles peuvent √™tre contradictoires) par exemple: chacun a le libre exercice de la profession de son choix. Mais il faut sauvegarder les interets de l‚Äôentreprise. Ces libert√©s fondamentales vont limiter les possibilit√©s de l‚Äôemployeur. On applique aussi les principes fondamentaux du droit des contrats, et donc le code civil.La relation individuelle de travail est un contrat, du coup la th√©orie g√©n√©rale des contrats a vocation √† s‚Äôappliquer. On applique aussi le code du travail (thanks Sherlock). On va aussi appliquer les conventions collectives. En gros, c‚Äôest une convention, un contrat, qui est n√©goci√© au niveau des branches d‚Äôactivit√©s au niveau national entre des repr√©sentations syndicales et des repr√©sentations des entreprises qui viennent pr√©ciser le droit du travail sur un secteur sp√©cifique. √Ä quelques exceptions pr√®s, ces conventions doivent apporter des dispositions qui sont plus favorables aux salari√©s que la Loi. Cela s‚Äôapplique sur un secteur pas un m√©tierExemple : L‚Äôenseignement sup√©rieur priv√© hors contrat pour EPITA (pour les ACUs par exemple).L‚ÄôEtat fran√ßais a toujours pouss√© √† ce qu‚Äôil y ait le plus de conventions collectives. Le but √©tant que l‚ÄôEtat n‚Äôintervienne pas trop mais laisse ce droit aux collectivit√©s. Il ne va √™tre impliqu√© que pour les m√©tiers pas encore couverts par des conventions collectives, en √©largissant une autre convention collective pour qu‚Äôelle affecte ce m√©tier par exemple.Les conventions trop favorables se sont faites d√©noncer. Ironiquement, les conventions s‚Äôappliquent sur toutes les personnes dans le secteur d‚Äôactivit√©, quelqu‚Äôun qui descend dans les mines aura les m√™mes avantages que l‚ÄôIng√©nieur qui l‚Äôa envoy√©. Les accords d‚Äôentreprise ou de branche qui vont pr√©ciser dans une entreprise un accord qui fixe des r√®gles diff√©rentes qui sont plus favorables que les conventions collectives. Les contrats de travail individuels qui doivent √™tre plus favorables que les accords d‚Äôentreprise.On va limiter notre √©tude au droit du salari√©, pas au droit public (pour les fonctionnaires).Un stagiaire n‚Äôest pas un salari√©, les r√®gles qui s‚Äôappliquent ne sont donc pas du tout les m√™mes. Donc on n‚Äôen parlera pas ici (ou au moins pas trop). Salaire &amp;gt; avantage (pour les retraites) et de nombreuses indemnit√©s sont calcul√©es sur les salairesA part quelques exceptions, en droit du travail, lors de contradictions entre deux textes, on applique le texte donnant le plus d‚Äôavantages au salari√©.Si le droit du travail est si avantageux pour les salari√©s, c‚Äôest qu‚Äôil y a un lien de subordination, et un √©tat de d√©pendance √©conomique, entre l‚Äôemploy√© et l‚Äôemployeur. C‚Äôest donc pour prot√©ger les employ√©s que ces lois existent avant tout. C‚Äôest beaucoup plus grave d‚Äôavoir un employeur qui insulte ses employ√©s plut√¥t que l‚Äôinverse, car il a d‚Äôautres moyens √† sa disposition.Ne pas laisser de traces des insultes (√©crit, r√©pondeur). Il faut plus r√©fl√©chir avant d‚Äô√©crire qu‚Äôavant de parler, car il est interdit d‚Äôenregistrer une personne √† son insu. Bien qu‚Äôil semble moins ‚Äúviolent‚Äù d‚Äôinsulter par √©crit que par oral.Preuves en droit du travailEn droit, la preuve reste un √©l√©ment d√©terminant. Ce qui ne peut pas √™tre prouv√© de fa√ßon l√©gale n‚Äôexiste pas.C‚Äôest √† celui qui pr√©tend quelque chose de le prouver.En droit du travail, le juge ne recherche pas les preuves. C‚Äôest aux parties de donner des preuves.Il peut √† titre exceptionnel demander une expertise.Pour tout ce qui est pr√©visible, on demande des preuves √©crites (la dur√©e d‚Äôun pr√©avis, d‚Äôune p√©riode d‚Äôessai).Il faut avoir un souci de tra√ßabilit√© que l‚Äôon soit employeur ou employ√© (ne pas partir dans la parano√Øa non plus).Pour tout ce qui est factuel, on va admettre des preuves par t√©moins et des preuves plus souples.Un √©crit valide est un acte sign√© et dat√© par chaque partie. Il doit y avoir autant d‚Äôexemplaires que de parties √† l‚Äôacte.Une promesse unilat√©rale n‚Äôa besoin que d‚Äôun exemplaire dat√© et sign√©.Une lettre, un mail, un SMS ne sont pas des √©crits au sens du droit mais sont des commencements de preuves, mais ne sont pas des preuves probantes.Avoir des preuves peut permettre d‚Äô√©viter des proc√®s.Pas de preuve, pas de droit. Pas de droit‚Ä¶ pas de droit.Pas de palais‚Ä¶ pas de palais.On peut aussi utiliser des attestations (t√©moignages). Constat de huissier : entre 200 et 500 euros. En vrai, √ßa d√©pend de la demande, on est √† moins cher dans le cas de l‚Äôauthentification d‚Äôun message t√©l√©phonique par exemple. Retranscrire un message √©lectronique par huissier : 100-150 eurosNe jamais oublier que l‚Äôemployeur est une personne morale et non une personne physique. La personne physique repr√©sentant cette personne morale peut changer (exemple¬†: promesse d‚Äôaugmentation).R√¥le de la jurisprudence en droit du travailOn a beau avoir le code du travail le plus √©pais du monde (vraiment ?), on a beaucoup de cas qui ne sont pas d√©finis dans le code du travail. On laisse alors au juge le soin d‚Äôinterpr√©ter. Ce sont les juges qui d√©finissent ce qu‚Äôest une faute grave ou un manquement.La jurisprudence va jouer un r√¥le important dans la loi du travail. Les juges de la cour de cassation ont de fait un grand pouvoir normatif en loi du travail d√ª √† leurs interpr√©tations de la loi. Quand la loi doit √™tre interpr√©t√©e, c‚Äôest le r√¥le de la cour de cassation, pour que tout le monde interpr√®te la loi de la m√™me mani√®re.Sur certains points, pour avoir une r√©ponse compl√®te √† une question, il va falloir regarder la loi¬†; les conventions collectives et les jurisprudences (toutes les jurisprudences sont disponibles sur L√©gifrance).Le droit international du travail adh√®re √† certaines conventions mais le droit international fixe o√π s‚Äôapplique le droit international fran√ßais. Tous les contrats sont soumis au droit fran√ßais s‚Äôils sont ex√©cut√©s sur le territoire fran√ßais. M√™me en √©tant fran√ßais, vous ne b√©n√©ficierez pas du droit du travail fran√ßais si vous travaillez √† l‚Äô√©tranger.Ca donne lieu parfois √† des difficult√©s, par exemple pour le t√©l√©travail. On fait alors appel au droit international pour savoir quel droit appliquer (celui de l‚Äôemployeur ou celui de l‚Äôemploy√©).Qu‚Äôest qu‚Äôun contrat de travail ?La qualification du contrat de travail est un vrai sujet d‚Äôactualit√© pour les juges.Les employeurs cherchent de la souplesse dans le contrat de travail tandis que l‚Äôemploy√© cherche de la stabilit√©.L‚Äôemployeur a autant besoin de souplesse que l‚Äôemploy√© de stabilit√©.Fillon : est-ce qu‚Äôil y avait un contrat de travail¬†?FN : qui √©tait l‚Äôemployeur ?R√©cemment, de nombreuses personnes qui n‚Äô√©taient pas salari√©es, les prestataires de services, pr√©tendent aux droits du travail (Uber, Deliveroo)D‚Äôun point de vue historique, la cr√©ation de l‚Äôauto-entreprenariat a multipli√© l‚Äôutilisation de la prestation de service. C‚Äô√©tait un des buts des lois sur l‚Äôauto-entreprenariat.Les juges ont d√ª d√©finir ce qu‚Äô√©tait un contrat de travail. Dans un contrat de travail, il y a trois points indispensables : la r√©alisation d‚Äôune prestation effective (le taff) le versement d‚Äôune r√©mun√©ration (le salaire) un lien de subordination (c‚Äôest qui le patron ?)Le lien de subordination va souvent √™tre prouv√© √† l‚Äôaide d‚Äôindices. La soumission √† des horaires / ordres, le lieu du travail, les consignes re√ßues, le pouvoir de sanction.Pour la cour de cassation, c‚Äôest la relation entre les parties qui va dire si c‚Äôest un contrat de travail ou pas. Peu importe ce qui est √©crit, ce qui compte ce sont les conditions de faits qui d√©finissent si c‚Äôest un contrat de travail ou une prestation (auto-entrepreneur)Des salari√©s de bo√Ætes de consulting qui sont envoy√©s dans d‚Äôautres bo√Ætes ne doivent pas √™tre trait√©s comme des employ√©s de l‚Äôautre bo√Æte.C‚Äôest l‚Äôarr√™t √éle de la tentation (3 Juin 2009), c‚Äôest un arr√™t de la cour de cassation. Les tentateurs ont demand√© la requalification de contrat.Il y a eu un lien de subordination (il y avait des ordres, des horaires). Donc il devait y avoir un contrat de travail. Depuis cet arr√™t, dans les jeux, ils font des contrats de travail.C‚Äôest cette jurisprudence qui est tr√®s utilis√©e pour requalifier le contrat.Cours n¬∞2 (15/10/2019)La qualification que donnent les parties √† leur relation importe peu. C‚Äôest la vraie relation de fait qui est prise en compte.Effectivement, il y a un caract√®re subjectif, il peut y avoir des conflits parce que cela peut toujours √™tre discut√©.C‚Äôest au juge d‚Äôappr√©cier.Il y a des faits qui imposent des qualifications juridiques. Quand on essaye de jouer avec les r√®gles pour d√©guiser ce que l‚Äôon fait, si le juge s‚Äôen rend compte, il peut requalifier, voire contre-lettre (&amp;lt;‚Äì c koi contre-lettre ?)L‚Äôarr√™t √éle de la tentation est toujours cit√© car les juges utilisent cette m√™me logique depuis.La preuveL‚Äô√©crit sert uniquement de preuve suppl√©mentaire pour prouver les engagements, mais il peut y avoir engagement sans √©crit.Le contrat de travail est obligatoire en droit du travail et d√©crit le contenu des engagements des parties.En l‚Äôabsence d‚Äô√©crit, on se r√©f√®re au droit du travail au minimum (et √©ventuellement aux accords d‚Äôentreprise en vigueur).Cela ne veut surtout pas dire que sans √©crit il n‚Äôy a pas de contrat. Dans notre situation, un √©crit pour un salari√© ne repr√©sente pas un avantage mais un inconv√©nient (sauf pour la r√©mun√©ration).Ce qui est vraiment obligatoire, c‚Äôest de d√©clarer le salari√© √† l‚ÄôURSSAF pour la d√©claration √† l‚Äôembauche.De mani√®re plus g√©n√©rale, en droit du travail¬†: Pas de preuve, pas de droit¬†! Idem est non esse aut non probari.Il est la m√™me chose de ne pas √™tre, que de ne pas √™tre prouv√©.En droit civil, pour qu‚Äôune √©coute soit l√©gale, il faut pr√©venir la personne pour l‚Äô√©coute¬†; en droit p√©nal, il faut que le juge soit pr√©venu.La l√©galit√© de la preuve n‚Äôest pas la m√™me en droit p√©nal qu‚Äôen droit civil.En outre, en droit civil, c‚Äôest aux parties elles-m√™mes de prouver leurs dires.Toutes relations entre personne priv√©e (personne physique ou morale), c‚Äôest aux particuliers de prouver ce qu‚Äôils pr√©tendent. Ce n‚Äôest pas au juge.Certaines preuves peuvent tr√®s rarement √™tre demand√©es par le juge, mais c‚Äôest exceptionnel.Exemple¬†:Un barman vole dans la caisse. Le patron installe une cam√©ra de vid√©osurveillance non d√©clar√©e et surprend le salari√©, et renvoie le barman.Cependant, comme la preuve est ill√©gale, la cour de justice a consid√©r√© le vol comme non prouv√© (donc qui n‚Äôexiste pas) et a donc consid√©r√© que le licenciement est abusif.Il y a une affaire o√π un majordome avait fait des √©coutes sauvages. Elles n‚Äôont pas √©t√© utilis√©es en civil et il a fallu attendre que dans le p√©nal un juge d√©cide qu‚Äôil veuille utiliser la preuve pour qu‚Äôelles soient utilis√©es (et l√©gales).Il faut essayer autant que l‚Äôon peut de se pr√©-constituer des preuves. Donc il faut de la tra√ßabilit√© dans ce que l‚Äôon fait. Il ne faut pas non plus √™tre parano√Øaque mais il faut autant que l‚Äôon peut en constituer.Une bonne preuve permet souvent de ne pas aller aux prud‚Äôhommes. Attention √† ne pas se constituer des preuves contre soi.Si vous voulez insulter quelqu‚Äôun, dites-lui mais ne l‚Äô√©crivez pas.Ne laissez pas de messages d√©biles sur un r√©pondeur t√©l√©phonique, n‚Äôenvoyez pas des SMS ou des e-mails injurieux, etc.Les modes de preuve (ordre hi√©rarchique d‚Äôimportance / pertinence) : Aveu judiciaire¬†: devant le juge. Reine des preuves, rare en droit du travail. Acte authentique (fait chez un notaire / officier de police‚Ä¶). Pas utilis√© en droit du travail. Acte sous seing priv√©. Acte formel sign√© par les deux parties. Par exemple un contrat de travail. Un √©crit. Un acte avec autant d‚Äôexemplaires que de parties. Les montants doivent √™tre √©crits en chiffres et en lettres. Exemple¬†: Convention de stage. Commencement de preuve par √©crit. On ne peut prouver qu‚Äôavec ce qu‚Äôon re√ßoit, pas avec ce qu‚Äôon envoie. Par exemple, un accus√© de r√©ception de lettre recommand√©e prouve qu‚Äôon a envoy√© quelque chose, mais pas son contenu. Pour les preuves d‚Äôinventions ou de propri√©t√© intellectuelle, on peut s‚Äôenvoyer √† soi-m√™me avec recommand√© une lettre scell√©e contenant une preuve de la chose¬†; en cas de jugement, on pourra desceller √† l‚Äôaudience et cela prouvera qu‚Äô√† date du recommand√© la chose existait d√©j√†. Le t√©moignage¬†: pour les faits o√π on n‚Äôa pas pu se constituer une preuve. Aveu extra-judiciaire : quasiment aucune valeur. Attention, en signant un contrat le pire pi√®ge est de signer un contrat sans avoir la signature de l‚Äôautre.Pour le demander de mani√®re pas trop frontale, on peut le demander pour la bonne forme.L‚Äôemployeur est une personne morale. La personne physique qui le repr√©sente ne s‚Äôengage pas √† raison personnelle.Par exemple, s‚Äôil vous promet √† l‚Äôoral une prime, puis qu‚Äôil d√©missionne ou meurt, vous ne pourrez pas le prouver √† son successeur.Un √©crit ne peut √™tre contredit que par un autre √©crit de m√™me hi√©rarchie.Il faut respecter un parall√©lisme dans les preuves.Par exemple, si on nous demande par recommand√©, on r√©pond par recommand√©.Attestation¬†: √©crit formel servant √† prouver la bonne foi d‚Äôune partie.Les diff√©rentes formes du contrat de travailDeux grandes formes de contrats de travail : Contrat de travail √† dur√©e d√©termin√©e (CDD) Contrat de travail √† dur√©e ind√©termin√©e (CDI)Il en existe d‚Äôautres.Les juges ont une ligne directrice, qui dit que : La forme normale du travail, c‚Äôest le CDI √† temps plein.C‚Äôest ce qui va guider les juges dans leur jugement.Tous les textes de lois doivent √™tre interpr√©t√©s √† la lumi√®re de ce principe.(Personne ne veut d‚Äôun CDD ou temps partiel en principe).En cons√©quence, les cas de recours au CDD doivent √™tre exceptionnels.La loi fixe les cas de recours.Un CDD ne doit pas pourvoir un poste durable et permanent.Il y a globalement 3 cas de recours aux CDD¬†: Remplacement de salari√©s absents (cong√© maladie, cong√© parental, cong√© sabbatique‚Ä¶). Il faut bien noter la personne que le ‚ÄúCDDiste‚Äù va remplacer. Accroissement temporaire d‚Äôactivit√© (emplois saisonniers, commande exceptionnelle, besoin de personnel durant une p√©riode‚Ä¶). Cas autoris√©s par la loi (CDD d‚Äôusage).Si on a un peu jou√© avec la loi et que le CDD est en r√©alit√© durable et permanent, le CDD peut √™tre requalifi√© en CDI.Le CDD doit √™tre pass√© par √©crit, justement pour prouver qu‚Äôil s‚Äôagit d‚Äôun CDD plut√¥t qu‚Äôun CDI.Cependant, dans certains cas, l‚Äôemployeur peut prouver qu‚Äôil s‚Äôagit d‚Äôun CDD. ==&amp;gt; quels cas ? : myst√®re et boule de gommeDans le cas normal :A d√©faut de contrat sign√© dans les 48 heures ouvrables, vous √™tes r√©put√© avoir √©t√© embauch√© en CDI √† temps plein sans p√©riode d‚Äôessai.Le temps partielLe temps partiel doit √™tre pass√© par √©crit.Le l√©gislateur demande √† r√©partir les horaires pour √©viter les interruptions trop longues (de sorte que l‚Äôemploy√© soit disponible pour un autre travail √† temps partiel).S‚Äôil y a un accroissement d‚Äôactivit√©, l‚Äôemploy√© √† temps partiel est prioritaire par rapport √† un recrutement ext√©rieur.Astreinte¬†: le salari√© reste √† son domicile mais doit venir s‚Äôil est sollicit√©.S‚Äôil n‚Äôest pas sollicit√© il est r√©mun√©r√© pour l‚Äôastreinte (donc moins). Sinon il est pay√© sous un contrat de travail normal avec un salaire normal √©galement (revaloris√© par rapport √† l‚Äôindemnit√© d‚Äôastreinte passive).Cours n¬∞3 (29/10/2019)Contenu du contrat de travailIl y a plusieurs obligations principales pour l‚Äôemployeur envers le salari√© : Obligation de verser un salaire Obligation de fournir un travail Obligation de loyaut√© ‚Äì&amp;gt; c√†d ? Obligation d‚Äôassurer la s√©curit√© du salari√©Ces obligations ne sont pas toutes dans le droit de travail mais √©galement dans le droit g√©neral (assurer la s√©curit√©).Plusieurs obligations principales pour l‚Äôemploy√© envers l‚Äôemploy√© : Effectuer le travail pour lequel il est r√©mun√©r√© Avoir un comportement ‚Äúnormal‚Äù (ne pas nuire) √ätre loyal (comme pour tout contrat)Ces obligations sont implicites (elles ne figurent pas dans le contrat de travail).Par exemple : Protection de la vie priv√©e (impos√©e par la loi).Donc la l√©gislation du contrat de travail contient des rappels sur le droit g√©n√©ral et des clauses supl√©mentaires sur le droit du contrat de travail.Dans les limites fix√©es par la loi, l‚Äôemployeur et le salari√© peuvent ajouter des clauses au contrat.La l√©galit√© de ces clauses est plus difficile √† analyser.Ce cadre est soumis au droit des contrats.Analyse de quelques clauses du contrat de travail Clause de non-concurrence Clause de confidentialit√© Mobilit√© P√©riode d‚Äôessai Toutes ces clauses doivent √™tre √©crites dans le contrat de travail pour √™tre en vigueur. Seules les clauses bien form√©es ont une port√©e l√©gale.Rappel : Le salari√© est en position d‚Äôinf√©riorit√© th√©orique. Nul ne peut se pr√©valoir de sa propre turpitude.Si le dommage subi est le fait de ses propres actions illicites ou ill√©gales, on ne peut pas r√©clamer justice.Une clause ill√©gale¬†: Pour un salari√©, il peut ne pas l‚Äôappliquer L‚Äôemployeur sera sanctionn√©La clause figure ou bien au d√©but du contrat de travail, ou bien peut √™tre rajout√©e (par √©crit) au cours du contrat.Toute clause non ill√©gale et consentie peut √™tre ajout√©e au contrat.Clause de non-concurrenceN‚Äôa vocation √† s‚Äôappliquer qu‚Äôau terme du contrat.Elle ne s‚Äôapplique pas lors de l‚Äôex√©cution du contrat de travail (parce qu‚Äôil faut de toute fa√ßon √™tre loyal envers son employeur).La clause de non-concurence sert √† emp√™cher un salari√© d‚Äôexercer une concurrence loyale √† son employeur √† l‚Äôissue du contrat de travail.Elle vise √† interdire au salari√© de faire quelque chose de l√©gal outre mesure¬†: travailler chez les concurrents ou cr√©er sa propre structure qui fait concurrence √† l‚Äôentreprise.Il y a des conditions pour que cette clause soit valable¬†: La clause de non-concurrence doit √™tre appr√©ci√©e avec en ligne de fond le libre-exercice de la profession de son choix (libert√© fondamentale, mais exceptions pour les professions r√©glement√©es par des dipl√¥mes ou par des numerus clausus¬†: m√©decins, juristes, b√¢timent‚Ä¶). Les juges vont √™tre s√©v√®res sur cette clause car elle peut limiter une libert√© fondamentale. √Ä partir de 2002, la cour de cassation a pos√© des conditions pour les clauses de non-concurrence Elle doit √™tre n√©cessaire pour la sauvegarde des int√©r√™ts de l‚Äôentreprise Seuls les postes qui peuvent menacer les int√©r√™ts de l‚Äôentreprise peuvent avoir une clause de non-concurrence. Commerce, encadrement, R&amp;amp;D. La clause doit √™tre limit√©e dans l‚Äôespace (au cas par cas, difficile si l‚Äôentreprise a un rayonnement national) et dans le temps (maximum 2 ans, selon le temps de renouvellement de la client√®le). Elle doit √™tre assortie d‚Äôune contrepartie financi√®re. Depuis le 7 mars 2007, la cour de cassation a pr√©cis√© que cette contrepartie doit √™tre vers√©e au moment o√π la clause s‚Äôapplique (donc √† partir de la rupture de contrat) Si la clause est vers√©e durant le contrat, elle d√©pend de l‚Äôanciennet√©. La clause de non-concurrence va g√™ner le salari√© lors de la recherche d‚Äôemploi (c‚Äôest quand il a du mal √† trouver un emploi qu‚Äôon peut lui verser la contrepartie). La concurrence d√©loyale est interdite, qu‚Äôil y ait une clause de non-concurrence ou non.Plusieurs questions se sont pos√©es sur cette clause : Il faut appliquer la clause quelle que soit la cause de la rupture. Peut-il y avoir une renonciation unilat√©rale ? Non sauf si elle a √©t√© pr√©vue de fa√ßon bilat√©rale. Que faire quand la clause est nulle ? La jurisprudence dominante a tendance √† laisser le salari√© choisir entre accepter la clause ou la refuser. Si la clause est valable¬†? Le salari√© s‚Äôexpose √† de grosses sanctions s‚Äôil rompt la clause¬†: il devra rembourser la contrepartie, voire se faire licencier de son nouveau poste. Si le nouvel employeur √©tait complice, il s‚Äôexpose √† des sanctions devant le tribunal de commerce.Il y a des clauses de non-concurrence d√©guis√©es.Toute clause visant √† emp√™cher un salari√© de travailler pour un concurrent √† l‚Äôissue du contrat est une clause de non-concurrence.Par exemple, on la d√©guise parfois en clause de confidentialit√©.Une clause de confidentialit√© est utile en tant que rappel √† la loi, bien que juridiquement surabondante.Cette clause est juridiquement surabondante mais utile pour rappeler cette loi qui n‚Äôest toujours pas tr√®s bien connue par les employ√©s.Mais le rappel de ces r√®gles ne doit pas emp√™cher le salari√© de travailler pour la concurrence. La plupart du temps, les clauses de confidentialit√© sont plus dans le B¬†to¬†B.La clause de non-sollicitation du personnel limite la libert√© du salari√© sans contrepartie salariale.L‚Äôaccord de non solliciation crois√©e (des op√©rateurs d‚Äôun oligopole s‚Äôaccordent pour ne pas embaucher les salari√©s des concurrents) est probl√©matique d‚Äôun point de vue l√©gal et donc n‚Äôappara√Æt pas.Clauses de mobilit√©Le salari√© s‚Äôengage √† aller partout o√π l‚Äôentreprise veut l‚Äôemmener.Mobilit√©¬†: contraindre un salari√© √† changer de domicile (induit par un changement d‚Äôemplacement de l‚Äôentreprise).Distincte du d√©placement (qui ne n√©cessite pas de changer de domicile).Le crit√®re pris en compte n‚Äôest pas le domicile du salari√© mais la distance entre l√† o√π il travaillait et l√† o√π il va travailler.Si le changement du lieu de travail implique un changement de domicile, on consid√®re que c‚Äôest une modification du contrat. S‚Äôil y a une modification du contrat, elle doit √™tre pr√©vue par une clause ou accept√©e par les parties au moment o√π on lui propose.Si √ßa n‚Äôimplique pas de changement de domicile, ce n‚Äôest plus une modification du contrat mais un changement des conditions de travail qui est dans les droits de l‚Äôemployeur.Mais √† partir de quand va-t-on consid√©rer que le changement de lieu de travail implique un changement de domicile¬†?Quand il y a changement de zone g√©ographique.Zone g√©ographique¬†: alchimie entre distance, temps de trajet, moyens pour effectuer le trajet‚Ä¶Quand il n‚Äôy a pas de clause de mobilit√©, on ne peut pas changer un salari√© hors de sa zone g√©ographique. Si c‚Äôest dans la m√™me zone g√©ographique, le salari√© n‚Äôa pas de le droit Domicile ‚Üí Travail¬†: temps de trajet.Travail ‚Üí autre endroit pour le travail¬†: d√©placement, temps de travailQuand il y a une clause de mobilit√©¬†: pour que la clause soit valable, il faut que la mobilit√© soit indispensable √† la sauvegarde des int√©r√™ts de l‚Äôentreprise (mobilit√© due √† un caprice du chef d‚Äôentreprise = ill√©gale).Si le salari√© (avec une clause de mobilit√©) ne veut pas accepter de changer de lieu de travail¬†: pendant des ann√©es, c‚Äô√©tait un licenciement pour faute. Maintenant consid√©r√© comme un licenciement justifi√©.Si c‚Äôest dans la m√™me zone g√©ographique, √ßa reste un licenciement pour faute.P√©riode d‚ÄôessaiDepuis 2008, la p√©riode d‚Äôessai doit √™tre une clause dans le contrat. Quand on d√©cide de faire une p√©riode d‚Äôessai. Limite de 1 √† 4 mois, renouvelable une fois.La p√©riode d‚Äôessai est une p√©riode durant laquelle l‚Äôemployeur et l‚Äôemploy√© peuvent finir le contrat beaucoup plus facilement. L‚Äôemployeur peut licencier avec un d√©lai de pr√©venance de 2 semaines tant que ce n‚Äôest pas une cause √©trang√®re au travail (politique religieuse, sant√©, grossesse‚Ä¶).La p√©riode d‚Äôessai est consid√©rablement r√©duite¬†: on ne peut pas en faire si on a fait un CDD.Seule influence¬†: sur les modalit√©s de rupture du contrat.Cours n¬∞4 (05/11/2019)L‚Äôassurance ch√¥mage n‚Äôest pas une indemnit√©.Deux choses √† savoir sur le salaire.Salaires = cr√©ance surprivil√©gi√©e (lors d‚Äôune liquidation, ce sont les premi√®res cr√©ances √† √™tre rembours√©es).Tout employeur (entreprise ou assurance) c√¥tise sur les salaires et les indemnit√©sassurance obligatoire sur la garantie des salaires Les bulletins de salaire sont √† garder √† vie, pour le droit et pour la retraite.En mati√®re de salaire, la prescription est de trois ans (voire plus dans certains cas particuliers).En cas de rupture de contrat de travail¬†:Diff√©rentes causes de ruptureSi nous vivions dans un monde id√©al, ce sont les faits qui devraient imposer un mode de rupture.A une situation factuelle correspond une m√©thode de rupture sp√©cifique.Sauf que ce n‚Äôest pas le cas dans la r√©alit√©, une grande partie du contentieux venant de la qualification de la rupture. Si on qualifie mal le contrat, on risque de devoir payer les indemnit√©s + les frais d‚Äôavocat. Il vaut mieux licencier sans cause que d‚Äôinventer une qualification bidon (voire d‚Äôantidater des documents).C‚Äôest la situation de fait qui impose le mode de rupture.Cette rupture peut √™tre √† l‚Äôinitiative¬†: du salari√© de l‚Äôemployeur d‚Äôun commun accord entre les deux partiesLa jurisprudence joue un r√¥le important dans la qualification de la rupture (car la loi est trop vague) en cherchant dans le code civil plut√¥t que par le droit du travail.Certains modes de rupture ne sont pas pr√©vus par le code du travail mais sont mis en place par des juges qui ont interpr√©t√© le code civil et le contrat de travail.C‚Äôest donc un domaine dans lequel il y a beaucoup d‚Äô√©volution dans les interpr√©tations et une grande part d‚Äôal√©atoire (car soumis √† l‚Äôinterpr√©tation des juges).√áa marche aujourd‚Äôhui, mais √ßa ne marchera peut-√™tre pas demain.Rupture √† l‚Äôinitiative du salari√©La d√©missionLe salari√© souhaite quitter son emploi pour des raisons qui lui appartiennent et doit √™tre non √©quivoque. Il doit remettre une lettre en main propre √† l‚Äôemployeur affirmant qu‚Äôil quitte l‚Äôentreprise.En g√©n√©ral, le salari√© d√©missionne lorsqu‚Äôil a trouv√© un emploi derri√®re.La prise d‚Äôacte de ruptureManquement grave aux obligations de l‚Äôemployeur remarqu√© par le salari√©. Le salari√© prend acte que l‚Äôemployeur a rompu unilat√©ralement le contrat en ne respectant pas le contrat.Le salari√© doit saisir le tribunal imm√©diatement.Si on prouve le manquement grave de l‚Äôemployeur, le juge en tirera les cons√©quences d‚Äôun licenciement sans cause.Si le salari√© ne prouve pas le manquement, la rupture prendra l‚Äôeffet d‚Äôune d√©mission.Il faut mieux pour le salari√© prendre acte de rupture que de d√©missioner et de tenter de requalifier cette d√©mission apr√®s.La rupture est assur√©e¬†: d√®s qu‚Äôon en prend acte, le contrat est rompu. Certains salari√©s utilisent la prise d‚Äôacte durant une proc√©dure de licenciement¬†: il y a toujours un d√©lai, donc le salari√© peut prendre acte de la rupture et donc √©chapper au licenciement (puisqu‚Äôon ne peut pas rompre deux fois le m√™me contrat).D√®s lors, on peut remettre en valeur les manquements de l‚Äôemployeur plut√¥t que les manquements du salari√©.Exemples de manquements de l‚Äôemployeur : employeur qui demande √† l‚Äôemploy√© de faire quelque chose d‚Äôill√©gal (e.g., produire un faux) employeur qui n‚Äôassure pas la s√©curit√© (physique ou morale) de ses employ√©s (e.g., employeur ne sanctionne pas suffisament les personnes responsables d‚Äôharc√®lement¬†; si un consultant se fait agresser par un client, alors la responsabilit√© de l‚Äôemployeur est engag√©e) non versement des salaires ne fournit plus de travail √† ses salari√©s On a souvent tendance √† demander √† des personnes de l‚Äôinformatique de faire des actions ill√©gales (RGPD). #BonPlanQuitterSaBo√ÆteSansD√©missionerR√©solution judiciaireDemande de r√©solution judiciaire pour demander la r√©siliation du contrat.Initiative communeLa rupture conventionnelle, alias licenciement √† l‚Äôamiable. Elle date de 2008.On a eu peur que certains employeurs aient une f√¢cheuse tendance √† l‚Äôimposer √† leurs salari√©s dont ils ne voulaient plus.Le l√©gislateur a donc impos√© une proc√©dure avec des d√©lais de r√©flexion, des entretiens, et l‚Äôobligation de transmettre les accords √† la direction d√©partementale du travail.Cette rupture conventionnelle est r√©serv√©e au cas pr√©cis o√π l‚Äôemployeur et le salari√© ne veulent plus continuer ensemble, mais cette volont√© de rompre le contrat ne d√©pend pas d‚Äôune faute.Exemple¬†: les d√©sirs / conditions de vie du salari√© changent raisons extr√™mes personnellesContestations¬†: le salari√© arrive parfois √† prouver qu‚Äôon lui a impos√© cette rupture (car moins cher qu‚Äôun licenciement sans cause) et pourra la requalifier.√Ä l‚Äôinitiative de l‚ÄôemployeurN√©cessairement un licenciement.Beaucoup de r√®gles de forme √† respecter, mais c‚Äôest surtout le fond, les motivations, qui doit √™tre respect√©. Si les r√®gles de forme ne sont pas respect√©es, il n‚Äôy aura pas de remise en compte du licenciement, seulement des sanctions.Les proc√©dures varient selon la cause du licenciement, la taille de l‚Äôentreprise, etc.Le salari√© va souvent contester le motif de son licenciement.Chaque licenciement est accompagn√© d‚Äôune lettre, m√™me plus importante que la proc√©dure, car elle contient les motifs du licenciement.La lettre fige les litiges. On ne peut pas invoquer autre chose que ce qu‚Äôil y a dans la lettre comme motif de licenciementL‚Äôemployeur poss√®de une arme absolue¬†: la mise √† pied. Il peut r√©diger la lettre plus tard.Licenciement pour motif √©conomiqueL‚Äôentreprise serait en p√©ril si elle gardait les salari√©s.Cela peut √™tre pour des difficult√©s √©conomiques, ou pour supprimer certains postes et qu‚Äôon ne peut pas recaser les gens ‚Üí donne lieu √† beaucoup de contestations sous motif que les postes ont √©t√© renomm√©s mais pas supprim√©s.Autre motif de contestation¬†: artifice comptable entre plusieurs soci√©t√©s.En France, les juges ont √©norm√©ment de mal √† admettre un motif √©conomique quand il s‚Äôagit d‚Äôune r√©organisation¬†: culture de pr√©servation de l‚Äôemploi.Le licenciement peut √™tre collectif, mais il s‚Äôagit d‚Äôun ensemble de licenciements individuels donc tous les employ√©s peuvent contester leur licenciement indivuellement.Licenciement personnel Non-disciplinaire¬†: sans faute Disciplinaire¬†: faute l√©g√®re / grave / lourde (les diff√©rents d√©gr√©s tendent √† dispara√Ætre)Motif non-disciplinaireRefus d‚Äôappliquer une clause de mobilit√©.Pendant tr√®s longtemps il a √©t√© consid√©r√© que c‚Äô√©tait une faute grave. Ce n‚Äôest plus une faute grave car elle limite des libert√©s fondamentales mais √ßa reste une faute r√©elle et s√©rieuse justifiant un licenciement.Incapacit√© du salari√© √† s‚Äôadapter √† de nouvelles m√©thodes (ni par mauvaise volont√©, ni par b√™tise).Incompatibilit√©s d‚Äôhumeur entre les personnes (?)√áa ne passe pas forc√©ment.√Ä titre exceptionnel, on admet qu‚Äôun motif tir√© de la vie priv√©e consistue un licenciement si ce motif a cr√©√© un trouble grave et objectif.Si un conflit d‚Äôint√©r√™t vient de la vie priv√©e des salari√©s, il peut √™tre tr√®s compliqu√© √† justifier le licenciement.G√©n√©ralement, quand un employeur veut licencier quelqu‚Äôun pour un motif tir√© de la vie priv√©e en sachant que √ßa ne fonctionnera pas, il invente des motifs en lui trouvant une faute.Le salari√© doit prouver que le motif avanc√© n‚Äôest pas le bon pour faire requalifier son licenciement.Licenciement disciplinaireOn distingue tradionnellement la faute grave et la faute lourdeFaute grave¬†: faute d‚Äôune gravit√© telle qu‚Äôelle rend impossible le maintien du salari√© dans l‚Äôentreprise.Il faut mettre la personne √† pied d√®s que la faute a √©t√© constat√©e.Tr√®s souvent une faute professionnelle. Peut √™tre une accumulation de comportements (pas de double peine, mais une r√©p√©tition d‚Äôune faute peut devenir une grosse faute).Sanction gradu√©e¬†: avertissement, mise √† pied, licenciement.Exemples de fautes graves : faute comportementale¬†: absence injustifi√©e, retards, vol ou escroquerie (falsification de note de frais), comportement vis-√†-vis des autres salari√©s (violences physiques ou morales dont insulter des subordonn√©s) faute professionnelleFaute lourde¬†: faute grave commise avec l‚Äôintention de nuire √† l‚Äôemployeur.Tableau r√©capitulatif Initiative Mode de rupture Assurance ch√¥mage Cong√©s pay√©s Pr√©avis Licenciement Sans cause Salari√© D√©mission G√©n√©ralement non ¬† ¬† Non Non Salari√© Prise d‚Äôacte de rupture Non? ¬† ¬† Non Non Salari√© (R√©solution judiciaire) Non? ¬† ¬† ¬† Non Commune Rupture conventionnelle ? ¬† ¬† ¬† Non Employeur Licenciement √©conomique Oui Oui Oui Oui Non Employeur Licenciement personnel (non disciplinaire) Oui Oui Oui Oui Non Employeur Licenciement personnel (faute grave) Oui Oui Non Oui Non Employeur Licenciement personnel (faute lourde) Oui Autrefois non Non Oui Non Employeur Licenciement personnel (sans cause s√©rieuse) Oui Oui Oui Oui Oui Cours n¬∞5 (19/11/2019)Aux prud‚Äôhommes, les plaignants veulent la requalification du mode de rupture.Les juges vont seulement regarder si le mode de rupture est le bon.Beaucoup de contentieux au moment de la rupture¬†: Difficile de s‚Äôopposer √† son employeur quand on est en poste.C‚Äôest lors de la rupture, lorsque l‚Äôon n‚Äôest plus dans l‚Äôentreprise, que l‚Äôon peut plus facilement se battre. Les cons√©quences de la qualification sont tr√®s importantes sur le montant des indemnit√©s qu‚Äôon va percevoir au moment de la rupture qui sont tr√®s diff√©rentes. Le salari√© peut avoir besoin psychologiquement que la justice reconnaisse la faute de l‚Äôemployeur.Indemnit√©s en fin de contratAssurance ch√¥mageCette indemnit√© est vers√©e par l‚Äô√âtat, pas par l‚Äôemployeur.Les conditions pour recevoir l‚Äôassurance chomage, ne d√©pendent pas de la rupture du contrat de travail du moment que la rupture est d√©cid√©e par l‚Äôemployeur (y compris pour une faute lourde).La d√©mission n‚Äôouvrait pas le droit √† l‚Äôassurance ch√¥mage, il y a r√©cemment eu des r√©formes.Les conditions sont fix√©es par les ASSEDIC.L‚ÄôASSEDIC ne regarde pas la cause du licenciement.Indemnit√© de cong√©s pay√©sLorsqu‚Äôune personne quitte une entreprise et n‚Äôa pas √©puis√© tout son stock de cong√©s.On acquiert un certain nombre de jours de cong√©s pay√©s par mois travaill√©, qui peuvent √™tre pris dans des conditions sp√©cifiques.Si le stock de cong√©s pay√©s n‚Äôest pas √©puis√©, l‚Äôemployeur doit indemniser les cong√©s pay√©s qui restent.Les cong√©s qui ne sont pas pris durant une p√©riode de r√©f√©rence sont perdus (sauf si l‚Äôemployeur accepte de les reporter).Pendant longtemps, l‚Äôidemnit√© de cong√©s pay√©s n‚Äô√©tait pas indemnis√©e pour un licenciement pour faute lourde.La cours de cassation vient de prendre une d√©cision. Que le salari√© qui n‚Äôavait pas pris ses cong√©s pay√©s recevait quand m√™me cette indemnit√© en cas de faute lourde.Indemnit√© de pr√©avisLe contrat de travail fixe un pr√©avis¬†: dur√©e que l‚Äôon doit respecter entre le moment de d√©cider de partir de l‚Äôentreprise et le moment o√π on quitte l‚Äôentreprise pour de bon.Ce d√©lai de pr√©avis est de 1 √† 3 mois.L‚Äôentreprise et le salari√© peuvent, d‚Äôun commun accord, ne pas effectuer le pr√©avis, √† condition que l‚Äôemployeur indemnise ce pr√©avis, c‚Äôest souvent le cas.Lorsque le salari√© est licenci√© pour faute grave ou lourde, le pr√©avis ne lui est pas d√ª.Lorsque le salari√© licenci√© pour faute grave/lourde fait requalifier son licenciement aux prud‚Äôhommes, il demande son indemnit√© de pr√©avis (ainsi que son indemnit√© aux cong√©s pay√©s sur la dur√©e du pr√©avis qu‚Äôil n‚Äôa pas effectu√©).En outre, un employeur laissant le salari√© effectuer son pr√©avis ne peut pas le licencier pour faute grave ou lourde.Comme les indemnit√©s sont calcul√©es vis-√†-vis du pr√©judice subi, les demandes d‚Äôindemnit√©s sont chiffr√©es au centime pr√®s.Indemnit√© l√©gale ou conventionnelle de licenciementCette indemnit√© est fix√©e par la loi ou par la convention collective.Elle est calcul√©e en fonction du salaire et du nombre d‚Äôann√©es d‚Äôanciennet√© du salari√©.Il peut √™tre plus judicieux pour l‚Äôentreprise de payer la formation continue d‚Äôun salari√© avec beaucoup d‚Äôanciennet√© plut√¥t que de le licencier et de payer sa giga-indemnit√© de licenciement.Indemnit√© pour licenciement sans cause r√©elle et s√©rieuseCette indemnit√© n‚Äôest due qu‚Äôen cas de licenciement sans cause r√©elle et s√©rieuse, et s‚Äôajoute √† l‚Äôindemnit√© pr√©c√©dente.Jusqu‚Äô√† la r√©forme de 2017, cette idemnit√© n‚Äôavait pas de bar√®me.La seule indication que donnait la loi √©tait que dans les entreprises de plus de 11 salari√©s pour les salari√©s de plus de 6 mois, il y avait une indemnisation de 6 mois de salaire¬†; le reste √©tait choisi par les juges, et variait de prud‚Äôhommes √† prud‚Äôhommes.En 2017, un bar√®me a √©t√© fix√© et a impos√© un plafond d‚Äôindemnisation de 9 mois de salaire.Ce plafond a √©t√© contest√© par les avocats car la tradition fran√ßaise veut que l‚Äôenti√®ret√© du pr√©judice soit r√©par√©.Devant les prud‚Äôhommes, toutes les pistes vont √™tre suivies par les avocats pour que le salari√© per√ßoive le plus d‚Äôindemnit√©s possibles.Dommages et int√©r√™tsPr√©judice moral, non-respect de la proc√©dure de licenciement‚Ä¶Le montant de l‚Äôindemnit√© est arbitraire.Indemnit√©s au titre de l‚Äôarticle 700 (le fameux)Indemnit√©s pour couvrir les frais de justice (3‚ÄØ000 ~ 10‚ÄØ000¬†‚Ç¨).Traditionnellement, en France, les employeurs sont condamn√©s √† verser ces indemnit√©s s‚Äôils perdent, mais les salari√©s n‚Äôy sont g√©n√©ralement pas condamn√©s s‚Äôils perdent.Rappels sur les prud‚ÄôhommesLes conseillers prud‚Äôhommaux sont √† moiti√© des salari√©s, √† moiti√© des employeurs.Ils re√ßoivent une formation. Ils √©taient auparavant √©lus, mais maintenant d√©sign√©s (√† condition d‚Äôen faire la demande). Ils si√®gent quelques jours par mois.Si ce sont des salari√©s, ils per√ßoivent leur salaire et l‚Äô√âtat rembourse l‚Äôemployeur.Si (et seulement si) ils sont retrait√©s ou ch√¥meurs, alors ils per√ßoivent une indemnit√© de l‚Äô√âtat.Sections Commerce Industrie Encadrement Agriculture et activit√©s diversesChaque section est s√©par√©e en deux bureaux¬†: Bureau de conciliationDeux juges¬†: un employeur, un salari√©.C‚Äôest devant ce bureau que la proc√©dure commence Bureau de jugementLe tribunal, compos√© d‚Äôun greffier, 4 juges (deux employeurs, deux salari√©s).Parmi les quatre juges, un est le pr√©sident (dont le r√¥le est de mener les d√©bats, au prud‚Äôhomme change tout les 6 mois, une fois salari√©, une fois employeur)Mais il n‚Äôa pas de voix pr√©pond√©rente, et les d√©cisions doivent √™tre prises √† la majorit√©.En cas de partage de voix, on envoie devant le juge d√©partiteur qui, lui, si√®ge les audiences de d√©partage.Pour saisir les prud‚Äôhommes il faut aller au greffeG√©n√©ralement, l‚Äôemployeur et le salari√© r√®glent leurs diff√©rents en priv√© ou devant le bureau de conciliation.Quand une affaire arrive devant le bureau de jugement, √ßa veut dire que le diff√©rent est tr√®s profond et qu‚Äôil n‚Äôest pas simple √† trancher.Le conseil des prud‚Äôhommes a √©t√© saisi un an avant le passage devant le bureau de jugement.Formation transverse (de r√©f√©r√©)¬†: proc√©dure d‚Äôurgence pour saisir la justice rapidement.Cette d√©cision est provisoire et devra √™tre suivie d‚Äôune autre d√©cision.En mati√®re civile, pas p√©nale.La proc√©dure est accusatoire¬†: les deux parties au proc√®s (employeur et salari√©) s‚Äôaccusent mutuellement.Le juge ne fait que r√©pondre et trancher les questions qu‚Äôon lui pose (il ne soul√®ve pas de questions de son propre chef).Ce sont les parties qui fixent les contours du proc√®s, pas le juge.Le juge ne cherche pas les preuves, sauf pour les preuves qui ne peuvent √™tre appel√©es que par un juge.L‚Äôavocat de la demande ou de la d√©fense a une argumentation √† tiroirs¬†: il a une demande √† titre principal, et plusieurs demandes subsidiaires si la demande √† titre principal est rejet√©e.La proc√©dure est accusatoire et contradictoire (les deux parties doivent partager les pi√®ces √† conviction).Si le principe contradictoire est viol√© ou si une des parties ne vient pas, il y a report d‚Äôaudience.La proc√©dure est gratuite (sauf frais de justice) et publique.Cependant, il est interdit de photographier ou d‚Äôenregistrer un proc√®s.Faire gaffe √† √©teindre son t√©l√©phone portable et √† se lever quand il le faut.Par contre on peut ramener ses meilleurs crayons de couleurs pour dessiner la sc√®ne en live #siarrytraumatisme" }, { "title": "DBRE: Representation et reproduction", "url": "/cours/posts/dbre_droits_reproduction/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-24 12:00:00 +0100", "snippet": "Lien de la note HackmdPluralite d‚ÄôauteursCas de la pluralite d‚Äôauteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelqu‚Äôun d‚Äôautre, on peut remunerer l‚Äôauteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de l‚Äôauteur original est proportionnelle aux recettes.Si on utilise l‚Äôimage de quelqu‚Äôun dans un manuel de 1000 pages, il est plus rentable de s‚Äôacquitter d‚Äôun forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation d‚Äôune oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de l‚Äôoeuvre et qui vont se concerter entre elles. Ex: le developpement d‚Äôun logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il n‚Äôy a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent l‚Äôoeuvre en ayant passe un contrat entre eux Chacun cede ses droits a l‚Äôun d‚Äôentre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a l‚Äôinitative d‚Äôune personne (physique ou morale).Cette personne est invastie des droits d‚Äôauteurs, et va sous son nom: L‚Äôediter La publier La divulguer Ce qui distingue l‚Äôoeuvre collective et la collaboration, c‚Äôest les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise n‚Äôarrive pas a prouver les conditions pratiques de la realisation d‚Äôun projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue d‚Äôun jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention d‚Äôun tiers pour harmoniser les apports communs).Duree des droits d‚Äôauteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits d‚Äôauteurs) aussi lorsque l‚Äôauteur meurt jeune Disney: utilisent des ‚Äúruses‚Äù Peut egalement etre raccourcie Si chanson d‚Äôun artiste-interprete, retombera plus vite dans le domaine publique Droits d‚Äôune oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire qu‚Äôune oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui n‚Äôutiliserai pas son droit moral ne l‚Äôa pas perdu et peut le faire valoir a tout moment. L‚Äôauteur ne peut pas ceder de facon generale son droit d‚Äôauteur car contraire a un principe d‚Äôordre publique. Attendu que l‚Äôinali√©nabilit√© du droit au respect de l‚Äôoeuvre, principe d‚Äôordre public, s‚Äôoppose √† ce que l‚Äôauteur abandonne au cessionnaire, de fa√ßon pr√©alable et g√©n√©rale, l‚Äôappr√©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait √† ce dernier de proc√©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas d‚Äôadaptation, de changement de support ou de genre qu‚Äôil y a le plus de probleme avec le droit au respect." }, { "title": "ASE2: TD 3", "url": "/cours/posts/ase2_td3/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, estimateur, Fisher, FDCR, maximum de vraisemblance", "date": "2021-03-24 10:00:00 +0100", "snippet": "Lien de la note HackmdExercice 12$X_1,X_2,‚Ä¶,X_n$ des v.a. independantes de la loi de Poisson $\\mathcal P(\\lambda=1)$.Soit $Y_n=\\sum_{k=1}^nX_k$ Determiner $\\lim_{n\\to+\\infty}P(Y_n\\le n)$ (utiliser le TCL) En deduire un equivalent simple de $\\sum_{k=0}^n\\frac{n^k}{n!}$ quand $n\\to+\\infty$ Quand on additionne des variables de Poisson independantes, on obtient une variable suivant la loi de Poisson avec comme parametre la somme de tous les parametres. Solution 1. $X_1,X_2,‚Ä¶,X_n$ sont des v.a independantes et de meme loi, alors d‚Äôapres le TCL: $\\frac{X_1+X_2+‚Ä¶+X_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^{\\mathcal L}\\mathcal N(0,1)$\\[\\begin{cases}Y_n=\\sum_{i=1}^nX_i, E(Y_n)= \\sum_{i=1}^nE(X_i)=\\sum_{i=1}^n1=n\\\\V(Y_n)=\\sum_{i=1}^nV(X_i)=n\\Rightarrow \\sigma=\\sqrt n\\end{cases}\\\\\\frac{Y_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^L\\mathcal N(0,1)\\\\P(Y_n\\le n)=P(\\frac{Y_n-n}{\\sqrt n}\\le 0)=F_n(0)\\] ou $F_n$ est la fonction de repartition de $\\frac{Y_n-n}{\\sqrt n}$or $\\frac{Y_n-n}{\\sqrt n}\\to_{n\\to+\\infty}^L\\mathcal N(0,1)$\\[\\begin{aligned}&amp;amp;\\Rightarrow \\lim_{n\\to+\\infty}P(Y_n\\le n)=\\lim_{n\\to+\\infty}F_n(0)=\\Phi(0) \\text{ f.d.r de } \\mathcal N(0,1)\\\\&amp;amp;\\Rightarrow \\lim_{n\\to+\\infty}P(Y_n\\le n)=\\frac{1}{2}\\end{aligned}\\] 2. La somme de v.a independantes de la loi de Poisson $\\mathcal P(1)$ suit une loi de Poisson $\\mathcal P(n)$\\[Y_n = \\sum_{k=1}^nX_k\\to\\mathcal P(n)\\\\P(Y_n\\le n)=\\sum_{k=0}^ne^{-n}\\frac{n^k}{k!}=e^{-n}\\sum_{k=0}^n\\frac{n^k}{k!}\\] D‚Äôapres la 1. $\\lim_{n\\to+\\infty}e^{-n}\\sum_{k=0}^n\\frac{n^k}{k!}=\\frac{1}{2}$ Donc\\[\\sum_{k=0}^n\\frac{n^k}{k!}\\sim\\frac{1}{2}e^n\\] avec $n$ grand Exercice 13Une entreprise compte 300 employes, chacun d‚Äôentre eux telephone en moyenne 6 minutes par heures. Quel est le nombre de lignes que l‚Äôentreprise doit installer pour que la probabilite que toutes les lignes soient utilisees au meme instant soit au plus egale a $0,025$. Solution Il faut definir 2 variables $N$: nombre de lignes installees $X$: nombre d‚Äôemployes telephonant a un instant $t$ Il faut d‚Äôabord determiner la loi de $X$. La chance d‚Äôavoir un employe telephonant a un instant $t$, on convertit les minutes en heure: $\\frac{6}{60} = \\frac{1}{10}$. $X$ suit donc une loi $\\mathcal B(300,\\frac{1}{10})$ On cherche $N$ la probabilite $P(X\\ge N)\\le 0,025$\\[\\mathcal B(300,\\frac{1}{10})\\simeq N(30,\\sqrt{27}) \\text{ selon le theoreme de Moivre-Laplace}\\\\U=\\frac{X-30}{\\sqrt{27}}\\simeq\\mathcal N(0,1)\\\\\\begin{aligned}P(X\\ge N)\\le0,025&amp;amp;\\Rightarrow P(U\\ge\\frac{N-30}{3\\sqrt{3}})\\le 0,025\\\\&amp;amp;\\Rightarrow1-\\Phi(\\frac{N-30+0,5}{3\\sqrt 3})\\le0,025\\\\&amp;amp;\\Rightarrow\\Phi(\\frac{N-30+0,5}{3\\sqrt 3})\\ge0,975=\\Phi(1,96)\\end{aligned}\\] ou $\\Phi$ est la fonction de repartition de la loi $\\mathcal N(0,1)$.\\[\\begin{aligned}&amp;amp;\\Leftrightarrow \\frac{N-30+0,5}{3\\sqrt 3} \\ge 1,96\\\\&amp;amp;\\Leftrightarrow N\\ge 3\\sqrt 3\\times1,96+29,5\\\\&amp;amp;\\Leftrightarrow N\\gt 40\\end{aligned}\\] Il faut installer au moins 40 lignes. Exercice 14On considere un echantillon $(X_1, X_2,‚Ä¶,X_n)$ d‚Äôune v.a. $X$.Determiner la vraisemblance de cet echantillon dans les cas ou $X$ est distribue suivant: une loi binomiale $\\mathcal B(N,p)$ une loi de Poisson $\\mathcal P(\\lambda)$ Une loi exponentielle $\\mathcal E(\\lambda)$ Une loi normale $\\mathcal N(m,\\sigma)$ Solution $(X_1,X_2,‚Ä¶,X_n)$ un echantillon de $X$. 1. $X\\sim\\mathcal B(N,p)$ ($\\theta=p$ parametre).\\[\\begin{aligned}L(x_1,x_2,...,x_n,p)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;=\\Pi_{i=1}^n\\binom{N}{x_i}p^{x_i}(1-p)^{N-x_i}\\\\&amp;amp;= \\Pi_{i=1}^n\\frac{N!}{x_i!(N-x_i)!}p^{x_i}(1-p)^{N-x_i}\\end{aligned}\\] \\[L(x_1,x_2,...,x_n,p)=\\frac{(N!)^n}{\\Pi_{i=1}^nx_i!(N-x_i)!}p^{\\sum_{i=1}^nx_i}(1-p)^{nN-\\sum_{i=1}^nx_i}\\] 2. $X\\sim\\mathcal P(\\lambda)$ ($\\theta=\\lambda$ parametre)\\[\\begin{aligned}L(x_1,x_2,...,x_n,\\lambda)&amp;amp;=\\Pi_{i=1}^nP(X_i=x_i)\\\\&amp;amp;= \\Pi_{i=1}^ne^{-\\lambda}\\frac{\\lambda^{x_i}}{x_i!}=e^{-n\\lambda}\\frac{\\lambda^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\end{aligned}\\] \\[L(x_1,x_2,...,x_n,\\lambda)=\\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\] 3. $X\\sim\\mathcal E(\\lambda)$ (exponentielle) (variable continue), $\\theta=\\lambda$ (parametre)\\[L(x_1,x_2,...,x_n,\\lambda)=\\Pi_{i=1}^nf(x_i)=\\Pi_{i=1}^n\\lambda e^{-\\lambda x_i}\\] \\[L(x_1,x_2,...,x_n,\\lambda)=\\lambda^ne^{-\\lambda \\sum_{i=1}^nx_i}\\] 4. $X\\sim\\mathcal N(m,\\sigma)$ (variable continue), parametres $m$ et $\\sigma$\\[L(x_1,x_2,...,x_n,m,\\sigma)=\\Pi_{i=1}^nf(x_i)\\\\\\text{or } f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{X-m}{\\sigma})^2} \\text{ (densite)}\\\\L(x_1,x_2,...,x_n,m,\\sigma)=\\Pi_{i=1}^n\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{X-m}{\\sigma})^2}\\] \\[L(x_1,x_2,...,x_n,m,\\sigma) = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n}e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(X_i-m)^2}\\] Exercice 15Soit $X$ une v.a. qui suit la loi normale centree, de variance $\\sigma^2$ inconnue ($\\sigma\\gt0$). $\\forall n\\ge 2$, on dispose d‚Äôune n echantillon $(X_1,X_2,‚Ä¶,X_n)$ des variables independantes et de meme loi que $X$.Soit $S_n=\\frac{1}{n}\\sum_{i=1}^nX_i^2$ Montrer que $S_n$ est un estimateur sans biais de $\\sigma^2$ Montrer que $S_n$ converge en probabilite vers $\\sigma^2$ Solution X v.a. normale centree $X\\to\\mathcal N(0,\\sigma)$, $\\sigma$ inconnu. $(X_1,‚Ä¶,X_n)$ echantillon de $X$.\\[S_n=\\frac{1}{n}\\sum_{i=1}^nX_i^2\\] 1. $\\forall i$, $X_i$ suit la loi $\\mathcal N(0,\\sigma)$: $V(X_i)=E(X_i^2)$ donc\\[\\begin{aligned}E(S_n)&amp;amp;=\\frac{1}{n}\\sum_{i=1}^nE(X_i^2)=\\frac{1}{n}\\sum_{i=1}^nV(X_i)\\\\&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n\\sigma^2=\\frac{n\\sigma^2}{n}\\\\&amp;amp;=\\sigma^2 \\text{ (sans biais)}\\end{aligned}\\] 2. Convergence de $Sn$?\\[\\begin{aligned}V(S_n) &amp;amp;= \\frac{1}{n^2}\\sum_{i=1}^nV(X_i^2)=\\frac{n}{n^2}V(X^2)\\\\&amp;amp;= \\frac{V(X^2)}{n}=\\frac{c}{n} \\quad (C=V(X^2))\\\\&amp;amp;\\Rightarrow V(S_n)\\to_{n\\to+\\infty}0\\end{aligned}\\] D‚Äôapres l‚Äôinegalite de Tchebychev:\\[\\begin{aligned}\\forall \\varepsilon, &amp;amp;P(\\vert S_n-E(S_n)\\vert\\ge \\varepsilon)\\le\\frac{V(S_n)}{\\varepsilon^2}\\\\\\Rightarrow &amp;amp;P(\\vert S_n-E(S_n)\\vert \\ge\\varepsilon)\\le\\frac{c}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\end{aligned}\\] Donc:\\[S_n\\to_{n\\to+\\infty}^P\\sigma^2\\] " }, { "title": "ASE2: Convergence et estimation - 4", "url": "/cours/posts/ase2_convergence_et_estimation_4/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, poisson, normale", "date": "2021-03-24 09:00:00 +0100", "snippet": "Lien de la note HackmdEstimateurExempleOn consid√®re un √©chantillon $(X_1, X_2,‚Ä¶,X_n)$ d‚Äôune variable de Poisson de parametre $\\theta$ (inconnu)La vraisemblance de cet echantillon est:\\[L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nP(X_i=x_i)\\\\L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^ne^{-\\theta}\\frac{\\theta^{x_i}}{x_i!}=\\frac{e^{-n\\theta}\\theta^{\\sum_{i=1}^nx_i}}{\\Pi_{i=1}^nx_i!}\\] Definition: On appelle quantit√© d‚Äôinformation de Fisher $I_n(\\theta)$ apport√©e par un √©chantillon sur le param√®tre $\\theta$ la quantit√© positive:\\[I_n(\\theta)=E((\\frac{\\delta \\ln L}{\\delta\\theta})^2)\\]Proposition \\(I_n(\\theta)=-E(\\frac{\\delta^2\\ln L(x,\\theta)}{\\delta\\theta^2})\\)Demonstration $L$ etant une densite: $\\int_{\\mathbb R^n}L(x,\\theta)dx=1$ En d√©rivant par rapport √† $\\theta$: $\\int_{\\mathbb R^n}\\frac{\\delta L(x,\\theta)}{\\delta\\theta}dx=0\\quad (1)$ En remarquant que $\\frac{\\delta\\ln L(x,\\theta)}{\\delta\\theta}=\\frac{\\frac{\\delta L}{\\delta\\theta}(x,\\theta)}{L(x,\\theta)}$ $(1)$ donne $\\int_{\\mathbb R^n}\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}L(x,\\theta)dx=0$Ce qui prouve que la variable al√©atoire $\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}$ est centr√©e et que $I_n(\\theta)=V(\\frac{\\delta\\ln L}{\\delta \\theta})$D√©rivons une deuxi√®me fois par rapport √† $\\theta$:\\[\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx+\\int_{\\mathbb R^n}\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta}\\frac{L(x,\\theta)}{\\delta\\theta}dx=0\\\\\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx+\\int_{\\mathbb R^n}(\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta})^2L(x,\\theta)dx=0\\]Donc: \\(\\begin{aligned}I_n(\\theta)&amp;amp;=E((\\frac{\\delta \\ln L}{\\delta\\theta})^2)\\\\&amp;amp;=\\int_{\\mathbb R^n}(\\frac{\\delta \\ln L(x,\\theta)}{\\delta\\theta})^2L(x,\\theta)dx\\\\&amp;amp;=-\\int_{\\mathbb R^n}\\frac{\\delta^2 \\ln L(x,\\theta)}{\\delta\\theta^2}L(x,\\theta)dx\\\\&amp;amp;=-E(\\frac{\\delta^2\\ln L(x,\\theta)}{\\delta\\theta^2})\\end{aligned}\\)In√©galit√© de FRECHET-DARMOIS-CRAMER-RAO(FDCR) On a pour tout estimateur T sans biais de $\\theta$:\\[V(T)\\ge\\frac{1}{I_n(\\theta)}\\] L‚Äôestimateur T sera qualifi√© d‚Äôefficace si la borne inf√©rieure est atteinte, c‚Äôest-√†-dire\\[V(T)=\\frac{1}{I_n(\\theta)}\\]M√©thode du maximum de vraisemblance Cette m√©thode consiste, √©tant donn√©e un √©chantillon de valeurs $x_1,x_2,‚Ä¶,x_n$ √† prendre comme estimation de $\\theta$ la valeur de $\\theta$ qui rend maximale la vraisemblance $L(x_1,x_2,‚Ä¶,x_n,\\theta)$ On prend comme estimation de $\\theta$ la solution de l‚Äô√©quation de la vraisemblance\\[\\frac{\\delta \\ln L}{\\delta\\theta} = 0\\]" }, { "title": "IREN: Retropropagation du gradient", "url": "/cours/posts/iren_gradient/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8, r√©seaux neuronnaux", "date": "2021-03-23 11:00:00 +0100", "snippet": "Lien de la note HackmdIndex du coursR√©tropropagation du gradientFonction logistiqueCalculons l‚Äôinfluence du poids $w_{2,2}^2$ sur l‚Äôerreur quadratique $E:\\frac{\\delta E}{\\delta w_{2,2}^2}$La derivee partielle de $y$ par rapport a $z$ est $y(1-y)$ On note t (truth) la vraie valeur avec l‚Äôerreur quadratiqueCorrectionQue vaut le gradient de $E :\\nabla E$?Qu‚Äôest-ce qu‚Äôon modifie pour arriver au bon resultat ?Les poids, on a 18 poids donc $\\nabla E$ est a dimension 18.\\[\\forall \\text{ layer }l, W^l\\leftarrow W^l-\\eta\\nabla E(W^l)\\]Pourquoi ce titre ?On fait une propagation a l‚Äôenvers, ‚Äúretropropagation‚Äù pour remonter l‚ÄôerreurLa methode du gradientLe but est de trouver le vecteur $w$ qui minimise notre erreur $E$Avec un $w_0$ choisi, l‚Äôalgorithme de descente du gradient est:\\[w_{t+1}=w_t-\\eta\\nabla E(W_t)\\]jusuq‚Äôa atteindre un seuil choisiRepresentation graphiqueCas simple: l‚Äôerreur est une fonction convexe.Si on modifie les cas apres chaque donnees, on risque d‚Äôosciller travailler par paquet de donn√©es. $\\rightarrow$ Notion de batchLorsque l‚Äôelliptiques est allong√©e, son gradient est quasiment orthogonal √† son axe long ce qui n‚Äôest pas du tout la bonne direction vers le minimum. la convergence sera longueTravail sur les donneesJouer sur l‚Äôechelle\\[y=w_0i_0+w_1i_1\\\\E=(y-t)^2\\]Soit comme jeux de donnees:\\[\\begin{aligned}&amp;amp;\\begin{matrix}0,1&amp;amp;10&amp;amp;\\rightarrow&amp;amp;2\\\\0,1&amp;amp;-10&amp;amp;\\rightarrow&amp;amp;2\\\\\\end{matrix}&amp;amp;\\begin{matrix}1&amp;amp;1&amp;amp;\\rightarrow&amp;amp;2\\\\1&amp;amp;-1&amp;amp;\\rightarrow&amp;amp;2\\\\\\end{matrix}\\end{aligned}\\]La fonction d‚Äôerreur correspondante a la forme suivante: normaliser les donn√©es pour √©viter des fonctions d‚Äôerreur √©cras√©esTranslation\\[y=w_0i_0+w_1i_1\\\\E=(y-t)^2\\]Soit comme jeux de donnees:\\[\\begin{aligned}&amp;amp;\\begin{matrix}101&amp;amp;101&amp;amp;\\rightarrow&amp;amp;2\\\\101&amp;amp;99&amp;amp;\\rightarrow&amp;amp;0\\\\\\end{matrix}&amp;amp;\\begin{matrix}1&amp;amp;1&amp;amp;\\rightarrow&amp;amp;2\\\\1&amp;amp;-1&amp;amp;\\rightarrow&amp;amp;0\\\\\\end{matrix}\\end{aligned}\\]L‚Äôerreur correspondante aux jeux de donn√©es a la forme suivante: centrer les donn√©es pour √©viter des fonctions d‚Äôerreur √©cras√©es.Les minimums locauxUne fonction d‚Äôerreur n‚Äôest pas forcement elliptique, il faut s‚Äôattendre a avoir des minimums locaux.Le point de convergence d√©pend du point de d√©part d‚Äôo√π le risque de finirdans un minimum local. Si on lance une bille, en fonction de la ou elle se trouve elle fini dans un minimum localComment sortir d‚Äôun minimum local pour rejoindre un minimum global ?Les solveursPour contrer ces differents problemes, on a differents solveursMoment et NesterovOn donne une inertie $\\alpha$ a la methode:On ne calcule pas le gradient au poids des poids, mais aux poids modifies.Nesterov propose de travailler sur les donn√©es mise √† jour:Ca peut aider a ‚Äúsortir‚Äù des trous et reduire les oscillations Si notre bille s‚Äôapproche d‚Äôun trou, on lui dira ‚ÄúNon va pas par la, fait demi-tour‚ÄùRMSpropLe coef d‚Äôapprentissage $\\eta$ influence beaucoup la convergence.On peux choisir autant de $\\eta_i$ que de parametres existants: $\\eta_i=\\varepsilon\\mu_i\\frac{\\delta E}{\\delta \\omega_i}$Avec:Ca marche mal avec les ‚Äúmini-batches‚Äù $9\\frac{\\delta E}{\\delta \\omega_i}$ de $0,1$ suivi d‚Äôune de $-0,9$ devrait faire du surplace, mais pas avec cette methodeOn prefere moyenner les gradients dans le temps, l‚Äôalgorithme est:AdagradOn cherche le w aui minimise $E$, donc $\\nabla E(w)=0$Au pas de temps $t$, on est au point $w_t$, on cherche $\\delta w$ tel que $\\nabla E(w-t+\\delta w)=0$ donc avec un developpement limite:Avec $\\nabla^2E$ la matrice hessienne de $E$.L‚Äôalgorithme iteratif est:Calculer l‚Äôinverse de la matrice essienne est trop couteux, on va chercher quelque chose qui lui ressemble, $V_t$ pour Adagrad:Exemple de convergenceRegardons √† quelle vitesse convergent diff√©rentes m√©thodes suivant la formede la fonction d‚Äôerreur.An overview of gradient descent optimization algorithmsTrois types de reseaux neuronauxQuelques exemples de reseaux neuronaux: reseau simple pour separer des donnees Qui a le cancer, qui ne l‚Äôa pas reseau recursif pour faire des additions reseau de convolution pour comprendre une imageUne id√©e pour s√©parer les donn√©es sur deux cercles?SeparationRelu defini un demi-plan, on va utiliser 6 Relu $(\\nearrow)$ pour faire un cercle grossier et une sigmoide $(\\rightsquigarrow)$ pour separer les 2 cerclesRecursifOn veut calculer $0101011+1001110$, on fait comme un addition a la main On a besoin d‚Äôavoir des retenues (si on a $1+1$ par exemple), c‚Äôest un reseau a memoire.Les cellules grises sont la memoire, cad les retenues, des operations precedentes. Ces reseau sont compliques a faire converger, il faut que la memoire fonctionne correctement.Convolution Les Convolution Neural network sont la grande reussite du deep learning.Le but est de travailler sur des images pour en extraire ses caracteristiquesEn entr√©e nous avons une image $N \\times N \\times 3$ (en RGB) dont nous diminuonsla surface √† chaque couche du r√©seau pour augmenter sa profondeur.√Ä la fin on peut voir l‚Äôimage comme un vecteur de caract√©ristiques.Ensuite (pas sur le dessin) on peut utiliser un r√©seau neuronal classique pour classer l‚Äôimage.Les convolutions Un filtre est un masque d‚Äôune certaine taille dont on a donn√© une valeur pour chacune des couchesOn fait la somme de tous les poids $\\times$ toutes les valeurs et on travaille un pixel sur 2. La taille des filtres est le nombre de canaux de l‚Äôimage de depart.Chacun des 5 filtres aura combien de canal ?2 car l‚Äôimage d‚Äôarrivee a 2 canauxDiminuer la surfaceL‚Äôexemple pr√©c√©dent saute un pas (travailler un pixel sur 2), qui r√©duit la surface. Si on a pas de saut de plus de filtre $\\rightarrow$ le nombre de donn√©es EXPLOSE. pooling: On r√©duit la surface de l‚Äôimage au fur et a mesure qu‚Äôon augmente sa profondeur.Le choix du maximum est le plus utilis√©. On pourrait faire une moyenne mais cela risque de r√©duire le contraste de l‚Äôimage.Le Net 5Le premier CNN, qui a bien fonctionn√©, pour lire les codes postaux sur les enveloppes, d√©velopp√© en 90 par Yann Le CunEvolution des CNNLes reseaux augmentent en pr√©cision, taille et nombre d‚Äôop√©rations.De plus en plus compliqu√©:On rajoute des trucs pour am√©liorer les r√©sultats (ou converger).L‚Äôid√©e est de reprendre des donn√©es ant√©rieures pour ne pas trop oublier. Le saut correspond √† l‚Äôop√©ration:\\[y=F(x,w)+x\\]KaggleLe Kaggle d‚ÄôOlivier RicouTensor FlowLe Tensor Flow Playground" }, { "title": "OCVX: Optimisation Convexe 2", "url": "/cours/posts/ocvx_kariulele_2/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:20:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Graphe de de $f: \\mathbb R \\rightarrow \\mathbb R$Calculer le pasCalcul du pas optimaltrouver $t^*$ par la minimisation de $f(x + t \\Delta x)$la tangente au graphe de $t \\overset{\\psi}{\\longrightarrow} f(x + t \\Delta x)$ en 0 est donn√©e par$\\psi(0) + t\\psi‚Äô(0) = f(x) + t$$= f(x) + t\\nabla f(x)^T \\Delta x$On s‚Äôarrete des qu‚Äôon trouve:$t^*$ tq$f(x + t^{*}\\Delta x) \\le f(x) + \\alpha t^{*} \\nabla f(x)^T \\Delta x$La hessienne d‚Äôune fonction f en un point definit une fonction quadratique.$X \\longmapsto X^T \\underbrace{\\nabla^2f(a)}_{\\text{matrice carre (hessienne de f en a)}}X$Dire que $a \\mapsto \\nabla^2f(a)$ est majoree sur un lieu $S$ de son domaine de definition est equivalent au fait de dire que les valeurs propres (fonctions en a) de la hessienne sont des fonctions majorees. $\\forall a \\in S$ on a que les valeurs propres de la hessienne de f sont minorees par une meme constante $m &amp;gt; 0$.Strictement convexe: Non Strictement convexe:Generaliser la descente classique$f(x + v) = f(x) + \\nabla f(x)^T v + o(v)$ On remplace $f(x+v)$ par son approximation au 1er ordre; cad $f(x) + \\nabla f(x)^T v$ On cherche la direction (cad les vecteurs de norme 1 ($|.|_2)$) tq $f(x) + \\nabla f(x)^T v$ est minimal. On cherche donc a calculer $v^{*} = argmin({\\nabla f(x)^T v \\vert \\Vert v\\Vert_2 = 1})$Rq: Si $v^{*}$ minimise $\\nabla f(x)^Tv$ ssi $-v^{*}$ maximise $\\nabla f(x)^Tv$ pour $|v|_2 = 1$Rappel: Cauchy Schwarz : $\\vert\\nabla f(x)^Tv\\vert \\le \\Vert\\nabla f(x)\\Vert_2 \\Vert v\\Vert_2$$\\vert\\nabla f(x)^Tv\\vert \\le \\Vert \\nabla f(x)\\Vert_2$En prenant $v = \\frac{\\nabla f(x)}{|\\nabla f(x)|_2}$ (hyp denominateur != 0)\\(\\nabla f(x)^T v^* = \\left(\\nabla f(x)^T \\nabla f(x)\\right) x \\frac{1}{\\|\\nabla f(x)\\|_2}= \\frac{\\|\\nabla f(x)\\|_{2}^{2}}{\\|\\nabla f(x)\\|_2}= \\|\\nabla f(x)\\|_2\\)Donc pour que $v^{*}$ maximise $\\nabla f(x)^Tv^{*}$ pour $|v|_2 = 1$Ainsi $\\frac{-\\nabla f(x)}{|\\nabla f(x)|_2}$ minimise $\\nabla f(x)^Tv$ pour $\\Vert v\\Vert_2 = 1$Au lieu d‚Äôutiliser une direction normalisee, pour la mise a jour, on regarde plutot $\\Delta_{x_{sd}} = |\\nabla f(x)|_2$ nsd =&amp;gt; normalized steepest descentPour la norme 1 on s‚Äôinteresse au calcul de:$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 = 1})$$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 \\le 1})$Ceci est un programme lineaire, ces points optimaux sont des points extremaux du lieu admissibleCes points extremaux sont les points:$\\mathcal F_{e_i}$ pour $i \\in {1,‚Ä¶,n}$$argmin({\\nabla f(x)^Tv \\, \\mid \\, \\Vert v\\Vert_1 \\le 1}) = I e_i$ pour un certain $i \\in {1,‚Ä¶,n}$$\\nabla f(x)^T e_i$ est la projection de $\\nabla f(x)$ sur $e_i$ cad $\\frac{\\partial f(x)}{\\partial x_i}$ Le $e_i$ qui realise l‚Äôargmin.$\\Delta x_{sd} =$ la projection de $\\nabla f(x)$ le long de $\\Delta x_{nsd}$$\\Rightarrow \\Delta x_{sd} = - \\frac{\\partial f(x)}{\\partial x_i} e_i$$\\Delta x_N = - (\\nabla^2 f(x))^{-1} (\\nabla f(x))$$f(x) + \\nabla f(x)^Tv + \\frac{1}{2}v^T\\nabla^2f(x)v = \\Psi(v)$$\\Psi$ est minimum ssi $\\nabla \\Psi(v) = 0$\\[\\nabla \\Psi(v) = \\nabla f(x) + \\nabla^2 f(x) v=&amp;gt; \\nabla \\Psi(v) = 0 &amp;lt;=&amp;gt; \\nabla^2 f(x) v = - \\nabla f(x)\\]" }, { "title": "OCVX: Optimisation Convexe 1, suite", "url": "/cours/posts/ocvx_kariulele_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:10:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!) Trouver l‚Äôextremum d‚Äôune parabole $f(x) = ax^2 + bx +c \\qquad a &amp;gt; 0$$f‚Äô(x) = 2ax +b$$x^{*} \\qquad tq f‚Äô(x^{*}) = 0$$2ax^{*} + b = 0$$x^{*} = -\\frac {-b}{2a}$\\[\\begin{aligned}f^{*} &amp;amp;= f(x^{*})\\\\&amp;amp;= a \\left(-\\frac{b} {2a}\\right)^2 + b\\left(-\\frac{b}{2a}\\right) + c\\\\&amp;amp;= \\frac{b^2}{4a}- \\frac{b^2}{2a} +c\\\\&amp;amp;= -\\frac{b^2}{4a} + c\\end{aligned}\\]$f: \\mathbb R \\longrightarrow \\mathbb R$f est d√©rivable en $x_0$ : $\\underset{h \\rightarrow 0}{lim} \\frac{f(x+h) - f(x)}{h}$ est finie.Et $\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} = f‚Äô(x_0)$$\\underset{h \\rightarrow x_0}{lim} \\frac{f(x)-f(x_0)}{x - x_0}$$f = o_{x_0}(g)$ $f$ est n√©gligeable par rapport √† $g$ en $x_0$.$\\Leftrightarrow$ Il existe une fonction $\\varepsilon : \\mathbb R \\rightarrow R$ avec $\\varepsilon(x) \\underset{x \\rightarrow x_0}{\\longrightarrow} 0$Et $f(x) = \\varepsilon(x)g(x)$ au voisinage de $x_0$.Si $g$ ne s‚Äôannule pas au voisinage de $x_0$$f=o_{x_0}(g) \\Leftrightarrow \\underset{x \\rightarrow x_0}{lim} \\frac{f(x)}{g(x)} = 0$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} = f‚Äô(x_0)$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0)}{h} - \\frac{hf‚Äô(x_0)}{h} = 0$soit $\\varepsilon : \\mathbb R \\longrightarrow \\mathbb R$tq $\\underset{h \\rightarrow 0}{\\varepsilon (h) \\rightarrow 0}$$\\underset{h \\rightarrow 0}{lim} \\frac{f(x_0 + h) - f(x_0) - hf‚Äô(x_0)}{h} = \\underset{h \\rightarrow 0}{lim} \\space\\varepsilon (h) = 0$$\\frac {f(x_0 + h) -f(x_0) - hf‚Äô(x_0)}{h} = \\varepsilon(h)$$f(x_0 + h) -f(x_0) - hf‚Äô(x_0) = h\\varepsilon(h)$$f(x_0 + h) = f(x_0) + hf‚Äô(x_0) + h\\varepsilon(h) = f(x_0) + hf‚Äô(x_0) + o_0(h)$$f(x) = f(x) + (x - x_0)f‚Äô(x_0) + (x - x_0) \\underbrace{\\varepsilon(x - x_0)}_{o_0(x- x_0)}$$f: \\mathbb R^n \\longrightarrow \\mathbb R$$x = \\begin{pmatrix}x_1 \\ \\vdots \\ x_n \\end{pmatrix} \\longmapsto f(x_1, \\dots, x_n)$$f(x_1, ‚Ä¶ , x_n) = x_1 + x_2 + ‚Ä¶ + x_n$La $k^{i√®me}$ d√©riv√©e partielle de f existe en $x_0 \\in \\mathbb R^n$$\\Leftrightarrow$ la fonction $\\underset{t \\rightarrow f(x_0,‚Ä¶,x_n)}{\\varphi :\\ \\mathbb R \\rightarrow \\mathbb R}$ est d√©rivable en 0et $\\varphi‚Äô(0) = \\frac{\\partial f}{\\partial x_k}(x_0) \\Leftrightarrow \\partial k f(x_0)$$f(x,y) = \\begin{cases}\\frac{xy}{x^2 + y^2} \\space \\text{ si } (x,y) \\ne (0,0) 0 \\qquad \\text{ si } (x,y) = (0,0)\\end{cases}$\\begin{aligned}\\frac{\\partial f}{\\partial x}(x,y) &amp;amp;= \\frac{\\partial}{\\partial x}\\left(\\frac{xy}{x^2 + y^2}\\right) &amp;amp;= y \\frac{\\partial}{\\partial x} \\left( \\frac{x}{x^2 + y^2} \\right) &amp;amp;= y \\frac{x^2 + y^2 -x(2x)}{(x^2 + y^2)^2} &amp;amp;= y \\frac{y^2 - x^2}{(x^2 + y ^2)^2}\\end{aligned}$\\frac{\\partial f}{\\partial x} (t,0) = 0 \\qquad \\frac{\\partial f}{\\partial y}(0,t) = 0$$\\frac{\\partial f}{\\partial x}(x,y) \\Leftrightarrow$ on d√©rive selon l‚Äôaxe $(o_x)$$\\Leftrightarrow$ on d√©rive selon le vecteur $e_x = (1,0)$$\\frac{\\partial f}{\\partial y}(x,y) \\Leftrightarrow$ on d√©rive selon l‚Äôaxe $(o_y)$La derivee directionnelleDans le cas de $n$ variables :$f:\\mathbb R^n \\longrightarrow \\mathbb R$$\\frac{\\partial f}{\\partial x_k}(x)$ = on d√©rive par rapport √† la $k^{i√®me}$ variable$\\Leftrightarrow$ on d√©rive selon la $k^{i√®me}$ variable$\\Leftrightarrow$ on d√©rive selon le vecteur $ek = (0, \\dots, o, \\underbrace{1}_{k^{i√®me}}, 0, \\dots, 0)$ D√©finition : On appelle d√©riv√©e directionnelle de $f$ en $x_0$ suivant le vecteur $h \\in \\mathbb R^2$ et on note $D_hf(x_0)$ la d√©riv√©e en 0 de la fonction \\(\\varphi : \\begin{aligned}\\mathbb R &amp;amp; \\longrightarrow \\mathbb R\\\\t &amp;amp;\\longmapsto f(x_0 + th)\\end{aligned}\\)$\\frac{\\partial f}{\\partial x}(x_0) \\equiv$ derivee de\\[\\varphi :\\begin{aligned}\\mathbb R &amp;amp; \\rightarrow \\mathbb R\\\\t &amp;amp;\\longmapsto \\underbrace{f(x_{01} +, \\dots, x_{0k+t}, \\dots, x_{0n})}_{\\begin{pmatrix}x_{01} \\\\ \\vdots\\\\ x_{0n}\\end{pmatrix} + t\\begin{pmatrix}0 \\\\ \\vdots \\\\ 1 \\rightarrow k^e\\\\ \\vdots \\\\ 0\\end{pmatrix}}\\end{aligned}\\]$f: \\mathbb R^2 \\longrightarrow R \\qquad \\space \\qquad x_0=(1,2)$$(x,y) \\longmapsto x^2 - y^2 \\qquad h=(3,5)$$\\varphi : \\mathbb R \\longrightarrow \\mathbb R$$t \\longmapsto f(x_0 + th)$$\\varphi(t) = f\\left(\\begin{pmatrix}1 \\ 2 \\end{pmatrix} + t \\begin{pmatrix}3 \\ 5\\end{pmatrix}\\right)$$= f(1+3t, 2+ 5t)$$= (1 +3t)^2 - (2 + 5t)^2$$= 1 + 6t + 9t^2 -(4 - 20t + 25t^2)$$= -3 - 14t - 16t^2$$\\varphi ‚Äò(t) = -14 -32t$$\\varphi ‚Äò(0) = -14 = D_h(x)$$h \\leftrightarrow \\alpha h$$D_{\\alpha h}f(x_0) = \\alpha D_hf(x_0)$On parle de d√©riv√©e directionnelle selon la direction de $h \\in \\mathbb R^n \\verb++ {0}$ uniquement quand $h$ est unitaire (par opposition √† la d√©riv√©e directionnelle selon le vecteur $h$).Malheureusement, l‚Äôexistence de derivees directionnelles en $Vn$ point selon tout vecteur n‚Äôimplique pas la continuit√© en ce point.$f(x,y) = \\begin{cases}\\frac {y^2}{x} \\qquad x \\ne 0y \\space\\space\\qquad x = 0\\end{cases}$En $(0,0)$ soit $h = \\begin{pmatrix} h_1 \\ h_2\\end{pmatrix} \\ne (0,0)$\\begin{aligned}\\varphi(t) = f(th) = f(th_1, th_2)&amp;amp;= \\begin{cases} \\frac{(th_2)^2}{th_1} \\qquad\\space\\space h \\neq 0th_2 \\qquad\\quad\\ h = 0\\end{cases}&amp;amp;= \\begin{cases} t\\frac{h_2^2}{h_1} \\qquad\\space\\space h \\neq 0th_2 \\qquad\\quad\\ h = 0\\end{cases}\\end{aligned}$\\varphi ‚Äò(t) = \\begin{cases} \\frac{h_2^2}{h_1} \\qquad h_1 \\ne 0 h_2 \\qquad h_1 = 0\\end{cases}$ = $\\varphi ‚Äò(0)$si $g$ est continue en $0$ et $f$ continue en $g(0)$ alors $f \\circ g$ est continue en $0$$g: \\mathbb R \\longrightarrow \\mathbb R^2$$t \\longmapsto (t^2, t)$$f \\circ g : \\mathbb R \\longrightarrow \\mathbb R^2$$t \\longmapsto f \\circ g(t) = f(g(t))$$f(g(t)) = f(t^2, t) = \\begin{cases}\\frac{t^2}{t^2} \\qquad t \\neq 00 \\qquad\\space t = 0\\end{cases}$$f \\circ g(t) = \\begin{cases}1 \\qquad\\space t \\neq 00 \\qquad\\space t = 0\\end{cases}$Donc $f \\circ g$ pas continue en $0$$\\Rightarrow f$ pas continue en $g(0) = (0,0)$$f(x_0 +h) = f(x_0) + hf‚Äô(x_0) + \\begin{cases}o_0(h)\\ h \\varepsilon(h) \\text{ avec } \\varepsilon(h) \\qquad \\varepsilon (h) \\underset{h \\rightarrow 0}{ \\longrightarrow} 0\\end{cases}$ D√©finition : On dit que $f: \\mathbb R^n \\longrightarrow \\mathbb R$ est differentiable de $x_0$ ssi il existe une application lin√©aire $d_{x_0}f$ (aussi not√© $df_{x_0}$) tq $f(x_0 + h) = f(x_0) + d_{x_0}f(h) + \\underset{||H|| \\varepsilon (h)}{o_0(h)}$$h \\mapsto h f‚Äô(x_0)$ est lin√©raire $\\varepsilon : \\mathbb R^n \\longrightarrow \\mathbb R$$d_{x_0} f:h \\mapsto d_{x_0}f(h) = h \\times f‚Äô(x_0)$ Propri√©t√© : Si $f$ est diff√©rentiable en $x_0$ alors $f$ est continue en $x_0$Propri√©t√© : Si $f$ est diff√©rentiable en $x_0$ alors $f$ admet des d√©riv√©es directionnelles selon tout vecteur $h \\in \\mathbb R^n \\verb++ {0}$, et la d√©riv√©e directionnelle vaut $D_hf(x_0) = d_{x_0}f(h)$Soit $f$ diff√©rentiable en $x_0$.Donc les d√©riv√©es partielles $\\frac{\\partial f}{\\partial x_k}$ existent en $x_0$Soit $h \\in \\mathbb R^n \\verb++ {0}$ et $(e_1, \\dots , e_n)$ la base$h = \\begin{pmatrix} h_1 \\ \\vdots \\ h_n\\end{pmatrix} = \\sum_{i = 1}^{n} h_i e_i$$D_hf(x_0) = d_{x_0}f(h) = d_{x_0}f(\\overset{n}{\\underset{i=1}{\\sum}} h_ie_i) = \\overset{n}{\\underset{i=1}{\\sum}} h_i d_{x_0}f(e_i)=\\overset{n}{\\underset{i=1}{\\sum}} h_i \\frac{\\partial f}{\\partial x_i}x_0$$d_{x_0}f(h) = \\langle \\nabla f(x_0), h \\rangle$Soit $f:\\mathbb R^n \\rightarrow \\mathbb R$on d√©finit le vecteur gradient de $f$ en $x_0$ par$\\nabla f(x_0) = \\begin{pmatrix}\\frac{\\partial f}{\\partial x_1}(x_0) \\vdots \\frac{\\partial f}{\\partial x_n}(x_0)\\end{pmatrix}$Si $f$ diff√©rentiable en $x_0$, alors $d_{x_0} f:h \\longmapsto \\langle \\nabla f(x), h \\rangle$$d_{x_0} :h \\longmapsto h f(x_0)$Soit \\(f: \\begin{aligned}\\mathbb R^n &amp;amp;\\longmapsto \\mathbb R^p\\\\x = (x_1, \\ldots, x_n) &amp;amp; \\longmapsto f(x) = (f_1(x), \\ldots, f_p(x))\\end{aligned}\\)Soit $x_0 \\in \\mathbb R^n$ et $f$ diff√©rentiable en $x_0$Les $f_1,\\dots, f_p$ sont diff√©rentiables en $x_0$Soit $h \\in \\mathbb R^n \\qquad \\overbrace{f(x + h)}^{\\in \\mathbb R^p} = \\overbrace{f(x_0)}^{\\in \\mathbb R^p} + \\overbrace{d_{x_0}f(h)}^{\\in \\mathbb R^P} + o_0(h)$\\[\\begin{pmatrix} f_1(x_0 + h) \\\\ \\vdots \\\\ f_p(x_0 + h)\\end{pmatrix} =\\begin{pmatrix} f_1(x_0) \\\\ \\vdots \\\\ f_p(x_0)\\end{pmatrix} +\\begin{pmatrix}d x_0 f_1( h) \\\\ \\vdots \\\\d x_0 f_p(h)\\end{pmatrix} + o_0(h)\\]\\[f(x_0 +h) = f(x_0) + \\begin{pmatrix} \\langle \\nabla f_1(x_0), h \\rangle\\\\ \\vdots \\\\ \\langle \\nabla f_p(x_0), h \\rangle \\end{pmatrix} + o_0(h)\\]\\[\\langle \\nabla f_i(x_0),h \\rangle = \\nabla f_i(x_0)^T h = \\left(\\frac{\\partial f_i}{\\partial x_1}(x_0), \\ldots, \\frac{\\partial f_i}{\\partial x_n}(x_0)\\right)\\begin{pmatrix}h_1 \\\\ \\vdots \\\\ h_n\\end{pmatrix}\\qquad \\frac{\\partial f_i}{\\partial x_j}(x_0) = \\partial_j f_i(x_0)\\]\\[f(x_0+h) = f(x_0) + \\begin{pmatrix} (\\partial_1 f_1(x_0) \\dots \\dots \\partial_n f_1(x_0))h \\\\ \\vdots \\\\ (\\partial_1 f_p(x_0) \\dots \\dots \\partial_n f_p(x_0))h \\end{pmatrix} + o_0(h)\\]\\[\\text{les p composantes de f :}\\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1}(x_0)&amp;amp; \\dots&amp;amp; \\frac{\\partial f_1}{\\partial x_n}(x_0)\\\\ \\vdots &amp;amp; &amp;amp; \\vdots \\\\\\frac{\\partial f_p}{\\partial x_1}(x_0)&amp;amp; \\dots&amp;amp; \\frac{\\partial f_p}{\\partial x_n}(x_0)\\end{pmatrix} \\begin{pmatrix} h_1 \\\\ \\vdots \\\\ h_n\\end{pmatrix}\\]On appelle jacobienne de $f$ en $x_0 = (u_1, \\ldots, u_n)\\begin{pmatrix}v_1 \\ \\vdots \\ v_n\\end{pmatrix}$ la matrice :\\(\\mathcal J_{x_0}f = \\left[\\frac{\\partial f_i}{\\partial x_j}(x_0)\\right]_{\\begin{aligned}i &amp;amp;= 1, \\ldots, p\\\\ j &amp;amp;= 1, \\ldots, n\\end{aligned}}\\)Telle que \\(\\underbrace{f(x_0 + h)}_{\\in \\mathbb R^p} = \\underbrace{(x_0)}_{\\in \\mathbb R^p} + \\underbrace{\\underbrace{\\mathcal J_ {x_0}f}_ {\\in \\mathbb M_{p,n}(\\mathbb R)} \\times\\underbrace{h}_ {\\in \\mathbb R^p}}_{\\in \\mathbb R^p} + o_0(h)\\)$d_{x_0}f: h \\longmapsto \\mathcal J_{x_0}f \\times h$ est bien lin√©aireSoit $f:\\mathbb R^n \\rightarrow \\mathbb R^p$ differentiable en $x_0 \\in \\mathbb R^n$Soit $g:\\mathbb R^p \\rightarrow \\mathbb R^n$ differentiable en $f(x_0) \\in \\mathbb R^p$Alors la composee $g \\circ f = d_{f(x_0)} g \\circ d_{x_0} f$Avec les jacobiennes $\\mathcal J_{x_0} g \\circ f = \\mathcal J_{f(x_0)} g {\\times}^{\\text{produit matriciel}} \\mathcal J_{x_0}f$$(g \\circ f)‚Äô = f‚Äô \\times (g‚Äô \\circ f)$$(g \\circ f)(x) = g(f(x))$$(g \\circ f‚Äô)(x) = f‚Äô(x) \\times g‚Äô(f(x))$Interpr√©tation g√©om√©trique du gradientOn se limite d√©sormais au cas des fonctions convexes.Quand les resultats √©nonc√©s s‚Äôappliquent √† un cadre plus g√©n√©ral que l‚Äôon sp√©cifiera. Les questions auxquelles on n‚Äôa pas encore de r√©ponses g√©n√©rales : ‚ÄúDirection‚Äù de minimisation d‚Äôune fonction objectif Trouver des hyperplans d‚Äôappui au lieu admissible d‚Äôun probl√®me d‚Äôoptimisation C‚Äôest la proposition suivante qui permet d‚Äôapport une r√©ponse √† ces 2 questions : Proposition :Soit $f:U \\subset \\mathbb R^N \\longrightarrow \\mathbb R$ fonction convexe et diff√©rentiable en $a \\in U$. $\\nabla f(a)$ d√©finit un hyperplan d‚Äôappui √† $\\mathcal C_{\\le r}(f) (r = f(a))$ [Q 4-33]On cherche √† r√©soudre le probl√®me de minimisation : $\\min f_0(x,y)= 2x + y$sujet √† : $3x^2 + y^2 \\leqslant 4$Pour minimiser $f_0$ on part vers la ‚Äúgauche‚Äù du dessin ; vers la direction oppos√©e au gradient de $f_0$.La position ‚Äúlimite‚Äù de ces courbes de niveaux (la courbe de niveau qui r√©alise la valeur optimale) correspond √† un hyperplan d‚Äôappui.$\\mathbb{A}$ est le sous-niveau de niveau 4 de $f_1(x, y) = 3x^2+y^2$\\(\\nabla f_1(x, y) = \\begin{pmatrix}6x \\\\ 2y\\end{pmatrix}\\)On cherche donc un point (x, y) tel que :\\(\\nabla f_1(x, y) + \\lambda \\nabla f_0(x, y) = 0 \\qquad \\text{avec } \\lambda \\geqslant 0\\)Pour trouver (x,y) on cherche a resoudre: $\\begin{cases}\\begin{pmatrix} 6x\\ 2y\\end{pmatrix} = -\\lambda \\begin{pmatrix} 2\\ 1\\end{pmatrix} 3x^2 +y^2 =4 \\end{cases}$Des deux premi√®res √©quations on obtient:\\(x=-\\frac{\\lambda}{3}, y=-\\frac{\\lambda}{2}\\)En r√©injectant dans la deuxi√®me √©quation :\\(x=-\\frac{1}{\\sqrt{21}}, y=-2\\sqrt{\\frac{3}{7}}\\) D√©finition :Avec les notations de la proposition on appelle espace tangeant √† $\\mathcal C_{r}(f)$ en a l‚Äôespace affine.\\begin{aligned}T_a(f) &amp;amp;= a + \\nabla f(a)^\\bot&amp;amp;= a+ {x | \\nabla f(a)^\\top x = 0}\\end{aligned}La proposition donne, telle quelle, la r√©ponse √† la question 2. pos√©e ci-dessus. Elle sugg√®re √©galement une direction vers laquelle minimiser la valeur objectif de f. On suppose que $\\nabla f(a)\\neq 0$, on regarde $-t\\nabla f(a)$ avec $t &amp;gt; 0$.Pour $t$ proche de 0,\\(f(u | \\nabla f(a))-f(a)=\\nabla f(a)^\\top(-t\\nabla f(a)) + ||t\\nabla f(a)||\\epsilon(\\nabla f(a))\\)le $O_o(t)$ est n√©gligable devant $-t\\nabla f(a)^\\top \\nabla f(a)=-t||\\nabla f(a)||^2_2$L‚Äôexpression $f(a-t\\nabla f(a))=f(a)$ est du signe de $-t||\\nabla f(a)||^2_2$. Pour $t$ assez pertit\\(f(a -t\\nabla f(a)) \\leqslant f(a)\\) Remarque : L‚Äô√©tude pr√©c√©dente est contrainte par le fait ‚Äú$t$ assez petit‚Äù. Ca donne une id√©e de direction du min, pas une garantie. L‚Äô√©tude ci-dessus ne n√©cessite pas de convexit√©. Caracteristique du premier ordre de la convexite :$f: T \\subset \\mathbb R^b \\longmapsto \\mathbb R$ est convexe si: $U$ est convexe $\\forall x,y \\in U, f(y) - f(x) \\geqslant \\nabla f(x)^T(y - x)$En supposant cette caracterisation VRAIE :Soit $y \\in \\mathcal C_{\\le r}(f);$ on veut montrer $\\nabla f(x)^T(y -x) \\le 0$Or comme f est convexe on a :\\(\\nabla f(x)^T(y-x) \\leqslant \\underbrace{f(y)}_{\\le r}\\underbrace{(fx)}_{=r}\\)d‚Äô ou $\\nabla f(x)^T (y-x) \\leqslant 0$Preuve de la caract√©risation de convexit√©Convexe $\\Leftrightarrow$ ($\\nabla$ convexe)Soient $x,y \\in U, t \\in [0,1]$On regarde la fonction\\(g(t) = f((1-t)x + ty)\\)La definition de convexite de f :\\[\\begin{matrix} &amp;amp; f((1-t) x + t(y)) &amp;amp; \\leqslant &amp;amp; (1-t)f(x) + tf(y)\\\\\\Leftrightarrow &amp;amp; g(t) &amp;amp; \\leqslant &amp;amp; (1-t)g(0) + g(1)\\\\\\Leftrightarrow &amp;amp; g(t) - g(0) &amp;amp; \\leqslant &amp;amp; t(g(1) - g(0))\\\\\\Leftrightarrow &amp;amp; \\frac{g(t) - g(0)}{t} &amp;amp; \\leqslant &amp;amp; g(1) - g(0)\\\\\\Rightarrow &amp;amp; g(0) &amp;amp; \\leqslant &amp;amp; f(y) - f(x)\\end{matrix}\\]Or $g(0) \\nabla f(x)^T(y -x)$D‚Äôou $\\color{green}{\\boxed{\\nabla f(x)‚Äô(y-x) \\leqslant f(y) - f(x)}}$($\\nabla$ convexe) et $U$ convexe $\\Rightarrow$ convexeSoient $x,y \\in U \\qquad z_t = (1 - t)x + ty$\\[\\begin{aligned}t \\times [f(y)- f(z_t)] &amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)^\\top(y -z_t)\\\\(1-t) \\times [f(x) - f(z_t) &amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)(x-z_t)]\\\\tf(y) + (1-t)f(x) + tf(z_t) - (1 -t)f(z_t)&amp;amp;\\geqslant&amp;amp; \\nabla f(z_t)(t(y -z_t) + (1-t)(x - z_t)) \\color{orange}{(D)}\\end{aligned}\\]$\\color{orange}{(D)}$ :$\\nabla f(z_t)(ty + (Lt)x -z_t) = 0$$(D) = 0$$(G):$\\begin{aligned}&amp;amp;tf(y) + (1-t)f(x) + f(z_t)&amp;amp;= tf(y) + (1-t)f(x) + f(ty + (1-t)x)\\end{aligned} Exercice :Trouver les points sur le parabolo√Øde $z = 4x^2 + y^2$ o√π le plan tangent est parall√®le au plan $x + 2y + z = 6$.De m√™me pour le plan $3x + 5y - 2z = 5$Probl√®mes d‚ÄôoptimisationCat√©gorie des probl√®mes convexes Convention :pour simplifier la notation on note $f : \\mathbb R^n \\longrightarrow \\mathbb R$ une fonction qui n‚Äôest pas n√©cessairement, d√©finie sur $\\mathbb R^n$ D√©finition :Un probl√®me d‚Äôoptimisation convexe est un probl√®me qui s‚Äôexprime sous la forme $\\min f_0(x)$, sujet √†:\\(f_i(x) \\leqslant 0 \\: \\forall i \\in \\{1,\\dots,m\\}\\\\f_j(x) = 0 \\: \\forall j \\in \\{1,\\dots, p\\}\\) O√π $f_0, f_i, h_j : \\mathbb R^n \\longrightarrow \\mathbb R$ sont convexes et de plus les $h_j$ sont affines.On peut en particulier r√©√©crire $(P)$ sous la forme: $\\min f_0(x)$ sujet √† :\\(\\begin{aligned}f_i(x) &amp;amp;\\leqslant 0 \\: \\forall i \\in \\{1,...,m\\}\\\\A x &amp;amp;= b\\end{aligned}\\)o√π $\\mathcal A \\in M_{p,n}(\\mathbb R); b \\in M_{p,1}(\\mathbb R)$On dit qu‚Äôun point $x$ est admissible s‚Äôil satisfait les contraintes d√©finies par $(P)$. Le lieu admissible $\\mathcal A$ de $(P)$ correspond aux points admissibles de $(P)$. On fait remarquer que sous nos hypotheses, $\\mathcal A$ est convexe. On note $p^{*}$ la valeur optimale de $(P)$:\\(p^{*} = \\underset{x \\in \\mathcal A}{inf}\\{f_0(x)\\}\\)Par convention si $\\mathcal A = \\emptyset; p^{*} = +\\infty$. Dans le cas sur $p^{*} = - \\infty$ on dit que ($P$) est non born√©.On appelle enfin point optimal $x^{*}$ de $(P)$ tout point tq $f_0(x^{*}) = p^{*}$. Un tel point n‚Äôexiste pas toujours; par exemple c‚Äôest le cas $\\underset{x \\in \\mathbb{R}_+^{*}}{min} \\frac{1}{x}$. De plus, il n‚Äôexiste pas en g√©n√©ral qu‚Äôun seul point optimal (quand il y en a); prendre par exemple le probl√®me:\\(\\underset{x \\in \\mathbb{R}}{min} 10\\)L‚Äô√©criture de ($P$) dans la d√©finition est appel√©e standard d‚Äôun probl√®me d‚Äôoptimisation. Il existe une notion th√©orique d‚Äô√©quivalence de probl√®me d‚Äôoptimisation, On ne rentrera pas dans le d√©tail, sachez qu‚Äôelle consiste √† r√©exprimer un probl√®me d‚Äôoptimisation de fa√ßon √† le r√©soudre plus facilement. Exemple :$\\min |x|$ sujet √†:\\(\\begin{aligned}x - 2 &amp;amp;\\leqslant 0 \\qquad (P_1)\\\\-x -2 &amp;amp;\\leqslant 0\\end{aligned}\\)$P_1$ est √©quivalent √†: $\\min -x^2$ sujet √†:\\(\\begin{aligned}x - 2 &amp;amp;\\leqslant 0\\\\-x -2 &amp;amp;\\leqslant 0\\end{aligned}\\)Pourquoi la convexit√© ?unicit√© du minimumSoit $f: \\mathbb R^n \\longrightarrow \\mathbb R$ une fonction convexe, alors $f$ : n‚Äôadmet pas de maximum locaux strictes. Admet au plus un minimum local stricte.Essayons de justifier le premier point. Supposons qu‚Äôil existe un voisinage $\\mathcal{B}(x, \\varepsilon)$ pour $\\varepsilon &amp;gt;0$ tq :\\(\\forall y \\in \\mathcal{B}(x, \\varepsilon), y \\neq x f(y) &amp;lt; f(x)\\)Soient $y_1,y_2 \\in \\mathcal{B}(x, \\varepsilon) \\backslash {x}$$\\forall t \\in [0,1]$(conv):$f(ty_1 + (1-t)y_2) \\leqslant tf(y_1) + (1-t) f(y_2)$Donc $tf(y_1) + (1 -t)f(y_2) \\leqslant f(x)$car $f(y_1) \\leqslant f(x)$ et $f(y_2) \\leqslant f(x)$La condition pr√©c√©dente exprime le fait que la s√©cante au graphe de f sur $\\mathcal{B}(x, \\epsilon)$ est en dessous de celui ci, donc pas dans l‚Äô√©pigraphe de f. Dans ce cas f n‚Äôest pas convexe.Pour le second point:si $y_1, y_2$ sont 2 minimaux locaux et diff√©rents, on retrouve la situation qui contredit la convexit√©.Condition d‚Äôexistance d‚Äôun minimum sous contraintesSi on est dans la situation suivante Propri√©t√© :Un point $x \\in \\mathcal A$ est optimal si:\\[\\nabla f(x^{*} )^\\top(y.x) \\geqslant 0\\] $-\\nabla f_0(x^{*})^\\top(y-x) \\leqslant 0$$-\\nabla f_0(x^{*})$ d√©finit un hyperplan d‚Äôappui en $x^{*}$ √† $\\mathcal A$. Preuve :Supposons $x^{*}$ satisfait $(op)$.D‚Äôapr√®s les in√©galit√©s de convexit√© sur $f_0$ on a:\\(\\forall y \\in \\mathcal A; \\nabla f_0(x^{*})^\\top(y-x^{*}) \\leqslant f(y) - f(x)\\)D‚Äôapr√®s $(op)$:\\(f(y) - f(x^{*}) \\geqslant 0 \\Leftrightarrow f(y) \\geqslant f(x^{*})\\)La r√©ciproque se fait par contraposition. On la laisse de c√¥t√© pour cette fois.Est-ce que l‚Äôhypoth√®se de convexit√© de $(P)$ sur tout son domaine de d√©finition est important ? $\\rightarrow$ Matheux dans sa t√™te : OUI$\\rightarrow$ Informaticien (matheux qui fait calculer) : BAH ‚Ä¶ CON vexe ?Cas sans contrainteOn s‚Äôint√©resse en un premier temps au probl√®me d‚Äôoptimisation de la forme:\\(\\underset{x \\in \\mathbb R^n}{\\min} f_0(x)\\)avec $f_0$ diff√©rentiable Propri√©t√© :Si $x^{*}$ est un point optimal de $f_0$ alors:\\(\\nabla f_0(x^{*}) = \\underline{0}\\) Preuve :On se place sur un voisinage $\\mathcal B(x^{*}, \\varepsilon)$ pour $\\varepsilon \\gt 0$ o√π $\\forall y \\in \\mathcal B(x^{*}, \\varepsilon); f_0(y) \\geqslant f_0 (x^{*})$ En particulier pour le h assez proche de 0: \\(\\begin{aligned}&amp;amp;f_0(x^{*} + h) -f_0(x^{*}) &amp;amp;\\geqslant 0\\\\\\Rightarrow &amp;amp;\\nabla f_0(x^{*})^T h + \\theta_0 &amp;amp;\\geqslant 0\\end{aligned}\\)Ainsi $\\forall h \\in \\mathcal{B}(\\underline{0}, \\eta)$ pour $\\eta &amp;gt; 0$ \\(\\nabla f_0(x^{*})^T \\geqslant 0\\)La seule application lin√©aire qui est possible sur un voisinage $\\mathcal B(\\underline{0}, \\eta)$ est l‚Äôapplication nulle.Dans le cas $f_0$ convexe, l‚Äôannulation du gradient en un point va nous limiter √† un sous-lieu de points optimaux √† √©tudier. En r√©alit√©, on a en g√©n√©ral la situation suivante: Les points critiques d‚Äôune fonction $f_0$ quelconque sont de l‚Äôune des trois formes suivantes: Minimum locaux. Maximums locaux. Points selles. Dans le cas convexe on a que des points du premier type. Dans ce cas l‚Äô√©tude des points critiques se confond avec celle des points minimaux.Probl√®me du dualSoit P le probl√®me d‚Äôoptimisation: \\(\\min f_0(x)\\)sujet √†\\(f_i(x) \\leqslant 0\\\\h_j(x) = 0\\)Si on voulait ramener l‚Äô√©tude de $(P)$ √† la minimisaion d‚Äôune seule fonction on pourrait √©tudier:\\(\\Phi(x) = f_0(x) + \\sum_{i=1}^n I_+(f_i(x)) + \\sum_{j=0}^pI_0(f_j(x))\\)o√π\\(\\begin{aligned}I_+ (x) &amp;amp;= \\begin{cases}0 \\text{ si } x \\leqslant 0\\\\+\\infty \\text{ sinon}\\end{cases}\\\\I_0 (x) &amp;amp;= \\begin{cases}0 \\text{ si } x = 0\\\\+\\infty \\text{ sinon}\\end{cases}\\end{aligned}\\)Probl√®me d‚Äôoptimisation √©quivalent √† $(P)$ mais inutilisable D√©finition :On appelle Lagrangien du probl√®me ($P$) la fonction: \\(\\mathcal L_P (\\underset{\\in \\mathbb R^n}{x}, \\underset{\\in \\mathbb R^m}{\\lambda},\\underset{\\in \\mathbb R^p}{\\nu}) = f_0(x) + \\sum_{i=1}^n \\lambda_i f_i(x) + \\sum_{j=0}^p \\nu_j f_j(x)\\)On d√©finit le probl√®me dual $(\\check{P})$ de $(P)$ comme suit: on note:\\[g(\\lambda, \\nu ) = \\underset{x \\in \\mathbb R^n}{inf} \\mathcal L(x,\\lambda, \\nu)\\]avec cette notation:\\[\\underset{\\lambda, \\nu}{max} g(\\lambda, \\nu) \\qquad (\\check P)\\\\\\text{sujet √†} \\quad \\lambda \\geqslant 0\\]Remarque: $g(\\lambda, \\nu)$ pour $\\lambda \\geqslant 0$ est l‚Äô$inf$ d‚Äôune fonction concave. (affines en les $\\lambda$ et $\\nu$) c‚Äôest donc concave (exo bribes de g√©ometries)Donc $(\\check{P})$ est toujours un probl√®me convexe. Propri√©t√© :\\(\\forall \\lambda \\geqslant 0 \\text{; on a : } g(\\lambda, \\nu) \\leqslant p^{*}\\) Preuve :Soit $x$ un point admissible de ($P$). on a donc $f_i \\leqslant 0$ et $h_j(x) = 0$.Donc \\(\\sum_{i= 1}^m d_if_i(x) + \\sum_{j = 1}^P \\nu_jh_j(x) \\leqslant 0 \\: \\forall \\qquad \\lambda \\geqslant 0\\)D‚Äôo√π:\\(\\begin{aligned}&amp;amp;\\mathcal L_p(x, \\lambda_1 \\nu) &amp;amp;=&amp;amp; f_0(x) + \\sum_{i=1}^n \\lambda_i f_i(x) + \\sum_{j=0}^p \\nu_j f_j(x)&amp;amp;\\leqslant&amp;amp; f_0(x)\\\\\\Rightarrow &amp;amp;\\underset{x}{inf} \\mathcal{L}(x, \\lambda, \\nu)&amp;amp;=&amp;amp; g(\\lambda, \\nu) &amp;amp;\\leqslant&amp;amp; f_0(x)\\\\\\Rightarrow &amp;amp;g(\\lambda, \\nu) &amp;amp;\\leqslant&amp;amp; p^{*}\\end{aligned}\\)Corollaire :Si on note $d^{*}$ la valeur optimale du dual on a : $d^{*} \\leqslant p^{*}$Question : Est ce qu‚Äôon a l‚Äô√©galit√© ?Dans la situation d‚Äô√©galit√© on dit qu‚Äôon a une dualit√© forte entre (P) et $(\\check{P})$Condition de Slater : Si $(P)$ est convexe et il existe un pt dans l‚Äôint√®rieur relatif du domaine de d√©finition de $(P)$ tq :$f_i(x)&amp;lt;0$$A x=b$alors $(P)$ et $(\\check{P})$ sont en dualit√© forte: D√©finition :On dit qu‚Äôun couple $(\\lambda, \\nu)$ est de $t$ dual admissible si $\\lambda \\geqslant 0$ et $g(\\lambda, \\nu) \\gt -\\infty$. Les points $(\\lambda^{*},\\nu^{*})$ optimaux pour $\\check{\\mathcal P}$ sont parfois appel√©s multiplicateurs de Lagrange.Les conditions KKT (Karush-Kuhn-Tucker)Supposons que les valeurs optimales, primale et duale, soient atteintes et egales, en particulier on a une dualite forte. On designe par $x^{*}$ (respectivement $(\\lambda^{*},\\nu^{*})$) un point optimal de $\\mathcal P$ (respectivement $\\check{\\mathcal P}$)On a :\\(\\begin{aligned}f_0(x^{*})&amp;amp;=g(\\lambda^{*}, \\nu^{*})\\\\&amp;amp;=\\inf(\\mathcal L_p (x, \\lambda^{*}, \\nu^{*}))\\\\&amp;amp;\\leq \\mathcal L_p(x^{*}, \\lambda^{*}, \\nu^{*})\\\\&amp;amp;=f_0(x^{*}) + \\sum_{i=1}^m \\lambda_i^{*} f_i(x^{*}) + \\sum_{j=1}^p \\nu_j^{*} h_j(x^{*})\\\\&amp;amp;\\leq f_0(x^{*})\\end{aligned}\\)Toutes les in√©galit√©s qui apparaissent pr√©c√©demment sont donc des √©galit√©s. On en d√©duit :1) $x^{*}$ minimise $\\mathcal L_p(x, \\lambda^{*},\\nu^{*})$2) $\\displaystyle \\sum_{i=1}^m \\underbrace{ \\lambda_i^{*} f_i(x^{*})}_{\\le 0} = 0$$\\Rightarrow \\forall i \\in {1,‚Ä¶,m}; \\lambda_i^{*}f_i(x^{*}) = 0$La fonction $x \\longmapsto \\mathcal L_p(x, \\lambda^{*}, \\nu^{*})$ est convexe des que $(P)$ l‚Äôest. Dire que $x^{*}$ minimise $x \\longmapsto \\mathcal L_p(x, \\lambda^{*}, \\nu^{*})$ est equivalent a dire que$\\nabla_x \\mathcal L_p (x^{*},\\lambda^{*},\\nu^{*}) = 0$$\\Leftrightarrow \\nabla f_0(x^{*}) + \\displaystyle \\sum_{i=1}^m \\lambda_i^{*} \\nabla f_i(x^{*}) + \\displaystyle \\sum_{j = 1}^{p} \\nabla j^{*} \\nabla hj(x^{*}) = 0$Pour resumer $(x^{*},\\lambda^{*}, \\nu^{*})$ verifient les contraintes :$f_i(x^{*}) \\leqslant 0 \\qquad \\forall i \\in {1,‚Ä¶,m}$$h_j(x^{*}) = 0 \\qquad \\forall j \\in {1,‚Ä¶,p}$$\\lambda_i^{*} \\geqslant 0 \\qquad \\forall i \\in {1,‚Ä¶,m}$ (KKT)$\\lambda_i^{*} f_i(x^{*}) = 0 \\qquad \\forall i \\in {1,‚Ä¶,m}$$\\nabla f_0(x^{*}) + \\displaystyle \\sum_{i =1}^m \\lambda_i^{*} \\nabla f_i(x^{*}) + \\displaystyle \\sum_{j = 1}^{p} \\nu_j^{*} \\nabla h_j(x^{*}) = 0$ Propri√©t√© : Quand $(P)$ est un probl√®me convexe et dans le cas de forte dualit√©, (condition de Slater satisfaite, par exemple) les conditions KKT sont n√©cessaires et suffisantes pour avoir une pair primal-dual optimale.Exercices :R√©soudre en utilisant les conditions KKT1\\(min_{x \\in \\mathbb R^2} \\quad \\frac{1}{2}({x_1}^2 + {x_2}^2) \\qquad tq \\quad x_1 - 2x_2 \\leqslant -2\\) Correction :\\(f_0(x_1, x_2) = \\frac{1}{2}(x_1^2 + x_2^2)\\)\\(\\begin{aligned} \\mathcal L(x_1,x_2, \\lambda) &amp;amp;= f_0(x_1, x_2) + \\lambda f_1(x_1, x_2)\\\\ &amp;amp;= \\frac{1}{2}\\left(x_1^2 + x_2^2\\right) + \\lambda (x_1 - 2x_2 + 2) \\end{aligned}\\) Pour que:$(x_1^{*}, x_2^{*})$ soit optimal, il faut que:\\(\\begin{aligned}&amp;amp;\\nabla_x \\mathcal L(x^{*}, \\lambda) = 0 \\\\&amp;amp;\\nabla_x \\mathcal L(x, \\lambda) = 0 \\Leftrightarrow \\begin{cases} \\frac{\\partial \\mathcal L}{\\partial x_1} = 0 \\\\\\frac{\\partial \\mathcal L}{\\partial x_2} = 0 \\end{cases} \\\\&amp;amp;\\begin{cases}\\frac{\\partial \\mathcal L}{\\partial x_1} = x_1 + \\lambda = 0\\\\\\frac{\\partial \\mathcal L}{\\partial x_1} = x_2 - 2\\lambda = 0\\end{cases}\\Leftrightarrow\\begin{cases}x_1 = -\\lambda\\\\x_2 = 2 \\lambda\\end{cases}\\end{aligned}\\)La fonction objective duale est:\\(\\begin{aligned}g(\\lambda, \\nu) &amp;amp;= \\underset{x \\in \\mathbb R^n}{inf} \\mathcal L(x, \\lambda, \\nu)\\\\g(\\lambda) &amp;amp;= \\frac{1}{2}((-\\lambda)^2 + (2\\lambda)^2) + \\lambda(-\\lambda - 4 \\lambda + 2)\\\\ &amp;amp;= \\frac{1}{2}(\\lambda^2 + 4\\lambda^2) - \\lambda^2 - 4\\lambda^2 + 2\\lambda\\\\ &amp;amp;= \\frac{5}{2}\\lambda^2 -5\\lambda^2 + 2\\lambda\\\\ &amp;amp;= -\\frac{5}{2}\\lambda^2 + 2\\lambda\\end{aligned}\\)Probl√®me dual $p^2$\\(\\underset{\\lambda \\geqslant 0}{max} \\qquad g(\\lambda, \\nu)\\)On cherche $\\underset{\\lambda \\geqslant 0}{max}(\\underbrace{-\\frac{5}{2}\\lambda^2 + 2\\lambda}_{g(\\lambda)})$On cherche \\(\\lambda^{*} \\quad tq \\quad \\begin{cases}\\nabla g(\\lambda^{*}) &amp;amp;= 0\\\\\\lambda^{*} &amp;amp;\\geqslant 0\\end{cases}\\)2)\\(\\begin{aligned}&amp;amp;\\nabla g(\\lambda) &amp;amp;=&amp;amp; -5\\lambda + 2\\\\&amp;amp;\\nabla g(\\lambda^{*}) &amp;amp;=&amp;amp; 0 \\\\\\Leftrightarrow&amp;amp; -5\\lambda^{*} + 2 &amp;amp;=&amp;amp; 0\\\\\\Leftrightarrow&amp;amp; \\lambda^{*} &amp;amp;=&amp;amp; \\frac{2}{5} \\geqslant 0\\end{aligned}\\)et $\\displaystyle x^{} = (x_1^{}, x_2^{*}) = \\left(-\\frac{2}{5}, \\frac{4}{5}\\right)$2 ‚Ä¶ Apres avoir mis sous forme matricielle\\(min_{x \\in \\mathbb R^3} \\quad \\frac{1}{2}(x_1^2 + x_2^2 + x_3^2) \\qquad tq \\quad \\begin{aligned} x_1 + x_2 + 2x_3 = 1 \\\\ x_1 + 4x_2 + 2x_3 = 3 \\end{aligned}\\) Correction ://FIXME" }, { "title": "OCVX: Optimisation Convexe 1", "url": "/cours/posts/ocvx_verjus_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-22 21:00:00 +0100", "snippet": "Notes de ce cours par Kariulele et Bjorn (Un grand merci a eux!)Bashar‚Äôs Github bashar.dudin@epita.frguillaume.tochon@lrde.epita.fr√Ä voir : Descente de gradientIntroductionEn rentrant dans l‚Äô√®re industrielle, il a fallu optimiser les co√ªts, minimiser les risques, etc.Des mathematiciens ont commenc√© √† se poser des questions.ex: gestion d‚Äôun stock, optimiser la construction de produits en usine. Algebre lin√©aire Calcul diff√©rentiel G√©ometrie Examples: Chercher le plus cours chemnin entre deux coordonn√©es GPS. D√©cider des meilleurs routes a√©riennes qui minimisent le prix d‚Äôapprovisionnement en k√©ros√®ne. Identifier des images d‚ÄôIRM qui correspondent √† des malformations du cerveau. Chercher des patterns dans la population d‚Äô√©tudiants int√©grants EPITA. Probl√®mes d‚ÄôoptimisationD√©finition formelleMinimiser $f_0(x)$sujet √† : $f_i(x) \\leq 0, \\forall i \\in {1,\\dots,p}$ $h_j(x) \\leq 0, \\forall j \\in {1,\\dots,m}$o√π $f_0$, les $f_i$ et les $h_i$ sont des applications de $\\mathbb{R}^n$ vers $\\mathbb{R}$. La fonction $f_0$ est dite fonction objectif; suivant le contexte ce sera une fonction de co√ªt ou d‚Äôerreur.Un probl√®me d‚Äôoptimisation du type de $(P)$ : diff√©rentiable si toutes les fonctions en jeu le sont. non-contraint s‚Äôil n‚Äôa aucune contrainte d‚Äôin√©galit√©s ou d‚Äô√©galit√©s. convexe si l‚Äôensemble des fonctions en jeu sont convexes, les contraintes d‚Äô√©galit√©s √©tant de plus affines.Lexique√âtant donn√©e un probl√®me d‚Äôoptimisation $(P)$ on appelle : point admissible de $(P)$ tout point de $\\mathbb{R}^n$ satisfaisant toutes les contraintes. L‚Äôensemble de tous les points admissibles est appel√© lieu admissible de $(P)$. valeur objectif d‚Äôun point admissible la valeur que prend la fonction objectif en celui-ci. valeur optimale de $(P)$ la meilleure borne inf√©rieure sur la fonction objectif. point optimale de $(P)$ tout point admissible dont la valeur objectif est la valeur optimale.Premi√®res remarques qualitatives Y a-t-il au moins une solution ? S‚Äôil y a au moins une solution, combien ? Peut-on toujours d√©crire l‚Äôensemble des solutions? Y a-t-il moyen d‚Äôapprocher des solutions?MLMap fittingProbl√®me d‚Äôoptimisation dit de map fitting D√©finition :Une famille diff√©rentiable d‚Äôapplications $f_\\alpha:\\mathbb{R}^n\\longmapsto\\mathbb{R}$ ind√©xe≈õ par $\\alpha \\in \\mathbb{R}^k$ est une famille de fonctions pour laquelle l‚Äôapplication $\\varphi:\\mathbb{R}^k\\times\\mathbb{R}^n\\longmapsto\\mathbb{R}$ qui envoie $(\\alpha,x)$ sur $f_\\alpha(x)$ est diff√©rentiable. Map Fitting :On consid√®re un ensemble de couples $(X_i, y_i)\\in\\mathbb{R}^n\\times\\mathbb{R}$ pour $i \\in { 1,‚Ä¶,p }$ et une famille diff√©rentiable d‚Äôapplications \\(\\{ f_\\alpha \\}_{\\alpha\\in\\mathbb{R}^k}\\). Le probl√®me de map fitting relatif aux donn√©es pr√©c√©dentes consiste √† trouver les meilleurs param√®tres $\\alpha^{*}$ tels que $f_{\\alpha^{*}}$ approche au mieux les $(X_i, y_i)$.R√©gression lin√©aireLe plus simple des probl√®mes de map fitting est celui de la r√©gression lin√©aire. La famille diff√©rentiable √† laquelle on s‚Äôint√©resse est index√©s par $\\mathbb{R}^2$: $f_\\alpha(x)=\\alpha_1x+\\alpha_0$ pour $\\alpha=(\\alpha_0,\\alpha_1)$ La m√©trique standard utilis√©e est le MSE (Mean Square Error) donn√©e pour un $f_\\alpha$ par\\(\\mathcal{E}(\\alpha)=\\sum_{i=1}^p\\frac{1}{p}(f_\\alpha (X_j)-y_i)^2\\)Le but est de trouver un param√®tre $\\alpha = (\\alpha_0,\\alpha_1)$ tel que $\\mathscr{E}(\\alpha)$ est minimal, autrement dit de r√©oudre le probl√®me d‚Äôoptimisation sans contraintesContour du cours La premi√®re partie est not√© par un TD et un partiel La seconde partie est not√© par une analyse √† faire (projet?)Classification Comment s√©parer la classe1 de la classe2 ? On fait un trait‚Ä¶Produit scalaire$x = \\begin{pmatrix}x_1 \\ \\vdots \\ x_n\\end{pmatrix} \\qquad y = \\begin{pmatrix}y_1 \\ \\vdots \\ y_n\\end{pmatrix}$\\[\\begin{aligned}\\langle:\\rangle : \\mathbb{R}^n &amp;amp;\\longrightarrow \\mathbb{R}\\\\(x,y) &amp;amp;\\longmapsto \\langle x,y \\rangle\\end{aligned}\\]$\\langle x,y \\rangle =\\displaystyle\\sum_{i=1}^{n}x_iy_i$$\\Vert x\\Vert =\\sqrt{\\langle x,x \\rangle}$On veut : $x_1, x_2$ en fonction de $\\Vert x\\Vert $ et $\\varphi$ $y_1, y_2$ en fonction de $\\Vert y\\Vert $ et $\\psi$ $x_1 = \\Vert x\\Vert \\cos{\\varphi} \\qquad x_2 = \\Vert x\\Vert \\sin{\\varphi}$ $y_1 = \\Vert y\\Vert \\cos{\\psi} \\qquad y_2 = \\Vert y\\Vert \\sin{\\psi}$ $\\langle \\vec{x}, \\vec{y}\\rangle = x_1 y_1 + x_2 y_2 = \\Vert x\\Vert .\\Vert y\\Vert .(\\underbrace{\\cos{\\varphi}\\cos{\\psi} + \\sin{\\varphi}\\sin{\\psi}}_{\\cos{(\\psi - \\varphi)} = \\cos{\\theta}}) =\\Vert x\\Vert .\\Vert y\\Vert .\\cos{\\theta}$ En dimension n :\\(\\theta(x,y)=arccos\\left(\\frac{\\langle x,y \\rangle}{\\Vert x\\Vert .\\Vert y\\Vert }\\right)\\) Formules usuelles trigonometriques :\\(\\sin \\left(s+t\\right)=\\sin \\left(s\\right)\\cos \\left(t\\right)+\\cos \\left(s\\right)\\sin \\left(t\\right)\\\\\\sin \\left(s-t\\right)=\\sin \\left(s\\right)\\cos \\left(t\\right)-\\cos \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s+t\\right)=\\cos \\left(s\\right)\\cos \\left(t\\right)-\\sin \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s-t\\right)=\\cos \\left(s\\right)\\cos \\left(t\\right)+\\sin \\left(s\\right)\\sin \\left(t\\right)\\\\\\cos \\left(s\\right)\\cos \\left(t\\right)=\\frac{\\cos \\left(s-t\\right)+\\cos \\left(s+t\\right)}{2}\\\\\\sin \\left(s\\right)\\sin \\left(t\\right)=\\frac{\\cos \\left(s-t\\right)-\\cos \\left(s+t\\right)}{2}\\\\\\sin \\left(s\\right)\\cos \\left(t\\right)=\\frac{\\sin \\left(s+t\\right)+\\sin \\left(s-t\\right)}{2}\\\\\\cos \\left(s\\right)\\sin \\left(t\\right)=\\frac{\\sin \\left(s+t\\right)-\\sin \\left(s-t\\right)}{2}\\\\\\)On peut repr√©senter une droite avec : 2 points 1 point et un vecteur directeur ou normal.$x=\\begin{pmatrix} x_1 \\ x_2 \\end{pmatrix} \\in D \\Leftrightarrow \\langle \\vec{Ox},\\vec{n} \\rangle = 0 \\Leftrightarrow \\underbrace{x^{\\top}n=0}_{\\langle x,n \\rangle}$$\\rightarrow$ Equation d‚Äôun hyperplan de vecteur normal $\\vec{n}$Soit une droite $ax_1 +bx_2 + c = 0$ : Son vecteur normal : $\\vec{n} = \\begin{pmatrix}a\\ b\\end{pmatrix}$ Son vecteur directeur : $\\vec{u} = \\begin{pmatrix}-b\\ a\\end{pmatrix}$ Exercice :Dessiner le lieu de $\\mathbb{R}^2$ donn√© par la relation\\(\\begin{pmatrix}1 &amp;amp; 2 \\\\-1 &amp;amp; 1\\end{pmatrix}\\begin{pmatrix} x_1\\\\ x_2\\end{pmatrix} \\leq \\begin{pmatrix}0\\\\0\\end{pmatrix}\\) $x_1 + 2x_2 \\leq 0$$-x_1 + x_2 \\leq 0$ On remplace l‚Äôin√©galit√© par une √©galit√© :$x_1 + 2x_2 = 0 \\qquad \\vec{n_1} = \\begin{pmatrix}1\\ 2\\end{pmatrix} \\qquad \\vec{u_1} = \\begin{pmatrix}-2\\ 1\\end{pmatrix}$$-x_1 + x_2 = 0 \\qquad \\vec{n_2} = \\begin{pmatrix}-1\\ 1\\end{pmatrix} \\qquad \\vec{u_2} = \\begin{pmatrix}-1\\ -1\\end{pmatrix}$ On a les vecteurs normaux on peut donc repr√©senter graphiquement le lieu. Exercice :Trouver le lieu de $\\mathbb{R}^3$ tq $\\underbrace{x_1 + x_2 + x_3}_{(1 1 1)\\begin{pmatrix}x1\\ x_2\\ x_3\\end{pmatrix}} \\geq 0$ $\\vec{n} = \\begin{pmatrix}1\\ 1\\ 1\\end{pmatrix}$$\\langle n, x \\rangle \\geq 0$ Espace affine$A = {(1,t) \\in \\mathbb{R}^2 \\vert t \\in \\mathbb{R}} = (1, 0) + \\underbrace{{(0,t) \\in \\mathbb{R}^2 \\vert t \\in \\mathbb{R}}}_{F}$ On note qu‚Äôon pouvait utiliser un autre point $(1,42)$ au lieu de $(1,0)$ donne le m√™me r√©sultat.$P={(t, 3t + u, -u) \\setminus (t, u) \\in \\mathbb{R}^2}$ $O \\in P$ $A = \\begin{pmatrix}1\\ 3\\ 0\\end{pmatrix} \\in P$ $B = \\begin{pmatrix}0\\ 1\\ -1\\end{pmatrix} \\in P$$\\vec{n} = \\vec{OA} \\times \\vec{OB}$ Produit vectoriel : Wikip√©dia Exercice :Ecrire param√©triquement la droite $D$ de $\\mathbb{R}^2$ de vecteur directeur $\\vec{u}=\\begin{pmatrix}1\\ -1\\end{pmatrix}$ et passant par $(2,3)$ Soit $M \\in D \\Leftrightarrow \\exists ~\\alpha \\in \\mathbb{R}$ tq \\(\\vec{AM} = \\alpha \\vec{u} \\\\ \\Leftrightarrow \\begin{pmatrix}x_1 - 2\\\\ x_2 - 3\\end{pmatrix} = \\alpha \\begin{pmatrix}1\\\\ -1\\end{pmatrix}\\\\\\Leftrightarrow \\begin{cases} x_1 -2 = \\alpha \\\\ x_2 - 3 = -\\alpha\\end{cases} \\\\\\Leftrightarrow \\begin{cases}x_1 = \\alpha + 2\\\\ x_2 = 3 - \\alpha\\end{cases}\\) Donc $(D) = {(\\alpha +2, 3-\\alpha) \\vert \\alpha \\in \\mathbb{R}}$ Exercice :Dessiner le lien de $\\mathbb{R}^2$ decrit par les contraintes :$\\begin{pmatrix}-1 &amp;amp; 2 1 &amp;amp; 1\\ \\end{pmatrix} = \\begin{pmatrix}x \\ y \\end{pmatrix} \\le \\begin{pmatrix} -1 \\ 1\\end{pmatrix}$$ax + by = 0$$ax + by +c = 0$$\\overrightarrow{n} \\begin{pmatrix}a \\ b \\end{pmatrix} \\overrightarrow{u} \\begin{pmatrix}-b \\ a \\end{pmatrix}$${ (x,y) \\in \\mathbb{R}^2 , -x + 2y \\le -1 \\text{ et } x+y \\le 1 }$$(D_1) = -x + 2y + 1 = 0$$(0, \\frac{-1}{2} \\in D_1)$$\\overrightarrow{n_1} = \\begin{pmatrix} -1 \\ 2\\end{pmatrix}$$\\overrightarrow{u_1} = \\begin{pmatrix} -2 \\ -1\\end{pmatrix}$\\[\\underbrace{Ax = r}_{\\text{√©criture implicite}} \\qquad \\text{ avec } \\begin{cases}\\text{A matrice } m \\times n\\\\A = [a_{i,j}]_{mn}\\\\x \\in \\mathbb R^n ~ r \\in \\mathbb R^m \\end{cases}\\]\\[\\begin{cases}a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n}xn = r_1\\\\\\vdots \\\\a_{m1}x_1 + a_{m2}x_2 + \\dots + a_{mn}x_n = r_m\\end{cases}\\] Hyperplan: Un plan de dimension $n-1$.Exemples: En 2D, c‚Äôest une droite. En 3D, c‚Äôest un plan‚Ä¶Notre description affine ne suffit pas dans le cas g√©n√©ral. Description d‚Äôun cercle :$x^2 + y^2 = r^2x^2+y^2-r^2=0$$\\boxed{f(x,y) = x^2 + y^2 - r^2}$ Ligne / Courbe de niveau d‚Äôune fonction f :\\(\\mathscr{C}_r=\\{x\\in \\mathbb{R}^n | f(x)=r\\}\\) Lieu de sous niveau d‚Äôune fonction f :\\(\\mathscr{C}_{\\leqslant r}=\\{ x\\ \\in \\mathbb{R}^n \\ f(x) \\leqslant r \\}\\) Les coniques : Ce sont les paraboles, hyperboles, elipses‚Ä¶ Exercice :Courbes de niveau 0,1,2 $f(x,y)=x^2+y^2$ $\\mathscr{C}_0$: seul $(0,0)$$\\mathscr{C}_1$: cercle de rayon 1 centr√© en 0$\\mathscr{C}_2$: cercle de rayon 2 centr√© en 0 $g(x,y)=x^2+4y^2$$\\mathscr{C}_0$: seul $(0,0)$ $\\mathscr{C}_1$: ellipse demi-grand axe 1, demi-petit axe $\\frac{1}{2}$, centr√© en 0$\\mathscr{C}_2$: ellipse demi-grand axe $\\sqrt{2}$, demi-petit axe $\\frac{\\sqrt{2}}{2}$, centr√© en 0 √âquation d‚Äôune √©llipse\\(\\bigg(\\frac xa\\bigg)^2 + \\bigg(\\frac yb\\bigg)^2=1\\)a : demi-grand axeb : demi-petit axe Epigraphe d‚Äôune fonction $f.\\mathbb R^n \\rightarrow \\mathbb R$ $Epi(f) = {(x,t) ~\\vert~ f(x) \\leq t}$ Exercice :Dessiner l‚Äôintersection de l‚Äô√©pigraphe de $f(x)=-\\sqrt{x}$ (sur $\\mathbb R^+$)avec la partie ${(x, y) | y \\leq \\sqrt x}$ Une partie de $A\\subset \\mathbb{R}^n$ est convexe ssi $\\forall x,y\\in A, \\forall t\\in [0,1]$ alors \\(tx+(1-t)y \\in A\\) L‚Äôadh√©rence d‚Äôune partie est sa frontiere.$A \\cup \\partial{A} = \\underbrace{\\bar{A}}_{adh√©rence}$ Exemple :$A = [1,2[$$\\partial A = {{1} {2}}$$\\bar A = [1,2]$ Quoi ? Hyper parapluie ??? [name=multun] Un hyperplan d‚Äôappui d‚Äôune partie $A$ est un hyperplan de $A$ qui poss√©de un √©l√©ment du bord de $A$ Une fonction convexe admet des hyperplans d‚Äôappui en chacun des points de sa fronti√®re. $f$ convexe $\\Leftrightarrow f(tx+(1-t)y) \\leq tf(x)+ (1-t)f(y)$Exemple de fonctions convexes : $f(x) = ax^2 +bx +c , a \\ge 0$ $f(x) = bx+ c$ $e^{ax} \\quad \\forall a$ $f(x) = -\\log(x)$ $f(x) = \\sqrt(x)$ $f(x) = \\vert x\\vert$ $f(x) = x^{2p}, p \\in \\mathbb{N}^*$ Exercice :Est ce que la somme de fonctions convexes est convexe ? $f = \\sum_{i=1}^{N}w_if_i$ la somme de fonctions convexes \\(\\begin{aligned}f(tx + (1-tg)) &amp;amp;= \\sum_{i=1}^N f_i (tx+(1-t)y) \\\\ &amp;amp;\\leq tf_i(x)+(1-t)f_i(y) \\\\ &amp;amp;\\leq \\sum_{i=1}^N w_i(tf_i(x)+(1-t)f_i(y)) \\\\ &amp;amp;\\leq \\sum_{i=1}^N tw_if_i(x) + \\sum_{i=1}^N(1-t)w_if_i(y) \\\\ &amp;amp;\\leq t\\underbrace{\\sum_{i=1}^N w_if_i(x)}_{f(x)} + (1-t) \\underbrace{\\sum_{i=1}^N w_if_i(y)}_{f(y)}\\end{aligned}\\)Donc c‚Äôest bien convexe !Soit $f(x,y) = x^2 + y^2$La fonction Hessienne de $f$:\\(H(x,y) = \\begin{pmatrix}\\frac{\\partial^2f(x,y)}{\\partial x^2}&amp;amp;\\frac{\\partial^2f(x,y)}{\\partial y \\, \\partial x} \\\\ \\frac{\\partial^2f(x,y)}{\\partial y \\, \\partial x}&amp;amp; \\frac{\\partial^2f(x,y)}{\\partial y^2}\\end{pmatrix}\\)Programme lin√©aire Exercice 1: $\\mathcal A_u : \\begin{cases}-x+2y \\leq 1x + y \\leq 1\\end{cases}$ $\\mathcal A_b = \\mathcal A_u \\cup {(x,y) \\in \\mathbb R^2, x-3y \\leq 6}$ $(D_1)$: $-x + 2y + 1 = 0 \\qquad (0, -\\frac 12) \\in (D_1) \\qquad \\vec{n_1}\\begin{pmatrix}-1\\ 2\\end{pmatrix} \\qquad \\vec{u_1}\\begin{pmatrix}-2\\ -1\\end{pmatrix}$ $(D_2)$: $x + y - 1 = 0 \\qquad (0,1) \\in (D_2) \\qquad \\overrightarrow{n_2}\\begin{pmatrix} 1 \\ 1\\end{pmatrix}\\qquad \\overrightarrow{u_2}\\begin{pmatrix} -1 \\ 1\\end{pmatrix}$ $(D_3)$: $x - 3y - 6 = 0 \\qquad (0,-2) \\in (D_3) \\qquad \\overrightarrow{n_3}\\begin{pmatrix} 1 \\ -3\\end{pmatrix}\\qquad \\overrightarrow{u_3}\\begin{pmatrix} 3 \\ 1\\end{pmatrix}$ \\(\\underbrace{\\min f_0(x,y) = y = -\\infty}_{(x,y) \\in \\mathcal{A}_u}\\)\\(\\underbrace{\\min f_0(x,y) = -y = 0}_{(x,y) \\in \\mathcal{A}_u}\\) Exercice 2: $f(x,y) = 3x^2 + y^2$\\(\\mathcal{C}_2(f)\\mathcal{C}_4(f)\\)?\\(\\mathcal{C}_{\\le 4}(f)\\)?\\(\\min f_0(x,y) = 2x + y\\)sujet √† $3x^2 +y^2 \\le 4$\\[\\begin{aligned}\\mathcal{C}_2(f) : &amp;amp; 3x^2 + y^2 = 2 \\\\\\Leftrightarrow &amp;amp;\\frac{3}{2}x^2 \\frac{1}{2}y^2 = 1\\\\\\Leftrightarrow &amp;amp;\\begin{pmatrix}\\frac{x}{\\frac{\\sqrt{2}}{\\sqrt{3}}}\\end{pmatrix}^2 + \\begin{pmatrix}\\frac{y}{\\sqrt{2}}\\end{pmatrix}^2\\\\\\end{aligned}\\begin{aligned}\\mathcal{C}_4(f) : &amp;amp; 3x^2 + y^2 = 4 \\\\\\Leftrightarrow &amp;amp;\\frac{3}{4}x^2 \\frac{1}{4}y^2 = 1\\\\\\Leftrightarrow &amp;amp;\\begin{pmatrix}\\frac{x}{\\frac{2}{\\sqrt{3}}}\\end{pmatrix}^2 + \\begin{pmatrix}\\frac{y}{2}\\end{pmatrix}^2\\\\\\end{aligned}\\begin{aligned}\\mathcal{C}_0(f_0) : &amp;amp; 2x + y = 0 \\\\&amp;amp; (0,0) \\in \\mathcal{C}_0(f_0)\\\\&amp;amp; \\overrightarrow{n}\\begin{pmatrix} 2\\\\ 1\\end{pmatrix} \\overrightarrow{u}\\begin{pmatrix} -1\\\\ 2\\end{pmatrix}\\end{aligned}\\] \\(\\min(f_0(xy)) = f_0^*$ pour $(x,y) = (x^*,y^*)\\)\\(3x^{*2} +y^{*2} = 4$ $(x^*,y^*) \\in \\mathcal{C}_4(f)\\)\\(2x^{*} + y^* = f_0^*$ $(x^*,y^*) \\in \\mathcal{C}_{f_0^*}(f_0)\\) \\(\\begin{aligned}\\Delta f(x^*, y^*) = \\begin{pmatrix} 6x^* \\\\ 2y^*\\end{pmatrix}\\\\\\langle \\Delta f(x^*,y^*), \\overrightarrow{u} \\rangle = 0\\\\\\begin{pmatrix} 6x^* &amp;amp; 2y^* \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = 0 \\end{aligned}\\) \\(\\begin{aligned}3x^{*2} + y^{*2} &amp;amp;= 4\\\\-6x^* + 4y^* &amp;amp;= 0 \\rightarrow y^* &amp;amp;= \\frac{6}{4} x^*\\\\&amp;amp; &amp;amp; = \\frac{3}{2}x^*\\\\&amp;amp; &amp;amp;= \\frac{6}{\\sqrt{21}}\\end{aligned}\\)$y^* = \\frac{6}{\\sqrt{21}}$ \\(3x^{*2} + (\\frac{3}{2}x^{\\*})^2 = 4\\)\\(3x^{*2} + \\frac{9}{4}x^{\\*2} = 4\\)\\(\\frac{21}{4}x^{\\*2} = 4\\)\\(x^{*2} = \\frac{16}{21}\\)\\(x^* = \\frac{4}{\\sqrt{21}}$ ou $-\\frac{4}{\\sqrt{21}}\\)G√©ometrie diff√©rentielle pour les petitsAvec ce qu‚Äôon a vu √† ce jour on peut chercher √† r√©soudre un probl√®me d‚Äôoptimisation de la forme suivante\\(\\begin{aligned}\\text{min}\\qquad &amp;amp; \\overbrace{-x_1-2x_2}^{f_o(x_1,x_2)} \\\\\\text{sujet √†} \\qquad &amp;amp;x_1+x_2 \\leqslant 5 \\\\&amp;amp; -2x_1+x_2 \\leqslant 3 \\\\&amp;amp; x_1, x_2 \\geqslant 0\\end{aligned}\\) Sur la rouge non plus, cf (0.5, 1)Tu d√©passe a gauche$\\color{red}{\\text{Le lieu admissible}}$$\\color{green}{\\mathscr{C}_0}:$ Courbe de niveau de $f_0$ passant par $(0,0)$Afin d‚Äôam√©liorer la valeur objectif du point courant, on cherche un point √† la fois dans le lieu admissible et dans le demi-espace, qu‚Äôon determine √† partir de l‚Äô√©quation de la fonction objectif.La courbe de niveau de la fonction objectif au point optimal isole le lieu admissible dans la partie + des demi-espaces defini par la courbe de niveau de la fonction objectif en ce point. le demi-espace est un hyperplan d‚Äôappui au lieu admissible. Exercice : \\(\\begin{aligned}\\text{min}\\qquad &amp;amp; x+y \\\\\\text{sujet √†} \\qquad &amp;amp;x^2+y^2 \\leqslant 1\\end{aligned}\\)Comment trouver les hyperplans d‚Äôappui au lieu admissible? point optimal en $(\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$je propose$\\color{blue}{\\text{Point optimal B}}$Quand on cherche √† minimiser une fonction objectif affine contrainte par un lieu admissible qui est une ellipse de $\\mathbb R^2$, on se retrouve √† rechercher des hyperplans d‚Äôappui de celui-ci .Cette notion nous ramene √† l‚Äô√©tude des d√©riv√©es de fonction num√©riques dont les graphes d√©crivent des morceaux du bord du lieu admissible. Pour g√©n√©raliser cette approche, on a besoin de g√©n√©raliser la notion de d√©riv√©e sur plusieurs variables.Normes sur $\\mathbb R^2$Une norme sur $\\mathbb R-ev$ est une mani√®re de mesurer la longueur d‚Äôun vecteur, tout en pr√©servant un minimum la structure d‚Äôev. Elle permet en particulier de mesurer la distance entre deux points pour la longueur du vecteur qui les relie. D√©finition :Une norme sur $\\mathbb R^n$ est une application $\\Vert \\cdot\\Vert : \\mathbb{R}^n \\longmapsto \\mathbb{R}$ telle que 1) $\\Vert x\\Vert = 0 \\Longleftrightarrow x = 0$2) $\\forall \\lambda \\in \\mathbb R , \\forall x \\in \\mathbb R^n: \\Vert \\lambda x\\Vert = |\\lambda|\\cdot\\Vert x\\Vert \\qquad \\quad$ (relation d‚Äôhomog√©init√©)3) $\\forall x, y \\in \\mathbb{R}^n$, $\\Vert x+y\\Vert \\leqslant \\Vert x\\Vert + \\Vert y\\Vert \\qquad \\qquad$ (in√©galit√© triangulaire) Exercice : sur $\\mathbb R^n$ \\[\\Vert x\\Vert _1 = \\displaystyle\\sum_{i=1}^{n}\\vert x_i\\vert\\] \\[\\Vert x\\Vert _2 = \\bigg(\\displaystyle\\sum_{i=1}^{n}(x_i)^2\\bigg)^{\\frac 1 2}=\\sqrt{x^Tx}\\] $\\Vert x\\Vert _\\infty = \\underset{i\\in {1,\\dots,n}}{\\max}{\\vert x_i\\vert }$ Pour $p \\geqslant 1$, \\(\\Vert x\\Vert _p = \\bigg(\\displaystyle\\sum_{i=1}^{n}\\vert x_i\\vert ^p\\bigg)^{\\frac 1 p} \\qquad \\qquad\\) (la norme p) ($p \\ge 1$) √Ä partir d‚Äôune norme sur $\\mathbb R^n$, on va pouvoir d√©finir : Une distance : $\\forall x, y \\in \\mathbb R^n, d(x, y) = \\Vert x-y\\Vert $ Une notion de voisinage d‚Äôun point Quand on fait de l‚Äôanalyse, on s‚Äôint√©resse √† ce qui se passe autour d‚Äôun point donn√© $\\varepsilon$-pr√®s. Par example, pour montrer qu‚Äôune suite num√©rique $(u_n)_{n\\in \\mathbb{N}}$ converge vers $l\\in \\mathbb{R}$, on v√©rifie: \\(\\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb{N}, n \\ge N \\Longrightarrow \\underbrace{|u_n - l| &amp;lt; \\varepsilon}_{u_n\\in ] l-\\varepsilon, l+\\varepsilon [}\\) La notion de norme sur $\\mathbb R^n$ permet de g√©n√©raliser cette notion √† toute dimension. Par exemple si $(u_n)_{n \\in \\mathbb{N}}$ une suite √† valeurs dans $\\mathbb R^n$ et $l = (l_1, .., l_n) \\in \\mathbb{R}^n$.On dit que (u_n) converge vers l au sens de la norme $\\Vert .\\Vert $ si :\\((E) \\qquad \\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb{N}, n \\ge N \\Longrightarrow \\Vert u_n - l\\Vert &amp;lt; \\varepsilon\\)On note$\\begin{aligned}B_{\\Vert \\cdot\\Vert }(l,\\varepsilon)={x\\in \\mathbb{R}^n | \\Vert x-l\\Vert &amp;lt;\\varepsilon} \\ \\bar{B}_{\\Vert \\cdot\\Vert }(l,\\varepsilon)={x\\in \\mathbb{R}^n | \\Vert x-\\Vert |&amp;lt;\\varepsilon} \\end{aligned}$Dans ce cas, $(E)$ s‚Äô√©crit : \\(\\forall \\varepsilon &amp;gt; 0, \\exists N \\in \\mathbb N , b \\ge N \\Rightarrow \\mathcal U_n \\in B_{\\Vert .\\Vert }(l,\\varepsilon)\\)Dans le cas de $\\mathbb R^2$ on represente $\\overline{B_{\\Vert \\cdot\\Vert }}(\\underbrace{\\underline{0}}_{\\text{l‚Äôorigine}},1)$ Remarque: les boules d‚Äôune norme sont convexes. du coup, les boules de Noel aussi #loul Comme on a pu le voir pour la cas de la convergence d‚Äôune suite se donner une norme sur $\\mathbb{R}^n$ va nous permettre de transposer les notons de continuit√© d‚Äôune fonction ou de comparaison de fonctions en un point $(o, \\theta, \\text{~} )$ Exercice :On se donne une norme $\\Vert .\\Vert $ sur$\\mathbb R^n$.continuite): Soit $f:(E, \\Vert .\\Vert _E)\\rightarrow (F, \\Vert .\\Vert _F)$on dit que f est continue en $a \\in E$ si $f$ est d√©fini au voisinage de $a$ \\(\\forall \\varepsilon &amp;gt; 0, \\exists \\mu &amp;gt; 0 tq\\Vert x-a\\Vert &amp;lt; \\mu \\Rightarrow \\Vert f(x) - f(a)\\Vert &amp;lt; \\varepsilon\\) $(\\theta)$ Une fonction f est un $\\theta_1(g)$ en a $\\in$ E s‚Äôil existe $\\varepsilon$ :(E,$\\Vert \\cdot\\Vert _E$) $\\rightarrow \\mathbb R$ telle que $f=\\varepsilon g$ $\\varepsilon \\xrightarrow[a]{} 0$ Quand g n‚Äôest pas identiquement nulle au voisinage de a, la condition pr√©c√©dente est √©quivalente √† $\\frac{\\Vert f\\Vert _F}{\\Vert g\\Vert _F} \\xrightarrow[a]{} 0$Il semble √† ce stade que la d√©finition de continuit√© ou celle de convergence d√©pende de la norme choisie. D√©finition :Les normes $\\Vert \\cdot\\Vert_\\alpha$ et $\\Vert \\cdot\\Vert_\\beta$ sur $\\mathbb{R}^n$ sont dites √©quivalentes s‚Äôil existe $c, C \\in \\mathbb{R}_+^{*}$ telle que\\(\\forall x \\in \\mathbb{R}^n, c\\Vert x\\Vert _\\alpha \\leqslant \\Vert x\\Vert _\\beta \\leqslant C\\Vert x\\Vert _\\alpha\\)Si 2 normes sont √©quivalentes alors elles d√©finissent les m√™mes fonctions continues, les m√™mes o, $\\theta$, ~ ou encore les m√™mes suites convergentes. Th√©or√®me :Sur $\\mathbb R^n$ toutes les normes sont √©quivalentes.Normes sur $\\mathbb R^n$ Les normes usuelles: \\[\\Vert .\\Vert _2 : \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _2 = (\\sum_{x=1}^n x_i^2)^{\\frac 12}=\\sqrt{x^Tx}\\] \\[\\Vert .\\Vert _1: \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _1 = \\sum_{i=1}^n\\vert x_i\\vert\\] \\[\\Vert .\\Vert _\\infty: \\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _\\infty = \\underset{i \\in \\{1,\\dots,n\\}}{max} \\vert X_i\\vert\\] Propri√©t√©:\\(\\forall p \\geq 1:\\\\\\forall x \\in \\mathbb R^n ; \\Vert x\\Vert _p = (\\sum(x_i)^p)^{\\frac 1p}\\)√Ä partir d‚Äôune norme, on d√©finit : Une distance : $d_{\\Vert .\\Vert }$(x,y) = \\Vert x-y\\Vert $ Des boules : Ouvertes : $B_{\\Vert .\\Vert }(x, \\varepsilon) = {y\\vert d_{\\Vert .\\Vert }(x,y) &amp;lt; \\varepsilon}$ Ferm√©es : \\(\\bar{B}_{\\Vert .\\Vert }(x, \\varepsilon) = \\{y\\vert d_{\\Vert .\\Vert }(x,y) \\leq \\varepsilon\\}\\) Objectif : Montrer que les boules ouvertes pour une norme $\\Vert .\\Vert $ sur $\\mathbb R^n$ sont convexes. D√©finition :Une fonction $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ est dite convexe si\\(\\forall x, y \\in \\mathbb{R}^n, \\forall t \\in [0, 1]; \\\\f(tx + (1 - t)y) \\le tf(x)+(1-t)f(y)\\) L‚Äôin√©galit√© de convexit√© se traduit g√©om√©triquement par le fait que les secantes entre deux points du graphe de $f$ sont au-dessus de salves prises par $f$ entre les abscisses de ces points. Soient $f: (\\mathbb R^2, \\Vert .\\Vert ) \\rightarrow (\\mathbb R, \\Vert .\\Vert )$ et $(0,0) \\in \\mathbb R^2$ $f$ est continue en $(0,0) \\in \\mathbb R^2$ si $\\forall \\varepsilon &amp;gt; 0, \\exists ~ q &amp;gt; 0, \\quad \\Vert (x,y)\\Vert &amp;lt; q \\implies \\Vert f(x,y)-f(0,0)\\Vert &amp;lt; \\varepsilon$ Diff√©rentiabilit√© et diff√©rentiellePour rappel on avait conclu √† la s√©ance pr√©c√©dente qu‚Äôil nous fallait √©tendre la notion de d√©riv√©e d‚Äôune fonction num√©rique au cas des fonctions √† plusieurs variables.On se donne une $f: \\mathbb R \\rightarrow \\mathbb R$ au voisinage $a \\in \\mathbb R$Dire que $f$ est derivable en $a \\in \\mathbb R$ c‚Äôest a dire que la limite:$lim_{h \\rightarrow 0, h \\ne 0} \\frac{f(a +h) - f(a)}{h} \\quad (D)$ existe ; c√†d est un nombre r√©√©l $l\\in\\mathbb{R}$L‚Äôobjectif est d√©tendre la notion de d√©rivabili√© au cas d‚Äôune fonction : $g: \\mathbb R^n \\mapsto \\mathbb R^m (n&amp;gt;1)$ en $a\\in\\mathbb{R}^n$ On ne peut pas faire : $\\frac{g(a+h)-g(a)}{\\underbrace{h}_{\\text{Un vecteur}}}$Diviser par un vecteur n‚Äôa pas de sens‚Ä¶L‚Äôapproche $(D)$ n‚Äôest pas celle qui s‚Äô√©tend le plus facilement vers le cas multivari√©. On doit voir les choses autrement.Si $f$ est derivable en $a$:$f(a +h) = \\boxed{f(a)} + \\underbrace{f‚Äô(a)h}_{*} + \\boxed{o_0(h)}$$*$ Est la partie lin√©aire de l‚Äôapproximation affine de $f$ en a; \\(\\begin{aligned}&amp;amp;h \\mapsto f&#39;(a).h\\\\ &amp;amp; \\mathbb R \\rightarrow \\mathbb R \\end{aligned}\\) Remarque: Caract√©riser les applications lin√©aires de $\\mathbb R$ dans lui-m√™me. Soit $\\mathcal L: \\mathbb R \\rightarrow \\mathbb R$ une application lin√©aire$\\forall x \\in \\mathbb R; \\mathcal L(x) = \\mathcal L(x.1) = x.\\mathcal L(1)$ Si $\\mathcal L$ est un endomorphisme de $\\mathbb R$ alors $\\mathcal L$ est de la forme $x \\mapsto \\lambda x; \\lambda \\in \\mathbb R$.Propri√©t√©: Soit $f: \\mathbb R \\rightarrow \\mathbb R$ une application d√©finie au voisinage de $a\\in\\mathbb R$, $f$ est d√©rivable en $a$ ssi il existe $\\lambda_a\\in\\mathcal{L}(\\mathbb{R,R})$ telle que $\\forall h \\text{ proche de } 0,\\;f(a +h) = f(a) + f‚Äô(a)h + o_0(h)$ $(**)$Preuve: $(\\Rightarrow)$: c‚Äôest ce que l‚Äôon vient de dire $(\\Leftarrow)$: On suppose qu‚Äôon a une √©criture du type $(**)$On regarde pour h assez proche de 0, $h \\neq 0$\\[\\begin{aligned}\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\frac{\\lambda_n(h) + o_0(h)}{h}\\\\&amp;amp;= \\frac 1h \\lambda_n(h) + \\frac 1h o_0(h)\\\\\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\lambda_a(1) + o_0 (1)\\\\\\Rightarrow \\underset{h \\rightarrow 0\\\\ h \\neq 0}{lim}\\frac {f(a+h) - f(a)}{h} &amp;amp;= \\lambda_a(1) \\in \\mathbb R\\end{aligned}\\]Donc $f$ est derivable en a et $f‚Äô(a)=\\lambda_a(1)$ D√©finition de la diff√©rentiabilit√©: On suppose $\\mathbb R^n, \\mathbb R^m$ munies de normes qu‚Äôon note indiff√©rentiablement $\\Vert \\cdot\\Vert $. Dans la suite les √©nonc√©s qu‚Äôon fait ne d√©pendent pas des normes choisies.On appelle ouvert de $\\mathbb{R}^n$ pour $\\Vert \\cdot\\Vert $ toute partie de $\\mathbb{R}^n$ qui contient des voisinages de chacun de ses points.Ex: $]a,b[ \\subset \\mathbb R$ $B_{\\Vert \\cdot\\Vert }(x,R); R &amp;gt; 0$D√©finition: Soit $f : u \\subset \\mathbb R^n \\rightarrow \\mathbb R^n$ une fonction d√©finie en $a \\in u$, $f$ est diff√©rentiable en $a$ s‚Äôil existe $\\lambda_u \\in \\mathcal L(\\mathbb R^n, \\mathbb R^n)$ telle que$\\forall h$ assez proche de $\\underline{0}$:$f(u+h)=f(a) + \\lambda_a(h) + o_\\underline{0}(h)$ $\\underline{0} = (0, ‚Ä¶, 0) \\in \\mathbb R^n$Propri√©t√©: Quand elle existe l‚Äôapplication lin√©aire $\\lambda a$ est unique.Preuve: Supposons qu‚Äôil existe pour h assez proche de 0,2 $\\lambda_n,\\mu_n \\in \\mathcal(\\mathbb R^n, \\mathbb R^m)$ telles que:$f(a+h) = f(a) + \\lambda_n(h) + o_\\underline{0}(h)$$= f(a) + \\mu_a(h) + o_\\underline{0}(h)$$\\forall h$ assez proche de $\\underline{0}$:$(\\lambda_a - \\mu_a)(h) = o_\\underline{0}(h)$Soit $v_1, \\ldots ,v_n$ une base de $\\mathbb R^n$.Pour $t$ au voisinage de $0 \\in \\mathbb R; t \\ne 0$$\\forall i \\in {1,\\ldots, n}$$(\\lambda_a - \\mu_a)(tv_1) = o_\\underline{0}(t\\overbrace{n}^{\\in \\mathbb R^n})$D‚Äôou $(\\frac{\\lambda_a - \\mu_a)(tv_1)}{t} = o_\\underline{0}(v)$$\\Leftrightarrow (\\lambda_a -\\mu_a)(v_i) = o_\\underline{0}(v)$$\\Rightarrow (\\lambda_a -\\mu_a)(v_i) = 0 \\qquad t \\rightarrow 0$Comme $\\lambda_a - \\mu_a$ est une application lin√©aire nulle sur tout √©l√©ment de la base $v_1,\\ldots,v_n$ elle est nulle. Donc $\\lambda_a = \\mu_a$.Definition: Soit $f: u \\rightarrow \\mathbb R^n$ definie sur un ouvert $u \\subset \\mathbb R^n$ Si $f$ est diff√©rentiable, l‚Äôunique application lineaire $Df(u) \\in \\mathcal L (\\mathbb R^n, \\mathbb R^n)$, telle que pour h assez proche de \\underline{0}.$f(a+h) = f(a) + Df(a)(h) + o_\\underline{0}(h)$$Df(a)$ est appel√©e dans le ce cas la diff√©√©√©rentielle de $f$ en $a$. Propri√©t√©: Si $f$ est diff√©rentiable en un point $a \\in u$ alors elle est continue en $a \\in u$ Propri√©t√©s: Soient $f,g$ 2 fonctions \\(\\begin{aligned}&amp;amp;u \\\\ &amp;amp;\\mathbb R^n \\rightarrow \\mathbb R\\end{aligned}\\) diff√©rentiables en $a \\in u$ alors $\\forall \\lambda \\in \\mathbb R, \\lambda f$ est diff√©rentiables en a et $D(\\lambda f(a)) = \\lambda Df(a)$ $f+g$ est diff√©rentiable en $a$ et $D(f+g)(a)=Df(a) + Dg(a)$ $\\langle f,g \\rangle$ est diff√©rentiable en a et $D(\\langle f, g\\rangle)(a) = \\langle f(a), Dg(a)\\rangle + \\langle Df(a), g(a) \\rangle$ Prop: Soient f, g des fonctions diff√©rentiables respectivement en $a$ et $b = f(a)$ Alors $g \\circ f$ est diff√©rentiable en a et $D(g \\circ f)(a) = Dg(f(n))\\circ Df(a)$$\\mathbb R^n \\overset{f}{\\longmapsto}\\mathbb R^m \\overset{g}{\\longmapsto}\\mathbb R^k$$a \\rightarrow f(a)$$\\mathbb R^n \\overset{Df(a)}{\\longmapsto}\\mathbb R^m \\overset{dg(f(a))}{\\longmapsto}\\mathbb R^k$ Ex:1) $\\mathbb R^n \\overset{f}{\\rightarrow} \\mathbb R$$X \\rightarrow \\langle X,X \\rangle = X^TX$ 2) $\\mathbb R^n \\overset{g}{\\rightarrow} \\mathbb R$$X \\rightarrow e^{X^TX}$ f(X + h) = (X + h)^T(X+h)$= (X^T +h^T)(X +h)$$f(X) = X^TX + h^TX + X^Th + h^Th$$\\mu_q h^Th = \\theta_\\underline{0}(h)$$h \\ne 0, \\frac{|h^Th|}{\\Vert h\\Vert _2} = \\frac{|h^Th|}{\\sqrt{h^Th}}$$= \\sqrt{hTh} = \\Vert h\\Vert _2 \\rightarrow 0; h \\rightarrow \\underline{0}$ Rappel normes, voir plus haut.$\\Vert x\\Vert _0 =$ # d‚Äôelements non nuls de x. (ce n‚Äôest pas une norme)In√©galit√© triangulaire invers√©e: $|: \\Vert x\\Vert -\\Vert y\\Vert : | \\le \\Vert x - y\\Vert $A partir d‚Äôune norme \\Vert .\\Vert on d√©finit la notion distance: $d: E \\times E \\rightarrow \\mathbb R^+$$(x,y) \\rightarrow \\langle x,y \\rangle$alors $\\sqrt{ \\langle x,x \\rangle}$ est une norme pour x.Voisinage de aBoule centr√©e en a et de rayon r.$\\rightarrow$‚ÄùTout ce qui se passe √† une $\\underbrace{\\text{distance}}_{\\text{besoin d‚Äôune norme}} r$ de $a \\in \\mathbb R^n$$\\rightarrow B_{\\Vert .\\Vert }(a,r) = {x \\in \\mathbb R, d(x,a) \\lt r}$Ceci est une boule ouverte$B_{\\Vert .\\Vert }(a,r) = {x \\in \\mathbb R^n, d(x,a) \\le r}$Ceci est une boule ferm√©e$\\overline{B_{\\Vert .\\Vert }} = B_{\\Vert .\\Vert } \\cup B_{\\Vert .\\Vert }$Les fonctions norme sont des fonctions convexes.\\(p = \\frac 12 \\qquad x = \\begin{pmatrix} x_1 \\\\ x_2\\end{pmatrix} \\qquad \\Vert x\\Vert _{\\frac12} = (\\sqrt{\\vert x_1\\vert } + \\sqrt{\\vert x_2\\vert })^2\\)\\(B_{\\Vert .\\Vert \\frac12}(0,1) = \\{(x_1,x_2) \\in \\mathbb R^2, (\\sqrt{\\vert x_1\\vert } + \\sqrt{\\vert x_2\\vert } \\le 1\\}\\)Dans le cadre ou $x_1 \\ge 0, x_2 \\ge 0$$(\\sqrt{x_1} + \\sqrt{x_2})^2 &amp;lt; 1$$\\sqrt{x_1} + \\sqrt{x_2} &amp;lt;1$$x_2 &amp;lt; (1 - \\sqrt{x_1})^2$$f:(\\mathbb R^n, \\Vert .\\Vert _{\\alpha} \\rightarrow (\\mathbb R^p, \\Vert .\\Vert _p)$$x = (x_1, ‚Ä¶, x_n) \\rightarrow (f_1(x_1,‚Ä¶,x_n),‚Ä¶f_p(x_1,‚Ä¶,x_n))$$a \\in \\mathbb R^n f$ est continue en $a \\in \\mathbb R^n$$\\forall \\varepsilon &amp;gt; 0, \\exists \\mu &amp;gt; 0, \\forall x \\in \\mathbb R^n, \\Vert x - a\\Vert _{\\alpha} &amp;lt; \\mu \\Rightarrow \\Vert f(x) - f(a)\\Vert _{\\beta} &amp;lt; \\varepsilon$Deux normes $\\Vert .\\Vert _\\alpha$ et $\\Vert .\\Vert _{\\beta}$ sont equivalentes ssi$\\exists c \\ge 0, C \\ge 0, \\forall x \\in E, c\\Vert x\\Vert _\\beta \\le \\Vert x\\Vert _\\alpha \\le C\\Vert x\\Vert _\\beta$dans un espace vectoriel de dimension finie, toutes les normes sont √©quivalentes.$x \\in \\mathbb R^n, x = \\begin{pmatrix} x_1 \\ .\\ .\\ .\\ x_n\\end{pmatrix}$\\(\\Vert x\\Vert_1 = \\sum_{i = 1}^n \\vert x_i\\vert \\qquad \\Vert x\\Vert _\\infty = max_{i = 1,...,n}\\vert x_i\\vert\\)‚Ä¶Fonction LipschitzienneUne fonction est dite Lipschitzienne ssi: $\\exists K &amp;gt; 0$ tq $\\Vert f(x) - f(y)\\Vert \\le K \\Vert x - y\\Vert $$\\forall x,y \\in D_y$Si f est Lipschitzienne, f est continue. $f: \\mathbb R^2 \\rightarrow \\mathbb R$$(x_1,x_2) \\rightarrow x_1 + x_2$$x = \\begin{pmatrix}x_1\\ x_2\\end{pmatrix} y = \\begin{pmatrix}y_1\\ y_2\\end{pmatrix}$$\\Vert x - y\\Vert = \\Vert \\begin{pmatrix}x_1 - y_1\\ x_2 - y_2\\end{pmatrix}\\Vert _1 = |x_1-y_1| + |x_2 - y_2|$$\\Vert f(x) - f(y)\\Vert _1 = \\Vert x_1 + x_2 - (y_1 +y_2)\\Vert _1$$= \\Vert (x_1 - y_1)+ (x_2 -y_2)\\Vert _1$$= |(x_1 - y_1) + (x_2 - y_2)|$$\\le|x_1 - y_1| + |x_2 - y_2|$L‚Äôensemble des fonctions continues est un espace vectoriel. Si f,g sont continues $\\lambda f + \\mu g$ est continue $\\forall(\\lambda,\\mu) \\in \\mathbb R^2 \\rightarrow$ structure d‚Äôespace vectoriel Si p =1, f*g est continue, $\\frac fg$ est continu partout ou g ne s‚Äôannule pas. Si $h:\\mathbb R^p \\rightarrow \\mathbb R^n$ qui est continue, alors $h\\circ f: \\mathbb R^n \\rightarrow \\mathbb R^n, x\\rightarrow h(f(x))$ est continue.Toutes les fonctions de type polynome sont continues.et $\\frac{f(x,y)}{g(x,y)}$ avec f et g polynomiales, est continue partout ou g ne s‚Äôannule pas. (fonction rationelle)$\\begin{cases} \\frac{xy}{x^2 +y^2} \\text{ si } (x,y) \\ne (0,0)0 \\text{ sinon}\\end{cases}$$f(x,0) = 0 \\rightarrow$ continu en 0$f(0,y) = 0 \\rightarrow$ continu en 0 exempleSoient $g:t \\rightarrow (t,t)$$f \\circ g(t) = f(g(t)) =f(t,t) = \\frac{t^2}{t^2 + t^2} = \\frac{t^2}{2t^2} = \\frac12$ si $t \\ne 0$ Donc $f \\circ g$ n‚Äôest pas continue. Exercice:1)$\\mathbb R \\overset{f}\\longmapsto \\mathbb R\\ X \\longmapsto X^T X$On cherche √† determiner la diffierenciablit√© de $f$ en tout point $a \\in \\mathbb{R}^n$\\(\\begin{aligned}f(a+h)&amp;amp;=(a+h)^T(a+h) \\\\ &amp;amp;=a^Ta+h^Ta+a^Th+h^Th \\\\ &amp;amp;=f(a)+\\underbrace{2a^Th}_{h \\rightarrow 2a^Th \\\\\\text{ est lin√©aire}}+h^Th\\end{aligned}\\)$\\Vert h\\Vert _2^2=\\Vert h\\Vert _2\\Vert h\\Vert _2=\\Vert h\\Vert \\varepsilon(h)$On a $f(a+h)=f(a)+\\text{ lim en h }+o_0(h)$. $f$ est diff√©rentiable en a et $\\Delta f(a)h=2a^Th$2)$\\mathbb R^n$ $\\overset{g}{\\rightarrow} \\mathbb R$$X \\rightarrow e^{X^TX}$$g: \\mathbb R^n \\overset{f}{\\rightarrow} \\mathbb R \\overset{exp}{\\rightarrow} \\mathbb R$$X \\rightarrow X^TX \\rightarrow e^{X^TX}$On s‚Äôint√©resse √† la diff√©renciabilit√© de g en $a\\in\\mathbb{R}^n$. La fonction g est compos√©e de fonctions diff√©rentiables, elle est donc diff√©rentiable en tout point.En $a \\in \\mathbb{R}^n, \\Delta g(a‚Äô)h=\\Delta \\exp (a^Ta)(\\Delta f(a)f(h))$Dans le cours: $\\Delta g(a)=\\Delta(exp\\circ f)(a)=\\Delta \\exp (f(a))\\circ \\Delta f(a)$\\(\\forall h \\in \\mathbb{R}^n, \\Delta g(a)(h)=\\Delta \\exp (a^Ta)(\\underbrace{\\Delta f(a)f(h)}_{\\in \\mathbb{R}})\\) $\\Delta f(a)(h)=2aTh \\qquad h \\in \\mathbb R$ $\\Delta exp(y)(k) = exp‚Äô(y)\\cdot k = e^yk$$\\implies \\Delta g(a)(h) = e^{a^Ta} \\times 2a^Th \\qquad h \\in \\mathbb R^n\\space a^T \\in \\mathbb R^n, e^{a^Ta} \\in \\mathbb R$ Gradient et d√©riv√©es partiellesSoit $f:U \\underline{\\subset} \\mathbb R^n \\rightarrow \\mathbb{R}^m$ une application diff√©rentiable en $a \\in U$. On peut donc √©crire, pour h assez proche de 0:$f(a+ h) = f(a) + Df(a)(h) + \\underset{l \\rightarrow 0}{o_0(h)}$$(f(a+h) = f(a) + \\Delta f(a)f(h) + \\Vert h\\Vert \\varepsilon(h))$L‚Äôapplication $\\Delta f(a)\\in \\mathscr{L}(\\mathbb{R}^n, \\mathbb{R}^m)$ o√π $\\mathscr{L}(\\mathbb{R}^n,\\mathbb{R}^m)$ est l‚Äôensemble des applications lin√©aires de $\\mathbb{R}^n$ dans $\\mathbb{R}^m$, est caract√©ris√©e par sa matrice dans des bases donn√©es. D√©finition:On appelle jacobienne de $f$ en $a \\in U$ la matrice de $Df(a)$ dans les bases canoniques de $\\mathbb{R}^n$ et $\\mathbb{R}^m$ Dans cette section,on √©tudie comment trouver les coefficients de la matrice jacobienne de $f$ en $a$Notation:La jacobienne de $f$ en $a$ s‚Äô√©crit $\\mathcal J_f(a) \\in M_{m,n}(\\mathbb{R})$On a $f(a+ h) = f(a) + \\mathcal J_f(a) \\cdot h + o_0(h)$On se pose en premier temps la question de savoir comment d√©terminer les lignes, puis en un second temps, les colonnes.$\\color{purple}{\\text{Pour les lignes}}$On √©crit $f = (f_1, -, f_m)$o√π $f_i:u \\rightarrow \\mathbb R$ est la composante de $f$ suivant la $i_{eme}$ coordonn√©e.Exemple:$\\mathbb R^3 \\overset{f}{\\rightarrow} \\mathbb R^4$$\\begin{pmatrix}x \\ y \\ z \\end{pmatrix} \\rightarrow \\begin{pmatrix}xy^2 \\ x+y+z \\ xyz \\ z\\end{pmatrix}$En notant,$f_1\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = xy^2$$f_2\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = x+y+z$$f_3\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = xyz$$f_4\\bigg(\\overset{x}{\\underset{z}{y}}\\bigg) = z$on a $f = (f_1, f_2, f_3, f_4)$En $a \\in U$, on a pour chaque $f$:$f_1(a+h) = f_i(a) + \\mathcal J_{f_i}(a)h + \\Vert h\\Vert \\varepsilon(h)$On peut donc √©crire:\\[\\begin{aligned}f(a+h) &amp;amp;= \\begin{pmatrix} f_1(a+h) \\\\ \\vdots \\\\ f_m(a+h) \\end{pmatrix} \\\\ &amp;amp;=\\begin{pmatrix} f_1(a) + \\mathcal J_{f_1}(a)h + \\Vert h\\Vert \\varepsilon (h)\\\\ \\vdots \\\\ f_m(a) + \\mathcal J_{f_m}(a)h + \\Vert h\\Vert \\varepsilon (h) \\end{pmatrix} \\\\ &amp;amp;= \\begin{pmatrix} f_1(a) \\\\ \\vdots \\\\f_m(a)\\end{pmatrix} + \\begin{pmatrix} \\mathcal J_{f_1}(a)h \\\\ \\vdots \\\\\\mathcal J_{f_m}(a)h\\end{pmatrix} + \\Vert |\\varepsilon(h) \\\\&amp;amp;= f(a) + \\begin{pmatrix} \\mathcal J_{f_1}(n) \\\\ \\vdots \\\\ \\mathcal J_{f_m}(n)\\end{pmatrix}h + \\Vert h\\Vert \\varepsilon(h)\\end{aligned}\\]$(\\mathcal J_{f_i}(n) \\in \\mathbb M_{m,n}(\\mathbb R))$‚Äù$\\varepsilon(h)$‚Äù est une quantit√© n√©gligeable sous forme de vecteurPar unicit√© de la diff√©rentielle, on a : $\\mathcal J_f(a) = \\begin{pmatrix} \\mathcal J_{f_1}(a) \\ \\vdots \\ \\mathcal J_{f_m}(a)\\end{pmatrix}$Autrement dit, $\\mathcal{J}f(a)$ est la concat√©nation des $\\mathcal{J}{f_i}(a)$ verticalement (en colonnes).$\\color{purple}{\\text{Pour les colonnes}}$Il nous reste √† comprendre comment constuire la jacobienne en un point d‚Äôune fonction de $\\mathbb{R}^n$ dans $\\mathbb{R}$.Soit $g:U\\subset\\mathbb{R}^n\\longmapsto \\mathbb{R}$ une fonction diff√©rentiable en $a\\in U$.Pour h assez proche de $\\underline{0}$, $g(a+h)+g(a)+\\mathcal{\\mathcal J}_{g}h+\\Vert h\\Vert \\varepsilon(h)$Soit $v\\in \\mathbb{R}^n$ et $t\\in \\mathbb{R}$, pour t assez proche de 0, \\(g(a+tv)=g(a)+\\mathcal{J}_g(a)tv+\\Vert tv\\Vert \\varepsilon(tv)\\)\\(g(a+tv)=g(a)+t\\mathcal{J}_g(a)v+\\Vert tv\\Vert \\varepsilon(tv)\\)Si $t \\neq 0$:\\(\\frac{g(a+tv)-g(a)}{t}=\\mathcal{J}_g(a)v+\\varepsilon(tv)\\)Quand $t\\longmapsto 0$ on a\\(\\mathcal{J}_g(a)v=\\displaystyle\\lim_{t\\rightarrow0}\\frac{g(a+tv)-g(a)}{t}\\)La valeur de la $\\mathcal{J}_g(a)$ en un vecteur v est d√©crite par la d√©riv√©e de la direction de g √† la droite a+tv.$g_v:t \\rightarrow g(a +tv)$$\\mathbb R : \\frac{g(a + tv)-g(a)}{t} = \\frac{g_v(t) - g_v(0)}{t}$ D√©finition:On appelle d√©riv√©e directionelle de g en a le long de v, la limite, quand elle existe, \\(\\partial_v(g(a))=\\lim_{t\\rightarrow0}\\frac{g(a+tv)-g(a)}{t}\\)Notation:Dans le cas v, c‚Äôest un vecteur de la base canonique, $v=ej$ on note\\(\\partial_{e_j}g(a)=\\frac{\\partial g}{\\partial x_j}(a)\\) Remarque:On vient de voir que si $g$ est diff√©rentiable en $a$ alors $g$ admet des d√©riv√©es directionnelles en $a$ le long de tout vecteur. La r√©ciproque est fausse.On peut avoir des directionnelles en tout point mais ne pas √™tre diff√©rentiable.\\[\\begin{cases} \\frac{x^2 y}{x^4 + x^2} &amp;amp; \\text{si} (x, y) \\neq (0, 0) \\\\ 0 \\qquad &amp;amp; \\text{sinon}\\end{cases}\\] Propri√©t√©: Si les d√©riv√©es partielles de g sont des fonctions continues alors g est diff√©rentiable en tout point de fonction diff√©rentielle $x \\longmapsto Df(x)$ continue. D√©sormais si g est diff√©rentiable en un point a alors\\(\\mathcal Jg(a) = (\\underbrace{\\frac{\\delta g(a)}{\\delta x_1}}_{\\mathcal Jg(a)e_1} \\dots \\underbrace{\\frac{\\delta g(a)}{\\delta x_n}}_{\\mathcal Jg(a)e_n})\\) Pour h assez proche de 0\\(g(a+h) = g(a) + \\underbrace{\\mathcal J_g(a)h}_{\\mathcal M_{1,n}(\\mathbb R)} + \\Vert h\\Vert \\varepsilon(h)\\) D√©finition: [gradient]On appelle gradient de g en a\\(\\nabla g(a)=\\mathcal{J}_g(a)^T\\)On lit $\\nabla$ ‚Äúnabla‚Äù Ex:Calculer:1) $\\nabla g(x,y)$ pour $\\mathbb R^2 \\rightarrow \\mathbb R$$(x,y) \\rightarrow xy^2 + y$2) $\\mathcal J_f(x,y)$ pour$\\mathbb R^2 \\rightarrow \\mathbb R^3$$(x,y) \\rightarrow (xy, y^2, \\sin(xy))$ 1) $\\frac{\\partial g (x,y)}{\\partial x} = y^2$ $\\frac{\\partial g (x,y)}{\\partial y} = 2yx + 1$$\\Rightarrow \\nabla g(x,y) = \\begin{pmatrix}y^2 \\ 2yx + 1\\end{pmatrix}$ 2)$\\mathcal Jf(x, y)= \\begin{pmatrix}y &amp;amp; x \\ ycos(xy) &amp;amp; xcos(xy)\\end{pmatrix}$ " }, { "title": "PRST: Feuille 4 - Exercices", "url": "/cours/posts/prst_feuille_4/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, intervalle, confiance", "date": "2021-03-22 11:00:00 +0100", "snippet": "Lien de la note HackmdExercice de coursProposer un intervalle de confiance asymptotique au niveau $0,90$ pour la moyenne $m$ d‚Äôune variable al√©atoire. Solution Astuce: mettre $0,05$ de chaque cote de la courbe, on cherche donc $95\\%$ sur notre table de loi normale centree reduite On a donc $1,96$ dans la table. Cf. cours.Exercice de coursFran√ßois pr√©l√®ve 300 serpents dans une for√™t et constate que 70 d‚Äôentre eux sont venimeux.D√©terminer un intervalle de confiance asymptotique pour la proportion de serpents venimeux dans cette for√™t au niveau de confiance 0, 95. Solution $\\hat p = \\frac{70}{300}\\simeq0,23, n = 300$ Conditions d‚Äôapplications du resultat: $n\\ge 30$ $n\\hat p \\ge5$ $n(1-p)\\ge5$ \\[\\hat p -1,96\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\simeq 0,18\\\\\\hat p +1,96\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\simeq 0,28\\] On a donc $[0,18;0,28]$Exercice 1Proposer un intervalle de confiance au niveau $0,90$ pour la moyenne $m$ pour une variable aleatoire gaussienne de variance $2$ dont nous connaissons les observations suivantes : $3,1 ; 2,4 ; 5 ; 7$ et $2,8$. Solution \\[\\sigma = 2\\\\V(X) = \\sqrt 2\\\\\\bar X_n \\simeq 4,06\\\\\\] On obtient $[3,023;5,09]$ Exercice 6 Soit $U_n$ une variable aleatoire suivant une loi $\\mathcal X^2(n)$, $(n\\ge1)$. Admettons que $\\phi_{U_n}(t)=\\frac{1}{(1-2it)^{\\frac{n}{2}}}$ est sa fonction caracteristique. (a) Montrer que $E(U_n)=n$ (b) Montrer que $V(U_n)=2n$ Soient $X$ et $Y$ deux variables aleatoires independantes suivant respectivement des lois $\\mathcal X^2(m)$ et $\\mathcal X^2(n)$. Montrer que la variable aleatoire $X+Y$ suit une loi $\\mathcal X^2(m+n)$ Solution\\[E(X) = \\frac{\\phi&#39;(0)}{i} \\text{(cf chapitre 1 complement)}\\\\\\phi_{U_n}&#39;(t)= \\frac{ni}{(1-2it)^{\\frac{n}{2}+1}}\\\\E(X) = \\frac{\\phi_{U_n}&#39;}{i}=n\\\\\\] \\((\\frac{1}{u^n})&#39;=-\\frac{ku&#39;}{u^{k+1}}\\) \\[\\phi_{U_n}&#39;&#39;(t)=\\frac{-(n+2)n}{(1+2it)^{\\frac{n}{2}+2}}\\\\E(X^2)=-\\phi^{(2)}(0) = n(n+2)\\\\V(X) = E(X^2)-E(X)^2=n(n+2-n)=2n\\] $X\\sim\\mathcal X^2(m)$, $Y\\sim\\mathcal X^2(n)$\\[\\begin{aligned}\\phi_{X+Y}&amp;amp;=\\phi_X(t)\\phi_Y(t)\\\\&amp;amp;= \\frac{1}{(1-2it)^{\\frac{m}{2}}}\\times\\frac{1}{(1-2it)^{\\frac{n}{2}}}\\\\&amp;amp;=\\frac{1}{(1-2it)^{\\frac{m+n}{2}}} \\text{ , cqfd.}\\end{aligned}\\]" }, { "title": "PRST: Seance 4 - Intervalle de confiance", "url": "/cours/posts/prst_seance_4/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, Student, Khi-deux, intervalle, confiance", "date": "2021-03-22 10:00:00 +0100", "snippet": "Lien de la note Hackmd Il y a 2 types d‚Äôestimation: estimation ponctuelle (les estimateurs) estimation par intervalle Deux resultats probabilistes: loi forte des grand nombre theoreme central limiteIntervalle de confiance pour la moyenne $m$Point de depart $(X_1,‚Ä¶, X_n)$ echantillon i.i.d de taille $n$ $(x_1,‚Ä¶,x_n)$ r√©alisations de cet √©chantillon $\\bar x_n = \\frac{1}{n}\\sum_{i=1}^nx_i$ estimation ponctuelle de la moyenne (esp√©rance) $m$ $S_n^2=\\frac{1}{1-n}\\sum_{i=1}^n(x_i-\\bar x_n)^2$ estimation ponctuelle de la variance $\\sigma^2$ Dans la majorite des cas, on ne connait pas la loi de probabilite d‚Äôun experience aleatoireDans le modele de Bernoulli avec un echantillon i.i.d de la $\\mathcal B$, un intervalle de confiance au niveau $0,95$ est:\\[[f-\\frac{1}{\\sqrt{n}};f+\\frac{1}{\\sqrt{n}}]\\]C‚Äôest un encadrement de la valeur reelle de $p$ TheroemeLa proportion $p$ appartient a cet intervalle, pour $95\\%$ des echantillons, sous les conditions: $n\\ge30$ $nf\\ge5$ $n(1-f)\\ge5$ Deux cas: $n$ quelconque: v.a. normales $n$ grand et utilisation du TCLTheoreme central limiteSoit $(X_i)$ une suite de v.a. i.i.d telle que $E(X_1^2)\\le+\\infty$. Noton $m:=E(X_i)$ et $\\theta^2=V(X_i)$\\[\\frac{\\sqrt{n}(\\bar X_n-m)}{\\theta}\\]converge en loi vers une loi normale centr√©e r√©duiteLoi normale centree reduite $\\mathcal P(X\\le0)=P(X\\ge0)=0,5$ $\\mathcal P(X\\le a)=\\mathcal P(X\\ge a)$ $\\mathcal P(-1,96\\le X\\le1,96)\\simeq 0,95$ et $\\mathcal P(-2,58\\le X\\le2,58)\\simeq 0,99$\\[m\\in\\biggr[\\bar X_n-1,96\\frac{\\sigma}{\\sqrt n};\\bar X_n+1,96\\frac{\\sigma}{\\sqrt n}\\biggr]\\]au niveau de confiance $0,95$Cas gaussien$X_1$ suit une loi normal, $\\forall n\\ge 1$, $\\frac{\\sqrt n(\\bar X_n-m)}{\\sigma}$ suit une loi normale centree reduite et\\[\\mathbb P(-1,96\\le \\frac{\\sqrt n(\\bar X_n-m)}{\\sigma}\\le1,96)\\simeq 0,95\\]Cas general\\[m\\in\\biggr[\\bar X_n-1,96\\frac{\\sigma}{\\sqrt n};\\bar X_n+1,96\\frac{\\sigma}{\\sqrt n}\\biggr]\\]au niveau de confiance $0,95$ La forme generale de l‚Äôintervalle de confiance asymptotique general pour $1-\\alpha$ pour la moyenne $m$ est :\\[\\biggr[\\bar X_n-z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt n};\\bar X_n+z_{1-\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt n}\\biggr]\\] Avec: $z_{1-\\frac{\\alpha}{2}}$: fractile d‚Äôordre $1-\\frac{\\alpha}{2}$ de la loi $\\mathcal N(0,1)$ Cas particulier du modele de Bernoulli Intervalle de confiance pour la proportion d‚Äôun echantillon dans une population donnee variance inconnue approximation pour la loi normale possible grace au theoreme suivant: Theoreme de Moivre-Laplace$X_n$ v.a $\\sim\\mathcal B(n,p)$. Soit $q:=1-p$\\[\\forall x\\in\\mathbb R\\\\\\lim_{n\\to+\\infty}\\mathbb P(\\frac{X-n-np}{\\sqrt{npq}}\\le x)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^xe^{-\\frac{t^2}{2}}dt=F(X)\\]Intervalle de confiance de la proportion $p$ L‚Äôintervalle de confiance asymptotique au niveau $1-\\alpha$ pour la proportion $p$ est:\\[\\biggr[\\hat p - z_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}; \\hat p + z_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{\\hat p(1-\\hat p)}}{\\sqrt n}\\biggr]\\]Loi du Khi-deux$(X_1,‚Ä¶,X_n)$ $n$ v.a. independantes normales centrees reduite. La v.a. $U_n:=\\sum_{i=1}^nx_i^2$ suit une loi du Khi-deix a $n$ degres de liberte notee $\\mathcal X^2(n)$ $f_{U_n}=\\frac{1}{2^{\\frac{n}{2}}}e^{-\\frac{x}{2}}x^{\\frac{x}{2} - 1}$ pour $x\\ge 0$ $E(U_n) = n$ $V(U_n) = 2n$ $\\phi_{U_n}(t)=\\frac{1}{(1-2it)^{\\frac{n}{2}}}$ Theoreme$X$ et $Y$ deux v.a. independantes suivant respectivement $\\mathcal X^2(m)$ et $\\mathcal X^2(n)$ alors la v.a $X+Y$ suit une loi $\\mathcal X^2(m+n)$Loi de Student$X$ et $Y$ deux v.a aleatoires independantes suivant les lois $\\mathcal N(0,1)$ et $\\mathcal X^2(n)$.\\[T_n=\\frac{X}{\\sqrt{\\frac{Y}{n}}}\\]suit une loi de Student $\\mathcal T_n$ a $n$ degre de libertePropriete $E(T_n) = 0$ (symetrie) $V(T_n)=\\frac{n}{n-2}$ pour $n\\gt2$ Theoreme$T_n$ converge en loi vers $\\mathcal N(0,1)$ lorsque $n$ tend vers $+\\infty$.Cas gaussien $X_1$ suit une loi normale $Tn:=\\frac{\\sqrt n(\\bar X_n-m)}{\\sqrt{S_n^2}}$ suit une loi de Student a $n-1$ degr√©s de libert√©. L‚Äôintervall de confiance au niveau $1-\\alpha$ pour la moyenne $m$ est:\\[\\biggr[\\bar X_n-t_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{S_n^2}}{\\sqrt n};\\bar X_n+t_{1-\\frac{\\alpha}{2}}\\frac{\\sqrt{S_n^2}}{\\sqrt n}\\biggr]\\] Avec: $t_{1-\\frac{\\alpha}{2}}$ fractile d‚Äôordre $1-\\frac{\\alpha}{2}$ de la loi de Student $n-1$ degr√©s de libert√©. " }, { "title": "IML: Dimensionality reduction", "url": "/cours/posts/iml_dimensionality_reduction/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8, principal component analysis", "date": "2021-03-19 13:00:00 +0100", "snippet": "Lien de la note HackmdWhy do we care ?We have at hand $n$ points $x1,‚Ä¶, xn$ lying in some N-dimensional space, $x_i \\in\\mathbb R^n , \\forall i = 1, . . . , n,$ compactly written as a $n √ó N$ matrix $X$ One row of $X$ = one sample One column of $X$ = a given feature value for all samplesExample of real high-dimensional data Real world data is very often high-dimensionalMNIST image classification: Sample $x$:image with 28x28 pixels Data set: 60000 samples Dimensionality: $x \\in\\mathbb R^{28√ó28=784}$MUSE hyperspectral image analysis: Sample $x$: pixel with 3600 spectral bands Data set: image with 300x300 pixels Dimensionality: $x \\in \\mathbb R^{3600}$ Pour discriminer les galaxies c‚Äôest raciste ca monsieurThe curse of dimensionality High-dimensional spaces suck donkey ballz suffer from the curse of dimensionality (also called Hughes‚Äô phenomenon)Sur $\\mathbb R$Sur $\\mathbb R^2$Revenir a la meme densite d‚Äôechantillonage:Sur $\\mathbb R^3$Revenir a la meme densite d‚Äôechantillonage:\\[\\frac{\\nu(\\mathbb S^n)}{\\nu([-1;1]^n)}=\\frac{\\pi^{\\frac{n}{2}}}{2\\Gamma(\\frac{n}{2}+1)}\\to_{n\\to+\\infty}0\\] Points uniformly distributed in a $n$‚àícube of side 2 mostly fall outside of the unit sphere! Why is it tricky? We naturally cannot picture anything that is more than 3D in our mind Picturing something 3D in a 2D flat screen can already be misleading Real data naturally lives in (complex) high-dimensional space Real data is often strongly correlated And somehow, we want to have a good look to our data before feeding it to some machine learning algorithm (can I use the inherent structure of my data to pimp my machine learning performances?)How ? Dimensionality reduction: transform data set $X$ with dimensionality $N$ into a new data set $Y$ ($n \\times M$ matrix) with dimensionality $M \\lt N$ (hopefully $M \\lt\\le N$) such that as few information as possible is lost in the process. $y_i$ ($i$th row of $Y$) is the low-dimensional counterpart (the projection) of $x_i$.INFORMATION ???Linear approachesSomehow trying to find a low-dimensional subspace in which the projected data would not be too much distorted after projection. Johnson-Lindenstrauss lemma Classical scaling (The one and only) Principal Component Analysis And much more‚Ä¶Johnson-Lindenstrauss lemmaIt‚Äôs not because you can that you will Let $0\\lt\\varepsilon\\lt1$ and let $x_1,‚Ä¶,x_n$ be $n$ points in $\\mathbb R^N$. Then there exists a linear map $f:\\mathbb R^N\\to\\mathbb R^M$ such that for every points $x_i$ and $x_j$\\[(1-\\varepsilon)\\Vert x_i-x_j \\Vert^2\\le \\Vert f(x_i)-f(x_j) \\Vert^2\\le(1+\\varepsilon)\\Vert x_i-x_j \\Vert^2\\] With $M=\\frac{4\\log(n)}{(\\frac{\\varepsilon^2}{2} ‚àí \\frac{\\varepsilon^3}{3}).}$ Johnson, W. B., &amp;amp; Lindenstrauss, J. (1984). Extensions of Lipschitz mappings into a Hilbert space. Contemporary mathematics. La douille: il faut trouver la matrice $M$.Classical scalingAlso called Principal Coordinates Analysis (PCoA) Lots of formula here, but you just need to retain the overall idea PCoA: project data points $X$ onto $Y$ with a linear mapping $M$ such that $Y = XM$ such that all pairwise distances between points do not change too much before/after projectionIf $D$ is the $n \\times n$ Euclidean distance matrix with entries $d_{ij} = \\Vert x_i ‚àí xj\\Vert_2$ and $D^{(2)} = [d_{ij}^2]$, PCoA seeks the linear mapping $M$ that minimizes\\[\\phi(Y)=\\sum_{i,j}(d_{ij}^2-\\Vert y_i-y_j\\Vert^2)\\]with $y_i = x_iM$ and $\\Vert m_i\\Vert^2=1\\forall i$ Solution: eigendecomposition (=diagonalisation) of the Gram matrix $K = XX^T = E\\Delta E$$K$ can be obtained by double centering $D^{(2)}:K=-\\frac{1}{2}C_nD^{(2)}C_n$ with centering matrix $C_n=I_n-\\frac{1}{n}ones(n,n)$Optimal projection onto the first $M$ dimensions $Y=\\Delta_M^{\\frac{1}{2}}E_M^T$ with $E_M$ matrix of the $M$ largest eigenvectors of $E$.Principal component analysis Also known as the Karhunen-Loeve transformClosely related to PCoA, but operates on the covariance matrix $X_c^T X_c$ PCA seeks the linear mapping $M$ that maximizes the projection variance $tr(M^T cov(X)M)$ with $\\Vert mi\\Vert^2 = 1 \\forall i$.\\[X=\\begin{bmatrix}\\overbrace{x_{11}}^{u_1=\\text{moyenne}} &amp;amp; \\overbrace{x_{12}}^{u_2}\\\\\\vdots &amp;amp; \\vdots\\\\x_{n1}&amp;amp;x_{n2}\\end{bmatrix} \\Rightarrow \\text{centrage des donnees}\\]\\[X_c=\\begin{bmatrix}x_{11}-u_1 &amp;amp; x_{12}-u_2\\\\\\vdots &amp;amp; \\vdots\\\\x_{n1}1-u_1&amp;amp;x_{n2}-u_2\\end{bmatrix}\\] Center the data $X_c = C_nX$ 1.b (opt) Reduce the data Compute covariance matrix $\\sum=\\frac{1}{n-1}X_c^TX_c$ Perform eigendecomposition $(E,\\Delta)$ of $\\sum$ Project on the first $M$ principal axes $Y=XE_M$Data after projection is uncorrelated, but haslost some interpretabilityMajor challenges related to PCAPCA is probably the most popular and used unsupervised linear dimensionality reduction technique, but it comes with a bunch of operability questions, the 2 principles being: How to automatically select the right number of dimensions to project? How to project a new data point on a learned projection subspace? See you in lab session for the answer Non-linear approachesWhen it is assumed that the data does not livein an Euclidean subspace (why would it anyway?),some more advanced techniques must be reliedon. Isomap Locally linear embedding Kernel Principal Component Analysis (aka PCA on steroids) Multilayer autoencoders And much more‚Ä¶Isomap Geodesic distance rocksIsometric feature mapping: same idea as classical scaling, but using geodesic distance instead of Euclidean distance. Compute k-nearest neighbor graph of data $x_1,‚Ä¶,x_n$ Compute all pairwise geodesic distances Apply classical scalingExempleIsomap applied to some images of the digit 2 in MNIST dataLocally linear embeddingLocally linear embedding: the manifold can be locally considered EuclideanFor each point $x_i$: get its k-nearest neighbors $x_j$, $j=1,‚Ä¶,k$ Get weights $w_{ij}$ that best linearly reconstruct $x_i$ with $x_j$: minimize $\\sum_{i=1}^n\\Vert x_i-\\sum w_{ij}x_j\\Vert$ with constraints $\\sum w_{ij}=1$ (closed-form solution) Low-dimensional embedding $\\to$ reconstruct $y_i$ with $y_j$ and same weights $w_{ij}$:minimize \\(\\sum_{i=1}^n\\Vert y_i-\\sum w_{ij}y_j\\Vert\\)with constraints $\\frac{1}{n}\\sum_iy_iy_i^T$ and $\\sum_iy_i=0$ (eigendecomposition of a Gram matrix)The kernel trick When one actually wants to increase the dimensionBase idea: map $n$ non linearly separable points to a (possibly infinite) space where they would be with a function $\\phi$ How should we define $\\phi$ ? Do we really want to compute stuff in a (possibly infinite) feature space? Mercer theorem: we do not need to know the mapping $\\phi$ explicitly as long as we have a positive semi-definite kernel/Gram matrix $K=[\\mathcal k(x_i,x_j)]=[&amp;lt;\\phi(x_i),\\phi(x_j)&amp;gt;]$Widely used kernel functions: Polynomial kernel: $\\mathcal k(x_i,x_j)=(x_i^Tx_j+1)^d$ Gaussian RBF kernel: $\\mathcal k(x_i,x_j)=e^{-\\gamma\\Vert x_i-x_j\\Vert^2}$ Sigmoid kernel: $\\mathcal k(x_i,x_j)=\\tanh(bx_i^Tx_j+c)$Kernel PCA PCA on steroidsThe maths behind are quite hard, but the following scikit-learn recipe works fine: Compute kernel matrix $k=[\\mathcal k(x_i,x_j)]=[&amp;lt;\\phi(x_i),\\phi(x_j)&amp;gt;]$ and double-center it $K_c=C_nKC_n$ Eigendecomposition of $K_c$ is strongly related to this of the (intractable) covariance matrix in the feature space $\\to$ get eigenvectors $V$ and corresponding eigenvalues $\\Delta$ of $K_c$. Keep the first $M$ columns of $\\sqrt{\\Delta V}$ to get the coordinates of projected data points in the low $M$-dimensional space. But things get nasty when one wants to project a new data point $x$ that was not known when constructing the kernel‚Ä¶Non-linear PCA Also known as autoencoderOverall idea: train an autoencoder (neural network with an autoassociative architecture) to perform an identity mapping. use the output of the bottleneck layer as low-dimensional code.Bottleneck code is a non-linear combination of entries (thanks to activation functions on the encoder layers) $\\to$ learned mapping is a non-linear PCA.Principal components are generalized from straight lines to curves: the projection subspace which is described by all nonlinear components is also curved.Let‚Äôs recapHigh-dimensional data set $X$ is a $n \\times N$ matrix, with $n =$ number of samples and $N =$ dimensionality of underlying space. Parametric $\\equiv$ explicit embedding from high-dimensional space to low-dimensional one For LLE: $p$ is the ratio of non-zero elements in a sparse matrix to the total number of elements For NL-PCA: $i$ is the number of iterations and w is the number of weights in the neural networkt-Distributed Stochastic Neighbor Embeddingt-SNE is a popular method to see in 2D or 3D wtf is going on in a high-dimensional spaces. Construct a probability distribution $p$ over pairs of points in the high-dim space: the more similar (the closer) the two points, the higher the probability Define a second probability distribution $q$ over the points in the low-dim space, and dispatch the points such that the distance between p and q in minimized (for the KullbackLeibler divergence) t-SNE is excellent in visualizing the well-separated clusters, but fails to preserve the global geometry of the data. t-SNE depends on a perplexity parameter, which reflects the scale of search for close points.Independant component analysisICA aims to provide a solution to the so-called cocktail party: retrieving independent sources that got mixed-up together with unknown scaling coefficients.Goal: estimate source $s$ and mixing matrix $A$ from observation $x = As$. Ill-posed $\\Rightarrow$ enforce independence on source components Work on higher order statistics (PCA limits to order-2 statistics) Unkown source must not be Gaussian-distributedContrarily to PCA vectors, ICA vectors are not orthogonal and not ranked by importance,but they are mutually independents." }, { "title": "OCVX: Parties de R et convexite", "url": "/cours/posts/ocvx_partie_r_convexite_/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-18 10:00:00 +0100", "snippet": "Lien de la note HackmdRappels de la seance precedente description des sous espaces affine de $\\mathbb R^n$ sous espaces vectoriels de $\\mathbb R^n$ $E\\subset\\mathbb R^n$ $0_{\\mathbb R^n}\\in E$ Sous espace affine $A=x_0+E$, $E$ sous espace vectoriel et $x\\in\\mathbb R^n$ Un sous-espace affine n‚Äôest pas un sous-espace vectoriel.Un sous-espace vectoriel est un sous-espace affine.\\[\\begin{aligned}(D) &amp;amp;= \\{x\\in\\mathbb R^n, X_0+\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= X_0+\\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\rightarrow\\text{description parametrique}\\end{aligned}\\]Description implicite Description implicite: ensemble des points qui verifient une certaine equation\\[\\begin{aligned}(D)=dx \\text{ tel que } &amp;lt;&amp;amp;x,n&amp;gt;=0\\\\&amp;amp;x^Tn=0\\end{aligned}\\]\\(\\{x\\text{ tel que } &amp;lt;x,n&amp;gt;=b\\}\\\\\\text{si je sais que } x_0\\in(D), &amp;lt;x_0,n&amp;gt;=b\\\\\\begin{aligned}\\{x \\text{ tel que }&amp;lt;x,n&amp;gt;=b=&amp;lt;x_0,n&amp;gt;&amp;amp;\\}\\\\&amp;lt;x,n&amp;gt;-&amp;lt;x_0,n&amp;gt;=0&amp;amp;\\}\\\\&amp;lt;x-x_0,n&amp;gt; = 0&amp;amp;\\}\\end{aligned}\\)Description de parties de $\\mathbb R^n$Ecriture impliciteOn se donne une fonction \\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\x=\\begin{pmatrix}x_1\\\\\\vdots\\\\x_n\\end{pmatrix}&amp;amp;\\mapsto f(x)\\end{aligned}\\\\\\begin{aligned}&amp;amp;\\mathcal C_0=\\{x\\in\\mathbb R^n\\vert f(x)=0\\}\\\\&amp;amp;\\mathcal C_x=\\{x\\in\\mathbb R^n\\vert \\underbrace{f(x)=x}_{g(x)=f(x)-r, \\mathcal C_r(f)=\\mathcal C_0(g)}\\}\\text{ courbe de niveau }x\\end{aligned}\\)Lieu de sous niveau\\(\\mathcal C_{\\le r}(f)=\\{x\\in\\mathbb R^n\\vert f(x)\\le r\\}\\)Exemple\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\)Question 3-10\\(\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\\\\\begin{aligned}\\mathcal C_0(f)&amp;amp;=\\{(0,0)\\}\\\\\\mathcal C_1(f)&amp;amp;=\\{(x,y)\\in\\mathbb R^2 \\text{ tel que } x^2+y^2=1\\}\\Rightarrow\\text{ cercle de rayon } 1\\\\\\mathcal C_2(f)&amp;amp;=\\text{ cercle de rayon }\\sqrt{2}\\end{aligned}\\)\\[\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+4y^2\\end{aligned}\\\\\\] Equation d‚Äôune ellipse de demi grand axe $a$ et demi petit axe $b$ \\(\\{(x,y)\\in\\mathbb R^2\\text{ tel que } (\\frac{x}{a})^2+(\\frac{y}{b})^2=1\\}\\)\\[a=b=r\\\\(\\frac{x}{a})^2+(\\frac{y}{b})^2=1\\Leftrightarrow x^2+y^2=r^2\\]\\(\\begin{aligned}\\mathcal C_0(g)&amp;amp;=\\{(0,0)\\}\\\\\\mathcal C_1(g)&amp;amp;=\\{(x,y)\\in\\mathbb R^2 \\text{ tel que } \\underbrace{x^2+4y^2=1}_{(\\frac{x}{1})^2+(\\frac{y}{\\frac{1}{2}})^2=1}\\}\\\\\\mathcal C_2(g)&amp;amp;=\\text{ de meme que }\\mathcal C_1\\end{aligned}\\)Question 3-11Surface definie apr les 2 branches d‚Äôune hyperbole $y\\mapsto\\frac{1}{x}$\\[\\{(x,y)\\in\\mathbb R^2, \\underbrace{y=\\frac{1}{x}}_{xy=1}\\}\\\\\\begin{aligned}g:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto xy\\end{aligned}\\\\y\\le\\frac{1}{x}\\Leftrightarrow yx\\le1\\] Donc pour la decrire: \\(\\{(x,y)\\in\\mathbb R^2, xy\\le1\\}=\\mathcal C_{\\le1}(g)\\)Ecriture parametriqueExemples\\(\\begin{aligned}f:\\mathbb R&amp;amp;\\to\\mathbb R\\\\t&amp;amp;\\mapsto f(t)\\end{aligned}\\\\graph(f)\\subset\\mathbb R^2\\\\\\{(t,f(t)),t\\in\\mathbb R\\}\\rightarrow\\text{ ecriture parametrique}\\)\\[\\begin{aligned}f:\\mathbb R^2&amp;amp;\\to\\mathbb R\\\\(x,y)&amp;amp;\\mapsto x^2+y^2\\end{aligned}\\\\graph(f)=\\{(x,y),f(x,y)),(x,y)\\in\\mathbb R^2\\}\\]Definition Soit\\(\\begin{aligned}f:\\mathbb R^n&amp;amp;\\to\\mathbb R\\\\t&amp;amp;\\mapsto f(t)\\end{aligned}\\\\graph(f)=\\{(t,f(t)),t\\in\\mathbb R^n\\}\\)Avec une ecriture parametrique, on peut se ramener a une ecriture implicite\\[y=f(x)\\Leftrightarrow f(x)-y=0\\\\graph(f)=\\{(x,f(t)),x\\in\\mathbb R\\}\\\\\\begin{aligned}graph(f) &amp;amp;= \\{(x,y),x\\in\\mathbb R,y=f(x)\\}\\\\&amp;amp;= \\{(x,y), x\\in\\mathbb R\\,\\underbrace{f(x)-y}_{g(x,y)}=0\\}\\\\&amp;amp;=\\{(x,y), g(x,y)=0\\}=\\mathcal C_0(g)\\end{aligned}\\]Epigraphe (au-dessus du graphe) d‚Äôune fonction $f$\\(Epi(f) = \\{(x,t),t\\ge f(x)\\}\\)Convexite dans $\\mathbb R^n$Parties convexes de $\\mathbb R^n$ On va dessiner des patates et des haricotsQuelle forme est convexe ? Si on prend 2 points quelconque de $A$ et qu‚Äôon trace ce segment, alors le segment est inclut dans $A$ $A$ est convexe et $B$ ne l‚Äôest pas.Pour un segment entre $x$ et $y$, n‚Äôimporte quel point de ce segments est une proportion du segment\\(tx+(1-t)y, t\\in[0;1]\\\\\\begin{aligned}t&amp;amp;=0\\to y\\\\t&amp;amp;=1\\to x\\\\t&amp;amp;= \\frac{1}{2}\\to\\text{milieu de } [x,y]\\end{aligned}\\) A CONNAITRE Definition: Une partie $A\\subseteq\\mathbb R^n$ est convexe si, et seulement si\\(\\forall x,y\\in A\\\\\\forall t\\in[0;1]\\\\tx+(1-t)y\\in A\\) Proprietes tout intervall de $\\mathbb R$ est convexe les sous espaces affines/les demi espaces sont convexesOn a $A$ et $B$ convexes $A\\cap B\\to$ convexe $A\\cup B\\to$ en general pas convexeEnveloppe convexe d‚Äôune partie $A\\subseteq\\mathbb R^n$Si on a une forme non-convexe, on ‚Äúbouche les trous‚Äù pour rendre la forme convexe et on obtient $conv(A)$ Intersection de tous les convexes qui $\\supseteq$ $A$. plus petit convexe qui $\\supseteq$ $A$ Soit $A$ une partie de $\\mathbb R^n$$x$ un point du bord si $\\forall\\varepsilon\\gt0, B(x,\\varepsilon)\\cap A\\neq \\emptyset$ $\\to$ bord/frontiere $\\delta A$ On appelle: adherence de $A$, $\\bar A=A\\cup \\delta A$ interieur de $A$, $\\dot A=A \\setminus\\delta A$ \\[A=[0;1[\\to\\begin{cases} \\delta A = \\{\\{0\\};\\{1\\}\\}\\\\ \\bar A = [0;1]\\\\ \\dot A = ]0;1[\\end{cases}\\]Hyperplan d‚Äôappui $A$ admet un hyperplan d‚Äôappui en $x\\in\\delta A$Si on peut definir un hyperplan qui separe l‚Äôespace en deux demi espaces tels que $A$ tombe integralement dans l‚Äôun des deux. $A$ admet un hyperplan d‚Äôappui de normale $\\vec n$ en $x\\in\\delta A$ si, et seulement si,\\(\\forall y\\in A, &amp;lt;y-x,n&amp;gt;\\le0\\) Question 3-20 N‚Äôayant pas d‚Äôhyperplan d‚Äôappui en un point donn√© de son bord:Haricots $\\to$ pas d‚Äôhyperplan d‚Äôappui en certains points de son bord. Ayant plus d‚Äôun hyperplan d‚Äôappui en un m√™me point: il faut un anglePoint anguleux $\\to$ plusieurs hyperplan d‚Äôappuis en ce point la N‚Äôayant aucun hyperplan d‚Äôappui:Pas d‚Äôhyperplan d‚Äôappui pour tous les points de bord. Ayant un hyperplan d‚Äôappui en tous les points de son bord:Pour tous les convexes Une partie est convexe ssi on peut definir un hyperplan d‚Äôappui en tout point de son bord.Fonction convexes A CONNAITRE Une fonction $f:\\mathbb R^n\\to\\mathbb R$ est convexe ssi: $Dom f$ est convexe $\\forall x,y\\in Dom f$, $\\forall t\\in[0;1]$ $f(tx+(1-t)y)\\le tf(x)+(1-t)f(y)$ $f$ concave si $-f$ convexe.Les droites affines sont les seules fonctions concaves ET convexesPetit bestiaire de fonctions convexes: $ax+b$ $e^{\\alpha x}, \\forall\\alpha\\in\\mathbb R$ $ax^2+bx+c$, $a\\ge0$ $-\\log(x)=\\log(\\frac{1}{x})$ $\\sqrt{x}$ $x^n$, $n$ pair La somme ponderee positivement de fonctions convexes est une fonction convexe \\(f_{i_{i\\ge 0}},i=1,...,N\\text{convexes}\\\\f=\\sum_{i=1}^N\\omega_if_i\\\\\\)Demonstration\\(Dom f=\\cap Dom f_i\\to\\text{ convexe}\\)Soit $x,y\\in Dom f$ et $t\\in[0;1]$\\(\\begin{aligned}f(tx+(1-t)y)&amp;amp;=\\sum_{i=1}^N\\omega_i\\underbrace{f_i(tx+(1-t)y)}_{\\le tf_i(x)+(1-t)f_i(y)\\text{ car } f \\text{ convexe}}\\\\&amp;amp;\\le \\sum_{i=1}^N\\omega_itf_i(x) + \\sum_{i=1}^N\\omega_i(1-t)f_i(y)\\\\&amp;amp;\\le t\\underbrace{\\sum_{i=1}^N\\omega_if_i(x)}_{f(x)} + (1-t)\\underbrace{\\sum_{i=1}^N\\omega_if_i(y)}_{f(y)}\\\\f(tx+(1-t)y)&amp;amp;\\le tf(x)+(1-t)f(y)\\end{aligned}\\) $f=\\max_{i=1,‚Ä¶,n}f_i$ est convexe la composition d‚Äôune fonction convexe $f$ avec $g$ affine croissant $g\\circ f$ est convexeLien entre partie convexe et fonction convexe: L‚Äôepigraphe d‚Äôune fonction convexe est une partie convexe Tous les lieux de sous niveaux d‚Äôune fonction convexe sont des parties convexesEn dimension 1:" }, { "title": "PRST: Exercices de cours du 17/03", "url": "/cours/posts/prst_exercises_17_03/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, Fisher, EMV", "date": "2021-03-17 14:30:00 +0100", "snippet": "Lien de la note Hackmd Les exos sont fait dans le meme ordre que pendant le coursExercice - loi normale loi normale de param√®tres $m$ et $\\sigma$ avec $\\sigma=1$ densite $f(x,m)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x-m)^2}{2}}$ pour $x\\in\\mathbb R$ et $m\\in\\mathbb R$ D√©terminer l‚ÄôEMV. Solution\\[\\begin{aligned}L(x_1,...,x_n)&amp;amp;=\\Pi_{i=1}^n\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{(x_i+m)^2}{2}}\\\\&amp;amp;= \\biggr(\\frac{1}{\\sqrt{2\\pi}}\\biggr)^ne^{-\\sum_{i=1}^n\\frac{(x_i-m)}{2}}\\end{aligned}\\] Passons au logarithme. Est-ce que la fonction est paire ?Oui car $\\log$ est defini sur $\\mathbb R^{+*}$.\\[\\log(L(x_1,...,x_n,m))=-n\\log(\\sqrt{2\\pi})-\\sum_{i=1}^n\\frac{(x_i-m)^2}{2}\\] Derivons par rapport a m:\\[\\begin{aligned}\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m} &amp;amp;= -\\sum_{i=1}^n\\biggr[(-x_i)+m\\biggr]\\\\&amp;amp;= \\sum_{i=1}^nx_i-nm\\\\\\end{aligned}\\\\\\begin{aligned}\\\\\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m}=0&amp;amp;\\Leftrightarrow\\sum_{i=1}^nx_i-mn=0\\\\&amp;amp;\\Leftrightarrow\\frac{1}{n}\\sum_{i=1}^nx_i=m\\end{aligned}\\] Verifions la condition du second ordre:\\[\\frac{\\delta\\log(L(x_1,...,x_n,m))}{\\delta m}=-n\\lt0\\] Donc la condition suffisante est verifiee. $\\hat m = \\bar X$ est l‚ÄôEMV du parametre $m$.Exercice - loi geometrique loi g√©om√©trique de param√®tre $p$ $P(X=x)=p(1-p)^{x-1}$ pour $x\\gt1$ et $p\\in]0;1[$ D√©terminer l‚ÄôEMV. Solution Soit $(x_1,‚Ä¶,x_n)\\in\\mathbb N^n_*$.\\[\\begin{aligned}L(x_1,...,x_n,p)&amp;amp;=\\Pi_{i=1}^np(1-p)^{x_i-n}\\\\&amp;amp;=p^n(1-p)^{\\sum_{i=1}^n(x_i-1)}\\end{aligned}\\\\\\log(L(x_1,...,x_n,p))=n\\log(p)+\\sum_{i=1}^n(x_i-1)\\log(1-p)\\\\\\frac{\\delta\\log(L(x_1,...,x_n,p))}{\\delta p}=\\frac{n}{p}-\\sum_{i=1}^n\\frac{x_1-1}{1-p}\\] \\[(\\log u)&#39;=\\frac{u&#39;}{u}\\\\\\Leftrightarrow \\log (1-p) = -\\frac{1}{1-p}\\] \\[\\frac{\\delta\\log(L(x_1,...,x_n,p))}{\\delta p} = 0\\\\\\begin{aligned}\\frac{n}{p}=\\sum_{i=1}^n\\frac{x_1-1}{1-p}&amp;amp;\\Leftrightarrow n(n-p)=p\\sum_{i=1}^n(x_i-1)\\\\&amp;amp;\\Leftrightarrow n-np=p\\sum_{i=1}^nx_i - np\\\\&amp;amp;\\Leftrightarrow p = \\frac{n}{\\sum_{i=1}^nx_i} = \\frac{1}{\\frac{n}{\\sum_{i=1}^nx_i}} = \\frac{1}{\\bar X}\\end{aligned}\\\\\\] \\[(\\frac{1}{u})&#39; = -\\frac{u&#39;}{u^2}\\] \\[(\\frac{1}{1-p})&#39;=-\\frac{(-1)}{(1-p)^2}=\\frac{1}{(1-p)^2}\\] \\[\\frac{\\delta^2\\log(L(x_1,...,x_n,p))}{\\delta p^2}=-\\frac{n}{p^2}-\\frac{\\sum_{i=1}^n(x_i-1)}{(1-p)^2}\\lt0\\] Donc la condition suffisante est verifiee. $\\hat p =\\frac{1}{\\bar X}$ est l‚ÄôEMV du parametre $p$.Exercice - information de FisherD√©terminer l‚Äôinformation de Fisher pour la loi de Poisson de param√®tre $\\lambda$. Solution\\[\\log f(x,\\lambda)=-\\lambda+x\\log(\\lambda)-\\log(x!)\\\\\\frac{\\delta\\log f(x,\\lambda)}{\\delta\\lambda} = -1+\\frac{x}{\\lambda}\\\\\\frac{\\delta^2\\log f(x,\\lambda)}{\\delta\\lambda^2}=-\\frac{x}{\\lambda^2}\\\\\\begin{aligned}E_n\\biggr(\\frac{\\delta^2\\log f(X,\\lambda)}{\\delta\\lambda^2}\\biggr)&amp;amp;=-E(\\frac{X}{\\lambda^2})\\\\&amp;amp;=-\\frac{1}{\\lambda^2}\\times\\lambda=-\\frac{1}{\\lambda}\\end{aligned}\\\\I(\\lambda)=-E\\biggr(\\frac{\\delta^2\\log f(x,\\lambda)}{\\delta\\lambda^2}\\biggr)=\\frac{1}{\\lambda}\\]" }, { "title": "IML: Introduction", "url": "/cours/posts/iml_introduction/", "categories": "Image S8, IML", "tags": "Image, SCIA, IML, S8", "date": "2021-03-17 11:00:00 +0100", "snippet": "Lien de la note HackmdMotivationWhat is learning ?It‚Äôs all about evolving DefinitionLearning: Improver over experience to perform better in new situations. Quoting S. BengioLearning is not learning by heart.Any computer can learn by heart.The difficulty is to generalize a behavior to a novel situation.Can machines learn ?A new science with a goal and an object. How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes ? Tom Mitchel, 2006 What is it good for ?According to Peter NorvigThe 3 main reasons why you may want to use Machine Learning: Avoid coding numerous complex rules by hand lower cost, more effective, faster reaction to changing problem Optimize the parameteres of your system given a dataset of yours Better accuracy Create systems for which you do not know the rules conscioulsy (e.g. recognize a face) Greater potential AI vs Machine Learning AI is a very fuzzy concept, much like ‚Äúany computer program doing something useful‚Äù Think ‚Äúif-then‚Äù rules ML can be considered a subfield of AI since those algorithms can be seen as building blocks to make computers learn to behave more intelligently by somehow generalizing rather that just storing and retrieving data items like a database system would do Engineering point of view: ML is about builiding programs with turnable parameters (typically an array of floating point values) that are adjusted automatically so as to improve their behavior by adapting to previously seen dataMachine Learning vs Deep LearningTraditional Machine LearningDeep LearningAI vs ML vs DLDL $\\subset$ ML $\\subset$ AIExerciseMachine Learning ExamplesCan you list examples of projects or products involving Machine Learning ? Google LensMachine Learning ProblemWhy is learning difficult ?Generalization is an ambiguous process.Given a finite amount of training data, you have to derive a relation for an infinite domain.In fact, there is an infinite number of such relations.How should we draw the relation?Which relation is the most appropriate?‚Ä¶the hidden test points (seen after the training)‚Ä¶Learning biasHow to guide generalization It is always possible to find a model complex enough to fit all the examples Example: polynomial with very high degree But how would this help us with new samples? It should not generalize well. We need to define a family of acceptable solutions to search from It forces to learn a ‚Äúsmoothed‚Äù representation. ‚Ä¶ but it should not smooth the representation too much! Occam‚Äôs Principle of Parsimony (14th century)One should not increase, beyond what is necessary, the number of entities required to explain anything.When many solutions are available for a given problem, we should select the simplest one.But what do we mean by simple?We will use prior knowledge of the problem to solve to define what is a simple solution. Example of a prior: smoothnessLearning as a search problemHypothesis space / initial, compatible (with train set), optimal, and ideal solutionsWhat are the sources of error ?Noise, intrinsic errorYour data is not perfect (can have noisy or erroneous labels). (or ‚ÄúEvery model is wrong.‚Äù) Even if there exist an optimal underlying model, the observations are corrupted by noise.(Inductive) bias, approximation errorWe are exploring a restricted subset of all possible solutions. Your classifier needs to drop some information about the training set to have generalization power (simplify to generalize).Variance, estimation errorYou have many ways to explain your training dataset. It is hard to find an optimal solution among those many possibilities. Our exploration is not very accurate, we are limited by data we see during training.Bias / variance compromise Low bias $\\Leftrightarrow$ high variance: large search set, can capture many useless details overfitting High bias $\\Leftrightarrow$ low variance: small search set, limited exploration, solution too simple underfitting. Solutions: regularization (penalize solutions which are too complex), early stopping (stop when no more progress)‚Ä¶Parameters of a ML problemMany variations for each element Protocol: supervision? feedback? how many samples for each ‚Äúexperience‚Äù? Measure of success: error cost? convergence? ‚Ä¶ Inputs (representation space): quality (noise, distribution) and nature (numerical, symbolical, mixed) Solutions (space hypothesis/functions to explore): many approachesThree kinds of ML problemsAccording to Samy BengioRegressionRegression input: samples described by several input variables (correlated)Regression output: a quantitative variable (scalar)Regression, classificationClassification input: samples described by several input variables (correlated)Classification output: a qualitative variable (class, category)Regression, classification, density estimationDensity estimation input: samples described by several input variables (correlated)Density estimation output: estimate of the probability distribution function overthe feature spaceThree kinds of supervision/trainingsAccording to Lecun, S. Bengio Supervised learning: Training data contains the desired behavior ‚Äî desired class, outcome, etc Medium feedback Reinforcement learning: Training data contains partial targets ‚Äî Did the system do well or not? Is some object present in the image (without knowing is position)? Weak feedback Unsupervised/Self-supervised learning: Training data is raw, no class or target is given. There is often a hidden goal in the task: compression, maximum likelihood, predict parts from other parts (BERT-like)‚Ä¶ Lot of feedback Forms of Machine LearningAccording to Cornuejols and Miclet Exploration-based: Generalization or specialization of rules Examples: Grammatical inference, heuristic discovery for SAT solvers‚Ä¶ Optimization-based: Topic of this course. Examples: linear separators and SVMs, neural networks, decision trees, Bayesian networks, HMMs‚Ä¶ Approximation-based: Data compression, analogy. Examples: KNN, embedding spaces Machine Learning EngineeringML from an engineer point of viewSolve problems using the right toolSome taxonomySimplified view of pre-2010 Machine LearningChoosing the right toolWhy we love scikit-learnRepresenting dataWhy we love scikit-learnRelated domainAt the cross-roads of numerous fields Signal processing Databses, information retrieval Statistics Pattern Recognition Optimization Data science, data mining" }, { "title": "ASE2: TD 2", "url": "/cours/posts/ase2_td2/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, binomial, poisson, normale", "date": "2021-03-17 10:00:00 +0100", "snippet": "Lien de la note Hackmd Avec Poisson: approximation en serie, mieux de passer par la Gaussienne (loi binomiale) car moins de calculsExercice 9Une usine fabrique des pieces, dont $3\\%$ ont des defauts On preleve 1000 pieces au hasard Quelle est la probabilite d‚Äôavoir plus de $50$ pieces defectueuses ? Quelles est la probabilite d‚Äôavoir entre $20$ et $40$ pieces defectueuses ? On veut $1950$ pieces sans defaut. Par prudence, on en preleve $2000$ au hasard. Quelle est la probabilite d‚Äôavoir sufffisamment de pieces en bon etat ? Solution Soit $X$ la v.a.: nombre de pieces defectueurse parmi 1000. $X$ suit la loi $\\mathcal B(n,p)$ avec $n=1000$ et $p=0,03$\\[\\mathcal B(n,p)\\simeq \\mathcal N(np,\\sqrt{npq})\\\\\\text{Donc } \\frac{X-np}{\\sqrt{npq}}\\to^{\\mathcal L}\\mathcal N(0,1)\\text{ (theoreme Moivre-Laplace)}\\\\\\begin{cases} np=30\\\\ npq=29,1\\end{cases}\\\\\\sqrt{npq}=\\sqrt{29,1}=5,4\\] 1.1.\\[\\begin{aligned}P(X\\gt50)&amp;amp;=1-P(X\\le50)\\\\&amp;amp;\\simeq 1-P(U\\le\\frac{50-30+0.5}{5,4})\\end{aligned}\\] avec $U=\\frac{X-30}{5,4}\\sim \\mathcal N(0,1)$\\[\\begin{aligned}P(X\\gt50)&amp;amp;\\simeq 1-P(U\\le3,8)\\\\&amp;amp;\\simeq 1-F(3,8)=1,0-0,9999... = 0\\end{aligned}\\] 1.2.\\[P(20\\le X\\le40)\\simeq P(\\frac{20-30-0,5}{5,4}\\le U\\le\\frac{40-30+0,5}{5,4})\\] avec $U=\\frac{X-30}{5,4}\\sim \\mathcal N(0,1)$\\[\\begin{aligned}P(20\\le X\\le40)&amp;amp;= P(-1,94\\le U\\le 1,94)\\\\&amp;amp;= F(1,94)-F(-1,94) \\text{ } F \\text{ fonction de repartition de }\\mathcal N(0,1)\\\\&amp;amp;= F(1,94)-(1-F(1,94))\\\\&amp;amp;= 2F(1,94)-1 = 2\\times 0,9738 \\text{ (Table de } \\mathcal N(0,1)\\text{)}\\\\&amp;amp;= 0,9476\\end{aligned}\\] 2.\\[X\\to\\mathcal B(2000,p=0,03), n=2000\\\\np=60,npq=58,2,\\sqrt{npq}=7,63\\\\\\mathcal B(2000;0,03)\\simeq\\mathcal N(60;7,63)\\] On veut $1950$ pieces en bon etat, donc:\\[P(X\\le50)=P(\\frac{X-60}{7,6}\\le\\frac{50-60+0,5}{7,63})\\\\U=\\frac{X-60}{7,63}\\to\\mathcal N(0,1)\\] Donc:\\[\\begin{aligned}P(X\\le50)&amp;amp;=P(U\\le-1,25)\\\\&amp;amp;= F(-1,25)\\\\&amp;amp;= 1-F(1,25)\\\\&amp;amp;= 1-0,8944=0,1056\\end{aligned}\\]Exercice 10Le nombre de pannes, par mois, sur une certaines machine, suit une loi de Poisson de moyenne egale a $3$. Un atelier fonctionne avec $12$ machines de ce type, independantes.En un mois, quelle est la probabilite de constater dans cet atelier: Plus de $42$ pannes ? entre $36$ et $45$ pannes ? Solution Soit $X_i$ v.a.: nombre de pannes, en un mois de la machine $n^oi$, $X_i\\to\\mathcal P(3)$.Soit $S_{12}=X_1+X_2+‚Ä¶+X_{12}$, $S_{12}$: nombre de pannes dans l‚Äôatelier$(X_i)$ sont independantes donc: $S_{12}=\\sum_{i=1}^{12}\\to\\mathcal P(12\\times 3)=\\mathcal P(36)$.\\[S_{12}\\to\\mathcal P(36), \\lambda=36\\gt20\\] On peut approximer cette loi par la loi normale:\\[\\frac{S_{12}-36}{\\sqrt{36}}\\simeq\\mathcal N(0,1)\\] 1. On cherche $P(S_{12}\\gt42)$\\[\\begin{aligned}P(S_{12}\\gt42)&amp;amp;=P(\\frac{S_{12}-36}{6}\\gt\\frac{42-36}{6})\\\\&amp;amp;= P(\\frac{S_{12}-36}{6}\\gt1)\\\\&amp;amp;=1-P(U&amp;lt;1)\\text{ avec } U=\\frac{S_{12}-36}{6}\\\\&amp;amp;=1-F(1)\\\\&amp;amp;=1-0,8413=0,1587\\end{aligned}\\] 2.\\[\\begin{aligned}P(36\\lt S_{12} \\lt45) &amp;amp;=P(0\\lt\\frac{S_{12}-36}{6}\\lt\\frac{3}{2})\\\\&amp;amp;=F(1,5)-F(0)\\\\&amp;amp;= 0,9332-0,5=0,4332\\end{aligned}\\]Exercice 11On jette $600$ fois un de equilibre a $6$ faces. On note $X$ le nombre d‚Äôapparitions de l‚Äôas (face marquee 1). Quelle est la loi de $X$ ? Calculer $E(X)$ et $V(X)$ Calculer $P(X\\gt 110)$ Determiner un intervale $[a;b]$ centre sur $E(X)$ tel que $P(a\\le X\\le b)=0,95$ Solution 1.\\[X\\to\\mathcal B(n,p)=\\begin{cases}n=600\\\\p=\\frac{1}{6}\\end{cases}\\] 2.\\[E(X) = np = 100,\\sigma(X)=\\sqrt{100\\times\\frac{5}{6}\\times\\frac{1}{6}} = 9,13\\] 3.\\[\\begin{aligned}P(X\\gt110) &amp;amp;= P(\\frac{X-100}{9,13}\\gt\\frac{110-100}{9,13})\\\\&amp;amp;= P(U\\gt\\frac{110-100}{9,13})\\\\&amp;amp;= P(U\\gt1,15)\\text{ avec } U=\\frac{X-100}{9,13}\\to\\mathcal N(0,1)\\\\&amp;amp;= 1-F(1,15)\\end{aligned}\\] Donc $P(X\\gt110)=1-0,8749=0,13$ \\[P(X\\gt110)=0,13\\] 4. Soit $r$: rayon de l‚Äôintervalle\\[\\begin{cases}a=E(X)-r\\\\b=E(X)+r\\end{cases}\\] On cherche $r$ tel que\\[P(\\vert X-100\\vert\\le r)=0,95\\] Posons $U=\\frac{X-100}{9,13}$\\[\\begin{aligned}P(\\vert X-100\\vert\\le r)=P(\\vert U\\vert\\le\\frac{r+0,5}{9,13})&amp;amp;=0,95\\\\P(\\frac{-r-0,5}{9,13}\\le U\\le\\frac{r+0,5}{9,13})&amp;amp;=0,95\\\\F(\\frac{r+0,5}{9,13})-F(\\frac{-r-0,5}{9,13})&amp;amp;=0,95\\\\2F(\\frac{r+0,5}{9,13})-1&amp;amp;=0,95\\\\\\end{aligned}\\\\F(\\frac{r+0,5}{9,13}) = \\frac{1,95}{2} = 0,975\\\\\\text{D&#39;apres la table: } \\frac{r+0,5}{9,13}=1,96\\\\\\Rightarrow r= 1,96\\times 9,13-0,5=17,39\\\\\\text{Donc: } \\begin{cases}a=100-17,39=82,61\\\\b=100+17,39=117,39\\end{cases}\\] \\[I=[82,61;117,39]\\] " }, { "title": "ASE2: Convergence et estimation - 3", "url": "/cours/posts/ase2_estimation_3/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, estimation", "date": "2021-03-17 09:00:00 +0100", "snippet": "Lien de la note Hackmd$\\bar X$ est un exemple d‚Äôestimateur de la moyenne $m=E(X)$ (sert a approximer la moyenne de la population globale) Utile quand on a un parametre inconnu. Definition:On appelle variance empirique, la statistique :\\[S^2=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar X)^2\\]Proposition\\[S^2 = \\frac{1}{n}\\sum_{i=1}^nX_i^2-(\\bar X)^2\\]Demo\\[\\begin{aligned}S^2&amp;amp;=\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar X) = \\frac{1}{n}\\sum_{i=1}^n(X_i^2 - X_i\\bar X+\\bar X^2)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nX_i^2-2\\bar X\\sum_{i=1}^nX_i+\\frac{n}{n}\\bar X^2\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nX_i^2-2\\bar X^2+\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i^-(\\bar X)\\end{aligned}\\]Montrons que $S^2\\to^P\\sigma^2$ lorsque $n\\to+\\infty$D‚Äôapr√®s la loi des grands nombres, on a:$\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\to^Pm=E(X)$ quand $n\\to+\\infty$et $\\frac{1}{n}\\sum_{i=1}^nX_i^2\\to^PE(X^2)$ quand $n\\to+\\infty$Donc $S^2=\\frac{1}{n}\\sum_{i=1}^nX_i^2-(\\bar X)^2\\to^PE(X^2)-E^2(X)=\\sigma^2=V(X)$ $S^2$ est un estimateur de la variance. DefinitionOn consid√®re une population $X$, distribu√©e suivant une loi de probabilit√© qui d√©pend d‚Äôun param√®tre $\\theta$ inconnu. On pr√©l√®ve un √©chantillon $(X_1,X_2,‚Ä¶,X_n)$ de $X$, on appelle estimateur de $\\theta$, toute variable al√©atoire $T_n$ fonction de l‚Äô√©chantillon:\\[T_n=f(X_1,X_2,...X_n)\\]On appelle biais de l‚Äôestimateur la quantit√© $b(T_n)=E(T_n)-\\theta$ On dit que l‚Äôestimateur est sans biais si $b(T_n)=0\\Leftrightarrow E(T_n)=\\theta$.Comme exemple $\\bar X$ est un estimateur sans biais de $m=E(X)$ puisque $E(\\bar X) = m$ DefinitionOn dit qu‚Äôune suite $(T_n)$ d‚Äôestimateurs de $\\theta$ est asymptotiquement (cad au voisinage de $+\\infty$) sans biais et si\\[lim_{n\\to+\\infty}(E(T_n))=\\theta\\]On appelle risque quadratique de $T_n$ ou erreur quadratique: \\(R(T_n)=E((T_n-\\theta)^2)\\)PropositiomLe risque quadratique est :\\[R(T_n) = V(T_n)+(E(T_n)-\\theta)^2\\]D√©monstration\\[(T_n-\\theta)^2=(T_n-E(T_n)+E(T_n)-\\theta)^2\\\\\\begin{aligned}E((T_n-\\theta)^2)&amp;amp;=E((T_n-E(T_n))^2)+2E((T_n-E(T_n))(E(T_n)-\\theta))+E((E(T_n)-\\theta)^2)\\\\&amp;amp;= V(T_n)+2(E(T_n)-\\theta)(E(T_n)-E(T_n))+(E(T_n)-\\theta)^2\\\\\\end{aligned}\\\\\\text{Donc } R(T_n) = V(T_n)+(E(T_n)=\\theta)^2\\]RemarqueSi l‚Äôestimateur est sans biais $b(T_n)=E(T_n)-\\theta=0$Alors $R(T_n)=V(T_n)$Donc si on a deux estimateurs sans biais du param√®tre $\\theta$, le plus pr√©cis est celui de variance minimale. DefinitionOn dit que l‚Äôestimateur $T_n$ est convergent si cet estimateur converge en probabilit√© vers le param√®tre $\\theta$.On ecrira $T_n\\to^P\\theta$ lorsque $n\\to+\\infty$ DefinitionOn appelle vraisemblance de $\\theta$, la densit√© de l‚Äô√©chantillon $(X_1,X_2,‚Ä¶,X_n)$:\\[\\begin{cases}L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nP(X_i=x_i) &amp;amp;\\text{(dans le cas discret)}\\\\L(x_1,x_2,...,x_n,\\theta)=\\Pi_{i=1}^nf(x_i) &amp;amp;\\text{(dans le cas continu)}\\end{cases}\\]" }, { "title": "IREN: Introduction aux r√©seaux neuronnaux ", "url": "/cours/posts/iren_introduction/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8, r√©seaux neuronnaux", "date": "2021-03-16 11:00:00 +0100", "snippet": "Lien de la note HackmdIndex du coursUn neurone On reflechis selon les impulsions electriques dans notre cerveau Il y a des seuils pour les impulsions electriques Poid: $w_0$ Energie de la part du voisin: $x_0$ Si on a une mauvaise ‚Äúconnexion‚Äù, on recoit pas ou peu les informations des voisins On a une fonction d‚Äôactivation $f$ (seuil) pour savoir si on ressort du neurone A la sortie on a une combinaison lineaire de l‚Äôentree de base La fonction d‚Äôactivation casse la linearite Les problemes ne se reglent pas lineairement a chaque fois Les maths d‚Äôun neurone $z=b+\\sum_iw_ix_i$ $y=\\sigma(z)$avec les $i$ entrees $x_i$ $b$ le biais $w_i$ les poids $\\sigma$ la fonction d‚Äôactivation ReLU: cancer ? $2,5$ en reponse Logistique (sigmoide) vrai ou faux Tangente hyperbolique Varie de $-1$ a $1$ Choisi entre vrai ou faux Un premier reseau neuronal√âvaluer les couples d‚Äôentr√©e $(1,1)$, $(0,1)$, $(1,0)$ et $(0,0)$ avec $\\sigma$ une logistique $(0,0) = 0$Construction d‚Äôun reseau neuronalPour construire un r√©seau neuronal par apprentissage supervis√© il faut : un grand jeu de donn√©es √©tiquet√©es par la sortie voulue d√©finir l‚Äôarchitecture du r√©seau avec le nombre de couches les types de couches le nombre de n≈ìuds par couche les fonctions d‚Äôactivations les connexions inter-couches toutes astuces qui fonctionnent une fonction d‚Äôerreur pour guider la correction sur les poids une m√©thode pour faire converger le r√©seau (trouver les bons poids) En cas de probl√®me, on sacrifie un poulet.Les donneesLes donn√©es doivent √™tre tr√®s nombreuses (assez pour d√©finir toutes les inconnues du r√©seau) de bonne qualit√© (pour ne pas tromper le r√©seau)On appronfondira avec des exemples et l‚Äôutilisation de Pandas pour nettoyer les donn√©es.Est-ce un champignon ? Pr√©cision suivant la qualit√© des √©tiquettes.L‚Äôarchitecture du r√©seauC‚Äôest la partie tactique et artistique.L‚Äô√©tude des diff√©rents r√©seaux n‚Äôentre pas dans le cadre de ce cours d‚Äôintroduction. On se limitera √† quelques r√©seaux lors des TP.La fonction d‚ÄôerreurLa fonction d‚Äôerreur indique de combien le r√©seau s‚Äôest tromp√© par rapport √†la v√©rit√© terrain ($y$ vs $t$). Elle doit √™tre d√©rivable correspondre au probl√®me trait√©Cette fonction est aussi appel√©e fonction de co√ªt (cost function ou loss function en anglais).Exemple L‚Äôerreur quadratique $E = (y ‚àí t)^2$ $E = \\log(\\cosh(y ‚àí t))$ quadratique puis lin√©aire lorsque l‚Äô√©cart cro√Æt L‚Äôentropie crois√©e pour des probabilit√©s (valeurs entre $0$ et $1$)\\[E=-\\sum_kt_k\\log(y_k)+(1-t_k)\\log(1-y_k)\\]Une m√©thode pour trouver les bons poidsComment l‚Äôerreur nous guide pour trouver les poids ?ExempleVous √™tes le directeur et tous les jours vous invitez votre √©quipe √† d√©jeuner. Il y a le choix entre le plat A, B ou C. Vous payez chaque jour l‚Äôaddition.Avec les donn√©es $[(5,3,2), 114]$, $[(6,2,2), 108]$, $[(3,4,5), 147]$ qui correspondent aux quantit√©s de chaque plat et au prix global, d√©duire le prix de chaque plat par une m√©thode d‚ÄôapprentissageQue proposez-vous ?C‚Äôest une equations a 3 inconnues mais on veut faire apprendre au reseau de neurones.Supposons qu‚Äôon met tous les prix a 10euros et qu‚Äôau lieu de payer 100euros pour 10 plats, on paye 114euros.Reflechir comme un reseau neuronal: On augmente tous les prix On augment les poids en fonction du nombre de fois ou un plat a ete prit On fait un pourcentage $\\rightarrow$ $50%$ La somme de tous les $i$ divise par $i_0$ Utilisons l‚Äôerreur pour corriger les poidsL‚Äôalgorithme consiste √† trouver les $w_i$ qui minimisent l‚Äôerreur : On initialise les poids √† une valeur probable (disons 10 pour tous) On corrige les poids au prorata de leur part dans l‚Äôerreur $E = y ‚àí t$ :\\(w_j = w_j ‚àí \\eta d_j\\) $d_j = \\frac{E\\times i_j}{\\sum_ki_k}$ $\\eta$ petit pour √©viter de sur-corrigerD√©roulons l‚Äôalgorithme avec $\\eta = \\frac{1}{10}$: $[(5,3,2), 114]$ Notre prix estim√© est de 100. $d_0=\\frac{(y-t)\\times i_0}{10} = -7.0$ donc $w_0=10+0.70=10.7$ $d_1=\\frac{(y-t)\\times i_1}{10} = -4.2$ donc $w_0=10+0.42=10.42$ $d_2=\\frac{(y-t)\\times i_2}{10} = -2.8$ donc $w_0=10+0.28=10.28$ $[(6,2,2), 108]$ Notre prix estim√© est de 105.6 et on obtient $w_0=10.84$, $w_1=10.46$ et $w_2=10.33$ $[(3,4,5), 147]$ Notre prix estim√© est de 126.04 et on obtient $w_0=11.37$, $w_1=11.16$ et $w_2=11.20$ On peut rejouer les donn√©es jusqu‚Äô√† converger la convergence peut √™tre longue avec un petit $\\eta$ cela peut diverger avec un trop grand $\\eta$ \\(\\frac{E\\times i_j}{\\sum_k i_k} = \\alpha\\frac{\\delta(y-t)^2}{\\delta w_j}\\)derivee partielle par rapport a $w_j$R√©tropropagation du gradientFonction logistiqueCalculons l‚Äôinfluence du poids $w_{2,2}^2$ sur l‚Äôerreur quadratique $E:\\frac{\\delta E}{\\delta w_{2,2}^2}$La derivee partielle de $y$ par rapport a $z$ est $y(1-y)$ C‚Äôest $e^x$ qui se balade. Il croise $2$ tout panique qui lui dit ‚ÄúDerivee me court apres!‚Äù et part en courant pendant que $e^x$ se marre. Ensuite $e^x$ tombe sur un gars qui cherche quelqu‚Äôun, et le gars lui demande ‚ÄúT‚Äôas pas peur de moi ?‚Äù, $e^x$ repond ‚ÄúBah non pourquoi?‚Äù, le gars lui repond ‚ÄúBah parce que je suis $\\frac{d}{dy}$‚ÄùQue vaut le gradient de $E :\\nabla E$?Pourquoi ce titre ?" }, { "title": "IREN: Tour d&#39;horizon", "url": "/cours/posts/iren_horizon/", "categories": "Image S8, IREN", "tags": "Image, Sante, IREN, S8", "date": "2021-03-16 10:00:00 +0100", "snippet": "Lien de la note HackmdNote: projet en binomeIndex du coursCas d‚Äôutilisation Pub ciblee Recommendations (Netflix) Description (d‚Äôune image pour les personnes malvoyantes) Securite Diagnostique (traitement d‚Äôimage medicale) Ex: creation d‚Äôune IA qui detecte le cancer et a commence a detecter le cancer chez des personnes ou les medecins n‚Äôavaient rien trouve et les medecins ont decouvert des nouveaux marqueurs du cancer Jeux (bot pour les echecs) Jeu de go: trop complexe pour tester toutes les possibilites IA developpee qui s‚Äôest averee tres creative Majordome (Alexa, Google Home) Le telephoneHistorique L‚ÄôIA n‚Äôest pas l‚ÄôoeufLes hivers ont bloque l‚ÄôIA avant qu‚Äôelle redemarreLes hiversLa renaissance est dues au triptique donn√©es, hardware, th√©orie.Aujourd‚Äôhui: 3$^{\\text{eme}}$ phase: l‚Äôespoir l‚ÄôIA va regler tous les problemes du monde L‚ÄôIA est une copie du cerveau humain (au moins le principe de base)Quand un enfant apprend, il a un flux de donnees continu (vue, ouie, etc.) Les GPUs ont evolues, developpe un parallelisme de choses a faire La theorie: comprehension globale et trucs locaux qui permet de tout faire marcher On n‚Äôa PAS de base robuste Ca marche mais on sait pas pourquoi Plus gros c‚Äôest mieuxBesoin de calculs pour l‚Äôentrainement et taille des r√©seaux Plus notre reseau est gros, plus on a besoin de donneesOn peut reduire les reseaux de neurones, si une connection entre 2 neurones est trop faible on la supprime.Exemple d‚Äôune voiture autonomeResNEt-50 a besoin de $7,72$ G operations pour traiter une image $255\\times 255$ $230$ Gops pour $30$ fps $9,4$ Tops pour du HD $338$ Topes pour $12$ cameras et $3$ couleurs par cameraNvidia A100 Peak rates = GPU boost clock Effective using Sparsity Tensor core: extensions de Nvidia pour gerer Tensorflow (par supposition du prof)Les leadersLes leaders les plusvisible sont Google (Tensorflow, Keras, DeepMind) Facebook (Torch, PyTorch) Microsoft (CNTK) IBM (Watson) Baiduet bien s√ªr le principal fabriquant : NVidia (Cuda, CuDNN) Ce qu‚Äôon voit moinsA cot√© de ceux qui participent activement √† la recherche et aud√©veloppement des outils, il y a ceux qui l‚Äôutilisent en interne. Amazon (Alexa, Amaxon Go) Apple Les constructeurs automobiles (Tesla, Uber, t o u s) tout ceux qui font du conseil (Netflix, Expedia‚Ä¶), de la pub (Criteo) plein de startups Types d‚ÄôapprentissageApprentissage supervise On a un jeu d‚Äôimage et on sait que l‚Äôimage 4 c‚Äôest une forme On montre l‚Äôimage au reseau (qui sortira une reponse au pif vu qu‚Äôil ne sait rien pour l‚Äôinstant) On corrige le reseaux en donnant la reponse Le reseaux changent les poids des connexions pour s‚ÄôadpaterExemple: le spamOn recoit un nouveau mail et le reseau de neurones determine si c‚Äôest un spam ou non, on le corrige s‚Äôil a faux Regression Classification Moindres carres SVM Regression polynomiale Regression logistique, arbre de decisions Reseau neuronal Reseau neuronal La revolution vient des reseaux neuronaux: Mur Demande des quantites enormes de donnees etiquettees Pas toujours simple √† faire marcher De plus en plus complexe Produit des r√©sultats remarquables en traitement d‚Äôimage traitement de la parole Apprentissage non supervise classer des classes qu‚Äôon ne connait pas $\\rightarrow$ clustering $K$-moyennes, ACP, des reseaux de neurones Difficile d‚Äôen mesurer l‚Äôefficacite (besoin de juges humains) Usage limite mais en progres Probleme: ne sait pas si ce qu‚Äôil a fait est ok ou non Ex; s‚Äôil classe par couluer au lieu de forme Besoin d‚Äôhumains pour juger Apprentissage par renforcementLie aux jeux videos Rules of the fame are unknown Learn directly from interactive game-play Le jeu informe si on gagne ou perd Pick actions on joystick, see pixels and scoresPoints clefs du renforcement Pas de superviseur qui connait la solution, seulement une note Le retour d‚Äôinformation est decale (pas immediat) La notion de temps est importante $\\rightarrow$ Systeme dynamique L‚Äôagent qui note a un impact sur la suite des donnees qu‚Äôon va recevoirTestQuel type d‚Äôapprentissage ? Comparaison de CNN pour la vision sur route - 2018 Apprentissage renforce (et pas supervise) Appel au t√©l√©phone - Google ‚Äì 2018 Un ‚Äúmajordome‚Äù prend RDV Plusieurs techniques en meme temps Essentiellement du supervis√© DeepMind StarCraft II combat et explications - 2019 L‚ÄôIA Deepmind Starcraft joue et controles ses persos (les bleus) contre un humain (les rouges) L‚ÄôIA ne joue pas plus vite que l‚Äôhumain (elle a une limite) Apprentissage renforce Helicopter - Stanford Univ. ‚Äì 2008 Apprentissage renforc√© On fait un dessin dans le ciel et on dit a l‚ÄôIA de suivre le dessin le mieux possible M√©lodie travaill√©e - Music VAE - 2018 Non supervis√© Capable d‚Äôextraire des carateristiques Creer un vecteur de la musique initiale et finale Creer des etapes intermediaires en ‚Äúinterpolant‚Äù Re-genere des vecteurs Recommence depuis la creation de vecteurs D√©bat : L‚Äô√âtat doit-il financer les √©coles pre-maternelle ? (3 √† 4 ans) Non ‚Äì Harish Natarajan Oui ‚Äì IBM Debater IA IBM (en vente) Comme Google Essentiellement du supervis√© Techniques en plus pour la comprehension de texte Un duo et l‚Äôartiste cach√© (2019 pour la m√©thode) Non supervis√© On decompose en vecteurs le visage de Macron et celui de l‚Äôartiste original Les mouvements de l‚Äôartistes original se font sur le visage de Macron Classifie les sourcils, la bouche, etc. De AlphaGo a MuZeroBonus: Film sur AlphaGo A massacre des professionnels C‚Äôest comme si nous on voyait le jeu en 2D et AlphaGo en 3D, on est aveugle en comparaison MuZero: Ne donne plus rien (pas de regles, donnees, etc.) Seulement si gagner ou perduUsage futur des differents types d‚ÄôapprentissageLe monde acad√©mique/internet et industriel sont diff√©rents.Transfer MLOn prend un reseau qui fonctionne deja dans un cas et on l‚Äôadapte pour fonctionner dans un autre cas Effacer les dernieres couches Detecter des objets/formes complexes (ex: une petite fille joue au balon) Garder les premieres couches Detecter des formes de bases Ainsi il est tout √† fait possible d‚Äôutiliser un r√©seau neuronal entrain√© pour une t√¢che A pour initier l‚Äôentrainement du r√©seau d‚Äôune t√¢che B proche.IBM IA pour l‚Äôindustrie IBM Watson Recruitement une aide a l‚Äôembauche pour les entreprises Watson solution pour la vente Watson Assistant pour le marketing Watson Decision Plateform pour l‚Äôagriculture IBM Equipement Maintenance Assistant pour am√©liorer la qualit√© et r√©duire la maintenance IBM Watson Supply Chain InsightsSite IBM AI For Industries" }, { "title": "OCVX: TD 1", "url": "/cours/posts/ocvx_td_1/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8, dimension, lieu, plan", "date": "2021-03-15 14:00:00 +0100", "snippet": "Lien de la note Hackmd Analyse en composante principale: algo data mining et reduction de dimensionsPour la reduction de dimension, on garde que les $n$ premieres.Ca se formule comme un probleme d‚ÄôoptimisationProjection de vecteur sur un autre vecteur : produit scalaire.Pour chercher quelles donnees se dispersent le plus, on va chercher un vecteur $w$ telle que la projection ($X.w$) de mes $x$ soit maximale et soit une matrice\\(X=\\begin{bmatrix} x_{11} &amp;amp; x_{12}\\\\ \\vdots &amp;amp; \\vdots\\\\ x_{i1} &amp;amp; x_{i2}\\\\ \\vdots &amp;amp; \\vdots\\\\ x_{n1} &amp;amp; x_{n2}\\end{bmatrix}\\) On cherche a maximiser $Var(X.w)$ sous contrainte que $\\Vert w\\Vert=1$Exemple perceptron (1 neurone)On cherche les parametres du vecteurs normalOn a un probleme qui prend comme origine quelque chose de geometriqueOn cherche a discriminer les ronds rouges des points verts, on a la marge en plus de la separation. On cherche a maximiser la marge telle que tous les echantillons d‚Äôune meme classe vont d‚Äôun cote ou de l‚Äôautre d‚Äôune separatrice.Question 1-1On se place en un premier temps dans le cas de dimension 2, celui du plan euclidien. Soient $x$ et $y$ deux vecteurs de $\\mathbb R^2$, on d√©signe par $\\theta$ l‚Äôangle orient√© (dans le sens direct) entre $x$ et $y$ et par $\\phi$ (resp. $\\psi$) celui entre $x$ (resp. $y$) et la partie positive de l‚Äôaxe des abscisses. Repr√©senter la description pr√©c√©dente par un dessin Exprimer les coordonn√©es de $x$ et $y$ en fonction de leurs normes respectives et des angles $\\phi$ et $\\psi$ En d√©duire une expression du produit scalaire de $&amp;lt;x, y&amp;gt;$ en fonction de $\\theta$ et des normes de $x$ et $y$\\[x,y\\in\\mathbb R^4, &amp;lt;x,y&amp;gt;=x^Ty=\\sum_{i=1}^nx_iy_i\\\\\\Vert x\\Vert=\\sqrt{&amp;lt;x,x&amp;gt;}=\\sqrt{x^Tx}\\\\d(x,y)=\\Vert x-y\\Vert\\\\\\theta(x,y)=\\arccos(\\frac{&amp;lt;x,y&amp;gt;}{\\Vert x\\Vert\\Vert y\\Vert})\\\\\\begin{aligned}&amp;lt;x,y&amp;gt;&amp;amp;=x_1y_1+x_2y_2=\\sum_ix_iy_i\\\\&amp;amp;= \\Vert x\\Vert\\Vert y\\Vert\\cos(\\theta(x,y))\\end{aligned}\\] $\\theta(x,y)=\\arccos(\\frac{&amp;lt;x,y&amp;gt;}{\\Vert x\\Vert\\Vert y\\Vert})$: cette formule est vraie quelque soit la nature de $x$ et $y$.Question 1-2D√©crire le lieu de $\\mathbb R^2$ donn√© par la relation matricielle :\\[\\begin{pmatrix} 1&amp;amp;2\\\\ -1&amp;amp;1\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\end{pmatrix}\\le\\begin{pmatrix} 0\\\\ 0\\end{pmatrix}\\] ensemble des vecteurs tels que \\(\\{x\\in\\mathbb R\\vert&amp;lt;x.y&amp;gt;\\ge0\\}\\)$y\\neq0$ et \\(\\{y\\}=\\{x\\in\\mathbb R^2\\vert&amp;lt;x.y&amp;gt;=0\\}\\)\\[\\begin{cases}x+2y\\le0\\\\-x+y\\le0\\end{cases}\\]Prenons la premiere equation et changeons $\\le$ en $=$ pour la resoudre. $x+2y=0$ est de la forme $ax+by=0$. Pour une equation de la forme $ax+by=0$: \\(\\vec n=\\begin{pmatrix} a\\\\ b\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u=\\begin{pmatrix} -b\\\\ a\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)On peut donc en deduire:\\(\\vec n_1=\\begin{pmatrix} 1\\\\ 2\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u_1=\\begin{pmatrix} -2\\\\ 1\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)On cherche le demi-plan oriente negativement par rapport a:\\(&amp;lt;\\vec n_1,\\begin{pmatrix} x\\\\ y\\end{pmatrix}&amp;gt;\\le0\\)Prenons la seconde equation et faisons de meme\\(-x+y=0\\\\\\vec n_2=\\begin{pmatrix} -1\\\\ 1\\end{pmatrix}\\text{ vecteur normal}\\\\\\vec u_2=\\begin{pmatrix} -1\\\\ -1\\end{pmatrix}\\text{ vecteur directeur}\\\\\\)L‚Äôintersection des 2 espaces verifie les 2 inegalites.Question 1-3Repr√©senter le lieu de $\\mathbb R^3$ d√©crit par la relations $x_1 +x_2 +x_3 \\ge 0$.On cherche:\\(\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}\\in\\mathbb R^3\\\\\\)tel que $x_1 +x_2 +x_3 \\ge 0$\\(&amp;lt;\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix},\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}&amp;gt;\\ge0\\)On va chercher le lieu de $\\mathbb R^3$ ou $&amp;lt;\\vec n.\\vec x&amp;gt;=\\vec n^T\\vec x=0$. On prend les point apres et dans le plan.Question 2-6√âcrire param√©triquement : la droite de $\\mathbb R^2$ de vecteur directeur $(1,‚àí1)$ et passant par $(2,3)$; le plan de $\\mathbb R^3$ donn√© par l‚Äô√©quation $x_1 +x_2 +x_3 = 2$.\\[\\begin{aligned}(D)&amp;amp;=\\{x\\in\\mathbb R^2,x=\\lambda u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\} \\text{ representation parametrique}\\\\&amp;amp;= \\{\\vec x\\in\\mathbb R^2,&amp;lt;\\vec n,\\vec x&amp;gt;=0\\}\\\\&amp;amp;=\\{n^Tx=0\\}\\\\&amp;amp;=\\{n_1x_1+n_2x_2=0\\} = \\text{ representation implicite}\\\\\\end{aligned}\\\\n=\\begin{pmatrix} n_1\\\\ n_2\\\\\\end{pmatrix}\\\\x=\\begin{pmatrix} x_1\\\\ x_2\\\\\\end{pmatrix}\\]$(A)=x+(0,1)$ la droite qui passe par $(0,1)$ et de vecteur directeur $\\vec u$\\[\\begin{aligned}(A)&amp;amp;=(0,1)+(D) = (0,1)+\\{\\lambda\\vec u,\\lambda\\in\\mathbb R\\} \\text{ avec } \\vec u=\\begin{pmatrix} u_1\\\\ u_2\\\\\\end{pmatrix}\\\\&amp;amp;= (0,1)+\\{(\\lambda u_1,\\lambda u_2),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(0,1)+(\\lambda u_1,\\lambda u_2),\\lambda\\in\\mathbb R\\}=\\{(\\lambda u_1, 1+\\lambda u_2),\\lambda\\in\\mathbb R\\}\\end{aligned}\\]\\[\\vec n^{\\perp}x=c\\Rightarrow n_1x+n_2y=c\\\\\\Rightarrow ax+by+c=0\\]On obtient l‚Äôequation implicite d‚Äôune droite affine.\\(\\rightarrow \\vec n = \\begin{pmatrix} a\\\\ b\\\\\\end{pmatrix} \\text{ et }\\vec u = \\begin{pmatrix} -b\\\\ a\\\\\\end{pmatrix} \\text{ et passant par } (0,-\\frac{c}{b})\\)Ecriture parametrique de: la droite de $\\mathbb R^2$ de vecteur directeur $\\vec u= (1,-1)$ et passant par $(2,3)$ $(A)$\\[\\begin{aligned}(A) &amp;amp;= (2,3)+\\{\\vec x\\in\\mathbb R^2, \\vec x=\\lambda\\vec u,\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= (2,3) + \\{(\\lambda,-\\lambda),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(2,3)+(\\lambda,-\\lambda),\\lambda\\in\\mathbb R\\}\\\\&amp;amp;= \\{(2+\\lambda,3-\\lambda),\\lambda\\in\\mathbb R\\}\\end{aligned}\\] le plan de $\\mathbb R^3$ donne par $x_1+x_2+x_3=2$ $(P)$. les points de $(P)$ sont les zeros de l‚Äôequation $x_1+x_2+x_3-2=0$ \\[x_1+x_2+x_3=2\\\\&amp;lt;\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}, \\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}&amp;gt;=2\\Leftrightarrow&amp;lt;n,x&amp;gt;=2 \\text{ avec } \\vec n=\\begin{pmatrix} 1\\\\ 1\\\\ 1\\end{pmatrix}\\text{ et }\\begin{pmatrix} x_1\\\\ x_2\\\\ x_3\\end{pmatrix}\\]$(A)=(2,0,0)\\in(P)$, $B=(0,2,0)$, $C=(0,0,2)\\in(P)$$\\vec{AB}$ et $\\vec{AC}$, $\\vec{AB}=(-2,2,0)$, $\\vec{AC}=(-2,0,2)$\\[\\begin{aligned}(P) &amp;amp;= (2,0,0)+\\lambda_1\\vec{AB}+\\lambda_2\\vec{AC}, (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\\\&amp;amp;= (2,0,0)+\\{\\vec{x}\\in\\mathbb R^3,\\vec{x}=\\lambda_1\\vec{AB}+\\lambda_2\\vec{AC},(\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= (2,0,0)+\\{\\lambda_1(-2,2,0)+\\lambda_2(-2,0,2),(\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= (2,0,0)+\\{(-2\\lambda_1-2\\lambda_2,2\\lambda_1,2\\lambda_2), (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\\\&amp;amp;= \\{(2-2\\lambda_1-2\\lambda_2,2\\lambda_1,\\lambda_2) (\\lambda_1,\\lambda_2)\\in\\mathbb R^2\\}\\end{aligned}\\]Question 2-7Dessiner le lieu de $\\mathbb R^2$ d√©crit par les contraintes\\[\\begin{pmatrix} -1 &amp;amp; 2\\\\ 1 &amp;amp; 1\\\\\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\\\\\end{pmatrix}\\le\\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\] D√©crire chacun des composants du lieu g√©om√©trique pr√©c√©dent param√©triquement Que change le fait de rajouter la contrainte $x‚àí3y \\le 6$ ? Quel lieu correspond √† la situation o√π l‚Äôon change le sens de toutes les in√©galit√©s ?On cherche le lieu de $\\mathbb R^2$ definit par\\[\\begin{pmatrix} -1 &amp;amp; 2\\\\ 1 &amp;amp; 1\\\\\\end{pmatrix}\\begin{pmatrix} x\\\\ y\\\\\\end{pmatrix}\\le\\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\\\\\begin{cases} -x+2y=-1\\\\ x+y=1\\end{cases}\\\\(D1)=-x+2y=-1\\Leftrightarrow \\underbrace{-x+2y+1}_{ax+by+c=0}=0\\\\\\vec{n_1} = \\begin{pmatrix} -1\\\\ 2\\\\\\end{pmatrix} \\text{ et }\\vec{u_1} = \\begin{pmatrix} -2\\\\ -1\\\\\\end{pmatrix}\\]On a le point particulier $(0;-\\frac{1}{2})$\\[(D_2)= x+y-1=0\\\\\\vec{n_2} = \\begin{pmatrix} 1\\\\ 1\\\\\\end{pmatrix} \\text{ et }\\vec{u_2} = \\begin{pmatrix} -1\\\\ 1\\\\\\end{pmatrix}\\]On a le point particulier $(0;1)$" }, { "title": "TIFO: Implementation", "url": "/cours/posts/tifo_implementation/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, max tree, FFT", "date": "2021-03-11 17:00:00 +0100", "snippet": "Lien de la note HackmdFASTER-FASTER-FASTER!!!Introduction Efficacite Taille des images Contrainte sur le temps de reponse Contrainte sur le materiel (telephone‚Ä¶) Solution Bien penser ses algorithmes (et ss structures de donnes) Revoir son implementation sur CPU Eventuellemnt envisager une implementation sur GPU Bien penser ses algorithmes Representation des images ‚Ä¶Repenser les algorithmes FFT (Fast Fourier Transform) ‚Ä¶Representation des imagesComment representer une image Matrice Vecteur Arbre/grpah Max Tree, Min Tree Tree of Shapes‚Ä¶ ‚Ä¶Matrice, vecteur: bien respecter le cache de la amchine !Max Tree:Image:Max-Tree CorrespondantRacine de l‚Äôarbre: image entiere On part du $\\min$ de l‚Äôimage Des que le $\\min$ separe 2 regions, on a 2 branches dans notre arbre Une branche de l‚Äôarbre, c‚Äôest une region de l‚Äôimage. Un noeud correspond a tous les pixels Les feuilles, si elles sont petites et nombreuses elles sont peut-etre que du bruitExempleCalcul de l‚Äôouverture ultime Long dans le cas general Solution: utilisation du max-tree On enleve les petites regions et on fait la difference entre l‚Äôimage d‚Äôorigine et l‚Äôimage obtenue. On continue sur les zones plus grosses et on regarde chaque fois le contraste obtenu.On peut estimer quel est le motif le plus contraste et le garder.On a des residus en coupant les branches.On parcours l‚Äôimage en profondeur avec le niveau de contraste:UO(noe, parent_leve, max_contrast) { node.r=max(parent_level-node.level, max_contrasy) for all child c UO(c, node_level.r)}Resultats: Format Nb of pixels Time (ms) 128x128 16384 0,18 256x256 65536 2,39 512x512 262144 12,01 1024x1024 1048576 52,04 2048x2048 4194304 235,53 Un probleme difficile a la base est rendu plus simple et plus rapide en changeant le codage de l‚ÄôimageOn calcule l‚Äôouverture ultime et on recupere tous les objets saillantsPour recuperer le texte, on relance l‚Äôouverture ultime sur une partie de l‚Äôimage Repenser les algorithmes Exemple FFT Implementation des filtres L‚Äôimage integrable Calcul rapide FFT (1965 - Cooley et Tukey) (Gauss 1805??) The DFT:\\[x(l)=\\sum_{k=0}^{N-1}x(k)e^{-\\frac{2j\\pi kl}{N}}, l=0,...,N-1\\]avec $N$ complexe mults, $N-a$ complexe add pour chaque $I$ $O(N^2)$Exploiter la symetrie:\\[\\begin{aligned}W_N&amp;amp;=e^{-\\frac{2j\\pi}{N}}\\\\W_N^{k(N-n)}&amp;amp;=W_n^{-kn}=(W_N^{kn})^* &amp;amp;(W_N^{kN}=1)\\\\W_N^{k(n)}&amp;amp;=W_N^{k(N+n)}=W_N^{(k+N)n}\\end{aligned}\\]On suppose que $N=2^m$\\[\\begin{aligned}X(l)&amp;amp;=\\sum_{k\\text{ pair}}x(k)W_N^{lk}+\\sum_{k\\text{ impair}}x(k)W_N^{lk}\\\\&amp;amp;=\\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi2kl}{N}} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi2(k+1)l}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)W_n^{2kl} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)W_N^{(2k+1)l}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)(W_n^2)^{kl}+W_n^l\\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)(W_N^2)^{kl} &amp;amp;W_n^2=W_{\\frac{N}{2}}\\end{aligned}\\] $\\frac{N}{2}$ DFT des echantillons pairs, $\\frac{N}{2}$ DFT des echantilons imapairs\\[X(l)=X_p(l)+W_N^lX_i(l)\\] Somme de 2 DFTs de $\\frac{N}{2}$ echantillons $2\\frac{N}{2}^2+N$ mutliplications Passe de $O(N^2)$ a $O(N\\log N)$L‚Äôimage integraleSouvent besoin de calculer des moyennes/ecart-types dans une imageOn passe un masque sur une imageLa valeur obtenue est la sommes des pixelsSi on veut calculer l‚Äôaire d‚Äôun rectangle aligne sur les axes:\\[Aire(ABCD)=C-B-D+A\\]Implementation des filtres Decomposition des convolutions (filtres separables) $N\\times N\\to N+N$ La taille du filtre a un impact sur la vitesse d‚Äôexecution Prise en compte des bordures?Implementation sur CPU Utilisation du parallelisme Utilisation des instruction SIMD Auto-vectorisation Intrinsics SIMD Boost::simd ‚Ä¶CPUSIMD Single instruction multiple data MMX, SSE, AVX, NEON‚Ä¶ Registres sous formes de vecteurs Bien adapte a l‚ÄôimageSIMD: un peu d‚Äôhistoire 1997 jeu d‚Äôinstruction MMX sur P166 (intel) L‚Äôordinateur multimedia - Regsitre 64bits paratages avec le FPU 1997 jeu d‚Äôinstrucutin - 3DNow ! (AMD) 1999 jeu d‚Äôinstruction SSE - Registres 128bits SSE2, SSE3, SSE4 - Registres 128bits AVX - Registres 512 256bits AVX512 - Registres 512bits Neon sur ARMSIMD Usage Par le compilateur: Active sur GGC avec l‚Äôoption -ftree-vectorize (par defaut active avec -O3) Renseigner l‚Äôoption -march=(corei7,native...) On peut avoir plus d‚Äôinfo avec les options -fopt-info-vec-* (-fopt-info-vec-optimized -fopt-info-vec-missed) Sorties: knn.cpp.229: note: LOOP VECTORIZED (attention: plusieurs passes) Auto-vectorisationfor (std::size_t x = 0; x &amp;lt; l; ++x) { output_image[x] = input_image1[x] + input_image2[x];} // en complet desaccord avec notre coding styleEntrees: -Wall -O3 -g -Wextra -Werror -m64 -march=native -ftree-vectorize -std=c++11 -fopt-info-vec-optimized #-fopt-info-vec-missedSorties: Par le compilateur (auto-vectorisation) Pas toujours facile s‚Äôassure que les donnees soient alignees (quasi impossible en cpp :-( ) __attribute__((aligned(TL_IMAGE_ALIGNEMENT))) std::align Alignas(.) aligned_alloc __restrict__ assume dans ICC Bonnes pratiques: Utiliser des indices plutot que des pointeurs Array of Structures vs Structure of Arrays Ne pas interrompre une boucle for (k = 0 ; k &amp;lt; size_vect; k++) { double t = v_example[k] - data[k_data++]; res += t * t; // if (res &amp;gt; tresh) { // breaks; // }}res *= -g;return exp(res) SIMD - intrinsics Possible de les utiliser en c/c++ Exemple:for (std::size_t x = 0; x &amp;lt; l; x+=16) { __m128i v_input_image1 = _mm_loadu_si128((const __m128i*)(input_image1 + x)); __m128i v_input_image2 = _mm_loadu_si128((const __m128i*)(input_image2 + x)); __m128i v_output1 = _mm_add_epi8(v_input_image1, v_input_image2); _mm_store_si128((__m128i*)(output_image+x), v_output1);} Probleme d‚Äôalignement des donnees aligned_alloc Difficilement portable Function Multiversioning (GCC 4.8) Utile pour la portabilite du programme __attribute((target(&quot;default&quot;)))int foo() { // The default version of foo}__attribute((target(&quot;sse4.2&quot;)))int foo() { // foo version for SSE4.2}__attribute((target(&quot;arch=atom&quot;)))int foo() { // foo version for the Intel ATOM processor}Boost::simd Permet d‚Äôecrire de maniere agnostique vis-a-vis de la vectorisation Le code devient portable Vectorisation vers certains processeurs gratuite et pour d‚Äôautres nonImplementation sur GPUUne fois qu‚Äôon a pousse nos algos a fond sur CPU‚Ä¶ Implementation sur GPU Cuda OpenCL Compute Shaders ‚Ä¶ Compute Shaders Glsl ‚Äúportable‚Äù ou autreOn a plein de threads dans chaque work groupConclusion Pas de points ‚Äúincontournables‚Äù Reflechir a notre implem pour qu‚Äôelle soit la plus efficace possible" }, { "title": "TIFO: Le bruit", "url": "/cours/posts/tifo_bruit/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, bruit", "date": "2021-03-11 16:00:00 +0100", "snippet": "Lien de la note HackmdModelisationAmelioration vs restauration: Amelioration: on ne sait pas ou on va Restauration: on a un modele que l‚Äôon souhaite atteindreModele de degradatation (dans le domaine spatial) $I_{\\text{deg}}=h*I_{\\text{ori}} + n$ $h\\to$ la degradation (optique, flou‚Ä¶) $n\\to$ le bruit Le bruit \\(I_{\\text{deg}} = h*I_{\\text{ori}} + n\\)On regarde $n$.Genant pour le cote esthetique que pour les traitements $\\Rightarrow$ Il faut donc reduire ce bruit Reduction de bruit Estimation ? Connaissances a priori ou pas Reduction Sans degrader le signal‚Ä¶ Bruit additifOn considere souvent ici le bruit additifFonction de repartition peut varier: Gaussienne, (impulsion) periodiqueEstimationSoit le capteur est connu: Photos d‚Äôune zone bien homogene dans de bonnes conditions d‚ÄôeclairementSoit le capteur pas connu: Analyse de quelques zonesExempleOn cherche dans les zones les plus homogenes l‚Äôecart-type des valeurs.ReductionRevisite des filtres classiques Mean filter Arithmetic mean Geometric mean Harmonic mean ‚Ä¶ Median + variantes Midpoint, alpha-trimmed Adaptative Gaussien selectif ‚Ä¶ Approche par ondelette l‚Äôimage $f(n)$ est bruite par $q(n)$ $g(n)=f(n)+q(n)$ L‚Äôestimation de la correction $F_c=W^{-1}T_{\\lambda}Wg$ $T_{\\lambda}p(y)=p(y)$ si $\\vert p(y)\\vert\\gt\\lambda$, $0$ sinon $T_{\\lambda}p(y)=p(\\lambda)\\pm\\lambda$ si $\\vert p(y)\\vert \\gt \\lambda$, $0$ sinon Resultat: ToS (Tree of Shape) Bruit = feuilles dans l‚Äôarbre Couper les feuilles de l‚Äôarbre pour affiner le resultat NLMeans Au lieu de faire la moyenne sur un voisinage, on cherche des patchs ressemblants Resultats:On a une image a laquelle on rajoute du bruit et qu‚Äôon debruite avec NLMeansDegradation periodiques Moi devant les cours de TIFO quand je me dit que je reviserai plus tardSpectre (eclairci):On a des taches aux coins qui apparaissent.Definition du filtre dans le domaine frequentiel:On fait un rejecteur (on met a 0 des frequences precises dans le spectre) Fait un peu grossierementOn multiplie le spectre et l‚Äôimage obtenue par le filtre, supprimant theoriquement l‚Äôorigine des degradations periodiques:Resultat:Si on fait la difference entre l‚Äôimage d‚Äôorigine et debruitee:La partie convolutionnelle Le bruit: $I_{\\text{deg}} = h*I_{\\text{ori}} + n$ On regarde $h$ Degradations convolutionnelles comme du flou de bouge Reduction $\\Leftrightarrow$ deconvolution Blind deconvolution: Seul $I_{\\text{deg}}$ connu Non-Blind deconvolution: $I_{\\text{deg}}$ et $h$ sont connnus Degradation: $g=h*f+n$Passage en frequentiel: $G(u,v)=H(u,v)F(u,v)+N(u,v)$ $h\\to$ point spread function (PSF) Estimation de $F$ (l‚Äôimage non bruitee) On a envie de dire: $g=h*f$ d‚Äôou une solution ‚Äúfacile‚Äù $F_e(u,v)=\\frac{G(u,v)}{H(u,v)}$ Toutefois, il y a le bruit additif $F_e(u,v)=F(u,v)+\\frac{N(u,v)}{H(u,v)}$ Quand $H\\to0$, $\\frac{N}{H}\\to+\\infty$ $\\Rightarrow$ limiter le support Solution:\\[F_e(u,v)=F(u,v)+\\frac{N(u,v)}{H(u,v)}\\] $h/H$ connu ou pas?Filtre de Wiener Mean square error entre $f$ et $f_e$: $e=E[(f-f_e)^2]$ On cherche $W$ tel que: $\\frac{1}{NM}E[\\vert F-F_e\\vert^2]$ soit $\\min$ $F_e=WG=WHF+WN$ $F-F_e=(1-WH)F-WN$ $e=\\frac{1}{NM}\\sum\\sum\\vert (1-WH)F-WN\\vert^2$ Expression en frequentiel de $f_e$ (en fonction de $H$) en derivant e en fonction de $W$\\[F_e = \\biggr[\\frac{1}{H}\\frac{\\vert H\\vert^2}{\\vert H\\vert^2+\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}}\\biggr]G\\] Filtre de Wiener:\\[w = \\biggr[\\frac{H^c}{\\vert H\\vert^2+\\underbrace{\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}}}_{=K}\\biggr]\\]Probleme: $\\frac{\\vert N\\vert^2}{\\vert F\\vert^2}$ pas connu $\\rightarrow$ mais considere constant $K$Degradation Comment determiner $H$ ? Faire une image d‚Äôune impulsion $\\to$ determine entierement $H$ Analyser une image et essayer de determiner sur des frontieres ou des impulsions la reponse $H$ Modeliser la degradation (flou de bouger‚Ä¶) $\\to$ Tres difficile la plupart du tempsQuantification des resultats Rapport signal sur bruit SNR $\\sum\\vert F(u,v)\\vert^2\\sum\\vert N(u,v)\\vert^2$ Mean Square Error MSE entre l‚Äôimage et l‚Äôestimation $\\frac{1}{N}\\sum (f(x,y)-f_e(x,y))^2$ Note: SNR=$\\sum\\frac{(fe(x,y)^2)}{MSE}$ Conclusion Restauration, amelioration Difficile dans le cas general " }, { "title": "TIFO: Filtrage, partie 2", "url": "/cours/posts/tifo_filtrage_partie_2/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, signal, Fourier, convolution", "date": "2021-03-11 15:00:00 +0100", "snippet": "Lien de la note HackmdSignal Representation Mathematiques d‚Äôun phenomene physiqueTraitement du signal Elaboration, detection et interpretation des signauxClassification des signaux Morphologique: continu/discret Spectrale: Bande de frequence BF/HF Energie: Energie finie/Puissance moyenne finie Typologie: deterministe/aleatoire Periodicite: non peridique/$x(t)=x(t+T)$Energie Energie $w_x$ d‚Äôun signal $x$\\[W_x=\\int_{-\\infty}^{+\\infty}\\vert x(t)\\vert^2dt\\] Les signaux a energie finie verifient la condition:\\[W_x=\\int_{-\\infty}^{+\\infty}\\vert x(t)\\vert^2\\lt+\\infty\\] Les signaux a support borne (cad duree limitee) sont a ernegie finiePuissance Puissance moyenne $P$ du signal $x$\\[P_x=\\lim_{T\\to+\\infty}\\frac{1}{T}\\int_{-\\frac{T}{2}}^{\\frac{T}{2}} \\vert x(t\\vert^2dt)\\] Energie finie $\\Rightarrow$ puissance moyenne nulle\\[W_x\\lt+\\infty\\Rightarrow P_x=0\\] Puissance moyenne finie $\\Rightarrow$ energie infinie\\[0\\lt P_x\\lt+\\infty\\Rightarrow W_x\\to+\\infty\\] Ex: les signaux periodiquesSignaux classiquesPorte\\[\\Pi_{\\frac{T}{2}}=\\begin{cases} 1 &amp;amp;\\text{si } t\\in[-\\frac{T}{2};\\frac{T}{2}]\\\\ 0 &amp;amp;\\text{ailleurs}\\end{cases}\\]Echelon d‚ÄôHeavyside\\[u(t)=\\begin{cases} 0 &amp;amp;\\text{si } t\\lt0\\\\ 1 &amp;amp;\\text{si } t\\ge0\\end{cases}\\]Signe\\[sgn(t) =\\begin{cases} -1 &amp;amp;\\text{si } t\\lt0\\\\ 0 &amp;amp;\\text{si } t=0\\\\ 1 &amp;amp;\\text{si } t\\gt0\\end{cases}\\]Triangulaire\\[\\triangle_T(t)=\\begin{cases} \\frac{1-\\vert T\\vert}{T} &amp;amp;\\text{si } \\vert t\\vert T\\\\ 0 &amp;amp;\\text{ailleurs}\\end{cases}\\]Gaussienne\\[g(t) = \\frac{1}{\\delta\\sqrt{2\\pi}}e^{-\\frac{t^2}{2\\delta^2}}\\]Sinus cardinal\\[sinc(t) = \\frac{sin(t)}{t}\\]Series de Fourier On consider les fonctions $g_n(t)$\\[g_n(t) = e^{2j\\pi\\frac{nt}{T}}\\] Que vaut\\[&amp;lt;g_n(t),g_m(t)&amp;gt; = \\frac{1}{T}\\int_Tg_n(t)g_m^*(t)dt=\\begin{cases} 0 &amp;amp;\\text{si } n\\neq m\\\\ 1 &amp;amp;\\text{si } n= m\\end{cases}\\]avec $g_m^*$ le conjugue dans les complexe Soit $f(t)$ periodique de periode $T(T\\gt 0)$. Un signal 1D periodique peut etre vu comme une somme de sinusoides\\[f(t) = \\sum_{n=-\\infty}^{+\\infty}C_ng_n(t)\\]Comment trouver $C_i$ ?\\[\\begin{aligned}\\frac{1}{T}\\int f(t)g_i^*(t)dt &amp;amp;= \\frac{1}{T}\\int(\\sum C_ng_n(t))\\int g_i^*(t)dt\\\\&amp;amp;= \\frac{1}{T}\\int(...+C_{i-1}g_{i-1}(t)+C_{i}g_{i}(t)+C_{i+1}g_{i+1}(t)+...)g_i^*(t)dt\\\\&amp;amp;= \\frac{1}{T}\\int(...+C_{i-1}g_{i-1}(t)g_i^*(t)+C_{i}g_{i}(t)g_i^*(t)+C_{i+1}g_{i+1}(t)g_i^*(t)+...)dt\\\\&amp;amp;=...+\\frac{1}{T}\\int C_{i-1}g_{i-1}(t)g_i^*(t)dt + \\frac{1}{T}\\int C_{i}g_{i}(t)g_i^*(t) + \\\\ &amp;amp;\\frac{1}{T}\\int C_{i-1}g_{i-1}(t)g_i^*(t)dt+...\\\\&amp;amp;=...+C_{i-1}\\underbrace{\\frac{1}{T}\\int g_{i-1}(t)g_i^*(t)}_{=0 \\text{ car } i-1\\neq i}+ C_i\\underbrace{\\frac{1}{T}\\int g_{i}(t)g_i^*(t)}_{=1} + C_{i+1}\\underbrace{\\frac{1}{T}\\int g_{i+1}(t)g_i^*(t)}_{=0 \\text{ car } i+1\\neq i}\\\\&amp;amp;= C_i\\end{aligned}\\]Harmoniques$C_n$: harmoniques On les sommes pour obtenir la sinusoides resultat $C_0$: frequence continue $C_1$: frequence fondamentale ‚Ä¶ $C_n$: $n^{ieme}$ harmonique f reel $\\Rightarrow$ $C_n=C_{-n}^(f(t)=f^(t))$Frequences Basses frequences Lentes variations Zones presque uniformes Hautes frequences Variations rapides Contours/coins Se retrouve dans les images Quand des details apparaissent, on monte dans les frequencesSeries et transformees de FourierSpectre D‚Äôamplitude: $\\vert C_n\\vert$ De phase $Arg(C_n)=arctg(-\\frac{b_n}{a_n})$ De puissance $\\vert C_n\\vert^2$ $f(t)$ reel $\\Rightarrow$ spectre d‚Äôamplitude symetrique Relation de PARSEVAL: Il y a conservation de la puissance de la representation temporelle a la representation frequentielle.On ne perde pas d‚Äôinformation lorsqu‚Äôon passe de l‚Äôun a l‚Äôautre.SignauxOn considere jusqu‚Äôa present des signaux periodiques On peut generaliser en prenant $T\\to+\\infty$On defini $TF{x(t)}$\\[X(f) = \\int_{-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}dt\\]On defini $TF^{-1}{x(t)}$\\[x(t)=\\int_{-\\infty}^{+\\infty}X(f)e^{+2j\\pi ft}df\\] Toutes les infos contenues dans le signal sont contenues dans le spectreTransformee usuellesPorteTransformee de Fourier: Sinus cardinalConstanteTransformee de Fourier: FondamentalePeigne de DiracTransformee de Fourier: un autre Peigne de DiracExistence de la transformee de $f(t)$ $f(t)$ bornee Integrale de $f(t)dt$ existe Les discontinuires de $f(t)$ sont en nombre limite On s‚Äôautorisera systematiquement a faire la transformee de Fourier de l‚ÄôimageProprietes Linearite\\[Kf(t)+g(t) \\Leftrightarrow KF(t)+G(t) \\text{ } K\\text{ complexe}\\] Similitude: Une dilatation dans le domaine temporel correspond a une contraction dans le domaine frequentiel $f(at)\\Leftrightarrow\\frac{1}{\\vert a\\vert}F(\\frac{f}{a})$ (a reel) Derivee: $\\frac{dx(t)}{dt}\\Leftrightarrow 2i\\Pi fX(f)$ $\\frac{dx(f)}{df}\\Leftrightarrow -2i\\Pi fX(t)$ Dans notre cas: Signal borne et echantilloneSoit le pic de Dirac $\\delta(t)$:Soit le pic de Dirac $\\delta(t_0)$:\\[\\delta(t_0)=\\delta(t-t_0)\\\\f(t)\\delta(t_0)=f(t_0)\\]Soit le peigne de Dirac $–®(t)$:\\[\\sum_{n=-\\infty}^{+\\infty}\\delta(t-nT)\\]$f(t).–®(t_0)=$ Une fonction echantillonee, c‚Äôest une fonction multipliee par un peigne de Dirac.Transformee de FourierDans notre cas: Signal discret (echnatillonne) + support borne Transformee de Fourier Discrete \\(\\begin{aligned}&amp;amp;X(f)=\\int_{-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}dt &amp;amp;X(f)=\\sum_{t=-\\infty}^{+\\infty}x(t)e^{-2j\\pi ft}\\end{aligned}\\)\\(X(l)=\\sum_{k=0}^{N-1}x(kT_e)e^{-2j\\pi lf_ekT_e}\\) \\begin{aligned}&amp;amp;X(l)=\\sum_{k=0}^{N-1}x(t)e^{\\frac{-2j\\pi}{N} kl} &amp;amp;X(k)=\\sum_{k=0}^{N-1}x(t)e^{\\frac{2j\\pi}{N} lk} \\end{aligned}Notes$F_e$ frequence d‚Äôechantillonnage $X(0)\\to-2F_e(/0)$ $X(N-1)\\to +2F_e(/+4F_e)$ Pas en frequence: $F_e/N$Calcul rapide de la TFDFast Fourier Transform (1965 - Cooley et Tukey\\[\\begin{aligned}X(l)&amp;amp;=\\sum_{k=0}^{N-1}x(k)e^{-\\frac{2j\\pi kl}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi 2kl}{N}} + \\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi 2(k+1)l}{N}}\\\\&amp;amp;= \\sum_{k=0}^{\\frac{N}{2}-1}x(2k)e^{-\\frac{2j\\pi 2kl}{N}} + e^{-\\frac{2j\\pi l}{N}}\\sum_{k=0}^{\\frac{N}{2}-1}x(2k+1)e^{-\\frac{2j\\pi2kl}{N}}\\end{aligned}\\] Pour calculer la TFD sur un signal de taille $N$, on calcul la transformee de Fourier sur les coeeficients pairs $(\\frac{N}{2})$ et la transformee de Fourier sur les coefficients impairs $(\\frac{N}{2})$‚Ä¶ et recursivementDans notre cas (Image) Signal 2D: TF2D (Transformee de Fourier a 2 dimensions)Visualisation du spectre:On peut aller de $-2F_e$ a $2F_e$ Representation pas pratique car le max d‚Äôinformation se retrouve dispatche aux differents angles.On interverti les cadrants. Les basses frequences se retrouvent au centreResultat:La convolutionReponse impulsionnelle ?Reponse a une impulsion $\\delta(t)$, cad envoyer un pic de Dirac unitqire et recupere la reponse impulsionnelle du filtre h(t). Cela caracterise le filtre.On peut en deduire pour n‚Äôimporte quel signal la sortie du filtre.La reponse du filtre est donnee par un produit de convolution\\[y(t)=x(t)\\times h(t)=\\int_{-\\infty}^{+\\infty}x(u)h(t-u)du\\]Reponse impulsionnelleSi le signal est une serie d‚Äôimpulsions ? On calcule la reponse du filtre a la 1$^{ere}$ impulsion On calcule la reponse de la seconde impulsion De meme pour la 3$^{eme}$ Par le principe de supperposition, les reponses s‚Äôadditionnent C‚Äôest ce qu‚Äôon fait lors du produit de convolution.Proprietes Commutative: $f(t)* g(t)=g(t)* f(t)$ Distributive: $(x(t)+y(t)) * g(t) = x(t) * g(t)+y(t) * g(t)$ Associative: $(x(t)* y(t))* z(t)=x(t)* (y(t)* z(t))$Theoreme de Plancherel Temps Frequences Convolution $*$ Multiplication $.$ Multiplication $.$ Convolution $*$ Autre propriete\\(f&#39;*g=f*g&#39;=(f*g)&#39;\\)Consequences du lien convolution $\\leftrightarrow$ multiplication Spectre d‚Äôun signal echantillonee Revisite du filtrage Passe haut Passe bas Passe Bande Rejecteur DeconvolutionAutres consequences: DoG - Difference de gaussiennes LoG - Laplacien d‚Äôune gaussienneSpectre d‚Äôun signal echantillonne:$f(t)–®(t_0)=$Dans le domaine frequentiel: La TF du peigne de Dirac est un autre peigne de Dirac plus espace Le signal se repete a l‚Äôinfini, on n‚Äôa besoin de connaitre qu‚Äôun espaceRevisite du filtragePasse haut / Passe Bas/ Passe Bande / Rejecteur On a un signal qu‚Äôon veut filtrer pour enlever le bruit On passe en frequenciel et on a le spectre du signal Les hautes frequences sont du bruit On defini un signal pour les enlever 1 sur toutes les basses frequences 0 partout ailleurs On multiplie les 2 On obtient le spectre supprime de toutes les bases frequences On fait l‚Äôinverse de la TF et on obtient le signal sans les hautes frequencesEn pratique, est-ce qu‚Äôon fait tout ca ?Non.On peut faire l‚Äôinverse Prendre le filtre defini Faire l‚Äôinverse et de le passer en temporel en temporel, la porte devient un sinus cardinal Convoluer le filtre avec le signal On obtient notre signal filtreAutre consequenceConvolution $f‚Äô=f*h\\Rightarrow F\\times H = F‚Äô$Deconvolution $\\frac{F‚Äô}{H} = F\\to$ domaine temporel Tres difficile si on ne connait pas le filtre initial Probleme des 0 (ou des valeurs tres petites dans $H$) Si on floute le visage de quelqu‚Äôun pour anonymat avec un filtre gaussien, on peut arriver a deconvoluer et retrouver le visage d‚Äôorigine (tres difficile en pratique) Il faudrait mettre un gros carre noir et non flouter le visageDetection de bord ($f$ gauss)‚Äô$\\to f$guass‚Äô (la derivee de la gaussien est connue formellement) Realise a la fois le lissage et la derivee LoG Laplacient d‚Äôune gaussienneDog Difference de gaussienneFiltrage Passe Bas Description Coef central superieur ou egal aux autres Autres coefs positifs Effet Pixel central devient une moyenne ponderee des voisins Les regions homogenes sont peut changees Les frontieres sont etalees Reduit le bruit Passe Haut Description Coef central positif et eleve Autres coefs petits, negatifs ou nuls La somme des coefficients est nulle Effet Zones homogenes: perte de la notion d‚Äôintensite Frontieres sont renforcees Proprietes de la TF2DLe module de l‚Äôimage ne change pasLe module change mais la phase est invariante a la rotationImpact du flou Cela veut dire que les hautes frequences sont reduites/degradees.Si on bouge, on a un flou directionnel, cad on a preserve l‚Äôinformation dans un sens et perdu dans l‚Äôautre.Skew estimationApplication:On a un document qui passe dans un scanner, il n‚Äôest pas forcement droit et on veut corriger l‚Äôorientation.On voit la rotation dans le spectre et on refait une transformee de Fourier.On peut estimer l‚Äôorientation du fichier d‚Äôorigine.Autres transformations Short Term Fourier Transform Discret Cosinus Transform Ondelettes Radon Wigner Hilbert ‚Ä¶Transformee en cosinus discreteOn fait la transformee de Fourier sur une base de sinusoide reel (utilise en JPEG)Probleme definiton varie d‚Äôun ouvrage a un autre Pour le JPEG, l‚Äôencodeur et le decodeur peuvent utiliser une transformee differenteShort Term Fourier Transform probleme: FT: soit le temps, soit la frequence Solution: ne considerer que des petits intervalles\\[X(f,t&#39;)=\\int_{-\\infty}^{+\\infty}x(t)w^c(t-t&#39;)e^{-2j\\pi t}dt\\] Impact de la taille de w W etroit $\\Rightarrow$ localisation temporelle correcte mais mauvaise resolution frequentielle W large $\\Rightarrow$ localisation temporelle imprecise mais bonne resolution frequentielle Transformee en ondelettes Avantages: FT: soit le temps, soit la frequence STFT: diffculte de regler la taille de w et taille fixee une fois pour toutes Transformee en ondelette: Representation temps-frequence la frequence avec sa position spatiale Adaptation de la resolution en fonction de la frequence Basses frequence $\\to$ Privilegie la resolution frequentielle Hautes frequence $\\to$ Privilegie la resolution temporelle analyse des signaux non stationnaires Definition:\\[\\Psi_x^\\psi(\\tau,s)=\\frac{1}{\\sqrt{\\vert s\\vert}}\\int x(t)\\psi^c\\biggr(\\frac{t-\\tau}{s}\\biggr)dt\\\\\\Psi_x^\\psi(\\tau,s)=\\int x(t\\psi_{\\tau, s}^c)(t)dt\\\\\\psi_{(\\tau,s)}=\\frac{1}{\\sqrt{\\vert s\\vert}}\\psi\\biggr(\\frac{t-\\tau}{s}\\biggr)\\]Exemples Haar Mexican Hat MorletUsage Compression Filtrage Approximation ‚Ä¶" }, { "title": "TIFO: Filtrage, partie 1", "url": "/cours/posts/tifo_filtrage_partie_1/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8, lissage, debruitage, laplacien, convolution, bords", "date": "2021-03-11 14:00:00 +0100", "snippet": "Lien de la note HackmdFiltrage Domaines spatial et frequentiel Lissage, elimination du bruit Detection de bords/coinsQuelques filtres classiques On s‚Äôappuie souvent sur le produit de convolution Matrice avec des coefficients On va recalculer la valeur d‚Äôun pixel en fonction de son voisinage Combinaison lineaire de tous les pixels voisins Lissage, debruitageComment eliminer le bruit dans une image ? Filtre moyenneur Objectif: lisser l‚Äôimage Donne une impression de flou Fonctionnement: on remplace la valeur d‚Äôun pixel par la moyenne des valeurs des pixels du voisinage Noyau de convolution: \\[\\frac{1}{9}\\begin{bmatrix} 1 &amp;amp; 1 &amp;amp; 1\\\\ 1 &amp;amp; 1 &amp;amp; 1\\\\ 1 &amp;amp; 1 &amp;amp; 1\\\\\\end{bmatrix}\\]Comment choisir la taille/forme du voisinage ?On reste generalement sur des voisinages carres par soucis de performanceResultats:Un leger flou apparait.Si on continue et qu‚Äôon augmente la taille du masque:Le lissage est un peu trop fort et on perd des details.Implementation Comment implementer un tel filtre ? Double boucle Que faire sur la bordure On ne traite pas les bords Recalculer sur la bordure avec des coeffs differents Dupliquer les dernieres et premieres lignes/colonne Image periodique: chercher les valeurs sur une autre periode $\\Rightarrow$ il n‚Äôy a pas de bonnes reponses Amelioration? Au lieu de faire contribuer tous les pixels egalement, on peut privilegier les pixels proches du centre Filtre Gaussien Filtre Gaussien Objectif: lisser l‚Äôimage Fonctionnement: on remplace la valeur d‚Äôun pixel par la moyenne ponderee des valeurs des pixels du voisinage Noyau de convolution: gaussienne Parametre/Taille du noyau ?ResultatComparaison ave le filtre moyenneur Avantages/inconvenients ? moins l‚Äôimpression de flou bonne amelioration Filtre Median Objectif: debruitage Fonctionnement: trier l‚Äôensemble des valeurs des intensites des pixels sur un voisinage puis remplacer la valeur du pixel considere par la valeur mediane sur le voisinageResultat Supprime facilement le bruit impulsionnel Preserve l‚Äôinformation de contour Est un peu lourd (tri) Je suis pas du tout narcissiqueOn a completement enleve le bruit ‚Äúpoivre et sel‚Äù de la 2$^{\\text{nde}}$ imageLissage Lissage (gaussien, moyenne‚Ä¶) Degrade les frontieres Solutions ? Faire contribuer principalement les pixels qui ont une couleur proche de la couleur du pixel considere ou ponderer leur apport en fonction de leur couleur Filtre de Nagao ‚Ä¶ Filtre gaussien, resultats:Gaussien selectif: seuil pour faire contribuer les pixel (si c‚Äôest inferieur, on les fait contribuer, sinon on les oublie). Permet de preserver les contours Seuil a fixer S‚Äôil est trop tolerant: tend vers le gaussien normal Pas assez tolerant: reste sur l‚Äôimage originale Nagao Filtre de Nagao Tenir compte des regions? Faire un median mais dans la region de variance faible Au lieu de prendre un masque centre sur le pixel, on va regarder sur differents voisinagesOn calcule la variance a chaque zones rouges On calcule la moyenne sur le voisinage avec la variance la plus faible On ne veut pas faire une moyenne a cheval sur un contour ResultatsNagao: on a fortement lisse l‚Äôimage mais on a garde les contoursDetection de bords Comment se caracterise un contour ? Comment trouver les contours ? Pourquoi trouver les contours ? Definir la notion de bord/contour Transition brutale (echelon) En ‚Äúescalier‚Äù Dans la vraie vie, jamais aussi brutale Quelle operation realiser pour detecter ce type de motif? Calcul de la derivee ?\\[\\lim_{x_0\\to x}\\frac{f(x_0)-f(x)}{x_0-x}\\] Si l‚Äôaccroissement est plus fort en $y$ que en $x$, on calcul le coefficient directeur. Quand la porte est tres fort, on a un contour.\\[\\frac{\\delta f(x,y)}{\\delta x} =\\]\\[\\frac{\\delta f(x,y)}{\\delta y} =\\] Vecteur directeur en tout point de la courbeCalcul de la deriveeEn continu on a $\\lim_{h\\to 0}\\frac{f(x + h) - f(x)}{h}$ et on veut calculer ca correctement en dirscret.Profil:Derivee: recherche de maxima locaux ?Calcul de la derivee en 1 point x En continu: $\\lim_{h\\to 0}\\frac{f(x + h) - f(x)}{h}$ En discret on a du mal a aller vers 0 En discret on a $\\frac{f(x+1)-f(x)}{1}$ Dans notre cas (discret) $f‚Äô(x)=(f(x+1)-f(x))$ ou $\\frac{1}{2}\\times (f(x+1)-f(x-1))$ Masques: $[-1;1]$, $\\frac{1}{2}[-1;0;1]$ Attention signal 2D Roberts Filtre de Roberts\\[r(x,y) = \\sqrt{(i(x,y)-i(x-1,y-1))^2} + \\sqrt{(i(x,y-1)-i(x-1,y))^2}\\\\r(x,y) = \\vert i(x,y)-i(x-1,y-1)\\vert + \\vert i(x,y-1)-i(x-1,y)\\vert\\] Contours pas forcement netsSobel, PrewittFiltres beaucoup plus communs.Sobel:Prewitt:Pourquoi ces coefficients ? On inclut le lissageLa difference: lisser par un filtre moyenneur / Sobel lisser par un filtre Gaussien / PrewittResultatsSobelPrewitt\\[\\frac{\\delta f(x,y)}{\\delta x}\\\\\\frac{\\delta f(x,y)}{\\delta y}\\]On peut combiner les derivees: calculer amplitude du gradient calculer l‚Äôangle\\[\\sqrt{sx^2+sy^2}\\\\tan^{-1}(\\frac{sy}{sx})\\]Informations sur l‚Äôorientation du gradientComment recuperer les contours a partir de l‚Äôimage du gradient ?On peut combiner les 2 images Le vecteur gradient est orthogonal aux lignes de niveaux plus sa norme est grande plus la transition est forte On cherche une transition maximaleDifferentes strategies pour recuperrer les contours: Seuillage Seuillage par hysteresis On cherche un seuil pour un profil On garde tout au dessus du seuil et on jette tout en dessous On inclut le motif a droite qu‚Äôon ne veut pas garder Pour regler ce probleme on utilise 2 seuils un seuil haut un seuil bas On a une 1$^{ere}$ binarisation avec le seuil haut On perd de l‚Äôinfo On enleve le motif qu‚Äôon veut pas Le seuil tolerant garde beaucoup plus d‚Äôinfos Hysteresis: on garde tous les resultats des seuils tolerant qui ont un contact avec le seuil haut Recherche de lignes de crete Probleme: Contour ferme/contour ouvert ? Kirsch, RobinsonKirsch and Robinson Compass Masks (Filtres de compas): On fait ‚Äútourner‚Äù le filtre. ‚ÄúSobel que l‚Äôon fait tourner‚ÄùL‚Äôamplitude est donnee par la plus forte reponse.L‚Äôorientation est deduite du masque qui a donne la plus forte reponse.Frei-ChenPermet de trouver les gradients et d‚Äôautres motifs (lignes croises, point, etc.) Edge Line ¬† 1.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;\\sqrt2&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\-1&amp;amp;-\\sqrt 2&amp;amp;-1\\end{bmatrix}\\) 5.\\(\\frac{1}{2}\\begin{bmatrix}0&amp;amp;1&amp;amp;0\\\\-1&amp;amp;0&amp;amp;-1\\\\0&amp;amp;1&amp;amp;0\\end{bmatrix}\\) 9.\\(\\frac{1}{3}\\begin{bmatrix}1&amp;amp;1&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\end{bmatrix}\\) 2.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;0&amp;amp;-1\\\\\\sqrt 2&amp;amp;0&amp;amp;-\\sqrt 2\\\\1&amp;amp;0&amp;amp;-1\\end{bmatrix}\\) 6.\\(\\frac{1}{2}\\begin{bmatrix}-1&amp;amp;0&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\1&amp;amp;0&amp;amp;-1\\end{bmatrix}\\) ¬† 3.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}0&amp;amp;-1&amp;amp;\\sqrt 2\\\\1&amp;amp;0&amp;amp;-1\\\\-\\sqrt 2&amp;amp;1&amp;amp;0\\end{bmatrix}\\) 7.\\(\\frac{1}{2}\\begin{bmatrix}1&amp;amp;-2&amp;amp;1\\\\-2&amp;amp;4&amp;amp;-2\\\\1&amp;amp;-2&amp;amp;1\\end{bmatrix}\\) ¬† 4.\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}-\\sqrt 2&amp;amp;-1&amp;amp;0\\\\-1&amp;amp;0&amp;amp;1\\\\0&amp;amp;1&amp;amp;-\\sqrt 2\\end{bmatrix}\\) 8.\\(\\frac{1}{2}\\begin{bmatrix}-2&amp;amp;1&amp;amp;-2\\\\1&amp;amp;4&amp;amp;1\\\\-2&amp;amp;1&amp;amp;-2\\end{bmatrix}\\) ¬† 9 masquent qui forment une base Chaque sous-famille est capable de detecter un motif localement La detectection se fait seulement avec:\\(\\frac{1}{2\\sqrt 2}\\begin{bmatrix}1&amp;amp;\\sqrt2&amp;amp;1\\\\0&amp;amp;0&amp;amp;0\\\\-1&amp;amp;-\\sqrt 2&amp;amp;-1\\end{bmatrix}\\text{ +rotations a }90^o\\\\\\theta=\\arccos\\biggr(\\sqrt{\\frac{\\sum_{k=1}^4(W_k\\times I)^2}{\\sum_{k=1}^9(W_k\\times I)^2}}\\biggr)\\) Plus $\\theta$ est grand, moins la bordure est marquee ($\\theta$ est entre 0 et $\\pi$).Avantages: Plus robuste a differents niveaux d‚Äôillumination Plus robuste car elimine les motifs lignes, points, etc. de la detection Peut etre utilise pour detecter les lignes en utilisant les masques 5 a 8 a la place des masques 1 a 4Le laplacienUtilisation de la derivee seconde Un point de contour est un passage a zero de la derivee secondeDerivee seconde:$f$: $f‚Äô$: $f‚Äô‚Äô$: Un point de contour n‚Äôest rien d‚Äôautre qu‚Äôun passage de la derivee seconde par 0. Calcul du laplacien $f‚Äô(x)=f(x+1)-f(x)$ $\\frac{f(x+1)-f(x)}{1}$ $f‚Äô‚Äò(x) = (x+1)-f‚Äô(x)$ $f‚Äô‚Äò(x = f(x+2)-f(x+1)-f(x+1)+f(x)$ On obtient un masque simple:\\[f&#39;&#39;(X) = f(X+1)-2\\times f(X)+f(X-1)\\] Si on veut detecter les contours, il faut chercher les passage par 0 du resultat:On a somme le masque horizontal et vertical Les contours sont reperes par un changement de signeOn va plutot chercher un changement de signe (de forte amplitude)Si $E\\gt0$ il faut un des $A,B,C$ ou $D\\lt0$ et inversement si $E\\lt 0$ La calcul des derivees est approche au moyen de filtres Simple et rapide Inconvenients: approximation, sensibilite au bruit, en particulier le Laplacien $\\rightarrow$ necessite de lisser le signal avant ou lors de la derivation Impact du lissage Robustess au bruit Delocalisation des points de contour Le Laplacien est sensible au bruit $\\to$ sur-segmentationEvaluation de la qualite de detection de contours: Bonne detection Bonne localisation Reponse unique Cf filtre de Canny/DericheDetection de points d‚Äôinteret Detection de coins Comment se caracterise un coin ? Comment trouver les coins ? Pourquoi trouver les coins ? Coin = gradient fort dans 2 directionsMoravecPour chaque point: On fait la somme $S$ des differences des intensites entre un voisinage centre sur le point et le voisinage decale On reitere le calcul avec des decalages dans toutes les directions Pour chaque point, on garde, parmi tous les decalages $i$ le resultat de $S_i$ qui a donne la plus faible valeurMoravec: Calcul d‚Äôun critere sur toute l‚Äôimage\\[c_{d_x,d_y}(x,y) = \\sum_{i=-s...+s}\\sum_{j=-s...+s}(I(x+i, y+j)-I(x+i+d_x,y+j+d_y))^2\\] On calcul un critere pour chaque point\\[c(x,y)=\\min_{d_x,d_y}(c_{d_x,d_y}(x,y))\\] Un coin est un maximum local de $c(x,y)$Desavantages: Sensible au bruit (des petites imperfections peuvent etre prises pour des coins) Contours de certaines directions peuvent etre pris pour des coins (anisotrope car on considere que quelques directions)HarrisRevision du critere pour etre plus robuste\\[c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)(I(x+i,y+j)-I(x+i+d_x,y+j+d))^2\\\\I(x+d_x,y+d_y)\\simeq I(x,y)+d_x\\biggr(\\frac{\\delta I(x,y)}{\\delta x}\\biggr)+d_y\\biggr(\\frac{\\delta I(x,y)}{\\delta y}\\biggr)+...\\\\c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)\\biggr(d_x\\biggr(\\frac{\\delta I(x+i,y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)\\biggr)^2\\]Critere:\\(c_{d_x,d_y}=\\sum_{i=-s...+s}\\sum_{j=-s...+s}w(i,j)\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2\\\\\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2\\)\\[\\biggr(d_x\\frac{\\delta I(x+i, y+j)}{\\delta x}+d_y\\frac{\\delta I(x+i,y+j)}{\\delta y}\\biggr)^2 = (d_x,d_y)\\begin{pmatrix} (\\frac{\\delta I}{\\delta x})^2 &amp;amp;(\\frac{\\delta I}{\\delta x\\delta y})\\\\ (\\frac{\\delta I}{\\delta x\\delta y}) &amp;amp; (\\frac{\\delta I}{\\delta y})^2\\end{pmatrix}\\begin{pmatrix}d_x\\\\d_y\\end{pmatrix}\\]Ce qui donne:\\[Ad+x^2+2Cd_xd_y+Bd_y^2\\\\M=\\begin{pmatrix} A&amp;amp;C\\\\ C&amp;amp;B\\end{pmatrix}=\\begin{pmatrix} (\\frac{\\delta I}{\\delta x})^2 &amp;amp;(\\frac{\\delta I}{\\delta x\\delta y})\\\\ (\\frac{\\delta I}{\\delta x\\delta y}) &amp;amp; (\\frac{\\delta I}{\\delta y})^2\\end{pmatrix}\\] Avec $w$ une gaussienneNouveau critere H $H=det(M)-\\alpha$ trace $(M)^2$ $\\lambda_1$ $\\lambda_2$ les deux valeurs propres $det(M)=\\lambda_1\\lambda_2$ et $trace(M)=\\lambda_1+\\lambda_2$ $H=\\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$ $H\\lt0$ contour $H\\to0$ ras $H\\gt\\gt0$ coin $\\alpha$ grand $\\Rightarrow$ $H$ diminue et le detecteur est moins sensible $\\alpha$ petit $\\Rightarrow$ $H$ diminue et le detecteur est plus sensibleAchard, Bigorgne, Devars Detection basee sur le produit vectoriel Pres d‚Äôun coin, la norme du produit vectoriel entre 2 vecteur gradient est grande Dans une zone homogene elle est faible La norme des vecteurs gradients est petite Sur un contour elle est faibke aussi L‚Äôangle frome entre 2 vecteurs gradients proches est petit Pour chaque point $i$, avec un voisinage $V_i$, on determine un critere $k$: \\(k=\\sum_{j\\in V_i}\\Vert\\overrightarrow{grad(P_i)}\\Vert^2\\Vert\\overrightarrow{grad(P_j)}\\Vert^2\\sin^2(\\widehat{grad(P_i),grad(P_j)})\\)\\(\\begin{aligned}&amp;amp;I_x=\\biggr(\\frac{\\delta I}{\\delta x}\\biggr) &amp;amp;\\Vert\\overrightarrow{grad(P)}\\Vert^2=I_x^2+I_y^2\\\\&amp;amp;\\widehat{\\sin(ox,grad(P)})=\\frac{I_y}{\\sqrt{I_x^2+I_y^2}} &amp;amp;\\widehat{\\cos(ox,grad(P)})=\\frac{I_y}{\\sqrt{I_x^2+I_y^2}}\\\\&amp;amp;k=I_x^2&amp;lt;I_y^2&amp;gt;+I_y^2&amp;lt;I_x^2&amp;gt;-2I_xI_y&amp;lt;I_xI_y&amp;gt; &amp;amp;&amp;lt;I&amp;gt;I\\times\\begin{pmatrix}1&amp;amp;1&amp;amp;1\\\\1&amp;amp;0&amp;amp;1\\\\1&amp;amp;1&amp;amp;1\\end{pmatrix}\\end{aligned}\\)ResultatsArchardAmelioration de la netteteLaplacien Retour sur la derivee seconde (Laplacien)$f$: $f‚Äô$: $f‚Äô‚Äô$: \\[f&#39;&#39;(X) = f(X+1)-2\\times f(X)+f(X-1)\\]Renforcement de la nettete$-f‚Äô‚Äô$: Ce qu‚Äôon ainerai c‚Äôest combine $f$ et $-f‚Äô‚Äô$ pour ecarter les amplitudes des extremums avant et apresOn prend $f$ et lui on lui retranche $k$ fois la derivee seconde pour accroitre le contraste locale$f$: $-kf‚Äô‚Äô$: $f-kf‚Äô‚Äô$: Masque pour le Laplacien Rajouter $+1$ au centre c‚Äôest comme rajouter l‚Äôimage completeResultats Augmente la nettete Renforce le bruitC‚Äôest l‚Äôinverse de ce qu‚Äôon a fait au debutConclusion Tout ce qu‚Äôon a fait jusqu‚Äôa present est faux car on a pas pris en compte la correction gamma." }, { "title": "OCVX: Introduction", "url": "/cours/posts/ocvx_introduction/", "categories": "Image S8, OCVX", "tags": "Image, SCIA, OCVX, S8", "date": "2021-03-11 13:00:00 +0100", "snippet": "Lien de la note HackmdIntroductionL‚Äôoptimisation fait partie des missions historiques de l‚Äôing√©nierie. Elle na√Æt avec l‚Äô√®re industrielle: une fois un concept √©labor√© il s‚Äôagit de r√©duire les coups, minimiser les risques de d√©fauts de livraisons ou √©tendre le scope d‚Äôaction ‚Ä¶Les techniques math√©matiques qui permettent de r√©soudre une partie de ces probl√®mes d‚Äôoptimisation balayent un large spectre des th√©matiques math√©matiques que vous avez pu aborder jusque l√†; l‚Äôalg√®bre lin√©aire, le calcul diff√©rentielle et un peu de g√©om√©trie. Le cours d‚ÄôOCVX a pour objectif de vous donner le bon degr√© de confort pour manipuler ces techniques.De quoi on parle ?Voici quelques exemples qu‚Äôon pourrait croiser lorsqu‚Äôon s‚Äôint√©resse √† l‚Äôoptimisation. Chercher le plus court/rapide chemin entre deux coordonn√©es GPS. D√©cider des meilleures routes a√©riennes qui minimisent le prix d‚Äôapprovisionnement en k√©ros√®ne. Identifier des images d‚ÄôIRM qui correspondent √† des malformations du cerveau. Chercher des patterns dans la population d‚Äô√©tudiants int√©grants Epita D√©cider d‚Äôachat/vente d‚Äôassets prenant en compte l‚Äôhistorique disponible.Probleme d‚ÄôoptimisationDefinition formelleOn √©crit en g√©n√©ral un probl√®me d‚Äôoptimisation $(P)$ sous la forme standard\\[\\begin{aligned}&amp;amp;\\text{minimiser} &amp;amp;f_0(x) &amp;amp;\\\\&amp;amp;\\text{sujet a } &amp;amp;f_i(x)\\le0, &amp;amp;\\forall i\\in\\{1,...,p\\}\\\\&amp;amp; &amp;amp;h_j(x)=0, &amp;amp;\\forall i\\in\\{1,...,m\\}\\end{aligned}\\]o√π $f_0$, les $f_i$ et les $h_j$ sont des applications de $\\mathbb R^n$ vers R. La fonction $f_0$ est dite fonction objectif ; suivant le contexte ce sera une fonction de co√ªt ou d‚Äôerreur. Les in√©galit√©s sont qualifi√©es de contraintes d‚Äôin√©galit√©s et les √©galit√©s de contraintes d‚Äô√©galit√©s. TentativeVous pouvez chercher √† formuler les probl√®mes √©num√©r√©s sous forme d‚Äôun probl√®me d‚Äôoptimisation, ce n‚Äôest pas toujours √©vident.Un probleme d‚Äôoptimisation du type de $(P)$ est dit differentiable si toutes les fonctions en jeux le sont; non-contraint s‚Äôil n‚Äôa aucune contraintes d‚Äôinegalites ou egalites convexe si l‚Äôensemble des fonctions en jeu sont convexes, les contraintes d‚Äôegalites etant de plus affinesSous la premi√®re hypoth√®se on a une s√©rie d‚Äôoutils math√©matiques qui nous permettront d‚Äôapporter un √©clairage riche sur $(P)$. Si l‚Äôon rajoute la seconde on est en mesure de construire des proc√©d√©s it√©ratifs efficaces en √©tat de r√©soudre ces probl√®mes. La derni√®re nous garantie de trouver la solution optimale. Fake newsLes √©l√©ments en italiques sont l√† pour marquer le fait que nos assertions √† ce stade sont encore un peu fausses. L‚Äôimage est un peu moins idyllique.Lexique√âtant donn√© un probl√®me d‚Äôoptimisation $(P)$ on appelle: point admissible de $(P)$ tout point de $R^n$ satisfaisant toutes les contraintes. L‚Äôensemble de tous les points admissibles est appel√© lieu admissible de $(P)$. valeur objectif d‚Äôun point admissible la valeur que prend la fonction objectif en celui-ci. valeur optimale de $(P)$ la meilleure borne inf√©rieure sur la fonction objectif. point optimal de $(P)$ tout point admissible dont la valeur objectif est la valeur optimale.Premieres remarques qualitativesComme est le cas de tout syst√®me d‚Äô√©quations, il est utile de se poser le type de questions suivantes: y a-t-il au moins une solution? s‚Äôil y a au moins une solution combien? peut-on toujours d√©crire l‚Äôensemble des solutions? y a-t-il moyen d‚Äôapprocher des solutions? QuestionChercher un probl√®me d‚Äôoptimisation qui: a un lieu admissible est vide; a plus d‚Äôun seul point optimal; n‚Äôa pas de valeur optimale mais a un lieu admissible non vide \\; a une valeur optimale mais pas de point optimal. Cadre de la premiere UE d‚ÄôOCVXContours du coursOn se limite au cours du premier semestre de majeure au cas des probl√®mes d‚Äôoptimisations sans contraintes. C‚Äôest un cadre suffisant pour les premi√®res applications des techniques d‚Äôoptimisations √† un premier niveau de ML ; il recouvre le cas des diff√©rentes r√©gressions, de l‚Äôentra√Ænement d‚Äôun r√©seau de neurones ainsi que les cas des algos de classification standards Il repr√©sente un premier niveau √† atteindre qui permet de fixer votre attitude vis-√†-vis d‚Äôun probl√®me d‚Äôoptimisation, sans s‚Äôencombrer de concepts plus abstraits √† concevoir. Il ne recouvre pas le cas des Support Vector MachinesRegression mon amieMap Fitting Une famille diff√©rentiable d‚Äôapplications $f_{\\alpha} : \\mathbb R^n \\to \\mathbb R$ index√©es par $\\alpha\\in \\mathbb R^k$ est une famille de fonctions pour laquelle l‚Äôapplication $\\phi : \\mathbb R^k \\times\\mathbb R^n ‚Üí \\mathbb R$ qui envoie $(\\alpha, x)$ sur $f_{\\alpha}(x)$ est diff√©rentiable. On consid√®re un ensemble de couples $(X_i, y_i) \\in\\mathbb R^n \\times\\mathbb R$ pour $i \\in {1, . . . , p}$ et une famille diff√©rentiable d‚Äôapplications ${f_{\\alpha}},\\alpha\\in\\mathbb R^k$ . Le probl√®me de map fitting relatif aux donn√©es pr√©c√©dentes consiste √† trouver les meilleurs param√®tres $\\alpha^$ tels que $f_{\\alpha^}$ approche au mieux (pour une m√©trique pr√©-choisie) a les $(X_i, y_i)$.La regression lineaireLe plus simple des probl√®mes de map fitting est celui de la r√©gression lin√©aire. Dans le cas de dimension 1 (on cherche √† approcher une fonction de $\\mathbb R$ dans $\\mathbb R$) il se d√©cline comme ceci: la famille diff√©rentiable √† laquelle on s‚Äôint√©resse est index√©es par $\\mathbb R^2$: $f_{\\alpha}(x)=\\alpha_1x+\\alpha_0$ pour $\\alpha=(\\alpha_0,\\alpha_1)$ la m√©trique standard utilis√©e est la MSE pour Mean Square Error donn√©e pour un $f_{\\alpha}$ par\\[\\mathcal E(\\alpha) = \\sum_{i=1}^p\\frac{1}{p}(f_{\\alpha}(x_i)-y_i)^2\\]c‚Äôest une estimation moyenne de la variance des pr√©dictions de $f_{\\alpha}$ Le but est de trouver un param√®tre $\\alpha=(\\alpha_0,\\alpha_1)$ tel que $\\mathcal E(\\alpha)$ est minimal, autrement dit de r√©soudre le probl√®me d‚Äôoptimisation sans contraintes minimiser $\\mathcal E(\\alpha)$.Le probl√®me de r√©gression lin√©aire a une solution analytique; c√†d une solution donn√©e par une expression explicite en fonction des entr√©es.Cette solution implique cependant l‚Äôinversion d‚Äôune matrice de taille √©quivalent √† celle des donn√©es en entr√©e. Chose particuli√®rement co√ªteuse.Empathie machineApproximation s√©quentielleIl est rare qu‚Äôun probl√®me d‚Äôoptimisation ait une solution analytique. M√™me quand cela est le cas il est souvent plus efficace de chercher une solution approch√©e.Un processus it√©ratif qui r√©sout un probl√®me d‚Äôoptimisation $(P)$ est un choix initial d‚Äôun point de d√©part (de pr√©f√©rence) admissible $x_0$ ; un processus it√©ratif qui construit un point admissible $x_{n+1}$ √† partir de $x_n$ et de donn√©es locales ayant une valeur objectif plus petite que celle de $x_n$.Cette d√©marche ne nous offre en g√©n√©ral qu‚Äôune approximation d‚Äôune solution. Elle a cependant l‚Äôavantage de pouvoir se d√©rouler en temps raisonnable. Il faut par ailleurs prendre en compte que l‚Äôimpl√©mentation des flottants en machines nous contraint d√©j√† √† approcher les grandeurs qu‚Äôon manipule.Acquis d‚Äôapprentissages vises (AAVs) Savoirs Identifier les √©l√©ments composants un probl√®me d‚Äôoptimisation et des √©l√©ments n√©cessaires √† son √©tude qualitative Cartographier les outils √† disposition pour r√©soudre un probl√®me d‚Äôoptimisation et les hyperparam√®tres qui d√©clinent et gouvernent ceux-ci. D√©crire le domaine de validit√© d‚Äôun algorithme. Savoir-faire Impl√©menter des algorithmes standards d‚Äôoptimisation sans contraintes Effectuer des analyses comparatives entre des diff√©rentes algorithmes d‚Äôoptimisation sans contraintes Reconna√Ætre les probl√®mes li√©s aux approximations num√©riques qui apparaissent dans toute impl√©mentation. Attitude - Analyse de risque Vivre par le moto : Un test n‚Äôest pas une statistique et une statistique ne vient pas sans variabilit√©. Contenus notionnels Pr√©-requis techniques Des √©l√©ments de g√©om√©tries Interpr√©tation g√©om√©trique du produit scalaire Courbes de niveau et epigraphes de fonctions. Parties et fonctions convexese en dimension finie. Des √©l√©ments de topologie Comment calculer des distances et d√©finir des voisinanges dans $\\mathbb R^n$ Approcher et comparer des fonctions √† plusieurs variables. Des √©l√©ments de calcul diff√©rentiel Approcher localement une fonction multivari√©es par une fonction affine. √âcriture en base ; jacobienne et gradient. Interpr√©tation g√©om√©trique du gradient Approximation locale de second ordre : la hessienne √âtude qualitative des probl√®mes d‚Äôoptimisation. Le lieu critique d‚Äôune fonction objectif. Apport de la convexit√© au contexte de l‚Äôoptimisation. √âtudes du cas quadratique. M√©thodes de r√©solutions it√©ratives. Descentes de gradients et M√©thodes de Newton EvaluationDeux modes d‚Äô√©valuations vont int√©ragir dans le cadre de ce cours Des √©valuations formatives via moodle, ce qui est suffisant pour garantir le fait que vous consacrez suffisamment de temps √† comprendre les √©l√©ments de cours et l‚Äôassimiler. Une √©valuation formative est not√©e de mani√®re binaire : 0% de la note si l‚Äô√©tudiant n‚Äôy participe pas s√©rieusement et 100% sinon. Des √©valuations sommatives comptabilis√©es de mani√®re classique. Elle seront compos√©es d‚Äôune √©valuation interm√©diaire qui prendra la forme d‚Äôun devoir sur table, celui-ci vise √† garantir votre capacit√© √† formuler un raisonnement g√©om√©trique / diff√©rentiel concernant les probl√©matiques d‚Äôoptimisation d‚Äôune √©valuation TP afin d‚Äôavoir un regard sur l‚Äôensemble des √©l√©ments que vous aurez pu mobiliser pour atteindre les objectifs de cours. Les √©valuations formatives comptent pour 20% de la note finale. On attend de vous de faire preuve d‚Äôautonomie lors du suivi de ce cours.MoodleL‚Äôensemble des contenus de cours, d‚Äôannonces, de bibliographies de travail √† rendre et des tests d‚Äô√©valuation seront disponibles sur un cours moodle auquels vous serez inscrit bient√¥t." }, { "title": "ISIM: La modelisation", "url": "/cours/posts/isim_modelisation/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, maillage, surface, polygone, animation", "date": "2021-03-11 09:00:00 +0100", "snippet": "Lien de la note HackmdModelisation Rendu temps reel Mailages/polygones Rendu photorealiste (algorithme type raytracing) Maillages/polygones Mathematiques Animation Modeles physiques Chaque objet est decrit par une formule mathematiques Tres compact et bien adapte pour les algorithmes type raytracing Formule compliquee ou impossible a determiner pour la plupart des objetsFormes de bases - primitives 2D/3D Sphere Cylindre Cube Plan Tore ‚Ä¶MaillageConstruction d‚Äôobjets par assemblage de polygones Bonne modelisation des objets avec peu de courbes (architecture‚Ä¶) Peu compacte mais facile manipulerRepresentation Polygone utilise: Majoritairement le triangle Facilite le traitement (remplissage‚Ä¶) Representation en interne Liste de coordonnees de sommets par polygone Duplication des sommets communs a plusieurs polygones Pas de connaissance de la topologie Liste de sommets puis liste d‚Äôindice par polygone Gain de place Reduction de la quantite d‚Äôinformation Pas de connaissance de la topologie Triangulation de Delauny Cas pour quand le maillage n‚Äôest pas en triangle.Diagramme de Voronoi $vor(p) = {x\\in E;\\forall qd(x,p)\\le d(x,q)}$Mesh Refinement On veut appauvrir le maillage quand il est loin et l‚Äôenrichir quand il est pres.Adaptive mesh refinement Depth taggingModelisation surfaciqueSurfaces de BezierBezier (1960 - Renault) Courbes de Bezier Surfaces de Bezier Ces courbes ont ete mises en place pour representer les carosseries de voituresCourbes de Bezier Courbes de Bezier: definir une courbe passant par 2 points: Lissage lineaire $P_1t+P_2(1-t)$ avec $0\\le t\\le1$ Si plus de points: continu par morceau Lissage polynomial $x(t) = Q(t) = a_3t^3+a_2t^2+a_1t+a_0$ $y(t) = R(t) = b_3t^3+b_2t^2+b_1t+b_0$ Pour garder la derivabilite en $P_1$ et $P_2$: $Q‚Äô(t) = 3a_3t^3+2a_2t+a_1$ Idem pour $y(t)$ Il faut trouver les $a_i$ et les $b_i$ On va utiliser: $x(0)=xP_1$ $x(1)=xP_2$ $x‚Äô(0) = x‚ÄôP_1$ $x‚Äô(1)=x‚ÄôP_2$ Ce qui donne: $x(t)=(2t^3-3t^2+1)xP_1+(-2t^3+3^2)xP_2+(t^3-2t^2+1)x‚ÄôP_1+(t^3-t^2)x‚ÄôP_2$ Idem pour $y(t)$ Comment avoir les $x‚Äô(0)=x‚ÄôP_1$ $x‚Äô(1)=x‚ÄôP_2$ Ajout de points de controles $D_n$ pour determiner la derivee localement. Les vecteurs tangents sont deduits par $3(D_1-P_1)$ Cela donne:\\[xP_1(1-t)^3+xD_1(3t(1-t)^2)+xD_23t^2(1-t)+xP_2t^3\\] On peut chainer et rajouter des morceaux pour agrandir la courbe.Resultats: La texture est d‚Äôailleurs proceduralePour definir une courbe plus complexe: Augementer le degre La modification d‚Äôun point de controle perturbe toute la courbe Joindre plusieurs courbes de BezierPour appliquer des transformations affines: Applique les transformations affines aux points de controleSurfaces de BezierPar extension: surfaces de Bezier 4 points de controle en 2D, 16 points de controle en 3D Joindre plusieurs surfaces de BezierLissage de polygonesSurface de subdivisionDifferents algorithmes: Algorithme de catmull-Clark, Doo-sabin.Un exemple en 2D: Diviser chaque segment en 3 parties egales joindre les divisions successives Recommencer jusqu‚Äôau niveau lissage desire A faire en 3DAlgorithme de Catmull-ClarkExemple: Est-ce qu‚Äôon peut dire que c‚Äôest fait‚Ä¶ a la main ?Modelisation par assemblageC.S.G. C.S.G.: Constructive Solid GeometryCombiner des briques de base (solides) par des operations: Union Intersection DifferenceUnion:Intersection:Difference:Representation sous forme d‚Äôarbre: Fonction implicite d‚Äôun solide: $F(x,y,z)$ $F(x,y,z)\\lt0$ interieur $F(x,y,z)=0$ surface $F(x,y,z)\\gt0$ exterieur Pour le calcul des C.S.G.: $-1;0;1$ $F_{A\\cap B}(p) = \\max(F_A(p),F_B(p))$ $F_{A\\cup B}(p) = \\min(F_A(p),F_B(p))$ $F_{A-B}(p) = \\max(F_A(p),-F_B(p))$ Modelisation par revolution L‚Äôobjet est construit par la rotation d‚Äôune forme autour d‚Äôun axe de revolution Fonction d‚Äôun angle Fonction d‚Äôun pas d‚Äôechantillonnage Trace du contour:L‚Äôaxe de revolution se situe au centre (axe vert et axe rouge) On se rend compte que le Graal n‚Äôest rien d‚Äôautre qu‚Äôune fulte a champagneAutres exemples: La boule de bowling presente des C.S.G.Modelisation par extrusion L‚Äôobjet est construit par une surface suivant une trajectoire Le chemin peut etre plus ou moins complique C‚Äôest peut-etre une etoile de mer mais je la fait sortir de terreRetour a la main de tout a l‚Äôheure:Cartes d‚ÄôaltitudesPermet generalement de representer les terrains: Construction: Iterative ‚Ä¶ Exemple: Is this minecraftBlobs/Metaballs Representation d‚Äôun objet par iosurfaceImaginons qu‚Äôon met une source d‚Äôenergie qui chauffe:Qu‚Äôest-ce qui se passe si on a 2 points d‚Äôenergie qui se rapprochent ?On obtient une courbe car les valeurs se somment. On peut utiliser cette courbe pour modeliser des formes arrondies.En 2D:En 3D: J‚Äôai fait un petit objet, je sais pas ce que c‚Äôest.Hand-spinner?On peut faire des gouttes de mercure qui s‚Äôattachent ensemble. Le point d‚Äôenergie n‚Äôest pas forcement ponctuel, ca peut un un plan, un cylindre, etc. On un un p‚Äôtit.. p‚Äôtit cheval Rendu En raytracing, evaluation le lonf du rayon Algorithme des ‚Äúmarching cubes‚Äù Particules Attention au calcul des normales Modelisation Eau ‚Ä¶ Modelisation de la vegetationGraftalesModelisation desplantes L-Systems (Lindenmayer, 1968) Similaire a une grammaire souvent utilise pour modeliser la vegetation (mais pas seulement) Y‚Äôa un super cours de theorie des langages donne par Jonathan FabrizioOn par de l‚Äôaxiome et on applique la regle de production On divise le 1$^{er}$ segment en 3 sous-segments On rajoute 2 segments inclines On repete a chaque etape On a besoin de differentes regles d‚Äôevolutions (branches, couleurs, etc.). Le plus dur c‚Äôest de definir la grammaire de base.Acquisition Comment font-ils pour faire des modeles aussi beau ?Scan 3DPour le monde de Nemo:On a un vrai artiste qui fait un vrai modeleSuite au scan 3D du modelePour Avatar: Cette pratique est assez courante.D‚Äôautres artistes scultent directement le modele numerique.Sculpture 3D:Codage des Formes/Maillages Aretes aillees B-rep Array of vertex Enregistrer tous les sommets et leurs proprietes Pas tres compact Array of indexes Lister les sommets et leur caracteristiques Tablea d‚Äôaddressage indexe Dans cette exemple: le sommet 1 est enregistre plusieurs fois, on a pas a enregistrer ses caracteristiques a chaque fois, on fait un addressage indexe. Ne mache pas toujours, les proprietes peuvent varier d‚Äôun meme sommet en fonction du polygone auquel il est rattache.Aretes aillesUne arete: une orientation Sommet de depart et d‚Äôarrivee On les memorise selon un ordre deux faces deux sommets quatre aretes Le sommet actuel y est toujours lie si elles existent Boundary Representation B-Rep Un solide est modelise par les elements exterieurs. Cela donne une surface fermee Ensemble de : Faces, aretes et sommets + relations topologiques Les faces ne doivent pas s‚Äôintersecter ailleurs que sur des aretes explicites (de la B-REP) Les afces doivent separer l‚Äôinterieur de l‚Äôexterieur du solide Redondance des donnees $\\to$ risque d‚ÄôincoherenceModelisation d‚Äôune sceneDeformation/Mouvements/Objets articules Representation hierarchique Systeme de pile de matrices Deformations libresOn veut contorsionner un objet mais ses morceaux doivent restes coherents. Une solution: faire un volume de Bezier et modifier les points de controle Solution simple Pas la plus efficace Animation Generation de toutes les images qui composent l‚Äôanimations Il faut donc modeliser les transformations Deplacements Deformations Changement de couleur ‚Ä¶ Equation de mouvement Definitions des positions et orientations - trajectoire a suivre Position cle et interpolation Specification que de quelques positions puis interpolation automatique pour generer les positions intermediaires (pas facile de respecter toutes les contraintes) Modele physique Donne du realisme au mouvement L‚Äôordinateur calcul les positions intermediaires L‚Äôanimateur fait les images ‚Äúcles‚Äù de l‚ÄôanimationPositions cles Celle de droite c‚Äôest quand Fabrizio va voir mon raytracerVitesse du mouvementIl faut gere l‚Äôacceleration du mouvement entre 2 positions cles Un mouvement lineaire n‚Äôest pas realiste Il y a du travail sur l‚Äôexpression du visageLe monde de NemoFilmer des poissons reels pendant tres longtemps et reproduire le mouvementAnimations difficilesAnimation de personnages Definition de l‚Äôanimation complete du personnage Difficile et consommation memoire trop elevee Definition d‚Äôun ‚Äúsquelette‚Äù et d‚Äôune ‚Äúpeau‚Äù Le mouvement est specifie uniquement pour le squelette Gain de place Retournons sur la main:On a rajoute un squelette, si on veut bouger la main, on bouge le squelette. Le squelette de la main est anatomiquement faux Definition d‚Äôun ‚Äúsquelette‚Äù Le corps humain comporte environ 200 os Environ une centaine d‚Äôarticulations assemblage de segments rigides Structure arborescente hierarchique Rotation avec ajout de contraintes Cinematique inverse Trouver la bonne position Le deplacement des os entraine le deplacement de la peau La peau Cylindres Maillages ou surfaces (Splines‚Ä¶) Attachement de chaque point a un os Ponderation de l‚Äôattachement d‚Äôun point aux os voisins Modeles de muscles Modelisation par blobs et surfaces implicites Dans l‚Äôensemble ce type de modeles n‚Äôest plus trop utilise Modelisation des muscles par des ressorts Modelisation par particules hierarchiques Noyau: lie au reste du modele Derme: deformation del‚Äôobjet Epiderme: cohesion et surface + interaction et collisions avec le rest du monde $\\to$ Diminution de la complexite Interaction uniquement avec la couche voisine Interaction avec l‚Äôexterieur geree au niveau de l‚Äôepiderme diminution du nombre de particules diminution de la quantite de calculs Problemes de jointures Augmentation du maillage aux jointures Ajout d‚Äôos dans l‚Äôarticulation Ajout de contraintes: section minimal autour de chaque os.. Lissage des ponderations des contributions des os sur l‚Äôenrobage Animation de visagesQuelques positions modelisees Normal, souriatn.. Calcul automartique des transitions (morphing)Temps reel: Blend shape Position neutre Codage des deltas pour arriver a une position particuliereMotion capture Realisme important Des acteurs vont jouer la scene Jouent dans un hangar dans lequel ils sont geolocalises Ils auraient pu se peindre le visage en bleu mais ils ont pas oses Au moins ils ont des p‚Äôtites oreilles Camera: geolocaliseeMapping: C‚Äôest pendant l‚Äôentrainement, pas le hangarMouvement du visage:Une grosse bete va manger des chevaux:On va caller des modeles 3D de chevaux qui se feront mangerFonctionne de la meme facon que le motion capture avec les humains: Pas tous les filmes utilisent le motion capture, comme RatatouilleTissus et vetementsModeles masses-ressorts Maillage de Provot On met des ‚Äúmasses‚Äù Ajout de ressorts pour le cisaillement et la courbure Indique les contraintes physiques entre chacune des masses Collisions et autocollisions Beaucoup de calculs division de l‚Äôespace et volumes englobants Autocollisions Eviter que le tissus passe au travers de lui-meme en se repliant Conclusions Modelisatione et animation" }, { "title": "PRST: Feuille 3 - Exercice", "url": "/cours/posts/prst_third_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, estimateur, poisson, normale, geometrique, pareto, uniforme", "date": "2021-03-10 14:30:00 +0100", "snippet": "Lien de la note HackmdExercice du coursD√©terminer les estimateurs des param√®tres $m$ et $\\sigma$ 2 donn√©s par la m√©thode des moments pour une loi normale $N (m, \\sigma^2)$. Solution \\(E(\\lambda) = \\frac{1}{\\lambda}\\\\\\lambda = \\frac{1}{E(X)}\\\\\\hat\\lambda=\\frac{1}{\\bar X_n}\\) $X_n\\to^{P.S} \\frac{1}{\\lambda}$ loi forte des grand normbres\\[f:x\\mapsto\\frac{1}{x}, \\mathcal C^{\\gamma}\\\\]0;+\\infty[\\to\\mathbb R\\]Exercice 1Determiner un estimateur convergent et sans biais du parametre $\\lambda$ pour la loi de Poisson. Solution On sait que:\\[E(Y) = \\lambda\\] Donc l‚Äôestimateur d‚Äôordre 1 de parametre $\\lambda$ est:\\[\\hat\\lambda = \\bar X_n = \\frac{1}{n}\\sum_{i=1}^nX_i\\] L‚Äôestimateur est sans biais et il est fortement convergent par la loi forte des grand nombres.Exercice 2Determiner un estimateur du parametre $\\alpha$ pour la loi de Pareto par la methode des momets (cf. feuille1). Solution On sait que $E(X) = \\frac{\\alpha}{\\alpha -1}$\\[\\alpha -1E(X) = \\alpha\\\\\\alpha(E(X)-1) = E(X)\\\\\\alpha=\\frac{E(X)}{E(X) - 1}\\\\\\bar\\alpha\\frac{\\bar X}{\\bar X -1}\\]Exercice 3Determiner un estimateur du parametre $p$ pour une loi geometrique. Solution\\[X\\sim\\mathcal E(p)\\\\E(X) = \\frac{1}{p}\\\\\\text{donc } p = \\frac{1}{E(X)}\\\\\\bar p = \\frac{1}{X}\\]Exercice du cours loi de Pareto de parametre $\\alpha$ densite $f(x,\\alpha)=\\alpha x^{-\\alpha-1}$ pour $x\\gt1$ et $\\alpha\\gt0$ Determiner l‚ÄôEMV Solution\\[\\begin{aligned}L(x_1,...,x_n,\\alpha)&amp;amp;=\\Pi_{k=1}^nf(x_k,\\alpha)\\\\&amp;amp;= \\Pi_{k=1}^n\\alpha x^{-\\alpha-1}\\\\&amp;amp;= \\alpha^n\\Pi_{k=1}^nx^{-\\alpha-1}\\\\\\log(L(x_1,...,x_n,\\alpha)) &amp;amp;= n\\log(\\alpha)+\\sum_{k=1}^n\\log(xk^{-\\alpha-1})\\\\&amp;amp;= n\\log\\alpha-(\\alpha-1)\\sum_{k=1}^n\\log(xk)\\\\\\frac{\\delta L}{\\delta\\alpha} &amp;amp;= \\frac{n}{\\alpha}-\\sum_{k=1}^n\\log(x_k)\\\\\\frac{\\delta L}{\\delta\\alpha} = 0 &amp;amp;\\Leftrightarrow \\frac{n}{\\alpha}-\\sum_{k=1}^n\\log(x_k)=0\\\\&amp;amp;\\Leftrightarrow \\alpha=\\frac{n}{\\sum_{k=1}^n\\log(x_k)}\\\\&amp;amp;\\Leftrightarrow \\alpha=\\frac{1}{\\frac{1}{n}\\sum_{k=1}^n\\log(x_k)}\\\\\\frac{\\delta^2L}{\\delta\\alpha^2}&amp;amp;=-\\frac{n}{\\alpha^2}\\lt0\\\\\\hat\\alpha &amp;amp;= \\frac{1}{\\frac{1}{n}\\sum_{k=1}^n\\log(x_k)} \\Rightarrow\\text{ EMV}\\end{aligned}\\]Exercice 6Soit $X$ une varibale aleatoire suivant une loi uniforme sur $[0,\\theta]$. Quelle est la densite de la variable aleatoire $X$ ? Quelle est son esperance ? En deduire un estimateur du parametre $\\theta$ par la methode des moments Solution 1.\\[f(x,\\theta)=\\begin{cases} \\frac{1}{\\theta} &amp;amp;\\text{si } x\\in[0,\\theta]\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\] 2.\\[E(X) = 0 + \\frac{\\theta}{2} = \\frac{\\theta}{2} \\Rightarrow \\theta=2\\times E(X)\\] 3.\\[\\hat\\theta=2\\bar X\\]" }, { "title": "PRST: Seance 3, Convergences", "url": "/cours/posts/prst_convergences/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, convergence, central limite, estimateur, moment, maximum de vraisemblance, exponentielle", "date": "2021-03-10 14:30:00 +0100", "snippet": "Lien de la note HackmdModes de convergenceConvergence presque sure (p.s.) $(X_i)$ suite de v.a definies sur le m√™me espace $\\Omega$ et $X$ une variable al√©atoire √©galement d√©finie $\\Omega$. convergence ponctuelle implique tous les autres.Convergence en probabilite Meme cadre que precedemment $\\forall\\varepsilon\\gt0, \\lim_{n\\to+\\infty}P(\\vert X_n-X\\vert\\ge\\varepsilon)=0$Convergence $L^2$ aussi appelee convergence en moyenne quadratique $\\lim_{n\\to+\\infty}E(\\vert X_n-X\\vert)=0$ n‚Äôa de sens que pour les variables al√©atoires telles que $E(X^2)\\lt+\\infty$ implique la convergence en probabilit√©, n‚Äôa pas de lien avec la convergence presque s√ªre.Th√©or√®me Central LimiteTh√©or√®me 4 (Loi forte des grands nombres)Soit $(Xi)$ une suite de variables al√©atoires i.i.d. (ind√©pendantes et identiquement distribu√©es) telle que $E(\\vert X_1\\vert) &amp;lt; +\\infty$.Notons $m := E(X_1)$.\\[\\lim_{n\\to+\\infty}\\bar X_n = m\\]au sens de la convergence p.s. o√π $\\bar X_n := \\frac{X_1+‚Ä¶+X_n}{n}$Th√©or√®me 5 (T.C.L. cas unidimensionnel) Soit $(X_i)$ une suite v.a. i.i.d. Notons $m := E(X_i)$ et $\\sigma^2 = V(Xi)$ $\\frac{\\sqrt{n}(\\bar X_n - m)}{\\sigma}$ converge en loi vers une loi normale centr√©e r√©duite.Cas multidimentionnel Soit $(X_i)$ une suite de vecteurs aleatoires de $\\mathbb R^p$ i.i.d. Notons $m:=E(X_i)\\in\\mathbb R^p$ et $\\Sigma$ la matrice de variances-covariances $\\sqrt{n}\\biggr(\\frac{1}{n}\\sum_{i=1}^nX_i-m\\biggr)$ converge en loi vers une loi normale multidimensionnelle $\\mathcal N(0, \\Sigma)$Premieres notions de statistiqueEchantillon de taille $n$ Point de depart: v.a. $X$ dont l‚Äôensemble des valeurs est note $\\mathcal H$ Donnee $n$ variables aleatoires i.i.d. A parti de l‚Äôechantillon, nous voudrons inferer la valeur d‚Äôun parametre (fini-dimensionnel) en estimation parametrique ou prendre une decision en decision statistiqueModele statistique $\\theta\\in\\mathbb R^d$ $\\Theta\\subset\\mathbb R^d$ ensemble des parametres $\\mathcal P:={\\mathbb P_{\\theta}\\vert\\theta\\in\\Theta}$ famille de lois indexees par $\\Theta$ But: estimer la valeur $\\theta_0$ ou de $g(\\theta_0)$ Estimateur: fonction (mesurable) $\\hat\\theta:\\mathcal H^n\\to\\mathbb R^d$ Exemple pour le parametre $\\lambda$ d‚Äôune loi $\\mathcal P(\\lambda)$ $\\Theta=]0;+\\infty[$ $\\mathcal H=\\mathbb N$RappelEstimateur propose $\\hat\\lambda:\\mathcal H^n\\to]0;+\\infty[$ $\\hat\\lambda(x_1, ‚Ä¶, x_i):=\\frac{1}{n}\\sum_{i=1}^nx_i$ $\\hat\\lambda$ moyenne empiriqueEstimateur sans biais $b(\\hat\\theta_n):=E(\\hat\\theta_n)-\\theta$ dans l‚Äôexemple: $\\hat\\lambda_n$ est sans biaisPourquoi l‚Äôestimateur est-il sans biais ?Pour tout $i\\in{1,‚Ä¶,n}$, $X_i\\sim\\mathcal P(\\lambda)$.\\[\\begin{aligned}E(X_i) &amp;amp;= \\lambda\\\\E(\\hat \\lambda) &amp;amp;= E(\\frac{1}{n}\\sum_{i=1}^nY_i)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^nE(X_i)\\\\&amp;amp;= \\frac{1}{n}\\sum_{i=1}^n\\lambda\\\\&amp;amp;= \\frac{1}{n}\\times n\\lambda = \\lambda\\end{aligned}\\]Estimateur convergent $\\hat\\theta_n$ convergent si $\\hat\\theta_n$ converge en probabilit√© vers $\\theta$ $\\hat\\theta_n$ fortement convergent si $\\hat\\theta_n$ converge presque s√ªrement vers $\\theta$Estimateurs de l‚Äôesperance et de la variance: cas general Pour l‚Äôesperance: $\\bar X_n:=\\frac{1}{n}\\sum_{i=1}^nx_i$ a moyenne empirique Pour la variance: $S_n‚Äô^2:=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar x_n)^2$ qui est aussi √©gale √† $\\frac{1}{n}\\sum_{i=1}^nx_i^2-\\bar x_n^2$ la variance empirique $\\bar X_n$ sans biais par contre $S_n‚Äô^2$ biais√© $S_n‚Äô^2$ parfois remplac√© par $S_n^2=\\frac{n}{n-1}S_n‚Äô^2$ qui est sans biais tous trois fortement convergents d‚Äôapr√®s la loi forte des grands nombres.Methode des moments Exploiter les moyennes et variances empiriques moyennes et variances sont remplaces par leurs contreparties empiriques fournit (en g√©n√©ral) des estimateurs convergents du fait de la convergence des moyennes et variances empiriques Exemple de la loi exponentielle: $E(X)=\\frac{1}{\\lambda}$ donc $\\lambda=\\frac{1}{E(X)}$ estimateur de $\\lambda$ donn√© par la m√©thode des moments: $\\hat\\lambda=\\frac{1}{\\bar X_n}$ $E(X^2)$ peut √™tre remplac√© par $\\frac{1}{n}\\sum_{i=1}^nx_i^2$ suivant le m√™me principe les moments et moments centr√©s d‚Äôordre sup√©rieur peuvent √™tre utilis√©s suivant le m√™me principe D√©terminer un autre estimateur donn√© par la m√©thode des moments pour la loi de Poisson.Methode du maximum de vraisemblancePrincipe Rechercher la valeur de $\\theta$ en fonction des observations $x_1,‚Ä¶,x_n$ assurant la plus grande probabilit√© d‚Äôobtenir ces observations.Fonction de vraisemblance $\\mathcal H$ ensemble des valeurs que peut prendre la variable al√©atoire $X$ pour la loi normale $\\mathcal H=\\mathbb R$ pour la loi normale $\\mathcal H=\\mathbb N$ loi depend de $\\theta$ donc la densite associee aussi que nous noterons $f(x,\\theta)$ Fonction de vraisembalnce \\[L(x_1,...x_n,\\theta):=\\Pi_{i=1}^nf(x_i,\\theta)\\]Maximum de vraisemblance fonction $\\hat \\theta$ de $x_1,‚Ä¶,x_n$ Qui maximise $L$ i.e. telle que $L(x,\\hat\\theta)\\ge L(x,\\theta)$ pour tout $\\theta\\in\\Theta$ o√π $\\Theta$ est l‚Äôespace des param√®tresCas unidimensionnel Si $L$ est de classe $\\mathcal C^2$ (i.e. deux fois derivable par rapport $\\theta$ et de derivee seconde continue), $\\hat\\theta$ est solution du systeme \\(\\begin{cases} \\frac{\\delta L}{\\delta \\theta} &amp;amp;= 0\\\\ \\frac{\\delta^2 L}{\\delta \\theta^2} &amp;amp;\\lt 0\\\\\\end{cases} (1)\\) La condition 1 est n√©cessaire et la condition 2 est sufisante. La condition 1 s‚Äôappelle l‚Äô√©quation de vraisemblance Pour simplifier les calculs, on peut remplacer la vraisemblance par la log-vraisemblance car la fonction logarithme est de classe $\\mathcal C^2$ et strictement croissante sur $]0; +\\infty[$. Ainsi $\\hat\\theta$ est solution du systeme: \\(\\begin{cases} \\frac{\\delta \\log L}{\\delta \\theta} &amp;amp;= 0\\\\ \\frac{\\delta^2 \\log L}{\\delta \\theta^2} &amp;amp;\\lt 0\\\\\\end{cases} (2)\\) La condition 1 est n√©cessaire et la condition 2 est sufisante.Logarithme Particulierement utile car: $\\log(ab) = \\log(a) + \\log(b)$ $\\log(\\frac{a}{b}) = \\log(a) - \\log(b)$ $\\log(a^x) = x\\log(a)$Exemple de la loi exponentielle $L(x,\\lambda)=\\Pi_{k=1}^n\\lambda e^{-\\lambda x_k} = \\lambda^ne^{-\\lambda}\\sum_{k=1}^nx_k$ $\\log(L(x,\\lambda)) = n\\log(\\lambda) - \\lambda\\sum_{k=1}^nx_k$ $\\log(\\frac{\\theta L}{\\theta\\lambda}(x,\\lambda)) = \\frac{n}{\\lambda}-\\sum_{k=1}x_k$ Condition n√©cessaire : $\\hat\\lambda(x)$ solution de :\\[\\frac{n}{\\lambda}-\\sum_{k=1}x_k = 0\\\\\\hat\\lambda(x) = \\frac{n}{\\sum_{k=1}^nx_k}\\] Condition sufisante: $\\frac{\\delta^2\\log L}{\\delta\\lambda^2}=-\\frac{n}{\\lambda^2}\\lt0$ La condition sufisante est satisfaite donc $\\hat\\lambda(x)$ est bien le maximum de vraisemblance. Estimateur du maximum de vraisemblance $\\hat\\lambda_n = \\frac{n}{\\sum_{k=1}^n} = \\frac{1}{\\bar X_n}$ Il est fortement convergent d‚Äôapres la loi fort des grands nombres" }, { "title": "DBRE: Titularite des droits d&#39;auteurs", "url": "/cours/posts/dbre_droits_auteur/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-10 12:00:00 +0100", "snippet": "Lien de la note HackmdPluralite d‚ÄôauteursCas de la pluralite d‚Äôauteurs: Prevu par la loi Cas extremement frequent2 cas de figures:1. Une oeuvre est incorporee dans une autreOn a une oeuvre a plusieurs contributeurs mais les contributeurs ne travaillent pas ensemble Ce sont des oeuvres composites, oeuvre qui vont integrer des oeuvres pre-existantes. Ex: une traductionSi on veut utiliser une oeuvre qui appartient a quelqu‚Äôun d‚Äôautre, on peut remunerer l‚Äôauteur original ou gratuitement. La gratuite est toujours ecrite noire sur blanc, jamais implicite. La remuneration de l‚Äôauteur original est proportionnelle aux recettes.Si on utilise l‚Äôimage de quelqu‚Äôun dans un manuel de 1000 pages, il est plus rentable de s‚Äôacquitter d‚Äôun forfait.2. Collaboration/collectiveOn a plusieurs auteurs qui vont concourir a la realisation d‚Äôune oeuvre.Dans le droit intellectuel: Oeuvre de collaboration Oeuvre collective Le regime de ces 2 cas est tres different.Oeuvre de collaboration Oeuvre de collaboration: on a plusieurs auteurs qui vont concourir ensemble a la realisation de l‚Äôoeuvre et qui vont se concerter entre elles. Ex: le developpement d‚Äôun logiciel, projet etudiant, comedie musicaleLes differents contributeurs se concertent entre eux, il n‚Äôy a pas de tiers qui intervient.Regime juridique:Ils sont co-auteurs et donc soit: Ils exploitent l‚Äôoeuvre en ayant passe un contrat entre eux Chacun cede ses droits a l‚Äôun d‚Äôentre eux ou un tiereOeuvre collective Oeuvre collective: Oeuvre cree a l‚Äôinitative d‚Äôune personne (physique ou morale).Cette personne est invastie des droits d‚Äôauteurs, et va sous son nom: L‚Äôediter La publier La divulguer Ce qui distingue l‚Äôoeuvre collective et la collaboration, c‚Äôest les conditions pratiques de sa realisation.Dans le monde reelSi une entreprise n‚Äôarrive pas a prouver les conditions pratiques de la realisation d‚Äôun projet, les droits reviennent aux employes suite a un tribunal. Pas de preuves, pas de droits. Pas de bras, pas de chocolatsSi on pretend a des conditions pratiques qui sont en realite autre ? Ex: Uber, relation plus proche de salaries/entreprise (contrat de travail) que prestation de service du point de vue d‚Äôun jugePour une oeuvre collective, il faut pas juste signer un papier mais concretement le mettre en place (intervention d‚Äôun tiers pour harmoniser les apports communs).Duree des droits d‚Äôauteurs:Pour les personnes physiques: 70 ans apres la mort de cet auteur Periode: a partir du 1$^{er}$ janvier Cette duree peut etre prolongee (ex: Saint-Exupery mort au combat, ses ayant-droits percoivent toujours ses droits d‚Äôauteurs) aussi lorsque l‚Äôauteur meurt jeune Disney: utilisent des ‚Äúruses‚Äù Peut egalement etre raccourcie Si chanson d‚Äôun artiste-interprete, retombera plus vite dans le domaine publique Droits d‚Äôune oeuvre Droits partioniaux Droits moraux Perpetuel Imprescriptible Inalienable ou incessible Une oeuvre dans le domaine public est une oeuvre libre du droit patrimoniaux, mais pas du droit moral.Dire qu‚Äôune oeuvre dans le domain publique est libre de droit est un abus de langage.Un auteur qui n‚Äôutiliserai pas son droit moral ne l‚Äôa pas perdu et peut le faire valoir a tout moment. L‚Äôauteur ne peut pas ceder de facon generale son droit d‚Äôauteur car contraire a un principe d‚Äôordre publique. Attendu que l‚Äôinali√©nabilit√© du droit au respect de l‚Äôoeuvre, principe d‚Äôordre public, s‚Äôoppose √† ce que l‚Äôauteur abandonne au cessionnaire, de fa√ßon pr√©alable et g√©n√©rale, l‚Äôappr√©ciation exclusive des utilisation, diffusion, adaptation, retrait, adjonction et changement auxquels il plairait √† ce dernier de proc√©der ; Droit au nom Droit de retrait et de repentir (pas pour le logiciel) Droit au respect (tres limite par le logiciel)En cas d‚Äôadaptation, de changement de support ou de genre qu‚Äôil y a le plus de probleme avec le droit au respect." }, { "title": "ASE2: Convergence et estimation - 2", "url": "/cours/posts/ase2_convergence_et_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, convergence, normale, gamma, poisson, loi, Mac-Laurin, Moivre-Laplace, central limite", "date": "2021-03-10 09:30:00 +0100", "snippet": "Lien de la note HackmdIntroductionLe probl√®me central de l‚Äôestimation en statistique est le suivant : disposant d‚Äôobservations sur un √©chantillon de taille $n$ on souhaite en d√©duire les propri√©t√©s de la population dont il est issu.On cherchera √† estimer, par exemple, la moyenne d‚Äôune population √† partir de la moyenne d‚Äôun √©chantillon. Le mode de tirage le plus important est l‚Äô√©chantillonnage al√©atoire simple correspondant √† des tirages √©quiprobables et ind√©pendants les uns des autres.L‚Äôune des premi√®res qualit√©s d‚Äôun estimateur est d‚Äô√™tre convergent en probabilit√© vers le param√®tre √† estimer. Un √©chantillon de $X$ est une suite de variables al√©atoires $(X_1,X_2,‚Ä¶,X_n)$ ind√©pendantes et de m√™me loi que $X$. Un estimateur d‚Äôun param√®tre $\\theta$ inconnu est une fonction qui d√©pend de l‚Äô√©chantillon et donc doit converger en probabilit√© vers le param√®tre $\\theta$. La pr√©cision d‚Äôun estimateur sera mesur√© par sa variance.Rappels de la loi Gamma et la loi Normale On dit qu‚Äôune variable al√©atoire positive $X$ suit une loi gamma de param√®tre $r$, not√©e $\\gamma_r$ si sa densit√© est donn√©e par :\\[f(x) = \\frac{1}{\\Gamma(r)}e^{-x}x^{r -1}\\] Avec $\\Gamma(x) = \\int_0^{+\\infty}e^{-t}t^{x-1}dt$ (fonction Gamma) definie pour $x\\gt0$Propri√©t√©s de la fonction Gamma $\\Gamma(x+1)=x\\Gamma(x)$ (int√©gration par partie) $\\Gamma(1) = 1$ $\\Gamma(n+1)=n!$ $\\Gamma(k+\\frac{1}{2})=\\frac{1.3.5‚Ä¶..(2k-1)}{2^k}\\Gamma(\\frac{1}{2})$ $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$Esp√©rance de la loi $\\gamma_r$ : Soit $X$ une variable al√©atoire suivant la loi gamma de param√®tre $r$.\\(E(X)=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}te^{-t}t^{r-1}dt=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^{r}e^{-t}dt=\\frac{\\Gamma(r+1)}{\\Gamma(r)}=r\\)Variance de la loi $\\gamma_r$ : $V(X) = E(X^2)-E^2(X)$\\[E(X^2)=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^2e^{-t}t^{r-1}=\\frac{1}{\\Gamma(r)}\\int_0^{+\\infty}t^{r+1}e^{-t}dt = \\frac{\\Gamma(r+2)}{\\Gamma(r)} = r(r+1)\\]Donc $V(X) = r(r+1)-r^2 =r$.Loi Normale de param√®tres$(m,\\sigma)$ On dit qu‚Äôune variable al√©atoire $X$ suit la loi normale not√©e $\\mathcal N(m,\\sigma)$ si sa densit√© est\\[f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-m}{\\sigma})^2}\\] o√π: $m = E(X)$ $\\sigma = \\sqrt{V(X)}$ (√©cart type) Avec le changement de variable $U=\\frac{X-m}{\\sigma}$ (variable normale centr√©e r√©duite), la densit√© de $U$ est:\\[f(u) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}u^2}\\]DemonstrationMontrons que $V(U) = 1$.On a:\\(V(U) = E(U^2) = \\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}}u^2e^{-\\frac{1}{2}u^2}du = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}u^2e^{-\\frac{1}{2}u^2}du\\)Posons $t=\\frac{u^2}{2}$, $dt = udu$\\(V(U) = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}2te^{-t}\\frac{dt}{\\sqrt{2t}} = \\frac{2}{\\sqrt{\\pi}}\\Gamma(\\frac{3}{2})=\\frac{2}{\\sqrt{\\pi}}\\frac{1}{2}\\Gamma(\\frac{1}{2})\\)Donc $V(U) = \\frac{1}{\\sqrt{\\pi}}\\sqrt{\\pi}=1$Moments de la loi normale centr√©e r√©duiteSoit $U$ une variable normale centr√©e r√©duite, on appelle moment d‚Äôordre $k$ de $U$ : $u_k=E(U^k)$ Si $k=2p+1$ alors $u_{2p+1} = 0$ (car fonction impaire) Si $k=2p$ alors $u_{2p} = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}u^{2p}e^{-\\frac{1}{2}u^2}du = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}u^{2p}e^{\\frac{1}{2}u^2}du$Posons $t=\\frac{u^2}{2}$, $dt=udu$\\[u_{2p} = \\frac{2}{\\sqrt{2\\pi}}\\int_0^{+\\infty}(2t)^pe^{-t}\\frac{dt}{\\sqrt{2t}}=\\frac{2^p}{\\sqrt{\\pi}}\\int_0^{+\\infty}t^{p-\\frac{1}{2}}e^{-t}dt = \\frac{2^p}{\\sqrt{\\pi}}\\Gamma(p+\\frac{1}{2})\\\\\\text{Or } \\Gamma(p+\\frac{1}{2}) = \\frac{1.3.5...(2p-1)}{2^p}\\Gamma(\\frac{1}{2}) \\text{ et } \\Gamma(\\frac{1}{2})=\\sqrt{\\pi}\\\\\\text{Donc } u_{2p}=1.3.5....(2p-1)=\\frac{(2p)!}{2^pp!}\\]Fonctions caract√©ristiques Definition: la fonction caract√©ristique d‚Äôune variable al√©atoire r√©elle $X$ est la transform√©e de Fourier de sa loi de probabilit√©. Elle est not√©e $\\phi_X(t)$ et on a:\\[\\phi_X(t)=E(e^{itX}) \\text{ (} i \\text{ complexe)}\\]Si $X$ est une variable √† densit√© ($X$ est une v.a continue de densit√© $f$) alors :\\[\\phi_X(t) = \\int_{\\mathbb R}e^{itx}f(x)dx\\]Si $X$ est une variable discr√®te alors sa fonction caract√©ristique est :\\[\\phi_X(t)=\\sum_ke^{itk}P(X=k)\\]Propri√©t√©s $\\phi_{\\lambda x} = \\phi_X(\\lambda t)$, $\\forall\\lambda$ un scalaire $\\phi_{X+a}(t)=e^{ita}\\phi_X(t)$, $\\forall a$ un scalaire Si $X$ est une variable al√©atoire d‚Äôesp√©rance $m$ et d‚Äô√©cart type $\\sigma$ et $U = \\frac{X-m}{\\sigma}$\\[\\phi_{\\frac{X-m}{\\sigma}} = \\phi_U(t) = e^{-\\frac{itm}{\\sigma}}\\phi_X(\\frac{t}{\\sigma})\\]RemarqueLa fonction caract√©ristique se pr√™te bien aux additions de variables al√©atoires ind√©pendantes.Si $X$ et $Y$ sont deux variables al√©atoires ind√©pendantes alors \\(\\phi_{X+Y}(t) = \\phi_X(t)\\phi_Y(t)\\\\\\text{En effet } \\phi_{X+Y}(t) = E(e^{it(X+Y)})=E(e^{itX}e^{itY})\\\\\\text{Or } X \\text{ et } Y \\text{ sont ind√©pendantes } E(e^{itX}e^{itY}) = E(e^{itX})E(e^{itY})\\\\\\text{Donc } \\phi_{X+Y}(t)=\\phi_X(t)+\\phi_Y(t)\\)PropositionSoit $X$ une variable al√©atoire de fonction de r√©partition $\\phi_X(t)$.On a $\\phi_x(0)=1$ et $\\frac{d^k\\phi_X}{dt^k}(0)=\\phi_X^{(k)}(0)=i^kE(X^k)$D√©moSupposons que $X$ est une variable continue de densit√© $f$On a:\\[\\phi_X(t)=\\int_{\\mathbb R}e^{itx}f(x)dx\\Rightarrow\\phi_X(0)=\\int_{\\mathbb R}f(x)dx=1 \\text{ (car f est une densit√©)}\\\\\\text{En d√©rivant } \\phi_X(t) \\text{ par rapport √† t: } \\phi_X&#39;(t)=i\\int_{\\mathbb R}xe^{itx}f(x)dx\\\\\\text{Si } t=0: \\phi_X&#39;(t)i\\int_{\\mathbb R}xf(x)dx=iE(x)\\\\\\text{Si on d√©rive 2 fois, } \\phi_X^{(2)}(t)=\\int_{\\mathbb R}(itx)^2e^{itx}f(x)dx\\\\\\text{En d√©rivant k fois par rapport √† t: }\\phi_X(t)^{k}(t)=\\int_{\\mathbb R}(ix)^ke^{itx}f(x)dx\\\\\\text{Donc } \\phi_x^{(k)}(0)=(i^k)\\int_{\\mathbb R}x^kf(x)dx=i^kE(X^k),\\forall k\\in\\mathbb N\\]Formule de Mac-LaurinSi $\\phi_X(t)$ est ind√©finiment d√©rivable on a:\\[\\phi_X(t)=\\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}\\phi_X^{(k)}(0)=\\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}i^kE(X^k)\\]Exemple 1Soit X une variable al√©atoire continue de densit√©:\\[f(x)=\\begin{cases} e^{-x} &amp;amp;\\text{si } x\\gt0\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\]D√©terminer la fonction caract√©ristique de $X$ Solution\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\int_{\\mathbb R}e^{itx}f(x)dx=\\int_{-\\infty}^{+\\infty}e^{itx}e^{-x}dx=\\int_{0}^{+\\infty}e^{-(1-it)x}dx\\\\&amp;amp;= \\int_{0}^{+\\infty}e^{-(1-it)x}dx=\\biggr[\\frac{-e^{-(1-it)x}}{1-it}\\biggr]_0^{+\\infty}=\\frac{1}{1-it}\\end{aligned}\\] Car $-e^{-(1-it)x}=e^{-x}e^{itx}\\to0$ lorsque $x\\to+\\infty$. Puisque $e^{itx}$ est born√©e de module 1 et $e^{-x}\\to0$ quand $x\\to+\\infty$Exemple 2D√©terminer la fonction caract√©ristique de la loi de Bernoulli de param√®tre $p$ Solution Soit $X$ une variable de Bernoulli\\[\\begin{cases}X=1 &amp;amp;\\text{avec la probabilit√© }p\\\\X=0 &amp;amp;\\text{avec la probabilit√© }1-p\\end{cases}\\] X √©tant discr√®te, donc sa fonction caract√©ristique est:\\[\\begin{aligned}\\phi_X(t)&amp;amp;=\\sum_ke^{itk}P(X=k)=\\sum_{k=0}^1e^{itk}P(X=k)=P(X=0)+e^{it}P(X=1)\\\\&amp;amp;= 1-p+pe^{it}=q+pe^{it} \\text{ avec } q=1-p\\end{aligned}\\]Convergences des suites de variables al√©atoiresUne suite $(X_n)$ de variables al√©atoires √©tant une suite de fonctions il existe diverses fa√ßons de d√©finir la convergence de $(X_n)$ dont certaines jouent un grand r√¥le en statistiques.Convergence en probabilit√© DefinitionLa suite $(X_n)$ converge en probabilit√© vers une variable al√©atoire $X$ si $\\forall\\varepsilon\\gt0, \\eta\\gt0$ (arbitrairement petits) il existe un entier $n_0$ tel que $\\forall n\\gt n_0\\Rightarrow P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$, c‚Äôest-√†-dire $P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$. On notera $(X_n)\\to^PX$.In√©galit√© de Bienaym√©-Tchebychev\\[P(\\vert X_n-E(X)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2},\\forall\\varepsilon\\gt0\\]RemarqueLorsque $E(X_n)\\to_{n\\to+\\infty}a$, il suffit de montrer que $V(X_n)\\to_{n\\to+\\infty}0$ pour √©tablir la convergence en probabilit√© de la suite $(X_n)$ vers $a$.En effet d‚Äôapr√®s Tchebychev: $P(\\vert X_n-E(X_n)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2}\\to0$Donc en passant √† la limite $\\lim_{n\\to+\\infty}P(\\vert X_n-a\\vert\\gt\\varepsilon)=0,\\forall\\varepsilon\\gt0$Convergence en moyenne quadratiqueOn suppose que $E(\\vert X_n-X\\vert^2)$ existe DefinitionOn dit qu‚Äôune suite de variables al√©atoires $(X_n)$ converge en moyenne quadratique vers une variable $X$ si $E(\\vert X_n-X\\vert^2)\\to_{n\\to+\\infty}0$ On notera $(X_n)\\to^{m.q}X$Convergence en loi DefinitionLa suite $(X_n)$ converge en loi vers la variable $X$ de fonction de r√©partition $F$ si en tout point de continuit√© de $F$ la suite $(X_n)$ des fonctions de r√©partition des $(X_n)$ converge vers $F$. C‚Äôest-√†-dire $\\lim_{n\\to+\\infty}F_n(x)=F(x)$ pour tout $x$ point de continuit√© de $F$. On notera $(X_n)\\to^LX$RemarquePour les variables discr√®tes, la convergence en loi est √©quivalente √†\\[\\lim_{n\\to+\\infty}P(X_n=k)=P(X=k)\\]Th√©or√®me Si la suite des fonctions caract√©ristiques $\\phi_{X_n}(t)$ converge vers $\\phi_X(t)$ alors $(X_n)\\to^LX$Applications: Convergence en loi de la binomiale vers la loi NormaleTh√©or√®me (Moivre-Laplace) Soit $(X_n)$ une suite de variables binomiales $\\mathcal B(n,p)$ alors\\[\\frac{X_n-np}{\\sqrt{npq}}\\to^L\\mathcal N(0,1) \\text{ lorsque } n\\to+\\infty\\]D√©monstrationLa fonction caract√©ristique de la loi $\\mathcal B(n,p)$ est:\\[\\phi_{X_n}(t)=(pe^{it}+1-p)^n \\text{ donc celle de } Y_n=\\frac{X_n-np}{\\sqrt{npq}} \\text{ est:}\\\\\\phi_{Y_n}(t) = (pe^{\\frac{it}{\\sqrt{npq}}}+1-p)^ne^{\\frac{-itnp}{\\sqrt{npq}}}\\\\\\ln(\\phi_{Y_n}(t))=nLn(p(e^{\\frac{it}{\\sqrt{npq}}}-1)+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle le d√©veloppement limit√© de l‚Äôexponentielle √† l‚Äôordre 2\\[e^x\\simeq1+x+\\frac{x^2}{2} \\text{(au voisinage de 0)}\\\\\\ln(\\phi_{Y_n}(t))\\simeq n\\ln(p(\\frac{it}{\\sqrt{npq}}-\\frac{t^2}{2npq})+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle $\\ln(1+x)\\simeq x-\\frac{x^2}{2}$ (au voisinage de 0)Donc:\\(\\begin{aligned}\\ln(\\phi_{Y_n}(t))&amp;amp;\\simeq n\\biggr[\\frac{pit}{\\sqrt{npq}}-\\frac{pt^2}{2npq}+\\frac{p^2t^2}{2npq}\\biggr]-\\frac{itnp}{\\sqrt{npq}}\\\\&amp;amp;\\simeq-\\frac{t^2}{2q}+\\frac{pt^2}{2q}=\\frac{t^2}{2q}(p-1)=-\\frac{t^2}{2}\\end{aligned}\\)En composant par l‚Äôexponentielle:\\[\\phi_{Y_n}(t)\\simeq e^{-\\frac{t^2}{2}}\\] fonction caract√©ristique de la loi normale $\\mathcal N(0,1)$Conclusion $\\frac{X_n-np}{\\sqrt{npq}}\\to^L\\mathcal N(0,1)$Remarquelorsque n est assez grand on peut donc approximer la loi Binomiale par la loi normale. On donne g√©n√©ralement comme condition $np$ et $nq\\gt5$.Il convient cependant d‚Äôeffectuer la correction de continuit√© : on obtient donc une valeur approch√©e de $P(X=x)$ par la surface sous la courbe de densit√© de la loi normale $\\mathcal N(np,\\sqrt{npq})$ comprise entre les droites d‚Äôabscisse $x-\\frac{1}{2}$ et $x+\\frac{1}{2}$\\[P(X=x)\\simeq P(x-\\frac{1}{2}\\lt X\\lt x+\\frac{1}{2})=P\\biggr(\\frac{x-\\frac{1}{2}-np}{\\sqrt{npq}}\\lt \\frac{X-np}{\\sqrt{npq}}\\lt \\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}}\\biggr)\\\\\\text{Et } P(X\\lt x)\\simeq P\\biggr(\\frac{X-np}{\\sqrt{npq}}\\lt \\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}}\\biggr)\\]ExempleSoit X une variable binomiale $\\mathcal B(n=40; p=0,3)$.La valeur exacte pour $P(X=11)$ est $0,1319$.La formule d‚Äôapproximation : \\(P(X=11)\\simeq P\\biggr(\\frac{11-\\frac{1}{2}-12}{\\sqrt{8,4}}\\lt \\frac{X-12}{\\sqrt{8,4}}\\lt \\frac{11+\\frac{1}{2}-12}{\\sqrt{8,4}}\\biggr)=P(-0,52\\lt U\\le-0,17)=0,131\\)Avec $np=12$ et $npq=8,4$Donc l‚Äôerreur est de moins de $1\\%$Convergence en loi de la loi de Poisson vers la loi normale TheoremeSoit $(X_{\\lambda})$ une suite de variables de Poisson de param√®tre $\\lambda$. Si $\\lambda\\to+\\infty$, $\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}}\\to^L\\mathcal N(0,1)$D√©monstrationon rappelle la fonction caract√©ristique de la loi de Poisson:\\[\\phi_{X_i}(t)=e^{\\lambda e^{it}-\\lambda}\\]On rappelle aussi la formule $\\phi_{\\frac{X-m}{\\sigma}}=e^{-\\frac{it\\lambda}{\\sqrt{\\lambda}}+\\lambda+\\frac{\\lambda it}{\\sqrt{\\lambda}}-\\frac{t^2}{2}-\\lambda}=e^{-\\frac{t^2}{2}}$ On retrouve la fonction caract√©ristique de la loi normale centr√©e et r√©duite.Conclusion $\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}}\\to^L\\mathcal N(0,1)$Th√©or√®me (Central-limite) Soit $(X_n)$ une suite de variables al√©atoires, ind√©pendantes et de m√™me loi d‚Äôesp√©rance $m$ et d‚Äô√©cart-type $\\sigma$ alors :\\[\\frac{X_1+X_2+....+X_n-nm}{\\sigma\\sqrt n}\\to\\mathcal N(0,1)\\]D√©monstration\\[\\frac{X_1+X_2+....+X_n-nm}{\\sigma\\sqrt n}\\to\\mathcal N(0,1) = \\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt n}\\]Posons $Y_n=\\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt n}$\\[E(\\frac{X_i-m}{\\sigma\\sqrt n})=\\frac{E(X_i)-m}{\\sigma\\sqrt {n}}=0 \\\\\\text{et}\\\\V(\\frac{X_i-m}{\\sigma\\sqrt n})=\\frac{1}{\\sigma^2 n}V(X_i)=\\frac{\\sigma^2}{n\\sigma^2}=\\frac{1}{n}\\]La fonction caract√©ristique de $Y_n=\\sum_{i=1}^n\\frac{X_i-m}{\\sigma\\sqrt{n}}$ est:\\[\\phi_{Y_n}(t) = \\Pi_{i=1}^n\\phi_{\\frac{X_i-m}{\\sigma\\sqrt{n}}}(t)=\\phi_{\\frac{X_i-m}{\\sigma\\sqrt{n}}}(t)^n=(1-\\frac{t^2}{2n}+o(\\frac{1}{n^2}))^n\\]On rappelle que $(1+\\frac{x}{n})^n\\to e^{x}$Car $(1+\\frac{x}{n})^n=e^{n\\ln(1+\\frac{x}{n})}\\simeq e^{n\\frac{x}{n}}=e^x$Donc $\\phi_{Y_n}(t)=(1-\\frac{t^2}{2n}+o(\\frac{1}{n^2}))^n\\to e^{-\\frac{t^2}{2}}$ lorsque $n\\to+\\infty$Estimateurs D√©finitionSoit $(X_1,X_2,‚Ä¶,X_n)$ un √©chantillon de $X$, c‚Äôest-√†-dire une suite de variables al√©atoires ind√©pendantes et de m√™me loi que $X$. La statistique $\\bar X$ ou moyenne empirique de l‚Äô√©chantillon est:\\[\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\]\\[E(\\bar X)=\\frac{1}{n}\\sum_{i=1}^n E(X_i)=\\frac{nm}{n}=m \\text{ o√π } m=E(X)\\\\V(\\bar X)=\\frac{1}{n^2}\\sum_{i=1}^n V(X_i)=\\frac{n\\sigma^2}{n^2}=\\frac{\\sigma^2}{n}\\to 0 \\text{ lorsque } n\\to+\\infty\\]Donc d‚Äôapr√®s Tchebychev $\\bar X=\\frac{1}{n}\\sum_{i=1}^nX_i\\to^Pm=E(X)$ quand $n\\to+\\infty$ C‚Äôest la loi des grands nombres." }, { "title": "ASE2: Rappels sur les lois", "url": "/cours/posts/ase2_rappels/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, loi, normale, poisson, exponentielle, geometrique", "date": "2021-03-10 09:00:00 +0100", "snippet": "Lien de la note HackmdLoi normale centree reduite $E(X) = 0$ $V(X) = 1$ $f(X) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{t^2}{2}}$ $F(X) = \\frac{1}{\\sqrt{2\\pi}}\\int_0^Xe^{-\\frac{t^2}{2}}$Loi Poisson $P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$ (avec $\\lambda = \\frac{1}{n}$)\\[P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!} \\text{ (avec } \\lambda = \\frac{1}{n}\\text{)}\\\\P(X_n = k)= e^{-\\frac{1}{n}}\\frac{1}{n^kk!}, \\forall k\\in\\mathbb N\\] Si $k=0$, $P(X_n = 0) = e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ Si $k\\ge1$, $P(X_n=k)=\\frac{1}{n^kk!}e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ car $\\frac{1}{n^k}\\to_{n\\to+\\infty}0$Loi exponentielle $E(X) = \\frac{1}{\\lambda}$ $V(X) = \\frac{1}{\\lambda^2}$ Densit√© de probabilit√©:\\[\\begin{cases} f(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\ f(t)=\\frac{1}{E(X)}e^{-\\frac{t}{E(X)}} &amp;amp;\\forall t\\ge0\\end{cases}\\\\\\Leftrightarrow \\begin{cases} f(t)=\\lambda e^{-\\lambda t} &amp;amp;\\text{si } t\\ge0\\\\ f(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\\\end{cases}\\] Fonction de r√©partition:\\[\\begin{cases} F(t)=1 - e^{-\\lambda t} &amp;amp;\\text{si } t\\ge0\\\\ F(t)=0 &amp;amp;\\text{si }t \\lt 0\\\\\\end{cases}\\]Loi geometrique $E(X)=\\frac{1}{p}$ $V(X) = \\frac{1-p}{p^2}$$(X_n), n\\gt0$ une suite de v.a. geometrique $G(\\frac{1}{n})$ avec $p=\\frac{1}{n}$ parametre.\\[\\begin{aligned}P(X_n = k) &amp;amp;= (1-p)^{k-1}p, \\forall k\\ge1\\\\&amp;amp;= (1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\end{aligned}\\]" }, { "title": "ASE2: TD 1, suite (encore)", "url": "/cours/posts/ase2_exercices_convergence_estimation_suite/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8, convergence, normale, loi", "date": "2021-03-10 09:00:00 +0100", "snippet": "Lien de la note HackmdExercice 5Soit $X$ une v.a. normale centree et reduite $X\\to\\mathcal N(0,1)$.Montrer que $\\forall x\\in\\mathbb R^*_+$\\[\\int_0^x e^{-\\frac{t^2}{2}}dt\\ge\\sqrt{\\frac{\\pi}{2}}(1-\\frac{1}{x^2})\\] Utiliser Tchebychev. Solution Soit $X\\to\\mathcal N(0,1)$ (Loi normale centree reduite). D‚Äôapres l‚Äôinegalite de Techbychev:\\[\\begin{aligned}\\forall\\varepsilon\\gt0, &amp;amp;P(\\vert X-E(X)\\vert\\ge\\varepsilon)\\le\\frac{V(X)}{\\varepsilon^2}\\\\\\text{or: } &amp;amp;E(X) = 0 \\text{ et } V(X) = 1\\\\&amp;amp;P(\\vert X\\vert\\ge\\varepsilon)\\le\\frac{1}{\\varepsilon^2}\\\\\\text{et} &amp;amp;P(\\vert X\\vert\\ge\\varepsilon)=1-P(\\vert X\\vert\\le\\varepsilon)\\\\\\text{Ca permet d&#39;ecrire: } &amp;amp;P(\\vert X\\vert\\lt\\varepsilon)\\ge 1-\\frac{1}{\\varepsilon^2}\\\\\\text{c.a.d.} &amp;amp;P(-\\varepsilon\\lt X\\lt\\varepsilon)\\ge1-\\frac{1}{\\varepsilon^2}\\\\&amp;amp;F(\\varepsilon) - F(-\\varepsilon)\\ge 1-\\frac{1}{\\varepsilon^2} \\text{ F: fonction de densite de }\\mathcal N(0,1)\\\\&amp;amp;F(\\varepsilon) - (1-F(\\varepsilon))\\ge 1-\\frac{1}{\\varepsilon^2}, \\forall\\varepsilon\\gt0\\\\\\Rightarrow &amp;amp;2F(\\varepsilon) -1 \\ge 1-\\frac{1}{\\varepsilon^2}(*)\\end{aligned}\\] On a aussi $\\frac{1}{\\sqrt{2\\pi}}\\int_0^xe^{-\\frac{t^2}{2}} = F(x) - F(0) = F(x) - \\frac{1}{2}, \\forall x\\gt0$\\[\\begin{aligned}\\Rightarrow \\int_0^xe^{-\\frac{t^2}{2}} &amp;amp;= \\sqrt{2\\pi}(F(x) - \\frac{1}{2})\\\\&amp;amp;=\\frac{\\sqrt{2\\pi}}{2}(2F(x) - 1), \\forall x\\gt0\\end{aligned}\\] Grace a l‚Äôinegalite $(*)$ et en remplacant $\\varepsilon$ par $x$, on obtient $\\forall x\\gt0$:\\[\\int_0^xe^{-\\frac{t^2}{2}}=\\frac{\\sqrt{2\\pi}}{2}(2F(x) - 1)\\ge\\frac{\\sqrt{2\\pi}}{2}(1-\\frac{1}{x^2})\\] On a bien: \\(\\forall x\\gt0, \\int_0^Xe^{-\\frac{t^2}{2}}\\ge\\sqrt{\\frac{\\pi}{2}}(1-\\frac{1}{x^2})\\) Exercice 6On considere une suite suite de v.a.a $(X_n), n\\in\\mathbb N^*$ dsitribue suivant la loi de Poisson $\\mathcal P(\\frac{1}{n}), (\\lambda = \\frac{1}{n})$. Montrer que $X_n$ converge en loi vers la variable aleatoire $X=0$ $(X_n\\to_{n\\to+\\infty}^L0)$ Solution $(X_n), n\\in\\mathbb N^*$ suit la loi de Poisson $\\mathcal P(\\frac{1}{n})$. Rappel:\\[P(X_n=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!} \\text{ (avec } \\lambda = \\frac{1}{n}\\text{)}\\] \\[P(X_n = k)= e^{-\\frac{1}{n}}\\frac{1}{n^kk!}, \\forall k\\in\\mathbb N\\] Si $k=0$, $P(X_n = 0) = e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}1$ Si $k\\ge1$, $P(X_n=k)=\\frac{1}{n^kk!}e^{-\\frac{1}{n}}\\to_{n\\to+\\infty}0$ car $\\frac{1}{n^k}\\to_{n\\to+\\infty}0$ Conclusion: on a montre que\\[\\begin{cases}&amp;amp;\\lim_{n\\to+\\infty}P(X_n=0)=1=P(X=0) \\Leftrightarrow X_n\\to_{n\\to+\\infty}^L0 \\text{ variable certaine}\\\\&amp;amp;\\lim_{n\\to+\\infty}P(X_n=k) = 0 = P(X=k), \\forall k\\ge1\\end{cases}\\]Exercice 7Soir $X$ une v.a. suivant la loi exponentielle de parametre $(\\lambda\\gt0)$. Montrer que $\\forall\\varepsilon\\gt0$, $P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\le\\frac{1}{\\lambda^2\\varepsilon^2}$ En deduire que $P(X\\gt\\frac{3}{\\lambda})\\le\\frac{1}{4}$ Solution $X$ suit la loi exponentielle$(\\lambda)$ de parametre $\\lambda$. 1.On rappelle que $E(X)=\\frac{1}{\\lambda}$ et $V(X)=\\frac{1}{\\lambda^2}$. En appliquant l‚Äôinegalite de Tchebychev:\\[\\begin{aligned}&amp;amp;P(\\vert X-E(X)\\vert\\ge\\varepsilon)\\le\\frac{V(X)}{\\varepsilon^2}, \\forall\\varepsilon\\gt0\\\\\\Rightarrow &amp;amp;P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\le\\frac{\\lambda}{\\lambda^2\\varepsilon^2}, \\forall\\varepsilon\\gt0\\end{aligned}\\] 2.L‚Äôevenement:\\[(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon) = (X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\cup(X-\\frac{1}{\\lambda}\\le-\\varepsilon)\\\\\\text{or: } A\\in A\\cup B\\\\\\text{donc: } (X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\in(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon \\vert)\\] On en deduit, par croissance de la probabilite:\\[\\begin{aligned}&amp;amp;P(X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\le P(\\vert X-\\frac{1}{\\lambda}\\vert\\ge\\varepsilon)\\\\\\Rightarrow &amp;amp;P(X-\\frac{1}{\\lambda}\\ge\\varepsilon)\\le\\frac{1}{\\lambda^2\\varepsilon^2} \\text{ (d&#39;apres la question 1)}\\end{aligned}\\] En choisissant $\\varepsilon=\\frac{2}{\\lambda}\\gt0$, on obtient $P(X\\ge\\frac{3}{\\lambda})\\le\\frac{1}{4}$ Exercice 8$(X_n)$ une suite de v.a. telle que $\\forall n\\in\\mathbb N^*$: $X_n$ suit la loi geometrique $G(\\frac{1}{n})$ (de parametre $\\frac{1}{n}$).On pose $Y_n=\\frac{X_n}{n}$. Determiner la fonction de repartition de la suite $Y_n:P(Y_n\\le x), \\forall x\\in\\mathbb R$ Montrer que $Y_n\\to_{n\\to+\\infty}^LY$ avec $Y$ suit la loi exponentielle $(\\lambda = 1)$ Solution $(X_n), n\\gt0$ une suite de v.a. geometrique $G(\\frac{1}{n})$ avec $p=\\frac{1}{n}$ parametre. Rappel:\\[\\begin{aligned}P(X_n = k) &amp;amp;= (1-p)^{k-1}p, \\forall k\\ge1\\\\&amp;amp;= (1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\end{aligned}\\] 1.On veut determiner la fonction de repartition de $Y_n$.\\[\\forall x\\le0, P(Y_n\\le x) = P(X_n\\le nx) = 0 \\text{ car } nx\\le0\\] Remarque: donc $\\forall x\\le 0$, $\\lim_{n\\to+\\infty}P(Y_n\\le x) = 0$. $\\forall x\\gt 0$ (reel strictement positif). Des que $n$ est assez grand, $nx\\ge 1$.\\[\\begin{aligned}P(Y_n\\le x) &amp;amp;= P(X_n\\le nx) = \\sum_{k=1}^{[nx]}P(X_n=k) \\text{ }([nx] \\text{participation entiere de } nx)\\\\\\forall x\\gt0, P(Y_n\\le x) &amp;amp;= \\sum_{k=1}^{[nx]}(1-\\frac{1}{n})^{k-1}\\frac{1}{n}\\\\&amp;amp;= \\frac{1}{n}\\sum_{k=1}^{[nx]}(1-\\frac{1}{n}^){k-1} = \\frac{1}{n}\\biggr(\\frac{1-(1-\\frac{1}{n})^{[nx]}}{1-(1-\\frac{1}{n})}\\biggr)\\\\&amp;amp;= P(Y_n\\le x) = 1 - (1-\\frac{1}{n})^{[nx]}\\end{aligned}\\] Donc:\\[F_n(X) = P(Y_n\\le x) =\\begin{cases} 0 &amp;amp;x\\le0\\\\ 1-(1-\\frac{1}{n})^{[nx]} &amp;amp;x\\gt0\\end{cases}\\] On a:\\[(1-\\frac{1}{n})^{[nx]} = \\exp([nx]ln(1-\\frac{1}{n}))\\\\\\ln(1-\\frac{1}{n})\\sim-\\frac{1}{n} \\text{ (} n \\text{ au voisinage de } +\\infty \\text{)}\\\\\\text{(}\\ln(1+x)\\sim x\\text{ au (voisinage de 0))}\\] Par definition de la partie entiere:\\[\\begin{aligned}&amp;amp;[nx]\\le nx\\lt[nx] + 1\\\\&amp;amp;nx-1\\lt[nx]\\le nx\\\\&amp;amp;\\Rightarrow 1-\\frac{1}{nx}\\lt\\frac{[nx]{nx}}\\le1\\\\&amp;amp;\\Rightarrow\\lim_{n\\to+\\infty}\\frac{[nx]}{nx}\\le1\\\\&amp;amp;\\Rightarrow [nx]\\sim nx \\text{ (} n \\text{ au voisinage de } +\\infty\\text{)}\\end{aligned}\\] Donc $[nx]\\ln(1-\\frac{1}{n})\\sim nx(-\\frac{1}{n})=-x$.\\[\\exp([nx]\\ln(1-\\frac{1}{n}))\\sim e^{-x} \\text{ (} n \\text{ au voisinage de } +\\infty\\text{)}\\\\\\forall x\\gt0, \\lim_{n\\to+\\infty} F_n(x) = \\lim_{n\\to+\\infty}P(Y_n\\le x)=1-e^{-x}\\] Conclusion:\\[\\forall x\\le 0, \\lim_{n\\to+\\infty}F_n(x)=\\lim_{n\\to+\\infty}P(Y_n\\le x)=0\\\\\\text{et}\\\\\\forall x\\gt0, \\lim_{n\\to+\\infty}F_n(x)=\\lim_{n\\to+\\infty}P(Y_n\\le x)=1-e^{-x}\\\\\\text{or } F(x)\\begin{cases} 0 &amp;amp;x\\le 0 \\\\ 1-e^{-x} &amp;amp;x\\gt 0\\end{cases}\\] $F(x)$ est la fonction de repartition de la loi exponentielle$(\\lambda=1)$ " }, { "title": "ISIM: Les textures", "url": "/cours/posts/isim_textures/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, texture, couleur, mapping, volume, transparent", "date": "2021-03-08 11:00:00 +0100", "snippet": "Lien de la note HackmdLes textures Objectifs Ajouter du realisme Simplifier la modelisation des secenes Simuler l‚Äôeclairage Applications Algorithmes temps reels Algorithmes photorealistes Types: Textures procedurales Textures plaquees Effet de volume Eclairage Les couleurs Associer une couleur par face Effet de volume donee par l‚Äôillumination Gouraud Phong Associer une couleur par sommet interpolation Indiquer les proprietes des materiaux diffusion specularite Les textures plaquees ‚ÄúMapper‚Äù un bitmap sur un polygone Realise Consommation memoire elevee Comment plaquer une texture? Sur un plan $\\to$ facile Sur une surface quelconque &amp;gt; Trouver une fonction Plaquer la texture suivant un projection simple Plan Sphere Cylindre Cube ‚Ä¶ Conformal map Projection: planar cylindrical spherical triplanar On cree un plan qu‚Äôon projette sur le theiere On cree un cyclindre qu‚Äôon projette sur le theiere On cree une sphere qu‚Äôon projette sur le theiereProjections: triplanar On le projette en fonction de la normale du point qu‚Äôon considere Permet de dissocier les textures en fonction de l‚Äôorientation Pour un personnage (ou objet complexe), on ne trouvera pas de fonction intermediaire.Association texture $\\leftrightarrow$ model On decoupe soi-meme sont modele Voir quel est le mapping entre le modele decoupe et aplatit et le bitmap qu‚Äôon veut mapperPossible d‚Äôavoir un decoupage plus ‚Äúintelligent‚Äù. Conformal mapOrigine du Bitmap Image (photo)Est-ce qu‚Äôon peut faire des photos ou des dessins ?On peut peindre ‚Äúcomme un artiste‚Äù les surfaces 3D Resultat d‚Äôun rendu (render to texture) Surfaces reflechissantes Ca va ? Pas trop le mal de mer maintenant ?Dans ce cas on map 6 textures sur la sphere Change quand on bouge la camera Pour le rendu final on a 6 rendus intermediaires‚ÄúMapper‚Äù un bitmap sur un polygone Interpolation dependante du $z$ Repetition de la texture si non compris entre 0 et 1Textures repetitivesQu‚Äôest-ce qui se passe quand on veut faire un mur de brique ? Motif repetitif On prend un motif qu‚Äôon duplique Avantages Inconvenients Economise de l‚Äôespace Le motif peut devenir visible Pour reduire les inconvenients: Prendre des patches plus petits Prendre des motifs differents Ce n‚Äôest qu‚Äôune facon de repousser le problemeMipmap Si on a notre mur qu‚Äôon voit de loin, plein d‚Äôartefacts apparaissent Le but du MIP est d‚Äôeviter la pixelisation lorsqu‚Äôon s‚Äôeloigne d‚Äôune texture Le niveau de detail des textures est adapte a la distance de l‚Äôobjet Souvant supporte nativement par les moteurs graphiques Lissage Mip mapping: niveau de detail (LOD) Point sampling: texel le plus proche Bilineaire: interpolation sur 4 texels Trilineaire: interpolation inter-LOD Anisotropique: prise en compte des effets d‚Äôangle (32 texels) Textures procedurales Texture generee Avantages: Economie de memoire Pas de repetition dans le motif Possibilite d‚Äôavoir une texture 3D ‚Ä¶ Effets classique: Damier, Rayures, ‚Ä¶ Je vous ai fait une espece de bronze ou je ne-sais-quoi Generation de bruit pour simuler l‚Äôaspect de certains elements Bruit structure Bruit de Perlin Afin de donner une impression d‚Äôorganisation, seul un sous enesemble de points est genere aleatoirement. Le reste des points es calcule par interpolation.Ajout d‚Äôautres frequences: $bruit(i,x)=p^{(i-1)}.bruit(2^{(i-1)},x)$ Parametres: pas, persistance et nombre d‚Äôoctaves Resultat: Somme de l‚Äôensemble des $bruit(i,x)$ 1 octave $p=0.5$ On interpole (interpolation lineaire) On prend un autre echantillonage et on interpole avec cette autre matrice $\\Leftrightarrow$ 2 tirages aleatoires donc 2$^{eme}$ octave 2 octaves $p=0.5$ 5 octaves $p=0.5$ 5 octaves $p=0.8$ 5 octaves $p=0.2$Applications: fumee Interpolation du balanc $\\to$ noir cieluages En dessous d‚Äôun certain seuil: Interpolation du gris bleu $\\to$ bleu Au dessus d‚Äôun certain seuil: bleu bois En dessous d‚Äôun certain seuil, marron fonce En dessous d‚Äôun certain seuil, marron clair Entre les deux, interpolation psycho‚Ä¶ A force de jouer avec les couleurs j‚Äôai un peu craque marbre $n = 1-\\sqrt{\\vert\\sin(2\\pi v)\\vert}$ Interpolation linaire du gris vers le noir en fonction de $n$ Generation possible en 3DUsage des texturesBillboard Element toujours face a l‚Äôobservateur sur lequel est plaque une texture Permet de simuler un objet/phenomene complique simplement a l‚Äôaide d‚Äôune texture: Arbre Feu ‚Ä¶ Environnement On peut s‚Äôenfermer dans un objet pour avoir notre environnement Equirectangular Une seule texture pour l‚Äôensemble de l‚Äôenvironnement Cubemap Skybox On enferme notre personnage dans un cube Meme resolution pour tous les points Mettre 6 cameras qui prennent $90^o$ dans une direction In-theiere stellarTexture particuliereObjets transparents Rendu type raytracing Loi de Snell-Descartes Rendu par projection openGL Pas de deviation de rayon Rend tous les objets qui ne sont pas transparents On verrouille le z-buffer en ecriture avant de dessiner tous les objets transparents Objets transparents: melanger la couleur de ce qui a deja ete dessine avec l‚Äôobjet transparent TexturesEffet de volume Perturbation des normales Bump mapping (Blinn) Permet de faire apparaitre des variation sur la surface Realise avec blender(C‚Äôest une mure en haut a droite)Comment voir que c‚Äôest bien juste la perturbation de normale ? Si on trace les contour, on voit bien qu‚Äôils sont lissent et qu‚Äôils ne vont pas dans les creux de la mure.Pour aller plus loin: Parallax mapping Relief mappingAmeliorations La texture permet d‚Äôajouter du realisme et evite de modeliser les details d‚Äôune surface. Toutefois le resultat est un peu plat. Initialement, on plaque un bitmap Ne pas considerer seulement le bitmap Ajout d‚Äôinformations:1. Deformations locales Height map Carte d‚Äôelevation Normales deduites en faisant une derivee partielle Normal map Diminue le niveau de details (polygones) Stocke dans une imageBitmap:Bitmap + bump mapping: Tache d‚Äôillumination a disparue2. Proprietes localesEx: speculariteBitmap + bump mapping + modifications speculairesConclusions Participe au realimse Permet la simplification des modeles Permet de simuler certains objets/phenomenes difficiles" }, { "title": "ISIM: Rendu temps reel", "url": "/cours/posts/isim_rendu_temps_reel/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8, clipping, backface culling, polygone, eclairage", "date": "2021-03-08 09:00:00 +0100", "snippet": "Lien de la note HackmdLe renduRendu temps reel vs Rendu photorealiste Rendu photorealiste: Objectif: Generation d‚Äôimages realistes Contrainte de temps faible Strategies Object-based rendering algorithms Illumination globale calculee independamment du point de vue Image-based rendering algorithms Illumination calculee partiellement, en fonction du point de vue Deterministic rendering algorithms Monte Carlo rendering algorithms Rendu temps reel Objectif: Generation rapide d‚Äôimages Le rendu temps reelPrincipe general Modelisation des objets dans un repere local Modelisation de la scene dans un repere global Projection de la scene sur le plan image passage repere global au repere camera projection sur le plan image (+dessin 2D) Pour faire le rendu: camera qui possede son propre repere les objets sont exprimes dans le repere lies a la scene on les change de repere et on les exprimes dans le repere lie a la camera on peut maintenant les projeter sur le plan image. Algorithmes 3D fondamentauxProjection des objets sur le plan image:Comment projeter un objet sur le plan image ? Plusieurs objets ? Il faut identifier les problemes! Comment determiner les sommets/face non visibles ? Comment determiner les objets caches (ou partiellement caches ?) Comment determiner les objets qui sont hors champ (ou partiellement hors champ/derrrier le plan image) ? Comment determiner les objets qui sont derriere le plan image ou partiellement visible ?Afin de les resoudre et: avoir une projection correcte etre efficaceClipping Comment determiner les objets qui sont hors champ (ou partiellement hors champ/derrrier le plan image) ? Comment determiner les objets qui sont derriere le plan image ou partiellement visible ? Estimation de la positiopn d‚Äôune face par rapport aux plans Elimination des faces a l‚Äôexterieur Decoupage des polygones a cheval (equations parametriques) Backface cullingComment determiner les faces non visibles ? Enumerer les sommets toujours dans le meme sens Determiner l‚Äôorientation de la face par rapport a l‚Äôaxe optique: Calculer le vecteur normal a la surface (produit vectoriel) Determiner l‚Äôangle entre le vecteur normal a la surface et le vecteur directeur de l‚Äôaxe optique (produit scalaire) Comment determiner les objets caches ou partiellement caches ? Trier les objets et les dessiner dans l‚Äôordre Comment determiner cet ordre ? Utiliser le centre de gravite Ne fonctionne pas dans tous les cas ! Si on dessine du plus pres au plus loin au lieu de par-dessus, on peut etre plus rapide. Utilisation d‚Äôun arbre B.S.P. (Binary Space Partitionning Tree) Chaque noeud represente un hyperplan (deduit d‚Äôune face F) Le 1$^{er}$ fils contient les faces du demi-espace derriere F et le second fils contient les faces du demi-espaces devant F Lorsque l‚Äôhyperplan intersecte une face, la face est coupee en 2 On peut deduire un ordre de parcours des polygones pour les dessiner du plus eloigne au plus proche idem, du plus proche au plus eloigneEfficacite: Compromis entre arbre equilibre et nombre de polygones (fragmentation des polygones)Z-bufferComment determiner les objets caches ou partiellement caches ?Utilisation du Z-buffer Sauvegarde de la profondeur pour chaque pixel dessine Avantages Inconvenients Simple Oblige a projeter l‚Äôensemble des polygones ¬† Probleme de resolution lors de l‚Äôencodage du Z ProjectionUne fois que l‚Äôon a elimine les elements hors champ de la camera, les elements qui ne sont pas de face On projette les sommets et on dessine (et rempli) le polygone en tenant compte de la profondeur\\[\\begin{aligned}&amp;amp;p_i=\\frac{fp}{z} &amp;amp;(1)\\end{aligned}\\]Algorithmes 2D fondamentauxRemplissage de polygones Suivant la projection des polygones, il faut dessiner/remplir le polygone Determiner si une partie n‚Äôest pas visibile Determiner la couleur et l‚Äôeclairage Eventuellement plaquer une texture ‚Ä¶ Les donnees sont la liste des sommetsDepend de plusieurs choses: Triangle de polygone Triangle ? Convexe ? Quelconque‚Ä¶? Donnees: Liste de sommet Approches: Triangulation Remplissage direct Inondation Algorithme: Parcourir toutes les arretes de haut en bas et remplir horizontalement Algorithme Trier les sommets pour definir les section Ordre de remplissage Determiner les arretes actives (dans la section) A chaque transition, il faut remettre a jour la liste des arretes actives On arrive a une frontiere de section On regarde le sommet suivant Il faut desactiver l‚Äôarrete actuelle et activer la suivante A chaque niveau il faut tracer des segments horizontaux On obtient des points d‚Äôintersection avec chaque arrete On les trie horizontalement pas ordre croissant Il faut etre prudent car en arrivant a un niveau une arrete peut etre ignoree. Simplification pour les polygones convexes (ou meme dans le cas du triangle) Se restreindre a des cas plus simples Trace de segments Trace rapide de segments Affichage de segments Suivi des arretes activer Comment faire ?Algorithme naif: Repose sur l‚Äôutilisation des nombres a virgule flottante (un peu lent)for (x = 1; ...;) { y = ax + b plot(x,y)}Critiquons ce bout de code: c‚Äôest pas ouf Si on parcourt les x et qu‚Äôon veut dessiner les y Matrice de pixel Si coeff faible (ex: 1), on avance lentement Si on a a = 4, pente tellement forte qu‚Äôon a des discontinuite dans le trace du segment Est-ce qu mon algo est bien ? a est un ratio donc float multiplication $\\rightarrow$ beaucoup de calculs Le resultat est un float avec une multiplication et additionAutre solution: Bresenham (65?)Uniquement avec des additions d‚ÄôentiersCritere: $y=mx+p$ avec $m=\\frac{d_y}{d_x}$ $D=d1-d2=(m(x_p+1)+p+y_p)-(y_p+1-m(x_p+1)+p)$ $D=d1-d2=2d_y(x_p+1)-2d_xy_p-d_x+2d_xp$ $D\\lt0\\Rightarrow(x_{p+1}, y_p)$ inc: $2d_y$ $D\\gt0\\Rightarrow(x_{p+1},y_{p+1})$ inc: $2d_y-2d_x$ Probleme d‚Äôaliasing.Trace de cercleAlgorithme naif Repose sur l‚Äôutilisation des nombres a virgule flottante float (un peu lent) Utilisation des symetries Precalcule des fonctions trigosAlgorithme de Bresenham Meme esprit que pour les segmentsCritere: $D(P) = x^2 + y^2 - r^2$ $D(A) = (x+1)^2 + y^2-r^2$ $D(B) = (x+1)^2+(y-1)^2-r^2$ $S=D(A)+D(B)$ $S\\ge0\\Rightarrow B$ $S\\lt0\\Rightarrow A$ Calcul de S incrementalClippingUne fois qu‚Äôon a projete le polygone, on l‚Äôa clipe mais on peut aussi le projeter et le fenetrer.Meme s‚Äôil est possible de fenetrer les polygones dans l‚Äôespace, on peut aussi le faire dans le plan (apres projection) Fenetrage rectangulaire de segments: Cohen-sutherland Fenetrage d‚Äôun polygone a partir des segments: Weiler-Atherton Fenetrage rectangulaire de segmentsCohen-sutherland Pour fenetrer il faut des criteres simples et rapides Fenetre de vue: 4 frontieres dans le plan Code associe a la position relative du point dans le plan Attribue a chaque sommet un code a 4bits Chaque bit representant la position relative du point par rapport a la frontiere Les points a l‚Äôinterieur de l‚Äôimage on tous leurs bits a 0 Les points a l‚Äôexterieur ont au moins un bit a 1 Pour savoir si une arrete est completement visible, on fait un ou logique entre le code du premier et deuxieme sommet Si le resultat = 0, l‚Äôarrete est entierement visible Pour savoir si une arrete est visible quand ses sommets sont hors de l‚Äôimage, on fait un et logique Si resultat = 0, l‚Äôarrete est potentiellement visible Sinon, probablement hors de l‚Äôimage Weiler-ArthertonPolygone projete sur l‚Äôimage: Partie a l‚Äôinterieur Partie a l‚ÄôexterieurOn prend notre polygone et fenetre de vue et on y insere tous nos points d‚Äôintersection: Ex: AB1, 1 sommet supplementaire, on l‚Äôinsere Obtient 2 nouveaux polygonesComment trouver le polygone resultat de la fenetre de vue ? Partir d‚Äôun point dun polygone depuis la fenetre de vue Parcours les arretes A point d‚Äôintersection, change de polygone (polygone $\\leftrightarrow$ quadrilatere) Toujours partir d‚Äôun point in l‚Äôinterieur de la fenetre sinon on tourne en rond. S‚Äôil n‚Äôy a pas de point du polygone a l‚Äôinterieur de l‚Äôimage, commencer par une intersection Avoir parcouru tous les points du polygone dans la fenetre Cyrus-BeckFenetrage entre 2 polygones Cyrus-Beck (Pour deux polygones convexes)Connaitre la position d‚Äôun point $Q$ par rapport a un cote de la fenetre ?\\[\\begin{align}&amp;amp;I(Q) = (Q-P).n\\begin{cases}&amp;amp;= 0\\\\&amp;amp;\\lt0\\\\&amp;amp;\\gt0\\end{cases}&amp;amp;(2)\\end{align}\\]Fenetrage d‚Äôun segment ? $L(t)=A+(B-A)t$ $I(Q)=(Q-P).n$ $I(L(T)) = (L(T)-P).n$ Intersection $(L(t)-P).n = 0\\Leftrightarrow t = \\frac{(A-P).n}{A-B.n}$ $D=(B-A)$ Cas 1: $D.N\\lt0\\Rightarrow t=t_{\\text{sup}}$ Cas 2: $D.N=0$ Cas 3: $D.N\\gt0\\Rightarrow t=t_{inf}$ On recommence pour tout les segments de la fenetre puis si $t_{\\text{inf}}\\gt t_{\\text{sup}}$ segment non visible sinon segment compris entre $[t_{\\text{inf}}..t_{\\text{sup}}]$ Polygones non convexe Decoupage en polygones convexes Triangulation de DelaunayRetour sur le clippingApplication de Cohen-Sutherland sur la pyramide 3D Peut appliquer l‚Äôalgo en 3D Au lieu de 4 codes on en a 6 Determination de la couleur des pixels durant le remplissageRemplissage en fonction de: La couleur de la face ? L‚Äôeclairage ?EclairageDetermination de la couleur Modele de Lambert $I_d = k\\times \\frac{N.L}{\\Vert N\\Vert.\\Vert L\\Vert}$ Meme niveau d‚Äôeclairement pour un polygone donne Un peu moche d‚Äôavoir des polygones uniformes Impression polygones plats Modele de Gourand Essayer de lisser le polygone On calcule l‚Äôillumination a chaque extremite du polygone Interpoler l‚Äôillumination Repeter l‚Äôinterpolation pour tous les points de la surface Utile quand on a beaucoup de points sur la surface Anecdote: Sur les verisons ancienne de OpenGL, c‚Äôetait soit Lambert soit Gourand. Fabrizio voulait avoir une lampe torche pour son 1$^{er}$ projet OpenGL, des qu‚Äôun spot illumine un angle ca eclaire beaucoup plus que si on eclaire plus le centre Modele de Phong On interpole la normale en tous les points du polygone suivant les arretes Beaucoup plus de calcul Marche mieux Attention au calcul des normales Echnatilloner suffisemment la surface ou bien placer la normaleOn approxime une surface ronde par des polygones. Si on calcule Lambert, on espere que l‚Äôinterpolation represente la normale reelle a la surface. L‚Äôaclairage donne l‚Äôimpression de volume.Pour chaque sommet du maillage, on stoque la normale.ResultatsLa difference entre Phong et Gouraud se creuse lorsque le modele est pauvrelightmapEclairages plus evoluesOn peut afficher des eclairages pre-calcules (du moment qu‚Äôil n‚Äôy a pas trop d‚Äôillumination)Permet de donner pas mal de realisme en temps reelConclusion Beaucoup d‚Äôalgorithmes Implementes dans les moteurs A connaitre pour inter-agir avec ces moteurs De nouvelles technologies emergent (RTX‚Ä¶)" }, { "title": "PRST: Table Normale Centree Reduite", "url": "/cours/posts/prst_table_normale_centree_reduite/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, normale, table", "date": "2021-03-05 16:30:00 +0100", "snippet": "Lien de la note HackmdPRST - Table normale centree reduiteSi $P(Z\\le-1,6)$:\\[P(Z\\le-1,6) = 1 - P(Z\\le1,6)\\] Commencer passer d‚Äôune loi normale a une loi centree reduite ?On a:\\(X\\sim N(\\mu,\\sigma^2)\\\\X-m\\sim N(0,\\sigma^2)\\\\\\frac{X-m}{\\sigma}\\sim N(0,1)\\)" }, { "title": "PRST: Feuille 2 - Exercice", "url": "/cours/posts/prst_second_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, brenoulli, binomial, loi, partiel", "date": "2021-03-05 15:30:00 +0100", "snippet": "Lien de la note Hackmd L‚Äôordre des exos dans le cours est 6 $\\to$ 4 $\\to$ 15 $\\to$ 19 $\\to$ 18Exercice 4Montrer que la somme de n variables al√©atoires ind√©pendantes suivant une loi de Bernoulli de param√®tre p suit une loi binomiale de param√®tres n et p. Solution $1^{ere}$ etape: Fonction caracteristique de $\\mathcal B(n,p)$, Pour $k\\in{0,1,2,‚Ä¶,n}$ \\(P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}\\) \\[\\begin{aligned}E(e^{itX})&amp;amp;=\\sum_{k=0}^{n}e^{itk}P(X=k)\\\\&amp;amp;= \\sum_{k=0}^{n}e^{itk}\\binom{n}{k}p^k(1-p)^{n-k}\\\\&amp;amp;= \\sum_{k=0}^{n}\\binom{n}{k}a^kb^{n-k} = (pe^{it}+n-p)\\end{aligned}\\] $2^e$ etape: Soient $X_1,‚Ä¶,X_n$ $n$ v.a. independantes de loi $\\mathcal B(p)$\\[\\begin{aligned}\\phi_{X_1+...+X_n}(t) &amp;amp;= (\\phi_{X_1}(t))^1\\\\\\phi_{X_1+...+X_n}&#39;(t) &amp;amp;= (pe^{it} + 1 - p)^n\\end{aligned}\\]Exercice 6 Exercice qui risque d‚Äôetre au partiel !Soient deux variables al√©atoires ind√©pendantes suivant respectivement des lois exponentielles de param√®tres respectifs $\\lambda1$ et $\\lambda2$. Montrer que la variable al√©atoire $min(X1; X2)$ suit une loi exponentielle de param√®tre $\\lambda1 + \\lambda2$. Solution On cherche:\\[\\begin{aligned}Y&amp;amp;=min(X1, X2)\\\\R_Y(x) &amp;amp;= e^{-(\\lambda_1+\\lambda_2)x}\\end{aligned}\\] On pose $Y=\\min(X_1,X_2)$. Par definition, pour $x\\gt0$:\\[\\begin{aligned}R_Y(x) &amp;amp;= P(Y\\gt x)\\\\&amp;amp;= P(min(X_1, X_2)\\gt x)\\end{aligned}\\] Point de logique: si le minimum est plus grand que $x$ alors les 2 sont plus grnads que $x$. \\[R_Y(x) = P(\\{X_1\\gt x\\}\\cap\\{X_2\\gt x\\})\\] $X_1$ et $X_2$ sont independantes donc:\\[\\begin{aligned}R_Y(x) &amp;amp;= P(X_1\\gt X_2)P(X_2\\gt x) = e^{-\\lambda_1x}\\times e^{-\\lambda_1x}\\\\&amp;amp;= e^{-(\\lambda_1+\\lambda_2)x}\\end{aligned}\\] Conclusion: $Y\\sim \\xi(\\lambda_1+\\lambda_2)$Exercice 15Soient $X$ et $Y$ deux variables al√©atoires ind√©pendantes et suivant toutes deux une loi normale centr√©e r√©duite. Consid√©rons les variables al√©atoires $U = X + Y$ et $V = X ‚àí Y$ Solution \\[\\begin{pmatrix} U\\\\ V\\end{pmatrix} =\\begin{pmatrix} 1 &amp;amp;1\\\\ 1 &amp;amp;-1\\end{pmatrix}\\begin{pmatrix} X\\\\ Y\\end{pmatrix}\\] On pose:\\[A=\\begin{pmatrix} 1 &amp;amp;1\\\\ 1 &amp;amp;-1\\end{pmatrix}\\] Toute combinaison lineaire de $U$ et $V$ es une combinaison de $X$ et $Y$, comme ce sont des vecteurs gaussien alors $(U,V)^T$ est un vecteur gaussien. 2.\\[\\begin{aligned} E(U)&amp;amp;=E(X+Y)=E(X)+E(Y)=0 \\\\E(V)&amp;amp;=E(X-Y)=E(X)-E(Y)=0\\\\E(UV)&amp;amp;=E(X^2-Y^2)=E(X^2)-E(Y^2)\\end{aligned}\\] $X$ et $Y$ sont centrees.\\(\\begin{aligned}VM(X)&amp;amp;=E(X^2)-\\underbrace{E(X)^2}_{=0}\\\\E(X^2)&amp;amp;=E(Y^2)=1\\\\E(UV)&amp;amp;=1-1=0\\\\Cov(U,V)&amp;amp;=0-0=0\\end{aligned}\\)Exercice 18Soit $X$ une variable al√©atoire discr√®te de support $\\mathbb N^*$ telle que, pour tout entier $k \\ge 1$,\\(P(X = k) = \\frac{\\alpha}{k!}\\)pour un certain r√©el $\\alpha$. D√©terminer le r√©el $\\alpha$ Calculer $E(X)$ puis $E(X(X ‚àí 1))$. En d√©duire $V(X)$. Solution Par definition: \\[\\sum_{k\\ge 1}P(X=k)=1\\] \\[\\sum_{k\\ge1}\\frac{\\alpha}{k!}=1 \\Rightarrow\\alpha\\sum_{k\\ge1}\\frac{1}{k!}\\] Developpement limite de $e^z$, $z\\in\\mathbb R$:\\[e^{z}=\\sum_{k\\ge0}\\frac{z^k}{k}=1\\] \\[\\begin{aligned}\\sum_{k\\ge1}\\frac{1}{k!}&amp;amp;=\\sum_{k\\ge0}\\frac{1}{k!}=e-1\\text{ developpement limite.}\\\\\\sum_{k\\ge1}P(X=k)&amp;amp;=\\alpha(e-1)\\\\ \\text{donc } \\alpha(e-1)&amp;amp;=1\\Leftrightarrow\\alpha=\\frac{1}{e-1}\\end{aligned}\\] Notons que $\\alpha$ est positif. 2.\\[\\begin{aligned}E(X) &amp;amp;= \\sum_{k\\ge1}X_{\\alpha}P(X=k) = \\sum_{k\\ge1}\\alpha\\frac{k}{k!} = \\alpha\\sum_{k\\ge1}\\frac{1}{(k-1)!}\\\\&amp;amp;= \\alpha\\sum_{j\\ge0}\\frac{1}{j!} = \\alpha e = \\frac{e}{e-1}\\end{aligned}\\] Calculons $E(X(X-1))$:\\[\\begin{aligned}E(X(X-1)) &amp;amp;= \\sum_{k\\ge1}k(k-1)P(X=k)\\\\&amp;amp;= \\sum_{k\\ge1}k(k-1)\\times\\frac{\\alpha}{k!}=\\sum_{k\\ge2}\\frac{\\alpha}{(k-2)!}\\\\&amp;amp;= \\sum_{j\\ge0}\\frac{\\alpha}{j!}=\\alpha e = \\frac{e}{e-1}\\\\E(X(X-1)) + E(X) &amp;amp;= E(X^2) \\text{ donc } E(X^2)=2 \\frac{e}{e-1}\\\\V(X)&amp;amp;=2 \\frac{e}{e-1}-\\biggr(\\frac{e}{e-1}\\biggr)^2\\\\&amp;amp;= \\frac{2e(e-1)e}{(e-1)^2} = \\frac{e^2-2e}{(e-1)^2}\\end{aligned}\\]Exercice 19 Exercice qui risque d‚Äôetre au partiel !Soit $(U_n)$ une suite de variables al√©atoires ind√©pendantes suivant une loi uniforme sur l‚Äôintervalle $[0; 1]$.On pose, pour tout entier $n \\ge 1$, $M_n := max(U_1, . . . , U_n)$ et $X_n = n(1‚àíM_n)$. Soit $n \\ge 1$. D√©terminer la fonction de r√©partition de $M_n$ puis celle de $Xn$. Montrer que la suite $(Xn)$ converge en loi. Mael a 5 cousins bretons qui viennent du Morbihand‚Ä¶ Solution 1.Soit $x$ un reel.\\[\\begin{aligned}P(M_n\\le x) &amp;amp;= P(max(U_1, . . . , U_n)\\le x) = P(\\{U_1\\le x\\}\\cap...\\cap\\{U_n\\le x\\})\\\\&amp;amp;= \\Pi_{k=1}^n P(\\{U_k\\le x\\}) = (P(U_1\\le x))^n\\\\&amp;amp;= (F(x))^n\\end{aligned}\\] ou F designe la fonction de repartition. Fonction de repartition de la loi $U([0;1])$:\\[\\begin{aligned}F(x)&amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\x &amp;amp;\\text{si } x\\in[0;1]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\\\int_0^x1dt &amp;amp;= x\\\\F_n(x)=P(M_n\\le x) &amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\x &amp;amp;\\text{si } x\\in[0;1]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\G_n(x) = P(X_n\\le x) &amp;amp;= 1-P(X_n\\gt x)\\\\&amp;amp;= 1-P(n(1-M_n)\\gt x)\\\\&amp;amp;= 1-P(1-M_n\\gt\\frac{x}{n}) = 1 - P(-M_n\\gt\\frac{x}{n}-1)\\\\&amp;amp;= 1-P(M_n\\lt1-\\frac{x}{n})\\\\ &amp;amp;=\\begin{cases}1-0 &amp;amp;\\text{si } 1-\\frac{x}{n}\\lt0\\\\1-(1-\\frac{x}{n}) &amp;amp;\\text{si } 0\\lt1-\\frac{x}{n}\\lt1\\\\1-1 &amp;amp;\\text{si } 1-\\frac{x}{n}\\gt1\\end{cases}\\\\&amp;amp;=\\begin{cases}0 &amp;amp;\\text{si } x\\lt0\\\\1-(1-\\frac{x}{n})^n &amp;amp;\\text{si } x\\in[0;n]\\\\1 &amp;amp;\\text{si } x\\gt1\\end{cases}\\\\\\end{aligned}\\] 2.Quelle propriete du cours doit-on utiliser ? Remarquons que:\\[\\lim_{n\\to+\\infty}G_n(x)=\\begin{cases}0 &amp;amp;\\text{ si } x\\lt0\\\\1-e^{-x}\\end{cases}\\\\\\] Il s‚Äôagit de la fonction de repartition de la loi $\\xi(1)$ Donc $X_n\\Rightarrow^{\\text{loi}} \\xi(1)$ $\\lim_{n\\to+\\infty}(1+\\frac{z}{n})^n = e^{z}$ pour tout reel $z$." }, { "title": "PRST: Feuille 1 - Exercice, suite", "url": "/cours/posts/prst_first_exercise_sheet/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8, loi, exponentielle, bernoulli, binomial", "date": "2021-03-05 14:45:00 +0100", "snippet": "Lien de la note Hackmd L‚Äôordre des exos dans le cours est 3 $\\to$ 9 $\\to$ 15 $\\to$ 16 $\\to$ 13Exercice 3 D√©terminer la fonction caract√©ristique de la loi de Bernoulli de param√®tre $p$. D√©terminer la fonction caract√©ristique de la loi exponentielle de param√®tre $\\lambda$. Solution $X\\sim\\mathcal B(p), E(e^{itx}) = p\\times e^{it\\times 1} + (1-p)e^{it\\times 0} = 1-p+p e^{it}$ Soit $t\\in\\mathbb R$: \\[\\begin{aligned}\\phi(t) = E(e^{itX}) &amp;amp;= \\int_0^{+\\infty}e^{itx}\\lambda e^{-\\lambda x}dx\\\\&amp;amp;= \\lambda\\int_0^te^{(it-\\lambda)x}dx\\\\\\text{Soit } A\\gt0: \\int_0^Ae^{(it-\\lambda)x}dx &amp;amp;= \\biggr[\\frac{1}{it-\\lambda}e^{(it-\\lambda)x}\\biggr]_0^A\\\\&amp;amp;= \\frac{1}{it-\\lambda}e^{(it-\\lambda)A} - \\frac{1}{it-\\lambda}\\times1\\\\e^{(it-\\lambda)A} &amp;amp;= \\underbrace{e^{itA}}_{\\le1 \\text{ car bornee}}\\times e^{-\\lambda A}\\\\\\end{aligned}\\\\\\lim_{A\\to+\\infty} e^{-\\lambda A} = 0\\] Car $\\lambda\\gt 0$. Par ailleurs $\\vert e^{itA}\\vert\\le1$. Donc $\\lim_{A\\to+\\infty}\\frac{1}{it-\\lambda} e^{-\\lambda A} = 0$ d‚Äôou $\\lim_{A\\to+\\infty}\\int_0^Ae^{(it-\\lambda)x}dx = - \\frac{1}{it-\\lambda} = \\frac{1}{\\lambda - it}$. Conclusion: $\\int_0^{+\\infty}e^{(it-\\lambda)x}dx$ est bien definie et egale a $\\frac{1}{\\lambda - it}$ \\(\\phi(t) = \\frac{\\lambda}{\\lambda - it}\\) Exercice 9Dans une fabrication en s√©rie, 7% des produits pr√©sentent un d√©faut. 40 articles sont contr√¥l√©s Que vaut la probabilit√© que 4 articles pr√©sentent un d√©faut? Que vaut la probabilit√© que moins de 4 articles pr√©sentent un d√©faut? Solution Pourquoi peut-on considerer que chaque V.A. (echantillon) sont independantes les unes des autres ? Comme c‚Äôest une fabrication en serie, c‚Äôest fait en tres grand nombre et un echantillon de 40 ne change rien. Pour parler de loi binomiale, il faut que l‚Äôechantillon soit petit par rapport a la population. \\[\\begin{aligned}P(X=4)&amp;amp;=\\binom{40}{4}\\times0,07^4\\times4,96^36\\simeq0,16\\\\P(X\\lt4)&amp;amp;=P(X=1)+P(X=2)+P(X=3)\\simeq 0,69\\end{aligned}\\]Exercice 13Soient $\\alpha$ un r√©el strictement positif et X une variable al√©atoire dont la densit√© est d√©finie par:$f_X(x) = \\alpha x^{‚àí\\alpha‚àí1}$ pour $x \\ge 1$ et $f_X(x) = 0$ sinon. V√©rifier que $f_X$ est bien une densit√© de probabilit√© et d√©terminer la fonction de r√©partition associ√©e Calculer $P(0 \\lt X \\le 2)$, Pour quelles valeurs de $\\alpha$, la variable al√©atoire $X$ admet-elle une esp√©rance? La calculer quand elle existeDans cet exercice, nous avons √©tudi√© la loi de Pareto de param√®tre $\\alpha$. Solution Montrons que $f_X$ est bien une densite. \\[\\begin{aligned}&amp;amp;\\text{i. } f_X(x)\\ge0 \\text{ par construction.}\\\\&amp;amp;\\text{ii. } \\int_1^{+\\infty}f_X(x)dx=1?\\end{aligned}\\] Soit $A\\gt0$:\\[\\begin{aligned}\\int_1^Af_X(x)dx=\\int_1^A\\alpha x^{-\\alpha-1}dx &amp;amp;= \\biggr[\\frac{\\alpha}{-\\alpha}x^{-\\alpha}\\biggr]_1^A\\\\&amp;amp;= [x^{-\\alpha}]_1^A\\end{aligned}\\] On sait que\\[lim_{A\\to+\\infty}A^{-\\alpha}=lim_{A\\to+\\infty}\\frac{1}{A^\\alpha} = 0\\] D‚Äôou\\[\\int_1^{+\\infty}f_X(x)dx=\\lim_{A\\to+\\infty}\\int_1^Af_X(x)dx = 1\\] Fonction de repartition:\\[F_X(x) = \\int_1^x\\alpha t^{-\\alpha-1}dt = 1-x^{-\\alpha}\\] 2.\\[\\begin{aligned}P(0\\lt x\\le2) &amp;amp;= P(1\\le Y\\le2) = \\int_1^2\\alpha x^{-\\alpha-1}dx\\\\&amp;amp;=[-x^{-\\alpha}]_1^2 = 1-\\frac{1}{2^\\alpha}\\end{aligned}\\] 3.$\\alpha\\gt 1$Exercice 15Les ≈ìufs pondus par une poule ont une longueur pouvant √™tre mod√©lis√©e √† l‚Äôaide d‚Äôune loi normale d‚Äôesp√©rance 6 et d‚Äô√©cart-type 1,4. Quelle est la probabilit√© de trouver un oeuf: d‚Äôune longueur sup√©rieure √† 8cm? d‚Äôune longueur inf√©rieure √† 5cm? Solution Notons L la v.a. consideree $L\\sim\\omega(6,(1,4)^2)$, $Y=\\frac{X-6}{1,4}\\sim\\mathcal N(0,1)$ \\[\\begin{aligned}1-P(X\\le8) &amp;amp;= 1-P(\\frac{X-6}{1,4}\\le \\frac{8-6}{1,4}) \\text{ Possible de le faire directement car 8 est positif}\\\\&amp;amp;= 1-P(Y\\le\\frac{10}{7})\\simeq1-P(Y\\le 1,43)\\end{aligned}\\] Cherchons 1,43 dans la table $\\mathcal N(0,1)$\\[1-P(Y\\le1,43)\\simeq0,92\\sim0,08\\] 2.\\[\\begin{aligned}P(X\\lt5) &amp;amp;= P(Y\\lt\\frac{5-6}{1,4}) = P(Y\\lt-\\frac{1}{1,4})\\simeq P(Y\\lt-0,71)\\\\&amp;amp;= 1-P(Y\\lt0,71)\\end{aligned}\\] D‚Äôapres la table de la loi $\\mathcal N(0,1)$ $P(Y\\lt0,71)\\simeq0,76$ donc $P(Y\\ge0,71)\\simeq 0,24$ et $P(X\\lt5) = P(Y\\lt-0,71)\\simeq0,24$Exercice 16Les composants d‚Äôun autoradio ont une dur√©e de vie pouvant √™tre mod√©lis√©e par une loi normale d‚Äôesp√©rance 2400 (heures d‚Äôutilisation) et d‚Äô√©cart-type 300. Un autoradio est utilis√©, en moyenne, 1000 heures par an. Quelle est la probabilit√© qu‚Äôun composant ait une dur√©e de vie sup√©rieure √† 3 ans? Solution Methode de professionnel: Si $X$ suit une loi normale $N(\\mu,\\sigma^2)$ \\(P(\\mu-\\sigma\\le X\\le\\mu+\\sigma)\\simeq0,68\\\\P(\\mu-2\\sigma\\le X\\le\\mu+2\\sigma)\\simeq0,95\\\\P(\\mu-3\\sigma\\le X\\le\\mu+3\\sigma)\\simeq0,997\\\\\\) \\[P(2400-2\\times300\\le X\\le2400+2\\times300) = P(1800\\le X\\le3000)\\simeq0,95\\\\Y=\\frac{X-2400}{300}\\sim\\mathcal N(0,1)\\\\P(X\\gt3000)=P(\\frac{X-2400}{300}\\gt2)\\Rightarrow1-P(Y\\le2)\\simeq1-0,977=0,023 \\text{ le jeu des arrondis}\\]" }, { "title": "PRST: Convergence", "url": "/cours/posts/prst_convergence/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-03-05 14:30:00 +0100", "snippet": "Lien de la note HackmdPRST - Seance 2Definition Soit $X$ une v.a (aucune condition prescrite) $\\phi$ definie sur $\\mathbb R$ par: $\\phi_X(t) = E(e^{itx})$ $\\vert e^{itx}\\vert \\le 1$ $\\phi(t)=\\int_{\\omega}e^{itx(\\omega)}$ Caracterise la loi d‚Äôune v.a, i.ei $\\phi_X=\\phi_Y \\Rightarrow X$ et $Y$ suivent la meme loiLois marginales Lois des v.a $X_i$ Impossible, sans hypothese supplementaire, de determiner la loi conjointe a partir des lois marginalesMatrice de covariance Matrice carre d‚Äôordre $d$ definie par $m_{ij} = Cov$Indepenance de 2 variables: cas discret 2 va $X$ et $Y$ sont dites independantes si, pour tout reel $x$ et $y$ de leur supports respectifs: $P({X\\le x})$ 2 variables aleatoires sont independantes si:Definition Un vecteur aleatoire $(X_1,‚Ä¶,X_d)$ est dit gaussien si toute combinaison des VA $X_k$ est gaussienne Un vecteur gaussien est entierement caracterise par $m=(E(X_1),‚Ä¶,E(X_d))^T$ et sa matrice de variance-covariances $\\Sigma$. Sa loi sera notee $N(m,\\Sigma)$ et nous parlerons de loi normale multidimensionnellePropositionSi $X$ est un vecteur gaussien et $A$ est une application lineaire definie sur $\\mathbb R^+$$Y = AX$ est un vecteur gaussien L‚Äôimage d‚Äôun vecteur gaussien par une application lineaire est un vecteur gaussien.Comment prouver que la d-ieme composante est gaussienne ?Soit $(X_1, X_2, X_3)$ un vecteur gaussien. Pourquoi $X_3$ suit-elle une loi gaussienne ?\\(\\underbrace{\\begin{pmatrix}0 &amp;amp; 0 &amp;amp;1\\end{pmatrix}}_{\\text{application lineaire}}\\begin{pmatrix}X_1\\\\X_2\\\\X_3\\end{pmatrix} = X_3\\)On considere Leo et Alexandre jouent a un jeu de pile ou face et font bourses communes. ¬† Leo pile 10 ‚Ç¨ face -10 ‚Ç¨ ¬† Alexandre Proba Image 10 ‚Ç¨ 1/2 SCIA 5 ‚Ç¨ 1/10 GISTRE -100 ‚Ç¨ 4/10 Ils vont pas en cours les SCIA - AlexandreOn a $(X;Y)$ avec $X$ les gains de Leo et $Y$ les gains de Alexandre. Les deux VA sont independantes\\[P(X=1-;Y=10) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\\\P(X=-10;Y=100) = \\frac{1}{2}\\times\\frac{4}{10} = 0,5\\\\(E(X); E(Y)) = (0; -34,5)\\]PropositionSoit $X = (X_1,‚Ä¶, X_d)$ un vecteur gaussien.Les variables aleatoires $X_1,‚Ä¶X_d$ sont independantes si et seulement si la matrice $\\Sigma$ est diagonale.$Cov(UV) = E(UV) - E(U) \\times E(V)$\\(\\Sigma =\\begin{pmatrix} Var(U) &amp;amp; Cov(U, V)\\\\ Cov(U, V) &amp;amp; Var(U)\\end{pmatrix}\\)Convergence presque sure (p.s.) $(X_i)$ suite de variables aleatoires sur le meme espace $\\Omega$ et $X$ une variable aleatoire egalement definie $\\Omega$ convergence ponctuelle implique tous les autres$\\lim_{n\\to+\\infty}X_n(\\omega) = Y(\\omega)$ pour tous $\\omega\\in\\Omega$Convergence en probabilite Meme cadre que precedemment $\\forall\\varepsilon\\gt 0, \\lim_{n\\to+\\infty}P(\\vert X_n - X\\vert\\ge \\varepsilon) = 0$Convergence en loi Meme cadre que precedemment $\\lim_{n\\to+\\infty}F_{X_n} = F_X$Theoreme de Paul Levy Si la suite de v.a. $(X_n)$ converge en loi vers une v.a. $X$ alors $\\lim_{n\\to+\\infty}\\pi_{X_n} = \\phi_X(t)$Convergence $L^2$ aussi appelee convergence en moyenne quadratique $\\lim_{n\\to+\\infty}E(\\vert X_n - X\\vert^2) = 0$ n‚Äôa de sens que pour les VA telles que $E(X^2)\\lt+\\infty$ implique la convergence en probabiliteConvergence $L^1$ aussi appelee convergence en moyenne $\\lim_{n\\to+\\infty}E(\\vert X_n -X\\vert) = 0$Loi forte des grands nombresSoit $(X_i)$ une suite de VA i.i.d. (independant et suivat la meme loi)\\[\\lim_{n\\to+\\infty}\\overline{X_n} = E(X)\\]au sens de la convergence p.s. ou $\\overline{X_n} := \\frac{X_1 + ‚Ä¶ + X_n}{n}$Cas unidimensionnel Soit $(X_i)$ une suite v.a. i.i.d. Noton $m:=E(X_i)$ et $\\sigma^2 = V(X_i)$ $X_1$ et $X_2$ deux v.a. independantes.\\(\\phi_{X_1 + X_2}(t) = \\phi_{X_1}(t) + \\phi_{X_2}(t)\\)Preuve\\(\\begin{aligned}\\phi_{X_1 + X_2}(t) &amp;amp;= E(e^{it(X_1 + X_2)})\\\\&amp;amp;= E(e^{itX_1})E(e^{itX_2})\\end{aligned}\\)Car les v.a. sont independantes\\(\\phi_{X_1+X_2} =\\)" }, { "title": "DBRE: Conditions de la protection", "url": "/cours/posts/dbre_protection/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-03-03 12:00:00 +0100", "snippet": "Lien de la note HackmdRecapLe monopole est confere pour favoriser la creation/innovation mais comporte un certain nombre d‚Äôexceptions pour ne pas avoir de blocage du marche.Le droit international prevoit une harmonisation pour qu‚Äôune oeuvre soit utilisee dans plusieurs pays, l‚Äôoeuvre depend des regulations de chacune des pays.La condition de protection La condition de protection est etudiee uniquement lorsqu‚Äôon veut faire valoir ses droits. Pourquoi me reprocher d‚Äôavoir copie quelquechose qui n‚Äôest pas protege ? Code de la propriete intellectuelle: une oeuvre est protegee si elle est originale. Mais ce n‚Äôest pas la seule condition de protection d‚Äôune oeuvre ! Est-ce que mon oeuvre est elligible au droit d‚Äôauteur ? Qu‚Äôest-ce qui, dans mon oeuvre, est considere comme protegeable? Ce ne sont pas les mots prits un a un Parmi la liste des oeuvres elligibles, je regardes quels elements sont originaux.$\\Rightarrow$ ce sont les etapes suivies par un juge lors d‚Äôun proces en contrefacon. Volet penal: passible d‚Äôune peine jusqu‚Äôa 3 ans de prison Volet civile: demander des dedomagemments ont consid√©r√©s notamment comme oeuvres de l‚Äôesprit au sens du pr√©sent code : 1¬∞ Les livres, brochures et autres √©crits litt√©raires, artistiques et scientifiques ; 2¬∞ Les conf√©rences, allocutions, sermons, plaidoiries et autres oeuvres de m√™me nature ; 3¬∞ Les oeuvres dramatiques ou dramatico-musicales ; 4¬∞ Les oeuvres chor√©graphiques, les num√©ros et tours de cirque, les pantomimes, dont la mise en oeuvre est fix√©e par √©crit ou autrement ; 5¬∞ Les compositions musicales avec ou sans paroles ; 6¬∞ Les oeuvres cin√©matographiques et autres oeuvres consistant dans des s√©quences anim√©es d‚Äôimages, sonoris√©es ou non, d√©nomm√©es ensemble oeuvres audiovisuelles ; 7¬∞ Les oeuvres de dessin, de peinture, d‚Äôarchitecture, de sculpture, de gravure, de lithographie ; 8¬∞ Les oeuvres graphiques et typographiques ; 9¬∞ Les oeuvres photographiques et celles r√©alis√©es √† l‚Äôaide de techniques analogues √† la photographie ; 10¬∞ Les oeuvres des arts appliqu√©s ; 11¬∞ Les illustrations, les cartes g√©ographiques ; 12¬∞ Les plans, croquis et ouvrages plastiques relatifs √† la g√©ographie, √† la topographie, √† l‚Äôarchitecture et aux sciences ; 13¬∞ Les logiciels, y compris le mat√©riel de conception pr√©paratoire ; 14¬∞ Les cr√©ations des industries saisonni√®res de l‚Äôhabillement et de la parure. Sont r√©put√©es industries saisonni√®res de l‚Äôhabillement et de la parure les industries qui, en raison des exigences de la mode, renouvellent fr√©quemment la forme de leurs produits, et notamment la couture, la fourrure, la lingerie, la broderie, la mode, la chaussure, la ganterie, la maroquinerie, la fabrique de tissus de haute nouveaut√© ou sp√©ciaux √† la haute couture, les productions des paruriers et des bottiers et les fabriques de tissus d‚Äôameublement. Article L112-2 Il n‚Äôy a pas de site web, jeux videos, etc. mais d‚Äôapres la jurisprudence ils en font partie. La jurisprudence a exclu a plusieurs reprises des textes sans originalite (definitions, lettre de l‚Äôalphabet, etc.).L‚Äôoriginalite qu‚Äôest-ce que c‚Äôest ? C‚Äôest l‚Äôempreinte de la personnalite de l‚Äôauteur. Ex: un style (en peinture, litterature, etc.).La titularite2 Hypotheses: Un oeuvre a un auteur unique La pluralite d‚Äôauteurs Article L111-1Modifi√© par LOI n¬∞2020-1674 du 24 d√©cembre 2020 - art. 35 (V) L‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit jouit sur cette oeuvre, du seul fait de sa cr√©ation, d‚Äôun droit de propri√©t√© incorporelle exclusif et opposable √† tous. Ce droit comporte des attributs d‚Äôordre intellectuel et moral ainsi que des attributs d‚Äôordre patrimonial, qui sont d√©termin√©s par les livres Ier et III du pr√©sent code. L‚Äôexistence ou la conclusion d‚Äôun contrat de louage d‚Äôouvrage ou de service par l‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit n‚Äôemporte pas d√©rogation √† la jouissance du droit reconnu par le premier alin√©a, sous r√©serve des exceptions pr√©vues par le pr√©sent code. Sous les m√™mes r√©serves, il n‚Äôest pas non plus d√©rog√© √† la jouissance de ce m√™me droit lorsque l‚Äôauteur de l‚Äôoeuvre de l‚Äôesprit est un agent de l‚ÄôEtat, d‚Äôune collectivit√© territoriale, d‚Äôun √©tablissement public √† caract√®re administratif, d‚Äôune autorit√© administrative ind√©pendante dot√©e de la personnalit√© morale, de la Banque de France, de l‚ÄôInstitut de France, de l‚ÄôAcad√©mie fran√ßaise, de l‚ÄôAcad√©mie des inscriptions et belles-lettres, de l‚ÄôAcad√©mie des sciences, de l‚ÄôAcad√©mie des beaux-arts ou de l‚ÄôAcad√©mie des sciences morales et politique. Les dispositions des articles L. 121-7-1 et L. 131-3-1 √† L. 131-3-3 ne s‚Äôappliquent pas aux agents auteurs d‚Äôoeuvres dont la divulgation n‚Äôest soumise, en vertu de leur statut ou des r√®gles qui r√©gissent leurs fonctions, √† aucun contr√¥le pr√©alable de l‚Äôautorit√© hi√©rarchique. Article L111-1 L‚Äôexistence ou la conclusion d‚Äôun contrat de louage d‚Äôouvrage ou de service par l‚Äôauteur d‚Äôune oeuvre de l‚Äôesprit n‚Äôemporte pas d√©rogation √† la jouissance du droit reconnu par le premier alin√©a, sous r√©serve des exceptions pr√©vues par le pr√©sent code.Il faut imperativement avoir un contrat de cession de droits si on sous-traite la creation d‚Äôune oeuvre. (ex: creation d‚Äôun jeu video) Le simple fait de commander une oeuvre ne veut pas dire qu‚Äôon est investi des droits sur l‚Äôoeuvre, il faut un transfere de titularite.Il y a une exception: Les droits des salaries appartiennent aux salaries.Ce n‚Äôest pas parce qu‚Äôun salarie est paye pour creer quelque chose que l‚Äôoeuvre appartient a l‚Äôemployeur, il faut une passation de droits.Et si on fait un projet a Epita, a qui appartient les droits ? L‚Äôoeuvre nous appartient car nous n‚Äôavons jamais signe de passation de droits MAIS il nous appartient sous reserve qu‚Äôon l‚Äôai fait entierement seul (cad pas de sujet, encadrement, etc.). Article L131-1Cr√©ation Loi 92-597 1992-07-01 annexe JORF 3 juillet 1992 La cession globale des oeuvres futures est nulle." }, { "title": "ASE2: TD 1, suite", "url": "/cours/posts/ase2_exercices_convergence_estimation_2/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-03-03 09:00:00 +0100", "snippet": "Lien de la note HackmdExercice 3Soit $X$ une VA de densite $f(x) = e^{-x-e^{-x}}$ $\\forall x\\in\\mathbb R$. Determiner la fonction de repartition de $X$ Soit $Y=e^{-X}$, determiner la fonction de repartition de $Y$, puis sa densite Calculer $E(Y)$, $V(Y)$ Soit $(Y_1,‚Ä¶, Y_n)$ un echantillon de $Y$, cad $(Y_i), 1\\le i\\le n$ sont alors des VA independantes et de meme loi que $Y$. On pose $\\overline{Y_{n}} = \\frac{1}{n}\\sum_{i=1}^nY_i$ Montrer que $\\overline{Y_n}\\to_{n\\to+\\infty}^P1$ Montrer que $\\overline{Y_n}\\to_{n\\to+\\infty}^{m.q}1$ Solution 1.$F(x) = P(X\\lt x) = \\int_{-\\infty}^xf(t)dt$ $\\forall x\\in\\mathbb R$\\[\\begin{aligned}F(x) &amp;amp;= \\int_{-\\infty}^xe^{-t}\\times e^{-e^{-t}}\\\\&amp;amp;= \\biggr[e^{-e^{-t}}\\biggr]_{-\\infty}^x = e^{-e^{-x}} \\text{ car } (e^{-e^{-t}})&#39; = e^{-t}e^{-e^{-t}}\\\\&amp;amp;= e^{-e^{-x}}\\end{aligned}\\] 2.$Y = e^{-X}$, Soit $G(y)$ la fonction de repartition de $Y$. $Y$ etant positive donc $G(y) = P(Y\\lt y) = 0$ pour $y\\le 0$. Pour $y\\gt 0$:\\[\\begin{aligned}G(y) &amp;amp;= P(Y\\lt y) = P(e^{-X}\\lt y) = P(-X\\lt \\ln(y))\\\\&amp;amp;= P(X\\gt-\\ln(y)) = 1 - F(-\\ln(y))\\\\&amp;amp;= 1 - e^{-y}\\\\\\text{Donc } G(y) &amp;amp;=\\begin{cases} 0 &amp;amp;y\\le 0\\\\ 1-e^{-y} &amp;amp;y\\gt 0\\end{cases}\\end{aligned}\\] La densite de $Y = e^{-X}$ est:\\[g(y) = G&#39;(y) =\\begin{cases} 0 &amp;amp;y\\le 0\\\\ e^{-y} &amp;amp;y\\gt 0\\end{cases}\\] 3.$E(Y) = \\int_{\\mathbb R}yg(y)dy = \\int_{-\\infty}^{+\\infty}ye^{-y}dy$ On integre par parties:\\(\\begin{cases} v = y &amp;amp;v&#39;=1\\\\ u&#39; = e^{-y} &amp;amp;u = -e^{-y}\\end{cases}\\\\\\begin{aligned}E(Y) = \\underbrace{\\biggr[-ye^{-y}\\biggr]_0^{+\\infty}}_{_{y\\to+\\infty}\\to0} - \\int_0^{+\\infty}(-e^{-y})dy &amp;amp;= \\int_0^{+\\infty}e^{-y}dy\\\\&amp;amp;= \\biggr[-e^{-y}\\biggr]_0^{+\\infty} = 1\\end{aligned}\\\\V(Y) = E(Y^2) - E^2(Y)\\\\E(Y^2) = \\int_0^{+\\infty}y^2e^{-y}dy\\\\\\text{Integration par parties:}\\begin{cases} v = y^2 &amp;amp;v&#39;=2y\\\\ u&#39;=e^{-y} &amp;amp;u=-e^{-y}\\end{cases}\\\\\\begin{aligned}E(Y^2) &amp;amp;=\\int_0^{+\\infty}Y^2e^{-y}dy = \\underbrace{\\biggr[-y^2e^{-y}\\biggr]_0^{+\\infty}}_{_{y\\to+\\infty}\\to0}-\\int_0^{+\\infty}2y(-e^{-y})dy\\\\&amp;amp;= 2\\int_0^{+\\infty}ye^{-y}dy = 2E(Y) = 2\\\\\\text{Donc: } V(Y) &amp;amp;= 2 - 1 = 1\\end{aligned}\\) 4.1.$\\overline{Y_n}=\\frac{1}{n}\\sum_{i=1}^{n}Y_i$, $(Y_i)_{1\\le i\\le n}$ idependantes et de meme loi que $Y$.\\[\\begin{aligned}E(\\overline{Y_n}) &amp;amp;= \\frac{1}{n}\\sum_{i=1}^nE(Y_i) = \\frac{1}{n}\\sum_{i=1}^n1 = \\frac{n}{n} = 1\\\\V(\\overline{Y_n}) &amp;amp;= \\frac{1}{n^2}\\sum_{i=1}^nV(Y_i)= \\frac{n}{n^2} = \\frac{1}{n}\\end{aligned}\\] En utilisant Tchebychev:\\[\\begin{aligned}\\forall\\varepsilon\\gt0, &amp;amp;P(\\vert\\overline{Y_n}-E(\\overline{Y_n})\\vert \\gt\\varepsilon)\\lt\\frac{V(\\overline{Y_n})}{\\varepsilon^2}\\\\\\Rightarrow &amp;amp;P(\\vert\\overline{Y_n}-1)\\vert \\gt\\varepsilon)\\lt\\frac{1}{n\\varepsilon^2}\\to_{n\\to+\\infty}0\\\\\\text{Donc: } &amp;amp;\\overline{Y_n}\\to_{n\\to+\\infty}^P1\\end{aligned}\\] 4.2.Montrons que $\\overline{Y_n}\\to_{n\\to+\\infty}^{m.q}1$\\[\\begin{aligned}E(\\vert\\overline{Y_n}-1)\\vert^2) &amp;amp;= E(\\vert\\overline{Y_n}-E(\\overline{Y_n})\\vert^2)\\\\&amp;amp;=V(\\overline{Y_n}) = \\frac{1}{n}\\to_{n\\to+\\infty}0\\\\\\text{Donc: } \\overline{Y_n}&amp;amp;\\to_{n\\to+\\infty}^{m.q}1\\end{aligned}\\]Exercice 4Soit $X$ une VA de loi $\\gamma_p$, $(p\\in\\mathbb N^*)$ Determiner la fonction caracteristique de $X$ En deduire celle de $\\frac{X-p}{\\sqrt{p}}$ Montrer que $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$ Solution 1.$X$ suit la loi $\\gamma_p$ (gamma). Sa densite est $f(x) = \\frac{1}{\\Gamma(p)}e^{-x}x^{p-1}$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\frac{1}{\\Gamma(p)}\\int_0^{+\\infty}e^{itx}e^{-x}x^{p-1}dx\\\\&amp;amp;=\\frac{1}{\\Gamma(p)}\\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\\\text{Posons: } I_{p-1}&amp;amp;=\\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\I_0 &amp;amp;= \\int_0^{+\\infty}e^{(it-1)x}dx = \\biggr[\\frac{e^{(it-1)x}}{it-1}\\biggr]_0^{+\\infty} = -\\frac{1}{it-1}\\\\\\text{Car: } e^{(it-1)x} &amp;amp;= e^{itx}.e^{-x}\\to_{x\\to+\\infty}0 \\text{ puisque }\\vert e^{itx}\\vert = 1\\text{ (bornee) }\\\\I_{p-1} &amp;amp;= \\int_0^{+\\infty}e^{(it-1)x}x^{p-1}dx\\\\\\end{aligned}\\\\\\text{Integration par parties:}\\begin{cases} v = x^{p-1} &amp;amp;v&#39;=(p-1)x^{p-2}\\\\ u&#39;=e^{(it-1)x} &amp;amp;u=\\frac{1}{it-1}e^{(it-1)x}\\end{cases}\\\\\\begin{aligned}I_{p-1}&amp;amp;=\\underbrace{\\biggr[\\frac{e^{(it-1)x}}{it-1}x^{p-1}\\biggr]_0^{+\\infty}}_{\\to_{x\\to+\\infty}0} - \\frac{p-1}{it-1}\\int_0^{+\\infty}e^{(it-1)x}x^{p-2}dx\\\\\\text{Car: } \\underbrace{e^{itx}}_{\\text{bornee}, \\vert e^{itx}\\vert = 1}&amp;amp;e^{-x}x^{p-1}\\to_{x\\to+\\infty}0\\\\I_{p-1} &amp;amp;= -\\frac{p-1}{it-1}I_{p-2}\\text{ } \\forall p\\ge 2\\\\I_{p-2} &amp;amp;= -\\frac{p-2}{it-1}I_{p-3}\\\\&amp;amp;.\\\\&amp;amp;.\\\\&amp;amp;.\\\\I_2 &amp;amp;= -\\frac{2}{it-1}I_1\\\\I_1 &amp;amp;= -\\frac{2}{it-1}I_1\\\\\\end{aligned}\\] En faisant le produit:\\[\\begin{aligned}I_{p-1} &amp;amp;= \\frac{(-1)^{p-1}(p-1)!}{(it-1)^p}I_0\\\\&amp;amp;= \\frac{(-1)^p(p-1)!}{(it-1)^p}\\\\\\phi_X(t) &amp;amp;= \\frac{1}{\\Gamma(p)}I_{p-1}=\\frac{(-1)^p}{(it-1)^p} \\\\&amp;amp;= (1-it)^{-p}\\end{aligned}\\] 2.On veut la fonction caracteristique de $\\frac{X-p}{\\sqrt{p}}$. Or, d‚Äôapres le cours:\\[\\phi_{\\frac{X-m}{\\sigma}}(t) = e^{-\\frac{itm}{\\sigma}}\\phi_X(\\frac{t}{\\sigma})\\] Ici $m=p$ et $\\sigma=\\sqrt{p}$ Donc:\\[\\begin{aligned}\\phi_{\\frac{X-p}{\\sqrt{p}}} &amp;amp;= e^{-\\frac{itp}{\\sqrt{p}}}\\phi_X(\\frac{t}{\\sqrt{p}})\\\\\\Rightarrow \\phi_{\\frac{X-p}{\\sqrt{p}}} &amp;amp;= e^{-\\frac{itp}{\\sqrt{p}}}(1-\\frac{it}{\\sqrt{p}})^{-p}\\end{aligned}\\] 3.Montrons que $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$\\[\\ln(\\phi_{\\frac{X-p}{\\sqrt{p}}}) = -\\frac{itp}{\\sqrt{p}}-p\\ln(1-\\frac{it}{\\sqrt{p}})\\] Or $\\ln(1+x)\\sim x-\\frac{x^2}{2}$ au voisinage de 0. Donc:\\[\\begin{aligned}\\ln(\\phi_{\\frac{X-p}{\\sqrt{p}}})&amp;amp;\\simeq-\\frac{itp}{\\sqrt{p}}-p(-\\frac{it}{\\sqrt{p}} + \\frac{t^2}{2p}) \\text{ pour p au voisinage de } +\\infty\\\\&amp;amp;\\simeq -\\frac{itp}{\\sqrt{p}}+\\frac{itp}{\\sqrt{p}}+\\frac{t^2}{2} = \\frac{t^2}{2} \\text{ pour p au voisinage de } +\\infty\\\\\\Rightarrow \\phi_{\\frac{X-p}{\\sqrt{p}}}&amp;amp;\\simeq e^{-\\frac{t^2}{2}} \\text{ : fonction caracteristique de } N(0,1)\\end{aligned}\\] Conclusion: $\\frac{X-p}{\\sqrt{p}}\\to_{p\\to+\\infty}^LN(0,1)$" }, { "title": "PRST: Feuille 1 - Exercice", "url": "/cours/posts/prst_first_exercise/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-02-24 15:30:00 +0100", "snippet": "Lien de la note HackmdExercice 4Demontrer les proprietes suivantes dans le cas discret: Soient $X$ et $Y$ deux variables aleatoires definies sur un meme espace $\\Omega$ et $\\lambda$ un nombre reel. Solution Soit $\\omega_1,‚Ä¶,\\omega_n$ les issues i.e. $\\Omega = {\\omega_1;‚Ä¶;\\omega_n}$\\[\\begin{aligned}E(X\\times Y) &amp;amp;= \\sum_{\\omega\\in\\Omega}(X(\\omega) + Y(\\omega))\\\\&amp;amp;= \\underbrace{\\sum_{\\omega\\in\\Omega} p(\\omega)X\\vert\\omega\\vert}_{=E(X)} + \\underbrace{\\sum_{\\omega\\in\\Omega} p(\\omega)Y\\vert\\omega\\vert}_{=E(Y)}\\\\&amp;amp;= E(X) + E(Y)\\end{aligned}\\]\\[\\begin{aligned}E(\\lambda X) &amp;amp;= \\sum_{\\omega\\in\\Omega}p(\\omega)\\lambda X(\\omega)\\\\&amp;amp;= \\lambda\\sum_{\\omega\\in\\Omega}p(\\omega)X(\\omega)\\\\&amp;amp;= \\lambda E(X)\\end{aligned}\\]Exercice 3Determiner la loi $\\mathcal B(3, \\frac{1}{3})$ Solution $P(X = x_1) = \\binom{3}{0}\\times\\frac{1}{3}^0\\times\\frac{2}{3}^3 = \\frac{8}{27}$ $P(X = x_2) = \\binom{3}{1}\\times\\frac{1}{3}^1\\times\\frac{2}{3}^2 = \\frac{4}{9}$ $P(X = x_3) = \\binom{3}{2}\\times\\frac{1}{3}^2\\times\\frac{2}{3}^1 = \\frac{2}{9}$ $P(X = x_4) = \\binom{3}{3}\\times\\frac{1}{3}^3\\times\\frac{2}{3}^0 = \\frac{1}{27}$ $P(X)$ $\\frac{8}{27}$ $\\frac{4}{9}$ $\\frac{2}{9}$ $\\frac{1}{27}$ $X$ $x_1$ $x_2$ $x_3$ $x_4$ Exercice 14Soit $X$ une variable aleatoire suivant une loi geometrique. Montrer que $P(X\\gt n+k\\vert X\\gt k) = P(X\\gt n)$ pour tous entiers naturels $k$ et $n$.Nous dirons que la loi geometrique est sans memoire. Solution Soient $n$ et $k$ deux entiers naturels.\\[\\begin{aligned}P(X\\gt n) &amp;amp;= \\sum_{k\\gt n} pq^{k-1}\\\\&amp;amp;= pq^n + pq^{n+2} +...\\\\&amp;amp;= pq^n(1+q+q^2+...)\\end{aligned}\\] Or $\\sum_{k\\ge0}q^k=\\frac{1}{1-q}$ pour $0\\le q\\lt1$ D‚Äôou:\\[P(X\\gt n) = pq^n\\times\\frac{1}{1-q} = pq^n\\times\\frac{1}{p} = q^n\\] Ainsi:\\[P(X\\gt n+k\\vert X\\gt k) = \\frac{P(\\{X=n+k\\}\\cap\\{x\\gt k\\})}{P(X\\gt k)}\\] Or ${X=n+k}\\cap{x\\gt k} = {X\\gt n+k}$ D‚Äôou: \\(P(X\\gt n + k) = \\frac{P(X\\gt n + k)}{P(X\\gt k)} = \\frac{q^{n+k}}{q^k} = q^n = P(X\\gt n)\\)Exercice 6Considerons une variable aleatoire $X$ suivant une loi de Poisson de parametre 3 Calculer $P(X=10)$ Calculer $E(X)$ et $V(X)$ Solution \\(P(X=10) = e^{-3}\\times\\frac{3^{10}}{10!}\\\\E(X) = V(X) = 3\\)Exercice 11La variable aleatoire $U$ suit une loi uniforme sur l‚Äôintervalle $[2;5]$.Calculer $P(U)\\in[2;3]$ et $E(U)$ Solution $P(U) = \\frac{1}{3}$" }, { "title": "PRST: Les differentes lois", "url": "/cours/posts/prst_first_class/", "categories": "Image S8, PRST", "tags": "Image, SCIA, PRST, S8", "date": "2021-02-24 14:30:00 +0100", "snippet": "Lien de la note HackmdSyllabus Rappel sur les notions de probas elementaires Rappel sur les variables scalairesGeneralites Etude d‚Äôexperiences aleatoires Experience aleatoire: experience dont on ne peut prevoir l‚Äôissue a l‚Äôavance mais dont on connait toutes les issues possibles Alea vient du latin alea qui est un jeu de desSituation elementaire $n$ issues $\\omega_1,‚Ä¶, \\omega_n$ univers $\\Omega={\\omega_1,‚Ä¶, \\omega_n}$ Proba d‚Äôoccurence associee $p_1,‚Ä¶, p_n$ loi de proba: donnees des $p_i Les probas $p_i$ sont positives et verifient: $p_1+‚Ä¶+p_n = 1$ evenements: sous-ensemble de $\\Omega$ Probabilite d‚Äôun evenements: somme des probas des issues qui le realiseExemple d‚Äôexperience aleatoire: traverser la route et voir si on se fait ecraser ou non (Alexandre tu vas bien ?) $\\rightarrow$ experience de Bernoulli a 2 issuesQuelles experiences aleatoire en informatique ?La duree de vie d‚Äôun composant electroniqueProprietes equiprobabilite: toutes les issues ayant la meme proba exercice: proposer une situation qui n‚Äôest pas equiprobable $A\\cap B$: ensemble des issues qui realisent simultanement $A$ et $B$ $A\\cup B$: ensmeble des issues qui realisent au moins un des 2 evenemenentsConditionnement Soient A et B evenements (supposons $P(A) \\neq 0$ et $P(B) \\neq 0$) $P_A(B) = \\frac{P(A \\cap B)}{P(A)}$ Formule de Bayes: $P_B(A) = \\frac{P_A(B)\\times P(A)}{P_A(B)\\times P(A) + P_{\\overline{A}}(B) \\times P(\\overline{A})}$ $P(B) = P_A(B)\\times P(A)+P_A(B)\\times P(\\overline{A})$Demonstration\\(\\begin{aligned}P_B(A) &amp;amp;= \\frac{P(A \\cap B)}{P(B)}\\\\&amp;amp;= \\frac{P_A(B)P(A)}{P(B)}\\\\&amp;amp;= \\frac{P_A(B)P(A)}{P_A(B)\\times P(A) +P_A(B)\\times P(\\overline{A})}\\end{aligned}\\) C‚Äôest une proba a posteriori, cad apres que l‚Äôexperience ait eu lieu.VA discrete VA $X :$ fonction definie sur $\\Omega$ et a valeurs dans $\\mathbb R$ $X$ peut prendre les valeurs $x_1,‚Ä¶, x_n$ $\\Omega$ sera ‚Äúoublie‚Äù et on se concentrera sur les probas $p_i := P({\\omega\\in\\Omega\\vert X(\\omega) = x_i}):= P(X=x_i)$ Loi d‚Äôune variable aleatoire: donnee par des reels $P(X=x_i)$ exercice: modeliser le gain a un jeu de Pile ou Face a l‚Äôaide d‚Äôune VA (gain de 100 euros si le ‚ÄúPile‚Äù et perte de 80 euros si ‚ÄúFace‚Äù) valeurs: 100 et -80 ex: si la piece tombe sur 2 on gagne 100 euros, sinon on en perde 80 $p_g = \\frac{1}{6}$ $p_p = \\frac{5}{6}$ Cf. Exercice 4Prenons Clara et Nizar en cobayent avec leurs numero prefere ¬† Clara Nizar ¬† 1 -10 30 20 2 50 -20 30 3 -10 30 20 4 -10 -20 -30 5 50 30 80 6 -10 -10 -20 $x_1 = -10$ $x_2 = 50$ $y_1 = -20$ $y_2 = -10$ $y_3 = 30$ Attention, la definition des reels $p_i$ a change ! Esperance: $E(X) = \\sum_{i=1}^np_i(x_i-\\overline x)^2$ Variance: $V(X) = E(X - E(X)^2) = E(X^2) - E(X)^2$Loi de Bernoulli VA $X$ pouvant prendre les valeurs 0 et 1 proba de prendre la valeur 1 notee $p$ par consequent: $P(x=0)=1-p$ $E(X) = p\\times1 + (1-p)\\times 0 = p$ et $V(X) =E((X - E(X)^2)) = p(1-p)$ Loi notee $B(p)$Loi binomial de parametre $n$ et $p$ some de $n$ variables independantes suivant une loi $B(p)$ Nombre de succes apres $n$ repetitions d‚Äôune experience de Bernouilli VA $X$ pouvant prendre les valeurs entieres comprises entre 0 et $n$ $P(X=k) = \\binom{n}{k}p^k(1-p)^{n-k}$ pour $k\\in{0,‚Ä¶,n}$ Loi notee $B(n,p)$ $\\binom{n}{k}$: coefficient binomial $E(X) = np$ et $V(X) = np(1-p)$ $\\binom{4}{0} = 1$ $\\binom{4}{1} = 4$ $\\binom{4}{2} = 6$ $\\binom{4}{3} = 4$ $\\binom{4}{4} = 1$Comment trouver de maniere maths ?On utilise le triangle de Pascal $\\binom{6}{3} = 20$ $\\binom{3}{2} = 3$Quels sont les elements remarquables sur le triangle de Pascal ? $\\binom{n}{k} = \\binom{n}{n-k}$ $\\binom{n}{0} = \\binom{n}{n} = 1$ $\\binom{n}{1} = \\binom{n}{n - 1} = n$ Cf. Exercice 3Loi binomial negative de parametre $n$ et $p$ aussi appelee loi de PascalLoi geometrique de parametre p nombre d‚Äôessais avant le premier succes dans une repetition de tirages inde de Bernoulli $p$ : probabilite de ‚ÄúSucces‚Äù $X$ peut prendre toutes les valeurs entieres hormis 0 $P(X=k)=pq^{k-1}$ ou $q=1-p$ $E(X) = \\frac{1}{p}$ et $V(X)=\\frac{q}{p^2}$ Loi notee $G(p)$ C‚Äôest une loi sans memoire.Qu‚Äôest-ce que ca veut dire ? La loi geometrique est ‚Äúsans memoire‚Äù, cad que les evenements passes n‚Äôinfluent pas les evenements futurs. Cf. Exercice 14 Les 2 grandes lois sans memoire sont les lois: exponentielle geometrique Loi Poisson de parametre $\\lambda$ $X$ peut prendre toutes les valeurs entieres $\\lambda$ parametre strictement positif $P(X=k) = e^{-\\lambda}\\frac{\\lambda^k}{k!}$ $E(X) = \\lambda$ et $V(X) = \\lambda$ loi notee $P(\\lambda)$ Cf. Exercice 6Cadre $X$ definie sur l‚Äôunivers $\\Omega$ et a valeurs dans $\\mathbb R$ ou dans un intervalle $I$ $P(X\\in[a;b]) = \\int_a^bf(x)dx$ fonction $f$ appelee la densite de la variable aleatoire $X$ Pour un reel $x$ donne: $P(X=x)=0$Densite de probabilite 2 conditions a connaitre $f(x)\\ge0$ pour tout reel $x\\in I$ $\\int_If(x)dx = 1$ (l‚Äôintervalle peut etre $\\mathbb R$)Fonction de repartition Soit $X$ une variable aleatoire $F_X(x) := P(X\\le x) = \\int_{-\\infty}^{x}f(t)dt$ Fonction de survie: $R_X(x) := P(X\\gt x) = 1 - F_X(x)$$\\int_0^{+\\infty}e^xdx$ a un sens dans $[0; +\\infty]$Esperance formule analogue au cas discret si $\\int_f\\vert x\\vert f(x)dx\\lt+\\infty$Variance Si $\\int_fx^2\\vert f(x)\\vert dx\\lt+\\infty$ la VA $X$ est dite de carre integrable $V(X) = \\int_f(x-E(X))^2f(x)fx$ est bien definie $V(X) = E(X^2) - E(X)^2$ (theoreme de Koenig-Huyghens) $V(aX) = a^2V(X)$Pour $X$ et $Y$ Tout depend de la dependance des variables, si $X$ et $Y$ sont independantes: $E(XY) = E(X)E(Y)$Loi uniforme sur l‚Äôintervalle $[a;b]$ $f(x) = \\frac{1}{b-a}$ pour $x\\in [a;b]$ et $f(x) = 0$ pour $x\\not\\in[a;b]$ $P(X\\in[c;d]) = \\frac{d-c}{b-a}$ si $a\\le c \\le c\\le d \\le b$ et $a\\lt b$ $E(X) = \\frac{a+b}{2}$ et $V(X) = \\frac{(b-a)^2}{12}$ Exercice: demontrer ce resultat puis calculer la fonction de reparatition associes Notee $U([a;b])$ CF. Exercice 11Loi exponentielle de parametre $\\lambda\\gt 0$ $f(x) = \\lambda e^{-\\lambda x}$ pour $x\\ge 0$ et $f(x) = 0$ pour $x\\lt0$ $E(X)=\\frac{1}{\\lambda}$ et $V(X) = \\frac{1}{\\lambda^2}$ $F(x) = 1-e^{-\\lambda x}$ pour $x\\ge 0$ et $F(x) = 0$ sinon $R(x) = e^{-\\lambda x}$ pour $x\\ge 0$ etLoi exponentielle Loi notee $\\varepsilon(\\lambda)$ duree de vie d‚Äôun phenomene sans memoire $\\forall s\\gt 0, \\forall t \\gt 0, P_{T\\gt t}(T\\gt s + t) = P(T\\gt s)$Loi normale centree reduite $f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$ pour $x\\in\\mathbb R$ $E(X) = 0$ et $V(X) = 1$ Loi notee $N(0;1)$ $P(X\\le0)=P(X\\ge0) = 0.5$ $P(X\\le-a) = P(X\\ge a)$ $P(-196\\le X\\le 1.96)\\approx0.95$ et $P(-2,58\\le X\\le2.58)\\approx 0.99$ Loi notee $N(0,1)$Loi normale de parametre $\\nu$ et $\\sigma$ Loi notee $N(\\nu,\\sigma^2)$ $X$ suit une loi $N(\\nu,\\sigma^2)$ si $Y = \\frac{X-\\nu}{\\sigma}$ suit une loi normale centree reduite $P(\\nu-\\sigma\\le X\\le \\nu+\\sigma)\\approx0.68$ $P(\\nu-2\\sigma\\le X\\le \\nu+2\\sigma)\\approx0.95$ $P(\\nu-3\\sigma\\le X\\le \\nu+3\\sigma)\\approx0.997$" }, { "title": "DBRE: Introduction", "url": "/cours/posts/dbre_introduction/", "categories": "tronc commun S8, DBRE", "tags": "tronc commun, DBRE, S8", "date": "2021-02-24 11:00:00 +0100", "snippet": "Lien de la note HackmdDBRE: Introduction Le coeur de la protection d‚Äôun logiciel se fait via les droits d‚Äôauteurs. On n‚Äôa aucune solution dont on puisse etre sur a 100%.La solution la plus probable est celle retenue par les juges. C‚Äôest pas bon pour la securite juridique mais on ne peut pas faire autrementPropriete intellectuellesPour qu‚Äôune invention soit brevetable, il faut que l‚Äôinventeur ait une activitee inventive, cad trouver une solution pas evidente pour ‚Äúl‚Äôhomme du metier‚Äù. L‚Äôinventivite et l‚Äôevidence sont subjectifs.On doit aussi avoir un peu de personnalite de l‚Äôauteur, que l‚Äôoeuvre soit originale $\\rightarrow$ subjectifFair use Le ‚Äúfair use‚Äù n‚Äôa pas d‚Äôequivalents en droit francais.Une autre difficulte vient de la recherche constante du compromis entre ‚Äúaccordons suffisemment de droits pour que les gens creent‚Äù mais ‚Äúpas trop pour pas bloquer‚Äù.Exceptions Dans les proprietes intellectuelles, il y a des tonnes d‚Äôexceptions.Le but est de contrebalancer un monopole necessaire pour retablir un equilibre, mais cela cause des incertetitudes juridiques.Exemple Apres le premier sequencage du genome humain, le president des US a precise qu‚Äôil n‚Äôetait pas brevetable car ce sont des genes (de meme avec le genome du COVID-19)Il est tout a fait possible de depose un vaccin libre de droits (mais cela ne se fait pas car pas viable economiquement)Certaines personnes ne deposent pas de brevets car l‚Äôinvention peuvent vite devenir obsolete ou pour mettre l‚Äôinvention a disposition de la communaute.Monsanto n‚Äôa pas brevete du mais, mais une facon de le cultiverDiffusion d‚Äôune oeuvre Selon de la ou une oeuvre est diffusee, ce ne sont pas les memes droits qui s‚Äôappliquent $\\rightarrow$ cela ne depend pas de la nationalite de l‚Äôauteur.De meme pour le droit du travail.Exemple Nous utilisons teams conformement aux droits d‚Äôauteur francais. Si on vend des chaussures sur Internet, qu‚Äôon s‚Äôaddresse au public d‚Äôun pays, qu‚Äôon livre la-bas, etc. on est soumis au droit de consommation du pays en question" }, { "title": "ASE2: TD 1", "url": "/cours/posts/ase2_exercices_convergence_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-02-24 10:00:00 +0100", "snippet": "Lien de la note HackmdExercice 1Determiner les fonctions caracteristiques dans les cas suivants:$X$ suit la loi binomiale $B(n,p)$ Solution $X$ suit la loi $B(n,p)$.$X$ est une somme independante de variables de Bernoulli $B(p)$.\\[X = \\sum^n_{j=1}X_j\\] ou $X_j\\to B(p) \\forall j = 1,‚Ä¶, n$ D‚Äôapres le cours, on a calcule la fonction caracteristique de Bernouilli $\\phi_{x_j}(t) = q + pe^{it}$ avec $q = 1-p$ or les $X_i$ sont independantes\\[\\phi_{\\sum_{j=1}^{k}X_j} = \\Pi^k_{j=1}\\phi_{X_j}(t) = (q+pe^{it})^n\\] Remarque: Comme 2e methode on peut calculer directement $\\phi_X(t)$, $X\\to B(n,p)$\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\sum^n_{k=0}e^{itk}P(X=k)\\\\&amp;amp;= \\sum^n_{k=0}e^{itk}\\binom{n}{k}p^k(1-p)^{n-k} \\\\&amp;amp;= \\sum^n_{k=0}\\binom{n}{k}(pe^{it})^k(1-p)^{n-k}\\\\&amp;amp;= (1-p+pe^{it})^n \\text{ (Netwon)}\\\\&amp;amp;= (q+pe^{it})^n\\end{aligned}\\]$X$ suit la loi de Poissons $P(\\lambda)$ Solution $X\\to P(\\lambda)$ Poisson de parametre $\\lambda$.\\[\\begin{aligned}P(X=k) &amp;amp;= e^{-\\lambda}\\frac{\\lambda^k}{k!} \\forall k\\in\\mathbb N\\\\\\phi_X(t) &amp;amp;= \\sum_{k=0}^{+\\infty}e^{itk}P(X=k) = \\sum_{k=0}^{+\\infty}e^{itk}e^{-\\lambda}\\frac{\\lambda^k}{k!}\\\\&amp;amp;=e^{-\\lambda}\\sum_{k=0}^{+\\infty}\\frac{(\\lambda e^{it})^{k}}{k!}\\\\\\end{aligned}\\] Rappel: $\\sum_0^{+\\infty}\\frac{x^k}{k!} = e^x$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= e^{-\\lambda}\\exp(\\lambda e^{it})\\\\&amp;amp;= \\exp(-\\lambda+\\lambda e^{it})\\end{aligned}\\]$X$ suit la loi uniforme $U[-a,a]$ Solution $X\\to U_{[-a, a]}$ (Loi uniforme sur $[-a, a]$)Sa densite est:\\(f(x)=\\begin{cases} \\frac{1}{2a} &amp;amp;\\forall x\\in [-a, a]\\\\ 0 &amp;amp;\\text{sinon}\\end{cases}\\) Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\int_{\\mathbb R}e^{itx}f(x)dx = \\frac{1}{2a}\\int_{-a}^ae^{itx}dx\\\\&amp;amp;= \\frac{1}{2a}\\biggr[\\frac{e^{itx}}{it}\\biggr]^a_{-a} = \\frac{1}{2a}\\biggr(\\frac{e^{ita} - e^{-ita}}{it}\\biggr)\\\\&amp;amp;\\Rightarrow \\phi_X(t) = \\frac{2i\\sin(at)}{2ait} = \\frac{sin(at)}{at}\\end{aligned}\\]$X$ suit la loi normale $N(0,1)$ Solution $X\\to N(0,1)$ (Loi normale centree reduite)En utilisant la formule de Mac-Laurin:\\[\\phi_X(t) = \\sum_{k=0}^{+\\infty}\\frac{t^k}{k!}i^kE(X^k)\\] or $X\\to N(0,1)$ $E(X^k) = 0$ si $k$ impair et $E(X^{2k}) = \\frac{(2k)!}{2^kk!}$ Donc:\\[\\begin{aligned}\\phi_X(t) &amp;amp;= \\sum_{k=0}^{+\\infty}\\frac{(-\\frac{t^2}{2})^k}{k!} \\\\&amp;amp;= e^{-\\frac{t^2}{2}}\\end{aligned}\\]Exercice 2Soit $X_n$ une suite de variables aleatoires de densite $f(x)=\\frac{ne^{-nx}}{(1+e^{-nx})^2}$.Montrer que $X_n\\to^P_{n\\to+\\infty}0$ Solution $X_n$ suite de VA $f_n(x) = \\frac{ne^{-nx}}{(1+e^{-nx})^2}$ On veut montrer que $X_n\\to^P_{n\\to+\\infty}0$\\[\\begin{aligned}P(\\vert X_n\\vert\\gt\\varepsilon) &amp;amp;= 1 - P(\\vert X_n\\vert\\le\\varepsilon)\\\\&amp;amp;= 1 - P(-\\varepsilon\\le X_n\\le\\varepsilon)\\\\&amp;amp;= 1 - \\int_{-\\varepsilon}^{\\varepsilon}f_n(x)dx\\\\&amp;amp;= 1-\\int_{-\\varepsilon}^{\\varepsilon}\\frac{ne^{-nx}}{(1+e^{-nx})^2}dx\\\\&amp;amp;= 1 - \\biggr[\\frac{1}{1+e^{-nx}}\\biggr]_{-\\varepsilon}^{\\varepsilon} = 1-\\frac{1}{1+e^{-n\\varepsilon}}+\\frac{1}{1+e^{n\\varepsilon}}\\\\\\lim_{n\\to+\\infty}P(\\vert X_n\\vert\\gt\\varepsilon) &amp;amp;= 1- 1 + 0 =0\\\\\\end{aligned}\\\\\\] Donc $X_n\\to^{P}_{n\\to+\\infty}0$" }, { "title": "ASE2: Convergence et estimation - 1", "url": "/cours/posts/ase2_convergence_estimation/", "categories": "tronc commun S8, ASE2", "tags": "tronc commun, ASE2, S8", "date": "2021-02-24 09:00:00 +0100", "snippet": "Lien de la note HackmdIntroduction L‚Äôestimation: on va considerer une population qui obeit a une loi de probabilite avec un parametre $\\theta$ inconnu.L‚Äôobjectif de l‚Äôestimation c‚Äôest estimer le parametre. On preleve un echantillon (suite de variables aleatoires independantes $X_1$, $X_2$,‚Ä¶, $X_n$ suivant la meme loi que la population $X$) dans cette population, on va construire un estimateur destine a converger vers le parametre $\\theta$. Un estimateur est une fonction $T = f(X_1, X_2, ‚Ä¶, X_n)$ de notre echantillon.Qualites de l‚Äôestimateur: Etre convergent Etre precis Plus la variance est minimale, plus on a un estimateur precis Etre efficacePour etudier la convergeance, on va voir 3 types: Convergence en proba Convergence quadratique Convergence discreteRappels de la loi Gamma et la loi Normale On dit qu‚Äôune variable aleatoire positive $X$ suit une loi gamma de parametre r, notee $\\gamma_r$ si sa densite est donnee par \\(f(x) = \\frac{1}{\\Gamma(r)}\\exp(-x)x^{\\gamma - 1}\\)Avec $\\Gamma(x) = \\int^{+\\infty}_0\\exp(-t)t^{x-1}dt$ (fonction Gamma) definie pour $x\\gt 0$Propriete de la fonction Gamma $\\Gamma(x+1)=x\\Gamma(x)$ (integration par partie) $\\Gamma(1)=1$ $\\Gamma(n+1)=n!$ $\\Gamma(k+\\frac{1}{2}) = \\frac{1.3.5‚Ä¶..(2k -1)}{2^k}\\Gamma(\\frac{1}{2})$ $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$Esperance de la loi $\\gamma_r$: soit $X$ une variable aleatoire suivant la loi gamma de parametre r.On a:\\(E(x)=\\frac{1}{\\Gamma}\\int^{+\\infty}_0 t^T\\exp(-t)dt = \\frac{\\Gamma(r+1)}{\\Gamma(r)} = r\\)Variance de la loi $\\gamma_r : V(X) = E(X^2) - E^2(X)$\\(E(X^2) = \\frac{1}{\\Gamma(r)}\\int^{+\\infty}_0 t^2\\exp(-t) t^{r-1}dt = \\frac{1}{\\Gamma(r)}t^{r+1}\\exp(-t)dt = \\frac{\\Gamma(r+2)}{\\Gamma(r)} = r(r + 1)\\)Donc $V(X) = r(r + 1) - r^2 = r$Loi Normale de parametre $(m, \\sigma)$On dit qu‚Äôune variable aleatoire $X$ suit la loi normale notee $N(m, \\sigma)$ si sa densite est $f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}(\\frac{x-m}{\\sigma})^2)$ou: $m=E(X)$ $\\sigma=\\sqrt{V(X)}$ (ecart-type)Avec le changement de variable $U=\\frac{X-m}{\\sigma}$ (variable normale centree reduite), la densite de $U$ est $f(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{1}{2}u^2)$.Montrons que $V(U) = 1$On a $V(U) = E(U^2) = \\int_{-\\infty}^{+\\infty}\\frac{1}{\\sqrt{2\\pi}}u^2\\exp(-\\frac{1}{2}u^2)du = \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}u^2\\exp(-\\frac{1}{2}u^2)du$.Posons: $t = \\frac{u^2}{2}$ ut = udu\\(\\begin{aligned}V(U) &amp;amp;= \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}2t\\exp(-t)\\frac{dt}{\\sqrt{2t}}\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\int^{+\\infty}_{0}t^{\\frac{1}{2}}\\exp(-t)dt\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\Gamma(\\frac{3}{2})\\\\&amp;amp;= \\frac{2}{\\sqrt{\\pi}}\\frac{1}{2}\\Gamma(\\frac{1}{2})\\end{aligned}\\)Donc $V(U) = \\frac{1}{\\sqrt{\\pi}}\\sqrt{\\pi} = 1$Moments de la loi normale centree reduiteSoit $U$ une variable normale centree reduite, on appelle moment d‚Äôordre $k$ de $U$: $u_k = E(U^k)$ Si $k = 2p + 1$ alors $u_{2p+1} = 0$ (car fonction impaire) Si $k = 2p$ alors $u_{2p} = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{+\\infty}u^{2p}\\exp(-\\frac{1}{2}u^2)du = \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_{0}u^{2p}\\exp(-\\frac{1}{2}u^2)du$Posons: $t= \\frac{u^2}{2}$ $dt=udu$\\(\\begin{aligned}u_{2p} &amp;amp;= \\frac{2}{\\sqrt{2\\pi}}\\int^{+\\infty}_0(2t)^p\\exp(-t)\\frac{dt}{\\sqrt{2\\pi}}\\\\&amp;amp;=\\frac{2^p}{\\sqrt{\\pi}}\\int^{+\\infty}_0t^{p-\\frac{1}{2}}\\exp(-t)dt\\\\&amp;amp;=\\frac{2^p}{\\sqrt{\\pi}}\\Gamma(p + \\frac{1}{2})\\end{aligned}\\)Or $\\Gamma(p+\\frac{1}{2})=\\frac{1.3.5‚Ä¶(2p-1)}{2^p}$ et $\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}$Donc $u_{2p}=1.3.5‚Ä¶..(2p-1) = \\frac{(2p)!}{2^pp!}$Fonctions caracteristiquesDefinition la fonction caract√©ristique d‚Äôune variable al√©atoire r√©elle $X$ est la transform√©e de Fourier de sa loi de probabilit√©. elle est not√©e $\\phi_x(t)$ et on a $\\phi_x=E(\\exp(itX))$ ($i$ complexe)Si $X$ est une variable a densite ($X$ est une VA continue de densite $f$) alors:\\(\\phi_X(t)=\\int_{\\mathbb R}\\exp(itx)f(x)dx\\)Si $X$ est une variable discr√®te alors sa fonction caract√©ristique est:\\[\\phi_X(t) = \\sum_k\\exp(itk)P(X = k)\\]Proprietes $\\phi_{\\lambda X} = \\phi_X(\\lambda t)$ $\\forall \\lambda$ un scalaire $\\phi_{X+a}(t) = \\exp(ita)\\phi_X(t)$ Si $X$ est une variable aleatoire d‚Äôesperance et d‚Äôecrat-type $\\sigma$ et $U = \\frac{X-m}{\\sigma}$\\[\\phi_{\\frac{X-m}{\\sigma}}(t) = \\phi_U(T) = \\exp(-\\frac{itm}{\\sigma})\\phi_X(\\frac{t}{\\sigma})\\]Remarquela fonction caract√©ristique se pr√™te bien aux additions de variables al√©atoires ind√©pendantes :Si $X$ et $Y$ sont deux variables al√©atoires ind√©pendantes alors\\[\\phi_{X+Y}(t)=\\phi_X(t)\\phi_Y(t)\\]En effet $\\phi_{X+Y}(t) = E(\\exp(it(X+Y))) = E(\\exp(itX)\\exp(itY))$Or $X$ et $Y$ sont ind√©pendantes $E(\\exp(itX)\\exp(itY)) = E(\\exp(itX))E(\\exp(itY))$Donc $\\phi_{X+Y}(t) = \\phi_X(t)\\phi_Y(t)$PropositionSoit $X$ une variable al√©atoire de fonction de r√©partition $\\phi_X(t)$.On a: $\\phi_X(0) = 1$ $\\frac{d^k\\phi_X}{dt^k}(0) = \\phi_X^{(k)}(0) = i^kE(X^k)$DemoSupposons que $X$ est une variable continue de densit√© $f$On a $\\phi_X(t)=\\int_{\\mathbb R}\\exp(itx)f(x)\\Rightarrow\\phi_X(0) = \\int_{\\mathbb R}f(x)dx=1$ (car $f$ est une densit√©)En derivant $\\phi_X(t)$ par rapport a t: $\\phi_x‚Äô(t)=i\\int_{\\mathbb R}x\\exp(itx)f(x)dx$ Si $t=0$, $\\phi_X‚Äô(0) = i\\int_{\\mathbb R}xf(x)dx=iE(X)$Si on d√©rive 2 fois, $\\phi_X^{(2)}(t)=\\int_{\\mathbb R}(ix)^2\\exp(itx)f(x)dx$ Pour $t = 0$, $\\phi_X^{(2)}(0) = (i)^2\\int_{\\mathbb R}x^2f(x)dx = -\\int_{\\mathbb R}x^2f(x)dx=-E(X^2)$En d√©rivant $k$ fois par rapport √† $t$: $\\phi_x^{(k)}(t)=\\int_{\\mathbb R}(ix)^k\\exp(itx)f(x)dx$ $\\phi_X^{(k)}(0) = (i^k)\\int_{\\mathbb R}x^kf(x)dx = i^kE(X^k)$ $\\forall k\\in\\mathbb N$Formule de Mac-Laurin Si $\\phi_X(t)$ est ind√©finiment d√©rivable on a:\\(\\phi_x(t) = \\sum^{+\\infty}_{k=0}\\frac{t^k}{k!}i^kE(X^k)\\)Exemple 1Soit X une variable al√©atoire continue de densit√©:\\(\\begin{cases} f(x) = \\exp(-x) &amp;amp;\\text{si } x\\gt0\\\\ f(x) = 0 &amp;amp;\\text{sinon}\\end{cases}\\)Determiner la fonction caracteristique de $X$ Solution On a \\(\\begin{aligned}\\phi_X(t)&amp;amp;=\\int_{\\mathbb R}\\exp(itx)f(x)dx=\\int_{0}^{+\\infty}\\exp(itx)\\exp(-x)dx = \\int_{0}^{+\\infty}\\exp(-(1-it)x)dx\\\\&amp;amp;= \\int_{0}^{+\\infty}\\exp(-(1-it)x)dx = \\biggr[\\frac{-\\exp(-(1-it)x)}{(1-it)}\\biggr]^{+\\infty}_{0} = \\frac{1}{1-it}\\end{aligned}\\) car $\\exp(-(1-it)x) = \\exp(-x)\\exp(itx)\\to 0$ lorsque $x\\to +\\infty$Puisque $\\exp(itx)$ est bornee de module 1 et $\\exp(-x)\\to 0$ quand $x\\to +\\infty$Exemple 2D√©terminer la fonction caract√©ristique de la loi de Bernoulli de param√®tre $p$ Solution Soit X une variable de Bernoulli : $X=1$ avec la probabilite $p$ $X=0$ avec la probabilit√© $1-p$ $X$ √©tant discr√®te, donc sa fonction caract√©ristique est:\\(\\phi_X(t)\\sum_k\\exp(itk)P(X=k) = \\sum_{k=0}^1\\exp(itk)P(X=k)=P(X=0)+\\exp(it)P(X=1)\\\\\\phi_X(t) = 1 - p + p\\exp(it) = q + p\\exp(it) \\text{avec } q =1 - p\\)Convergence des suites de variables aleatoires Une suite $X_n$ de variables al√©atoires √©tant une suite de fonctions il existe diverses fa√ßons de d√©finir la convergence de $X_n$ dont certaines jouent un grand r√¥le en statistiques.Convergence en probabiliteDefinition La suite $X_n$ converge en probabilit√© vers une variable al√©atoire $X$Si $\\forall\\varepsilon\\gt0, \\eta\\gt 0$ ( arbitrairement petits) il existe un entier $n_0$ tel que\\[\\forall n\\gt n_o \\Rightarrow P(\\vert X_n-X\\vert\\gt\\varepsilon)\\lt\\eta\\] C‚Äôest-√†-dire $P(\\vert X_n-X\\vert\\gt\\varepsilon)\\to_{n\\to+\\infty}0$ On notera $(X_n)\\to^PX$ In√©galit√© de Bienaym√©-Tchebychev:\\[P(\\vert X - E(X)\\vert\\gt\\varepsilon)\\lt\\frac{V(X)}{\\varepsilon^2} \\text{ , } \\forall\\varepsilon\\gt 0\\]RemarqueLorsque $E(X_n)\\to_{n\\to+\\infty}0$, il suffit de montrer que $V(X_n)\\to_{n\\to+\\infty} 0$ pour √©tablir la convergence en probabilit√© de la suite $(X_n)$ vers a.En effet d‚Äôapr√®s Tchebychev:\\(P(\\vert X_n-E(X_n)\\vert\\gt\\varepsilon)\\lt\\frac{V(X_n)}{\\varepsilon^2}\\to 0\\)Donc en passant a la limite:\\[\\lim_{n\\to+\\infty}P(\\vert X_n - a\\vert\\gt\\varepsilon) = 0\\\\ \\forall\\varepsilon\\gt0\\]Convergence en moyenne quadratiqueOn suppose que $E(\\vert X_n-X\\vert^2)$ existe.Definition On dit qu‚Äôune suite de variables al√©atoires $(X_n)$ converge en moyenne quadratique vers une variable X si\\[E(\\vert X_n-X\\vert^2)\\to_{n\\to+\\infty}0\\] On notera $(X_n)\\to^{m.q}X$Convergence en loiDefinition La suite $(X_n)$ converge en loi vers la variable $X$ de fonction de r√©partition $F$ si en tout point de continuit√© de $F$ la suite $(F_n)$ des fonctions de r√©partition des $(X_n)$ converge vers $F$, c‚Äôest-√†-dire $\\lim_{n\\to+\\infty}F_n(x)=F(x)$ pour tout x point de continuit√© de F On noter $X_n\\to^LX$RemarquePour les variables discr√®tes, la convergence en loi est √©quivalente √†\\[\\lim_{n\\to+\\infty}P(X_n=k) = P(X=k)\\]TheoremeSi la suite des fonctions caract√©ristiques $\\phi_{x_n}(T)$ converge vers $\\phi_X(t)$ alors $(X_n)\\to^LX$Applications - Convergence en loi de la binomiale vers la loi NormaleTh√©or√®me (Moivre-laplace) Soit $(X_n)$ une suite de variables binomiales $B(n,p)$Alors $\\frac{X_n - np}{\\sqrt{npq}}\\to^LN(0,1)$ lorsque $n\\to+\\infty$DemonstrationLa fonction caract√©ristique de la loi $B(n,p)$ est:\\[\\begin{aligned} \\phi_{X_n}(t) &amp;amp;= (p\\exp(it)+1-p)^n \\text{ donc celle de } Y_n=\\frac{X_n-np}{\\sqrt{npq}} \\text{ est:}\\\\ \\phi_{Y_n} &amp;amp;=(p\\exp(\\frac{it}{\\sqrt{npq}})+1-p)^n\\exp(-\\frac{itnp}{\\sqrt{npq}})\\\\ Ln(\\phi_{Y_n}(t)) &amp;amp;= nLn(p(\\exp(\\frac{it}{\\sqrt{npq}})-1)+1) - \\frac{itnp}{\\sqrt{npq}}\\end{aligned}\\]On rappelle le d√©veloppement limit√© de l‚Äôexponentielle √† l‚Äôordre 2: $\\exp(x) \\approx 1+x+\\frac{x^2}{2}$ (au voisinage de 0)\\[Ln(\\phi_{Y_n}(t)) \\approx nLn(p(\\frac{it}{\\sqrt{npq}} - \\frac{t^2}{2npq})+1)-\\frac{itnp}{\\sqrt{npq}}\\]On rappelle $Ln(1+x)\\approx x - \\frac{x^2}{2}$ (au voisinage de 0)Donc:\\[\\begin{aligned}Ln(\\phi_{Y_n}(t))&amp;amp;\\approx n[\\frac{pit}{\\sqrt{npq}}-\\frac{pt^2}{2npq}+\\frac{p^2t^2}{2npq}]-\\frac{itnp}{\\sqrt{npq}}\\\\&amp;amp;\\approx -\\frac{t^2}{2q} + \\frac{pt^2}{2q} = \\frac{t^2}{2q}(p-1)=-\\frac{t^2}{2}\\end{aligned}\\]En composant par l‚Äôexponentielle:\\[Ln(\\phi_{Y_n}(t))\\approx\\exp(-\\frac{t^2}{2}) \\text{ caract√©ristique de la loi normale } N(0,1)\\]Conclusion: $\\frac{X_n-np}{\\sqrt{npq}}\\to^LN(0,1)$Remarque Lorsque $n$ est assez grand on peut donc approximer la loi Binomiale par la loi normale. On donne g√©n√©ralement comme condition $np$ et $nq\\gt5$Il convient cependant d‚Äôeffectuer la correction de continuit√© : on obtient donc une valeur approch√©e de $P(X=x)$ par la surface sous la courbe de densit√© de la loi normale $N(np,\\sqrt{npq})$ comprise entre les droites d‚Äôabscisse $x-\\frac{1}{2}$ et $x+\\frac{1}{2}$\\[P(X=x)\\approx P(x-\\frac{1}{2}\\lt X\\lt x+\\frac{1}{2}) = P(\\frac{x-\\frac{1}{2}-np}{\\sqrt{npq}}\\lt\\frac{X-np}{\\sqrt{npq}}\\lt\\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}})\\]Et $P(X\\le x)\\approx P(\\frac{X-np}{\\sqrt{npq}}\\lt\\frac{x+\\frac{1}{2}-np}{\\sqrt{npq}})$" }, { "title": "ISIM: Rendu photorealiste 2", "url": "/cours/posts/isim_rendu_photorealiste_2/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-22 11:00:00 +0100", "snippet": "Lien de la note HackmdLa RadiositeOn essaye d‚Äôestimer la ‚Äúradiosite‚Äù de chaque element de la scene, c‚Äôest a dire la quantite d‚Äôenergie de chaque element emet‚Ä¶ $B_i$ la radiosite de la surface $i$ $E_i$ la quantite de lumiere emise par la surface $i$ $P_i$ la fraction de lumiere incidente qui est reflechie par la surface $i$ $F_{ij}$ la fraction de lumiere quittant la surface $i$ et atteignant la surface $j$\\[B_i = E_i + P_i\\sum_i(F_{ij}B_j)\\]Calcul des $F_{ij}$ par hemi-cubesOn projet un triangle, la partie bleue est la projection de ce triangle. Cela nous donne le niveau d‚Äôenergie recue par ‚Äúpetits carres‚Äù. Ne permet pas directement de calculer une vue de la scene mais simplement l‚Äôillumination globale Avantages: Prend mieux en compte les sources secondaires Calculee une fois pour toutes Inconvenients Tient compte de la diffusion Assez lourd Obligation d‚Äôavoir un maillage (il faut discretiser les surfaces) Objets transparents ? Photon map Pre-calcul de l‚Äôillumination de la scene Lancement des rayons lumineux depuis les sources et calcul des accumulations des photons Avantages: Permet de modeliser plus proprement les sources secondaires, les ombres portees (‚Ä¶) et surtout les objets transparents (caustiques) Faire des ombres correctes sous les objets transparents Inconvenients Calculs Complexite Penible a coder Resultats: video manquante :(Ameliorations: Projection Maps Visual importance map (3-pass Technique) Shadow photons ‚Ä¶Path Tracing/Bidirectional Path Tracing Modelisation des proprietes de reflexion des surfaces: (Bidirectional reflectance distribution function BRDF) (idem pour la transmission) Si on a une surface et qu‚Äôon lance un laser, qu‚Äôelle est l‚Äôenergie ressortante en fonction de l‚Äôangle d‚Äôincidence? Solution pour resoudre l‚Äôillumination BRDF: Biderectional reflectance distribution function (Reflectivite bidirectionnelle)Conservative:\\(\\int f_r(x,\\theta,\\theta_o)L_{input}(x, \\theta_i)\\vert\\theta_i.N_x\\vert\\delta w_0\\le 1\\)Reciprocite de Helmholtz:\\(f_r(x, \\theta_i, \\theta_o) = f_r(x,\\theta_o^{-1}, \\theta_i^{-1})\\) Mesuree Goniophotometer ‚Ä¶ Modele Blinn-Phong Cook-Torrance GGX ‚Ä¶ Principe du rendu:Path Tracing Avantages: Rendu realiste Convient bien aux scenes d‚Äôexterieurs Prend bien en compte l‚Äôapport des autres objets Rend les caustiques Possibilite de modeliser les effets (profondeur de champ‚Ä¶) Inconvenients: len bruite (Il faut bcp d‚Äôiterations pour converger) difficile pour scenes avec des petites sources lumineuse (ou sources cachees) Bidirection Path Tracing Amelioration du calcul du rendu Lancement des rayons depuis l‚Äôobservateur et depuis les sources Avantages: Facilite la recherche du chemin vers la source lumineuse Permet de modeliser les petites sources lumineusesPBGI: Point-Based Global Illumination Tres peu enseigne Beaucoup utilise dans l‚Äôindustrie du cinema Monster Academy: 1er long-metrage en raytracing La-haut: utiliser PBGI SFX de Pirates des Caraibes avec PBGI Methode pour estimer l‚Äôillumination globales Avantages: Rapide Image non bruitee (pas d‚Äôartefacts temporel) Inconvenients Pas aussi precis que le raytracing Difficile de gerer les effets miroir Approximation de la scene par nuage de points Un point - un disque de couleur Calcul de l‚Äôillumination direct de la scene Approximation de la scene par nuage de points Un point = un disque de couleur Calcul de l‚Äôillumination directe de la scene Regroupement des pointsCalcul de l‚Äôillumiantion globale Calcul de la contribution des points sur un disque Pour les points eloignes Utilisation du cluster Pour les points proches Raytracing Pour les autres points Utilisation directe du disque Bilan et remarquesRendusRendu simpleRendu simple avec anti-aliasingRendu avec la radiositeRendu avec les photonsRendu avec la radiosite et les photonsRendu avec anti-aliasingBilan Raytracing Calcul de l‚Äôillumination en fonction d‚Äôun point de vue Calcul l‚Äôillumination approximatif : g√®re mal les objets transparents, les lumi√®res secondaires, les ombres port√©es‚Ä¶ On peut combiner cet algorithme avec des techniques de calcul d‚Äôillumination globale pour palier √† ces probl√®mes Radiosity Calcul l‚Äôillumination globale G√®re que la diffusion mais am√©liore l‚Äôapport des lumi√®res secondaires PhotonMap Calcul l‚Äôillumination globale Plus diffcile √† mettre en √∑uvre (impl√©mentation, art√©facts‚Ä¶) G√®re bien les objets transparents (caustiques) et √©ventuellement les ombres port√©es et les sources secondaires PathTracing G√®re bien les objets transparents, les lumi√®res secondaires, les ombres port√©es Calcul tr√®s long Risque d‚Äôapparition de bruit PBGIRemarques sur l‚Äôimplementation Doit √™tre bien r√©fl√©chie Parall√©lisation possible Utilisation du GPU possible ‚Ä¶ModelisationPour chaque ‚Äúforme‚Äù il faut √™tre capable de: calculer la normale en chaque point calculer l‚Äôintersection avec une droite, √©ventuellement calculer les coordonn√©es de la textureCalcul des intersections : dans le rep√®re monde ou le rep√®reobjet ?Pour aller plus loin Textures Autres effets (Brouillard, Bleu atmosph√©rique, ‚Ä¶) ‚Ä¶ g√©n√©ration d‚Äôanaglyphes (cyan et rouge (espacement $\\frac{1}{30} ‚àó f$ ))Post scriptumRaycasting Principe: On ne lance que les rayons depuis l‚Äôobservateur et on ne calculpas les rebonds‚Ä¶(Raytracing est une extension du raycasting ?)Wolfstein: On lance des rayons dans le plan!La longueur du rayon permet de conclure sur la hauteur du mur 1 rayon donne 1 colonne de l‚Äôimage + gestion des objetsAvanatages: Algorithme rapide On est loin du rendu photor√©aliste‚Ä¶" }, { "title": "TIFO: Codage, partie 2 - Histogramme", "url": "/cours/posts/tifo_codage_partie2/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8", "date": "2021-02-19 10:00:00 +0100", "snippet": "Lien de la note HackmdAnalyse globale de l‚ÄôimageHistogramme Recense les occurrences de chaque couleur Donne une information globale sur l‚Äôimage Permet la realisation de petits traitement globaux Peut etre calcule sur une image en couleur Calcul de l‚Äôhistogramme Code:histogramme: tableau initalise a 0image: l&#39;image sour forme d&#39;un vecteurfor (offset = 0; offset &amp;lt; sx*sy; ++offset) histogramme[image[offset]]++Quels information peut apport l‚Äôhistogramme Si une image est sur-exposee Si une image est sous-exposee Si une image manque de contrasteApplicationsAmelioration du contrasteApplication: modification du contraste a l‚Äôaide de l‚ÄôhistogrammeCorrection de l‚Äôhistogramme: Etirement $[min, max] \\to [0, \\text{borne_sup}]$ Fonction de correction: $f(x) = ax + b$ $a = \\frac{b_{sup} - b_{inf}}{max - min}$ $b = b_{inf} - ax$ Generalement $b_{inf} = 0$ Etirement du resultat J‚Äôai bien augmente le contraste J‚Äôai detruit une partie de l‚Äôinformation On a sature des pixels, effacant des details Amelioration de l‚ÄôimageApplication: modification du contraste a l‚Äôaide de l‚Äôhistogrammeimage: l&#39;image sous forme d&#39;un vecteurfor (offset = 0; offset &amp;lt; sx*sy; ++offset) image[offset] = f(image[offset])Tout depend du choix de f Fonction $\\log$ si $x\\neq 0$, $f(x)=\\frac{\\ln(x)}{\\ln{max}}*max$ si $x=0$, $f(x) = 0$ L‚Äôintervalle des zones sombres est augmentee Fonction $\\exp$ L‚Äôintervalle des zones claires est augmentee L‚Äôimage est assombrie Attention aux plages de valeurs (exp(255)‚Ä¶) Modification des couleurs de l‚ÄôimageApplication: calcul du negatif Fonction de correction: $f(x) = b_{sup} - x$Amelioration du contrasteApplication: amelioration du contraste a l‚Äôaide de l‚Äôhistogramme cumule Calcul de l‚Äôhistogramme cumule\\(\\begin{cases} hc(x) = hc(x-1) + h(x) &amp;amp;\\text{pour } x\\gt 0\\\\ hc(x) = h(x) &amp;amp;\\text{pour } x = 0\\end{cases}\\) Essayer d‚Äôuniformiser la repartition des niveaux de gris dans l‚Äôhistogramme Cela revient a essayer de rendre l‚Äôhistogramme cumule lineaire $f(x) = b_{sup} * \\frac{hc(x)}{nb_{pix}}$ Resultat:Histogramme et images couleurs Differentes manieres de calculer Globale Par plan Traitements: Independamment sur chaque canal Changement d‚Äôespace et traitement uniquement dans le plan L ou V ApplicationsAmelioration du contraste Egalisation d‚Äôhistogramme de couleur Effectuer l‚Äôegalisation sur chaque canal ? Donne de mauvais resultats en general (modification des couleurs) Solution: Changer d‚Äôespace de representation Utilisation de HSV ? Egalisation uniquement sur la valeur Amelioration de l‚ÄôimageSpecification d‚Äôhistogramme Imposer la forme de l‚Äôhistogramme (comme pour l‚Äôegalisation qui donne un histogramme plat) Indexation Distance entre histogrammes Comparaison d‚Äôimages Segmentation automatique en plan de sequences Difference entre images consecutives Distances Bin-by-bin distances Distances de Hellinger Bhattacharyya ‚Ä¶ Cross-bin distances Earth Mover‚Äôs Distance ‚Ä¶ Diminution du nombre de couleurs Pourquoi diminuer le nombre de couleurs? Simplifier l‚Äôimage Diminuer l‚Äôespace necessaire de stockage Focaliser sur les elements qui nous interessent Effet artisitique Pourquoi plus precsiement passer de la couleur aux niveaux de gris ? Traitement de la couleur pas toujours aisee Plusieurs canaux Pas vraiment de relation d‚Äôordre utilisable avec la couleur Pourquoi plus precisement passer en noir et blanc ? Focaliser sur les elements qui nous interessent Separation fond/forme (O.C.R., ‚Ä¶) Objectif Reduire le nombre de couleurs utilisees tout en conservant le plus possible une image proche de l‚ÄôoriginaleAlgorithme Mediane cut Basee sur l‚Äôetude de l‚Äôhistogramme Diffusion de l‚Äôerreur Adoucit certaines erreurs pour la visualisation Median cut algorithm Reduction du nombre de couleurs Construction de l‚Äôhistogramme des couleurs Elimination des extremites vides Decoupage du prallelepipede restant en 2 sous-blocs contenant autant de points Pour chaque sous bloc, recommencer jusqu‚Äôa avoir autant de sous blocs que de couleurs souhaitees Trouver pour chaque partie, une couleur representante Diffusion de l‚ÄôerreurLe but est de compenser l‚Äôerreur commise sur un pixel en propageant cette erreur sur les pixels voisins\\(\\text{FloydSteinberg:}\\\\\\begin{matrix} 12 &amp;amp; 15 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\)Ex: on fait une erreur en substituant le 12 par son representant, on propage la difference entre 12 et son representant sur son voisin 15 On remplace la couleur du pixel considere par le representant\\(\\text{FloydSteinberg:}\\\\\\begin{matrix} &amp;amp; 15 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\)\\(\\begin{matrix} &amp;amp; 21 &amp;amp; 18 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 67 &amp;amp; 25 &amp;amp; 26 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}\\) On calcul l‚Äôerreur commise par cette substitution en faisant la difference entre la vraie couleur et la couleur de remplacement: on trouve une erreur pour chaque canal.\\(+6\\) On repartie l‚Äôerreur estimee sur les pixels voisins Les voisins en haut et a droite participent plus que les voisins en diagonales ¬† $X$ $-7$ ‚Ä¶ $-3$ $-5$ $-1$ ‚Ä¶ \\[\\text{FloydSteinberg:}\\\\\\underline{\\begin{matrix} &amp;amp; 21 &amp;amp; 11 &amp;amp; 67 &amp;amp; 68 &amp;amp; ...\\\\ 64 &amp;amp; 20 &amp;amp; 25 &amp;amp; 57 &amp;amp; 89 &amp;amp; ...\\\\\\end{matrix}}\\] Ce dernier tableau etait recommande par FloydSteinberg pour la propagation de l‚Äôerreur. ¬† X 7/16 3/16 5/16 1/16 Resultats:Passage en noir et blanc (binarisation)Binarisation: Separation fond/formeSeuil global: Utilisation de l‚Äôhistograme On suppose l‚Äôhistogramme bi-modal (1 mod pour le fond et 1 pour la forme) Trouver le niveau de gris a la jonction entre les 2 Seuil global - resultats:Seuil global - un algorithme simple: Supposons un seuil T initial Calculons les moyennes m1 et m2 des ensembles des pixels d‚Äôintensite inferieure a T et superieur ou egale a T respectivement Corriger T avec $T = \\frac{m_1 + m_2}{2}$ Si $T \\gt \\Delta T$ continuer en 2Seuil global - Le critere d‚ÄôOtsu On cherche 2 classes Minimiser la variance intra-classe Maximisier la variance inter-classe $m_1(k)$ et $m_2(k)$ les moyennes des 2 classes formees par le seuil k $m_g$ la moyenne $p_1(k)$ et $p_2(k)$ les probabilites d‚Äôoccurrence des 2 classes formees par le seuil k Maximiser la variance inter-classe: $\\sigma(k)^2=P_1(k)(m_1(k)-m_g)^2 + P_2(k)(m_2(k)-m_g)^2$ Or $P_1(k)m_1(k) + P_2(k)m_2(k) = m_g$ et $P_1(k) + P_2(k) = 1$ $\\sigma(k)^2 = P_1(k)P_2(k)(m_1(k) - m_2(k))^2 = \\frac{(m_gP_1(k)-m_1(k))^2}{P_1(k)(1-P_1(k))}$ Reviens a chercher le k dans l‚Äôintervale ou $P_1(k)(1-P_1(k))\\neq 0$ rel que $\\sigma(k)^2$ est le maximum (si plusieurs max, faire la moyenne) Seuil global Rapide et simple Se calcul directement sur l‚Äôhisotgramme Dans la pratique pas toujours efficace selon le contexte ResultatsOriginal:Otsu:" }, { "title": "TIFO: Codage, partie 1 - couleurs et representations", "url": "/cours/posts/tifo_codage_partie1/", "categories": "Image S8, TIFO", "tags": "Image, TIFO, S8", "date": "2021-02-19 09:00:00 +0100", "snippet": "Lien de la note HackmdCodage des couleursLe modele RGB/RVBEspace RGB/RVB (Red-Green-Blue) One code une couleur par un triplet representant la quantite de rouge, de vert et bleu de la couleur Une couleur est un point du cube: L‚Äôorigine du repere $(0,0,0)$: le noir L‚Äôopposee: $(1,1,1)$ le blanc Chaque axe code une couleur primaire (R,G,B) Decomposition d‚Äôune image suivant les 3 axes:Sur une image reelle: Le modele RGB Modele base sur la perception humaine (couleurs primaires en synthese additive) Pas toujours intuitif pour selectionner une couleur Tres repandu Le model HLSL‚Äôespace HLS (Hue, Lightness, Saturation) On code une couleur par 3 composantes: teinte, luminance et saturation. L‚Äôespace ressemble a 2 cones que l‚Äôon a joint par leurs bases. Une couleur est un point de cet espace Teinte C‚Äôest l‚Äôangle sur le disque $0^o$ rouge $60^o$ jaune $120^o$ vert $180^o$ cyan $240^o$ bleu $300^o$ magenta Luminance La luminance est la hauteur dans le cone Saturation La saturation (‚Äúpurete de la couleur‚Äù) est la distance au centre du disque Decomposition suivant les 3 axes:Sur une image reelle:La saturation J‚Äôai un p‚Äôtit singe ici: Modele intuitif pour ‚Äúchoisir une couleur‚Äù. L‚Äôutilisation de la teinte est interessante toutefois, sur des saturations faibles, la teinte n‚Äôa plus vraiment de signification Beaucoup de variantes (HSV‚Ä¶)Le modele YMCA CMYL‚Äôespace CMY (couleurs primaires en syntese soustractive) Mieux adpate pour les peripheriques d‚Äôimpression Beaucoup de variantes En image on l‚Äôutilise quasiment jamais.Codage d‚Äôun niveau de grisComment coder un niveau de gris ? Une seule composante qui code la luminance Une convention possible: Composante nulle $\\rightarrow$ pas de lumiere (noir) Composante au maximum $\\rightarrow$ maximum de lumiere (blanc) Un niveau de gris quelconque = un point de l‚Äôaxe: Autres espacesIl existe d‚Äôautres espaces de representation YIQ NTSC 1953 Facilite la transmission et la compatibilite de l‚Äôimage tant pour un ecran couleur que un ecran noir et blanc Y donne la luminance Lab La distance entre 2 couleurs dans cet espace est representative de la difference percue visuellement entre les 2 couleurs XYZ YCbCr ‚Ä¶Conversions entre espaces de couleursRGB $\\leftrightarrow$ HLS H$[0^o, 360^o]$ L$[0,1]$ S$[0,1]$ Teinte Estime en fonction de 2 bornes min et max Pour L $\\le 0,5$ Saturation Joue sur l‚Äôecartement min $\\leftrightarrow$ max sur la teinte Si S $=0$, min $=$ max $=$ L Donc max $=$ ($1$ + S)L et min $=$ ($1$ - S)L Pour L $\\ge 0,5$ Meme raisonnment RGB $\\leftrightarrow$ YIQLe passage de l‚Äôun a l‚Äôautre est simple:\\[\\begin{pmatrix} Y\\\\ I\\\\ Q\\end{pmatrix}=\\begin{pmatrix} 0.30 &amp;amp; 0.59 &amp;amp; 0.11\\\\ 0.60 &amp;amp; -0.28 &amp;amp; -0.32\\\\ 0.21 &amp;amp; -0.52 &amp;amp; 0.31\\end{pmatrix}\\begin{pmatrix} R\\\\ G\\\\ B\\end{pmatrix}\\]RGB $\\leftrightarrow$ CMY Les couleurs primaires de l‚Äôespaces CMY sont les couleurs complementaires des couleurs primaires de l‚Äôespace RGB La conversion est donc simple: $R = 1 - C$ $G = 1 - M$ $B = 1 - Y$ RGB $\\leftrightarrow$ niveaux de gris Idee simple et intuitive: $L = (r + v + b)/3$ Amelioration $L = 0.299r + 0,587v + 0,114b$ Pourquoi la premiere idee est-elle fausse ? Car nos yeux percoivent certaines couleurs mieux que d‚Äôautres (cf. la seconde formule) Peut-on faire l‚Äôinverse (passer du niveau de gris a la couleur ?) Non bien-sur: projection, on passe d‚Äôun image 3D a 2D, on a perdu de l‚Äôinfo Avec des regles on peut se donner une colorisation de l‚Äôespace (teinte sepia, vert comme une camera de surveillance, etc.) mais on ne retrouvera pas la couleur d‚Äôorigine RGB $\\leftrightarrow$ noir et blanc Est-il possible de passer a une image noir et blanc ? Utile pour traiter les images ‚Äútrop‚Äù riches On binarise l‚Äôimage Qu‚Äôest-ce qu‚Äôon veut extraire de l‚Äôimage ? Y a t il un interet a passer a une image en noir et blanc ?Codage des couleursIl existe differents espaces pour la representation des couleurs Il faut etre capable de choisir le bon, en fonction de l‚Äôobjectif recherche Etre capable, dans la mesure du possible de passer de l‚Äôun a l‚ÄôautreCodage de l‚ÄôimageRepresentation d‚Äôune image couleurCodage d‚Äôune image par une matrice: L‚Äôimage est une fonction discrete 2D, elle est souvent codee par une matric Pour une image codee en RGB, un point de l‚Äôimage = un triplet (r,g,b) de valeurs dans la matrics Un point de l‚Äôimage = un pixel. Que signifie pixel ? Picture element Representation d‚Äôune image en niveaux de grisCodage d‚Äôune image par une matrice: L‚Äôimage est une fonction discrete 2D, elle est souvent codee par une matrice Pour une image codee en niveaux de gris, un point de l‚Äôimage = une valeur dans la matrice codant la luminanceAcces aux pixels Comment coder cette image en memoire ? Matrice ? Vecteur ? Comment acceder a un point de cette image ? Comment acceder a ses voisins ? Comment parcourir l‚Äôimage ?for (i = 0; i &amp;lt; sx; i++) for (j = 0; j &amp;lt; sy; j++) offset = i + j * sxfor (j = 0; i &amp;lt; sy; j++) for (i = 0; j &amp;lt; sx; i++) offset = i + j * sxfor (offset = 0; offset &amp;lt; sx * sy; ++offset) Utiliser un iterateur ?Resolution/Echantillonage Discretisation spatiale (resolution) Echantillonage (amplitude)Nombre de couleurs - EchantillonnageCodage par palette (couleurs indexees) Bit(s) par pixel Couleurs 1 bpp ??? 2 bpp ??? 4 bpp ??? 6 bpp ??? 8 bpp ??? Codage sans palette Bits par pixel Couleurs Bits par canaux 16 bpp ? ? 24 bpp ? ? 32 bpp ? ? Representation de l‚ÄôimageUn moyen classique de representer une image est d‚Äôutiliser une matrice. Y a t il d‚Äôautres approches ? Arbres (max tree, min tree, tree of shape) Graphes ‚Ä¶Maillage On choisit intuitivement un maillage carre mais cela peut-il presenter des inconvenients ? Y a t il d‚Äôautres maillages possibles ?TopologieChoix de la connexite des pixels4-connexe: Voisins en haut, en bas, a gauche, a droite Pas lies aux voisins en diagonale Plusieurs regions8-connexe: Une seule region Cela pose un probleme de topologie: Si le fond est 8-connexe (en noir), la forme (en blanc) est 4-connexe Si le fond est 4-connexe (en noir), la forme (en blanc) est 8-connexe Contradiciton avec le theoreme de Jordan Que faire ? Vivre avec Changer la forme de pixels Intercaler des frontieres entre les pixels ‚Ä¶ Changer la forme de pixels:Codage en memoire:Pour: Plus de probleme de connexite Plus de probleme de distance Tout le monde est a la meme distance Contre: Gestion de la memoire Inteprete chaque ligne de la matrice comme ayant un decalage offset Intercaler des frontieres entre les pixelsLes frontieres sont determinees par les inter-pixelsExemple d‚Äôarbre: Max treeA chaque fois qu‚Äôon a 2 regions qui se separent, on cree des branchesStockage/Transfer Differents formats: JPEG, TIFF, PNM, PNG, BMP, GIF, TGA Choix en fonction de criteres Avec ou sans compression (avec ou sans perte) Avec ou sans couleur Avec ou sans palette Une seule image ou plusieurs Optimise pour une architecture ? (Ex. BMP sauvegarde a l‚Äôenvers) Libre ou pas (Ex. GIF et Compuserve) Exemple Format PNM PBM: noir et blanc PGM: niveaux de gris PPM: couleurs 2 variantes PNM TGA Format tres simple (extrait de spec)Application On a vu pas mal de choses sur la formation d‚Äôune image On va l‚Äôappliquer en changeant les couleurs ou l‚Äôillumination d‚Äôune image en changeant l‚Äôorganisation spatiale des pixels de l‚Äôimage en combinant des changements dans le couleurs et dans l‚Äôorganisation spatiale des pixels Changement d‚ÄôilluminationEn tous points de la scene, la reponse du capteur est donne par:$L(x,y) = \\int E(x,y,\\lambda)S(x,y,\\lambda)R(\\lambda)d\\lambda$ Avec $E(x,y)$ l‚Äôeclairage $S(x,y,\\lambda)$ la reflectance de la surface (fonction de la longueur d‚Äôonde $\\lambda$) $R(\\lambda)$ la sensitivite du capteur qui (pour simplifier est supposse repondre a une seule longueur d‚Äôonde: $R(\\lambda) = \\sigma(\\lambda-\\lambda_k)$)On a donc: $L(x,y) = E(x,y)S(x,y,\\lambda_k)$ La meme image prise avec 2 niveaux d‚Äôilluminations differents: $L1(x,y) = E_1(x,y)S(x,y,\\lambda_k)$ $L2(x,y) = E_2(x,y)S(x,y,\\lambda_k)$Donc: $L2(x,y) = (E_2(x,y)/E_1(x,y))*L1(x,y)$Et donc: $L2(x,y)=C*L1(x,y)$ Pour changer l‚Äôillumination il faut donc multiplier les valeurs des pixels par une constante (et non additionner/soustraire par une constante comme c‚Äôest usuellement fait)Correction d‚Äôillumination non uniforme Soit une image acquise $I_1$ avec un eclairage non uniforme $I_1(x,y)=S(x,y,\\lambda_k)E(x,y)$ Soit l‚Äôimage du fond $I_f$ $I_f(x,y)=F(x,y,\\lambda_k)E(x,y)$La soustraction des deux donne:\\(I_1(x,y)-I_f(x,y) = [S(x,y,\\lambda_k)-F(x,y,\\lambda_k)]E(x,y)\\)Le ratio des 2 donne:\\(\\frac{I_1(x,y)}{I_f(x,y)} = \\frac{S(x,y,\\lambda_k)}{F(x,y,\\lambda_k)}\\)Difference vs RatioModification des couleurs de l‚Äôimage Application : effet artistique $\\rightarrow$ effet sepia On associe a un niveau de luminance une couleur \\[\\begin{pmatrix} r\\\\ g\\\\ b\\end{pmatrix}=\\begin{pmatrix} 0,784 &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0,588 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0,391\\end{pmatrix}\\begin{pmatrix} l\\\\ l\\\\ l\\end{pmatrix}\\]Resultat:Modification de l‚Äôorganisation spatiale des pixelsApplication: effets artistiques $\\text{image_resultat}(x,y) = \\text{image_origin}(g(x,y), h(x,y))$ Les fonctions $g$ et $h$ ne tiennent pas forcement compte de la valeur du pixel Rotation - cisaillement Etirement - retrecissement Ondulations Spirale Tranlations aleatoires ‚Ä¶ La 2e image c‚Äôest quand on me chatouille le cou $\\text{image_resultat}(x,y) = \\text{image_origin}(g(x,y), h(x,y))$La transformation doit etre appliquee dans ce sens !Application: le morphing d‚ÄôimagesModification des couleurs et de l‚Äôorganisation spatiale des pixels Application: le morhping Vu la structure d‚Äôune image, il est possible d‚Äôappliquer des operateurs sur ces images Exemple: la moyenne En combinant Une moyenne ponderee des images (dont les poids evoluent au cours du temps) Un champ de vecteur de translation Problemes de precision Sur les fonctions colorimetriques Sur les transformations spatialesLa correction gammaRetour sur la perception La perception de l‚Äôoeil est logarithmique La repartition des niveaux d‚Äôenergie n‚Äôest donc pas lineaire mais exponentielle Tous les calculs fait jusqu‚Äôa present sont completement faux car 50% du signal n‚Äôest pas a la moitie du niveau de gris (128) mais a 186.\\(r = \\frac{number}{255}^{gamma}\\\\gamma = 2.2\\) Les niveaux de gris ne sont que des numeros, faire des operations (moyenne, addition, application de filtres, interpolation‚Ä¶) n‚Äôa pas vraiment de sens Dans la pratique, on omet souvent la correction gamma lors des etapes de filtrages C‚Äôest faux Il y a un compromis entre precision du resultat et vitesseRetour sur le passage de la couleur en niveuax de gris Espace CIE XYZ 1931 $R‚Äô= r/255 V‚Äô = v/255 B‚Äô = b/255$ $Rsrvb = [(R‚Äô+0.055)/1.055]^{2.4}$ $Vsrvb = [(V‚Äô+0.055)/1.055]^{2.4}$ $Bsrvb = [(B‚Äô+0.055)/1.055]^{2.4}$ \\(\\begin{pmatrix} X\\\\ Y\\\\ Z\\end{pmatrix}=\\begin{pmatrix} 0,4124 &amp;amp; 0,3576 &amp;amp; 0,1805\\\\ 0,2126 &amp;amp; 0,7152 &amp;amp; 0,0722\\\\ 0,0193 &amp;amp; 0,1192 &amp;amp; 0,9505\\end{pmatrix}\\begin{pmatrix} Rsrvb\\\\ Vsrvb\\\\ Bsrvb\\end{pmatrix}\\) $Y$ donne la luminanceL‚Äôinterpolation Que faire lorsque l‚Äôon doit ‚Äúchercher‚Äù la valeur d‚Äôun pixel mais que l‚Äôon ne tombe pas precisement sur un pixel ? 1er solution (rapide): prendre la du pixel le plus proche 2nd solution: Faire une interpolation bi-lineaire Peut-on faire mieux ? Interpolation bicubique Utilise 4 points (calcul de la derivee) Interpolation bicubique\\[f(x) = ax^3+bx^2+cx+d\\\\f&#39;(x)=3ax^2+2bx+c\\]On connait les valeurs pour $x=-1$, $x=0$, $x=1$ et $x=2$\\(f(-1)=p0, f(0)=p1 \\text{ et } f(2)=p3\\\\f&#39;(0)=(p2-p0)/2 \\text{ et } f&#39;(1)=(p3=p1)/2\\)Mais aussi\\(f(0) = d\\\\f(1) = a+b+c+d\\)\\[f&#39;(0) = c\\\\f&#39;(1) = 3a+2b+c\\]On peut donc en conclure que les coefficients a,b,c,d du ploynome et donc interpoler les valeurs intermediaires du signal entre 0 et 1.Artefact:Autres interpolation Il existe d‚Äôautres methodes d‚Äôinterpolation Pour faire le choix de l‚Äôinterpolation, il faut faire un compromis entre vitess et qualiteConclusion Codage de l‚Äôimage et de la couleur Espaces de couleurs, passage d‚Äôun espace a l‚Äôautre Applications Effet sepia Transformation artistiques Morphing Correction gamma Interpolation" }, { "title": "DEVI: Presentation", "url": "/cours/posts/devi_presentation/", "categories": "Image S8, DEVI", "tags": "Image, DEVI, S8", "date": "2021-02-18 13:00:00 +0100", "snippet": "Lien de la note HackmdJoseph Chazalon, Clement DemoulinsFebruary 2021EPITA Research &amp;amp; Development Laboratory (LRDE)About this courseThis is a course about containers using Docker What it is How to use it for simple, then less simple cases PracticeTools an gradingGraded content for each sessions using Moodle For sessions 1 and 2: 10 min quiz on Moodle at the end of each sessionSoftware stack illustratedA real case of 2 incompatible software stacks we had to handleMany solutions Use libs with forward/backwared compatibility FIx bad dependency declarations in packages Use lnagugae compatibility layer Rebuild stuff manually Install various versions of libs at different placesDependency hellWhen you have to rebuild manually, step by step, all your software stack checking each dependencyWhat are you paid for ?Waht you really want is simply to separate: your development &amp;amp; product software stack your os &amp;amp; userland software stackAnd what about deployement ?Deployement challengeSolutions Containers Beaucoup plus leger Demarrage presque immediat Virtual Machines Emuler le systeme d‚Äôexploitation Devoir reserver RAM, CPU, etc. On peut avoir plusieurs VMs sur une meme machine Containers and virtual machines are 2 good solutions to software stack isolation have similar resource isolation and allocation benefits(CPU, mem, net &amp;amp; disk IO) but function differently because containers virtualize the OS (the kernel) instead of hardware so containers are lighter and faster than VMs (min storage) more portable less secure DockerPromises lightweight easy deployementBenefits for devBuild once‚Ä¶ run anywhere portable runtime env no worries about missing dependencies run each app in its own isolated container Automate testing, integration, packagingBefenits for adminConfigure once‚Ä¶ run anything Make the entire lifecycle more efficient, consistent and repeatable Increase the quality of codeDocker adoption Docker was launched in 2013 (8 years ago) and became a massive trend. Github project search ‚Äúdocker‚Äù $\\rightarrow$ $\\gt$ 45 000 projectsReasons for NOT using (Docker) containers (currently) Archive your program (because it is not made for that) Your program uses OSX primitives Your program runs on Windows only You need to deploy many containers on clustersDemo1: VSCode Remote ContainerImplementation of Docker ContainersUnder the hood, Docker is built on the following components: The Go programming language The following features of the Linux kernel Namespaces groups capabilities NamespacesAccording to man namespaces: A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that hey have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes. One use of namespaces is to implement containers.CgroupsAccording to man cgroups Control groups, usually referred to as cgroups, are a Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored. The kernel‚Äôs cgroup interface is provided through a pseudo-filesystem called cgroupfs. Grouping is implemented in the core cgroup kernel code, while resource tracking and limits are implemented in a set of per-resource-type subsystems (memory, CPU, and so on).CapabilitesAccording to man capabilities: Traditional UNIX implementations distinguish two categories of processes: privileged processes (whose effective user ID is 0, referred to as superuser or root), and unprivileged processes (whose effective UID is nonzero). Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the process‚Äôs credentials (usu ally: effective UID, effective GID, and supplementary group list). Starting with kernel 2.2, Linux divides the privileges traditionally associated with superuser into distinct units, known as capabilities, which can be independently enabled and disabled. Capabilities are a per-thread attribute.Open Container Initiative runtime (container) specificationsContainer configuration, lifecycle, and how to rpx them using JSON files. creating the container is being created created the runtime has finished the create operation, and the container process has neither exited nor executed the user-specified program running the container process has executed the user-specified program but has not exited stoppedOpen Container Initiative image specificationsAn image stores the files for the root FS of a container, ie the files or containerized program will seeProblem(s) Many containers share the same basis (Ubuntum Alpine, Debian, etc.) because we do not want to rebuild a complete software stajc by hand down to the kernelSolution: Split images into meaningful layers Ubuntu base, Python dependencies, App‚Ä¶ Share common layers between containers in read-only Add a thin writable layer on top of this stack of layers View this stack as a single, consistent and writable filesystemImage LayersEfficiency implemented using Copy-on-Write (COW)Open Container Initiative distribution specificationsAPI protocol to facilitate distribution of images: What is a repository How to list, pull, push images HTTP APIImages and containersWhen using Dokcer, you think about images and containersGood to remember A (Docker) container is just: a root filesystem with some bind mounts containing all the software stack down to the kernel a control policy enforced by the kernel with some isolation mechanisms: PID, network, etc. some environment variables, kernel configuration and automatically generated file: for hostname, DNS resolution, etc. an abstract view of a group of processes not even a single kernel object Using DockerRegular workflow Obtain an image docker image pull USER/IMAGENAME:TAGdocker image import ARCHIVEdocker image build ... Create a container for image docker container create --name CONTAINER_NAME IMAGE Start the container docker container start CONTAINER_NAME (opt.) execute more programs within the container docker container exec CONTAINER_NAME Attach your console to the container docker container manage/monitor the containerContainer storage explainedStorage overviewWhere is Docker data stored ?Under var/lib/dockerBase image contentBind mountsVolumesWhat Shareable space management by Docker Can bes used to share data between container Create using docker volume create VOLNAME or --volume or --mount type=volume on start/run Survive container removal: must be removed manuallyWhere Stored under /var/lib/docker/volumes/+ name or unique idReusing volumes for another containerIt is possible to mount volumes from another container.This can be convenient in several cases: get a shell in a super minimal container migrate a database upgrade a containerFragile isolation with host Relies on kernel security You can share a lot of things with host Many public images run services as root" }, { "title": "ISIM: Rendu photorealiste", "url": "/cours/posts/isim_rendu_photorealiste/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-18 11:00:00 +0100", "snippet": "Lien de la note HackmdRendu photorealiste Objectif Generation d‚Äôimages realistes Contrainte de temps faible Strategies: Object-based rendering algorithms Illumination globale calculee independamment du point de vue Image-based rendering algorithms Illumination calculee partiellement, en fonction du point de vue Deterministic rendering algorithms Monte Carlo rendering algorithms Les algorithmes qu‚Äôon va voir: Raytracing Path Tracing et Bidirectional Path Tracing ‚Ä¶ Radiosity Photon map ‚Ä¶Formation de l‚ÄôimageCapture de l‚Äôimage:Modele stenope:Capture de l‚Äôimage (capteur CCD, CMOS)Dans notre cas nous pouvons faire passer des rayons avec differentes longueurs d‚Äôonde par le meme point On peut facilement modeliser la camera Il faut reussir a modeliser l‚Äôeclairage Idee: ‚Äúsuivre‚Äù les rayons lumineux pour trouver le chemin parcouru depuis la source jusqu‚Äôa l‚Äôoeil Principe: Lancer une ‚Äúinfinite‚Äù de rayons depuis la source pour esperer trouver ceux qui frappent l‚Äôoeil de l‚Äôobservateur C‚Äôest tres lourd!Raytracing Historique 68, Appel (du raycasting?) 80, Whitted (ajoute les effets optiques: reflexion, transparence‚Ä¶) Principe Idee de base: Difficile de suivre tous les rayons partant de la source en revanche il est possible d‚Äôestimer le chemin inverse Faire le chemin inverse pour trouver les objets ‚Äúvus‚Äù Pour chaque objet vu, on peut estimer une approximation de l‚Äôeclairage local Approximation de 2 types de contributions: la partie diffuse la partie speculaire Calcul de l‚Äôillumination locale: Composante diffuse Composante speculaire Apport des sources primaires Apport des sources secondaires Sources primaires: Lumieres ponctuelles Spots Lumieres directionnelles Objets lumineux Sources secondaires: Les autres objets eclaires Modele local:La composante diffuse La propriete de diffusion de la surface est $k_d$ La couleur de la surface est $C$Voila ce que ca donne: ‚ÄúMais vous avez triche monsieur il y a des ombres !‚Äù C‚Äôest faux, il faut regarder l‚Äôeffet de degrade: c‚Äôest la lumiere diffusante.La composante speculaire La propriete de reflexion de la surface est $k_s$ L‚Äôintensite de la lumiere depend de l‚Äôangle fait par $S$ et $L$On a en resultat: La lumiere est blanche donc on a un reflet blanc sur les objets.Il y a un coefficient de brillance, la tache speculaire est plus ou moins piquee (ex: la lumiere dans les yeux des gens) Les ‚Äú$k_d$‚Äù incluent la couleur Il faut sommer toutes les sources lumineuse $i$‚Ä¶ Resultat: Encore une fois je triche comme un arracheur de dent car je n‚Äôai pas explique comment avoir l‚Äôombre, normalement ca devrait etre le degrade du bleu.Est-ce qu‚Äôon peut affiner ce modele ? On peut ajouter un coeff d‚Äôattenuation $f(d)$ ($d$ $\\rightarrow$ distance) Estimer que ce n‚Äôest pas un rayon qui repart mais un cone $f(d) = 1/d$ $f(d) = 1/d^2$ $f(d) = 1/(d + k)$ ‚Ä¶ Quel modele de couleur prendre ?Une synthese additive RVB.AlgorithmeEtape 1: Prise en compte des sources primairesPour l‚Äôensemble des points de l‚Äô‚Äòimage: Calculer le vecteur directeur du rayon lumineux $v$ partant de l‚Äôobservateur Chercher les intersections de ce rayon lumineux avec l‚Äôintegralite des objets de la scene et garder le plus proche Calculer le niveau d‚Äôeclairement au point d‚Äôintersection en sommant l‚Äôapport diffus et speculaire pour chaque source lumineuse Problemes: Ne tient pas compte des sources lumineuses secondaire Ne gere pas les ombres Prise en compte des sources secondaires:On ne considere pas tous les points de toutes les surfaces de l‚Äôespace, par contre on va aller explorer la direction du rayon rebondissant sur la table.Pour y arriver, on calcule l‚Äôillumination au point sur la table, rien nous empeche de ‚Äúrelancer‚Äù un rayon et voir quel objet on intersecte. Une fois qu‚Äôon l‚Äôintersecte, on calcul l‚Äôillumination au point. C‚Äôest du cast ray. La reponse ‚Äúlancer plus de rayon‚Äù ca fonctionne.Etape 2: Prise en compte des sources primaitres et certaines sources secondairePour l‚Äôensemble des points de l‚Äôimage: Calculer le vecteur directeur du rayon lumineux $v$ partant de l‚Äôobservateur Chercher les intersections de ce rayon lumineux avec l‚Äôintegralite des objets de la scene et garder le plus proche Relancer un rayon dans la direction de $S$ puis calculer le niveau d‚Äôeclairement recursivement Calculer le niveau d‚Äôeclairement au point d‚Äôintersection en sommant l‚Äôapport diffus et speculaire pour chaque source lumineuse ainsi que l‚Äôeclairement dans la direction de $S$Etape 3: Prise en compte de l‚ÄôombrePour l‚Äôensemble des rayons que l‚Äôon ‚Äúlance‚Äù vers les sources primaires, il faut chercher si un objet de la scene ne s‚Äôest pas insere entre le point considere et la source. Pour cela, il faut a nouveau calculer l‚Äôintersection du rayon avec l‚Äôensemble des objets de la scene et prendre le plus proche.Resultats Je triche plus (ou quasiment plus) Je triche j‚Äôai pas du tout parle de texture et d‚Äôanti-aliasing L‚Äôalgorithme du raytracing est un processus simple, recursif Il faut etre capable, pour chaque objet, de calculer la normale en chaque point Il faut reflechir a la condition d‚Äôarret Avantages Algorithme simple et rapide a mettre en oeuvre Genere des images honorables ‚Ä¶Inconvenients Temps de calcul un peu eleve Pas de gestion de la profondeur de champ et autres effets Mauvaise gestion des ombres (frontieres trop brutales) Sources secondaire pas suffisamment prises en compte (eclairage indirect incorrect) Objets transparents ‚ÄúAlisaing‚Äù ‚Ä¶Les problemes du RaytracingProbleme de l‚Äôaliasing Probleme: si on lance un rayon c‚Äôest touche ou pas touche alors que ca devrait etre la proportion de chaque.On risque aussi de louper les petits objets.Solution On lance plus de rayons (cast ray)! Sur-echantillonage Lancer plusieurs rayons pour chaque pixel De maniere organisee Au hasard Lancer plusieurs rayons pour chaque pixel ou le gradient est eleve Bon resultats mais peut etre tres lent Post-filtrage Resultat moyen mais tres rapide ResultatsAvec anti-alisaing sur toute l‚Äôimage (50 rays/pixel)temps: de l‚Äôordre de 7-8 secondesAnti-aliasing sur les zones de gradient eleve (50 rays/pixel)Temps: l‚Äôordre de la secondeProbleme du temps de calcul On lance plus de rayons (cast ray)!Solutions: Volumes englobants Projection sur un plan/partition de l‚Äôespace Pre-trier les objets? Calcul parallele Utilisation d‚ÄôOpenGL ‚Ä¶Probleme des objets transparentsSolutions: Comme nous avons relance le rayon reflechi, il faut ‚Äúsuivre‚Äù le rayon refracte Loi de la refraction Tenir compte du rayon refracte pour l‚Äôillumination locale: $I=I_d+I_s+I_s+k_tT$Milieux transparents: Loi de la refraction (Snell Descartes): $n_1\\sin i_1 = n_2\\sin i_2$Surfaces translucides: Distribution probabilisteCalcul de l‚Äôombre Solution approchee:Ne pas devier le rayon mais filtrer les longueurs d‚ÄôondesProbleme de l‚Äôeclairage indirectSi on va sous notre bureau, d‚Äôapres nos calculs il devrait faire totalement noir alors que ce n‚Äôest pas le cas avec l‚Äôeclairage indirect.Solution Ajouter une lumiere ambiante: $I=k_a*I_a+I_d+I_r+I_t$ Solution vraiment approximativeResultats:Probleme de l‚ÄôombreOn lance un rayon pour savoir si on est eclaire mais ca donne une reponse binaire, c‚Äôest comme considerer la source comme ponctuelle. Notre source lumineuse n‚Äôest pas ponctuelle.Quel est la proportion de notre source ?Comment faire pour avoir des ombres plus douces ?Solution Cast ray ! Ne plus considerer une lumiere comme ponctuelle Probleme de temps de calcul BilanAvantages Algorithme tres simple Donne des images honorablesDes problemes majeurs persistent Les sources secondaires ne sont pas suffisamment bien geres Les objets transparents non plusAmelioration Raytracing distrubue (84) Sur-echantillonnage pour simuler les ombres douces la profondeur de champ ‚Ä¶ Ne regle pas le probleme de l‚Äôapport de la diffusion des sources secondaires Quantite de calcul enorme Conclusion Algorithme simple Necessite beaucoup d‚Äôameliorations pour avoir des images photorealistes" }, { "title": "ISIM: Rappels", "url": "/cours/posts/isim_rappels/", "categories": "Image S8, ISIM", "tags": "Image, ISIM, S8", "date": "2021-02-18 09:00:00 +0100", "snippet": "Lien de la note HackmdOptique et image Pour synthetiser une image, il faut comprendre comme celle-ci se forme et est capturee.Dans ce cas: Table Observateur (cam) Source lumineuse rayons se propagent dans toutes les directions eclaire la table la table renvoie la lumiere qui est captee par l‚Äôobservateur $\\rightarrow$ source lumineuse secondaire L‚Äôobservateur ne peut pas faire de difference entre un objet qui emet de la lumiere et un objet qui le renvoieQu‚Äôen est-il de la couleur ?Quelles sont les couleurs primaires ? RGB RJBComment ca se fait que je vois la nape bleue ?Dans les rayons lumineux il y a des longueurs d‚Äôondes.La table filtre les longueurs d‚Äôonde et renvoie les rayons qui correspondent au bleu.2 systemes: Source primaire: rajoute des couleurs RVB couleurs primaires $\\Rightarrow$ sysnthese additive Objets qui renvoient la lumiere et en absorbe une partie: enleve de la couleur CMJ (Cyan, Magenta, Jaune) complementaire aux couleurs primaires $\\Rightarrow$ sysnthese soustractive Capture de l‚ÄôimageDans un appareil photo/oeil/camera: Chambre noire Pellicule/capteurs photosensibles transforme la lumiere recue en energie transforme la lumiere recue en teinte (ancien appareils photos) Point image image envoyee Foyer selectionne les rayons lumineux Plan image image recue a l‚Äôenvers Caracteristiques Zoomer ou dezoomer En augmentant ou reduisant la distance focale Zoomer: reduire le champ de vision (grande distance focale) Dezoomer: augmenter le champ de vue (petite distance focale) Ouvrir ou fermer le diaphragme Si ouvre Plus de foyer unique Image devient flou On reduit la zone de nettete Plus on ouvre le diaphragme, plus on reduit la profonder de champ Si reduit le diaphragme Plus de profondeur de champ Moins de lumiere Varier la taille de diaphragme Peut etre une contrainte Rendre l‚Äôarriere-plan flou Jouer avec dans les images de synthese Le foyer doit etre avant le plan image IRL, mais en virtuel il peut etre apres (cf. schema).Comment capturer l‚Äôimage en pratique Dans l‚Äôappareil photo: matrice de capteurs photosensibles qui generent de l‚Äôenergie quand ils sont frappes.Image en niveau de gris: Pour la couleur, pour chaque capteur photosensibles on met des filtres (ex: capturer que les longueurs d‚Äôonde qui capturent le vert).Probleme: on connait l‚Äôintensite en tout point mais pas pour toutes les longueurs d‚Äôonde, il faut la deduire via les voisins. C‚Äôest le patterne de Bayer.Pourquoi ces couleurs ? C‚Äôest les couleurs primaires RVB. Pourquoi RVB?Pourquoi plus de vert ? Lie a la perception humaine, nos yeux sont plus sensibles au vert/jaune.Pour un capteur virtuel, pour chacune des cellules on peut mesurer toutes les longueurs d‚Äôondes pour RVB.Formation de l‚Äôimage Les longeurs d‚Äôonde du spectre visible est une plage tres etroite.Pourquoi les couleurs primaires sont RVB ?On a des capteurs dans nos yeux pour RVB.Pourquoi on peut reconstituer toutes les couleurs a partir de RVB? Si par exemple on voit une couleur jaune, nos capteurs vert et rouge sont stimules. Dans les couleurs possibles il n‚Äôy a pas de blanc, ca arrive quand on stimule tous les capteurs en meme temps. De meme pour le magenta, qui arrive quand uniquement le cone vert n‚Äôest pas stimule. Certaines couleurs n‚Äôexistent pas, notre oeil nous donne une representation.Codage de la couleurModele RGB One code une couleur par la quantite de rouge, de vert et de bleu que contient cette couleur Une couleur est alors un point du cube Modele directement lie a notre perceptionLe modele RGB est directement issue de notre perception des couleurs.Generation d‚Äôune image synthetique Simuler les phenomenes optiques qui conduisent a la formation de l‚Äôimage.Geometrie Euclidienne Produit scalaire: forme ilineaire, symetrique, definie positive Espace pre-hilbertien $(E,\\vert)$ reel $E$: R-espace vectoriel $\\vert$: produit scalaire Espace euclidien Espace pre-hilbertien reel de dimension finie Espace affine $\\mathcal F$ de $E$ (e.v): $\\mathcal F$ s.e.v de $E$ Soit $A\\in E, \\forall x\\in\\mathcal F; A + x\\in\\mathcal F$ Cas particuliers: Dim 0 $\\Rightarrow$ un point Dim 1 $\\Rightarrow$ une droite affine Dim 2 $\\Rightarrow$ un plan affine Repere cartesien de $\\mathcal F : (O, B)$ avec $O$ un point de $\\mathcal F$ et $B$ une famille de vecteurs de $\\mathcal F$ formant une base de $\\mathcal F$ Soir $E$ un $\\mathbb R$-espace vectoriel, une norme $N$ sur $E$ est une application de $E$ dans $\\mathbb R$ tel que: $\\forall u\\in E, N(u) \\ge 0$ $\\forall u \\in E, N(u) = 0 \\Leftrightarrow u = 0$ $\\forall (u,\\lambda)\\in (E\\times\\mathbb R), N(\\lambda u) = \\vert\\lambda\\vert N(u)$ $\\forall(u,v)\\in E^2,N(u+v)\\le N(u)+N(v)$ Definition associee au produit scalaire: $N(u)=\\sqrt{u\\vert u}$: norme euclidienne Produit mixte: $[u,v,w] = det(u,v,w)$ $= (u\\times v).w$ Donne le volume du parallelepipede Produit vectoriel; $x;[u,v,w] = x.w(x=u\\times v)$ $\\Vert u\\times v\\Vert$ aire du rectangle $\\frac{1}{2}\\Vert u\\times v\\Vert$ aire du triangle Vecteurs et angles en euclidien Produit scalaire: $u.v=\\Vert u\\Vert\\Vert v\\Vert\\cos(u,v)$ Produit vectoriel: $u\\times v = \\Vert u\\Vert\\Vert v\\Vert\\sin(u,v)$ $u.v = 0 \\Leftrightarrow u$ et $v$ ortho $(u.v)^2 + (u\\times v)^2 = \\Vert u\\Vert^2\\Vert v\\Vert^2$ Equation de droites 2D Cartesienne: $y=ax + b$ Implicite: $ax+by+c=0$ Parametrique: $A+\\lambda\\overrightarrow v$ 3D Cartesienne Implicite Parametrique: $A+\\lambda\\overrightarrow v$ Equation d‚Äôun plan 3D Cartesienne: $ax+by+cz+d=0$ Implicite Parametrique Prendre un point du plan et donner 2 vecteurs qui vont definir une base $A+\\lambda_1\\overrightarrow v_1\\lambda_2\\overrightarrow v_2$ Equation d‚Äôun cercle/sphere 2D/3D Cartesienne: $(x-a)^2+(y-b)^2+(z-c)^2 = r^2$ Implicite Parametrique\\(\\begin{cases} x &amp;amp;= a + r\\cos(\\theta)\\sin(\\lambda)\\\\ y &amp;amp;= b + r\\sin(\\theta)\\cos(\\lambda)\\\\ z &amp;amp;= c + r\\sin(\\lambda)\\\\\\end{cases}\\) Determinant Utilite du determinant: Equation de droite passant par ($x_1$, $y_1$) et $u(a,b)$ \\(\\begin{vmatrix} x-x_1 &amp;amp; a\\\\ y-y_1 &amp;amp; b\\\\ \\end{vmatrix} = 0\\) Equation de droite passant par ($x_1$, $y_1$) et ($x_2$, $y_2$) \\(\\begin{vmatrix} x-x_1 &amp;amp; x-x_2\\\\ y-y_1 &amp;amp; y-y_2\\\\ \\end{vmatrix} = 0\\) Idem pour l‚Äôequation d‚Äôun plan dans un espace 3DIntersectionIntersection droite/plan Droite: $P+t\\overrightarrow v$ Plan: $ax+by+cz+d=0$ ou $\\overrightarrow N.\\overrightarrow X = d$ $\\overrightarrow N.(P+t\\overrightarrow v) = d$ $t_i = \\frac{d-\\overrightarrow N.P}{\\overrightarrow N\\overrightarrow v}$ Cas particulier si $d$ parallele au plan ($\\overrightarrow N\\overrightarrow v=0$) $I=P+t_i\\overrightarrow v$Intersection droite/plan $\\rightarrow$ droite\\triangle Verifier que $I$ est dans le triangle $ABC$ Exprimer $I$ en fonction de $A$, $B$ et $C$ Les coordonnees barycentriques doivent etre toutes positives Determiner les de chaque cote du triangle Determiner la position de $I$ vis a vis de chaque cote i.e $ax+by+c\\lt0$ ou $ax+by+c\\gt0$ Avec l‚Äôalgorithme de Cyrus-Beck En regardant l‚Äôorientation du sens de parcours Intersection droite/sphere Calcul de l‚Äôintersection dans le repere local ou global ? Idem que pour le plan mais avec l‚Äôequation de la sphere. 3 cas possibles: Pas de solution (pas d‚Äôintersection) Solution double (la droite touche la surface de la sphere) Deux solutions distinctes (la droite traverse la sphere) Distance point/droite $d(p, D) = \\frac{\\vert ax_p + by_p + c\\vert}{\\sqrt{(a^2 + b^2)}}$ $d(p, D) = \\frac{\\vert\\overrightarrow{AM}.\\overrightarrow n\\vert}{\\Vert n\\Vert}$ Distance point/plan $d(p,P)=\\frac{\\vert ax_p+by_p+cz_p+d\\vert}{\\sqrt{(a^2+b^2+c^2)}}$ $d(p, P) = \\frac{\\vert\\overrightarrow{AM}.\\overrightarrow n\\vert}{\\Vert n\\Vert}$ Distance droite/droite $D_i(A_i, \\overrightarrow{v_i})$ $d(D_1, D_2) = [\\overrightarrow{A_1A_2}, \\overrightarrow{v_1}, \\overrightarrow{v_1}]/\\Vert\\overrightarrow{v_1}\\overrightarrow{v_2}\\Vert$ Distance sphere/sphereGeometrie projective Geometrie euclidienne Etude des formes des ‚Äúobjets‚Äù Invariance par rotation, tranlsation, reflexion Geometrie projective Etude des objets tel qu‚Äôils sont vus Perception des angles, des distances, du parallelisme distordu Exemple avec des rails de train paralleles mais qui semblent se rejoindre au point de fuite: N‚Äôallez pas aller vous faire renverser par un trainDependant du point de vie, B est entre A et C ou A est entre B et C:Projection sur le plan image On a juste a projeter les sommets d‚Äôune faceDans l‚Äôespace, on ne prend pas l‚Äôobjet entier mais juste une face. On trace une droite qui passe par le foyer et le sommet, on note l‚Äôintersection avec le plan image ce qui nous donne sa projection.Point de fuiteSi on a une droite qu‚Äôon veut projeter sur le plan image, on prend le plan forme par la droite et le plan qui inclut le foyer de projection. Si on fait une intersection de ce plan avec le plan image, c‚Äôest exactement la projection de la droite sur le plan image en accord avec le foyer. Si on fait de meme avec d‚Äôautres droites, elle convergeraient toutes vers un meme point: la point de fuite.Horizon Intersection du plan passant par le foyer et parallele au plan objetTous les points de fuite de droites paralleles sont alignees sur le l‚ÄôhorizonPoints a l‚ÄôinfiniOn a l‚Äôensemble de droites, si on les projettent on a undividuellement l‚Äôensemble des points de la droite, avec une image et un antecedent sauf que si on prend une droit qui va suffisament loin on est parallele au plan objet. Ce sont les points a l‚Äôinfini.On a le corollere dans l‚Äôautre sens: certains points appartiennent au plan parallele au plan image et passent par le foyer, ils ne peuvent pas etre projetes sur le plan image car leur droite ne coupe jamais le plan image. On doit rajouter au plan objet et au plan image des points a l‚Äôinfini. Un ensemble de droites paralleles convergent vers ce point a l‚Äôinfini.On peut representer le plan projectif par un disque, l‚Äôensemble de paralleles est represente par une seule droite sur ce disque. Le point de fuite est le meme de chaque cote du plan image.Pour le rajouter sur le disque, on doit le ‚Äúplier‚Äù pour que les extremites se rejoignent.Coordonnees homogenesDans le plan $RP^2$ est l‚Äôensemble des triplets $[p] = [p_1, p_2, p_3]$ avec $(p1,p2,p3)$ dans $\\mathbb R^3$ prive de $(0,0,0)$ Deux points $p$ et $q$ sont egaux si et seulement si il existe un $k$ dans $R^*$ tel que: $p_1=kq_1$ et $p_2 = kq_2$ et $p_3=kq_3$ Deux cas: $p_3 = 0$, $[p_1,p_2,p_3] = [p_1,p_2,0]\\in RP^2$ $p_3 \\neq 0$, $[p_1,p_2,p_3] =[p_1/p_3,p_2/p_3,1]\\in RP^2$Pourquoi s‚Äôembeter avec cette 3e coordonnes ?Si $p_3$ est a 0, on parle des points a l‚Äôinfini. Homogenes: peut representer les points euclidiens et les points ideaux.$[a,b,0]:(a,b)$ donne la direction des points associesIdem pour une droite projective et pour l‚Äôespace 3D.Transformation usuellesRepresentation des transformations usuelles dans l‚Äôespace projectif Translation Echelle Rotation ProjectionCombinaison des transformations.Translation Euclidien: \\(P + \\begin{pmatrix} t_x\\\\ t_y\\end{pmatrix}\\) Coordonnees projective: on a une coordonnees de plus\\(\\begin{pmatrix} x + t_x\\\\ y + t_y\\\\ 1\\end{pmatrix}=\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; t_x\\\\ 0 &amp;amp; 1 &amp;amp; t_y\\\\ 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\begin{pmatrix} X\\\\ Y\\\\ 1\\end{pmatrix}\\) La translation est passe d‚Äôune addition a une multiplication matriciel.Si on passe en 3D, on a une matrice qui permet d‚Äôexpliquer la translation en 3D:\\(\\begin{pmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; t_x\\\\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; t_y\\\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; t_z\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\)Mise a l‚Äôechelle:\\(\\begin{pmatrix} S_x &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; S_y &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; S_z &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\)Rotation: Suivant un axe canonique:\\[\\begin{pmatrix} \\cos &amp;amp; -\\sin &amp;amp; 0 &amp;amp; 0\\\\ \\sin &amp;amp; \\cos &amp;amp; 0 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\] Suivant un axe quelconque:\\[\\begin{pmatrix} x^2(1 - \\cos) + \\cos &amp;amp; xy(1-\\cos)-z\\sin &amp;amp; xz(1-\\cos) + y\\sin &amp;amp; 0\\\\ yx(1 - \\cos) + z\\sin &amp;amp; y^(1-\\cos)+\\cos &amp;amp; yz(1-\\cos) - x\\sin &amp;amp; 0\\\\ xz(1 - \\cos) + y\\sin &amp;amp; yz(1-\\cos)+x\\sin &amp;amp; z^2(1-\\cos) + \\cos &amp;amp; 0\\\\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\\end{pmatrix}\\]Modelisation des rotations: L‚Äôordre des rotations compte Specifier un ordre suivant les axes $O_x$, $O_y$ et $O_z$ Specifier l‚Äôaxe de rotation Utilisation des quternions $Q=a+bi+cj+dk$ $a,b,c,d$ reels $\\rightarrow$ $a$ partie reelle et $(b,c,d)$ partie imaginaire $I^2=j^2=k^2=-1$ $i.j=k;j.k=i;k.i=j$ $j.i=-k;k.j=-i;i.k=-j$ Les quaternions unites (norme $(Q) = 1$) permettent une representation plus compacte de n‚Äôimporte qu‚Äôelle rotation Combinaisom des transformations On peut pre-calculer une matrice qui est l‚Äôensemble des transformations.Rajouter une coordonnees nous permet d‚Äôexprimer l‚Äôensemble des transfomrations sous forme d‚Äôun produit matriciel." }, { "title": "BOOM: La tranformee et Series de Fourier", "url": "/cours/posts/boom_SF_TF/", "categories": "Image S8, BOOM", "tags": "Image, BOOM, S8", "date": "2021-02-17 10:00:00 +0100", "snippet": "Lien de la note HackmdTheoreme de superpositionComment s‚Äôappelle le theoreme a l‚Äôorigine de la transformee de Fourier ?Tous les signaux peuvent etre reconstruits a partir de sinusoides. Theoreme de superposition: tous les signaux compliques sont une superposition de signaux simples.Exemples La musique Le son Les rides sur l‚Äôeau premier signal decompose de cette maniere: la lumiere blanche somme de toutes les longueurs d‚Äôondes des differentes couleurs on a tous les memes recepteurs en theorie, on est + ou - sensibles en pratique Being discrete but looking continuousInside some audio file:Partie rouge: la note de musique qu‚Äôon entend depuis le debut du cours: abscisses: frequence ordonnee: hauteurSampling the real world Physical phenomena are continous by nature (light, sound pressure, temperature, current, voltage, etc) and must somehow be discretized in order to be digitally handled and stored on computers. Theoreme de Shannon: pour echantilloner sans pertes, on doit echantilloner a une frequence 2x superieure a celle du signal.Quand on echantillone un son, on veut avoir le meme son que dans la vraie vie mais on veut pas un fichier de 3To. Le but d‚Äôechantillonage est de trouver le meilleur echantillonage possible pour reconstruire un son mais pas avoir un fichier enorme. Fourier: trouver la frequence fondamentale d‚Äôun signal.Pas assez precis $\\rightarrow$ sous echantillonageTrop precis $\\rightarrow$ sur echantillonageHow fast is a signal varying ?Consider the sample signal $x(t) = A_0\\cos(2\\pi f_0t)$ On parle de serie de Fourier et transformee de Fourier, repectivement pour les signaux periodiques purs et les autres. Decomposition en serie de Fourier: trouver les coefficients pour decomposer un signal periodique.Phenomene de Gibbs Au niveau des discontinuites d‚Äôun signal: l‚Äôapproximation oscille beaucoup, c‚Äôest un effet de bord lors des transformees et series de Fourier.Decomposition en Series de Fourier (SF)Exemple Offset: amplitude moyenne du signal ($A_0$)On va prendre une premiere sinusoide, regarder l‚Äôerreur par rapport au signal d‚Äôorigine et recommencer jusqu‚Äôa avoir le signal voulu.$b_N$: coefficient des series de Fourier associes au sinus$a_N$: coefficient associes aux cosinusDans ce cas il n‚Äôy a que des $b_N$ car on a que des sinus. Dans le cas d‚Äôune fonction paire ?Que des coefficients $b_N$ Dans le cas d‚Äôune fonction impaire ?Que des coefficients $a_N$Avec l‚Äôoffset notre fonction $\\widetilde{f}(t)$ n‚Äôest ni paire ni impaire. Pour savoir si une fonction est paire ou impaire, on la centre sur l‚Äôaxe des abcisses (on lui enleve sa moyenne). Nos sinus ont une periodicite $\\frac{n}{T}$Definition $T \\equiv$ periode $f = \\frac{1}{T} \\equiv$ frequence $nf = n \\times \\frac{1}{T} \\equiv$ harmonique de rang $n$ \\(x(t) = a_0 + \\sum^{+\\infty}_{n = 1} \\biggr(a_n\\cos(2\\pi\\frac{n}{T}t) + b_n\\sin(2\\pi\\frac{n}{T}t) \\biggr)\\)en tout point de continuite de $x\\in \\mathcal{C}^1$ par morceaux d‚Äôapres le theoreme de DIRICHLET. $a_0 =$ moyenne sur une periode $= \\biggr(\\int_0^Tx(t)dt\\biggr)\\times\\frac{1}{T} \\equiv$ offset $(\\big\\updownarrow)$ \\[\\forall n \\ge 1 \\begin{cases}a_n &amp;amp;= \\frac{2}{T}\\int^T_0x(t)\\cos(2\\pi\\frac{n}{T}t)dt\\\\b_n &amp;amp;= \\frac{2}{T}\\int^T_0x(t)\\sin(2\\pi\\frac{n}{T}t)dt\\end{cases}\\] Phenomene de GibbsSi $x$ est discontinu en $t$, la serie converge vers $\\frac{1}{2}(x(t^-)+x(t^+))$. $\\Delta(x(t_0)) = \\vert x(t_0^-) - x(t_0^+)\\vert \\Rightarrow$ le sursaut en $x(t_0^-)$ et $x(t_0^+)$de la somme partielle $S_n(t)$ est de l‚Äôordre de $0,09\\Delta x(t_0)$Proprietes Si $x$ est pair, $b_n = 0 \\forall n \\in \\mathbb{N}^*$ Si $x$ est impair, $a_n = 0 \\forall n \\in \\mathbb{N}^*$$\\Rightarrow$ parite ‚Äúmodulo l‚Äôoffset‚ÄùVive les nombres complexes ! \\(x(t)=\\underbrace{a_0+\\sum^{+\\infty}_{n=1}\\biggr(a_n\\cos(2\\pi\\frac{n}{T}t) + b_n\\sin(2\\pi\\frac{n}{T}t)\\biggr)}_{\\text{coeffs reels}} = \\underbrace{\\sum^{+\\infty}_{n=-\\infty}C_ne^{i2\\pi\\frac{n}{T}t}}_{\\text{coeffs complexes}}\\)\\(\\forall n \\in\\mathbb{Z}, C_n = \\frac{1}{T}\\int^T_0x(t)e^{-i2\\pi\\frac{n}{T}t}\\) ${\\vert C_n\\vert, n\\in\\mathbb{Z}}$ s‚Äôappelle le spectre du signal. $\\forall n \\ge 1, C_n = \\overline{C_{-n}}$Egalite de Parseval L‚Äôenergie d‚Äôun signal est ce qui va caracteriser le signal, elle sera conservee entre temporel et frequenciel. \\(\\frac{1}{T}\\int^T_0\\vert x(t)\\vert^2dt = \\sum^{+\\infty}_{n = -\\infty}\\vert C_n\\vert^2 = a_0^2 + \\frac{1}{2}\\sum^{+\\infty}_{n=1}(a_n^2+b_n^2)\\)Transformee de Fourier (TF)Definition\\(\\begin{aligned}X:\\mathbb{R} &amp;amp;\\to \\mathbb{C}\\\\\\nu&amp;amp;\\mapsto\\int_{\\mathbb{R}}x(t)e^{-i2\\pi\\nu t}dt\\end{aligned}\\)\\(\\begin{aligned}\\nu&amp;amp;\\equiv\\text{ frequence}\\\\ &amp;amp;\\equiv\\frac{n}{T}\\end{aligned}\\) Tansformee de Fourier (TF pour les intimes) $\\equiv$ decomposition en serie de Fourier ou les harmoniques varient de maniere continueTF inverse\\(x(t)=\\int_{\\mathbb{R}}X(\\nu)e^{+i2\\pi\\nu t}d\\nu\\)Proprietes de la TF $x$ est reel et pair $\\Leftrightarrow X$ reel et pair $x$ est reel et impair $\\Leftrightarrow X$ imaginaire pur et impair \\[\\begin{aligned}X(\\nu) &amp;amp;= \\Re e (X(\\nu)) + i\\Im m(X(\\nu))\\\\ &amp;amp;= \\vert \\underbrace{X}_{\\text{module}}(\\nu)\\vert e ^{i\\underbrace{\\phi}_{\\text{phase}}(X(\\nu))}\\end{aligned}\\] spectre $= \\vert X(\\nu)\\vert\\equiv$ l‚Äôamplitude des frequences dans $x$ phase $\\equiv$ position des frequences dans le signalTheoreme de Plancherel \\(\\mathcal{F}(x*y) = \\mathcal{F}(x) \\times \\mathcal{F}(y)\\\\\\mathcal{F}(x\\times y) = \\mathcal{F}(x) * \\mathcal{F}(y)\\)$z = x\\times y \\Rightarrow Z(\\nu) = X(\\nu)Y(\\nu)$$x* y = \\mathcal{F}^{-1}(X(\\nu)\\times Y(\\nu))$Dirac \\(\\delta(t)\\begin{cases} = 0 &amp;amp;\\text{si } t \\neq 0\\\\ =+\\infty &amp;amp; \\text{si } t = 0\\end{cases}\\text{et}\\int_{\\mathbb{R}}\\delta(t)dt = 1\\)Peigne de Dirac\\(\\begin{aligned}–®_T : \\mathbb{R} &amp;amp;\\to \\mathbb{R}\\\\t &amp;amp;\\mapsto \\sum_{n\\in\\mathbb{Z}}\\delta(t-nT)\\end{aligned}\\) Signal echantillonne: $x_e(t) = x(t) \\times –®_{Te}(t)$$\\Rightarrow$ Theoreme de Shannon: $\\nu e \\ge 2\\nu_{max}$ (pour eviter la perte d‚Äôinformation)" }, { "title": "BOOM: La correlation et la convolution", "url": "/cours/posts/boom_correlation_convolution/", "categories": "Image S8, BOOM", "tags": "Image, BOOM, S8", "date": "2021-02-15 10:00:00 +0100", "snippet": "Lien de la note Hackmd Les TD et TP ne sont pas notes et ont des corrections (a la fin de la semaine).Typical reaction of an average EPITA students when he discovered that this cours was about the Fourier transform L‚Äôordi d‚ÄôElodie crash ? ‚ÄúMath√©matiques du ‚Äúpas de signal‚Äù‚ÄùPiqure de rappelOn a entendu une magnifique note de piano puis une note de piano bruitee.On va regarder les signaux:Lequel est bruite et lequel n‚Äôest pas bruite ? Resultat: celui de gauche. Oscillations rapides: hautes frequences.Le signal de gauche c‚Äôest notre signal + un autre signal qui oscille tres vite. Le but c‚Äôest de reperer quelles frequencer enlever. Filtrage de signal: selection de certaines frequences ou suppression d‚Äôautres. Comme les chercheurs d‚Äôor: on met le sable dans le tamis et on tamise, les mailles laisse passer le sable et garde les pepites.Dans ce cas, on supprime les hautes frequences (en theorie).D‚Äôou peut venir le bruit ?Peut etre lie au capteur, s‚Äôapplique aussi en Image, on a besoin de connaitre les bruits pour les enlever.En pratique, toujours une petite correlation. Quand on parle de mathematiques de signaux, on l‚Äôapplique aussi a l‚Äôimage car c‚Äôest un signal en 2D; le traitement d‚Äôimage est une sous-partie du traitement du signal. Les bibliotheques utilisees en python n‚Äôont pas toutes la meme representation de l‚Äôimage. Certaines bibliotheques transforment l‚Äôimage en 1D et d‚Äôautres en 2D. Convolution en 1D sur du signal est + ou - la meme en 2D sur les images.A droite: transformee de Fourier du signal classique et a gauche signal bruite.On a un ‚Äúpate‚Äù en bas. Si on zoom:Les signauxQu‚Äôest-ce qu‚Äôun signal ? Quelque chose qui evolue au cours du temps, qu‚Äôon peut mesurer (ex: la temperature; la mesure reguliere la transforme en signal, un electrocardiogramme‚Ä¶).Un flux d‚Äôelectron qu‚Äôon va mesurer.L‚Äôimage Une image est aussi un signal car il y a une mesure: la mesure du nombres de photons qui arrivent. Les images en noir et blanc n‚Äôexiste pas, ce sont des photos en niveaux de gris.Prendre une photo avec un telephone: on a un capteur et plus un photon tape a un endroit plus le pixel sera blanc. Plus on laisse le capteur ‚Äúouvert‚Äù, plus on capte de photons et l‚Äôimage sera plus net.Le signalA quoi ca sert ?Verifier les risques d‚Äôincendie (temperature + humidite), le rechauffement climatique, etc. Les signaux sont utiles pour les statistiquesExemple: le radar Ne pas toucher a cette fenetre !Cas parfait: signal continu.On envoie un signal et on compte le temps que ca prend pour revenir. Attention aux variations avec l‚Äôair, l‚Äôeau, le vide, etc.Les chauves-souris le font ‚Äúautomatiqument‚Äù mais attention a l‚Äôeffet Dopler: si une mouche bouge, la frequence renvoyee est modifiee.Premier problemeNotre chauve-souris envoie un signal continu mais nos ordis ont pas une memoire infinie et le signal risque d‚Äôavoir du bruit a cause du capteur, numerisation, etc On passe d‚Äôun monde analogique a numerique et il risque d‚Äôy avoir de la perte d‚Äôinformation $\\rightarrow$ problemes d‚Äôeffets de bords.Cas reelOn recupere un signal decale et bruite.Les outils pour traiter ce signal: la correlation L‚Äôensemble des signaux forment un espace vectoriel. La ressemblance = la correlation La norme = la distanceLa ressemblance est max quand ?Quand on a une superposition des deux signaux. On va ‚Äúglisser‚Äù le signal de gauche sur celui de droite et calculer la ressemblance, cad la correlation ou une integrale (l‚Äôaire sous la courbe des 2 signaux).Quand on va faire, on ne va pas avoir la correlation maximale theorique. Dans la correlation: L‚Äôauto-correlation Entre 2 signaux $x$ et $x$ Entre le meme signal sans aucune modification Nous sert a definir l‚Äôespace des calculs qu‚Äôon va faire L‚Äôinter-correlation Entre 2 signaux $x$ et $y$ Dans ce cas c‚Äôest l‚Äôinter-correlation.Notre correlation est maximale en $-5$ car on a un decalage de $-5s$Recap sur le bruitPourquoi on arrive quand meme a retrouver notre signal de base ? La correlation entre le signal et le bruit est nulle car le bruit est non-correle.La correlationDefinition\\(\\Gamma_{xx}(\\tau) = \\int_{\\mathbb{R}}x(t)\\overline{x(t-\\tau)}dt = &amp;lt;x(t),x(t-\\tau)&amp;gt;\\)$\\Gamma_{xx}(0)$ est maximale car il n‚Äôy a pas de decalage\\[\\begin{aligned}&amp;amp;= &amp;lt;x(t), x(t)&amp;gt;\\\\&amp;amp;= \\int_{\\mathbb{R}}|x(t)|^2\\\\&amp;amp;= ||x(t)||^2 = \\text{ENERGIE du signal}\\end{aligned}\\]Proprietes Dans le cas des signaux reels, si $x$ est reel, l‚Äôauto-correlation est paire: $\\Gamma_{xx}(-\\tau) = \\Gamma_{xx}(\\tau)$ Inter-correlation:\\(\\Gamma_{xy}(\\tau) = \\int_{\\mathbb{R}}x(t)\\overline{y(t-\\tau)}dt = &amp;lt;x(t),y(t-\\tau)&amp;gt;\\) C‚Äôest la formule qu‚Äôon utilisera.L‚Äôinter-correlation est nulle si les signaux ne s‚Äôintersectent pas. On prend un signal, on le fait glisser sur un autre et on calcul la multiplication des aires sous la courbes de l‚Äôintersection des 2.Cas du radarOn envoie $x(t)$ et on recupere $y = x(t-t_0) + \\nu(t)$ $\\nu(t)$ : bruit $x(t-t_0)$ : signal retarde de $t_0$Le bruit depend de $t$ et pas de $x$.\\[\\begin{aligned}\\Gamma_{xy}(\\tau) = &amp;lt;x(t),y(t-\\tau)&amp;gt; &amp;amp;= &amp;lt;x(t),\\overbrace{x(t - (\\tau + t_0) + \\nu(t-\\tau))}^{y(t-\\tau)}&amp;gt;\\\\&amp;amp;= &amp;lt;x(t), x(t - (\\tau + t_0))&amp;gt; + \\underbrace{&amp;lt;x(t),\\nu(t-\\tau)&amp;gt;}_{=0}\\\\&amp;amp;= \\Gamma{xx}(\\tau-t_0)\\end{aligned}\\]$\\Gamma{xx}(\\tau+t_0)$ est maximal en $0$:\\(\\tau + t_0 = 0 \\Rightarrow \\tau=-t_0\\)Sur le notebook: les courbes ne sont pas arrondies, si on zoom dessus on pourrait voir des traits.La convolution On va parler de convolution continue: En numerique: des sommes En analogique: des integrales Avec la convolution, possible de recuperer un signal debruite:On veut recuperer notre signal a partir du gros pate bleu. La convolution est utilisee pour debruiter des signaux tout le temps.C‚Äôest faisable avec la correlation mais plus chiant. Convolution avec une image: probleme aux bords. La ‚Äúfenetre glissante‚Äù passant sur une image risque de sortir du bord de l‚Äôimage.Attention a comment on gere les bords.ExempleDefinition\\((f*g)(t) = \\int_{-\\infty}^{+\\infty}g(x)f(t-x)dx = \\int_{-\\infty}^{+\\infty}g(x)f(t-x)dx = (g*f)(t)\\)Difference de la correlation: On ne prend pas le conjugue, $t-x$ inverse $g$ Il n‚Äôy a pas de $t-\\tau$Proprietes Element neutre de la convolution: le delta de Dirac\\[f*g=g*f=f \\Rightarrow g \\equiv \\delta:t\\to\\begin{cases} 0 &amp;amp; t\\neq 0\\\\ +\\infty &amp;amp; t= 0\\end{cases}\\text{et}\\int_{\\mathbb{R}}\\delta(t)dt = 1\\] Si $f$ et $g$ sont de meme parite: $f*g$ est paire. Si $f$ et $g$ sont de parite contraire: $f*g$ est impaire." }, { "title": "AWS TD 4 - Modules 9 and 10", "url": "/cours/posts/aws_td_4/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 18:30:00 +0100", "snippet": "Lien de la note HackmdAWS TD 4Any company La loi de Conway: ‚Äúles organisations qui con√ßoivent des syst√®mes [‚Ä¶] tendent in√©vitablement √† produire des designs qui sont des copies de la structure de communication de leur organisation. ‚ÄúDudil: lorsque tu demandes a un parti tiers de t‚Äôauditer pour montrer ta bonne foi Quand tu te fais racheter, tu caches les cadavres et tu repeint les murs.AnyCompany backgroundAnyCompany architecture: Fly and SnapAnyCompany architecture: Show and Sell" }, { "title": "AWS Module 10 - Automatic Scaling and Monitoring", "url": "/cours/posts/aws_module_10/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 11:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Load Balancing Distributes incoming app or network traffic across multiple targets in a single or multiples AZ Scales your load balance as traffic to your aapp changes over time Types of loads balancersHow Elastic Loads Balancing works With Application Load Balncers and Network Load Balancers, you register targets in traffic to the target groups With Classic Load Balancers, you register instance with the load balancer Load balancer performs health checks to monitor health of registered targetsElastic Load Balancing use cases High available and fault-tolerant app Containerized app Elasticity and scalability VPC Hybrid environments Incoke Lambad functions over HTTP(S)Load balancer monitoring Amazon CloudWatch metrics Used to verify that the system is performing as expected and creates an alarm to initiate an action if a metric goes outside an acceptable range Access logs Capture detailed information about requests sent to your load balancer AWS CloudTrail logs Capture the who, what, when, and where of API interactions in AWS services Section 2: Amazon CloudWatchMonitoring AWS resourcesTo use AWS efficiently, you need insight into your AWS resources: How do you know when you should launch more Amazon EC2 instances ? Is your app‚Äôs performance or availability being affected by a lack of sufficient capacity ? How much of your infrastructure is actually being used ?Amazon CloudWatch Monitors AWS resources App that run on AWS Collect and track Standard metrics Custom metrics Alarms Send notifications to an Amazon SNS topic Perform Amazon EC2 Auto Scaling or Amazon EC2 actions Events Define rules to match changes in AWS environment and route these events to one or more target functions or streams for processing CloudWatch alarsm Create alarms basde on Static threshold Anomlay detection Metric math expression Specify Namespace Metric Statistic Period Conditions Additional configuration Actions Section 3: Amazon EC2 Auto ScalingWhy is scaling important ? Scaling is the ability ot increase of decrease the compute capacity of your app. First graph: unused capacity on most days of the week, not cost optimized Second graph: under capacity on certain days Automatic capacity scaling is necessary to support the fluctuating demands for service.Amazon EC2 Auto Scaling Hels you maintaint app Enables you to automatically add or remove EC2 instances according to conditions that you define Detects impaired EC2 instances and unhealthy app, and replaces the instances without your intervention Provides several scaling options Manual Scheduled Dynamic (on-demand) Predictive Typical weekly traffic at Amazon.comNovember traffic to Amazon.comAuto Scaling groups An Auto Scaling group is a collection of EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. Scaling ou vs scaling inHow Amazon EC2 Auto Scaling worksImplementing dynamic scalingAWS Auto Scaling Monitors you app and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost Provides a simple, powerful user interface that enables you to build scaling plans for resources, including Amazon EC2 instances and Spot Fleet Amazon Elastic Container Service (Amazon ECS) Tasks Amazon DynamoDB tables and indexes Amazon Aurora Replicas Wrap-upWhich service would you sue to send alerts base on Amazon CloudWatch alarms ? Amazon Simple Notification Service AWS CloudTrail AWS Trusted Advisor Amazon Route 53 Answer Keywords: send alerts Amazon CloudWatch Alarms Answer: 1." }, { "title": "AWS Module 9 - Cloud Architecture", "url": "/cours/posts/aws_module_9/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-12 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS Well-Archtitected FrameworkArchitecture: designing and building Architecture is the art and science of designing and building large structure. manage size and complexity identify business goals capabilities needing improvement alignement between tech deliverables of a solution and business goals work with delivery teamWhat is the AWS Well-Architected Framework ? A guide for designing infrastructure that are Secure High-performing Resilient Efficient A consistent approach to evaluating and implementing cloud architectures A way to provide best practices that were developed through lessons learned by reviewing customer architecturesPillars of the AWS Well-Architected FrameworkPillar organizationBest practice area Identity and Access ManagementQuestion text SEC 1: How do you manage credentials ad authentication ?Question context Credential and authentication mechanisms include password, tokens and keys granting access directly or inderectly in your workload. Protect credentials with appropriate mechanisms to help reduce the risk of accidental or malicious use.Best practices Define requirements of identity and access management Secure AWS account root user Enforce use of multi-factor authentication Automate enforcement of access controls Integrate with centralized federation provider Enforce password requirements Rotate credentials regularly Audit credentials periodicallySection 2: Operational Excellence Pillar Focus Run and monitor systems to deliver business value, and to continually improve supporting processes and procedures Key topics Managing and automating changes Responding to events Defining standards to successfully manage daily operations Operational excellence design principles Perform operations as code Define entire workload (app and infra) Limit human error Consistent responses to event Annotate documentation automating the creation of annoted doc input to your operations as code Make frequent, small, reversible changes components updated regularly Refine operations procedures frequently opportunities to improve procedures Anticipate failure potential sources of failure Learn from all operational events failures share what is learned Operational excellence questions Prepare How do your determine what your priorties are ? How do you design your workload so that you can understand its state ? How do you reduce defects, ease, remediation and improve flow into production ? How do you mitigate deployement risks ? How do you know that you are ready to support a workload ? Operate How do you understand the health of workload ? How do you manage workload and operation events ? Evolve How do you evolve operations ? Section 3: Security Pillar Focus Protecte info, systemes, and assets while delivering business value through risk assessments and mitigation strategies Key topics Identifying and managing who can do what Establishing controls to detect security events Protecting systems and services Protecting confientiality and integrity of data Security design principles Implement a strong identity foundation principle of least privileges separation of duties Enable traceability monitor, alert and audit actions integrate logs and metrics to automatically respond and take action Apply security to all layers defense-in-depth security controls to all layers of your architecture Automate security best practices improve ability to securely scale more rapidly and cost effectively Protect data in transit and at rest classify data into sensitivity levels use mechanisms such as encryption, tokenization and access control Keep people away from data reduce risk of loss or modif of sensitive data due to human error create tools to reduce manual processing of data Prepare for security events incident management process Security questions Identity and access management How do you manage credentials and authentication ? How od you control human access ? Ho do you control programmatic access ? Detective controls How do you detect and investigate security events ? How do you defend against emerging security threats ? Infrastructure protection How do you protect your networks ? How do you protect your compute resources ? Data protection How do you classify your data ? How do you protect your data at rest ? How do you protect your data in transit ? Incident response How od you respond to an incident ? Section 4: Reliabality Pillar Focus Prevent and quickly recover from failures to meet business and customer demand Key topics Setting up Cross-project requirements Recovery planning Handling change Reliability design principles Test recovery procedures test how you system fails validate recovery procedures expore failure pathways Automatically recover from failure monitor systems for key performance indicator configure system to trigger an automated recovery when a threshold is breached Scale horizontally to increase aggregate system availability replace one large resources with multiple smaller one reduce impact of a single point of failure Stop guessing capacity monitor demand and system usage automate the addition or removal of resources to maintain the optimal level Manage change in automation use automation to make changes to infra manage changes to automation Reliability question Foundations How do you manage service limits ? How do you manage your network topology ? Change management How does your system adapt to changes in demand ? How do you monitor your resources ? How do you implement change ? Failure management How do you back up data ? How does your system withstand component failure ? How do you test resilience ? How do you plan for disaster recovery ? Section 5: Performance Efficiency Pillar Focus Use IT and computing resources efficiently to meet system requirements and to maintain that efficiency as demand changes and technologies evolve Key topics Selecing thr right resource types and sizes based on workload requirements Monitoring performances Making informed decisions to maintain efficiency as business needs evolve Performance efficiency design principles Democratize advanced technologies consume tech as a service focus on product dev Go global in minutes deploy systems in multiple AZ Use serverless architectures remove operational burden of maintaining servers reduce costs Experiment more often comparative testing Have mechanical sympathy use tech approach aligning best with what you want to achieve Performance efficiency question Selection How do you select the best performing architecture ? How do you select your compute solution ? How do you select your storage solution ? How do you select your db solution ? How do you select your networking solution ? Review How do you evolve your workload to rake advantageof new releases ? Monitoring How do your monitor your resources to ensure they are performing as expected ? Tradeoffs How do you use tradeoffs to improve performance ? Section 6: Cost Optimization Pillar Focus Run systems to deliver business value at the lowest price point Key topics Understanding and controlling when money is being spent Selecting the most appropriate and right number of resource types Analyzing spending over time Scaling to meeting business needs without overspending Cost optimization design principles Adopt a consumption mode pay only for the computing resources required Measure overall efficiency measure business output cost associated measure the gain you are making Stop spending money on data centers operations AWS does the heavy-lifting Analyze and attribute expenditure accuratly identify system usage and cost Use managed and application-level services to reduce cost of ownership reduce operational burden of maintaining servers for tasks lower cost per transaction Cost optimization questions Expenditure awareness How do you govern usage ? How do you monitor usage and cost ? How od you decommission resources ? Cost-effective resources How do you evaluate cost when you select services ? How do you meet cost target when you select resource type and size ? How do you you use pricing models to reduce cost ? How do you plan for data transfer changes ? Matching supply and demand How do you match supply of resources with demand ? Optimizing over time How do you evaluate new services ? Section 7: Reliability and Availability ‚ÄúEverything fails, all the time‚Äù - Werner Vogels, CTO, Amazon.comReliability A measure of your system‚Äôs ability to provide functionality when desired by the user System includes: hardware, software, firmware Probability that your entire system will function as intended for a specified period Mean time between failures (MTBF) = total time in serviceumber of failuresUnderstanding reliability metricsAvailability Normal operation time / total time A percentage of uptime (ex: 99.9%) over time (ex: 1y) Number of 9s - 5 9s means 99.999% availabilityHigh availability System can withstand some measure of degradation while still remaining available Downtime is minimized Minimal human intervention is requiredAvailability tiersFactors that influenc availability Fault tolerance The built-in redundancy of an app compononents and its ability to remain operational Scalability The ability of an app to accomodate increases in capacity needs without changing design Recoverability The process, policies, and procedures that are related to restoring service after a catastrophic event Section 8: AWS Trusted Advisor Online tool that provides real-time guidnace to help you provision your resources following AWS best practices Looks at your entire AWS enivronment and gives you a real time recommendations in Cost Optimization eliminating unused resources commitment to reserve capacity Performance checking service limit service throughput Security improve security of the app by identifying gaps permissions increase availability and redundancy Fault Tolerance service usage more than 80% of the service limit values based on snapshot Wrap-upA SysOps engineer working at a company wants to protect their data in transit and at rest. What service could they use to protect their data ? Elastic Load Balancibg Amazon Elastic Block Stor (Amazon EBS) Amazon Simple Storage Service (Amazon S3) All of the above Answer Keywords: protect their data in transit and at rest Answer: 4." }, { "title": "AWS TD 3 - Modules 7 and 8", "url": "/cours/posts/aws_td_3/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 18:30:00 +0100", "snippet": "Lien de la note Hackmd L‚Äôexam de la certif est beaucoup plus dur que les knowledge checks.Il existe 2 types de devices: char device block device" }, { "title": "MBTI - Les differents types de personnalite", "url": "/cours/posts/mbti_1/", "categories": "tronc commun S8, MBTI", "tags": "tronc commun, MBTI, S8", "date": "2021-02-11 14:00:00 +0100", "snippet": "Lien de la note HackmdPr√©sentationAnne Dewilde Directrice Labo 3IE 15 ans chez HP Travaill√© dans Le secteur de la d√©fense Le secteur banque/assurance Le cours: approche de connaissance de soi L‚Äô√©cole veut mettre l‚Äôaccent sur les soft skills.Exercice d‚Äôintrospection sur soi-m√™me Veut en aucun cas nous caller dans des cases Exercice difficile D√©velopper notre savoir-√™treExercie SUR FEUILLE 5 mots qui nous caract√©risent 2 mots random et on signe Les m√™me mot et signature mais avec l‚Äôautre mainQuels retours sur le dernier exo ? Pas ambidextre La signature change totalement Ecrit aussi mal avec les 2 mains Identifier nos zones de pr√©f√©rence.QuestionnaireQuestionnaire CCTITotal de 11 par colonne, c‚Äôest un indicateur de clart√©.MBTIHistorique MBTI s‚Äôappuie sur la th√©orie de la personnalit√© de Carl Jung Le mod√®le a √©t√© mis au point par Briggs Et Myers Rare mod√®le de personnalit√© qui d√©cit de mani√®re positiveRecherche 20 ans de recherche 4000 articles scientifiques Am√©lior√© et maj en continuLa r√®gle d‚Äôor Les diff√©rences de comportement que nous observons ne sont pas du hasardPoints importants Pas de bon ou mauvais type Tout le monde peut utiliser les huit pr√©f√©rences Chacun meilleur juge de son type D√©termine ni aptitudes, ni comp√©tences MBTI utilis√© qu‚Äôen dev et pas s√©lection ¬† Ce que je sais Ce que je ne sais pas Ce que les autres savent Ouvert Aveugle Ce que les autres ne savent pas Cach√© Inconnu $\\rightarrow$: feedback $\\downarrow$: ouverture Diagonale: lucidit√©L‚Äôorientation de l‚Äô√©nergie Certains d‚Äôentre nous sont attir√©s par le monde ext√©rieur (E) Stimul√© par les gens Action r√©flexion action Souvent amical Exprime ses √©motions A besoin de contact Elargit Peut sembler superficiel √† un I D‚Äôautre le monde int√©rieur (I) Stimul√© par les pens√©es R√©flexion action r√©flexion Souvent r√©serv√© Ravale ses √©motions A besoin d‚Äôintimit√© Approfondit Peu sembler √©loign√© √† un E Modes de perception Pr√©f√©rences pour la Sensation et l‚ÄôiNtuition Certains pr√©f√®rent les fait pr√©cis (S) Vit dans le pr√©sent et savoure Activit√©s concr√®tes Commence par le d√©but, avance pas √† pas Manipule les pi√®ces pour trouver l‚Äôassemblage par t√¢tonnements Aime les proc√©dures et d√©marches √©prouv√©es Peut sembler mat√©rialiste pour un N D‚Äôautres ont une vue d‚Äôensemble (N) Vit tourn√© vers l‚Äôavenir Pr√©f√®re imaginer des possibilit√©s Proc√®de par bonds, saute les √©tapes Etudie le sch√©ma d‚Äôensemble pour comprendre comment les pi√®ces s‚Äôassemblent Aime le changement et la vari√©t√© Peut sembler inconscient pour un S Crit√®res de d√©cision T: thinking F: feeling Certains proc√®dent plut√¥t d‚Äôune mani√®re logique avec une grille de crit√®res (T) V√©rit√©, justice Regarde les √©v√®nements en spectateur ext√©rieur Commence √† voir ce qui ne va pas Bon pour analyser des plans Peu sembler froid et condescendant √† F D‚Äôautres se d√©cident selons leurs sentiments et leurs valeurs (F) Relations humaines Regarde les √©v√®nements en participant Commence par appr√©cier spontan√©ment Bon pour comprendre les gens Peu sembler brouillon et sensible √† T Organisation J: Judgement P: Perception Aime prendre des d√©cisions Curieux, aime l‚Äôimpr√©vu" }, { "title": "AWS Module 8 - Databases", "url": "/cours/posts/aws_module_8/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 11:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Amazon Realtional Database Service (RDS)Unmnagade vs managed servicesUnmanagedmanaged by you: Scaling Fault tolerance AvailabilityMore fine-tune controlManagedbuilt in the service: Scaling Fault tolerance AvailabilityRequires less configurationChallenges of relational databases Server maintenance and energy footprint Software installation and patches Database backups and high availability Limits on scalability Data security OS installation and patchesAmazon RDS Managed services that sets up and operates a relational database in the cloudManaged services responsabilitiesYou manage App optiAWS manages: OS installation and patches Databse software installation and patches Database backups High availability Scaling Power and racking and stacking servers Server maintenanceAmazon RDS DB instancesAmazon RDS in a VPC Select IP address range Subnets Configure routing and access control listHigh availability with Multi-AZ deployement1 Automatically generates a standby copy in another AZ within the same VPC Enhanced availability2 If the main database instance fails, Amazon RDS automatically brings the standby instance online.Amazon RDS read replicasFeatures Offers asynchronous replication Can be promoted to master if neededFunctionality Use for read-heavy database workloads Offload read queriesUse casesWhen to Use Amazon RDS Use Amazon RDS when your app requires Do not use Amazon RDS when your app requires Complex transactions or complex queries Massive read/write rates A medium to high query or write rate (Up to 30,000 IOPS) Sharding due to high data size or throughput demands No more than a single worker node or shard Simple GET or PUT requests and queries that a NoSQL database can handle High durability Relational database managemnet (RDBMS) customization Amazon RDS: Clock-hour billing and db characteristicsClock-hour billing Resources incur charges when runningDatabas characteristics Physical capacity Engine Size Memory class Amazon RDS: DB purchase type and multiple DB instancesDB purcharse type On-demand isntances Compute capacity by the hour Reserved Instance Low, one-time, upfront paymenent for db instances that are reserved with a 1-year or 3-year term Number of DB instances Provision multiple DB instance to handle peak loadsAmazon RDS storageProvisioned storage No charge Bakcup storage up to 100% of db storage for an active db Charge (GB/month) Backup storage for terminated DB instances Additional storage Charge (GB/month) Backup storage in addition to provisioned storage Amazon RDS: Deployement type and data transferRequests The number of input and output requests that are made to the dbDeployement type - storage and I/O vary, depending on whether you deploy to Single AZ Multiple AZData transfer No charge for inbound data transfer Tiered charges for outbound data transferSection 2: Amazon DynamoDBRealtion vs non-relation DBWhat is Amazon DynamoDB ? Fast and flexibe NoSQL db service for any scale NoSQL db tables Can be scaled Create tables and add items Global tables Automatically replicates choices across AWS regions Virtually unlimited storage Items can have differing attributes Don‚Äôt have to migrate schema Low-latency queries Scalable read/write throughput Store data accross multiples facilities fault-toleratn architecture stored in SSDs encrypt data at rest set time to live Automatically partitions dataAmazon DynamoDB core components Tables, itmes and attributes DynamoDB supports 2 different kinds of primary keys Partition key Sort key Items in a table must have a keySection 3: Amazon RedshiftAmazon Redshift Fast, fully managed data warehouse, simple and cost-effective to analyze data using SQL and business intellignec tools.Introduction to Amazon Redshift Fast and fully-managed data warehouse Pay for what you use Complex analytics queries Parallel processing Only seconds Parallel processing architectureAutomation and scalingAutomate manage monitor scale Security is built-in with encryption of data.Compatibility Supports standard SQL Connect with SQL clients Java connectivity Open DB connectivity Interact direclty with AWS CLI or management consoleAmazon Redshift use cases Enterprise data warehouse (EDW) Migrate at a pace that customers are comfortable with Experiment without large upfront cost or commitment Respond faster to business needs Big data Low price point for small customers Managed service for ease of deployment and maintenance Focus more on data and less on database management SaaS Scale the data warehouse capacity as demand grows Add analytic functionality to app Reduce hardware and software costs Section 4: Amazon Aurora MySQL and PostreSQL compatible relational db built for the cloud. Enterprise-class relational db Compatible with MySQL or PostgreSQL Automate time-consuming tasks (such as provisioning, patching, backup, recovery, failure detection and repair) Can reduce db costsAmazon Aurora service benefits Fast and available Managed service Simple Pay-as-you-go CompatibleHigh availability Storing multiple copies through different AZ Data backed up to Amazon S3 Use up to 15 read replicaResilient design Instant crash recovery Does not need to replay the redo log Do it on every read operation Removes the buffer cache from the db processWrap-upWhich of the following is a fully managed NoSQL db service ? Amazon RDS Amazon DynamoDB Amazon Aurora Amazon Redshift Answer Keywords: NoSQL Answer: 2." }, { "title": "AWS Module 7 - Storage", "url": "/cours/posts/aws_module_7/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-11 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Amazon Elastic Block Store (Amazon EBS)Storage Provides persistent block storage volumes with Amazon EC2 instances Called non-volatile storage Replicated within AZAWS Storage options: block storage vs object storageWhat if you want to change one character in a 1-GB file ?Amazon EBS Amazon EBS enables you to create individual storage volumes and attach them to an Amazon EC2 instance Amazon EBS offers block-level storage Volumes are automatically replicated within its AZ Can be backed up automatically to Amazon S3 through snapshots Uses include Boot volumes and storage for Amazon Elastic Compute Cloud (Amazon EC2) instance Data storage with a file system Database hosts Enterprise app Amazon EBS volume typesAmazon EBS Snapshots Point-in-time snapshots Recreate a new volume at any time Encryption Encrypted Amazon EBS volumes No additional cost Elasticity Increase capacity Change to different types Volumes, IOPS and pricing Volumes Amazon EBS volumes persist independently from the instance All volume types are charged by the that is provisioned per month IOPS General Purpose SSD Charged by the amount that you provision in GB per month until storage is released Magnetic Charged by the number of requests to the volume Provisioned IOPS SSD Charged by the amount that you provision in IOPS (multiplied by the percentage of days that you provision for the month Snapshots Added cost of Amazon EBS snapshots to Amazon S3 is per GB-month of data stored Data transfer Inbound data transfer is free Outbound data transfer accross Regions incurs charges Section 2: Amazon Simple Storage Service (Amazon S3)Storage Amazon S3 is object-level storage. If want to change part of a file, must do the change and repload the entier fileAmazon S3 overview Data stored as objects in buckets Virtually unlimited storage Single object is limited to 5 TB Designed for 11 9s of durability Granular access to bucket and objects Data private per default Can set up notification When object is added When object is deleted Amazon S3 stroage classesAmazon S3 offers a range of object-level storage classes that are designed for different use cases Amazon S3 standard High availability High durability Perfomance Frequently access data Amazon S3 Intelligent-Tiering Optimize cost Moving data to the most cost-effective access tier long-live data with unpredictable access pattern Amazon S3 Standard-Infrequent Access (Amazon S3 Standard-IA) Data accessed less frequently long-term storage Amazon S3 One Zone-Infrequent Access (Amazon S3 One Zonw-IA) Data accessed less frequently Stores data in a single availbility zone Amazon S3 Glacier Secure Durable low cost data archiving three retrieval options min to hours Amazon S3 Glacier Deep Archive Lowest cost long-term detention retrieved once or twice a year Amazon S3 bucket URLS (two styles)To upload your data: Create a bucket in an AWS Region Upload almost any number of objects to the bucketBucket path-style URL endpoint:https://s3.ap-northeast-1.amazonaws.com/bucket-nameBucket virtual-hosted-style URL endpointhttps://bucket-name.s3-ap-northeast-1.amazonaws.comData is redundantly stored in the RegionPrevent data lossDesigned for seamless scalingAmazon S3: automatically manage the storage scales to handle high volume of request billed for what you useAccess the data anywhere AWS CLI AWS Management Console SDK Bucket names must be globally unique and DNS compliant: all lowercase, only letters, numbers and dashesAmazon S3 common scenarios Backup and storage Application hosting Media hosting SoftwareAmazon S3 pricing Pay for what you use GBs per month Transfer OUT to other Regions PUT, COPY, POST, LIST and GET requests You do not pay for Transfers IN to Amazon S3 Transfers OUT from Amazon S3 to Amazon CloudFront or Amazon EC2 in the same region Amazon S3: Storage pricingTo estimate Amazon S3 costs: Types of storage classes Standard storage is for 11 9s of durability 4 9s of availability S3 Standard-Infrequent Access (S-IA) is for 11 9s of durability 3 9s of availaibility Amount of storage The number and size of objects Requests Number of requests (GET, PUT, COPY) Type of requests Different rates for GET requests Data transfer Pricing based on amount of data transferred ou of Amazon S3 Region Data transfer in is free, but incur charges for data transferred out Section 3: Amazon Elastic File System (Amazon EFS)Storage Implements storage for EC2 instancesFeatures File storage in the AWS Cloud Works well for big data and analystics, media processing workflows, content management, web serving and home directories Petabyte-scale, low-latency file system Shared storage Elastic capacity Gigabytes to petabytes of data Supports Network File System (NFS) versions 4.0 and 4.1 (NFSv4) Compatible with all Linux-based AMIs for Amazon EC2 Pay for what you useAmazon EFS architectureAmazon EFS implementation create your Amazon EC2 resources and launch your instance Create your Amazon EFSfile system Create your mount targets in the appropriate subnets Connect your Amazon EC2 instances to the mount targets Verify the resources and protection of your AWS accountAmazon EFS resources Mount target Subnet ID Security gorups One or more per file system Create in a VPC subnet One per AZ Must be in the same VPC Tags Key0value pairs Section 4: Amazon S3 GlacierStorage Secure, durable and extremely low-cost data archiving. Archive Any object such as photo, video, file or document stored in Amazon S3 Glacier Bas unit of storage unique ID Vault Container for storing archive Specifies vault name Premissions access policy Vault lock policy Amazon S3 Glacier review Designed to provide 11 9s of durability for objects Supports encryption of data in transit/at rest through Secure Sockets Layr (SSL) or Transpor Layer Security (TLS) Vault lock: enforces compliance through a policy Extremely low-cost for long-term archiving Three options: expedited, standard or bulk Retrieval times from a few minutes to hours Amazon S3 Glacier Storage service for low-cost data archiving and long-term backup Configure lifecycle archiving Amazon S3 content to Amazon S3 Glacier Retrieval options Standard: 3-5 hours Bulk: 5-12 hours Expedited: 1-5 min Amazon S3 Glacier use cases Media asset archiving Healthcare info archiving Regulatory and compliance archiving Sicentific data archiving Digital preservation Magnetic tape replacementUsing Amazon S3 Glacier RESTful web services Java or .NET SDKs Amazon S3 with lifecycle policiesLifecycle policies Amazon S3 lifecycle policies enable you to delete or move objects based on age.Amazon S3 storage classesStorage comparisonServer-side encryptionServer-side encryption: SSE S3 each objects has unique key AES 256 SSE-C Own encryption keys AWS Key Management Service Scaled for the cloud Customer master keys IAM Console or API Access keys How keys can be used Security with Amazon S3 Glacier Controle access with IAM Amazon S3 Glacier encrypts your data with AES-256 Amazon S3 Glacier manages your keys for youWrap-upA company wants to store data that is not frequently accessed. What is the best and cost-effective solution that should be considered ? Amazon S3 Storage Gateway Amazon S3 Glacier Amazon EBS Amazon S32 Answer keyword: not frequently accessed cost-effective solution Answer: 2." }, { "title": "AWS TD 2 - Module 5 and 6", "url": "/cours/posts/aws_td_2/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 19:30:00 +0100", "snippet": "Lien de la note Hackmd Mes draps sont pleins de neige mais a part ca ca va bien - ChewieModule 5VPC Le sol sur lequel on va construire. Un VPC est un sac de subnets. Un VPC existe au sein d‚Äôune region. Dedie a notre compte Existe a travers de AZIP addressingSac des differents blocs qu‚Äôon va prendreRoute tables and routes La table de routage est la ‚Äúrepresentation‚Äù d‚Äôun router. Elle s‚Äôapplique a un ou plusieurs subnets et le subnet a exactement une table.VPC endpointsPour eviter de ‚Äúsortir‚Äù de Amazon pour aller utiliser d‚Äôautres services" }, { "title": "AWS Module 6 - Compute", "url": "/cours/posts/aws_module_6/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 16:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Compute services overviewAWS compute services Amazon EC2: resizable virtual machine Amazon EC2 auto-scaling: define conditions to launch or terminate EC2 instances Amazon ECR: store and retrieve Docker images Amazon ECS: Container orchestration service that supports Docker VMWare Cloud on AWS: hybrid cloud without custom hardware AWS Elastic Beanstalk: run and manage web app AWS Lambda: serverless compute solution Amazon EKS: run managed kubernetes on AWS Amazon LightSail: building app or website AWS Batch: running batch job at any scale AWS Fargate: run containers AWS Outpost: run AWS services in your on-premises data center AWS Serverless Repository: discover, deploy and publish application Categorizing compute servicesChoosing the optimal compute service The optimal compute service or services that you use will depend on your use case Some aspects to consider What is your application design ? What are your usage pattern ? Which configuration settings wll you want to manage ? Selecting the wrong compute solution for an architecture can lead to lower performance efficiency A good starting place: understand the available compute options Section 2: Amazon EC2Amazon Elastic Compute Cloud (Amazon EC2)Example uses of Amazon EC2 instances: App server web server Database server Game server Mail server Media server Catalog server File server Computing server Proxy serverAmazon EC2 overview Amazon Elastic Compute Cloud (Amazon EC2) Provides virtual machines (EC2 instance) in the cloud Fives you full control over the guest operating system (Windows or Linux) on each instance You can launch instances of any size into and Availability Zone anywhere in the world Launch instance from Amazon Machine Images (AMIs) Launch instances with a few clicks or a line of code, and they are ready in minutes You can control traffic to and from instancesLaunching an amazon EC2 instance Nine key decisions when creating a EC2 instance.1. Select an AMI Amazon Machine Image (AMI) Is a template that is used to create an EC2 instance Contains a Windows or Linux OS Often has some software pre-installed AMI choices: Quick Start Linux and Windows AMIs provided by AWS My AMIs Any AMIs that you created AWS Marketplace Pre-configured templates from third parties Community AMIs AMIs shared by others; use at you own risk 2. Select an instance type Consider you use case How will the EC2 instance you create be used ? The instance type that you choose determines Memory (RAM) Processing power (CPU) Disk space and disk type (Storage) Network performance Instance type categories General purpose Compute optimized Memory optimized Storage optimized Accelerated computed Instance types offer family, generation and sizeInstance type naming and sizesBased on use caseNetworking features The network bandwith (GBps) varies by instance type To maximize networking and bandwith performance of your instance type If you have interdependent instances, launch them into a cluster placement group Enable enhanced networking Enhanced networking types are supported on most instance types Enhanced networking types Elastic Network Adapter (ENA): Supports network speeds of up to 100 Gpbds Intel 82599 Virtual Function interface: Supports network speeds of up to 10 Gbps Section 3: Amazon EC2 Part 23. Specify network settings Where should the instance be deployed ? Identify the VPC and optinally the subnet Should a public IP address be automatically assigned ? To make it internet-accessible 4. Attach IAM role (optional) Will software on the EC2 insrance need to interact with other AWS services ? If yes, attach an appropriate IAM Role An AWS Identity and Access Management (IAM) role that is attache to an EC2 instance is kept in an instance profile You are not restricted to attaching a role only at instance launch You can also attach a role to an instance that already exists 5. User data script (optional) Optionally specify a user data script at instance launch Use user data scripts to customize the runtime environment of your instance Script executes the first time the instance starts Can be used strategically Reduce the number of custom AMIs that you build and maintain 6. Specify storage Configure the root volume Where the guest operating system is installed Attach additional storage volumes (optional) AMI might already include more than one volume For each volume, specify: The size of the disk (in GB) The volume type Different types of SSDs and HDDs are available If the volume will be deleted when the instance is terminated If encryption should be used Amazon EC2 storage options Amazon Elastic Block Store (Amazon EBS) Durable, block-level storage volumes You can stop the instance and start it again, and the data will still be there Amazon Elastic Block Store Storage is provided on disls that are attached to the host computer where the EC2 instance is running If the instance stops, data stored here is deleted Other options for storage (not for root volume) Mount an Amazon Elastic File System (Amazon EFS) file system Connect to Amazon Simple Storage Service (Amazon S3) Example storage options Instance 1 characteristics It has an Amazon EBS root volume type for the operating system What will happen if the instance is stopped and then started again ? The OS volume would survive Any data stored on Amazon EBS would remain intact Any data stored in ephemeral volume 1 would be lost Instance 2 characteristics It has an Instance Store root volume type for the operating system What will happen if the instance stops (because of user error or a system malfunction)? All data stored in ephemeral volume 2 would be lost, including the OS Section 4: Amazon EC2 Part 37. Add tags A tag is a label that you can assign to an AWS resource Consists of a key and an optional value Tagging is how you can attach metadata to an EC2 instance Potential benefits from tagging - Filtering, automation, cost allocation and access control8. Security group settings A security group is a set of firewall rules that control traffic to the instance. It exsists outside of the instance‚Äôs guest OS Create rules that specify the source and which ports that network communications can use. Specify the port number and the protocol, such as TCP, UDP or ICMP Specify the source that is allowed to use the rule9. Identify the key pair At instance launch, you specify an existing key pair or create a new key pair A key pair consists of A public key that AWS stores A private key file that you store It enables secure connections to the instance For Windows AMIs Use the private key to obtain the administrator password that you need to log in to your instance For Linux AMIs Use the private key to use SSH to securely connect to your instance Amazon EC2 console view of a running EC2 instanceAnother option: Launch an EC2 instance with the AWS CLI EC2 instances can also be created programmaticallyaws ec2 run-instances --image0id ami-1a2b3c4d --count 1 --instance-type c3.large \\--key-name MyKeyPair --security-groups MySecurityGroup --region us-east-1This example shows how simple the command can be. This command assumes that the key pair and security group already exists More option could be specifiedAmazon EC2 instance lifecycleConsider using an Elastic IP address Rebooting an instanc will not change any IP addresses or DNS hostnames When an instance will not change any IP addresses or DNS hostnames When an instance is stopped and then started again The public IPv4 address and external DNS hostname will change The private IPv4 address and internal DNS hostname do not change If you require a persistent public IP address Associate an Elastic IP address with the instance Elastic IP address characteristics Can be associated with instances in the Region as needed Remains allocated to your account until you choose to release it EC2 instance metadata It is data about your instance While you are connected to the instance, you can view it In a browser: http://169.254.169.254/latest/meta-data/ In a terminal window: curl http://169.254.169.254/latest/meta-data/ Example retrievable values Public IP address, private IP address, public hostname, instance ID, security groups, Region, Availability zone Any user data specified at instance launch can also be accesse at: http://169.254.169.254/latest/user-data/ It can be used to configure or manage a running instance For example, author a configuration script that read the metadata and uses to configure applications or OS settings Amazon CloudWatch for monitoring Use Amazon CloudWatch to monitor EC2 instances Provides near-real-time metrics Provides charts in the Amazon EC2 console Monitoring tab Maintains 15 months of historical data Basic monitoring Default, no additional cost Metric data sent to CloudWatch every 5 minutes Detailed monitoring Fixed monthly rate for seven pre-selected metrics Metric data delivered every 1 min Section 5: Amazon EC2 Cost OptimizationAmazon EC2 pricing models On-Demand Instances Pay by the hour No long-term commitments Elligible for the AWS Free Tier Dedicated Hosts A physical server with EC2 instance capacity fully dedicated to your use Dedicated instances Instances that run in a VPC on a hardware that is dedicated to a single customer Reserverd Instances Full, partial, or no upfront payment for instance you reserve Discount on hourly charge for that instance 1-year or 3-year term Scheduled Reserverd Instances Purchase a capacity reservation that is always available on a recurring schedule you specify 1-year term Spot Instances Instances run as long as they are available and your bid is above the Spot Instance price They can be interrupted by AWS with a 2-minute notification Interruption options include terminated, stopped or hibernated Prices can be significantly less expensive compared to On-Demand Instances Good choice when you have flexibility in when your applications can run Benefits On-Demand Instances Spot Instances Reserved Instances Dedicated Hosts Low cost and flexibility Large scale, dynamic workload Predictability ensures compute capacity is available when needed Save money on licensing costs &amp;lt;/br&amp;gt; Help meet compliance and regulatory requirements Use casesThe 4 pillars of cost optimizationPillar 1: Right size Provision instances to match the need CPU, memory, storage and network throughput Selct appropriate instance types for your use Use Amazon CloudWatch metrics How idle are instances? When Downsizze instances Best practice: right size, then reservePillar 2: Increase elasticity Stop or hibernate amazon EBS-backed instances that are not actively in use Example: non-production development or test instances Use automatic scaling to match needs base on usage Automated and time-based elasticity Pillar 3: Optimal pricing model Leverage the right pricing model for your use case Consider your usage patterns Optimize and combine purchase types Examples: Use On-Demand Instance and Spot Instances for variable workloads Use Reserved Instances for predictable workloads Consider serverless solutions (AWS Lambda)Pillar 4: Optimize storage choices Reduce cost while maintaining storage performance and availability Resixe EBS volumes Changes EBS volumes types Can you meet performance requirements with less expensive storage ? Example: Amazon EBS Throughput Optimized HDD (st1) storage typically costs half as much as the default General Purpose SSD (gp2) storage option Delete EBS snapshots that are no longer needed Identify the most appropriate destination for specific types of data Does the app need the instance to reside on Amazon EBS ? Amazon S3 storage options with lifecycle policies can reduce costs Measure, monitor and improve Cost optimization is an ongoing process Recommendations Define and enforce cost allocation tagging Define metrics, set targets, and review regularly Encourage teams to architect for cost Assign the responsibility of optimization to an individual or to a team Section 6: Container servicesContainer basics Containers are a method of operating system virtualizationBenefits: Repeatable Self-contained environments Software runs the same in different environments Developer‚Äôs laptop, test, prod Faster to launch and stop or terminate than virtual machinesWhat is Docker ? Docker is a software platform that enables you to build, test, and deploy app quickly. You run containers on Docker Containers are created from a template called an image A container has everything a software app needs to runContainers vs VMsAmazon Elastic Container Service (Amazon ECS) A highly scalable, fast, container management service. Key benefit Ocherstartes the running of Docker containers Maintains and scales the fleet of nodes that run your containers Removes the complexity of standing up the infrastucture Integrated with features that are familiar to Amazon EC2 service users Elastic Load Balancing Amazon EC2 security groups Amazon EBS volumes IAM roles Amazon ECS orchestrates containersAmazon ECS cluster optionsDo you want to manage the Amazon ECS cluster that runs the containers ? Yes: create an Amazon ECS cluster backed by Amazon EC2 Provides more granular control over infrastructure No: create an Amazon ECS cluster back by AWS Fargate Easier to maintain, focus on your app What is Kubernetes ? Kubernetes is open source software for containers orchestration deploy and manage containerized app at scale The same toolset can be used on premises and in the cloud Complements Docker Docker enables you to run mutliple containers on a single OS host Kubernetes orchestrates mutliple Docker hosts (nodes) Automates Container provisioning Networking Load distribution Scaling Amazon Elastic Kubernetes Service (Amazon EKS) EKS Enables you to run Kubernetes on AWS Certified Kubernetes conformant Supports Linux and Windows containers Compatible with Kubernetes community tools and add-ons Use Amazon EKS to Manage clusters of Amazon EC2 instances Run containers that ar ochestrated by Kubernetes on those instances Amazon Elastic Container Registry (Amazon ECR) Amazon ECR is a fully managed Docker container registry that makes it easy for developpers to store, manage and deploy Docker container images. Supports Team collab Acces control Third party integration Possible to use with Amazon EKSSection 7: Introduction to AWS LambdaAWS Lambda: Run code without servers AWS Lambda is a serverless compute service.Benefits of Lambda Supports multiple programming languages Completely automated administration Built-in fault tolerance Supports orchestration of multiple functions Pay-per-use pricingAWS Lambda event sourcesAWS Lambda function configuration Create lambda function: give a name Runtime environment Python Node.js Execution role to grant IAM permission to the function to interact with other services Configure the function adding a trigger Add function code Specify the memory in megabytes (up to 3008MGB) Specify env variableSchedule-based Lambda function example: start and stop EC2 instancesEnvent-based Lambda function example: create thumbnail imagesAWS Lambda limitsSoft limits per Region Concurrent executions = 1,000 Function and layer storage = 75GBHard limits for individual function: Max function memory alloc = 3,008 MB Function tiemout = 15 min Deployement package size = 250 MB unzipped, including layersSection 8: Introduction to AWS Elastic BeanstalkAWS Elastic Beanstalk An easy way to get web app up and running A managed service that automatically handles Infra provisionning and config Deployement Load balancing Automatic scaling Health monitoring Analysis and debugging Logging No additional charge for Elastic Beanstalk Pay only for the underlying ressources that are used AWS Elastic Beanstalk deployements Supports web app written for common platforms Java, .NET, PHP, Node.js, Python, Ruby, Go and Docker You upload your code Elastic Beanstalk automatically handles the deployement Deploys on servers such as Apache, NGINX, Passenger, Puma, and Microsoft Internet Information Services (IIS) Benefits of Elastic BeanstalkWrap-upWhich AWS service helps developers quickly deploy resources which can make use of different programming languages, such as .Net and Java ? AWS CloudFormation AWS SQS AWS Elastic Beanstalk Amazon Elastic Compute Cloud (Amazon EC2) Answer Keywords: developers quickly deploy resources different programming languages Answer 3." }, { "title": "AWS Module 5 - Networking and Content Delivery", "url": "/cours/posts/aws_module_5/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-10 14:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: Networking basicsNetworks A computer network is 2 or more machine connected together A network can be partitionned into subnets Requires a networking device (router/switch)IP addresses Each machine on the network has a unique Internet Protocol address (IP) assigned to it Unique number assigned to a machine Four decimal number separated by dots Each number is 8 bits max (between 0 and 255) $\\rightarrow$ total = 32 bitsIPv4 and IPv6 addresses IPv4 (32-bit) address: 192.0.2.0 IPv6 (128-bit) address: 2600:1f18:22ba:8c00:ba86:a05e:a5ba:00FF Adapt to more user Each column is 16 bits (0 to FFFF) Classless Inter-Domain Routing (CIDR) A CIDR adress is expressed as an IP address and is the first address of the network. It‚Äôs followed by a ‚Äò/‚Äô character The numer after is how many bits of the routing prefix must be steady Express a group of addressesOpen Systems Interconnection (OSI) modelSection 2: Amazon VPCAmazon VPC Private space in Amazon Cloud Enables you to provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define Gives you control over your virtual networking resources Selection of IP address range Creation of subnets Configuration of route tables and network gateways Enables you to customize the network configuration for your VPC Enables you to use multiples layers of security Can use IPv4 and IPv6VPCs and subnets VPCs: Logically isolated from other VPCs Dedicated to your AWS account Belong to a single AWS Region and can span multiple Availability Zones Subnets: Range of IP addresses that divide a VPC Belong to a single Availability Zone Classified as public or private Do not have a direct access to internet IP addressing When you create a VPC, you assign it to an IPv4 CIDR block (range of private IPv4 addresses) You cannot change the address raneg after you create the VPC The largest IPv4 CIDR block size is /16 The smallest IPv4 CIDR block size /28 IPv6 is also supported (with a different block size limit) CIDR blocks of subnet cannot overlapReserved IP addressesExample: A VPC with an PIv4 CIDR block of 10.0.0.0/16 has 65,636 total IP addresses. The VPC has four equal-sized subnets. Only 251 IP addresses are available for use by each subnet.Public IP address type Public IPv4 address Elastic IP address Manually assigned through an Elastic IP address Associated with an AWS account Automatically assigned through the auto-assign public IP address settings at the subnet level Can be allocated and remapped anytime ¬† Additional costs might apply Elastic network interface An elastic network interface is a virtual network interface that you can Attach to an instance Detach from the instance and attach ot another instance to redirect network traffic Its attributes follow when it is reached to a new instance Each instance in your VPC has a default network interface that is assigned a private IPv4 address from the IPv4 address range of your VPCRoute tables and routes A route table contains a set of rules (or routes) that you can configure to direct network traffic from your subnet. Each route specifies a destination and a target By default, every route table contains a local route for communication within the VPC Each subnet must be associated with a route table (at most one)Section 3: VPC networkingInternet gateway An internet fateway is a scalable, redundant, and highly availble VPC, allows communication between VPC and public internet.Two purposes: Provide a target in your VPC route tables for internet traffic Perform network address translations for intances that were assigned public PIv4 addressesTo make a subnet public, you attach an internet gateway to your VPC and add a route entry to the route table. Network Address Translation (NAT) gateway enables intances in a private subnet to connect to the public internet and prevent it from initation a connection.To create a NAT Gateway: Must specify the public subnet in which NAT gateway should live Must specify an elastic IP address to associate with the NAT gatewayAfter NAT gateway is created: Update the private subnet route tableCan use a NAT instance in a public subnet in your VPCVPC sharing Enables customers to share subnets with other AWS accounts (participant) in the same organization.VPC peering Enables you to privately route traffic between 2 VPCs.You can connect VPCs in your own AWS account, between AWS accounts, or between AWS RegionsRestrictions: IP spaces cannot overlap Transitive peering is not supported You can only have one peering resource between the same 2 VPCs.AWS Site-to-Site VPN By default, Amazon VPC cannot communicate with your own remote network enable by attaching a virtual private gateway to the VPC creating a custom route table updating security group rule creating an AWS site-to-site VPN connection configuring routing AWS Direct Connect Performance can be negatively affected if your data center is located far away from your AWS region AWS direct connect dedicated private connection between your network and one of the direct connect locations uses open standard 802.1q virtual local area networks VPC endpoints A VPC endpoit is a virtual device that enable you to privately connect to Amazon regional servicesAWS PrivateLink: Requires VPC interface endpoint Private connectivity between 2 VPCs, AWS services and on-premises appTwo types of endpoints: Gateway endpoints (Amazon S3 and Amazon DynamoDB) Interface endpoints (powered by AWS PrivateLink)AWS Transit Gateway A transit gateway is a network transit hub that you use to interconnect your VPCs and on-premises network.Section 4: VPC securitySecurity groups A security group acts as a virtual firewall that controls inboud and outbound traffic from your instance. Security groups have rules to manage instance traffic Default security groups are sealed shut to inbound traffic. we need to define rules. Security groups are stateful. The outbound traffic is always allowed.Network access control lists (network ACLs) Act at a subnet level. One-to-one relationship with subnet A network ACL has separate inbound and outbound rules, and each rule can either allow or deny traffic. Default network ACLs allow all inbound and outbound IPv4 traffic Network ACLs are statelessSecurity groups versus network ACLs Attribute Security Groups Network ACLs Scope Instance level Subnet level Supported Rules Allow rules only Allow and deny rules State Stateful (return traffic is automatically allowed, regardless of rules) Stateless (return traffic must be explicitly allowed by rules) Order of Rules All rules are evaluated before decision to allow traffic Rules are evaluated in number order before decision to allow traffic Section 5: Amazon Route 53DNS resolution It is the process of tranlsating an internal name to the corresponding IP address.Route 53 Is highly available and scalable Domain Name System (DNS) web service Is used to route end users to internet applications by transalting names into numeric IP addresses Is fully compliant with IPv4 and IPv6 Connects user requests to infrastructure running in AWS and also outside of AWS Is used to check the health of your resources Features traffic flow enables you to register domain nameSupported routing Simple routing Use in single-server environments Weighted routing Assign wights to resource record sets to specify the frequency Latency routing Help improve your global app Geolocation routing Route traffic based on location of your users Geoproximity routing Route traffic based on locations of your resources Failover routing Fail over to a backup site if your primary site becomes unreachable Multivalue answer routing Respond to DNS queries with up to eight healthy records selected at random Use case: Multi-region deployementDNS failoverImprove the availablity of your applications that run on AWS by: Configuring backup and failover scenarios for your own app Enabling highly available multi-region architectures on AWS Creating health checkDNS failover for a multi-tiered web appSection 6 Amazon CloudFrontContent delivery and network latency Challenge of network communication: network performance. Latency can happen depending on the geographical location of the user.Amazon CloudFront Fast, global and secure CDN service Global, network of edge locations and Regional edge caches Self-service model Pay-as-you-go pricingInfrastructureWhen a customer makes a demand, CloudFront respond with the IP address of the edge location closest to the customer. CloudFront obtains the data and copies it to the edge location. Edge locations Network of data centers that Cloudfronts uses to serve popular content quickly to customer Regional edge cach CloudFront location that caches content that is not popular enough to stay at an edge location. It is located between the origin server and the global edge location When data become stale, it is removed from the cache of the edge location Wrap-upWhich AWS networking service enables a company to create a virtual network within AWS? AWS Config Amazon Route 53 AWS Direct Connect Amazon VPC Answer keyword: AWS networking service Create a virtual network Answer 4." }, { "title": "Open Source: Comprendre, Contribuer", "url": "/cours/posts/open_source/", "categories": "tronc commun S8, Open Source", "tags": "tronc commun, Open Source, S8", "date": "2021-02-10 09:00:00 +0100", "snippet": "Lien de la note HackmdPar Lionel Laskelionel@lespot-bouygues.comIntroductionLionel LASKE Responsable Le Spot BOUYGUES Membre du board de l‚Äôorganisation Open source sugarlabs Auteur et Lead developpeur sugarizer 10 000 utilisateurs 80 contibuteurs Plateforme educative pour enfant Mentor Google Summer of Code depuis 2013Pourquoi ce cours ? Parce que l‚ÄôOpen Source est un phenomene mondial ! devenu culturel open data: open source lie a la data Wikipedia Open Street Map TousAntiCovid Parce que c‚Äôest un sujet complexe part de technique (Github) part de juridique modele economique Comment ca fonctionne ? Comment on gagne de l‚Äôargent avec des outils ouverts ? Pour nous faire partager son experiencePartie 1 - ComprendreQuizz TimeQuelle est la societe qui contribue le plus sur GitHub ? The Linux Foundation Google Microsoft RedHat Microsoft $1^{er}$ contributeur GitHub TypeScript Visual Studio Gode GitHub Npm Google $2^{nd}$ contributeur GitHub Android Angular TensorFlow Kubernetes Facebook React React Native GraphQL IBM RedHat Eclipse Apache Spark Pourquoi on fait de l‚Äôopen source ? L‚ÄôOpen Source est omnipresentAvantages de l‚ÄôOpen Source Cout d‚Äôusage Cout de developpement S‚Äôappuie sur d‚Äôautres developpeurs pour developper un outils Communaute Mettre un projet en open source: permet de developper une communaute Avancer plus vite sur l‚Äôoutils Innovation Plus facile d‚Äôinnover Beneficier des idees des autres Securite Peut etre a double tranchant Avoir le code ouvert: ‚ÄúVous pouvez me faire confiance‚Äù White hat trouvent des failles de securite Reversible Voir comment sont traitees nos donnees Definition Les 4 libertes fondamentales Liberte 0: Pouvoir executer le programme Liberte 1: Pouvoir etudier son fonctionnement Liberte 2: Pouvoir le redistribuer Liberte 3: Pouvoir le modifier et le redistribuer Comment s‚Äôassurer qu‚Äôun logiciel est Open Source ?Plusieurs licences possibles open source initative Free Software Foundation Approche pragmatique Approche Ethique Considerations techniques: logiciels de meilleurs qualites car plus de contributeurs et de reviewers Considerations idealistes: l‚Äôutilisateur doit garder le controle du logiciel Favoriser les modeles economiques Liberer les utilisateurs ‚Ä¶ en opposition au logiciel proprietaire Seul l‚Äôauteur peut acceder au code source (ou des partenaires sous NDA) Pour utiliser le logiciel vous devez accepter une licence qui: Interdit la redistribution/pret/revente Exemple: Licence WindowsHistoriqueQuizz TimeQui a invente le concept d‚ÄôOpen Source ? Steve Job Linus Torvald Bill Gates Richard Stallman Aucune des 4 reponses n‚Äôest fausse1960: Prehistoire Le hardware est tres cher L‚Äôinformatique est reservee aux chercheurs Le logiciel a une complexite limitee Le logiciel est disponible librement1970: Proprietaire Baisse du cout des ordinateurs Augmentation de la complexite des logiciels Apparition des 1er micro-ordinateurs Premieres licences proprietaire Seules les universites continuent a partager le codeAnecdote : An Open Letter to Hobbyusts par Bill Gates1980: Naissance 1983: annonce du projet GNU par Richard Stallman 1985: Creation de la Free Software Fundation 1987: Lancement de GCCAnecdote: l‚Äôimprimante de Stallman Richard Stallman est programmeur au AI Lab du MIT Il souhaite modifier le pilote d‚Äôune imprimante Xerox pour signaler automatiquement les bourrages papiers Il sollicite un collegue qui dispose du code source mais qui refuse ‚ÄúIl m‚Äôa explique qu‚Äôil s‚Äôetait engage a ne pas en donner de copier‚Äù car il avait une NDA avec Xerox ‚ÄúCe qui rendait l‚Äôenjeu important etait le caractere systematique et impersonnel de son refus, le fait qu‚Äôil s‚Äôetait engage d‚Äôavance a ne cooperer ni avec moi ni avec aucune autre personne‚Äù - R. Stallman 1990: Fondation 1991: Creation de Linux 1993: Lancement des distributions Debian, NetBSD, FreeBSD, RedHat 1994: Creation de MySQL 1995: Creation de PHP 1996: Creation d‚ÄôApache 1998: Lancement de Netscape 1999: Lancement de SourceForce2000: Explosion 2002: Lancement Firefox 2004: Lancement de la distribution Ubuntu sur base Debian 2005: Lancement du projet Git 2007: Lancement de Android, sur une base Linux 2008: Lancement de GitHub 2008: Lancement de Chromium en meme temps que Chrome2010: Evidence 2010: Lancement de nom 2013: Revelations de Edward Snowden 2014: Lancement de Signal 2018: Rachat de Github par Microsoft pour 7,5 milliards de $ 2019: Rachat de RedHat par IBM pour 34 milliards de $LicencesQuizz TimeCombien existe-t-il de licences Open Source ‚Äúofficiellement‚Äù reconnues ? 3 10 100A qui appartient votre code ? A votre ecole si vous etes etudiants A votre employeur si vous etes salaries A vous si vous le faites chez vous Sauf contrat employeur specifique Pour permettre a d‚Äôautres d‚Äôy contribuer, il faut donc utiliser une licence ouverte. Permissive Copyleft Tout le monde peut modifier Tout le monde peut modifier Les versions peuvent ne pas etre modifiables Tout le monde doit pouvoir modifier les versions modifiees Ce que decrivent les licences Les regles de mention de paternite du programme Les regles pour modifier le programme Les regles pour redistribuer le programme Les regles pour associer d‚Äôautres licences dans le meme programme La protection contre les brevetsCartographie des licences Open SourceAnecdote: la controverse React React est lance par Facebook en 2013 sous Apache v2 En 2014 React passe sous licence BSD avec une note sur l‚Äôutilisation des brevets: Permet d‚Äôutiliser les brevets possedes par Facebook Facebook s‚Äôautorise a vous retirer les droits d‚Äôutilisation si vous menez une action en justice contre eux ou contre une autre entreprise utilisant React En 2015 Facebook ajoute une note supplementaire a la licence pour eviter les confusions En 2017 la fondation Apache prend position contre l‚Äôutilisation de React car il n‚Äôest pas sous une licence Open Source En novembre 2017, React passe sous licence MITAnecdote: la licence SSPL MongoDB MongoDB est lance en 2009 sous licence AGPL v3 Les clouds d‚ÄôAmazon, d‚ÄôIBM, ‚Ä¶ louent des instances MongoDB sans que MongoDB en tire benefice En Octobre 2017, MongoDB devient une societe cotee En Octobre 2018 passe son code sous licence SSPL et soumet cette nouvelle licence a l‚ÄôOSI La licence impose qu‚Äôun fournisseur de cloud utilisant MongoDB ouvre toute la stack technique permettant son herbegement En Mars 2019 l‚ÄôOSI refuse de consider la licence SSPL comme une licence Open Source RedHat, Debian, Fedora et les autres distributions Linux excluent MongoDB de leurs distributions En Janvier 2019, Amazon lance DocumentDB, une base de donnees NoSQL compatible MongoDBGouvernanceQuizz TimeQui d√©cide des contributions accept√©es dans le Kernel Linux ? Linus Torvald seul Le board de la Linux Foundation Les entreprises qui contribuent au KernelLe modeles de gouvernance Open SourceDictateur bienveillant ‚ÄúBDLF‚Äù: Benevolent Dictator For Life Le Dictateur est generalement l‚Äôauteur initial A le dernier mot sur toutes les grandes decisions Evite des discussions sans fin‚Ä¶ La qualite et le succes du projet dependent beaucoup de la sagess du dictateurExemple: Gouvernance Linux Jeremy Malcolm - Internet Governance Forum ‚ÄúTorvalds possesses ultimate authority to decide which contributions to the Linux operating system kernel should be accepted and which should be refused‚Äù ‚ÄúThe Linux kernel development process is neither anarchistic nor consensual: if Torvalds does not like a patch, it does not go in to the kernel‚Äù Gouvernance Communautaire Pilotage ouvert et public (mailing list, IRC, ‚Ä¶) Choix collegiaux: Qui peut contribuer Qui peut commiter Qui peut resoudre les conflits Recherche de consensus dans la decisions Favorise la Meritocratie Release sont generalement mois frequentes car circuit de decision plus longExemple: Gouvernance FreeBSD Composition: Contributeurs (plusieurs milliers) Commiters (500) Core team (9) Les Commiters approuvent les PR des Contributeurs Les Commiters elisent la Core Team La Core team choisi les Commiters parmi les Contributeurs La Core team decide des orientations du projetGouvernance Entreprise Une seule entite controle la Conception, le Developpement et les Release Contributions externes pas forcement bienvenue Roadmap pas necessairement publique Discussions internes et controverses pas forcement publiquesExemple: Gouvernance AOSP ‚ÄúThe Android Open Source Project (AOSP) includes individuals working a variety of roles. Google is responsible for Android product management and the engineering process for the core framework and platform; however, AOSP considers contributions from any source, not just Google.‚Äù ‚ÄúProject leads are senior contributors who oversee the egineering for individual Android projects.‚ÄùModeles EconomiquesQuizz TimeQuelle est la soci√©t√© qui tire le plus de revenu de l‚ÄôOpen Source ? Google Docker RedHatRedHat: 3,5 milliards de $ de revenus par anGagner de l‚Äôargent avec l‚ÄôOpen Source ? Vente de licences Une version ‚ÄúCommunity‚Äù gratuite avec une licence copyleft Une version ‚ÄúEntreprise‚Äù payante avec plus de features et une licence permissive Vente de services Hosting ou mode SaaS Formations/Certifications Support Autres Publicite Dons/Mecenat Droit d‚Äôusage de la marque Exemple:Elastic SearchIntelliJ IDEAVLC ‚ÄúLe logiciel Francais le plus utilise au monde‚Ä¶ et le moins rentable‚Äù J.B. Kempf 1 million de telechargements/jour 450 millions d‚Äôutilisateur Plus de 3 milliards de telechargement Developpe en 1997 a l‚ÄôEcole Centrale Paris Sous GPL en 2001 Gere par l‚Äôassociation VideoLan en 2008 Creation en 2012 de la societe VideoLabs 18 employes, 1m d‚Äôeuros de CA Monetise la terchnologie et les utilisateurs VLC pour delivrer des services Anecdote: Heartbleed Vulnerabilite dans OpenSSL en 2011 Decouverte en avril 2014 OpenSSL etant utilise tres largement (Nginx, Apache, Android, ‚Ä¶) la faille touche 17% des serveurs wen et 800.000 objets connectes En 2012 la Open SSL Foundation touchait 2.000$/an pour financer ses contributeurs Lancement en 2014 de la Core Infrastructure Initiative Idee de la Linux Foundation 3.000.000$/an pour financer des projets Open Source ‚Äúcore‚Äù Partie 2 - ContribuerPourquoi contribuer a l‚ÄôOpen Source ? Ameliorer ses competences Participer au bien commun Recontrer des gens du monde entier Apprendre ou apprendre aux autres Ameliorer les outils qu‚Äôon utilise Se faire connaitreQuel projet choisir ?Quizz TimeQuel est le pourcentage estim√© de projets Open Source actifs ? 30% 10% 5% La plupart des projets Open Source sont des echecs‚Ä¶Les causes les plus courantes: Ne repond pas a un vrai besoin Plus assez de developpeuts interesses (ou le developpeur principal s‚Äôen desinteress) Le projet est depasse techniquement, un competiteur fait mieux Manque de documentation Manque de leadership, pb de gouvernance, conflits Manque de temps/d‚Äôargent Ce fort taux d‚Äôechec n‚Äôest pas necessairement une mauvaise chose, beaucoup d‚Äôidees peuvent en decoulerIdentifier les signes vitaux d‚Äôun projet Regarder les statistiques du projet Watch / Star / Fork / Used by Verifier les commits De quand date le dernier commit ? Combien y a-t-il de contributeurs ? Verifier les issues Combien y a-t-il d‚Äôissues ? Sont-elles recentes ? Sont-elles fermees regulierement ? Verifier les PR Combien y a-t-il de PR ? Sont-elles recentes ? Exemple:React contributors vs Vue.js contributorsStatistiques Angular sur Synopsis Open HubVerifier que le projet est accueillant Est-ce un projet Open Source ? Y a-t-il une licence ? Comment acceuille t-il les contributeurs ? Y a-t-il un guide du contributeur ? un code de conduite ? Y a-t-il de la documentation ? Y a-t-il des issues tagguees ‚Äúgood first issue‚Äù ? Comment les mainteneurs repondent aux contributions ? Repondent-ils rapidement aux questions/issues ? Repondent-ils amicalement ? Y a-t-il des dicussions sur les issues/PR ? Remercient-ils les gens pour leur contribution ? Exemple: code de conduite KubernetesComment contribuer ?Checklist: demarrer une contribution Installer l‚Äôapplication/le projet S‚Äôassurer que c‚Äôest la derniere version Jouer avec l‚Äôapplication/le projet Lire la doc S‚Äôabonner aux listes de diffusion, forum, IRC, slack, ‚Ä¶ Commenter des posts/issues C‚Äôest deja une contribution ! Declarer une issue Verifier qu‚Äôil n‚Äôy a pas deja une issue similaire Indiquer les etapes pour la reproduire et l‚Äôenv. de test Faire une Pull RequestCreer une Pull Request Les Pull Request (PR) sont la base des contributions Open SourceExercie: First Contributions Un site pas a pas pour realiser votre $1^{ere}$ Pull Request Faites une PR pour ajouter votre nom a la liste des contributeursExemple: Hacktober Fest Evenement organise par Digital Ocean pour inciter a contribuer a des projets Open Source Chaque annee du 1$^{er}$ au 31 Octobre Les projets interesses inscrivent leur repo et tagguent des issues ‚Äúhackotberfest‚Äù Les 70 000 premiers participants qui font 4 PR gagnent un t-shirtLe Google Summer Of CodeQu‚Äôest-ce que c‚Äôest ? Le Google Summer of Code (GSoC) est un programme ‚Äúonline‚Äù international destine a encourager les etudiants des ecoles et universites a participer au developpement de projets Open Source.Objectifs du programme Pour les organisations Open Source: identifier chaque annees de nouveaux dev Pour les etudiants: participer au dev de projets Open Source, se construire une experience et un reseau, etre remunere (~4,000 euros/2 mois) Pour Google: soutenir le monde de l‚ÄôOpen SourceComment ca marche ? Les organisations faisant de l‚ÄôOpen source font la demande a Google pour etre des organisations du GSoC Google choisit les organisations qui participent Les etudiants soumettent leurs candidatures pour realiser les projets proposes Les organisations choisissent les meileurs etudiants Les etudiants developpent, encadres par les mentors des organisationsQuelques organisations participant au GSoCComment etre retenu au GSoC ? Commencer a contribuer avant Mars/Avril Se presenter a l‚Äôorganisation Mailing list, forum Multiplier les contributions (PR, issue) Bien comprendre le projet propose Echanger avec les mentors Suggerer des solutions Realiser un prototype Passer du temps a rediger sa proposition Demander une relecture de sa propositionConclusion L‚ÄôOpen Source est un phenomene culturel Comprendre son fonctionnement est indispensable Contribuer est une source de satisfaction et un vrai plus pour monter en competence Questions/ReponsesDans le cas o√π la licence est ajout√©e apr√®s la cr√©ation du repository, son effet est-il r√©troactif ? La premi√®re version (les premiers commits avant la licence) du projet est-elle concern√©e par la nouvelle licence ? Non, la licence ne s‚Äôapplique qu‚Äôaux versions actuellesOn a parl√© de l‚Äôopen source en terme de software. Qu‚Äôen est il du hardware ? Je ne peux pas vous en apprendre plusComment sera evalue le cours ? Aucune idee, a voir avec la pedagoCe n‚Äôest pas fini !Pour en savoir plus: retrouver la version integrale sur YouTubeFinal QuizzAvez-vous maintenant envie de devenir contributeur ? Oui Non Ne sais pas" }, { "title": "TD AWS 1 - Rappel des modules 1, 2, 3 et 4", "url": "/cours/posts/aws_td_1/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 18:30:00 +0100", "snippet": "Lien de la note HackmdModule 1 Le cloud c‚Äôest la democratisation de la VM. 2006 par AWS qui parle de cloud computing Le cloud est une revolution car on peut acheter de la puissance de calcul directementExemple: une entreprise se dvpt, on peut s‚Äôattendre a ce que l‚Äôevolution de la puissance de calcul soit lineaire. En pratique, la courbe reel est tres aleatoire Zone verte: ‚Äúje paye pour rien‚Äù Ensuite besoin de plus de machines mais il faut les commander, faire livrer, installer etc. (15j au mieux) $\\rightarrow$ arrive apres la bataille et repayer une fortune pour rien Le cloud veut regler ce probleme. Le client ne veut pas des machines mais de la puissance de calcul (machine virtuelle) -AmazonPermet l‚Äôelasticite: la puissance de calcul suit en live le besoin Le cloud, c‚Äôest la transformation du capex en opex (pay-as-you-go) Capex: capital expenses One-time and upfront cost Investment in capital Opex: operational expenses Regular cost Exemple: Croquetor, leader mondial de la vente de croquettes en ligneBesoin de: Data center (equinix) Provisioning (obtention des machines) Configurer les machines Deploy App (et la coder au passage)Avant le cloud: avait son propre data centerLe coeur de l‚Äôentreprise c‚Äôest l‚Äôapp, du moment qu‚Äôil y a As a Service, on ne peut pas outsourcer le reste ? App SaaS Deploy PaaS (Heroku) Configure ¬† Provisioning IaaS (Compute, network, storage) Data center (Equinix) Heroku: historiquement le premier, git push de l‚Äôapplication et le serveur git deploy Outlook est un SaaS, on n‚Äôa pas a l‚Äôinstaller. En tant que end user, on consomme le service d‚Äôun SaaS, qui utilise probablement un PaaS qui utilise lui-meme le IaaSModule 2Module 3 Infrastructure globale: on a des Regions Data replication Dans une Region: Availability Zones (data center) Best practice: replique au sein de Availability Zones edge locations: cache et CDN Ce n‚Äôest PAS dans les data centers Sainte trinite infra: Compute Network Storage IaaS+: Database" }, { "title": "StartUp Lab", "url": "/cours/posts/startup_lab/", "categories": "tronc commun S8, StartUp Lab", "tags": "tronc commun, StartUp Lab, S8", "date": "2021-02-09 11:00:00 +0100", "snippet": "Lien de la note HackmdPresentation youtube.Daniel Jarjoura Startup Lab Founder (2013) EPITA Alumni (2006)3 chiffres 5,4 milliards d‚Äôeuros investis dans les entreprises tech FROu va cet argent ?Quels sont les autres financements de ces entreprises ? Il n‚Äôy a jamais eu de meilleur moment pour creer une startup tech 22,7 % de fondateurs issus d‚Äôune ecole d‚Äôinge Pas besoin de faire une ecole de commerce pour reussir, mais trop peu d‚Äôingenieurs osent se lancer 12 millionaires crees depuis la creation du StartUp Lab C‚Äôest possible a EpitaLe Startup Lab c‚Äôest quoi ?Etudiants qui ont envie d‚Äôentreprendre a avoir un produit qui fonctionne et repond a une problematique bien definie en 1 an. Un suivi hebdomadaire Des masterclasses thematiques Des rencontres avec des fondateurs tech Un accompagnement de l‚ÄôEPITA 100% remote en 2020 Restera en remote car n‚Äôa pas eu d‚Äôimpact sur les startups creees Nouveaute cette annee: limite fixe, 8 equipes seront recrutees Option 1: 1 equipe + 1 idee Profil des membres de l‚Äôequipe Valeur ajoutee de l‚Äôideee Niveau technique de l‚Äôidee Ouverture d‚Äôesprit de l‚Äôequipe Option 2: 1 equipe + 0 idee Profil des membres de l‚Äôequipe FOCUS: Developer Startups Option 3: 0 equipe + 0 idee Recrutement de personnes pour le StartUp Lab Head of communication Head of sales Head of product 100% des premieres idees ne sont pas bonnes et ne survivent pas au 1er contact avec les clients.La partie la plus difficile est le contact avec les clients." }, { "title": "AWS Module 4 - AWS Cloud Security", "url": "/cours/posts/aws_module_4/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 10:30:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS shared responsibility modelAWS: Security of the cloud Physical facilities and system Hardware, software for running AWS services Customers: Securing app and datasets in the cloud Data encryption in transit from one systeme to another Use Amazon Tools Network configured for security Firewall configuration and security of OSAWS responsability: Security of the cloudAWS responsibilites: Physical security of data centers Controler, need-based access Hardware and software infrastructure Storage decommissioning, host operating, system (OS) access logging, and auditing Network infrastructure Intrusion detection Virtualization infrastructure Instance isolation Between customers workloads Customer responsibility: Security in the cloudCustomer responsabilities: Amazon Elastic Compute Cloud (Amazon EC2) instance operating system Including patching, maintenance Applications Passwords, role-based access, etc. Security group configuration OS or host-based firewalls Including intrusion detection or prevention systems Network configurations Account management Login and permission settings for each user Service characteristics and security responsibilityInfrastructure as a service (IaaS) Customer has more flexibility over configuring networking and storage settings Customer is responsible for managing more aspects of the security Customer configures the access controlsPlatform as a service (PaaS) Customer does not need to manage the underlying infrastructure AWS handles the operating system, database patching, firewall configuration, and disaster recovery Customer can focus on managing code or dataSoftware as a service (SaaS) Sofware is centrally hosted Licensed on a subscription model or pay-as-you-go basis Services are typically accessed via web browser, mobile app, or application programming interface (API) Customers do not need to manage the infrastructure that supports the serviceSection 2: AWS Identity and Access Management (IAM) Use IAM to manage access to AWS resources A resource is an entity in an AWS account that you can work with Example resources; An Amazon EC2 instance or an Amazon S3 bucket Example: control who can terminate Amazon EC2 instances Define fine-grained access rights Who can access the resours Which resources can be accessed and what can the user do to the resource How resources can be accessed IAM is a no-cost account featureIAM: Essential components IAM user A person or application that can authenticate with a AWS account IAM group A collection of IAM users that are granted identical authorization IAM policy The document that defines which resources can be accessed and the level of access to each resource Created independently than users and groups IAM role Usefule mechanism to grant a set of permissions for making AWS service requests Grant temporary access to a service Similar to sudo in Linux Authenticate as an IAM user to gain accessWhen you define an IAM user, you select what types of access the user is permitted to use.Can use either programmatic access, AWS Management Console access, or both.Programmatic access Authenticate using: Acces key ID Secret access key Provides AWS CLI and AWS SDK accessAWS Management Console access Autheticate using: 12-digit Account ID or alias IAM user name IAM password If enabled multi-factor authentificatuin (MFA) prompts for an authentification codeIAM MFA MFA provides increased security In addition to user name and password, MFA requires a unique authentification code ot access AWS serviceAuthorization: What actions are permittedAfter the user or application is connected to the AWS account, what are they allowed to do ?IAM: Authorization Assign permissions by creating an IAM policy Permissions determine which resources and operations are allowed: All permissions are implicitly denied by default Is something is explicitly denied, it is never allowed Best practice: Follow the principle of least privilege.Note: the scope of IAM service configurations is global. Settings apply accross all AWS RegionsIAM Policies An IAM policy is a document in JSON that defines permissions Enables fine-grained access control 2 types of policies identity-base resource-based Identity-based policies * Attach a policy to any IAM entity An IAM user, an IAM group or an IAM role * Policies specify; Actions that may be performed by the entity Actions that may not be performed by the entity * A single policy can be attached to multiple entities * A single entity can have multiple policies attached to it Resource-based policies * Attached to a resource (such as an S3 bucket) IAM policy example Any actions not explicitly allowed are denied $\\rightarrow$ out-of-the-box access are always deny (implicit deny) Any actions explicitly denied are always denied If there is a competition betwee an allowed statement and a deny statement, the deny statement always wins Resource-based policies Identity-based policies are attached to a user, group or role Ressource-based policies are attached to a resource (not to a user, group or role) Characteristics of resource-based policies Specifies who has access to the resource and what actions they can perform on it The policies are inline only, not managed Resource-based policies are supported only by some AWS servicesIAM permissionsHow IAM deterines permissions:IAM groups An IAM group is a collection of IAM users A group is used to granted by attaching IAM policy or policies to the group A user can belong to multiple groups There is no default group Groups cannot be nestedIAM role An IAM role is an IAM identity with specific permissions Similar to an IAM user attach permissions policies to it Different from IAM user Not uniquely associated with one person Intended to be assumable by a person, application or service Role provides temporary security credentials Examples of how IAM roles are used to delegate access Used by an IAM user in the same AWS account as the role Used by an AWS service (such as Amazon EC2) in the same account as the role Used by an IAM user in a different AWS account than the role Example use of an IAM roleScenario: An app that runs on an EC2 instance needs access to a S3 bucketSolution: Define an IAM policy that grants read-only access to the S3 bucket Attach the policy to a role Allow the EC2 instance to assume the roleSection 3: Securing a new AWS accountAWS account root user access versus IAM access Best practice: Do not use the AWS account root user except when necessary Access to the account root user requires logging in the the email address (and password) that you used to create the accout Example actions that can only be done with the account root user: Update the account root user password Changed the AWS Support plan Restore an IAM user‚Äôs permissions Change account settings (for example, contact info, allowed Regions) Securing a new AWS account: Account root userStep 1: Stop using the account root user as soon as possibleThe account root user has unrestricted access to all resourcesTo stop using the account root user: While you are logged in as the account root user, create an IAM user for yourself. Save the access keys if needed Create an IAM group, give it full administrator permissions, and add the IAM user to the group Disable and remove your account root user access keys, if they exist Enable a password policy for users Sign in with your new IAM user credentials Store your account root user credentials in a secure placeStep 2: Enable multi-factor authentication (MFA) Require MFA for your account root user and for all IAM users You can also use MFA to control access to AWS service APIs Options for retrieving the MFA token Virtual MFA-compliant applications Google Authenticator Authy Athenticator (Windows phone app) U2F security key devices YubiKey Hardware MFA options Key fob or dispLy card offered by Gemalto Step 3: Use AWS CloudTrail CloudTrail tracks user activity on your account Logs all API requests to resources in all supported services your account Basic AWS Cloud event history is enabled by default and is free It contains all management event data on latest 90 days of account activity To accces CloudTrail Log in to the AWS Management Console and choose the CloudTrail service Click Event History to view, filter and search the last 90 days of events To enable logs beyond 90 days and enable specified event alerting, create a trail From the CloudTrail Console trails page, click Create trail Give it a name, apply it to all Regions, and create a new Amazon S3 bucket for log storage Configure access restrictions on the S3 bucket (for example, only admin users should have access) Step 4: Enable a billing report, such as the AWS Cost and Usage Report Billing reports provide info about your use of AWS resources and estimated costs for that use AWS delivers the reports to an Amazon S3 bucket that you specify report is updated at least one per day The AWS Cost and Usage Report tracks your AWS usage and provides estimated charges associated with you AWS account, either by the hour or by the daySection 4: Securing accountsAWS Oganizations AWS Organizations enables you to consolidate multiple AWS accounts so that you centrally manage them Security features of AWS Organizations: Group AWS accounts into organizational units (OUs) and attach different access policies to each OU Integration and support for IAM: permissions to a user are the intersection of what is allowed by AWS Organizations and what is granted by IAM in that account Use service control policies to establish control over the AWS services and API actions that each AWS account can access Service control policies Offer centralized control over accounts: limit permissions that are available in an account that is part of an organization Not a subsitute for Identity and Access management configurations ! In JSON Ensure that accounts compuly with access control guidelines SCPs are similar to IAM permissions policies They use similar syntax However, an SCP never grants permissions Instead, SCPs specify the maximum permissions for an organization AWS Key Management Service (AWS KMS) Enables you to create and manage encryption keys Enables you to control the use of encryption across AWS services and in your applications Integrated with AWS CloudTrail to log all key usage Uses hardware security modules (HSMs) that are validated by Federal Information Processing Standards (FIPS) 140-2 to protect keysAmazon Cognito Adds user sign-up, sign-in and access control to your web and mobile app Scales to millions of users Support Sign-in with social identity providers, such as Facebook, Google and Amazon, and enterprise identity providers, such as Microsoft Active Directory via Security Assertion Markup Language (SAML) 2.0 Help meet security requirementesAWS Shield is a managed distributed denial of service (DDoS) protection service Safeguards applications running on AWS Provides always-on detextion and automatic inline mitigations AWS Shield Standard enabled for at no additional cost. AWS Shield Advanced is an optional paid service Available to all customers Use it to minimize application downtime and latencySection 5: securing data on AWSEncrytpion of data at rest Encryption encodes data with a secret key, wich makes it unreadable Only those who have the secret key can decode the data AWS KMS can manage you secret keys AWS supports encryption of data at rest Data at rest = Data stored physically Can encrypt any data supported by AWS key management service You can encrypt data stored in any service that is supported by AWS KMS Amazon S3 Amazon EBS Amazon Elastic File System (Amazon EFS) Amazon RDS managed databases Encryption of data in transit Encryption of data in transit (data moving across a network) Transport Layer Security (TLS) (formerly SSL) is an open standard protocol AWS Certificate Manager provides a way to manage, deploy and renew TLS or SSL certificates Secure HTTP (HTTPS) creates a secure tunnel uses TLS or SSL for the bidirectional exchange of data AWS services support data in transit ecryptionSecuring Amazon S3 buckets and objects Newly created S3 buckets and objects are private and protected by default When use cases require sharing data objects on Amazon S3 It is essential to manage and control the data access Follow the permissions that follow the principle of least privilege and consider using Amazon S3 encryption Tools and options for controlling access to S3 data include Amazon S3 Block Public Access feature IAM policies Bucket policies: when can‚Äôt log with IAM Access control lists (ACLs): a legacy access control mechanism AWS Trusted Advisor bucket permission check: a free feature Section 6: Working to ensure complianceAWS compliance programsCustomers are subject to many different security and compliance regulations and requirements AWS engages with certifyin bodies and independent auditors to provide customers with detailed infromation about the policies, processes, and controls that are established and operated by AWSCompliance programs can be brodaly categorized Certifications and attestations Assessed by a third-party, independent auditor Examples: ISO 27001, 27017, 27018 and ISO/IEC 9001 Laws, regulations, and privacy AWS provides security features and legal agreements to support compliance Examples: EU General Data Protection regulation (GDPR), HIPAA Alignments and framework Industry- or function-specific security or compliance requirements Examples: Center for Internet Security (CIS), EU-US Privacy Shield certified AWS Config Assess, audit and evaluate the configurations of AWS resources Use for continuous monitoring of configurations Automatically evaluate recorded configurations versus desired configurations Review configuration changes View detailed configuration histories Simplify complicance auditing and security analysisAWS Artifact Is a resource for compliance-related information Provide access to security and compliance reports, and select online agreements Can access example downloads: AWS ISO certifications Payment Card Industry (PCI) and Service Organization Control (SOC) reports Access AWS Artifact directly from the AWS Management Console Under Security, Identity \\&amp;amp; Compliance Accept agreements with AWS on multiple accountsWrap-upSample exam questionWhich of the following is AWS‚Äôs reponsibility under the AWS shared responsibility model ? Configuring a third-party app Maintaining physical hardware Securing app access and data Managing custom Amazon Machine Image (AMIs) Answer keywords: AWS‚Äôs responsibility AWS shared responsibility model Answer 2." }, { "title": "AWS Module 3 - AWS Global Infrastructure Overview", "url": "/cours/posts/aws_module_3/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-09 09:00:00 +0100", "snippet": "Lien de la note HackmdSection 1: AWS Global Infrastructure The AWS Global Infrastructure is designed and built to deliver a flexible, reliable, scalable and secure cloud computing environmnent with high-quality global network performanceAWS Region An AWS Region is a geographical area Data replication across Regions is controlled by you Communication between Regions uses AWS backbone network infrastructure Each region provides full redundancy and connectivity to the network A region typically consists of two or more Availability ZoneSelecting a Region Might be legal requirements Local laws can restrict the Region Ex: European Union Latency Can test with Cloud Ping Not all AWS services are available depending on the regionAvailability Zones Each Region has multiple Availabiity Zones Each Availability Zone is fully isolated partition of the AWS infrastructure 69 Availability Zones worldwide Availability Zones consist of discrete data centers Usually 3 They are designed for fault isolation They are interconnected with other Availability Zones by using high-speed private networking Dedicated fiber You choose your Availability Zones AWS recommends replicating data and resources across Availability Zones for resiliency Protected for tornadoes, lightning, earthquakes‚Ä¶ AWS data centers AWS data centers are designed for security Data centers are where the data resides and data processing occurs Each data has redundant power, networking and connectivity, and is housed in a separate facility A data center typically has 50,000 to 80,000 physical serversAWS uses custom netowrking equipment source from multiple ODMs. ODM: Original Device ManufacturersDesign and manufacture product based on specifications from a second company. The second company rebrand the products for sale.Points of Presence AWS provides a global network of 187 Points of Presence locations Consists of 176 edge locations and 11 Regional edge caches Used with Amazon CloudFront A global Content Delivery Network (CDN) that delivers content to end users with reduced latency Regional edge caches used for content with infrequent accessAWS infrastructure features Elasticity and scalability Elastic infrastructure; dynamic adaption of capacity Scalable infrastructure; adpats to accomodate growth Fault-tolerance Continues operating properly in the presence of a failure Built-in redundancy of components High availability High level of operational performance Minimize downtime No human intervention Section 2: AWS services and service category overviewAWS foundational servicesAWS categories of servicesStorage service category Amazon Simple Storage Service (Amazon S3) Object storage Scalability, data availbility and performance Amazon Elastic Block Store (Amazon EBS) high performance block storage Used with Amazon EC2 Amazon Elastic File System (Amazon EFS) Scalable file system (NFS) Use with AWS Cloud Services Amazon Simple Storage Service Glacier Extremely low-cost Data archiving Compute service category Amazon EC2 Resizable compute capacity Amazon EC2 Auto Scaling Automaticaly add or remove EC2 instances Amazon Elastic Container Service Supports docker container Amazon EC2 Container Registry (ECR) Fully managed docker container registry AWS Elastic Beanstalk Deploying and scaling web applications AWS Lambda Run code without servers No charge when the code is not running Amazon Elastic Kubernetes Service (Amazon EKS) Deploy, manage and scale applications using Kubernetes AWS Fargate Run container without having to manage servers Database service category Amazon Relational Database Service (RDS) Relational database in the cloud Scalable Automating database setup, patching, back-ups Amazon Aurora MySQL and PostreSQL 5 time faster than MySQL 3 times faster than PostreSQL Amazon Redshift Analytic queries against petabytes of data Fast Amazon DynamoDB NoSQL database Single digit performance Networking and content delivery service category Amazon VPC Isolated sections AWS Cloud Elastic Load Balancing Automatically distributes incoming application traffic Amazon CloudFront Delivery network (CDN) Secures data to cutsomers AWS Transit Gateway Connect Amazon VPC and on-premises network Amazon Rout 53 Scalable cloud domain name system Translate URL to IP addresses AWS Direct Connect Established dedicated private network AWS VPN Secure private tunnel to AWS global network Security, identity and compliance service category AWS Identity and Access Management (IAM) Enables you to manage access AWS Organizations Restricts actions and services allowed in your account Amazon Cognito Let you add user authentification and access control to web and mobile apps AWS Artifact On-demand access to AW security and compliance reports AWS Key Management Service (KMS) Create and manage encryption keys AWS Shield Managed distributied denial of service protection service AWS cost management category AWS Cost and Usage Report Set AWS cost and usage data AWS Budget Set custom budget AWS Cost Explorer Visualize and manage AWS cost and usage Management and governance service category AWS Management Console Web-based user interface for accessing your AWS account AWS Config Track resource inventory Amazon CloudWatch Monitor resources and app AWS Auto Scaling Scale multiple resources to meet demand AWS Command Line Interface (CLI) Unified tool to manage AWS services AWS Trusted Advisor Optimize perfomance and security AWS Well-Architected Tool Reviewing and improving workloads AWS CloudTrail Track user activity an API usage Wrap-up videoSample exam questionWhich component of AWS global infrastructure does Amazon CloudFront use to ensure low-latency delivery ? AWS Regions AWS edge locations AWS Availability Zones Amazon Virtual Private Cloud (Amazon VPC) Answer keyword: components of AWS global infrastructure CloudFront: AWS service low-latency: benefit provided by the component Answer: 2." }, { "title": "GPRO - Refresh from ing1 classes", "url": "/cours/posts/gpro_refresh/", "categories": "tronc commun S8, GPRO", "tags": "tronc commun, GPRO, S8", "date": "2021-02-08 14:00:00 +0100", "snippet": "Lien de la note HackmdRefresh du cours de GPRO de l‚Äôing1What is a Project ? Un projet est une entreprise temporaire initiee dans le but de fournir un produit, un service ou un resultat unique.Exemple: Bridge Railroad Apollo Vaccine Mobile Ap Web Site NOT a project: OperationsProject ManagementA pragmatic approach vs ‚ÄúJust do it!‚ÄùA quoi ca nous sert le project management ? En entreprise, travail toujours sur un projet, on aborde le project management de facon genericCharacteristics of a project Scope Qu‚Äôest-ce qu‚Äôon veut faire ? Comment on doit le faire ? Time S‚Äôorganiser pour livrer le projet a une deadline Cost Realiser le projet avec le budget Parties prenantes - Stakeholders Toute personne ayant une influence sur le projetDans les parties prenantes: Pour une application, les utilisateurs Dans un stage, le maitre de stageProject life cycleScope: Cadre du projet Pour une app, si on veut qu‚Äôelle tourne sur IOS, Android, etc.Plannification: Organiser le travail Gros du boulot du chef de projetExecute/control: Commencer a developper Suivre le planPM Classic or AGILE ?BOTH !Classic predictive Liste de fonctionnalites precises Decoupe en lots de travaux Partage le travail Predictive car on prevoit tout des le depart.Agile Methode cyclique Developpe par cyclesMethode quand on est pas certain du but finalAgile ScrumUn sprint dure maximum un mois et a chaque sprint on livre un bout de logiciel qui fonctionneQUIZZ 1Parmi toutes ces realisations quelle est celle qui N‚ÄôEST PAS un projet ? Modifier une application existante pour introduire une toute nouvelle fonctionnalite Construire un nouveau DATACENTER Asssurer recurreement la mise en production de toutes les nouvelles applications, ou de nouvelles versions pour la corporation qui vous emploie Implementer une nouvelle application Mettre en oeuvre une nouvelle comptabilite sur SAPPhase 1: InitiateUnderstand the meaning of the projectProject CharterFiche de route du projetContient des infos detaillees: Objectifs Dates cles Parties prenantesUne objectif flou et vous ne savez pas ce qu‚Äôon attend de vousLe client vous pilote sans donner une vision claire du projetVous avez le Droit et le Devoir de collecter les informations de comprehension du PROJECT CHARTERProject Charter contents Project purpose Measurable project objectives and related success criteria High0level requirements Fonctionnalites definies de maniere large High-level project decription, boundaries, and key deliverables Summary milestone schedule Key stakehodler list Clients Manager Les gens qui travaillent sur le projet Overall project risk Project approval requirements Faire valider le projet une fois fini ExamplesExemple 1 - PFEE MTI Bouyfues Telecom 2020 Presente d‚Äôabord le contexte Problematiques Baisses des ventes suite a des promotions agressives de la concurrence Veille concurrentielle faite a la main Detection tardive des actions des concurrentes Objectifs du projet Ameliorer la capacite d‚Äôanalyse des marketplaes Reduire le temps de reaction face aux promotions agressive des concurrentes Grandes lignes du projet Visualiser les evolutions de prix Predire l‚Äôevolution des prix Alerter l‚Äôutilisateur de changement de prix Disposer d‚Äôun module d‚Äôopti des prix sous contraintes Planning des Jalons principaux Risques globaux Risque de livraison d‚Äôun projet difficilement maintenable Risque que le scraping soit peu durable Risque que la realisation ne corresponde pas aux attentes a cause d‚Äôun besoin faiblement ecrit Critere de sortie du projet Les differents livrables sont fonctionnels dans une version pilote de production disponible sur l‚Äôenv AWS de l‚Äôentreprise Exemple 2 Perimetre TimelinePhase 2: ScopeProduct Scope (Perimetre Produit) pour un logiciel applicatif: Exigences fonctionnelles Contraintes (techniques, de qualite, projet)Exigence fonctionnelle Ce que le client attend comme fonction de notre produitExemples pour une application: Permet de creer un compte Permet de rejoindre un groupe de discussiom Permet de prendre RDV Exigence fonctionnelle N‚ÄôEST PAS une specifite fonctionnelle.Get the product scopeSituation 1: Customer team provides fully Documented Product/Project Scope Dev team reviews the Scope with appropriate Product Owner Collecting requirements - Recueillir les exigences Fromalizing the requirements - formaliser les exigences Tableau des exigences ExempleAgile Methodology: The product backlogUser story En tant que &amp;lt;qui&amp;gt;, je veux &amp;lt;quoi&amp;gt; afin de &amp;lt;pourquoi&amp;gt;.Difference GILE: On peut affiner au fur et a mesure les exigences en avancant dans la release.ExempleCompleter les Product Backlog ou les tableaux d‚Äôexigence4 types d‚Äôexigences (projet dev de logiciel) Exigences Fonctionnelles Contraintes techniques Exigences Qualite Exigence du ProjetQuizz 3Dans la methode Predictive, un cahier des charges ou un tableau des exigences, ou, dans la methode Agile, un Product Backlog est un document dont le contenu correspond a: Description des mecanismes techniques permettant le fonctionnement du produit Description des travaux a mettre en oeuvre pour realiser le produit Description des tests unitaires pour valider le produit Description du planning produit Description des exigences, besoins et fonctionnalites auxquels le produit correspondFrom SCOPE to Project ScheduleTake scope definition result as INPUT Work Breakdown Structure: WBSWork Package: WBWB are usually attached to a Project DeliverableOne WBS for Presence:Defining activitiesAmount of work that can be estimated Need for expert judgementDefine Milestones - BornesDecomposition en activitesPresence 1-POCResources Need for expert judgementDuration Need for expert judgement Estimate TOP Down vs Bottom UPOrdonner et EstimerExemples from MTI PFEEConstruite via Microsoft project En resume, en decoupant l‚Äôensemble des productions a realiser et le travail qu‚Äôelles representent. Puis apres estimation, en repartissant dans le temps ces activites. Vous disposez d‚Äôun plan et d‚Äôun planning initial (BASELINE) de realisation de votre projet complet.Planning AGILESet an order to User Stories - Organiser les Users StoriesOn peut definir un flot de narration. Par rapport a ce flot de narration, pour chaque etape des User Stories corresponsdent (se connecter, se deconnecter, modification de mot de passe, creation de mot de passe, etc.).Sur l‚Äôaxe des ordonnees: organise les users stories suivant le flot de narration (ex: Je me connecte/deconnecte) $\\rightarrow$ ce qui parait le plus important.Release Carving - Decoupage en ReleasesQuelles sont les fonctionnalites essentielles que l‚Äôon doit mettre en Release 1 Par Exemple ?Une fois qu‚Äôon a regroupe depuis le product backlog un des user stories pour la release (Decoupage en sprint (Sprint Carving)) on affecte des ‚ÄúStory Points‚Äù (assign ‚ÄúStory Points‚Äù) $\\rightarrow$ assigner des pointsL‚Äôaffectation des points doit etre fait par l‚Äôequipe de developpement. En resume,Vous avez convenu dans le Productbacklog le perimetre de la release a realiser. Vous avez decompose cette release en N Sprints d‚Äôun poids equivalent pouvant etre realises successivement dans le temps que represente un Sprint.Exemple MTI PFEEExemple 1Exemple 2Des prerequis avant de commencer le developpement Sprint 0 ? Each Sprint Starts with: SPRINT PLANNINGExemple MTI PFEEQuizz 5Quelle est la SEULE affirmation vraie concernant un SPRINT dans la methode Agile ? La duree d‚Äôun sprint peut etre de 3 mois Lors de l‚Äôexecution d‚Äôun sprint, le client peut proceder a des changements de perimetre qui sont geres dans la gestion de changement Un Sprint peut debuter meme si le president n‚Äôest pas termnie Un Increment Produit ‚ÄúFini fonctionnel‚Äù et potentiellement utilisable est produit lors d‚Äôun Sprint La duree du Sprint est variable et s‚Äôadapte aux taches a realiser pour chacun d‚ÄôeuxMonitoring Sprint Execution: Daily SCRUMUne fois le sprint fini: sprint review Client et dev Demo Doit etre valide par le clientSprint retrospective: Reunion de devs Qu‚Äôest-ce qui a marche Qu‚Äôest-ce qui n‚Äôa pas marcheCommunication Client-DevConstruite dans la methode SCRUM, si le client a opte pour AGILE, il doit imperativement se plier a minima aux evenements prevus dans la methode.Bien s‚Äôaccorder sur les moyens (canaux, convocation, calendrier) pour fluidifier le processusExecuting in Predictive/Classic Project ManagementBaseline to control In predictive just follow the plan but lot of unexpected eventsMettre en place un cadre de communication pour controler le dev du projetExemple de plan de communication Formalisez le plan de communication Faites approuver par le clien Planifier la logistique des evenements de com (placer les RDV, format, diffusion des comptes rendus‚Ä¶)Internal review meetings - Reunions de suivi internesAnalysing delays in Gantt ChartChange ManagementPlan &amp;amp; Execute/control Individual project risk an uncertain event or condition that, if it occurs, has a positive or negative effect on one or more project objectivesLa methode pour les risques:Liste de risques possibles:Analyse qualitativeOn manage en priorite les risques a plus haut impactDans ce cas le rouge et noir, en bleu on ignore, en jaune on regarde un peu en detailsRisk Response Strategy Accept Acknowledge the existence of a threat but no proactive action is taken Avoid Risk response is to eliminate the threat by appropriate action Transfer Risk is transfered to a third party that will accept the risk and the potential impact Mitigate Action is taken to reduce the probability and/or impact of a threat En resume, Identifiez les risques qui peuvent affecter le projet Filtrez pour ne conserver que les plus significatifs Definir des strategies et des plans d‚Äôaction pour les risques retenus " }, { "title": "AWS Module 2 - Cloud Economics and Billing", "url": "/cours/posts/aws_module_2/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-08 11:30:00 +0100", "snippet": "Lien de la note HackmdSection 1: Fundamentals of pricingAWS pricing modelThree fundamental drivers of cost with AWS: Compute Charged per hour/second Varies by instance type Storage Charged typically per GB Data transfer Outbound is aggregated and charged Inbound has no charge (with some exceptions) Charged typically per GB How do you pay for AWS ?Pay for what you usePay only for the servuces that you consume, with no large upfront expensesPay less by using moreRealize volume-based discounts: Savings as usage increases Tiered pricing for services like Amazon Simple Storage Service (Amazon S3), Amazon Elastic Book Store (Amazon EBS) or Amazon Elastic File System (Amazon EFS) $\\rightarrow$ the more you use, the less you pay per GB Multiple storage service deliver lower storage costs based on needsPay even less as AWS Grows AWS focuses on lowering cost of doing business This pratice results in AWS passing savings from economies of scale to you Since 2006, AWS has lowered pricing 75 times (as of Septembre 2019) Future higher-performing resources replace current resources for no extra chargeCustom pricing Meet varying needs through custom pricing Available for high-colume projects with unique requirementsAWS Free TierEnables you to gain free hands-on experience with the AWS platform, products and services. Free for 1 year for new customersServices with no chargeModule 2: Total cost of OwnershipOn-premises versus cloudWhat is Total Cost of Ownership (TCO) ? Total Cost of Ownership (TCO) is the financial estimate to help identify direct and indirect costs of a system.Why use TCO ? To compare the costs of running an entire infrastructure environmnet of specific workload on-premises versus on AWS To budget and build the business case for moving to the cloudTCO ConsiderationOn-premises versus all-in-cloudYou cloud cave up to 96 percent a year by moving your infratstructure to AWS. Your 3-year total savings would be $159,913AWS Pricing CalculatorUse the AWS Pricing Calculator to: Estimate monthly costs Identify opportunities to reducse monthly costs Model your solutions before building them Explore price points and calculations behind your estimate Find the available instance types and contract terms that meet your needs Name your estimate and create name groups of servicesReading an estimateYour estimate is broken into: first 12 months total total upfront total monthlyAdditional benefit considerations Cloud Total Cost of Ownership: what will be spent to run the solution Return on Investement analysis (ROI): determine the value generated while considering savings $\\rightarrow$ soft and hard benefits Hard benefits Soft benefits Reduced spending on compute, storage, networking, security Reuses of service and applications that enabl you to define (and redefine solutions) by using the same cloud service Reductions in hardware and softare purchases (capex) Increased developer productivity Reductions in operational costs, backup, and disaster recovery Improved customer satisfaction Reduction in operations personnel Agile business processes that can quickly respond to new and emerging opportunities ¬† Increase in global reach Case study: Delaware NorthBackground: Growing global company with over 200 locations 500 million customers: $3 billion USD annual revenueChallenge: Meet demand to rapidly deploy new solutions Constantly upgrade aging equipmentCriteria: Have a broad solution to handle all workloads Be able to modify processes to improve efficiency and lower costs Eliminate busy work (such as patching software) Achieve a positive return on investment (ROI)Solution: Move their on-premises data center to AWS Eliminated 205 servers (90%) Moved nearly all aplications to AWS Used 3-year Amazon ECE2 Reserved InstancesCost comparisonResultsSection 3: Billing AWS Organizations: account management service to consolidate multiple AWS accounts a branch can have only one parentKey features and benefits Policy-base account management Group based account management APIs that automate account management Consolidate billingSecurity with AWS Organizations Control access with AWS Identity and Access Management (IAM) IAM policies enable you to allow or deny access to AWS services for users, groups and roles Service control policies (SCPs) enable you to allow or deny access to AWS services for individuals or group accounts in an organizational unit (OU)Organization setupAccessing AWS Organizations AWS Management Console AWS Command Line Interface (AWS CLI) tools Software development kits (SDKs) HTTPS Query application programming interfaces (API)Section 4: AWS Billing and Cost ManagementAWS Billing DashboardSpend summary: how much you spent last monthMonth-to-Date spend by service: services most usedTools AWS Budgets AWS Cost and Usage Report AWS Cost ExplorerMonthly billsCost ExplorerForecast and track costsCost and usage reportingSection 5: Technical Support ModelsAWS Support Provide unique combination of tools and expertise: AWS Support AWS Support Plans Support is provided for: Experimenting with AWS Production use of AWS Business-critical use of AWS Proactive guidance Technical Account Manager (TAM) Best practices: AWS Trusted Advisor Account assistance AWS Support Concierge Support plansAWS Support offers four support plans: Basic Support: Resource Center access, Service Health Dashboard, product FAQs, discussion forums, and support for health checks Developper Support: Support for early development on AWS Business Support: Customers that run production workloads Entreprise Support: Customers that run business and mission-critical workloadsCase Severity and response timesWrap-upSample exam questionWhich AWS service provides infrastructure security optimization recommendations ? AWS Price List Application Programmin Interface (API) Reserved Instances AWS Trusted Advisor Amazon Elastic Comput Cloud (Amazon EC2) Spot Fleet Answer Keyword: recommendations Answer: 3." }, { "title": "AWS Module 1 - Cloud Concepts Overview", "url": "/cours/posts/aws_module_1/", "categories": "tronc commun S8, AWS", "tags": "tronc commun, AWS, S8", "date": "2021-02-08 10:00:00 +0100", "snippet": "Lien de la note HackmdIntroduction Intro to cloud computing Advantages of cloud computing Introduction to AWS AWS Cloud Adoption FrameworkSection 1: Introduction to cloud computingWhat is cloud computing ? Cloud computing is the on-demand delivery of compute power, database, storage applications, and other IT resources via the internet with pay-as-you-go pricingInfrastructure as softwareCloud computing enable you to stop thinking of your infrastructure as hardware and instead think of it as software.In the traditional compute model: Infrastructure as hardware Hardware solutions Require space, staff, physical security, planning, capital expenditure Have a long hardware procurement cycle Require you to provision capacity by guessing max peaks Cloud computing model: Infrastructure as software Software solutions: Are flexible Can change more quickly, easily and cost-effectively than hardware solutions Eliminate the undifferentiated heavy-lifting tasks Cloud service modelsCloud computing deployement models Cloud Hybrid Between cloud and existing premises On-premises (private cloud) Dedicated resources Similarities between AWS and traditional ITSection 2: Advantages of the cloudTrade capital expense for variable expense Capital expense = capexMassive economies of scaleBecause of aggregate usage from all customers, AWS can achieve higher economies of scale and pass savings onto customers.Stop guessing capacityIncrease speed and agilityWeeks between wanting resources and having resources to only minutes.Stop spending money on running and maintaining data centersGo global in minutesCan deploy applications in multiple places of the worldSection 3: Introduction to AWSWhat are web services ? A web service is any piece of software that makes itself availbale over the internet and uses standardized format such as XML or JSON fro the request and the response of an API interaction.What is AWS a secure cloud platform offering a broad set of global cloud-based products provides on-demand access to compute, storage, network, database, and other IT resources and management tools offers fexibility You pay only for the individual services you need, as long as you use them AWS services work together like LegosServicesChoosing a serviceThe service you select depends on your business goals and tech requirements.3 ways to interact with AWS AWS management console Easy-to-use graphical interface Command Line Interface (AWS CLI) Access to services by discrete commands or scripts Software Developement Kits (SDKs) Acces services directly from your code Section 4: Moving to the AWS CloudAWS Cloud Adoption FrameworkAWS CAF provides guidance and best practices to help organizations build a comprehensive approach to cloud computing across the organization and throughout th IT lifecycle to accelerate successful cloud adoptionAWS CAF is organized into six perspectives Perspectives consist of sets of capabilities.Six core perspectivesBusiness perspectives We must ensure that IT is aligned with business needs, and that IT investments can be traced to demonstrable business results - Business managers, finance managers, budget owners, and strategy stakeholdersPeople perspectives We must prioritize training, staffing and organizational changes to build an agile organization - Human resources, staffing, and people managersGoverance perspective We must ensure that skills and processes align IT strategy and goals with business strategy and goals so the organization can maximise the business value of its IT investments and minimize business risks. - CIO, program managers, business analysts and portgolio managersPlatform perspective We must understand and communicate the nature of IT systems and their relationships. We must be able to describe the architecture of the target state environment in detail. - CTO, IT managers and solutions architectsSecurity perspective We must ensure that the organization meets its security obejctives - CISO, IT security managers and IT security analystsOperations perspective We align with and ssupport the operations of the business, and define how day-to-day, quarter-to-quarter, and year-to-year business will be conducted - IT operations manager and IT support managersWrap-upSample exam questionWhy is AWS more economical than traditional data centers for applications with variable compute workloads ? Amazon Elastic Compute Cloud (Amazon EC2) costs are billed on a monthly basis Customers retain full administrative access to their Amazon ECE2 instances Amazon ECE2 instances can be launched on-demand when needed Customers can permantly run enough instances to handle peak workloads Answer Keywords: AWS more economical than traditional data centers, indicate one of the 6 computing benefits and variable indicates need for flexibility Answer: 3" }, { "title": "Kickoff Image", "url": "/cours/posts/kickoff_image/", "categories": "Image S8, Kickoff", "tags": "Image, S8", "date": "2021-02-05 09:30:00 +0100", "snippet": "Lien de la note HackmdCours Tous les cours sont TD/TPPremiere partie du semestreBooster MASI (BOOM) Lundi et mercredi Rappels de MASI Qu‚Äôest-ce qu‚Äôune convolution ? Qu‚Äôest-ce qu‚Äôune correlation ? TD aprem Pour les TP: pas de salle Notebook Jupyter Devoir ramener ordis en presentiel Python pour le Big Data Apprendre a se servir de Python pour traiter de la donnee avec le prof de CAMA Cours possiblement en Zoom au lieu de Teams Pour suivi personnalise Introduction aux Reseaux de Neurones Avec prof de CAMA 6h de cours 6h TD/TP Sur zoom Cours de Olivier Ricou en distanciel Olivier Ricou ouvert aux remarques constructivesDeployement et Virtualisation Apprendre a se servir de Docker TP avec intro au cours Cours modal Une partie de la classe presentiel Autre distanciel Echange de place 1 semaine sur 2 Introduction a la synthese d‚Äôimages Prof de THL Plus de traitement que de synthese Cours compact au debut du semestre Premier projet a rendre Traitement d‚Äôimage fondamentale Gros cours du S8 36h au total Jonhattan presente les bases du traitement d‚Äôimage en C++ Evaluation par partiels Elody presente plus avance et en python Evalue par projet Projet communs a plusieurs matieres pour des projets plus avances et moins de projets a completer, charge de travail plus legerePour tous les modules doit etre fourni une note a l‚ÄôadmProbabilite et statistique (commun avec SCIA) En distanciel 12h de cours magistraux 6h de TD seuls Partiel classique Fondement des probas stats pour le machine learning Devoir sur tableOptimisation convexe (commun avec SCIA) Bi-modal Bashar et Guillaume Approches differentes Plus gros du cours: apprendre ce que c‚Äôest une differentielle Debut mi-mars et fini au mois de Juin 19h de cours 7h de cours 12h de TD Controle continu + compte rendu de TP pour 2e partie du semestreIntroduction au machine learning Guillaume et Joseph Cours maudit: profs changent chaque annee 18h de cours 2h d‚Äôintro 4 seance de 4h Imagerie medicale Commence avant la semaine de partiels 3 seances avant puis 3 apres 1ere seance: ‚Äúdetente‚Äù Evaluation par projet Pas le droit de faire du deep learning Seulement traitement d‚Äôimage classique 20h de cours de spe/semaine, 4j de cours sur 5, journee remplie 3h de cours le matin et 3h l&#39;aprem, avoir des creneaux libres pour avancer sur les projets Peut rajouter des heures en plus (soutenance, etc.)L‚Äôan dernier les etudiants on pas eu de soutenance, juste rendre projet/video prez, dur de faire un retour personnalise.Cette annee repasse sous un systeme de soutenance pour les projets, pas de rapport mais presentation (et soutenance de mini-projets). Si on nous donne un projet a faire pour dans 2 mois, veut pas dire que 2 mois de boulot mais 2 mois pour s‚Äôorganiser et etaler la charge de travail.QuestionProjet en commun avec d‚Äôautre majeures ? NonPour les projets en commun entre plusieurs matieres ? But d‚Äôutiliser les outils pour faire quelque chose de bienCours avec les SCIA ? Veut reprendre les cours au max en presentiel mais SCIA + Image = bcp d‚Äôeleves et depend des annonces gouvernementales sur les universite (pour l‚Äôinstant tres floues). Personne n‚Äôest force a venir en presentiel.Rediffusion des cours ? NonConclusion 1ere partie du semestre2 projets: IREN (Introduction aux Reseaux de Neurons) et ISIM (Introduction a la synthese d‚Äôimage)2eme partie du semestrePlus de projetsOCVX, IMEDImagerie Couleur et Capteur Specifite imagerie couleur, qu‚Äôest-ce que la couleur Aimerai y ajoindre une intervention de Benoit PochonEtude de cas pratique en image et RdF Peut-etre dispense pour les RDI Pour ceux qui ne font pas de recherche, voir comment on fait Choisir un article et le presenter Forcer a lire un article de conf et a le synthetiser Implementation rapide GPGPU Edwin et Joseph Ce cours est comme le vin, s‚Äôameliore d‚Äôannee en annee En SM 14 (presentiel) Evaluation par projet (LE GROS PROJET de cette partie du semestre)Introduction a VTK et ITK Distanciel Julien Jomier, gars de la boite derriere CMake ProjetProgrammation OpenGL Eval par projetMachine Learning pour la reconnaissance des formes (commun SCIA) 2h de cours le matin et 3h de TP le vendredi Cours pref des etudiants pendant le S8Hackhaton PIFUN Remplacer le projet traitement d‚ÄôImage Hackhaton sur 3 jours Manipulation Raspberry Pi Computer vision + machine learning Apres les partiels (et si possible soutenances de projet) RDI dispensesPFEE Gens des labos dispenses Projet qui demarre entre Avril/Mai et continue jusqu‚Äôa Janvier Les entreprises viennent proposer des sujets Ce sont des clients et on doit realiser leur projet Ils presentent et on choisi Par groupe de 3 ou 4 Interdit groupes de 3 avec 2 assistants Interdit groupes de 4 avec 3 assistants Travail en continu Si un assistant arrete de bosser en Septembre les autres doivent continuer Tout le monde a interet que le PFEE se passe bien Permet aux entreprises de proposer des sujets l‚Äôannee suivante Peut obtenir des stages Des fois ou le PFEE se passe mal a cause de l‚Äôentreprise Possibilite de contacter les entreprises nous-meme pour recuperer des sujetsOrganisation Pas de creneaux PFEE car besoin d‚Äôun prof associe Cette annee: creneaux Mise au point avec Elodie Si l‚Äôentreprise ne donne plus de signe de vie, contacter Elodie directement.Si l‚Äôentreprise utilise notre travail, on leur suggere de donner un petit quelque chose en echange.Le labOn en a pas.Canaux de communicationTeams + mailing listLes chefs de majeure ne seront pas sur le DiscordLes rolesLes delegues2 delegues, a elire avant mercredi 10/02, trait d&#39;union entre l&#39;adm et les chefs de majeure Communiquer avec les chefs de majeure, leur transferer les mails Invites au conseil de classe Transmettre les infos des industriels Une fois choisis, envoyer la liste a Elody et GuillaumeLab Role fantome Besoin d‚Äôun respo lab Respo com 4 respos com, minimum 2 Interface avec la com Etre la pour les JPOs Au moins un respo com par JPO Electif dedie (peut faire du theatre) Peut pas etre RDI Pas vendre Epita, vendre la majeure Appariteur 2 appariteurs Reprendre max d‚Äôactivite en presence Aimerai mettre en place: Diviser la promo en 2 Chaque etudiant d‚Äôun groupe est en binome avec un etudiant de l‚Äôautre groupe L‚Äôeleve en presentiel s‚Äôoccupe de celui en distanciel Rentransmettre en live Dans chaque groupe une personne respo de la retransmission Responsable de l‚Äôorganisation qui vient distanciel/presentiel" }, { "title": "PFEE GE Healthcare 2", "url": "/cours/posts/pfee_ge_healthcare_2/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 16:15:00 +0100", "snippet": "Lien de la note HackmdProbleme La fluoroscopie ne montre pas toutes les informations Injection cause des contrastesSolutionsScanner preoperatoire 2-3 mois en amontPendant l‚ÄôoperationFusion manuelle des 2 modalitesEn resume Premiere donnee: image 2D (fluoroscopie) Seconde donnee: volume 3D (scanner CT)But du projetAutomatisation de ce processusBut de l‚ÄôagentGeneration de donneesRecherches de donnees publiquesFichiers .DICOM Ensemble de coupes d‚Äôun patient donneGeneration de donneesPour un scanner donne: Reconstruction volume 3D Generation de projectionPour une projection: Generation de patchesDonnees 2D uniquementNotre projet: recalage 2D/2D afin de se concentrer sur la mise en place d‚Äôune architecture globalesApprentissage par renforcement Trouver la meilleure sequence d‚Äôactions permettant d‚Äôaligner 2 images Un agent artificiel apprend la meilleure strategieQ-learning But de l‚Äôagent de trouver la policy La notion de q-value renvoie a la recompense obtenue sur le long termeApprentissage par renforcement superviseq-values deja calculees avant l‚Äôapprentissage On va faire une regressions entre q-value et output du reseau Permet d‚Äôavoir une convergence plus stableRole du reseau de neurones Determiner action optimale pour chaque etat Estimer les q-values pour chaque paire etat/action Le reseau prend un etat en entree et retourne les q-vqlues pour chaque actionPre-traitement Patch normalise entre 0 et 1Phase d‚ÄôentrainementObtention des images a chaque etape d‚Äôinference Choisi action parmi 6 pour q-value maximale Applique l‚ÄôactionResultatsReduction de la dimension du problemeConclusionCe que le projet nous a apporte Montee en competences Recalage d‚Äôimage Imagerie medicaleCe que le projet a apporte a GE Meilleure connaissance des bases de donees publiques Premiere approche de l‚Äôapprentissage par renforcementQuestionsGuillaume TochonC‚Äôest quoi epsilon policy ? Fonction qui permet de diriger exploration et exploitationElodie PuybareauLe temps de traitement sur une image ? Relativement instantaneeRetours GE HealthcareRetour globalement positif, resultat fonctionnel" }, { "title": "PFEE GE Healthcare: Deep Learning Inpainting", "url": "/cours/posts/pfee_ge-healthcare/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 15:30:00 +0100", "snippet": "Lien de la note HackmdHow to get a volume ? Turn around the patient X ray acquisition in different anglesArtifactsDifferent types of artefact: Motion artifact Metal artifact Ring artifacts (detector)State of the art Where Correction applied on volumes Inpainting Fill selected image area Requires having the mask of the missing partsMethodsInterpolation 2DInterpolation algorithm from skimage to create a basline: Nearest neighbor LinearU-NET 2DImprovements ? Conv2D/3D do not consider the mask Losses (MSE/MAE) do not consider the maskPartial convolution Presented by Nvidia in 2018 Mask area is much less visible and overall results are improvesKeras ?Loss improvement Using a train VGG deep learning classifier Layers used: 3rd, 6th and 10th DataExperimentsGoal 2D Perfomance machine learning Added value 3D Adding temporal gives best results Can we be more memory efficient using patches ? Evaluation method Quantitative evaluation MSE MAE SSIM Structural similarity PSNR Peak To Signal Noise Ratio More quantitative than qualitative Quality eval Eval by human eye ResultsQualitative 2DRibs reconstructionQualitative 2D+TAnalysis Machine learning can be used for this task PConv and VGG loss are the best improvementsConclusion Implementation of PConv2D and PConv3D Promising resultls Kickstarted GE exploration and gave them insights on their future work Had fun with advance machine learningQuestionsGuillaume TochonLe papier a ete utilise sur des images de scan ? Non sur des images naturellesExpliquer ‚Äòsmoothing loss‚Äô Dilatation verticale et horizontale des resultatsElodie PuybareauGeneration des artefacts: probleme avec modele 2D+T, pourquoi blanc alors que modele 2D noir ? Les modeles 2D sont aussi blanc sur les imagesElevesExemple d‚Äôapplications concretes ? Application de corrections permet d‚Äôavoir des images pouvant etre travaillees pour un medecinGenration des artefacts aleatoires ? Oui pour la position et rotation en 3D mais sinon non, pas de perte de temps a generer de la donneeTester avec des formes differentes ? Oui avec des coins et des aiguillesGenerer un nombre infini de donnees, probleme de fit ? OuiInterpolation lineaire plus simple ? Oui mais beaucoup de stries et n‚Äôarrive pas a reconstruire certaines partiesRetour GE HealthcareBonne organisation, bon avancement des projets mais baisse d‚Äôactivite lors d‚Äôexamens, groupe autonome" }, { "title": "PFEE Mihaly", "url": "/cours/posts/pfee_mihaly_prez/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:45:00 +0100", "snippet": "Lien de la note HackmdPrototypage d‚Äôun voxeliseur avec VTKMihaly Startup d‚Äôimpression 3D Nouvelle tech d‚Äôimpression qui permet d‚Äôavoir du texturing et de la couleur Precision a l‚Äôechelle du micrometre Creation de l‚Äôapplication et du pipeline de traitements des objets a imprimer Problematique: Impression 2.5D/3D dans un espace reduit Incapacite de creer des structures de soutien pour les objets flottants Opti de l‚Äôutilisation de materiaux colorises Gros volume de donnees (scan de plusieurs millions de vertices) Premieres approches2 solutions possible: Voxeliser Decouper la partie externe du volume Imprimer cette couche et reassembler le modele creux Voxeliser Decouper le volume en sous-volumes Imprimer et reassembler Premieres iterations Utilisation de notre propre voxeliseur a partir de bibliotheques qu‚Äôon adapteGrand tournant: Decouverte VTKOutils VTK On a eu un cours Visualisation et interactions integrees Gestion PyQT Package python Simplifie utilisation Blender rapide mais mauvais sur les grosses donnees Meshlab meilleur pour les gros sets Pipeline Entree: modele 3D (OBJ)Sorties attenduesPlein de formats differents : utilise OBJ et XMLResultatProblemesVTK: Pas de doc Peu d‚Äôexemples et pas dans tous les langages Import vtkmodules.allConclusion Gerer les fichiers de facon plus propre Trouver un moyen de generer un bitmap de maniere intelligente Automatiser de plus en plus la segmentation en sous-volumes Comprendre VTKQuestionsGuillaume TochonComment a ete decoupe le travail ? Avant VTK, probleme de restreindre le sujet et VTK probleme de l‚ÄôengineQuels cours on ete utiles ? VTK tres utile meme si le cours est legerImpression 2.5D ? Pour des scans de tableau, seulement une face compteElody PuybareauEst-ce que le projet vous a plu ? Oui meme si beaucoup de galeres, on pu voir l‚Äôimprimante 3D de $3m^2$ElevesPourquoi le screenshot du tableau ? Tableau: fichier de 1,6Go, seule solution de screen le tableau pour avoir la textureRetour de Mihaly2-3 precisions sur la machine: 9 tetes avec des micro-buses qui lache du polymere sur $3m^2$ donc beaucoup de donnees, galere car confinement, retour tres positif" }, { "title": "PFEE Mihaly", "url": "/cours/posts/pfee_mihaly/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:45:00 +0100", "snippet": "Lien de la note HackmdPrototypage d‚Äôun voxeliseur avec VTKMihaly Startup d‚Äôimpression 3D Nouvelle tech d‚Äôimpression qui permet d‚Äôavoir du texturing et de la couleur Precision a l‚Äôechelle du micrometre Creation de l‚Äôapplication et du pipeline de traitements des objets a imprimer Problematique: Impression 2.5D/3D dans un espace reduit Incapacite de creer des structures de soutien pour les objets flottants Opti de l‚Äôutilisation de materiaux colorises Gros volume de donnees (scan de plusieurs millions de vertices) Premieres approches2 solutions possible: Voxeliser Decouper la partie externe du volume Imprimer cette couche et reassembler le modele creux Voxeliser Decouper le volume en sous-volumes Imprimer et reassembler Premieres iterations Utilisation de notre propre voxeliseur a partir de bibliotheques qu‚Äôon adapteGrand tournant: Decouverte VTKOutils VTK On a eu un cours Visualisation et interactions integrees Gestion PyQT Package python Simplifie utilisation Blender rapide mais mauvais sur les grosses donnees Meshlab meilleur pour les gros sets Pipeline Entree: modele 3D (OBJ)Sorties attenduesPlein de formats differents : utilise OBJ et XMLResultatProblemesVTK: Pas de doc Peu d‚Äôexemples et pas dans tous les langages Import vtkmodules.allConclusion Gerer les fichiers de facon plus propre Trouver un moyen de generer un bitmap de maniere intelligente Automatiser de plus en plus la segmentation en sous-volumes Comprendre VTKQuestionsGuillaume TochonComment a ete decoupe le travail ? Avant VTK, probleme de restreindre le sujet et VTK probleme de l‚ÄôengineQuels cours on ete utiles ? VTK tres utile meme si le cours est legerImpression 2.5D ? Pour des scans de tableau, seulement une face compteElody PuybareauEst-ce que le projet vous a plu ? Oui meme si beaucoup de galeres, on pu voir l‚Äôimprimante 3D de $3m^2$ElevesPourquoi le screenshot du tableau ? Tableau: fichier de 1,6Go, seule solution de screen le tableau pour avoir la textureRetour de Mihaly2-3 precisions sur la machine: 9 tetes avec des micro-buses qui lache du polymere sur $3m^2$ donc beaucoup de donnees, galere car confinement, retour tres positif" }, { "title": "PFEE ForEvent", "url": "/cours/posts/pfee_forevent/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-04 14:00:00 +0100", "snippet": "Lien de la note HackmdPar Alexandre Girard - Nassim Habib-Allah - Xavier FichterForEvent Agence d‚Äôanimation evenementielle implantee a Paris et BordeauxEtat de l‚Äôart App Ipad pour creer sa propre BD photos Dev en Swift Quelques secondes de calcul par imageObjectifs Ameliorer le temps de traitement des images Ajout de nouveaux filtres Creer une verion PC, portable sur un serveurFonctionnement du projet/filtres On utilise C++/OpenGL: GLFW et glad Combinaison de Vertex/Fragment Shader Chaque filtre est rendu dans un FrameBufferFiltre Manga/CouleurFilte ComicsDeployer sur un serveur Deployer avec docker et Serveur-X Utiliser nvidia-docker-runtime et xvfb Contrainte de la versio d‚ÄôOpenGL Deployer sans docker et Serveur-X Utiliser EGL au lieu de GLFW OpenGL moderne dispo Rendu Headless API Web Une interface simple pour upload une image vers le serveur et choisir le filtre a appliquer Permet de telecharger l‚Äôimage filtreeResultatsBenchmark:Ameliorations Faire de GPGPU $\\rightarrow$ Compute Shader ou CUDA Reunir plus de filtres dans un shaderConclusionProjet interessant, nouvel aspect de OpenGL et rendu sur serveurQuestionsGuillaume TochonPourquoi parti sur l‚Äôaspect rendu que traitement ? Pas pret a composer des filtres, besoin de connaissances en Swift: ‚ÄúOuh la c‚Äôest quoi cette chose‚ÄùElody PuybareauSur la version comics, outils deja pret ou polarisation maison ? Filtre deja disponible sur l‚Äôapplication, portage PC, quelques types a changer/opti mais sinon filtres deja existantsElevesSatisfait du rendu ? Bien-sur c‚Äôest styleCombien de temps ? Avril/Mai en fonction de si un virus ne bloque pas l‚Äôeconomie mondiale jusqu‚Äôa FevrierForEventQuestion pour les profs: comment se passe l‚Äôattribution des projets ? Proposition des sujets, repartis par groupe (1 groupe = un sujet), beaucoup de bataille pour obtenir un sujet mais surtout les etudiants choississentRetour de ForEventExperience nouvelle et positive, communication a ameliorer mais reussi a remplir les objectifs surtout que ralenti aussi a cause du corona, explorations a essayer mais manque de connaissance de la part de l‚Äôentreprise (ex: filtre peinture impressioniste)" }, { "title": "Epee et fusee", "url": "/cours/posts/epee_fusee/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 12:15:00 +0100", "snippet": "Lien de la note Hackmd Qu‚Äôest-ce qui se passe si on fusionne une epee et une fusee ?Jeu d‚Äôepee ou les joueurs peuvent se deplacerLe reseau Defini la structure du code Photon Unity Network Synchronisation du minimum Pas ouf de synchoniser tout Synchro les animations Personnage 3D Modele 3D et animations Si le joueur bouge sa main dans le jeu, tout le monde doit le voir Hit Box par membre du corps (tete, torse‚Ä¶) Metaphore du corps du joueurModele camera Retranscrire les deplacements reels du joueur dans le jeu Le personnage est la camera Le corps du personnage suit la cameraLes fusees Une fusee par main (activable par le joueur) Changement de velocite du personnage selon orientation de la main Deplacement tridimensionnel Permet un deplacement assez fun Ne cause pas la nauseeLes armes Abstraction: support de plusieurs armes (et bouclier) Detection des collisions avec les personnages Systeme d‚Äôenerge: solution pour gerer les collisions entre les armesChangement d‚Äôarme Propre a chaque main Changement enclenche par: main derriere la nuque Calcul par rapport a la position du joueurEnvironnement 3D Objectif: vertigineux, theme urbain Probleme: souvent trop lourd pour le Quest Solution: texture basse qualiteQuestionsLe mouvement des personnages synchro sur le reseau ? Ce qu‚Äôon synchro c‚Äôest la target d‚Äôorigine et sa rotation, on synch la tranlsationDegats de chutes ? Non pas implemFaire des deplacements dans une zone de non gravite ? Manque l‚Äôaspect de retomber facilementQuelles interactions PC ? Pas d‚Äôinteraction PC, la vue sert de debuggueur" }, { "title": "Station spaciale", "url": "/cours/posts/space/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 12:00:00 +0100", "snippet": "Lien de la note HackmdSujet Pilotage station spatialeConcept Joueur VR Pilote le vaisseau dans la station Joueur PC Dirige la station Communication Entre joueurs: discordJoueur 1: Pilote Positionne dans un vaisseau Controle du vaisseau via les manettes VR Peut se deplacer dans toutes les directionsJoueur 2: Tour de controle Deplacement via clavier/souris Se deplace sur les passerelles/plateformes pour appuyer sur les boutons Dispose de differents boutons Controle ce qui se passe dans la station a l‚Äôaide de 4 camerasBut: aide le vaisseau a se poser sans encombres et repartirInteractions entre les 2 joueurs Le gardien de la station ferme les portes apres avoir verifie l‚Äôidentite du vaisseau Le gardien indique au vaisseau ou se poser Le gardien indique les manoeuvresMetaphores d‚Äôinteractions Utilisation d‚Äôun pointeur laser dans le menu Utilisation d‚Äôune main virtuelle dans le jeu pour controller le vaisseau Le pilote appuie sur la gachette de la manette pour saisir les joysticks Le gardien de la station active les boutons en cliquant sur la souris a l‚Äôaide d‚Äôun reticule Le gardien de la station se deplace en vue 1er personneDifficultes Integration de la VR (assets, port USB-C) Joysticks du vaisseau instable Problemes de reseau (perte de paquets) rendant le gameplay instable (mouvement saccades‚Ä¶)QuestionsLibrairies pour integration casque/reseau ? Package integration Occulus pour le casque et pour le reseau des sockets" }, { "title": "Master Piece", "url": "/cours/posts/master_piece/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:50:00 +0100", "snippet": "Lien de la note HackmdGeneration du terrain Bruit de PerlinGameplay Inspire mais pas copie des Transformers Un joueur PC controle la voiture et l‚Äôautre controlle la tourelle a l‚Äôarriere de la voitureCe que l‚Äôon peut parametrer Vie ennemi/joueur Degates ennemi/joueur Vitesse d‚Äôappartion des ennemis / munitions Carateristiques de la voiture Nombre d‚ÄôennemisAmelioration possibles Power-upQuestionsQuels outils pour le reseau ? Photon mais ne fonctionne pas donc demo en localLe comportement des ennemis ? Vont direct sur la voiture, s‚Äôarrete puis lance animation d‚Äôattaque" }, { "title": "Mad Maze", "url": "/cours/posts/mad_maze/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:30:00 +0100", "snippet": "Lien de la note HackmdIntroduction Jeu inspire de ‚ÄúKeep Talking and nobody explores‚Äù Grand labyrinthe rpz les salles d‚Äôun vaisseau Trouvez et declenchez les boutons pour en sortirMapLe joueur PC dispose de la carte du chemin a prendre pour guider le joueur VR.Implem Package: SteamVR avec commandes personnalisees Contient des deplacement Teleportation Map: Cree sur Space Engineers, exportee en .obj Multiplayer: Cooperation pour trouver les boutons et la sortieNiveau de difficulte Le joueur PC doit communiquer clairement et savoir lire une carte, les numeros de salle sont une aide La vision est reduite a la lampe frontale en interieur, possibilite d‚Äôutiliser la vue VR Facile de se perdre complemetement, meme avec la carte, meme pour les devProblemes rencontrees Generer la map (trop) volumineuse Gerer correctement toutes les collisions Avoir des boutons non bogues Compliquer de tester la VRQuestionsPossible de generer des maps randoms ? Malheureusement non, pas de chargement procedural mais generer la visualisation en chunks donc technique possible de le faireLe joueur PC ne voit pas le joueur VR ? Non mais peut partager la vue VR du joueur" }, { "title": "Obstacles", "url": "/cours/posts/obstacles/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:15:00 +0100", "snippet": "Lien de la note HackmdPar Amelie, Alexandre, BrunoSujet: un jeu collaboratif2 joueurs: un avec un casque VR, l‚Äôautre PCBut: Le joueur VR doit finir le niveau Le joueur PC doit l‚Äôen empecher, en utilisant la mapMap3 zones Attente (spawn): choix des armes Combat FinJoueur PC Empecher le joeur VR de finir le niveau Faisant spawn des ennemis sur la map Accelerer la vitesse des plateformesJoueur VR Deplacement avec Joystick Rotation en bougeant la tete Se defendre avec une armeCombat Les ennemis peuvent lancer des boules de feu Le joueur VR perd des PV s‚Äôil se fait toucher ou touche une ennemi Tirer sur une boule de feu permet de la detruire, meme avec un coup de sabre laserFin de la partie Le joueur VR a passe la porte de fin de niveau $\\rightarrow$ joueur VR gagne Le temps imparti $\\rightarrow$ joueur PC gagne Le joueur VR tombe $\\rightarrow$ joueur PC gagneProblemes rencontres Le reseau Mirror Le spawn des joueurs sur la scene et leurs gameobjects La synchro (objets, ennemis, etc.) QuestionsPertinant que les ennemis et boules de feus synchro ? Sans la synchro, le joueur PC ne verrait pas la vraie sceneBoule de feu instantiee sur le network ou chez le client ? Avec Photon: utilise photon view, de meme que les ennemisComment sont gerer les deplacement ? OVR ControllerInteraction entre les 2 joueurs: comment le joueur PC voit le joueur VR ? Le joueur PC a une camera fixe et le joueur VR est rpz par un cube sur son ecran." }, { "title": "Martin et Titouan", "url": "/cours/posts/martin_titouan/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 11:15:00 +0100", "snippet": "Lien de la note Hackmd Je vais me faire une fondue savoyarde ca ira mieux.A chaque fois que la camera bouge, on render une nouvelle texture sur le plan.QuestionSi on recule a traver le portail ? On reste dans la salle, on calcule l‚Äôangle par rapport au plan pour traverser le portailInteraction avec d‚Äôautres joueurs ? Un joueur PC et un joueur VR, un joueur se cache et l‚Äôautre le cherche (pas implem)Musique de la video uniquement sur la video ou dans le jeu ? Uniquement sur la video" }, { "title": "Mona VR", "url": "/cours/posts/mona/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:40:00 +0100", "snippet": "Lien de la note Hackmd Coupler peinture/VR Plsrs modes Enregistrement des oeuvres dans une gallerie Partager en reseauPeinture et reprod oeuvre Canvas creer sur Blender Interaction peinture / toile Impression en filigrane des oeuvres Image desaturee utilise comme textures Lien unity/occulus Peu tuto Plugin 2019 Occulus Integration XR unity utilitiesGallery Possible sauvegarder Clear le tableau Nom du fichier: date sauvegarde Display des productions disponibles a partir du menuMulti Mode peinture a 2 Photon Pun 2 Utilisation intuitive Modele host/client vs room server Une room avec 2 joueurs maxConclusion Approche pedagogique Donner le gout de la peinture Faire connaitre des tableaux Decouverte dev vr Ameliorations possibles Upload son tableau au choix Precision Pallette de couleurs plus complexe QuestionsCreation de l‚Äôimage ? Texture du canvas changee et updateePu partager la texture par reseau ? Oui" }, { "title": "War VR", "url": "/cours/posts/war/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:30:00 +0100", "snippet": "Lien de la note Hackmd War VR A collaborative VrWar : a card game War: a 2-player card game Deck evenly divided between 2 players At each round, top cards are revealed: higher card wins Winner gains the opponent‚Äôs card If equal value = ‚Äúwat‚Äù Next card top down End of game when a player got no card leftWar VR: in Reality Hard to work on while being homestuck Hard to rush Massive restructuring mid-development Drastic artistic and game design shift No collaboration J‚Äôen appelle au Dragon blanc aux yeux bleus !What‚Äôs left Game mechanics (hidden by the scenario) Second player: plays automaticallyProblems encountered Network: PC build One Occulus Quest that needs the game to be built to test XR interactable madnessQuestionsComment shuffle les cartes ? En Csharp fonction pour SuffleDifficile d‚Äôemuler le casque VR sur PC ? Anne s‚Äôest occupe de tout ce qui touche a la VRPartie reseau d‚Äôabord mirror, et pour la partie PC ? But pour verifier les instanciation, pour Occulus fonctionne mais a jamais build PC, tester le multi dans l‚ÄôediteurInteractions avec les manettes ? Tester ‚Äúflip the table‚Äù mais faisait n‚Äôimporte quoiComment recuperer les sons Yugi-oh ? Pas tres legalement avec la serie sur Netflix" }, { "title": "Whiteboard in VR", "url": "/cours/posts/whiteboard/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:15:00 +0100", "snippet": "Lien de la note Hackmd On va vous montrer un projet tout pourri!Projet: whiteboard en VRProject goals Write on a whiteboard Implement mutliple tools Interact with multpile people with the whiteboardFeatures implemented Write on the whiteboard Create a pen Grab a pen Detect collision between pen and whiteboard Problems encountered Difficulte avec textures Detecte collision mais pas de texture Pas pu rajouter le multi Difficult test environment Difficulty on Linux Moving, could only work in the kitchen but had an occulus 50cm space to test a VR game Pourquoi je suis penche ? Le cable etait pas assez long C‚Äôest parce que je sais pas dessiner que c‚Äôest moche - en dessinant un moutonQuestionEst-ce qu‚Äôil y une sensation en ecrivant ? Non car la manette vibre en permanenceEn terme de mutliplayer ? Utiliser PhotonComment applique la texture ? Repere la collision et applique la texture en X,Y" }, { "title": "Le Projet Grosses Mains", "url": "/cours/posts/grosses-mains/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 10:00:00 +0100", "snippet": "Lien de la note HackmdUn jeu triple AConcept Coop VR/PC Platformer Object displacement Mutliple scalesVR Player Capacity to grab objects in environment Creation of passageInteractable Can grab a plankKeyboard/mouse player Input System Manager Cimemachine Camera Handles Mouse input Define movement direction according to the camera vectors Handles rotation and animations Add jump and gravityNetwork handling Photon Photon view: dire au perso ou il est pour le netowrk Character follow: permet au personnage network de suivre le perso client Verifier que perso network bien instancieLevel Design The floor is lava Movable objects to help the player go through the levelQuestionPourquoi photon pour la partie reseau ? Le plus simple a utiliser, a la base serveur dedier mais Photon bien plus simple et moins de tempsQuel casque ? Occulus quest, dans la video 2 joueurs sur Quests car autant de joueurs VR + PC possibleComment la cooperation se fait entre 2 joueurs en VR ? Ne peuvent pas interagir, uniquement pour la video demoPour les animations du perso PC, comment ? Tout ete fourni avec le personnage (assets)" }, { "title": "Bowowob", "url": "/cours/posts/bowowob/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 09:30:00 +0100", "snippet": "Lien de la note HackmdProject presentation Inspired by The Lab by Vavle Castle defense Enemy waveTool used XP interaction toolkit Photon Network UnityPlayer Movement Room scale Teleportation Network Player avatar spawned on network Movement synch with avatar Bow &amp;amp; arrowQuiver On enterBow Complex interaction Shooting an arrow Place arrow on string Bow hand and string hand distance for animation and particles Arrow When released Force applied Check for certain collisions Line renderer and particles Network Arrows are spawned on the server Forces and positions are synchronizedEnnemies 3 different spawns Checkpoint system Death animation For each wave: More enemies Same health Map Assets were combined to build it unity URP is used to make the game look better Shadows were usedMultiplayer Interactable objects Potions Shareable equipment Arrows Bow Conclusion Problems encountered Arrow synch Objects were not shareable Random hand crashing Good proof of concept and quite funQuestionsCommence quand ? Combien de temps ? Solo rapide a faire, tout casse avec le reseau, beaucoup de temps a fix le multi, a du faire des impasses sur certaines parties du gameplayComment faire les particules ? Package Unity qui gere les particules, suffit d‚ÄôactiverClient master ? Celui qui recoit les infos en premier et recoit les trucs en synchro" }, { "title": "Comballoration", "url": "/cours/posts/comballoration/", "categories": "Image S8, RVAU", "tags": "Image, S8, RVAU", "date": "2021-02-03 09:00:00 +0100", "snippet": "Lien de la note HackmdVideo de demonstration: duel 1v1 en VR avec des armes (epee, pistolet, assiettes, etc.) Le but est tout simple: c‚Äôest de le tuerContexte Projet de Realite Virtuelle et AUgmentee Necessite d‚Äôavoir de la collaboration, aka pas de solo Dernier projet a EpitaSujet choisi Jeu de combat 1v1 Gare du Nord CollaborationComposants de base Le paquet OVR Gestion de base du casque VR Gestion de base des manettes Occulus Le paquet Mirror Gestion de reseau Copie de Unet, API reseau de Unity Fonctionnement Pour les armes: Reprise du fonctionnement du TP INtroduction de Commands Pour la camera VR: Reprise du TP Ajout d‚Äôun script pour l‚Äôinitialisation du multi Boucles de jeu principales Pas de PVs Emphase sur la vitesse pour attraper l‚Äôepee ou le pistolet Des qu‚Äôun joueur se fait toucher: MORTDifficultes La camera Reprendre le TP correctement Avoir la camera au bon endroit Synchro de la camera et bugs mix VR/Network Le reseau Synchro des positions Gestions d‚Äôautorite avec Mirror Tentatives ratees Robot Kyle avec des animations Bug de reseau, etc‚Ä¶ VR Rig Perso 3D Notre propre mesh de personnage (blender et unity voulaient pas) Ajout de joueurs (sur tel par exemple)Outils Polybrush LowPOlyConclusion Projet ultra fun Necessite de recruter des cobayes pour les tests (Nausee, etc.) Bonne decouverte de Unity (admissions paralleles) Press F to pay respect at Robot KyleQuestionsProjets de combien de temps ? Fait la semaine derriereImmobile ou on peut se deplacer ? On peut se deplacer mais certainement mort instantFonctionne sur casque autre que Occulus ? Utilisation de OVR, jamais pose la question vu que le but est de le faire en QuestCreation des contenus 3D? Recuperation d‚Äôassets + assemblage des scenes a la main.Organisation du travail ? Occulus maison, 1 s‚Äôoccupe des scenes et les 2 autres le reste, beaucoup de pair programming" }, { "title": "PFEE Vesselness Covid", "url": "/cours/posts/pfee_covid/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-01 16:00:00 +0100", "snippet": "Lien de la note HackmdSous la supervision d‚ÄôOdyssee MerveillePar Camille, Rene-Louis, Salome et SophieAnalyse des consequences du Covid dans les vaisseaux sanguins.VesselnessAlgo se basant sur les structures tubulaires des vaisseaux sanguinsRORPO Tool using mathetical morpholy to segment vessels characterizing the curvilinear structures detecting these strcutures by countin th number of high responses of an oriented filter, the path operatorsUne reponse indique le rayon et l‚Äôautre le chemin du vaisceauBut et problematique du PFEE Peut-on utiliser RORPO pour analyser les differences entre patient sain et pattient atteint ? Ces differences nous permettent-elles de determiner l‚Äôavancement de la maladie ?La pipeline Segmentation via RORPO Extraction de donnees/metriques Visualisation des metriques Analyse des resultatsTimeline du projetPrise en main de nouveaux outils Slicer: tres utilise dans l‚Äôimagerie medicale HPC avec qsubMetriques Valider les hypotheses: dilatation du reseaux vasculaire + lesions Certaines metriques moins pertinentes que d‚Äôautres mais sont garder car on connait mal cette maladieSegmentation des vaisseaux:Metriques quantitatives Nombre de composantes connexes Nombre de Voxels labellisesDes donnees par labelMetriques par label, cad par composante connexePas eu le temps de recuperer un outilsUn maximum de minimumOn travail sur les rayons des composantes connexePar element connexe, on calcul le rayon minimum et on en retire: le min des min la moyenne des min le maximum des min un histogramme des minUn maximum de maximumPar element connexe, on calcul le rayon minimum et on en retire: le min des max la moyenne des max le maximum des max un histogramme des maxLa moyenne, une donnee controversee le min des moyennes la moyenne des moyennes le maximum des moyennes Manque de sens theorique si mauvaise segmentation. Mais cette perte de sens ne serait pas exploitable ? Devrion nous pas nous tourner vers une moyenne pondere par la taille des vaisseaux ?Des metriques pour le futur des moyennes ponderees Volume du reseau vasculaire relativement au volume des poumons Volune des composantes connexes Remplacer les metriques par label par des metriques par embranchement grace a un algorithme de transformation en graphePresentation du Dataset Donnees confidientielles Patients + ou - atteintsNombre de composantes connexe augmente avec la severite duUniforme chez les patients les plus atteints, mais besoin de plus de donnees pour en tirer une conclusionRayon moyenExtremum toujours patient severement atteintRecapAugmentation du nombre de voxel pour une taille de poumon qui n‚Äôaugmente pas chez les patients atteints.Conclusion a partir des resultats Les metriques sont a adpate Pas de resultats concluantPour la suite Ajouter de nouvelles metriques Plus grand datasetQuestionsElody PuybareauRORPO ne fait directement de segmentation: quelle est la brique rajoutee pour la segmentation ? Commencer par utiliser RORPO, stagiaire de Odyssee a cree la brique en plus qui a ete reprise pour ce PFEEUtilisation des output du stagiaire ? Faire une pipeline qui prend tout en compte mais algorithme lourd donc division des taches Utilistion de Matplotlib: attention car segmentation binaire mais 3 couleurs a cause de Matplotlib qui en melange pour les objets fins \\(\\rightarrow\\) ne jamais faire confiance a Matplotlib et son interpolationGuillaume TochonBase de donnees restreinte, dur d‚Äôen tirer des estimateurs fiable et representatif: pertinent de montrer des histogramme ? Coefficient de correlation plus pertinents ? Outils pour la posterite car le projet va etre repris, pas vraiment pense a un autre indicateur, but de faire l‚Äôanalyse de donnees que d‚Äôen tirer des conclusionsVous etes satisfait du travail fourni ? Bien aime avoir plus de temps pour travailler, dommage de pas avoir plus de temps pour PFEE, assez content du projet. A la fin du projet proche d‚Äôavoir une demarche scientifique complet, manque de temps. Frustration a cause de blocages sur sujets techniques.Quels sont les cours qui ont ete le plus utile? IMED, IMED2 utile mais arrive un peu tard $\\rightarrow$ PFEE utile pour IMED2Repartition du travail? Pair programming, rotations 2 par 2Question etudiantsTres peu de resultats: comment faire dans ce cas? On peut esperer en avoir plus, tres complique de recuperer des donnees surtout venant de l‚Äôhopital. On ne peut pas en tirer de conclusion.Si vous aviez plus de donnees, comment aurai ete la fin du projet? Beaucoup de recul sur les patients, reflexion sur les resultats mais pas sure de comment conclure.OdysseeIdee de ce PFEE: degrossir la pipeline globale, des etudiants qui travaille sur le pipeline complet, avoir des resultats concrets.Une fois qu‚Äôon a le pipeline complet, on a une vision plus globale et on se rend compte de ce qui bloque, ils ont eu une tres bonne demarche sur le projet. Beaucoup de contraintes: l‚Äôaccessibilite des donnees, acces moyens de calcul, etc.Pipeline develope qui va etre tres util et repris par la suite." }, { "title": "PFEE RORPO", "url": "/cours/posts/pfee_odyssee/", "categories": "Image S8, PFEE", "tags": "Image, S8, PFEE", "date": "2021-02-01 15:30:00 +0100", "snippet": "Lien de la note HackmdRORPO By Odyssee MerveilleMathematical morphologyThe basic operators: Erosion Dilation Opening ClosingHow it works Relies on path operatorsC++ directional featuresRORPO: recuperer des features directionnelles, objets tubulairesDans l‚Äôexemple: indiquer vecteur directionel Pointwise Rank Filter Find orientation of interest Combine orientationsDans l‚Äôexemple: la separation qui minimise le mieux la formule est la bleueImplementationParametres optionel:Iterer pixels image:Chercher la bonne separation des groupes:Combiner orientations sur un meme vecteur:PyRORPOPython moduleLibrairie entierement en C++ pour PythonMethods: RORPO RORPO_multiscaleBindings libs: Ctypes CFFI Boost::PythonWhy pybind11: Focus on C++ Use of c++ to specify the module Simple to useBindingsA droite: definir la methode de notre module python $\\rightarrow$ mapping de notre fonction chapeauBINDING_OF_TYPE: defini tous nos bindings a chaque ligneDocumentationThe documentation on how to create shared library, import shared module in python, on each available functionNew options for C++ progran uint8: convert image in uint8 normalize: input mage normalizedTests pytest virtualenv integretaion machineTests: Float/double input image Input image containging negative values uint8 option windows optionIsotropic imagesIsotropy is uniformity in all orientationsUse of:itk::ResampleImageFilter&amp;lt;TInputImage, TOutputImage, TInterpolarPrecisionType, TTransformationPrecisionType&amp;gt;Encountered difficulties Creation of a PIP package Pas forcement de documentation: package en C++ pour python Package pas installable et distribuables sur differentes plateformes Isotropic imagesQuestionsGuillaume TochonPackage pip manquant mais hors ca est-ce que le produit est considere fini ? Pour les features implementees, le produit est termine, est fonctionel et fonctionne comme planifie au debutApplications concretes de tout ca? Non, hors celle de Odyssee. Odyssee a fourni des images synthetiques pour tester le programme et verifier que les resultats marchaient.Quels ont ete les cours suivis dans la majeur les plus utiles ? Le cours TK et morpho de mathsElody PuybareauQuestion sur RORPO: Vous avez montre l‚Äôexemple avec un nifty, marche que sur nifty ou d‚Äôautres types d‚Äôimage? Ca marche sur d‚Äôautres type d‚Äôimage, marche sur n‚Äôimporte quel type d‚Äôimage. Le ‚Äúload to numpy‚Äù n‚Äôest qu‚Äôun exemple Comment vous gerer la conversation en uint8? Par exemple les donnees medicales sont souvent en 16bits, regarde en details les histoire de dynamique ? Gerer automatiquement: lorsqu‚Äôon recoit des images de type uint16, directement gerer par RORPO Comment a ete decoupe le travail en equipe ? Tous ensembles, separes les differentes taches, etc. ? Separer les differentes tachesPression de faire des points avec Odyssee qui a permis d‚Äôavancer ou auto-motive ? Lorsqu‚Äôon a plusieurs projets en simultanes, oui les reunions avec Odyssee permette de progresser regulierement. Repartir bredouille d‚Äôune reunion permet de se motiver pour la fois d‚Äôapres.ElevesQu‚Äôest-ce qui a bloque le developpement du package pip? Que ce soit pas du full python, pas de facon propre de bind une librairie en C++OdysseeRessenti et travail fourni: projet long a demarrer au debut mais pas mal de background pour comprendre RORPO, beaucoup de code pas forcement hype propre a prendre en main et aussi beaucoup de projets en parallele.Gael et Anna ont propose des solutions satisfaisantes pour le binding, Anna a meme trouve des bugs dans le code original.Le binding en python est suffisant et librairie deja en cours d‚Äôutilisation et au final tres satisfaite du travail.Travail pas tres axe recherche mais plus dev et amelioration." }, { "title": "Reunion rentree", "url": "/cours/posts/reunion_rentree/", "categories": "tronc commun S8, Rentree", "tags": "S8, tronc commun", "date": "2021-02-01 11:00:00 +0100", "snippet": "Lien de la note HackmdJoel Courtois Changer les relation ecole-eleves Generation etudiants purement consomateur (reproches fait si le produit ne correspond pas aux attentes) A tous les niveaux: evolution en temps reel, marche quand tout le monde s‚Äôapplique $\\rightarrow$ echanges Comment suivre les cours dans des condtions correctes ? 170 connectes au lieu de 220 (oups)Les cours Maximum de presentiel ! Accueil dans les labos Contraintes distanciations Etudiants ne souhaitant pas revenir Pour ne pas le nommer, le laboratoire de Gistre - Jojo Depends des eleves, des personnes souhaitant revenir Travaux d‚Äôaggrandissiment impossible car corona On ne peut pas avoir une pure attitude de consommateur, on doit co-construire des solutions.Je n‚Äôai pas eu mon 1er voeu :cry: Effet de desertement: SRS: 50 places pour 25 personnes Aujourd‚Äôhui: 90+ demandes Certains ravis de ne pas avoir leur 1er choix, on ne peut pas donner le 1er voeu a tout le monde :(Beaucoup de personnes en Gistre dont ce n‚Äôetait pas le 1er choixOuvertue de la majeure SanteLe staffNouveaux personnes dans l‚Äôadm pour le suivi des etudiants, equipe mises en place pour renforcer + arrivee de Claire Lecoq15 fevrier: arrivee Florent Boulay pour suivi d‚Äôeleves $\\rightarrow$ personne ressourcesJob a la sortie~20 etudiants n‚Äôayant pas fait leur stage TC car pas d‚Äôoffre On est dans le creux de la vague.Les ing3 ont des stages avec un taux similaires aux annees precedentes.La demande reste extremement forte, notre arrivee sur le marche du travail sera probablement apres la pandemie. Les entreprises vont chasser les epiteens/epiteennes Vous etes les prochains a rejoindre l‚ÄôeliteSoumis aux aleas, prob confinement dans les semaines a suivre, etc. On passera cette periode en mieux que si nous sommes dans cet esprit de travail commun - JojoClaire Lecoq Vous n‚Äôetes pas en fin d‚Äôetudes, vous etes en debut de carriere.1er annee eprouvantes, conditions sanitaires pas oufs, eleves en souffrance On doit creer des collectifs etudiants de notre cote, pour apprendre, retransmettre aux eleves a distance, etc.Questions Gistre Le lab: l‚Äôextension n‚Äôa pas ete faite, transfo en salle de classe mais peut rentransformer en labo si besoin Responsable de majeure present Gistre ne bouge pas Gistre est la et va fonctionner! Les mineures seront en S9 Presentiel prevu, dans GITM par exemple Quelle procedure pour elire les delegues ? Historiquement les etudiants se debrouillent entre eux Le chef de majeure organise lui-meme les elections Semaine AWS : tronc commun avec activites AWS, anime par CHEWIIIIIIIIIIIE Ce n‚Äôest PAS une semaine AWS Attendre les annonces pour savoir si presentiel ou non Tout sera regler cette semaine Tom si tu veux vraiment un mug Amazon, il leur en reste quelques-uns Pour les petits fruits je sais pas, il faut voir avec Joel Courtois Cartes etudiantes pretes cette semaine, distribuee aux delegues $\\rightarrow$ attendre l‚Äôelection des delegues A quoi sert le coatching ? Personne a appeler en cas de difficultes (scolaires, morales, etc.) Profil complementaires entre Elody et Delphine Elody: eleves en decrochage scolaire Delphine: preparateur psychologique, peut aider a construire un chemin en plusieurs etapes $\\rightarrow$ coaching Soutenance de stages gerees au fil de l‚Äôeau, mois de fevrier jusqu‚Äôa Avril/Mai/Juin Nous vous souhaitons un bon parcours dans vos majeures - Claire &amp;amp; Jojo Bonzai, on y va ! - Jojo" }, { "title": "SEDE : How to pass the exam?", "url": "/cours/posts/sede_how_to_pass_the_exam/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-07-13 15:00:00 +0200", "snippet": "Lien de la note HackmdMCQ Have to know basic terms You should be able to demonstrate that you understand the term by explaining it in your own words You should be able to RTFM for Unix Basics c/Unix development give concrete examples create your own examples Advanced questions There will be source code samples to edit (and fix) It won‚Äôt be 100% clean It won‚Äôt be exactly like ‚Äústandard epita code‚Äù Security issues to fix are nasty ones If it‚Äôs different it‚Äôs not necessarily wrong Beware of wrong assumptions You should be able to point ou the most problematic lines Write in proper English" }, { "title": "PROC : Seance de revisions", "url": "/cours/posts/proc_revisions/", "categories": "S6, tronc commun, PROC", "tags": "S6, PROC, tronc commun", "date": "2020-07-03 14:00:00 +0200", "snippet": "Lien de la note HackmdCalculer la densiteEtant donnee $f$, est-ce une densite ? Si oui, $P(\\text{X}\\le3)$ ? Verifier que la $f \\ge 0$ et $\\int^{+\\infty}_{-\\infty} = 1$Calculer avec la densiteEtant donnee $f$ densite, calculer $E(\\text{X})$, $Var({\\text{X}})$ $E(\\text{X}) = \\int^{+\\infty}_{-\\infty}xf(x)dx$ $Var(\\text{X}) = \\int^{+\\infty}{-\\infty}\\biggr(x-E(x)\\biggr)^2f(x)dx=\\int^{+\\infty}{-\\infty}x^2f(x)dx - \\biggr(E(x)\\biggr)^2$X et Y independants, calculer la densite$\\text{X}$ et $\\text{Y}$ independants, densite $f$ et $g$. Densite de $\\text{X} + \\text{Y}$ ? $h(x) = \\int^{+\\infty}_{-\\infty}f(x - y)g(y)dy$Calculer la densite de $\\alpha\\text{X} + \\beta$Densite de $\\alpha\\text{X} + \\beta$. Densite de $\\text{X}$ : $f$. Il faut passer par la fonction de repartition. $F(X) = P(\\text{X}\\le x) = \\int^{+\\infty}_{-\\infty}f(t)dt$ $f(x) = F‚Äô(x)$ Soit $\\text{Y} = \\alpha\\text{X} + \\beta$, $g$ sa densite $G(x) = P(\\text{Y}\\le x) = P(\\alpha\\text{X} + \\beta\\le x)$ Premier CasSi $\\alpha\\gt 0, G(x) = P(\\alpha\\text{X} + \\beta\\le x) = P(\\text{X}\\le\\frac{x-\\beta}{\\alpha}) = F(\\frac{x-\\beta}{\\alpha})$En derivant $G‚Äô(x) = \\frac{1}{\\alpha}F‚Äô(\\frac{x-\\beta}{\\alpha})$Second CasSi $\\alpha\\lt 0, G(x) = P(\\alpha\\text{X}+\\beta\\lt x) = P(\\text{X}\\ge\\frac{x-\\beta}{\\alpha}) = 1 - \\frac{1}{\\alpha}F‚Äô(\\frac{x-\\beta}{\\alpha})$En derivant $G‚Äô(x) = -\\frac{1}{\\alpha}F‚Äô(\\frac{x-\\beta}{\\alpha}) \\Rightarrow g(x) = -\\frac{x-\\beta}{\\alpha}f(\\frac{x-\\beta}{\\alpha})$Convergence en probabiliteDefinition $\\vert X_n\\vert$ converge en probabilite vers $\\text{Y}$ si $\\forall\\epsilon\\gt0, P(\\vert\\text{X} - \\text{Y}\\vert\\gt\\epsilon)\\to_{n\\to\\infty}0$Rappel \\(\\int_1^{+\\infty}\\frac{1}{x^{\\alpha}}dx\\begin{cases} \\text{converge si et seulement si} &amp;amp; \\alpha\\gt1\\\\ \\text{diverge si et seulement si} &amp;amp; \\alpha\\le1\\end{cases}\\)\\(\\int_0^{1}\\frac{1}{x^{\\alpha}}dx\\begin{cases} \\text{converge si et seulement si} &amp;amp; \\alpha\\lt1\\\\ \\text{diverge si et seulement si} &amp;amp; \\alpha\\ge1\\end{cases}\\)Primitive de $\\frac{1}{x^\\alpha}$:\\(\\begin{aligned}x^{-\\alpha} &amp;amp;= f(x)\\\\F(x) &amp;amp;= \\frac{1}{-\\alpha+1}x^{-\\alpha+1}\\end{aligned}\\)Cas particulier On tire $X_1, X_2,‚Ä¶, X_n$ independemment distribuee et on definit la moyenne $\\bar X_n = \\frac{X_1 + ‚Ä¶ + X_n}{N}$\\(\\begin{aligned}E(\\bar X_n) &amp;amp;= E(X_1)\\\\Var(\\bar X_n) &amp;amp;= \\frac{1}{n}Var(X_1)\\\\\\sigma(\\bar X_n) &amp;amp;= \\sqrt{Var(\\bar X_n)}\\\\\\text{Car}\\space E(\\bar X_n) &amp;amp;= \\frac{1}{n}(E(X_1) + ... + E(X_n)) \\\\ &amp;amp;= E(X_1)\\\\Var(\\bar X_n) &amp;amp;= \\frac{1}{n^2}(Var(X_1) + ... + Var(X_n))\\\\&amp;amp;= \\frac{nVar(X_1)}{n^2} = \\frac{Var(X_1)}{n}\\end{aligned}\\)In√©galit√© de Tchebychev \\(\\begin{aligned}\\forall\\epsilon\\gt0, P(\\vert\\bar X_n - E(X_n)\\vert\\ge\\epsilon) &amp;amp;\\le \\frac{Var(\\bar X_n)}{\\epsilon^2}\\\\&amp;amp;\\le\\frac{Var(X_1)}{n\\epsilon^2}\\to_{n\\to\\infty}0\\end{aligned}\\)Donc $P(\\vert\\bar X_n - E(X_n)\\vert\\gt\\epsilon)\\to_{n\\to\\infty}0$Theoreme central limite $X_1, X_2, ‚Ä¶, X_n$ $\\bar X_n = \\frac{X_1 + ‚Ä¶ + X_n}{n}$On a vu que $E(\\bar X_n) = E(X_1)$ et que $Var(\\bar X_n) = \\frac{1}{n}Var(X_1)$ \\(Z_n = \\frac{\\bar X_n - E(\\bar X_n)}{\\sigma(\\bar X_n)}\\to Z\\)Ou $Z$ a une distribution normal centre reduite: $Z\\rightsquigarrow N(0,1)$ \\(E(Z_n) = 0 \\space\\text{et}\\space Var(Z_n) = 1\\)On a $\\forall[a,b]\\subset\\mathbb{R}$,\\(P(Z_n\\in[a,b])\\to_{n\\to\\infty}P(Z\\in[a,b])\\)Exercice typiquePremier exerciceSoient $X_1, ‚Ä¶, X_n$ independemment distribuee avec $E(X_1) = 3$, $Var(X_1) = 4$ et $\\bar X_n = \\frac{X_1 + ‚Ä¶ + X_n}{n}$. Trouver n tel que $P(\\vert\\bar X_n - 3\\vert \\ge 1)\\le 5\\%$. Solution :warning: Si $Z\\to N(0,1)$, $P(-1,96\\le Z\\le1,96) = 95\\%$1 est pris au hasar mais pas 3, c‚Äôest l‚Äôesperance.Ici, on definit \\(\\begin{aligned}Z_n &amp;amp;= \\frac{\\bar X_n - E(\\bar X_n)}{\\sigma(\\bar X_n)}\\\\&amp;amp;= \\frac{\\bar X_n - 3}{\\sqrt{\\frac{4}{n}}}\\\\&amp;amp;= \\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}}\\end{aligned}\\)Si n est grand:\\(P\\Biggr(-1,96\\le\\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}} \\le 1,96\\Biggr) = 95\\%\\\\P\\Biggr(\\Biggr\\vert\\frac{\\bar X_n - 3}{\\frac{2}{\\sqrt n}}\\Biggr\\vert \\le 1,96\\Biggr) = 95\\%\\\\P\\Biggr(\\vert\\bar X_n - 3\\vert \\le \\frac{1,96 * 2}{\\sqrt n}\\Biggr) = 95%\\\\P\\Biggr(\\vert\\bar X_n - 3\\vert \\ge \\frac{3,92}{\\sqrt n}\\Biggr) = 5\\%\\) Si $\\frac{3,92}{\\sqrt n} = 1$, on a:\\(P(\\vert\\bar X_n - 3\\vert\\ge 1) = 5\\%\\) Si $\\frac{3,92}{\\sqrt n} \\ge n_0$ avec $n_0 = 3,92^2$ valeur minimale de n, on a:\\(P(\\vert\\bar X_n - 3\\vert\\ge 1) \\ge P(\\vert\\bar X_n - 3\\vert\\ge \\frac{3,92}{\\sqrt n}) \\le 5\\%\\) Deuxieme exerciceOn achete une machine. $P_{\\text{Machine defectueuse}} = 2\\%$. On achete $n$ machines. Pour $i\\in [1, n]$\\(X_i =\\begin{cases} 1 &amp;amp; \\text{si defectueuse}\\\\ 0 &amp;amp; \\text{sinon}\\end{cases}\\)et $\\bar X_n = \\frac{X_1 + ‚Ä¶ + X_n}{n}$On sait que $\\bar X_n\\to_{\\text{prob}}2\\%$. Trouver $n_0$ tel que $\\forall n\\ge n_0$, $P(0,01\\le\\bar X_n\\le 0,03) \\ge 95\\%$. Solution Autrement dit, \\(\\begin{aligned}P(\\vert\\bar X_n - 0,02\\vert\\le0,01)&amp;amp;\\ge95\\%\\\\\\text{donc}\\space P(\\vert\\bar X_n - 0,02\\vert\\ge0,01)&amp;amp;\\le5\\%\\end{aligned}\\)\\(X_i =\\begin{cases} 1 &amp;amp; \\text{avec proba}\\space p = 0,02\\\\ 0 &amp;amp; \\text{avec proba}\\space 1-p\\end{cases}\\\\E(X_i) = 0*(1-p)+ 1\\ast p = p\\\\\\begin{aligned}Var(X_i) &amp;amp;= E\\biggr((X_i-E(X))^2\\biggr)\\\\&amp;amp;= E\\biggr((X_i - p)^2\\biggr) = p(1-p) = 0,02 * 0,98\\end{aligned}\\)Pour $\\bar X_n$:\\(\\begin{aligned}E(\\bar X_n) = E(X_1) = p\\\\Var(\\bar X_n) = \\frac{1}{n}Var(X_1) = \\frac{p(1-p)}{p}\\end{aligned}\\)On pose:\\(Z_n = \\frac{\\bar X_n \\ E(\\bar X_n)}{\\sigma{\\bar X_n}} = \\frac{\\bar X_n - p}{\\sqrt{\\frac{p(1 - p)}{n}}}\\) On a donc:\\(\\begin{aligned}P(\\vert Z_n\\vert\\ge 1,96) &amp;amp;= 5\\%\\\\P(\\biggr\\vert \\frac{\\bar X_n - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\biggr\\vert\\ge 1,96) &amp;amp;= 5\\%\\\\P(\\vert \\bar X_n - p\\vert\\ge 1,96\\sqrt{\\frac{p(1-p)}{n}}) &amp;amp;= 5\\%\\\\\\end{aligned}\\)Si $n$ tel que $1,96\\sqrt{\\frac{p(1-p)}{n}} \\le 0.01$, on a $P(\\vert X_n - p\\vert\\ge 0,01)\\le5\\%$Troisieme exerciceSoit $f(x) = ‚Ä¶$. Si vous pensez que $f$ est une densite, entrer $P(X\\le3)$ Sinon rentrer $-1$ Solution :abc: Discussion sur les integrales impropres.Il faut verifier que $\\int_{-\\infty}^{\\infty}f(x)dx = 1$. Si $f$ est non-nulle sur une partie infinie de $\\mathbb{R}$, il faut discuter de la nature de l‚Äôintegrale. Soit elle est: divergente et $f$ n‚Äôest pas une densite convergente et verifier que l‚Äôintegrale vaut 1 et que $f$ est positive ExemplesExemple 1\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{si}\\space x\\le1\\\\ \\frac{1}{x} &amp;amp; \\text{si}\\space x\\gt1\\end{cases}\\) Solution \\(\\int^{+\\infty}_{-\\infty}f(x)dx = \\int^{+\\infty}_{1}\\frac{1}{x}dx\\)L‚Äôintegrale est divergente donc $f$ n‚Äôest pas une densite.Exemple 2\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{sur}\\space ]-\\infty, 1]\\\\ \\frac{1}{x^{10}} &amp;amp; \\text{sur}\\space ]1, +\\infty[\\end{cases}\\) Solution \\(\\begin{aligned}\\int^{+\\infty}_{-\\infty}f(x)dx &amp;amp;= \\int^{+\\infty}_{1}\\frac{1}{x^{10}}\\space\\text{avec}\\spacex^{-10}\\to\\text{primitive:}\\space\\frac{1}{-10 + 1x^{^-10+1}}\\\\&amp;amp;=\\biggr[-\\frac{1}{9}\\ast\\frac{1}{x^9}\\biggr]^{+\\infty}_{1}\\\\&amp;amp;=0-(-\\frac{1}{9}) \\\\&amp;amp;= \\frac{1}{9}\\end{aligned}\\)$f$ n‚Äôest pas une densite.Exemple 3\\(f(x) =\\begin{cases} 0 &amp;amp; \\text{si}\\space x\\le1\\\\ \\frac{9}{x^{10}} &amp;amp; \\text{si}\\space x\\gt 1\\end{cases}\\) f est une densite (cf exo ci-dessus) $P(X\\le3)$? $E(X)$? $Var(X)$? Solution $P(X\\le3)$?\\(\\begin{aligned}P(X\\le3) &amp;amp;= \\int^{3}_{-\\infty}f(x)dx\\\\&amp;amp;=\\int^3_1\\frac{9}{x^{10}}dx \\space\\text{avec}\\space\\frac{9}{x^{10}}\\to\\text{primitive:}-\\frac{1}{x^{9}}\\\\&amp;amp;=\\biggr[-\\frac{1}{x^{9}}\\biggr]_1^3 = -\\frac{1}{3^9} + \\frac{1}{1^9} = 1 - \\frac{1}{3^9}\\end{aligned}\\) $E(X)$?\\(\\begin{aligned}E(X) &amp;amp;= \\int^{+\\infty}_{-\\infty}xf(x)dx\\\\&amp;amp;= \\int^{+\\infty}_{1}\\frac{9x}{x^{10}}dx\\\\&amp;amp;= \\int^{+\\infty}_{1}\\frac{1}{x^{9}}dx \\space\\text{avec}\\space x^{-9}\\to\\text{primitive:}\\frac{1}{-9+1}x^{-9+1} = -\\frac{1}{8}x^{-8}\\\\&amp;amp;= 9\\biggr[-\\frac{1}{8}x^{-8}\\biggr]_1^{+\\infty}\\\\\\&amp;amp;= 9[-0+\\frac{1}{8}] = \\frac{9}{8}\\end{aligned}\\) $Var(X)$?\\(\\begin{aligned}Var(X) &amp;amp;= \\int^{+\\infty}_{-\\infty}(x-\\frac{9}{8})^2f(x)dx\\\\&amp;amp;= E(X^2) - (E(X))^2\\\\&amp;amp;= \\int^{+\\infty}_{-\\infty}x^2f(x)dx - (\\frac{9}{8})^2\\end{aligned}\\)\\(\\int^{+\\infty}_{-\\infty}x^2f(x)dx = \\int^{+\\infty}_{1}x^2\\frac{x9}{x^{10}}dx \\space\\text{avec}\\space x^{-8}\\to\\text{primitive:}\\frac{1}{-8+1}x^{-8+1}=-\\frac{1}{7}x^{-7}\\)\\(E(X^2) = 9\\biggr[-\\frac{1}{7x^7}\\biggr]_{1}^{+\\infty} = 9\\biggr(-0+\\frac{1}{7}\\biggr)\\)\\(Var(X) = \\frac{9}{7} - \\frac{9}{8}^2\\) Densite de $X + Y$ quand $X$ et $Y$ independants $X$: densite $f$ $Y$: densite $g$ $Z = X + Y$: densite $h $h$ est la convolution de $f$ et $g$\\(h(x) = \\int^{+\\infty}_{-\\infty}f(x-y)g(y)dy\\) Exemple de distribution uniforme $X\\rightsquigarrow\\mathcal{U}([1, 2])$ $Y\\rightsquigarrow\\mathcal{U}([4, 5])$$f(x)g(y)\\not = 0 \\Leftrightarrow x\\in[1,2]\\space\\text{et}\\space y\\in[4,5]$\\(h(x) = \\int^{+\\infty}_{-\\infty}f(y)h(x - y)dy = \\int^{+\\infty}_{-\\infty}f(x-y)g(y)dy\\)Soit $x_0$ fixe, on calcule $h(x_0) = \\int^{+\\infty}_{-\\infty}f(x_0-y)g(y)dy$.\\(\\begin{aligned}f(x_0-y)g(y) \\not= 0 &amp;amp;\\Leftrightarrow \\begin{cases}1\\le x_0-y\\le2\\\\4\\le y\\le 5\\end{cases}\\\\&amp;amp;\\Leftrightarrow \\begin{cases}\\begin{aligned}x_0 -2\\le\\space &amp;amp;y\\le x_0 - 1\\\\4\\le\\space &amp;amp;y\\le 5\\end{aligned}\\end{cases}\\end{aligned}\\) Vert: $x_0 -2\\le\\space y\\le x_0 - 1$Rouge $4\\le\\space y\\le 5$ Cas $x_0 - 1\\lt4$ ($x_0 \\lt 5$): Pas de $y$ qui convient $h(x_0)=\\int^{+\\infty}_{-\\infty}0dx=0$ Cas $5\\le x_0 - 2$ ($x_0\\ge7$): Pas d‚Äôintersection $h(x_0) = 0$ Cas $4\\le x_0 - 2\\le5\\le x_0 - 1$: $h(x_0) = \\int_{x_0 -2}^5 1\\ast1dx=[x]_{x_0 -2}^5 = 5-(x_0 - 2) = 7 - x_0$ Cas $x_0-2\\le4\\le x_0 -1\\le5$ ($5\\le x\\le6$): $h(x_0) = \\int_4^{x_0-1}1dy = [y]_4^{x_0-1} = x_0 - 1 - 4 = x_0 - 5$ Finalement: $x\\in[5,6]$, $h(x_0) = x_0 - 5$ $x\\in[6,7]$, $h(x_0) = 7 - x_0$ Ailleurs, $h(x_0)=0$" }, { "title": "OPEL : Seance de revisions", "url": "/cours/posts/opel_revisions/", "categories": "S6, Shannon, OPEL", "tags": "S6, OPEL, Shannon", "date": "2020-07-03 10:00:00 +0200", "snippet": "Lien de la note HackmdCalculer les integrales doubles On fixe une integrale et on calcule l‚Äôautre.Premier exo$I = \\iint_D x^2 dxdy, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb{R}^2, x\\le1, \\space y\\ge0,\\text{ et } y\\le x\\rbrace$On trouve d‚Äôabord les bornes, on fixe $x$ et on regarde les variations de $y$. Comme $x\\le1$ et $x\\ge y^2$, $x$ est positif et varie entre 0 et 1. Donc on fixe $x\\in[0, 1]$, on integre par rapport a $y$ positif et $y\\le\\sqrt{x}$, $y$ varie de 0 a $\\sqrt x$. \\(\\begin{aligned}I &amp;amp;= \\int^{x=1}_{x=0}x^2\\biggr(\\int_{y=0}^{y=\\sqrt{\\sqrt{x}}}dy\\biggr) dx\\\\&amp;amp;= \\int^{1}_{0}x^2\\sqrt{x}dx\\\\&amp;amp;= \\int^{1}_{0}x^{\\frac{5}{2}}dx = \\biggr[\\frac{2}{7}x^{\\frac{7}{2}}\\biggr]^{1}_{0}\\\\&amp;amp;= \\frac{2}{7}\\end{aligned}\\)Deuxieme exo$J = \\iint_D x^2dxdy, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb{R}^2, \\frac{x^2}{a^2}+\\frac{y^2}{b^2}\\le1\\rbrace$Cette integrale nous rappelle l‚Äôinterieur d‚Äôun ellipse.Meme technique, on fixe $x$ et on regarde les variations de $y$.Premiere partieQuand on trace une ellipse, $x$ varie entre $-a$ et $a$. Pour trouver les variations de $y$, on fixe $x$ puis on isole $y$, $y$ va dependre de $x$ en fonction de la trajectoire de l‚Äôellipse. On obtient deux branches: une branche positif et une branche negatif en bas. \\(\\frac{x^2}{a^2}+\\frac{y^2}{b^2}\\le1 \\Rightarrow -b\\frac{\\sqrt1 - x^2}{a^2} \\le y\\le +b\\frac{\\sqrt1 - x^2}{a^2}\\)$y$ varie de $-b\\frac{\\sqrt1 - x^2}{a^2}$ a $+b\\frac{\\sqrt1 - x^2}{a^2}$.Deuxieme partieCette integrale est plus dur car on a une racine carree, cela peut s‚Äôapparenter a un changement de variable.\\(\\begin{aligned}J &amp;amp;= \\int_{-a}^{a}x^2\\biggr(\\int_{-b\\frac{\\sqrt1 - x^2}{a^2}}^{+b\\frac{\\sqrt1 - x^2}{a^2}}dy\\biggr)dx\\\\J &amp;amp;= 2b\\int_{-a}^{a}x^2\\sqrt{1-\\frac{x^2}{a^2}}dx \\\\&amp;amp;\\text{On utilise la parite, tous les x sont au carre.}\\\\ &amp;amp;\\text{On fait donc deux fois l&#39;integrale de 0 a a}\\\\J &amp;amp;= 4b\\int_0^{a}x^2\\sqrt{1-\\frac{x^2}{a^2}}dx\\end{aligned}\\)On pose $x = a\\cos(t)$ pour se debarasser de la racine carre. L‚Äôastuce est de faire apparaitre une fonction trigonometrique pour obtenir $1-\\cos^2\\Rightarrow\\sin^2$, $x = a\\cos(t)\\Rightarrow dx=-a\\sin(t)dt$ Il y a un changement de bornes. $0 = acos(t)\\Rightarrow\\frac{\\pi}{2}$ et $x =a, \\cos(t) = 1\\Rightarrow t=0$\\(\\begin{aligned}J &amp;amp;= 4b\\int_{\\frac{\\pi}{2}}^0 a^2\\cos^2(t)\\vert\\sin(t)\\vert(-a\\sin(t)dt)\\\\ &amp;amp;= 4ba^3\\int^{\\frac{\\pi}{2}}_0\\cos^2(t)\\sin^2(t)dt\\space\\text{Attention! les bornes ont ete permuttees}\\\\ &amp;amp;= ba^3\\int^{\\frac{\\pi}{2}}_0\\biggr(\\sin(2t)\\biggr)^2dt=ba^3\\int^{\\frac{\\pi}{2}}_0\\biggr(\\frac{1-\\cos(4t)}{2}\\biggr)dt\\space\\text{car}\\space\\sin(2t) = 2\\sin(t)\\cos(t)\\\\ &amp;amp;= \\frac{ba^3}{2}\\biggr[-\\frac{\\sin(4t)}{4} + t\\biggr]^{\\frac{\\pi}{2}}_0 = \\frac{a^3b\\pi}{4}\\end{aligned}\\) Si la fonction etait impair le resultat serait 0 car $\\int_{-a}^a = 0$Troisieme exo$K = \\iint_D\\cos(x^2+y^2) dxdy, \\space\\text{ou } D=\\text{Disque de centre O et de rayon R}$ Faites un changement de variable en polaire.On pose $x = r\\cos(\\theta)$ et $y = r\\sin(\\theta)$. On est sur un disque de centre $O$ et de rayon $R$. L‚Äôangle polaire $\\theta$ varie de $0$ a $2\\pi$ et r varie de $0$ a $R$.Posons $\\begin{cases}x = r\\cos(\\theta)\\y = r\\sin(\\theta)\\end{cases}$.\\(\\begin{aligned}K &amp;amp;= \\int^{\\theta=2\\pi}_{\\theta=0}\\int^{r = R}_{r=0}cos(r^2)rdrd\\theta\\space\\text{car c&#39;est le Jacobien}\\\\&amp;amp;= \\int^{2\\pi}_{0}d\\theta\\int^{R}_{r=0}r\\cos(r^2)dr\\\\&amp;amp;= 2\\pi\\biggr[\\frac{1}{2}\\sin(r^2)\\biggr]=\\pi\\sin(r^2)\\end{aligned}\\)Quatrieme exo$I‚Äô = \\iint_D\\frac{dxdy}{(1+x^2)(1+y^2)}, \\space\\text{ou } D=0\\le y\\le x\\le 1$$x$ varie de $0$ a $1$ et $y$ varie de $0$ a $x$. Le domaine est un triangle. Si $y = x$ c‚Äôest la bissetrice.\\(\\begin{aligned}I&#39; &amp;amp;= \\iint_D\\frac{dxdy}{(1+x^2)(1+y^2)}\\\\&amp;amp;= \\int^{x=1}_{x=0}\\int^{y=x}_{y=0}\\frac{dxdy}{(1+x^2)(1+y^2)}\\\\&amp;amp;= \\int^{1}_{0}\\frac{dx}{1+x^2}\\int^{y=x}_{y=0}\\frac{dy}{1+y^2}\\\\&amp;amp;= \\int^{1}_{0}\\frac{\\arctan(x)}{1+x^2}\\\\&amp;amp;= \\biggr[\\frac{1}{2}(\\arctan(x))^2\\biggr]^1_0 = \\frac{1}{2}(\\frac{\\pi}{4})^2 = \\frac{\\pi^2}{32}\\end{aligned}\\)Cinquieme exo$J‚Äô = \\iint_D\\frac{dxdy}{(1+x^2+y^2)^2}, \\space\\text{ou } D=\\lbrace(x,y)\\in\\mathbb(R), \\space \\vert x\\vert\\le x^2+y^2\\le 1\\rbrace$On a l‚Äôinterieur d‚Äôun disque de centre $O$ et de rayon 1. Si $x\\ge0$ $\\vert x\\vert = x \\le x^2 + y^2$ $x^2 - x + y^2 ge 0 \\Rightarrow \\biggr(x - \\frac{1}{2}\\biggr)^2 + y^2\\ge\\frac{1}{4}$ Si $x\\lt0$ $\\vert x\\vert = x \\le x^2 + y^2\\Rightarrow\\biggr(x+\\frac{1}{2}^2\\biggr) + y^2 \\ge \\frac{1}{4}$$D$ est la partie du disque de centre $O$ et de rayon $1$, exterieure au disque de centre $\\Omega(\\frac{1}{2}, 0)$ et de rayon $R=\\frac{1}{2}$ et au disque de centre $\\Omega^1(-\\frac{1}{2}, 0)$ et $R=\\frac{1}{2}$\\(D = D_1U D_2U D_3U D_4\\)D et la fonction $f(x, y)$ sont invariantes dans les symetrie par rapport aux axes. Determiner les extremes des fonctions suivantesPremier exo$f(x,y) = -x^2y+\\frac{1}{2}y^2+y$On determine les points critiques: $\\vec{grad}f=\\vec 0$\\(\\Rightarrow\\begin{cases}\\frac{\\partial f}{\\partial x} = -2xy = 0 \\Leftarrow x= 0\\space\\text{ou}\\space y=0\\\\\\frac{\\partial f}{\\partial y} = -x^2+y+1=0\\end{cases}\\) si $x=0\\Rightarrow y+1=0\\Rightarrow y=-1$ si $y=0\\Rightarrow x^2+1\\Rightarrow x=\\pm1$Donc il existe 3 points critiques: $M_1(0,-1)$, $M_2(-1,0)$ et $M_3(1,0)$.La matrice Hessienne:\\(\\nabla^2f(x,y)=\\begin{pmatrix}-2y &amp;amp; -2x\\\\-2x &amp;amp; 1\\end{pmatrix}\\)Nature des points critiques:\\(\\nabla^2f(x,y)=\\begin{pmatrix}2 &amp;amp; 0\\\\0 &amp;amp; 1\\end{pmatrix}\\)$r=2$, $t=1$, $s=0$$s^2-rt=-2\\lt0$ et $r=2\\gt0\\Rightarrow M_1(0,-1)$ est un minimum local.\\(\\nabla^2f(M_2) = \\begin{pmatrix}0 &amp;amp; 2\\\\2&amp;amp;1\\end{pmatrix}\\\\\\)$s^2-rt=4-gt0\\Rightarrow M_2(-1, 0)$ est un point.\\(\\nabla^2f(M_3) = \\begin{pmatrix}0 &amp;amp; -2\\\\-2 &amp;amp; 1\\end{pmatrix}\\\\\\)$s^2-rt=4-gt0\\Rightarrow M_3(1, 0)$ est un point. Deuxieme exo $f(x, y) = (x^2+y^2)e^{-x}$ Troisieme exo $f(x,y)=e^{x+y}-x^2-y$ Quatrieme exo $f(x,y,z) = z^2+xyz^2+xy$ " }, { "title": "CCMP2 : Seance de revisions", "url": "/cours/posts/ccmp2_revisions/", "categories": "S6, tronc commun, CCMP2", "tags": "S6, CCMP2, tronc commun", "date": "2020-07-02 11:00:00 +0200", "snippet": "Lien de la note HackmdRevisions CCMP2Middle End Traduction vers le langage Tree Lineariser le code etape de linearisation: casser l‚Äôarborescence faire remonter les expressions et instructions qui sont imbriquees jusqu‚Äôa la racine on doit conserver la semantique de notre programme si on remonte quelque chose trop haut il peut ecraser d‚Äôautres instructions Traduction vers des Block de Bases commence par un label, fini par un JUMP ou CJUMP necessaire car: les microprocesseurs actuels n‚Äôont pas des if then else, ils connaissent les CJUMP, condition, label on tronconne le code si on a un block qui commence sans labe =&amp;gt; on rajoute un label si on a un block qui fini sans jump =&amp;gt; on rajoute un jump permet d‚Äôavoir des BB qui peuvent etre ‚Äúbouges‚Äù a volonte Back End Finir la linearisation Choisir un microprocesseur et regarder son jeu d‚Äôinstruction Instruction Selection pour trouver la meilleure instruction en supposant qu‚Äôon a un nombre de registres illimite Couvrir l‚ÄôAST par le jeu d‚Äôinstructions code non generique =&amp;gt; diverge en fonction des microprocesseurs Analyse de vivacite construire un controle flow graph calculer live in et live out (duree de vie de nos variables) deduit le graphe d‚Äôinterference =&amp;gt; variable a et b vivent simultanement (peuvent pas etre dans le meme registre) Allocation des registres input : AST linearise + graphe d‚Äôinterference on va travailler sur le graphe d‚Äôinterference une fois le registre pour une variable trouve on va propager les modification dans l‚ÄôAST (a = registre 1, b = registre 2, etc.) probleme quand on decremente le nombre de registres mettre des variables dans le meme registre si pas assez de registres: faire un spill, mettre des variables sur la pile 1. Faire une coloration 2. Si on n‚Äôy arrive pas: faire un spill 3. Recacul graphe de flow control 4. Reproduire du in et out 5. Reproduire un graphe d‚Äôinterference PartielOn reprend le code et on regarde toutes les utilisations de a.Une premiere idee serait de faire des utilisations directement avec le stack pointer. Le probleme c‚Äôest que les architectures actuelles n‚Äôont pas un double acces de memoire" }, { "title": "CCMP1 : Seance de revisions", "url": "/cours/posts/ccmp1_revisions/", "categories": "S6, tronc commun, CCMP1", "tags": "S6, CCMP1, tronc commun", "date": "2020-07-01 11:00:00 +0200", "snippet": "Lien de la note HackmdRappelsCompilateur a 3 etapes front-end middle-end back-endOn utilise des outils: Le scanner prend en entree un fichier (Java, ‚Ä¶) but : reconnaitre des mots (j‚Äôai reconnu un entier, variable ‚Ä¶) renvoie un token quand reconnais quelque chose token $sujet$, token $verbe$, token complement Le parser marche main dans la main avec le scanner tokens doivent etre connus par le scanner + parser check si le flux de tokens est valide par rapport a une grammaire il faut definir la grammaire: peut etre ambigue TC flashbacks ex : Sujet Verbe Complement Point utilise un arbre de derivation: $\\text{sujet}\\to\\text{verbe}\\to\\text{complement}$ probleme: embarque tout un tas de choses inutiles ex : $Point$ retourne un AST (Abstract Syntax Tree) rpz les differents elements du langage source etre capable de gerer les cas d‚Äôambiguite (conflits shift/reduce) verifier que l‚ÄôAST soit valide utiliser un visiteur trouver un mecanisme pour automatiser l‚ÄôAST: visiteur Le binder lier les utilisations aux declarations des variables faire une premiere phase de nettoyage pour etre sur que notre AST est correct si ce n‚Äôest pas bon : erreur de typage utiliser des regles d‚Äôinferences liage declaration-appel Type-checker verifie si le programme est semantiquement correct parcours l‚ÄôAST check la coherence des types de variable deduction des types Annale Mars 2018VisiteurPermettent de prendre une hierarchie de classe et d‚Äôetre capable de la visiter, cad explorer chacun des elements les un a la suite des autres.Il a egalement un traitement exclusif d‚Äôune classe: un visiteur peut visiter les enfants d‚Äôun noeud. Il a un traitement exclusif d‚Äôune classe.Resoudre le probleme du dispatch statique/dynamique.Appliquer les regles d‚ÄôinferenceSi je suis capable de montrer que 1 est de type entier je ne fais rien. Si je suis capable de montrer que 4 est de type entier et que je suis capable de montrer que 1 est de type entier alors $4 + 2$ est de type entierJe suis capable de montrer que 3 est de type floatant alors $4 + 2 * 3.0$ est de type floatant.8.0 est de type flottant alors l‚Äôexpression est de type floatantDifference coerxicion ouvrante/retrecissante coerxicion ouvrante : prendre un type petit et le mettre dans un type plus gros int i = ....float j = i coexircion fermante : sens inverse mais on perd de l‚Äôinfo Reprise sur erreur if (toto;blablabla) L‚Äôutilisateur peut ecrire quelque chose de invalide mais le programme est capable de nous redonner des informations sur la suite du programme. L‚Äôerreur est sur le ‚Äò;‚Äô, on se met en mode erreur et on continue a ‚Äúmanger‚Äù des tokens jusqu‚Äôa retrouver un etat stable pour afficher plusieurs erreurs (ex: retrouver la parenthese fermante).Lire et discard les tokens jusqu‚Äôa retrouver un token valide Construction dans un langage existant AST Java, C, C++ (plus de Tiger) Liaison des nomsQue modifie le ebreakLe ebreak va nous permettre de breaker sur plusieurs niveaux de boucle Le scanner ? oui Le parser? oui ebreak est-il une instruction ou une expression ? instruction car ne retourne pas de valeur L‚ÄôAST? ne seras pas demander car toute la promotion ne fait pas Tiger Problemes de typageVerifie qu‚Äôon ait un entier et non autre chose. Vu que le ebreak prend un argument c‚Äôest forcement une expression, hors un string est une expression. Il va falloir s‚Äôassurer dans le type checker que la valeur prise par le ebreak est un nombre.Lier le ebreak avec un whileOn pourrait lier le ebreak avec le while mais on ne sait pas ce qu‚Äôil y a la suite car on peut avoir des valeurs que au runtime.DesucragePrendre une construction et la transformer en une autre constructionEvaluation : QCM points negatifs" }, { "title": "Partiels Shannon", "url": "/cours/posts/partiels_shannon/", "categories": "", "tags": "Shannon, partiels", "date": "2020-06-30 00:05:00 +0200", "snippet": " Lundi 6 juillet Mardi 7 juillet Mercredi 8 juillet Jeudi 9 juillet Vendredi 10 juillet PROC10h00-11h30 ¬† CCMP110h00-11h30 ¬† CCMP210h00-11h30 OPEL14h00-15h30 ¬† GPRO14h00-15h30 ¬† ¬† Lundi 13 juillet Mardi 14 juillet Mercredi 15 juillet Jeudi 16 juillet Vendredi 17 juillet ¬† ¬† SEDE10h00-11h30 ¬† CAMA10h00-11h30 ¬† ¬† TRSE14h00-14h45 ¬† ¬† Lundi 20 juillet Mardi 21 juillet Mercredi 22 juillet Jeudi 23 juillet Vendredi 24 juillet ASE110h00-11h30 ¬† LOFOLOGI2FMSI_E10h00-11h00 ¬† JANGUSOCRASEDE210h00-11h30 ANFI14h00-15h00 ¬† RESE14h00-15h00 ¬† DRG114h00-15h00 BGEN15h30-16h30 ¬† RXANMOB215h30-16h30 ¬† ¬† " }, { "title": "QUI : Le formalisme quantique du qubit", "url": "/cours/posts/le-formalisme-quantique-du-qubit/", "categories": "S6, electif, QUI", "tags": "S6, QUI, electif", "date": "2020-06-25 20:00:00 +0200", "snippet": "Lien de la note HackmdLa notion d‚Äôetat quantiqueEspace des etatsEspace lineaire Les etats purs sont la polarisation en selon $O_x$ et $O_y$Pour decrire la polarisation d‚Äôun photon on utilise un espace lineaire, un espace vectoriel de dimension finie $\\mathcal H$ dont les vecteurs de base correspondent aux etats purs.On associe la base ${\\vert x\\rangle, \\vert y\\rangle}$ a $O_x$ et $O_y$. Un etat de polarisation ${\\vert\\Phi\\rangle}$ correspond a un vecteur appartenant a $\\mathcal H$ : \\(\\vert\\Phi\\rangle = \\lambda\\vert x\\rangle + \\mu\\vert y\\rangle\\) On utilise la notation de Dirac.Etat de polarisationIl existe differents types de polarisation pouvant etre representes par un vecteur complexe. $\\mathcal H$ est un espace vectoriel complexe de dimension 2 Cela permet de prendre le conjugue d‚Äôun vecteur:\\(\\overline{\\vert\\Phi\\rangle} = \\langle\\Phi\\vert = \\bar\\lambda\\langle x\\vert + \\bar\\mu\\langle y\\vert\\) $\\bar\\lambda, \\bar\\mu$ : conjugues de $\\lambda,\\mu$ Produit scalaire On peut ecrire une amplitude de probabilite comme un produit scalaire:\\(\\langle\\Psi\\vert\\Phi\\rangle = \\biggr(\\bar\\nu\\langle x\\vert + \\bar\\sigma\\langle y\\vert\\biggr) + \\biggr(\\lambda\\vert x\\rangle + \\mu\\vert y\\rangle\\biggr) = \\bar\\nu\\lambda\\langle x\\vert x\\rangle + \\bar\\sigma\\mu\\langle y\\vert y\\rangle\\) $\\vert\\Psi\\rangle = \\nu\\vert x\\rangle + \\sigma\\vert y\\rangle$ Les vecteurs de bases sont orthogonaux entre eux et sont de norme unitaire:\\(\\begin{matrix}\\langle x\\vert x\\rangle = \\langle y\\vert y\\rangle = 1 &amp;amp; \\text{et} &amp;amp; \\langle x\\vert y\\rangle = \\langle y\\vert x\\rangle = 0\\end{matrix}\\) On a donc:\\(\\langle \\Psi\\vert \\Phi\\rangle = \\bar\\nu\\lambda + \\bar\\sigma\\mu = \\overline{\\langle \\Phi\\vert \\Psi\\rangle}\\)Norme La norme au carre d‚Äôun vecteur $\\vert\\Phi\\rangle$ s‚Äôecrit comme le produit scalaire de $\\vert\\Psi\\rangle$ avec son conjugue $\\langle\\Phi\\vert$:\\(\\Vert\\Phi\\Vert^2 = \\langle\\Phi\\vert\\Phi\\rangle = \\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2\\)Un etat physique represente par un vecteur doit etre normalise : \\(\\Vert\\Phi\\Vert^2 = \\langle\\Phi\\vert\\Phi\\rangle = \\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2 = 1\\)Espace de Hilbert Un espace de Hilbert $\\mathcal H$ est un espace vectoriel complexe pas forcement de dimension finie muni d‚Äôun produit scalaire; introduisant une norme, et complet.Amplitude et probabiliteCalcul d‚ÄôamplitudeLes etats de polarisation sont rpz par des vecteurs unitaires dans $\\mathcal H$. Un etat de polarisation rectiligne ou lineare selon $\\theta$, note $\\vert\\theta\\rangle$ s‚Äôecrit:\\(\\vert\\theta\\rangle = \\cos\\theta\\vert x\\rangle + \\sin\\theta\\vert y\\rangle\\)On peut calculer l‚Äôamplitude de probabilite en utilisant la notation de Dirac pour qu‚Äôun photo polarise suivant $\\theta$ traverse un polariseur oriente suivant $\\alpha$:\\(\\begin{aligned}\\textbf{a}(\\theta\\to\\alpha) &amp;amp;= \\langle\\alpha\\vert\\theta\\rangle \\\\&amp;amp;= \\biggr(\\cos\\alpha \\langle x\\vert + \\sin\\alpha \\langle y\\vert\\biggr)\\biggr(\\cos\\theta \\vert x\\rangle + \\sin\\theta \\vert y\\rangle\\biggr) \\\\&amp;amp;= \\cos\\alpha\\cos\\theta + \\sin\\alpha\\sin\\theta\\\\&amp;amp;= \\cos(\\theta - \\alpha)\\end{aligned}\\)Probabilite Suite au calcul precedent, la probabilite de traverser l‚Äôanalyseur (probabilite de mesurer un photon polarisation selon $\\alpha$) est:\\(\\textbf{P}(\\theta\\to\\alpha) = \\cos^2(\\theta - \\alpha) = \\vert\\langle\\alpha\\vert\\theta\\rangle\\vert^2\\)La probabilite de trouver un etat $\\vert\\Phi\\rangle$ dans un autre etat $\\vert\\Psi\\rangle$ s‚Äôexprime selon:\\(\\begin{matrix}\\textbf{a}(\\Phi\\to\\Psi) = \\langle\\Psi\\vert\\Phi\\rangle &amp;amp; \\textbf{et} &amp;amp; \\textbf{P}(\\Phi\\to\\Psi) = \\vert\\langle\\Psi\\vert\\Phi\\rangle\\vert^2\\end{matrix}\\)La mesure quantiqueOn reprend le systeme de polariseur/analyseur avec l‚Äôanalyseur oriente selon $O_x$. Le polariseur ($\\textbf{P}$) va prepare l‚Äôetat quantique puis l‚Äôanalyseur ($\\textbf{A}$) va tester sa polarisation.$\\textbf{P}_s$ est la probabilite de sortie du photon de ($\\textbf{A}$): ($\\textbf{P}$) est selon $O_x$ : $\\textbf{P}_s = 100\\%\\Rightarrow\\text{Resultat : 1}$ ($\\textbf{P}$) est selon $O_y$ : $\\textbf{P}_s = 0\\% \\Rightarrow\\text{Resultat : 0}$ Polarisation arbitraire Supposons que le polariseur est oriente selon la direction $\\theta$ ou sa direction orthogonale $\\theta_{\\bot}$, on peut construire un systeme orthonorme de vecteur de base ${\\vert\\theta\\rangle, \\vert\\theta_{\\bot}\\rangle}$ a partir de la base ${\\vert x\\rangle, \\vert y\\rangle}$:\\(\\begin{matrix}\\vert\\theta\\rangle = \\cos\\theta\\vert x\\rangle + \\sin\\theta\\vert y\\rangle &amp;amp; \\textbf{et} &amp;amp; \\vert\\theta_{\\bot}\\rangle = -\\sin\\theta\\vert x\\rangle + \\cos\\theta\\vert y\\rangle\\end{matrix}\\)Le polariseur prepare le photon dans l‚Äôetat $\\vert\\theta\\rangle$, on a donc:\\(\\textbf{P}_s = \\cos^2\\theta\\) Apres le passage du photon dans l‚Äôanalyseur, son etat $\\vert\\theta\\rangle$ devient $\\vert x\\rangle$. La mesure modifie (ou perturbe) l‚Äôetat de polarisation.Difference entre mesure classique et quantiqueIl y a une difference de principe entre la mesure en physique classique et la mesure en physique quantique: Cas classique: la quantite physique preexiste a la mesure Si une voiture est contolee a $180km.h^{-1}$, cette vitesse preexistait avant la mesure Cas quantique: l‚Äôetat de polarisation $\\vert\\theta\\rangle$ n‚Äôexistait pas avant d‚Äôetre mesure. Si on prend l‚Äôexemple de la voiture dans une version quantique, son etat de vitesse serait donne par la superposition d‚Äôun etat a $120km.h^{-1}$ et d‚Äôun autre a $180km.h^{-1}$.La notion d‚ÄôoperateurComment un etat quantique peut se transformer sous l‚Äôeffet d‚Äôoperateurs de la forme de matrices de dimensions 2?PrincipesOn peut formuler 2 principes a partir de l‚Äôanalyse de la structure mathematique: L‚Äôetat physique d‚Äôun systeme quantique est rpz par un vecteur $\\vert\\Phi\\rangle$ appartenant a $\\mathcal H$. $\\vert\\Phi\\rangle$ est unitaire ($\\Vert\\Phi\\Vert^2 = 1$) et est un vecteur d‚Äôetat du systeme quantique. Soient $\\vert\\Psi\\rangle$ et $\\vert\\Phi\\rangle$ 2 etats physiques. L‚Äôamplitude de probabilite de trouver $Phi$ dans $Psi$ est $\\textbf{a}(\\Phi\\to\\Psi) = \\langle\\Phi\\vert\\Psi\\rangle$. La probabilite pour $\\Phi$ de reussir le test $\\Psi$ est:\\(\\textbf{P}(\\Phi\\to\\Psi)=\\vert a(\\Phi\\to\\Psi)\\vert^2 = \\vert\\langle\\Psi\\vert\\Phi\\rangle\\vert^2\\) Pour realiser le test on doit preparer le systeme dans l‚Äôetat $\\vert\\Phi\\rangle$ puis on va tester le systeme qui va le mettre dans l‚Äôetat $\\vert\\Psi\\rangle$.Operateur de projectionMesure et projectionDans le test precedent on a fait une projection orthognale sur $\\vert\\Psi\\rangle$" }, { "title": "QUI : La physique du qubit", "url": "/cours/posts/qui-la-physique-du-qubit/", "categories": "S6, electif, QUI", "tags": "S6, QUI, electif", "date": "2020-06-25 19:30:00 +0200", "snippet": "Lien de la note HackmdGeneralitesInformatique quantique L‚Äôinformatique quantique est l‚Äôutilisation des lois et proprietes de la mecanique quantique pour encoder et tranposter de l‚Äôinformation.Mecanique quantique La mecanique quantique est une theorie physique pour decrire un systeme dont la taille est celle d‚Äôun atome ($10^{-10}m$) ou moindre. Tout systeme est ultimement un objet quantique. La mecanique quantique doit permettre de retrouver les lois classiques.Qubits Qubits (Quantum bits) : changer les proprietes quantiques individuelles d‚Äôune particule telle que son energie, sa polarisation, son ‚Äúspin‚Äù pour encoder de l‚Äôinformation. C‚Äôest la plus petite quantite d‚Äôinformation que l‚Äôon peut transporter ou stocker dans un systeme quantique.Loi de Moore Le nombre de transistors garves sur une puce double tous les 18 mois environ.D‚Äôapres cette loi, les dimensions d‚Äôun puce seront inferieures a 10 nm apres 2020. A cette echelle les proprietes quantiques des atomes et electrons vont devenir importantes.Avantages et inconvenients du calcul quantique Superposition Un bit classique peut seulement prendre les valeurs 0 et 1 Un qubit peut prendre les valeurs 0 et 1 et toutes celles intermediaires Un qubit est constitue d‚Äôune superposition lineaire des etats quantiques correspondant aux bits 0 et 1 cela decuple les capacites de calcul, le cryptage et de transport de l‚Äôinformation Intrication 2 objets quantiques intriques bien que separes pas une distance arbitraire sont une seule et meme entite on ne peut pas comprendre cette entite comme la reunion de 2 objets independants Parallelisme mise en oeuvre des proprietes de superposition et d‚Äôintrication permet a un ordinateur quantique de realiser plus d‚Äôoperations qu‚Äôun ordinateur classique algoritmes quantiques algorithme de Shor algorithme de Grover Decoherence : Obstacle majeur sensibilite a l‚Äôenvironnement entraine une perte de relation de phase entre 2 etats quantiques relation necessaire a la realisation d‚Äôun calcul quantique interaction des qubits avec l‚Äôenvironnement qui brouille les superpositions lineaires Un ordinateur quantique fiable doit etre parfaitement isole. Des codes d‚Äôerreur ont ete creer pour palier aux defauts d‚Äôisolation.Premier modele physique d‚Äôun qubit : le photon La polarisation du photon sers a encoder de maniere quantique un qubit.PolarisationLa polarisation a ete mise en evidence avec un cristal birefringent, c.a.d. qui decompose la lumiere en deux rayons polarises dans des directions perpendiculaire alors que la lumiere incidente est polarisee. Les vibrations lumineuses ont un caractere vectoriel.Une onde transverse Pour une orientation convenable, on observera une extinction d‚Äôun des deux rayons. C‚Äôest une vibration transverse (orthogonale) a la direction de propagation. Une onde scalaire se propageant au cours du temps selon la direction $O_z$ est decrite par:\\(u(z,t) = u_o\\cos(\\omega t - kz)\\) $\\omega = ck = \\frac{2\\pi}{T} = 2\\pi f$ : frequence angulaire de la vibration ($s^{-1}$) $c$ : vitesse de la lumiere ($m.s^{-1}$) On se place dans un plan fixe en $z = 0$ : \\(u(z = 0, t) = u(t) = u_0\\cos(\\omega t)\\) Vecteur polarisation Le modele de l‚Äôonde scalaire peut se generaliser aux 3 dimensions pour representer le vecteur champ electrique qui caracterise une onde lumineuse:\\(\\vec E = \\vec E_0\\cos(\\omega t)\\) L‚Äôorientation de ce champ est la polarisation de la lumiere.La lumiere est percue comme un champ electromagnetique dont la composante electrique est orthogonale a sa direction de propagation. Pour decire l‚Äôorientation du champ electrique on a besoin d‚Äôun systeme d‚Äôaxe $O_x$ et $O_y$. En posant $\\Vert \\vec E_0 \\Vert = E_0$ : \\(\\vec E = \\begin{pmatrix} E_x \\cr E_y \\end{pmatrix} = E_x \\vec u_x + E_y \\vec u_y \\Rightarrow \\vec E = E_o\\cos \\theta \\cos(\\omega t)\\vec u_x + E_0 \\sin \\theta\\cos(\\omega t)\\vec u_y\\) L‚Äôangle $\\theta$ caracterise l‚Äôorientation de $\\vec E$ dans $xOy$, c.a.d. la polarisation L‚Äôintensite de l‚Äôonde lumineuse est proportionnelle au carre du champ electrique\\(I \\propto E_0^2\\) On introduit un vecteur unitaire, note $\\hat{p}$ et appartenant au plan $xOy$ tel que:\\(\\hat{p} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta\\end{pmatrix} \\Rightarrow \\vec E = E_0\\cos(\\omega t)\\hat{p}\\) Si $\\theta = 0$ : polarisation selon $O_x (\\hat{p} = \\vec u_x)$ Si $\\theta = \\pi / 2$ : polarisation selon $O_y (\\hat{p} = \\vec u_y)$ Changement et mesure de la polarisation de la lumierePolariseur et analyseurOn utilise un systeme a 2 polarisateurs consecutifs pour changer et mesurer l‚Äôorientation du champ $\\vec E$: polariseur ‚Äúd‚Äôentree‚Äù : oriente la polarisation de la lumiere incidente selon un angle $\\theta$ par rappor a $O_x$ polariseur ‚Äúde sortie‚Äù (l‚Äôanalyseur) : possede un axe de polarisation faisant un angle $\\alpha$ avec $Ox$ On utilise un vecteur unitaire $\\hat{n}$ pour decrire la polarisation de l‚Äôanalyseur\\(\\hat{n} = \\cos\\alpha\\vec u_x + \\sin\\alpha\\vec u_y = \\begin{pmatrix}\\cos\\alpha\\\\ \\sin\\alpha\\end{pmatrix}\\)Loi de Malus On doit determiner l‚Äôorientation du champ electrique $\\vec E‚Äô$ pour mesurer la polarisation a la sortie de l‚Äôanalyseur.On projete $\\vec E$ oriente selon $\\hat{p}$ dans la direction $\\hat{n}$\\(\\begin{aligned}\\vec E &amp;amp;= (\\vec E \\cdot\\hat{n})\\hat{n} \\\\&amp;amp;= E_0\\cos(\\omega t)(\\hat{p}\\cdot\\hat{n})\\hat{n} \\\\&amp;amp;= E_0\\cos(\\omega t)(\\cos\\theta\\cos\\alpha + \\sin\\theta\\sin\\alpha)\\hat{n}\\\\\\vec E &amp;amp;= E_0\\cos(\\omega t)\\cos(\\theta - \\alpha)\\hat{n}\\end{aligned}\\) La loi de Malus est une loi classique pour l‚Äôintensite a la sortie de l‚Äôanalyser:\\(I&#39; = I\\cos^2(\\alpha-\\theta)\\)Type de polarisation Pour une polarisation lineaire, les deux composantes de $\\vec E$ ont la meme dependence par r Les composantes de $\\vec E$ se notent avec une phase specifique a chacune qui peut etre differentes : \\(\\begin{cases}E_x = E_0\\cos\\theta\\cos(\\omega t - \\delta_x) \\\\E_y = E_0\\cos\\theta\\cos(\\omega t - \\delta_y)\\end{cases}\\) En fonction de la differnce de phase $\\delta = \\delta_x - \\delta_y$: Si $\\delta = 0$ ou $\\delta = \\pm\\pi$ : polarisation rectiligne $E_x$ et $E_y$ oscillent dans un plan fixe faisant un angle $\\theta$ avec $Ox$ Si $\\theta = \\pm\\frac{\\pi}{2}$ : polarisation circulaire l‚Äôextremite du vecteur $\\vec E$ decrit un cercle au cours du temps Si $\\theta \\not = p\\frac{\\pi}{2}$ avec $p \\in \\mathbb{Z}$ : polarisation elliptique pas de relation particuliere entre les phases des composantes l‚Äôextremite de $\\vec E$ decrit une ellipse On ne peut pas mesurer la phase individuelle d‚Äôune composante $\\vec E$, seule $\\delta$ est accessible. On peut imposer $\\delta_x = 0$ en redefinissant l‚Äôorigine des temps. Le champ electrique $\\vec E$ peut aussi s‚Äôecrire : \\(\\vec E = E_0\\textbf{Re}\\biggr[e^{-i\\omega t}\\begin{pmatrix}\\lambda \\\\ \\mu\\end{pmatrix}\\biggr]\\space \\text{avec} \\begin{pmatrix}\\mu \\\\ \\lambda\\end{pmatrix} = \\begin{pmatrix}\\cos\\theta e^{i\\delta_x} \\\\ \\sin\\theta e^{i\\delta_y}\\end{pmatrix}\\) $\\begin{pmatrix}\\mu \\ \\lambda\\end{pmatrix}$ : polarisation $\\mu,\\lambda\\in \\mathbb{C}$ $\\vert\\lambda\\vert^2 + \\vert\\mu\\vert^2 = 1$ Approche quantique de la polarisationEn reduisant l‚Äôintensite lumineuse, on peut etudier la polarisation rectiligne individuelle de chaque photon constituant la lumiere. La taille typique d‚Äôun photon est donnee par sa longueur d‚Äôonde de l‚Äôordre du nanometre.On detecte $N$ photons, si $N\\to\\infty$ on doit retrouver le comportement ondulatoire classique de la lumiere.On prend une lame birefringente avec des photons incidents dont la polarisation rectiligne fait un angle $\\theta$ avec $O_x$.Non simultaneiteLe faisceau est separe en des faisceaux d‚Äôintensite: $I\\cos^2\\theta$ polarise selon $O_x$ $I\\sin^2\\theta$ polarise selon $O_y$ Un photon est detecte soit en $D_x$ soit en $D_y$ Pour mesurer la probabilite de detection d‚Äôun photon pour chaque detecteur:\\(\\textbf{P}_x = \\cos^2\\theta \\space \\textbf{et}\\space \\textbf{P}_y = \\sin^2\\theta\\)Cette experience met en valeur l‚Äôaspect corpulaire de la lumiere.Recouvrement de la loi classique Si $N$ photons sont envoyes alors le nombre de photons detectes par chaque detecteur est :\\(D_x:N_x\\simeq N\\cos^2\\theta \\space \\textbf{et} \\space D_y:N_y\\simeq N\\sin^2\\theta\\)On retrouve la loi de Malus lorsque $N\\to\\infty$.Nature probabilisteIl est impossible de prevoir le chemin d‚Äôun photon, ce qui est en opposition avec le determinisme de la mecanique classique.Recombinaison de faisceauOn cherche a recombiner deux faisceaux, et retrouver la loi de Malus malgre la differentiation de chemin, par ce dispositif:On s‚Äôattend a une intensite de sortie proporionelle a $\\textbf{P}_x$.Le photons a 2 chemins possibles : (E) : il traverse le polariseur avec une probabilite de $\\cos^2\\theta$, puis l‚Äôanalyseur avec une probabilite de $\\cos^2\\theta$ la probabilite totale est $\\cos^2\\theta\\cos^2\\alpha$ (O) : il traverse le polariseur avec une probabilite de $\\sin^2\\theta$, puis l‚Äôanalyseur avec une probabilite de $\\sin^2\\theta$ la probabilite totale est $\\sin^2\\theta\\sin^2\\alpha$ La probabilite totale est : \\(\\textbf{P}_{tot} = \\cos^2\\theta\\cos^2\\alpha + \\sin^2\\theta\\sin^2\\alpha \\not = \\cos^2(\\theta - \\alpha)\\)Le raisonnement est FAUX.Amplitude de probabilite Pour retrouver la loi de Malus, il faut raisonner a partir de la notion d‚Äôamplitude de probabilite pour chaque chemin. Le module au carre de cette amplitude donne la probabilite: \\(\\begin{matrix}\\textbf{a}(\\theta\\to x) = \\cos \\theta &amp;amp; \\textbf{a}(\\alpha\\to x) = \\cos \\alpha\\\\\\textbf{a}(\\theta\\to y) = \\sin \\theta &amp;amp; \\textbf{a}(\\alpha\\to y) = \\sin \\alpha\\end{matrix}\\) $\\textbf{a}(\\theta\\to x)$ : amplitude assiociee a la probabilite de detecter un photon polarise selon $O_x$ L‚Äôamplitude totale de sortie s‚Äôobtient en superposant les amplitudes pour des chemins indiscernables:\\(\\textbf{P}_{tot} = \\vert\\textbf{a}_{tot}^2\\vert = \\cos^2(\\theta - \\alpha)\\)Le raisonnement est BON.DiscernabiliteUn photon ne fait aucune distinction entre les chemins (E) et (O), sinon la probabilite serait $\\textbf{P}_{tot} = \\cos^2\\theta\\cos^2\\alpha + \\sin^2\\theta\\sin^2\\alpha \\not = \\cos^2(\\theta - \\alpha)$. C‚Äôest l‚Äôindiscernabilite des chemins possibles.InterpretationOn a 2 interpretations possibles: Le photon emprunte 2 trajets a la fois la question ‚ÄúQuel trajet ?‚Äù n‚Äôa aucun sens La deuxieme interpretation est preferable car il est impossiblde de differencier les chemins experimentalement. La notion de trajectoire n‚Äôexiste pas en physique quantique. Elle est remplacee par la notion de probabilite de presence. Un photon ne peut prendre physiquement qu‚Äôun seul des 2 chemins.Application : La cryptographie quantiqueOn attribue arbitrairement : Valeur 1 : photon polarise par $O_x$ Valeur 0 : photon polarise par $O_y$Convention de communicationSi Alice (A) et Bob (B) echangent des informations sous forme quantique alors cela prend la forme d‚Äôune suite de photons polarises : \\(\\text{y y x y x y y y x ...}\\)Bob analyse la polarisation de l‚Äôinformation recue a l‚Äôaide d‚Äôune lame birefringente et en deduis le message de Alice\\(\\text{0 0 1 0 1 0 0 0 1 ...}\\)Possibilite d‚ÄôecoutePour intercepter le message, Eve va devoir mesurer la polarisation quantique d‚Äôun des photons, elle a $50%$ de chance de se tromper, puis doit renvoyer le photon a Alice et a $50%$ de chance de se tromper. Si leur message a ete espionne, Alice et Bob peuvent constater une plu grande quantite d‚Äôerreurs.Protection de la cle publiqueProtection de la cle publique La cryptographie repose sur une cle de chiffrage (cle publique) connue seulement de l‚Äôexpediteur et du destinataire.Le temps de calcul est le principal obstacle pour dechiffrer le messageCryptographie quantiqueIl s‚Äôagit de proteger la cle de chiffrage, tel que s‚Äôassure que la transmission d‚Äôune cle n‚Äôa pas ete espionee (distribution quantique d‚Äôune cle).Protocole BB84Choix de polarisation On suppose qu‚ÄôAlice peut envoyer 4 types de photons avec des polarisations rectilignes differentes: On peut regrouyper les polarisations en 2 ensembles differents:TransmissionAlice choisit au hasard une des deux bases pour emettre / recevoir des photonsCes bases sont constituees par des systemes similaires a la lame birefringente.Quand Bob recoit un photon, il choisit parmis ce bases aleatoirement. Il va ensuite analyser la polarisation du photon recu.ReceptionParfois la base de reception de Bob $\\mathfrak B_B$ n‚Äôest pas ‚Äúalignee‚Äù avec la polarisation du photon recu, l‚Äôetat de polarisation est projete sur l‚Äôune des 2 directions de $\\mathfrak B_B$.ComparaisonAlice rend publique sa base d‚Äôemission $\\mathfrak B_A$ pour indiquer a Bob les photons recus dont la polarisation n‚Äôetait pas alignee. Si $\\mathfrak B_B \\not = \\mathfrak B_A$ il y a eu une projection, dans ce cas le photon recu est rejete et Bob conserve que les photons dont la $\\mathfrak B_B$ etait en accord avec $\\mathfrak B_A$. Dans le tableau la cle conservee ou clee reconciliee est $\\text{0 1 0 1 ‚Ä¶}$InterceptionUne personne souhaitant intercepter le message (Eve) doit recevoir d‚ÄôAlice puis renvoyer a Bob chaque photon intercepte. 2 cas se presentent : La base $\\mathfrak B_E$ de Eve est alignee Eve a 0% de chances de se tromper La base $\\mathfrak B_E$ de Eve est non-alignee Eve a 50% de chances de se tromper Non-clonageIl est impossible pour Eve de proceder differemment, elle est obligee de projeter. Theoreme de non-clonage : Il est impossible d‚Äôinteragir avec un ‚Äúetat quantique‚Äù sans le modifier, il ne peut pas etre clone. Alice et Bob peuvent detecter un eventuel espion avec une probabilite de $1-\\frac{3}{4}^n$" }, { "title": "SUDE : Last session", "url": "/cours/posts/sude_last_session/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-06-17 10:00:00 +0200", "snippet": "Lien de la note HackmdAssessment To upload before the presentation tomorrow We can do a video, just make sure it‚Äôs available in Teams The difficult part is to find green it actions If people can‚Äôt speak during the presentation because of thechnical issues, no problem : others can speak or video Don‚Äôt mix up the Green IT with corporate obligations. We should talk about the actions taken to reduce the impact on the environment.There used to be a club called Club Green IT, good lead for a subject.SDG Put the SDG at the end of the presentation We don‚Äôt have to develop them, just do orally the presentation on the first part One sentence per SDG is enough We are not asking for a report, just put bullet points GHG emissionsWhat is the point of computing GHG emitted by a company ? To prepare an action plan to reduce them.Metal in IT China owns most of the rare earth production, they can choose to not provide it anymore.We have to be careful about metals in IT, some resources are low and the price may rise.Average computer lifespan 1985 : 10 to 15 years (average lifespan of 10 years), easy to upgrade, fix, reuse and recycle 2007 : lifespan dropped to 2,5 years launch of Windows Vista =&amp;gt; most companies had to change equipment because the hardware couldn‚Äôt support the new OS versions same problem for MacOS perfect example on how they did not consider that everyone had good enough hardware 2015 : 3 to 15 years (average lifespan of 5 years), impossible to upgrade, fix, reuse or recycleImpacts on the life cycleWhat are the impacts at each stage of the life cycle ?ProductionWhat are the environmental impacts of the components ? 40 chemical components in a smartphone, including rare earth. Part of our electronic equipment are mined in unsanitary conditions and uses child labor =&amp;gt; confilct minerals pollution high production ratesUse Devices with various energy efficiencyEnd of life 1,68 millions tons of electronic waste put on the market in 2015 166 times the Eiffel Tower‚Äôs weight 75% of electronical waste is out of the official radar sent to illegal landfills (Ghana, Nigeria, China, India, Pakistan, Bangladesh, South America) Production has the biggest impact on the environment.VocabularyGreen IT Continous improvement process aiming at reducing ICT ecological, economical and social footprint.IT For Greem The approach that uses digital with th objective to reduce environmental impact.Sustainable design for digital service Approach allowing to integrate environmental, economical and social aspects in the design of a digital service.What is Eco Design ? Eco-design is an innovative approach.Stages of the life cycle Raw materials Focus on renewable/recycled materials Volume/weight reduction Manufacturing Choice of cleaner technologies Reduction of the number of parts and materials Reduction in assembly operations Reduction in production waste and emissions Distribution Eco-design and packaging Reduction of the weight / volume ratio Logistics optimization Sales Consideration of the eco-design of POS advertising and other sales support Eco-design of shops Usage Increase durability (reliability, repair, modularity, etc.) Promotes updates (recharge, etc.) Switch from product to service Shared use og the product End of life Separable materials Material recovery Component recovery Product recovery (reuse) Digital AccessibilityExample : Color BlindnessAbout 8% of men and 0.5% of women worldwide are red-green colorblind. Make sure to use colors that everyone can see.Green IT Actions" }, { "title": "Reunion APP ERO", "url": "/cours/posts/appero/", "categories": "S6, tronc commun, APP ERO", "tags": "S6, APP ERO", "date": "2020-06-10 10:00:00 +0200", "snippet": "Lien de la note HackmdDrone: parcourir les rues au moins une fois graphe non orient√©D√©neigeuses : reprend le graphe en orient√© 2 arcs : une fois dans un sens pour d√©neiger d‚Äôun c√¥t√© et la deuxi√®me fois pour l‚Äôautre c√¥t√© une rue peut etre √† sens uniquer√©seau p√©destre et routier : on ne s‚Äôoccupe que des deneigeuses qui d√©neigent la route, pas les trottoirsProbl√©matique de graphe euleriens et non eulerien Si non-eulerien : degr√©s impairs rendre le graphe eulerien de fa√ßon optimale =&amp;gt; poids minimalQuels sont les param√®tres attendus ? solve : option orient√©e et non orient√©e orient√©e : d√©neigeuse non-orient√© : drone Pr√©sentation vid√©oPlut√¥t libre, contrainte de dur√©e (10 min)MoulinetageExpliquer dans le readme comment executerExpliquer nos choix, quelles sont les limitesQu‚Äôest-ce qu‚Äôon regardeLa distance entre 2 sommets distincts : Floyd-Warshall et non DjisktraDans le cas non-oriente : je prend l‚Äôarrete qui me coute le moins cher =&amp;gt; couplage parfaitNotationOuvrir tout les rendus, on explique comment l‚Äôexecuter et Bashar le fait tourner sur un graphePouvoir iterer sur cles + valeurs2 solves: solve_dummy : utiliser les librairies pour faire un truc opti solve normal : celui qui sera utilise" }, { "title": "Journee de presentation de stages", "url": "/cours/posts/stage/", "categories": "S6, stage", "tags": "S6, stage", "date": "2020-06-09 10:00:00 +0200", "snippet": "Lien de la note Hackmd adista : ogrosjeanne@adista.fr python typescripts Boston consulting group : freier.niels@bcg.com Pas de descriptif exact de stage profile data science bon en python (possible si bon java / scalar / c++) stage a Paris 4/5 stagiaires Datakeen : gael@datakeen.co Machine learning engineer JS, Python, Docker, Kubernetes Grande arche de la defense Factonics Data science devops AWS, PostgreSQL 19e Paris Make me reach : axelm@perion.com AWS, NodeJS, TypeScript Dans Paris en face du grand Rex Mindo : dan.elgrabli@mindo.app, sebastien.lepy@mindo.app Brainsonic : tutur@brainsonic.com CB+ : Front-end Back end Fullstack Veesion Front end : Python, GCP, AWS, Azure, Docker, Ansible, Jenkins Backend : Python, Django, concept d‚ÄôAPIs, Docker, Ansible Jenkins 3IE Advance QCM " }, { "title": "SUDE : Les gazs a effet de serre", "url": "/cours/posts/sude_gaz_serre/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdIntroduction to GreenHouse Gases (GHG) emission calculationWhat are the main green house gases? Carbone Dioxyde Methane N2O Methodologies to compute GHG emissions GHG protocol (US methodology) ISO 14064-1 Bilan Carbone (french methodology)Designing a carbon footprint Organizational boundaries In a control approach you account for all GHG emissions from facilities over which you have a financial or operational control In a equality share approach you would account for GHG emissions in proportion to the percentage ownership over the facility Base year have to set a base year so you can follow the emission trend Operational boundaries have to decide which emissions to report Direct emissions (scope 1) and energy indirect emissions (scope 2) are mandatory Reporting of other indirect emissions (scope 3) is not Emission scopes Scope 1 = Direct energy sources Any source activity from an asset controlled by the organization Ex : electricity to light the office Scope 2 = Indirect energy sources Any source activity not controlled by the organization that generates energy used by the organization Ex : a car used by an employee Scope 3 = Other indirect sources Any non-energy related sources not controlled by the organization that impacts the organization Monitoring Emissions Data collection Data processing Organisation project management people involved etc. Identify sources Activity that impacts organization‚Äôs operation and results in the emission of greenhouse gases Examples Natural gas heating Water use Business travel Air conditionning Waste sent to municipal landfill‚Ä¶ Collect data and define units to use Natural gas heating m3 Gj ft3 Ccf Electricity kWh Gj Emission factors An emission factor is a ratio corresponding to the amount of greenhouse gases emitted as a result of a given unit of activityExample - Natural Gas GWP : a ration denoting the effect of a quantity of a greenhouse gas on climate change with an equal quantity of carbon dioxyde usually expressed over a 100 year period Carbon dioxyde always has a GWP of 1 Result are expressed in Carbon Dioxyde equivalent (g/kg/t C02e) Natural Gas Emission GWP t C02e C02/m3 ~27t 1 27 CH4/m3 0.0005t 25 0.0125 N20/m3 0.0005t 298 0.149 Implement strategies / actions to reduce Computing is necessary the most important being to understand what to reduce and which actions are neededGreenIt or Sustainable ICT We cannot solve our problems with the same thinking we used when we created them ‚Äì Albert EinsteinGeneral statemets - Shift Project 2018 Digital consumption as forecast is not sustainable Energy intensity of digital industry is in continuous growth No digital impact foreseen on worldwide productivity nor growth It is still possible to move ot a more sober digital worldDigital energy consumptionIn France : Digital Energy Consumption represents $12\\%$ of total energy consumption.GHG emissions : $2,5\\%$ in 2013 to $4\\%$ in 2020Example : Iphone" }, { "title": "SOCRA : Cours du 4 juin", "url": "/cours/posts/socra/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-06-04 10:00:00 +0200", "snippet": "Lien de la note HackmdIT in companySoftware needs Software Apache Monitoring Linux NetworkClassic segregation it‚Äôs not what you think| IT-Development | IT-Production | IT-System ||‚Äî‚Äì | ‚Äî‚Äî- | ‚Äî‚Äî‚Äî || Develop software | Manage software in production | Manage hardware and OS+ || | Assist users | Handles DPR || Paid for new features | Paid for uptime | Paid for stability, security |Assume failures No software is guaranteed without bugs.User error investigation Call support (Niveau 1) Use standard procedures (N1) Check logs (N2) Check configuration (N2) Call development : error in software (N3)Help them using Error messages Cristal clear logsExamples : LogsCreate new wishError returned With that kind of log, impossible to know what happened.2020-03-31 09:48:26.1539|INFO|0HLULB1T307F0|WishController|Create : New wish for #433 by #ce4ed122-3cfd-47cd-a8ea-9d0b9d4c55f4 : My Mobility2020-03-31 09:48:26.1575|WARN|0HLULB1T307F0|WishController|HasOneNotNull - Property not found : LinkedID2020-03-31 09:48:26.1577|WARN|0HLULB1T307F0|WishController|Error returned form HasOneNotNull : Property not found : LinkedId With this kind of log, we see the error right away.Logs Use different levels : Trace, Debug, Info, Warning, Error, Fatal Use and existing framework There is never too much logsFrom dev to PRODCI/CD Quesaco Continous : forming an unbroken whole; without interruption integration : the coodination of processes delivery : delivering letters, packages‚Ä¶. babies‚Ä¶ deployement : bringing resources into effective action CI process goalValidate code at each steps, for each developersConfirm software stability (a minimum)Create a delivery workflowAvoid human interactionHow to go live Take a (development) ticket Develop using BDD, TDD (and pair programming) Push on VCS Deploy on a test environment Test your software Everything is OK, then deploy on production Eventually calculate metrics like coverage, technical debt‚Ä¶A softwareDelivery process Get sources Add version Build Run tests Publish componentsEnvironmentsDEV, PROD, PRE-PROD, UATCreate packages Get sources Add version Build Run tests Create one package for each componentsCI/DC Tools Shell script! Jenkins Travis CI Bamboo Teamcity Monolyth AKA Single-tiered Self-contained IndependantMulti-tier Layer separation Flexible3-tier| Presentation ||‚Äì|| Logic || Data |Example| Console : Get report||‚Äì|| Business Logic : list of all sales and aggregate them || Data : MySQL : access sales‚Äô store |SOA : Service Oriented Architecture A service : represents a business activity is self contained is a black box for its consumers may consist of other underlying services CommunicationLocal : IPC|File|Shared Memory||‚Äî-|‚Äî-||Local - Bidirectional, one process at time for writing|Local - Bidirectional, one process at time for writing| Signal Socket Local - Unidirectional, not used for data Local or netowrk - bidirectional, synchrone Pipe Message queue Local - Unidirectional Local or network - bidirectional, asynchrone Problem.. What if a I send a message and the service is down ?How to send a message which can be handled by multiples service, but only processed by one ?How to handle a client deconnection ? A master ?Message queueing (aka MQ) Like a mailbox Increase TCP/IP features: Durability - purging : is the message saved ? What is TTL ? Delivery policy : should the message be delivered once more ? Security : which applications should have the message ? Notifications : the publisher can be notified when message is received Implementations : Apache ActiveMQ, OMQ, RabbitMQ, JMS, ‚Ä¶APICRUDREST CRUD operations Stateless On HTTP/S VERB Request has body Response has body Safe Indempotent Cacheable ¬† ¬† GET Optional YES YES YES YES ¬† POST YES YES NO NO YES ¬† PUT YES YES NO YES NO ¬† DELETE NO NO NO YES NO /api/users|GET|POST|PUT|DELETE||‚Äî|‚Äî-|‚Äî|‚Äî‚Äî||Retrieve all users|Create a new user|N/A|Delete all users|/api/users/{id}|GET|POST|PUT|DELETE||‚Äî|‚Äî-|‚Äî|‚Äî‚Äî||Retrieve one user|Create a new user|Update|Delete one user|OpenData - OpenAPI Free to use, reuse and redistribute Lots of companies : GAFAM, RATP, gouvernements‚Ä¶ Lots of domains : genetic, chemical, geographic, justice‚Ä¶ Swagger oh no it‚Äôs 2010 againAn SOA SoftwareTo manage more users : But there is still a problem..The current state problem What did my user?How can I guaranty it?Can I prove it? So let‚Äôs think events!Events afterall|Item added||‚Äî‚Äî||Item removed||Payment received||Order shipped| Item added : book Item added : DVD Item removed : DVD Payment received Order shippedEvents sourcing Command : user intention =&amp;gt; AddItemToCart Event : happened in the past =&amp;gt; ItemAddedToCart Immutable Event storeCQRSCommand and Query Responsibility SegregationCloudHow to run ? Software Libraries - dependencies Operating system HardwareI am a userI USE SERVICES!!!!I‚Äôm a developer Why should I care about hardware failure ? Infrastructure as a Service Why must I update the operating system ? Platform as a service Is the (right) JVM installed ? Platform as a service I know nothing about SQL Server, I just want a database ! Platform as a service / Software as a Service ITO are against me !IaaS to SaaSMe or nothing|Entreprise|Cloud provider||‚Äî‚Äî‚Äî-|‚Äî‚Äî‚Äî‚Äî‚Äì||On premise|Cloud|Entreprise &amp;amp; cloud provider : hybridLambda functions One endpoint, one function Focus on objective Access defined resources Call other functions if" }, { "title": "ASE1 : Typical exam", "url": "/cours/posts/ase1-typical-exam/", "categories": "S6, tronc commun, ASE1", "tags": "S6, ASE1, tronc commun", "date": "2020-06-02 15:00:00 +0200", "snippet": "Lien de la note HackmdFormatFichier excel deja pret ou on devra mettre nom + prenom + uid. Format CSV fr, separation des champs avec ,Jouons avec RUID&amp;lt;-20254 #UID de l&#39;etudiantX&amp;lt;-runif(1000) #Loi uniforme pour une variable X et on en prend milleplot(X) #Affiche XZ&amp;lt;-1:1000 #Vecteur Zplot(Z)alpha&amp;lt;-UID/23000K&amp;lt;-UID/7500alpha0.8806087K2.700533Ces nombres sont differents pour tout le mondeV&amp;lt;-K*X^alphaW&amp;lt;-K*Z^alphasort(V) #Loi uniforme de Vsort(W) #Loi uniforme de WLe vecteur W a ete construit par vous, il depend de votre numero. Vous devez etre capable de decrire W.boxplot(W) #Ne sera pa demande au partielsummary(W) #Decrit des valeurs utilesMin 1st Qu. Median Mean 3rd Qu. Max2.7 350.1 643.5 630.1 919.1 1193.8 sd(W) #Ecart typevar(W) #VarianceOn aura la commande dans l‚Äôenonce.cor(V, W) #Correlation entre V et WK&amp;lt;-2.5alpha&amp;lt;-2.1W&amp;lt;-K*Y^alphasummary(W)Jouez avec mean, sd, boxplot, summary, var, cov, cor.X&amp;lt;-1:100Y&amp;lt;-X^2plot(X, Y)Le coefficient de correlation de X et Y au pif ?Plutot proche de 1 car la courbe ressemble a une droite. :snail:cor(X, Y)0.96Intervalle de confianceOn va s‚Äôinteresser au poids d‚Äôun nouveau-ne. :snail: On en a pese 49 On a trouve une moyenne de 3.6 KgsJe sais que l‚Äôecart-type est de 0.5 Kg. Je souhaite avoir un intervalle de confiance a $95\\%$ du poids moyen.Derniere hypothese: le poids suit une loi normale.Il y a 2 facons de faire: Rappeler le raisonnement Apprendre la formule du coursRappelons le raisonnementEn general ‚ÄúObservation = moyen + ecart = moyenne + k * ecart type‚Äù sauf qu‚Äôon doit faire une deduction sur la moyenne.Estimation de moyenne de type moyenne observee +- k * ecart type. Quand on connait l‚Äôecart type K depend de la distribution de la loi normale.x.barre&amp;lt;-3.6sigma&amp;lt;-0.5n&amp;lt;-49Formule du coursUn intervalle de confiance a $95\\%$, $\\alpha = 5\\%$, $\\frac{\\alpha}{2} = 2.5\\%$ et $1-\\frac{\\alpha}{2} = 0.975$On utilise qnormu&amp;lt;-qnorm(0.975)u1.959964mu.inferieur&amp;lt;-x.barre-u*sigma0/sqrt(n) #Formule du coursmu.superieur&amp;lt;-x.barre+u*sigma0/sqrt(n) L‚Äôintervalle de confiance a $95\\%$ est $[3.46, 3.74]$.On a mesure un ecart type de 0.53 Kgs. Quel est l‚Äôintervalle de confiance?On a mesure une moyenne de 3.6 Kgs et un ecart type de 0,53 Kgs sur 49 bebes.v&amp;lt;-qt(0.975, 49-1)v2.010635ecart&amp;lt;-v*0.53/sqrt(n-1)mu.inferieur&amp;lt;-x.barre-ecartmu.superieur&amp;lt;-x.barre+ecart3.443.75Patients maladesPour une maladie donnee, un traitement gueri $90\\%$ des patients.J‚Äôai fait un test avec 1000 patients et 850 sont gueris au bout de 2 semaines. :snail:J‚Äôaccepte le 90% sur cette base?Un test de chi2, dans le cours.Ici : k=2 classes patients gueris, p1 = 0.9 patients non gueris, p2 = 0.1n&amp;lt;-1000N1&amp;lt;-850N2&amp;lt;-150p1&amp;lt;-0.9p2&amp;lt;-0.1Z&amp;lt;-(N1-n*p1)^2/(n*p1) + (N2-n*p2)/(n*p2)Z27.77778qchisq(0.95, 1)3.84qchisq(0.99, 1)6.63La valeur de Z est trop grande, les ecarts de Z sont trop grands. En principe Z doit rester petit, on va refuser l‚Äôhypothese de guerison a $90\\%$. :snail:H0: la proba de guerison est de $90\\%$, la proba de non guerison est $10\\%$.Regression lineaireplot(X, Y, col=&quot;blue&quot;) On veut appliquer ces formulesmX&amp;lt;-mean(X)mY&amp;lt;-mean(Y)sX&amp;lt;-sd(X)sY&amp;lt;-sd(Y)rho&amp;lt;-cor(X, Y)beta&amp;lt;-rho*sY/sXalpha&amp;lt;-mY-beta*mXPREV&amp;lt;-beta*X+alphapoints(X,PREV,col=&quot;red&quot;,pch=19,cex=0.8)ECARTS&amp;lt;-Y-PREVvar(PREV)var(ECARTS)var(PREV) + var(ECARTS)2174766:snail:" }, { "title": "SUDE : cours du 28 mai", "url": "/cours/posts/sude_dev_durable/", "categories": "S6, electif, SUDE", "tags": "S6, SUDE, electif", "date": "2020-05-28 10:00:00 +0200", "snippet": "AssessmentPresentation (4-5 students) to be presented on session 4 - (~10 min per group) and uploaded prior the beginning of the courseInstructions Select a company with Green IT actions Choose at least 4 Green IT actions and explains why they can be considered as good practices and how they reduce the environmental impact At the end of the presentation (not to be presented orally), put the work on Sustainable Development Goals : Which SDG the company contributes to? (give 1 example per SDG) and for SDGs it does not contributes to, give an example of what the company could do. Quick presentationVal√©rie Schneider: Founded her own company: Val√©rie Schneider Conseil Lectures at ISEP, ECE, EPITA, SUP RH CSR, Circular Econmy, Green IT Strategy, Business Models, Awareness, ProjectsWhat is the definition of sustainable development ? ‚ÄúSustainable development is the development which meets the needs of current generations without compromising the ability of future generations to meet their own needs‚Äù ‚Äì Brundtland report, 1987 Development means everyone get access to better education, better health and minimun income. 3 keywords for the defnition development needs future generation What are the key challenges humanity has to face today ?Proposed by students: Global warming Climate change Waste management Covid19 Over consumptionWe are more than 7 billions. How many of us will there be in 2050? Challenge #1 : population growth : the population should stabilize at the end of the century, the growth rate is decreasing. In the last 40 years, the population doubled. Challenge #2 : Consumption growth : We are consumming more and more energy, goods, etc. We own more and more goods, want to get the newest technologies and throwing the old devices too often. It is the linear economy Challenge #3 : Limited resources : Global overshoot occurs when humanity‚Äôs annual needs exceeds what Earth‚Äôs ecosystems can renew in a year. It means we are drawing down the planet‚Äôs resources rather than living off its annual interest. It leads to a depletion of Earth‚Äôs life-supporting natural capital. Our ecological footprint get bigger and bigger. If everyone lived like we do it France, we would need 3 Earths to feed everyone. Challenge #4 : Global warming : The Greenhouse effect is a natural phenomen, without it there would not be life on Earth. However, because of human activities, we are emitting more gases than necessary (CO2, CH4, etc.). Challenge #5 : Biodiversity : Currently there are more than 91,520 species on the IUCN Red List more than 25,820 are threatened with extinction including 41% of amphibians 34% of conifers 33% of reef building corals 25% of mammals and 13% of birds Middle East has Oil, China has Rare Earths - Deng Xiaoping, 1992ContextMore than 1 ton of resources is needed to produce a laptop. Precious metals, such as gold, silver, platinum, etc. can be found inside of a computer.Critical metals: Rare earths : China has more than 60% of rare earths, produce 88% and consume 69% of it. They are used in many electronic appliances, magnets, wind turbines, etc. Cobalt Lithium NickelChina owns 44% of those metals and is 58% of its demand. However, these resources are limited. How can we continue to use them?Impact of rare earths extraction / production Environmental impacts Social impactsSolutions Open or re-open mines ? Social acceptance Environmental risks ROI? Finding alternatives ? Reduce or do not use rare earths Like tellurium and indium CdTE solar PV How to combine humanity development and sustainability ?The importance of biodiversity Aesthetic and scientific value Medical research Traditional and modern medicine Direct economic value Food Clothing Energy Sustainable development goals " }, { "title": "CAMA : ma42 - Gradient conjugu√©", "url": "/cours/posts/ma42-gradient-conjugue-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-25 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25/05Programmer le gradient conjugu√©A partir de ce cours sur le gradient conjugu√© programmez en Python + Numpy le gradient conjugu√© en exploitant les astuces math√©matiques indiqu√©es pour optimiservotre code. Effectuez des tests pour valider votre code. Comparez la vitesse de convergence √† celle du gradient avec Œº optimal. Tracez des courbes de convergence (cf la feuille qui en parle) Comparez les temps de calcul.Note : Veuillez √©crire des fonctions les plus propres possibles, en particulier qui n‚Äôutilisent pas des variables globales comme c‚Äôest le cas dans ma correction du gradient (ma33). Solution import numpy as npimport scipy.linalg as linimport matplotlib.pylab as plt%matplotlib inline%config InlineBackend.figure_format = &#39;retina&#39; def make_system(N): A = 1.0 * np.random.randint(-10, 10, size=(N,N)) A[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominante A = A + A.T # sym√©trique A = A / np.abs(A).sum(axis=0).mean() b = 1.0 * np.random.randint(-10,10,size=(N)) return A, bA, b = make_system(2)print(A, &quot;\\n\\n&quot;, b) [[ 0.65174129 -0.32338308] [-0.32338308 0.70149254]] [ 6. -1.] def gradient_conjugu√©(A, x0, b, error=1E-9, convergence=False): x = x0.copy() # je ne veux pas modifier les param√®tres qu&#39;on me donne e2 = error**2 r = A @ x - b # le gradient mais aussi le r√©sidu r2 = r @ r p = -r if convergence: conv = [np.sqrt(r2)] while r2 &amp;gt; e2: alpha = (r @ r) / np.dot(A @ p, p) x += alpha * p r += alpha * (A @ p) beta = (r @ r) / r2 p = -r + beta * p r2 = r @ r if convergence: conv.append(np.sqrt(r2)) return np.array(conv) if convergence else x gradient_conjugu√©(A, np.array([0.,0.]), b, convergence=True) array([6.08276253e+00, 2.51964707e+00, 2.22044605e-16]) def compute_error(N, method=gradient_conjugu√©): A, b = make_system(N) x = method(A, np.zeros(N), b) err = A @ x - b return np.sqrt(err @ err)compute_error(10) 4.165926057296536e-15 Comparons avec le gradient simple def gradient(A, x0, b, e = 1E-9, convergence=False, max_iterations=1000): x = x0.copy() e2 = e**2 k = 0 gradJ = A @ x - b g2 = gradJ @ gradJ divergence_limite = 1E6 * g2 if convergence: conv = [np.sqrt(g2)] while g2 &amp;gt; e2: ¬µ = np.dot(gradJ, gradJ) / np.dot(A @ gradJ, gradJ) x -= ¬µ * gradJ gradJ = A @ x - b g2 = gradJ @ gradJ if convergence: conv.append(np.sqrt(g2)) # la suite n&#39;est que des tests pour se prot√©ger if g2 &amp;gt; divergence_limite: # au cas o√π on diverge print(&quot;DIVERGE&quot;) break k += 1 if k &amp;gt; max_iterations: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(conv) if convergence else x # v√©rifions que ca marchecompute_error(10, method=gradient) 6.767792116739432e-10 Perfs # comparons les performancesseed = 123np.random.seed(seed)%timeit compute_error(1000, method=gradient) 34 ms ¬± 4.23 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each) seed = 123np.random.seed(seed)%timeit compute_error(1000, method=gradient_conjugu√©) 32.1 ms ¬± 847 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10 loops each) Le gain n‚Äôest pas clair‚Ä¶ Nombre d‚Äôiteration dans les 2 cas N = 1000A,b = make_system(N)x0 = np.zeros(N) Pour le gradient simple err = gradient(A, x0, b, convergence=True) plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient&#39;)plt.semilogy(); Pour le gradient conjuge err = gradient_conjugu√©(A, x0, b, convergence=True) plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient conjugu√©&#39;)plt.semilogy(); Argh, le gradient conjugu√© n‚Äôest pas la r√©volution pr√©dite !Un cas r√©elLogiquement vous devriez √™tre d√©cu aussi on va tester avec un probl√®me r√©el qui correspond √† cet exemple de l‚Äô√©quation de Poisson. Le syst√®me matriciel de ce probl√®me est t√©l√©chargeable ici. Une fois le fichier sauv√©, pour r√©cup√©rer A et b faites :npz = np.load(&#39;/tmp/Ab.npz&#39;)A = npz[&#39;A&#39;]b = npz[&#39;b&#39;] Faites une √©tude rapide de A, indiquez quel pourcentage des valeurs de A est diff√©rent de 0. Afficher l‚Äôimage de la matrice avec plt.imshow(A) (faire une grande image pour voir quelque chose). Refaites la comparaison entre les deux m√©thodes avec ce syst√®me matriciel. Regardez la documentation de lin.solve (en particulier les options) et comparer lin.solve √† vos deux algorithmes. Solution print(A.min(), A.max()) -1.5693731138089555 4.357203686821435 diff0 = (A != 0).sum() / (A.shape[0] * A.shape[1])print(f&quot;Pourcentage de valeurs != 0 : {100 * diff0:.3} %&quot;) Pourcentage de valeurs != 0 : 0.339 % plt.figure(figsize=(15,15))plt.imshow(A) Comparaison gradient simple et conjugu√© %time err = gradient_conjugu√©(A, np.zeros(len(A)), b, convergence=True) CPU times: user 1.75 s, sys: 155 ms, total: 1.91 sWall time: 521 ms plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient conjugu√©&#39;)plt.semilogy(); # le gradient simple%time err = gradient(A, np.zeros(len(A)), b, convergence=True, max_iterations=10000) CPU times: user 1min 11s, sys: 4.3 s, total: 1min 15sWall time: 19.4 s plt.plot(np.arange(err.shape[0]), err)plt.title(&#39;Convergence du gradient&#39;)plt.semilogy(); On voit la sup√©riorit√© du gradient conjugu√© tant en nombre d‚Äôit√©rations (175 contre 7800) qu‚Äôen temps de calcul (0,5 s contre 20 s). Comparaison avec lin.solve ?lin.solve %time x = lin.solve(A, b, assume_a=&#39;pos&#39;) CPU times: user 170 ms, sys: 85.1 ms, total: 255 msWall time: 94.4 ms r = A @ x - br @ r 2.0359257929180678e-25 On note aussi lin.solve est plus rapide et sa solution est nettement meilleure‚Ä¶ lin.solve utilise une m√©thode directe ici. Cela est d√ª au fait que Scipy utilise la biblioth√®que Lapack (qui est imbatable). Le gradient conjugu√© de Scipy (avec Lapack) Le gradient conjugu√© √† tout son sens pour les matrices creuses aussi il est dans la partie ‚Äúsparse‚Äù de Scipy. On a vu que notre matrice √† plus de 99 % de valeur nulles ce qui en fait bien une matrice creuse. Aussi je la charge dans le format COO qui ne stocke que les valeurs non nulles et: import scipy.sparse as sparsefrom scipy.sparse.linalg import cgAc = sparse.load_npz(&#39;/tmp/Acoo.npz&#39;)%time x = cg(Ac, b) CPU times: user 24.8 ms, sys: 15.1 ms, total: 39.9 msWall time: 10.8 ms On gagne un facteur 10 !" }, { "title": "CAMA : ma41 Syst√®me matriciel non lin√©aire", "url": "/cours/posts/ma41-systeme-matriciel-non-lineaire/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-25 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25 / 06 Si la matrice $A$ d√©pend de ${\\bf x}$ (not√© $A({\\bf x})$), alors le syst√®me matriciel \\(A({\\bf x)x = b}\\)n‚Äôest pas lin√©aire.Exemple :\\[\\begin{bmatrix}1 &amp;amp; x_1 \\\\2x_1 &amp;amp; -x_2 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1} \\\\x_{2} \\\\\\end{bmatrix} =\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\end{bmatrix}\\]donne le syst√®me suivant non lin√©aire puisqu‚Äôon a descarr√©s :\\[\\begin{align}x_1 + x_1 \\, x_2 &amp;amp;= b_1 \\\\2 \\, x_1^2 - x_2^2 &amp;amp;= b_2 \\end{align}\\]Comment r√©soudre un tel syst√®me ?La m√©thode du point fixe La m√©thode du point fixe consiste √† appliquer l‚Äôalgorithme it√©ratif suivant : \\({\\bf x}^{k+1} = g({\\bf x}^k)\\)pour r√©soudre $g({\\bf x}) = {\\bf x}$. $x_0$ donn√© ${\\bf \\bar x} = g({\\bf \\bar x})$ un point fixe de $g$ ${\\bf x}^{k+1} = g({\\bf x}^k)$ avec $k = 0, 1, 2, ‚Ä¶$Est-ce que $g({\\bf x}^k)^k$ converge ? Si $\\bf{x_0} \\lt {\\bf \\bar x_2}$ : $\\lim_{k\\to+\\infty} = {\\bf \\bar x_1}$ Si $\\bf{x_0} \\gt {\\bf \\bar x_2}$ : $\\lim_{k\\to+\\infty} = +\\infty$ Selon le point de d√©part, la m√©thode converge ou diverge.La m√©thode du point fixe pour r√©soudre $A({\\bf x)x = b}$ On doit d√©finir une fonction $g$ telle que la solution de $J({\\bf x}) = {\\bf x}$ soit la solution du syst√®me matriciel non lin√©aire : \\(g({\\bf x}) = A^{-1}({\\bf x}) \\, {\\bf b}\\)Inverser A est trop co√ªteux, on √©crit notre algorithme it√©ratif sous forme de probl√®me matriciel lin√©aire √† r√©soudre:\\(A({\\bf x}^k) \\, {\\bf x}^{k+1} = {\\bf b}\\)Si on connait ${\\bf x}^k$ on peut √©valuer $A({\\bf x}^k)$, le syst√®me est lin√©aire et permet de trouver ${\\bf x}^{k+1}$.Le fonctionnement de l‚Äôalgorithme va d√©pendre du type de la matrice $A$ et de la valeur initiale $x_0$.Exemple :\\(\\begin{bmatrix}x_0 - 2 x_1 &amp;amp; x_1 \\\\x_0 &amp;amp; 2 x_0 + x_1 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_0 \\\\x_1 \\\\\\end{bmatrix} =\\begin{bmatrix}1 \\\\9 \\\\\\end{bmatrix}\\)Ce syst√®me a pour solutions [1, 2] et [2, 1].def A(x): return np.array([[x[0] - 2*x[1], x[1]] , [x[0] , x[1] + 2*x[0]]]) / 10 b = np.array([1, 9]) / 10 # avec normalisation grossi√®rex = np.array([1, 1])for i in range(1, 10): x = lin.solve(A(x), b)...x^7 = [1.37317932 2.74635363]x^8 = [0.72823777 1.45647516]x^9 = [1.37317809 2.74635608]La solution oscille sans converger. La m√©thode du point fixe a un petit rayon de convergence.Appliquon l‚Äôinertie¬µ = 0.5 # on avance de moiti√© vers le prochain xx = np.array([3, 2])for i in range(1, 10): x_old = x x = lin.solve(A(x), b) x = ¬µ * x + (1-¬µ) * x_old...x^9 = [1.00876429 1.98253948]La convergence est rapide (9 iterations). L&#39;inertie augmente le rayon de convergence : plus $\\mu$ est petit plus le rayon de convergence est grand. Pour trouver les autres solutions il faut choisir un autre point initial.La m√©thode de Newton-Raphson \\({\\bf x}^{k+1} = {\\bf x} - \\frac{f({\\bf x_n})}{f&#39;({\\bf x_n})}\\) La m√©thode de Newton est une m√©thode de point fixe.\\({\\bf x}^{k+1} = g({\\bf x}^k)\\)o√π $g({\\bf x)} = {\\bf x} - \\frac{f({\\bf x})}{f‚Äô({\\bf x})}$On souhaite r√©soudre notre systeme non lin√©aire. Gr√¢ce √† la formule ci-dessus, on a en 1D:\\(f&#39;(x^k) \\; (x^{k+1} - x^k) = - f(x^k)\\)Ce qui donne en $n$ dimensions:\\(J_{\\bf f}({\\bf x}^k) \\; ({\\bf x}^{k+1} - {\\bf x}^k) = - {\\bf f}({\\bf x}^k)\\)avec $J_{\\bf f}$ la matrice Jacobienne de ${\\bf f}$ :\\(J_{\\bf f}\\left({\\bf x}\\right)=\\begin{pmatrix} \\dfrac{\\partial f_1}{\\partial x_1} &amp;amp; \\cdots &amp;amp; \\dfrac{\\partial f_1}{\\partial x_n} \\\\\\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\\\dfrac{\\partial f_n}{\\partial x_1} &amp;amp; \\cdots &amp;amp; \\dfrac{\\partial f_n}{\\partial x_n}\\end{pmatrix}\\)Notre syst√®me non lin√©aire avec $f$ une fonction vectorielle:\\({\\bf f}({\\bf x}) = A({\\bf x})\\, {\\bf x} - {\\bf b}\\)ExempleOn reprend le syst√®me matriciel pr√©c√®dent. La matrice Jacobienne de la fonciton $f$ est : \\(J_{\\bf f}({\\bf x}) = \\begin{bmatrix}2 x_0 - 2 x_1 &amp;amp; 2 x_1 - 2 x_0\\\\2 x_0 + 2 x_1 &amp;amp; 2 x_0 + 2 x_1 \\\\\\end{bmatrix}\\)def f(x): return A(x) @ x - bdef J_f(x): return 2 * np.array([[x[0] - x[1], x[1] - x[0]], [x[0] + x[1], x[0] + x[1]]])x = np.array([3, 2])for i in range(30): delta = lin.solve(J_f(x), -f(x)) x = x + delta...x^29 = [2.05693134 1.05693134]On converge (moins vite) o√π la methode du point fixe oscille sans converger. Le co√ªt de la construction de la matrice Jacobienne peut √™tre tres √©lev√©. Pour aller plus vite on peut recalculer la matrice toutes les 3 iterations ou plus. Il s‚Äôagit d‚Äôune matrice pleine qui rend compliqu√© la resolution du systeme (une methode de gradient ne marchera pas) " }, { "title": "CAMA : Ecriture du produit scalaire", "url": "/cours/posts/produit-scalaire/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note Hackmd" }, { "title": "CAMA : ma40 M√©thode du gradient conjugu√©", "url": "/cours/posts/ma40-methode-du-gradient-conjugue/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 24 / 05M√©thode du gradient conjugueSi on a calcul√© le $\\mu$ optimal alors la plus forte pente $\\nabla J ({\\bf x}^{k+1})$ sera orthogonale √† la pente qui d√©finie la droite sur laquelle on cherche $\\mu$. On a donc\\(\\nabla J ({\\bf x}^{k+1})^T \\, . \\, \\nabla J ({\\bf x}^k) = 0\\)Le minimum suivant ${\\bf x^{k+2}}$ sera le minimum de l‚Äôespace g√©n√©r√© par $\\nabla J ({\\bf x}^{k+1})$ et $\\nabla J ({\\bf x}^k)$. On ne sait pas si ${\\bf x^{k+3}}$ sera calcul√© le long de la direction $\\nabla J ({\\bf x}^k)$.Une recherche optimale du minimum d‚Äôune fonction convexe dans un espace $\\mathbb{R}^n$ ne devrait pas prendre plus de $n$ it√©rations si on est capable de calculer le $\\mu$ optimal dans la direction choisie.On cherche le minimum dans les directions des vecteurs de la base de notre espace $\\mathbb{R}^n$ afin de trouver le minimum global.G√©n√©rer une base de $\\mathbb{R}^n$Si on veut trouver notre minimum global en $n$ it√©rations au maximum, il faut que nos directions ne soient pas redondantes et que les $n$ premi√®res directions g√©n√®rent $\\mathbb{R}^n$ ou en forment une base.La nouvelle direction $d^k$ doit √™tre orthogonale √† toutes les directions pr√©c√©dentes et permet de trouver une base qui g√©n√®re un espace de dimension $k + 1$.Le cas ${\\bf Ax = b}$La fonctionnelle √† minimiser est :\\(J({\\bf x}) = \\frac{1}{2} \\, {\\bf x}^T \\, A \\, {\\bf x} - {\\bf b}\\, . {\\bf x}\\) Si A est sym√©trique, son gradient est $\\nabla J({\\bf x}) = A \\; {\\bf x} - {\\bf b}$Si on calcule ${\\bf x^k}$ comme avant on a l‚Äôorthogonnalit√© de 2 directions successives.Que se passe-t-il si ${\\bf x^k+1}$ minimise $J$ dans l‚Äôespace $G_k$ g√©n√©r√© par toutes les directions pr√©c√©dentes ?\\(J({\\bf x}^{k+1}) = \\min_{\\bf v \\in G_k} J({\\bf x}^k + {\\bf v})\\)avec ${\\bf G_k} = span{ {\\bf d}^0, {\\bf d}^1,\\dots, {\\bf d}^k} = \\left{ {\\bf v} = \\sum_{i=0}^{k} \\alpha_i \\, {\\bf d}^i \\quad \\forall \\alpha_i \\in ‚Ñù \\right}$. Toutes les d√©riv√©es partielles par rapport aux vecteurs de ${\\bf G_k}$ sont nulles :\\(\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf w} = 0 \\quad \\forall {\\bf w} \\in {\\bf G_k}\\)Cela se v√©rifie si ${\\bf w}$ est un des vecteurs de la base:$$ \\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf e}_i = \\begin{bmatrix}\\partial J / \\partial x_{1} \\\\\\partial J / \\partial x_{2} \\\\\\vdots \\\\\\partial J / \\partial x_{i} \\\\\\vdots \\\\\\partial J / \\partial x_{n} \\\\\\end{bmatrix}\\, . \\,\\begin{bmatrix}0 \\\\0 \\\\\\vdots \\\\1 \\\\\\vdots \\\\0 \\\\\\end{bmatrix} =\\frac{\\partial J}{\\partial x_i}({\\bf x}^{k+1}) $$ La d√©riv√©e partielle de $J$ dans une direction ${\\bf w}$ de ${\\bf G_k}$ est nulle revient a dire $\\nabla J({\\bf x}^{k+1})$ est orthogonal √† ${\\bf w}$.G√©n√©rer les directions ${\\bf d}^i$La formule it√©rative devient :\\({\\bf x}^{k+1} = {\\bf x}^k - ¬µ^k\\, {\\bf d}^k\\) Pour calculer les ${\\bf d}^k$ on utilise la formule des d√©riv√©es partielles de $J$ par rapport √† un vecteur ${\\bf w \\in G_k}$ o√π elles sont nulles. ${\\bf d}^i$ g√©n√®rent l‚Äôespace ${\\bf G_k}$, il suffit que les d√©riv√©es partielles de $J$ par rapport ${\\bf d}^i$ soient nulles\\(\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf d}^i = 0 \\quad \\forall i \\le k \\qquad (1) \\\\\\) En d√©roulant les calculs on obtient : \\(\\begin{align}\\nabla J({\\bf x}^{k}) \\, . \\, {\\bf d}^i - ¬µ^k \\, A \\, {\\bf d}^k \\, . \\, {\\bf d}^i &amp;amp;= 0 \\quad \\forall i \\le k \\\\\\end{align}\\) Si $i \\lt k$, le premier terme est nul : \\(A \\, {\\bf d}^k \\, . \\, {\\bf d}^i = 0 \\quad \\forall i &amp;lt; k \\qquad (2)\\) On a les conditions pour construire la nouvelle direction ${\\bf d}^k$ \\({\\bf d}^k = \\nabla J({\\bf x}^k) - \\sum_{i=0}^{k-1} \\frac{A\\, \\nabla J({\\bf x}^k) \\, . \\, {\\bf d}^i} {A\\, {\\bf d}^i \\, . \\, {\\bf d}^i} \\; {\\bf d}^i\\) Si $i =k$, on obtient la valeur n√©cessaire $¬µ^k$ pour garantir que $\\nabla J({\\bf x}^{k+1}) \\, . \\, {\\bf d}^k = 0$ : \\(¬µ^k = \\frac{\\nabla J({\\bf x}^{k}) \\, . \\, {\\bf d}^k} {A \\, {\\bf d}^k \\, . \\, {\\bf d}^k} = \\frac{(A \\, {\\bf x}^{k} - b) \\, . \\, {\\bf d}^k} {A \\, {\\bf d}^k \\, . \\, {\\bf d}^k} \\\\\\,\\) Propri√©t√© L‚Äôensemble des gradients de $J$ aux points $\\bf{x}^i$ forment une base de l‚Äôespace ${\\bf G_k}$ : \\(\\nabla J({\\bf x}^{k+1}) \\perp \\nabla J({\\bf x}^i) \\quad \\forall i \\le k\\) " }, { "title": "CAMA : Derivees partielles", "url": "/cours/posts/derivees-partielles/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-24 10:00:00 +0200", "snippet": "Lien de la note HackmdLes fonctions Une fonction $f$ est dite scalaire lorsque son espace d‚Äôarriv√©e est $\\mathbb{R}$. Une fonction $f$ est dite vectorielle lorsque son espace d‚Äôariv√©e est $\\mathbb{R}^n$ avec $n \\gt 1$.Les deriveesSoit $f(x, y)$ une fonction scalaire: sa deriv√©e partielle premi√®re en $x$ : $\\frac{\\partial f}{\\partial x} = \\partial_x f$ sa d√©riv√©e partielle seconde en $y$ : $\\frac{\\partial^2 f}{\\partial y^2} = \\partial_{yy} f$ sa diff√©rentielle totale $df(x, y) = \\frac{\\partial f}{\\partial x}(x, y)dx + \\frac{\\partial f}{\\partial y}(x, y)dy$ $\\frac{\\partial(f \\circ g)}{\\partial x} = \\frac{\\partial f}{\\partial g} \\frac{\\partial f}{\\partial x}$Nabla $\\nabla$L‚Äôop√©rateur nabla pour une fonction qui part d‚Äôun espace a 2 dimensions est \\(\\nabla =\\begin{pmatrix}\\frac{\\partial f}{\\partial x} \\\\\\frac{\\partial f}{\\partial y} \\\\\\end{pmatrix}\\) Pour une fonction scalaire $f:\\mathbb{R}^2\\to\\mathbb{R}$ : \\(Gradiant : Grad(f) = \\nabla f = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} \\\\\\frac{\\partial f}{\\partial y} \\\\\\end{pmatrix} \\\\ Laplacien : \\triangle f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} \\space avec\\space \\nabla.\\nabla = \\triangle\\) Pour une fonction vectorielle $f:\\mathbb{R}^2\\to\\mathbb{R}^2$ : \\(Divergence : Div(f) = \\nabla.f = \\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y} \\\\ Laplacien: \\triangle f = \\begin{pmatrix} \\frac{\\partial^2 f_x}{\\partial x^2} + \\frac{\\partial^2 f_x}{\\partial y^2}\\\\\\frac{\\partial^2 f_y}{\\partial x^2} + \\frac{\\partial^2 f_y}{\\partial y^2}\\end{pmatrix}\\)D√©veloppement limit√©Le D.L. d‚Äôune fonction $f:\\mathbb{R}^2\\to\\mathbb{R}$ en ${\\bf u} = (u_x, u_y)$ est:\\(f({\\bf u + \\delta u}) = f(u) + &amp;lt;\\nabla f(u), \\delta u&amp;gt; + \\frac{1}{2!}&amp;lt;\\nabla^2f(u)\\delta u, \\delta u&amp;gt; + o(\\Vert\\delta u\\Vert^2) \\\\ = f(u) + \\partial_x f(u)\\delta u_x +\\partial_y f(u)\\delta u_y + \\partial_{xx}f\\frac{\\delta u_x^2}{2} + \\partial_{xy}f\\delta u_x \\delta u_y + \\partial_{yy}f\\frac{\\delta u_y^2}{2} + o(\\Vert\\delta u\\Vert^2)\\)Avec $\\nabla^2 f$ la matrice hessienne de f et $&amp;lt;u, v&amp;gt;$ une autre notation du produit scalaire." }, { "title": "CAMA : ma33 - Gradient pour r√©soudre Ax = b -- Exercice", "url": "/cours/posts/ma33-gradient-pour-resoudre/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 17/05La m√©thode du gradient pour r√©soudre A x = bLe but de ce TP est de vous laisser avancer tout seul. Reprenez les cours et programmez la m√©thode du gradientpour r√©soudre le syst√®me matriciel $A {\\bf x} = {\\bf b}$ avec A sym√©trique et √† diagonale dominante($a_{ii} &amp;gt; \\sum_{k \\ne i} |a_{ik}|$). Commencez en 2D avec une matrice 2x2, v√©rifier que le r√©sultat est bon et tracer la courbe de convergence Passez en nxn (on montrera que cela marche avec une matrice 9x9)Il peut √™tre int√©ressant de normaliser la matrice A pour √©viter que les calculs explosent. Solution 2x2 # plein de copier coller du coursimport numpy as npimport scipy.linalg as linimport matplotlib.pylab as pltimport plotly.offline as pyimport plotly.graph_objects as go%matplotlib inline%config InlineBackend.figure_format = &#39;retina&#39;np.set_printoptions(precision=3, linewidth=150, suppress=True)plt.style.use([&#39;seaborn-whitegrid&#39;,&#39;data/cours.mplstyle&#39;]) N = 2A = np.random.randint(-10, 10, size=(N,N))A = A * 1.0 # pour passer en reelsA[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominanteA = A + A.T # sym√©triqueA = A / np.abs(A).sum(axis=0).mean()b = np.random.randint(-10,10,size=(N))print(A, &quot;\\n\\n&quot;, b) [[1.037 0.184] [0.184 0.596]] [7 2] def grad_J(x): return A@x - b def minimum_J(start_value, ¬µ=0.1, e = 0.001): x = [np.array(start_value)] while True: x.append(x[-1] - ¬µ * grad_J(x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: break # la suite n&#39;est que des tests pour se prot√©ger if np.square(x[-1] - x[-2]).sum() &amp;gt; 1E9: # au cas o√π on diverge print(&quot;DIVERGE&quot;) break if len(x) &amp;gt; 1000: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(x)x = minimum_J(np.zeros(N)) x[-1] - lin.solve(A, b) array([-0.007, 0.016]) plt.plot(x[:,0], x[:,1], &#39;x:&#39;) nxn np.abs(A) array([[1.037, 0.184], [0.184, 0.596]]) N = 9A = np.random.randint(-10, 10, size=(N,N))A = A * 1.0 # pour passer en reelsA[np.diag_indices(N)] = 0.1 + np.abs(A).sum(axis=0) # diag dominanteA = A + A.T # sym√©triqueA = A / np.abs(A).sum(axis=0).mean()b = np.random.randint(-10,10,size=(N)) x = minimum_J(np.zeros(N)) x[-1] - lin.solve(A, b) array([ 0. , -0.006, 0.001, 0.006, 0.017, 0.008, -0. , 0.014, 0.004]) print(&quot;Converge en %d it√©rations&quot; % len(x))x Converge en 178 it√©rations array([[ 0. , 0. , 0. , ..., 0. , 0. , 0. ], [ 0.3 , -0.2 , 0. , ..., 0.8 , -0.6 , -0.4 ], [ 0.576, -0.396, -0.001, ..., 1.548, -1.176, -0.783], ..., [ 3.088, -4.714, 0.223, ..., 13.007, -14.827, -9.853], [ 3.088, -4.714, 0.223, ..., 13.007, -14.827, -9.853], [ 3.088, -4.714, 0.223, ..., 13.007, -14.828, -9.854]]) Introduire de l‚ÄôinertieIntroduire de l‚Äôinertie dans la m√©thode du gradient. Que constate-t-on ? Reponse Ajouter de l‚Äôinertie dans une m√©thode it√©rative veut dire qu‚Äôon avance moins vite vers le point suivant : x_next = ...x = w * x_next + (1 - w) * x avec w qui repr√©sente la force d‚Äôavanc√©e (ou l‚Äôinverse du poids de l‚Äôinertie).Dans le cas de la m√©thode du gradient cela donne : x_next = x - |¬µ| grad_J(x)x = w * x_next + (1 - w) * x ce qui se d√©veloppe ainsi : x = w * (x - |¬µ| grad_J(x)) + (1 - w) x ou x = x - w * |¬µ| grad_J(x) On voit donc qu‚Äôajouter de l‚Äôinertie ne fait que modifier le param√®tre ¬µ qui justement sert √† avancer plus ou moins vite. ¬µ est d√©j√† une sorte d‚Äôinertie. Donc cela ne change pas la m√©thode et cela n‚Äôamm√©liore pas l‚Äôalgorithme.Valeur optimale de ¬µOn note que deux directions de pente sucessives sont orthogonales si le point suivant est le minumum dansla direction donn√©e ($\\nabla J ({\\bf x}^k$)).\\[\\nabla J ({\\bf x}^{k+1})^T \\; \\nabla J ({\\bf x}^k) = 0\\]D√©monstrationOn veut r√©gler ¬µ pour arriver au minimum de J lorsqu‚Äôon avance dans la direction $- \\nabla J({\\bf x}^{k})$.Cela veut dire que la d√©riv√©e partielle de $J({\\bf x}^{k+1})$ par rapport √† ¬µ doit √™tre√©gale √† 0 ou bien en faisant apparaitre ¬µ dans l‚Äô√©quation :\\[\\frac{\\partial J ({\\bf x}^k - ¬µ \\; \\nabla J ({\\bf x}^k))}{\\partial ¬µ} = 0\\]En d√©veloppant on a\\[\\begin{aligned}\\frac{\\partial J ({\\bf x}^{k+1})}{\\partial {\\bf x}^{k+1}} \\; \\frac{\\partial {\\bf x}^{k+1}}{\\partial ¬µ} &amp;amp;= 0 \\\\J&#39;({\\bf x}^{k+1}) \\, . \\, (- \\nabla J ({\\bf x}^k)) &amp;amp;= 0 \\\\(A\\, {\\bf x}^{k+1} - b) \\, . \\, \\nabla J ({\\bf x}^k) &amp;amp;= 0 \\quad \\textrm{puisque A est sym√©trique}\\\\\\nabla J ({\\bf x}^{k+1}) \\, . \\, \\nabla J ({\\bf x}^k) &amp;amp;= 0 \\quad \\textrm{CQFD}\\end{aligned}\\]En utilisant cette propri√©t√©, √©valuer la valeur optimale de ¬µ pour atteindre le minimum dans la direction de$\\nabla J ({\\bf x}^k)$.Exercice√âcrire le m√©thode du gradient avec le calcul du ¬µ optimal √† chaque it√©ration pour r√©soudre $A {\\bf x} = {\\bf b}$. Solution On reprend l‚Äôavant-derni√®re ligne de la d√©monstration et on remplace $\\bf x^{k+1}$ par $\\bf x^{k} -\\mu\\nabla J(\\bf x^k)$:\\[\\begin{aligned}(A(\\bf x^k - \\mu\\nabla J(\\bf x^k)) -b)\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\(A\\bf x^k -b - \\mu A\\nabla J(\\bf x^k))\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\(A\\bf x^k -b)\\cdot\\nabla J(\\bf x^k) - \\mu A\\nabla J(\\bf x^k)) -b\\cdot\\nabla J(\\bf x^k) &amp;amp;= 0\\\\\\mu &amp;amp;= \\frac{\\nabla J(\\bf x^k)\\cdot\\nabla J(\\bf x^k)}{A\\nabla J(\\bf x^k)\\cdot\\nabla J(\\bf x^k)}\\end{aligned}\\] def minimum_J(start_value, e = 0.001): x = [np.array(start_value)] while True: gradJ = grad_J(x[-1]) ¬µ = np.dot(gradJ, gradJ) / np.dot(A @ gradJ, gradJ) x.append(x[-1] - ¬µ * grad_J(x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: break # la suite n&#39;est que des tests pour se prot√©ger if np.square(x[-1] - x[-2]).sum() &amp;gt; 1E9: # au cas o√π on diverge print(&quot;DIVERGE&quot;) break if len(x) &amp;gt; 1000: # c&#39;est trop long, je crains la boucle infinie print(&#39;Trop long, boucle infinie ?&#39;) break return np.array(x) x = minimum_J(np.zeros(N))x[-1] - lin.solve(A, b) array([-0., -0., 0., -0., 0., 0., 0., 0., -0.]) print(&quot;Converge en %d it√©rations&quot; % len(x))x Converge en 14 it√©rations array([[ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], [ 5.295, -3.53 , 0. , -15.884, -8.824, -1.765, 14.119, -10.589, -7.06 ], [ 3.488, -5.355, -0.197, -12.432, -13.603, -3.608, 12.295, -13.31 , -8.402], [ 3.085, -4.72 , 0.257, -14.479, -14.586, -3.802, 12.956, -14.127, -9.531], [ 3.128, -4.877, 0.194, -13.924, -15.279, -4.164, 12.973, -14.572, -9.669], [ 3.076, -4.743, 0.232, -14.255, -15.457, -4.161, 13. , -14.712, -9.837], [ 3.091, -4.75 , 0.226, -14.166, -15.569, -4.242, 13.013, -14.786, -9.842], [ 3.083, -4.72 , 0.226, -14.224, -15.6 , -4.239, 13.009, -14.815, -9.863], [ 3.087, -4.718, 0.225, -14.208, -15.618, -4.257, 13.011, -14.829, -9.859], [ 3.086, -4.711, 0.224, -14.22 , -15.623, -4.256, 13.008, -14.836, -9.861], [ 3.087, -4.71 , 0.223, -14.217, -15.627, -4.26 , 13.009, -14.839, -9.859], [ 3.087, -4.708, 0.223, -14.219, -15.627, -4.26 , 13.008, -14.84 , -9.859], [ 3.087, -4.708, 0.222, -14.219, -15.628, -4.261, 13.008, -14.841, -9.858], [ 3.087, -4.708, 0.222, -14.219, -15.628, -4.261, 13.007, -14.841, -9.858]]) " }, { "title": "CAMA : ma32 ma32 M√©thode du gradiant pour syst√®me matriciel", "url": "/cours/posts/ma32-methode-du-gradient-pour-systeme-matriciel/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 25/06$Ax = b$ vu comme un probleme d‚ÄôoptimisationPour r√©soudre $Ax = b$ on va chercher le minimum de la fonctionnelle\\(J(x) = \\frac{1}{2}x^TAx - b.x\\)La d√©riv√©e s‚Äôannule en ce point et est $Ax - b$Calcul de la d√©riv√©eLes deriv√©es de dimension sup√©rieure a 1 peuvent √™tre manipul√©es comme des deriv√©es partielles ou une deriv√©e totale. On s‚Äôint√©resse √† la deriv√©e dans une direction, c.a.d la deriv√©e partielle en $y$ si on va dans la direction de l‚Äôaxe $y$. D√©finition$f : \\Omega \\subset {X\\to Y}$ ($\\Omega$ ouvert) est d√©rivable en $a\\in\\Omega$ si\\(\\exists f&#39;(a)\\in L(X,Y)\\space tel\\space que \\\\f(a+h) = f&#39;(a) + f(a)(h) + h\\space\\epsilon(h)\\)avec: $\\lim_{h\\to 0}\\epsilon (h) = 0$ $L(X, Y)$ applications lin√©aires continues de $X$ dans $Y$ $f‚Äô(a)\\in L(X, Y)$ et non $f‚Äô$ Si $f$ est d√©rivable en $a$ alors $\\forall h \\in X$\\(f&#39;(a)(h) = lim_{\\theta\\to0}\\frac{f(a + \\theta h) - f(a)}{\\theta}\\) Attention √† v√©rifier le type de chaque terme.$f$ est une fonction scalaire donc : $Y = \\mathbb{R}$ $X = \\mathbb{R}^n \\space avec\\space n\\gt 1$ Notation avec le gradient\\(f(a + h) = f(a) + (\\nabla f)(a)^T h + h^T\\epsilon(h)\\) $f$ est scalaire $(\\nabla f)(a)$ est un vecteur dont le produit scalaire avec h donne un r√©elCalculons la d√©riv√©e de J suivant une directionOn calcule la d√©riv√©e de $J(x)$ au point $a$ suivant la direction $h$\\(J&#39;(a)(h) = \\lim_{\\theta\\to0}\\frac{J(a + \\theta h) - J(a)}{\\theta} \\\\= \\lim_{\\theta\\to 0}\\frac{1}{\\theta}\\biggr(\\frac{1}{2}(a+\\theta h)^TA(a+\\theta h) - b^T(a+\\theta h) - \\frac{1}{2}a^TAa+b^Ta\\biggr) \\\\= \\lim_{\\theta\\to0}\\frac{1}{\\theta}\\biggr(\\frac{1}{2}(\\theta a^TAh + \\theta h^TAa +\\theta^2 h^TAh) - \\theta b^Th\\biggr) \\\\= \\frac{1}{2}(a^TAh + h^TAa) - b^T h\\)donc\\(J&#39;:x\\in\\Omega\\subset\\mathbb{R}^n\\to L(\\mathbb{R}^n,\\mathbb{R}) \\\\x\\mapsto\\frac{1}{2}(x^TA + Ax)-b\\)A sym√©triqueDans le cas ou A est sym√©trique, on a:\\(J&#39;(x) = \\nabla J(x) = Ax - b\\)Si la d√©riv√©e s&#39;annule, c.a.d qu&#39;on trouve le minimum, on a r√©solu le syst√®me matriciel Les conditions pour utiliser la m√©thode de gradient sont: A sym√©trique J a un minimum Propri√©te Si A est sym√©trique et d√©finie positive alors $J$ est convexe strictement et coervice ($\\lim_{\\lVert a \\rVert\\to\\infty}J(a) = +\\infty$), alors elle a un minimum." }, { "title": "CAMA : ma31 x.T A x sur un maillage en Numpy", "url": "/cours/posts/ma31-x.TAx-sur-un-maillage-en-numpy/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 17/05Calculons $x^TAx$ avec NumpyNous voulons tracer la courbe, avec $x\\in\\mathbb{R}^2$ :\\(J_A(x) = x^TAx\\)On prendra $x\\in\\mathbb{R}^n$ plus tard. Pour une valeur de $x$ le calcul est x.T @ A @ x, mais on veut faire ce calcul pour un ensemble de $x$ On construit un maillage: un ensemble de point $x$ pour lesquels on calculera $J_A(x)$On utilise np.meshgridx = np.linspace(-1,1,3) # retourne des nombres espaces egalement dans un intervalle specifiey = np.linspace(-1,2,4)mesh = np.meshgrid(x,y) # donne les x puis les y du maillageM = np.array(mesh)M = M.transpose([1,2,0])shape of M: (4, 3, 2)M = array([[[-1., -1.], [ 0., -1.], [ 1., -1.]], [[-1., 0.], [ 0., 0.], [ 1., 0.]], [[-1., 1.], [ 0., 1.], [ 1., 1.]], [[-1., 2.], [ 0., 2.], [ 1., 2.]]])Pour calculer $x^TAx$, on commence par calculer $x^TA$ pour tous points du maillage. On utilise la matrice identit√© pour v√©rifier nos calculs.Cas avec $A = 2*Id$A = 2 * np.diag([1, 1]) # Construit un array diagonalMA = np.einsum(&quot;ijk, ka -&amp;gt; ija&quot;, M, A) # Notation d&#39;EinsteinMA = array([[[-2., -2.], [ 0., -2.], [ 2., -2.]], [[-2., 0.], [ 0., 0.], [ 2., 0.]], [[-2., 2.], [ 0., 2.], [ 2., 2.]], [[-2., 4.], [ 0., 4.], [ 2., 4.]]])On retrouve `2*M`.On peut v√©rifier sur un certain point:M[0,1] @ Aarray([ 0., -2.]) Notez qu‚Äôon a √©crit $xA$ et non $x^TA$. Lorsqu‚Äôon a un vecteur, Numpy privil√©gie le produit matrice vecteur qui donne un vecteur. Ainsi: m[0,1] @ A == m[0,1].T @ ASi on veut une diff√©rence entre un vecteur vertical et horizontal, il faut utiliser des arrays 2D de taille 1*n ou n*1np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, MA, M) # comme k n&#39;est pas dans le r√©sultat, c&#39;est sur lui qu&#39;on fait la sommearray([[ 4., 2., 4.], [ 2., 0., 2.], [ 4., 2., 4.], [10., 8., 10.]])Comme A est la matrice identit√© x2, on retrouve pour tout point sa norme au carr√©Optimisons :np.tensordot Un tensor est une matrice en N dimensions.Comparons les temps de calcul.%timeit np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, np.einsum(&quot;ijk, ka -&amp;gt; ija&quot;, M, A), M)135 ¬µs ¬± 2.56 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each)%%timeit # pour calculer le temps d&#39;execution de toute la cellule %%MA = np.tensordot(M, A, axes=(2,1)) # on somme sur l&#39;axe 2 de M (les points) et l&#39;axe 1 de A (les colonnes)np.einsum(&quot;ijk, ijk -&amp;gt; ij&quot;, MA, M) 102 ¬µs ¬± 1.2 ¬µs per loop (mean ¬± std. dev. of 7 runs, 10000 loops each) On peut avoir un gain de temps 30% et plus ou un peu moins bien que einsum" }, { "title": "CAMA : ma30", "url": "/cours/posts/ma30-methode-du-gradient/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-17 10:00:00 +0200", "snippet": "Lien de la note HackmdCAMA : ma30 Optimisation - M√©thode du gradientCours du 17/05Probleme d‚ÄôoptimisationSoit une fonction $J : \\mathbb{R}^n\\to\\mathbb{R}$, trouver le minimum de $J$, c.a.d trouver $u$ tel que\\(J(u) = \\inf_{v\\in\\mathbb{R}^n}J(v)\\)Probl√®me d‚Äôoptimisation avec contrainte Il est possible de chercher $u$ non pas dans $\\mathbb{R}^n$ mais dans une partie de $\\mathbb{R}^n$, c‚Äôest alors un probl√®me d‚Äôoptimisation avec contrainte.Exemple : On cherche le minimum de $J(x, y)$ avec $x \\lt y$, on cherche dans la partie de $\\mathbb{R}^2$ qui v√©rifie $x \\lt y$.La m√©thode du gradientOn imagine un probl√®me d‚Äôoptimisation en 2D comme un terrain avec du relief, $J(x, y)$ represente l‚Äôaltitude en tout point $(x, y)$. La m√©thode du gradient consiste a prendre un point au hasard et descendre dans la direction qui descend le plus afin de trouver le minimum de $J$.L&#39;algorithme du gradient consiste √† :* prendre un point de d√©part au hasard $p^0 = (x_0, y_0)$* calculer le gradient de $J$ en ce point$$\\nabla J(x_0, y_0) = \\begin{bmatrix} \\frac{\\partial J}{\\partial x} \\\\\\frac{\\partial J}{\\partial y}\\end{bmatrix} (x_0, y_0)$$* avancer dans la direction oppos√©e (le gradient monte) ${\\bf p}^{k+1} = {\\bf p}^k - \\mu \\, \\nabla J({\\bf p}^k)$* on recommence l&#39;√©tape pr√©c√©dente jusqu&#39;√† avoir un point fixe, c.a.d $|| {\\bf p}^{k+1} - {\\bf p}^k|| &amp;lt; \\varepsilon$ avec $\\epsilon$ une petite valeur.def J(x, y): return x**2 + 0.5 * y**2 - 2 * x + 3x = np.linspace(-3,3,100) # genere des points a distance egale sur l&#39;intervalle [-3,3]y = np.linspace(-3,3,100)mx, my = np.meshgrid(x,y)mz = J(mx, my) Calcul du gradient : def grad_J(x,y): return np.array([2*x-2, y]) # calcul√© √† la main √† partir de J **Algorithme du gradient :**``` pythonx = np.array([0,0]) # un point au hasard¬µ = 0.1 # plus il est petit et moins on avance vitee = 0.0001 # epsilon pour la condition d&#39;arr√™twhile True: x_old = x x = x - ¬µ * grad_J(*x) # *x donne en arguments toutes les valeurs de x donc x[0] en 1er arg et x[1] en 2e if np.square(x_old - x).sum() &amp;lt; e**2: break```Le minimum obtenu en appelant $J(*x)$ est au point $[1. 0.]$ ayant pour valeur $2.0000001053122918$.Etude de la convergence du gradientOn stocke les valeurs des points entre le point initial et le point final pour obtenir un ensemble de points et tracer des courbes de convergence.def minimum_J(start_value, ¬µ=0.1, e = 0.001): x = [np.array(start_value)] while True: x.append(x[-1] - ¬µ * grad_J(*x[-1])) if np.square(x[-1] - x[-2]).sum() &amp;lt; e**2: breakx = minimum_J(start_value = (0,1)) # valeur initiale non alignee avec la solutionImpact de $\\mu$Comment est-ce que $\\mu$ influence sur la convergence? $\\mu = 0.1$ : on fait des petits pas. $\\mu = 2$ : on diverge, les pas sont trop grands. On passe de $1$ a $-1$ puis $1$, $-1$ sans tomber sur la solution $0$. $\\mu = 0.8$ : on converge en $17$ iterations contre $46$ avec $\\mu = 0.1$, c‚Äôest 3x plus rapide. $\\mu = 1$ : boucle infinie, on oscille infiniment entre $[0, 0]$ et $[2, 0]$. La valeur de $\\mu$ est importante. Si elle est trop petite on perd du temps, si elle est trop grande on ne trouve pas la solution." }, { "title": "SOCRA : Cours du 15 mai", "url": "/cours/posts/socra-design-patterns/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-05-15 10:00:00 +0200", "snippet": "Working with others Avoid : missing code files ugly code naming code deletion Anticipate problems Rules are required Coding style Code reviewal Automated process Software Craftmanship Basics Quality : clean code, refactoring, tests, simple design Humility : question yourself, countinously improvement Sharing : pair programming, collective ownership of source code Pragmatism : understand constraint, adapt ! Professionalism : treat your client as a partnerDesign patternsWhat is a design pattern ? A general, reusable solution to a commonly occurring problem within a given context in software design.GoF : 24 patterns Creational Builder, Factory Method, Abstract factory, Prototype, Singleton Structural Adapter, Bridge, Composite, Decorator, Facade, Flyweight, Proxy, Delegation Behavioral Chain of responsability, Command, Interpreter, Iterator, Mediator, Memento, Observer, State, Strategy, Template method, Visitor Design patterns CreationalThe singleton Restricts the instanciation of a class to one object. Singleton - Singleton : Singleton - Singleton() + getInstance() : Singleton public class Singleton { private static readonly Singleton instance = new Singleton(); private Singleton() { } public static Singleton Instance() { return instance; }} This is a thread-safe implementation.Factory method Creating objects without having to specify the exact class of the object that will be created.interface IFruit { int Price { get; }}class Cherry : IFruit { public int Price { get; } = 75;}class Apple : IFruit { public int Price { get; } = 100;}class Banana : IFruit { public int Price { get; } = 150;}enum FruitType { Banana, Apple, Cherry}class FruitFactory { private Dictionary&amp;lt;FruitType, Func&amp;lt;IFruit&amp;gt;&amp;gt; mapper; public FruitFactory() { mapper = new Dictionary&amp;lt;FruitType, Func&amp;lt;IFruit&amp;gt;&amp;gt; { {FruitType.Apple, () =&amp;gt; new Apple()}, {FruitType.Banana, () =&amp;gt; new Banana()}, {FruitType.Cherry, () =&amp;gt; new Cherry()} }; } public IFruit Create(FruitType type) { if (!mapper.TryGetValue(type, out var result)) { throw new Exception(&quot;No fruit with type {type}&quot;); } return result(); }}Design Patterns StructuralAdapter (aka Wrapper) Allows the interface of an existing class to be used as another interface.interface IOAdapter { String Read(); void Write(String message);}class ConsoleAdapter : IOAdapter { public String Read() { return Console.Readline(); } public void Write(String message) { Console.WriteLine(message); }}Decorator Allows behavior to be added to an individual object, either statically or dynamically, without affecting the behavior of other objects from the same class.public interface IBananaDecorator : IFruit { Banana Banana { get; }}public class HandOfBanana : IBananaDecorator { const int factor = 4; public HandOfBanana(Banana banana) { Banana = banana; } public int Price =&amp;gt; Banana.Price * factor; public Banana Banana { get; } public int Accept(IFruitVisitor fruitVisitor) { return Banana.Accept (fruitVisitor) * factor; }}Design Patterns BehaviouralVisitor A way of separating an algorithm from an object structure on which it operates.public interface IFruit { int Price { get; } int Accept(IFruitVisitor fruitVisitor);}public class Cherry : IFruit { public int Price { get; } = 75; public int Accept(IFruitVisitor fruitVisitor) { return fruitVisitor.Apply(this); }}public interface IFruitVisitor { int Apply(Cherry fruit); int Apply(Banana fruit); int Apply(Apple fruit);}internal class CherryPromotion : IFruitVisitor { private int count; public int Apply(Apple fruit) { return fruit.Price; } public int Apply(Banana fruit) { return fruit.Price; } public int Apply(Cherry fruit) { var reduction = 0; count++; if (count % 2 == 0) { reduction = -20; } return fruit.Price + reduction; }}Observer An object, called the subject, maintains a list of its dependents, called observers, and notifies them automatically of any state changes, usually by calling one of their methods.public interface IObservableBasket{ void Register(IBasketObserver observer); void Add(IFruit fruit);}public class ObservableBasket : IObservableBasket{ List&amp;lt;IFruit&amp;gt; list = new List&amp;lt;IFruit&amp;gt;(); private readonly List&amp;lt;IBasketObserver&amp;gt; observers = ... public void Register(IBasketObserver observer) { observers.Add(observer); } public void Add(IFruit fruit) { list.Add(fruit); Notify(fruit); } private void Notify(IFruit fruit) { foreach (var observer in observers) { observer.Notify(fruit); } }}public interface IBasketObserver{ void Notify(IFruit fruit);}class BasketLogger : IBasketObserver{ public void Notify(IFruit fruit) { ConsoleAdapter.Instance.Write($&quot;Item added : ‚Äú + fruit.GetType().Name); }}Strategy Enables selecting an algorithm at runtime.public class CherryForStrategy : Cherry{ public CherryForStrategy(IPriceStrategy strategy) { Strategy = strategy; } public IPriceStrategy Strategy { get; set; } public override int Price =&amp;gt; Strategy.Apply(base.Price);}public interface IPriceStrategy{ int Apply(int defaultPrice);}public class SecondAtHalfPrice : IPriceStrategy{ private int count; public int Apply(int defaultPrice) { var reduction = 0; count++; if (count % 2 == 0) { reduction = -20; } return defaultPrice + reduction; }}Organize your timeGet Things Done Capture / collect Clarify / process Organize Reflect / plan Engage / doPomodoro Focus on one task during 25 min Take a break 5 min Repeat 3 or 4 times Take a break 20 minEisenhower matrixOrganize your codeVersion control system VCS Revision Mode CVS Per file Client-server SVN Per commit Client-server GIT Per commit Distributed Branching modes How many productions versions ? How many developers ? Which development process ?FeatureReleaseOrganize your learningTrain yourself Monitory technology Try them : POC Be careful of the silver bullet syndromeTrain with others Coding dojo / Kata Pair programming Code reviews" }, { "title": "CAMA : ma21 - Exercice", "url": "/cours/posts/ma21-surrelaxation-exos/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-11 11:00:00 +0200", "snippet": "Lien de la note HackmdCAMA : ma21 Surrelaxation pour Gauss-Seidel ‚Äì ExerciceCours du 11/05import numpy as npimport scipy.linalg as linimport matplotlib.pylab as plt%matplotlib inlinenp.set_printoptions(precision=3, linewidth=150, suppress=True)On va augmenter le rayon de convergence la m√©thode Jacobi amm√©lior√©e faite en TD √† savoir la m√©thode de Gauss-Seidel.On √©tudiera sa convergence dans diff√©rents cas.Gauss-SeidelLorsqu‚Äôon calcul le x suivant avec Jacobi on ne profite pas du fait que N est triangulaireet donc qu‚Äôon connait la nouvelle valeur de $x_n$ lorsqu‚Äôon calcule $x_{n-1}$. Avec Gauss-Seidelon utilise toujours la derni√®re valeur calcul√©e ce qui acc√©l√®re la convergence.Pour r√©sumer Gauss-Seidel d‚Äôun point de vu matriciel on a : D = la matrice diagonale extraite de A : D = np.diag(np.diag(A)) L = la matrice stritecement triangulaire inf√©rieure de A : L = np.tril(A, -1) U = la matrice stritecement triangulaire sup√©rieure de A : U = np.triu(A, 1)et une it√©ration est donn√©e par la formule suivante :\\[(D + L){\\bf x}^{k+1} = -U{\\bf x}^k + {\\bf b}\\]ou\\[{\\bf x}^{k+1} = D^{-1} \\, ( -L\\, {\\bf x}^{k+1} - U\\; {\\bf x}^k + {\\bf b})\\]c.a.d.\\[\\begin{bmatrix}x_{1}^{k+1} \\\\x_{2}^{k+1} \\\\\\vdots \\\\x_{n}^{k+1} \\\\\\end{bmatrix}=\\begin{bmatrix}1/a_{11} \\quad 0 \\quad \\ldots \\quad 0 \\\\0 \\quad 1/a_{22} \\quad \\ldots \\quad 0 \\\\ \\vdots \\\\0 \\quad 0 \\quad \\ldots \\quad 1/a_{nn} \\\\\\end{bmatrix}\\;\\left(\\;-\\begin{bmatrix}0 \\quad 0 \\quad \\ldots \\quad 0 \\\\a_{21} \\; 0 \\quad \\ldots \\quad 0 \\\\ \\vdots \\\\a_{n1} \\, a_{n2} \\; \\ldots \\quad 0 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1}^{k+1} \\\\x_{2}^{k+1} \\\\\\vdots \\\\x_{n}^{k+1} \\\\\\end{bmatrix}-\\begin{bmatrix}0 \\; a_{12} \\; \\ldots \\; a_{1n} \\\\0 \\quad 0 \\; \\ldots \\; a_{2n} \\\\ \\vdots \\\\0 \\quad 0 \\; \\ldots \\; 0 \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1}^k \\\\x_{2}^k \\\\\\vdots \\\\x_{n}^k \\\\\\end{bmatrix}+\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\vdots \\\\b_{n} \\\\\\end{bmatrix}\\; \\right)\\]Notons que je peux mettre $L\\, {\\bf x}^{k+1}$ √† droite du signe √©gal si je r√©soud mon syst√®me ligne par ligne en commencant par le haut puisque dans ce cas les ${\\bf x}^{k+1}$ utilis√©s sont connus. C‚Äôest ce qu‚Äôon a fait lors du dernier TP.Surrelaxation de Gauss-SeidelComme on a fait avec Jacobi, on introduit de l‚Äôinertie avec $w$ :\\[{\\bf x}^{k+1} = w \\, D^{-1} \\, ( -L\\, {\\bf x}^{k+1} - U\\; {\\bf x}^k + {\\bf b}) + (1-w) \\; {\\bf x}^k\\]V√©rifiez que l‚Äôon arrive √† l‚Äô√©criture matricielle suivante :\\[\\left(\\frac{D}{w} + L\\right)\\, {\\bf x}^{k+1} = \\left(\\frac{1-w}{w} \\, D - U\\right)\\; {\\bf x}^k + {\\bf b}\\]√âcrit ainsi on voit que cette m√©thode consiste √† avoir les √©l√©ments de la diagonale des 2 cot√©s de l‚Äô√©galit√©. On peut interpr√©ter cela comme un avantage li√© √† un gain d‚Äôinformation lors des op√©rations matrice vecteur.Programmons Gauss-Seidel surrelax√©On √©crira deux fonctions : solve_triangular(L,b) qui retourne la solution de L x = b lorsque L est triangulaire inf√©rieure gauss_seidel_r(A, b, x0, w, n) qui fait n iteration de Gauss-Seidel avec w donn√© en argument √† partir de x0. Cette fonction retourne un tableau des valeurs de x calcul√©es (donc tableau en 2D).Comme toujours, attention √† limiter les for et √† faire le plus possible d‚Äôop√©rations vectorielles et matricielles. Solution def solve_triangular(L, b): x = np.empty(len(b)) x[0] = b[0] / L[0,0] for i in range(1,len(L)): x[i] = (b[i] - L[i,:i] @ x[:i]) / L[i,i] return x # je teste A = np.tril(np.random.randint(10, size=(4,4)))b = A.sum(axis=1)solve_triangular(A,b) array([1., 1., 1., 1.]) def gauss_seidel_r(A, b, x0, w=0.5, n=100): D = np.diag(np.diag(A)) L = np.tril(A, -1) U = np.triu(A, 1) L = D / w + L U = ((1-w) / w) * D - U x = x0 values = [] for _ in range(n): x = solve_triangular(L, U @ x + b) values.append(x) return np.array(values) L‚Äôalgorithme de Wikipedia est difficile alire, lent et il s‚Äôagit de Jacobi avec relaxation et non Gauss-Seidel avec relaxation, il est tout ce qu‚Äôil ne faut pas faire. np.random.seed(123)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1)x0 = np.random.random(4)res = gauss_seidel_r(A, b, x0, w=0.2, n=100)print(res[-1])[1. 1. 1. 1.]def plot_convergences(values, result): error = np.square(values - result).sum(axis = -1) / np.square(result).sum(axis=-1) error2 = np.square(np.diff(values)).sum(axis = -1) / np.square(values).sum(axis=-1) fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,4)) ax1.plot(range(len(error)), error) ax1.set_title(&#39;Erreur absolue normalis√©e&#39;) ax1.semilogy(); ax2.plot(range(len(error2)), error2) ax2.set_title(&#39;Erreur relative normalis√©e&#39;) ax2.semilogy() print(&quot;It√©ration du minimum :&quot;,np.argmin(error), np.argmin(error2))plot_convergences(res, np.ones(4)) Resultat It√©ration du minimum : 99 99 Est-ce que la m√©thode de Gauss-Seidel non relax√©e converge dans ce cas ? Reponse gauss_seidel_r(A, b, x0, w=1, n=100)[-1] # oui array([1., 1., 1., 1.]) Le bon casTrouver un seed qui permet de g√©n√©rer un cas qui ne converge pas avec Gauss-Seidel de base mais qui converge avec la relaxation ($w=0.2$). Solution seed = 0while True: np.random.seed(seed) A = np.random.randint(10, size=(4,4)) b = A.sum(axis=1) x0 = np.random.random(4) res = gauss_seidel_r(A, b, x0, w=0.2, n=100) res2 = gauss_seidel_r(A, b, x0, w=1, n=100) if np.square(res[-1] - np.ones(4)).sum() &amp;lt; 0.01 and np.square(res2[-1] - np.ones(4)).sum() &amp;gt; 1 : print(seed) break seed += 1 87 Tracer les courbes de convergence pour le cas retenu avec et sans relaxation. Solution np.random.seed(87)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1)x0 = np.random.random(4) plot_convergences(gauss_seidel_r(A, b, x0, w=0.2, n=100), np.ones(4)) It√©ration du minimum : 95 97 plot_convergences(gauss_seidel_r(A, b, x0, w=1, n=100), np.ones(4)) It√©ration du minimum : 0 0 √âtude de $w$Toujours dans notre cas retenu,indiquer quel est l‚Äôintervale devaleurs de $w$ qui garantit la convergence pour notre syst√®me matriciel A x = b avec toujours le m√™me x0 et un nombre d‚Äôit√©rations √† d√©terminer.Trouver la valeur optimiale de $w$ pour converger le plus rapidement pour ce cas.La pr√©cision demand√©e pour l‚Äôintervale et la valeur optimale est de $10^{-2}$. Solution # utilisons une m√©thode par dichotomiewmin = 0wmax = 1while wmax - wmin &amp;gt; 1E-2: w = (wmax + wmin) / 2 res = gauss_seidel_r(A,b,x0, w, n=1000)[-1] if np.square(res - np.ones(4)).sum(axis=-1) &amp;lt; 1E-3: # converge wmin = w else: wmax = wprint(f&quot;Intervale de convergence : ]0,{(wmin+wmax)/2}]&quot;) Intervale de convergence : ]0,0.69140625] plot_convergences(gauss_seidel_r(A, b, x0, w=0.7, n=500), np.ones(4)) # ca converge tres doucement It√©ration du minimum : 493 494 plot_convergences(gauss_seidel_r(A, b, x0, w=0.7 + 1E-2, n=500), np.ones(4)) # ca diverge clairement Il semble que $\\omega=0.7$ soit la limite de la convergence. # M√©thode brutale (Newton serait plus joli mais je ne sais pas si vous connaissez)# de toute facon c&#39;est tr√®s rapideN = 500best_w = 0best_it = Nfor i in np.arange(0.01, 0.7, 0.01): it_cv = np.argmax(np.square(gauss_seidel_r(A, b, x0, i, 500) - np.ones(4)).sum(axis=-1) &amp;lt; 1E-6) # attention, si la r√©ponse est 0 cela veut dire que cela n&#39;est pas descendu en dessous de 1E-6 if it_cv &amp;gt; 0 and it_cv &amp;lt; best_it: best_w = i best_it = it_cvbest_w, best_it (0.36000000000000004, 154) plot_convergences(gauss_seidel_r(A, b, x0, w=0.36, n=100), np.ones(4)) It√©ration du minimum : 99 99 Trouver la valeur optimale de $\\omega$ doit bien s√ªr pouvoir √™tre fait rapidement. Pour certains probl√®mes particulier on connait la formule qui donne le $\\omega$ optimal, sinon il faut utiliser des heuristiques sans garanties." }, { "title": "CAMA : ma20 Convergence de Jacobi avec inertie", "url": "/cours/posts/ma20-convergence-jacobi-interie/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-11 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 11 / 05Ajouter de l‚Äôinertie √† Jacobi La m√©thode de Jacobi m√®ne au syst√®me it√©ratif :\\({\\bf x}^{k+1} = M^{-1} \\, ( N\\; {\\bf x}^k + {\\bf b})\\)Cette m√©thode converge ssi la matrice $b$ a un rayon spectral inf√©rieur √† 1 (cf ma12). On peut agrandir le rayon de convergence en ajoutant de l‚Äôinertie:\\({\\bf x}^{k+1} = w \\, M^{-1} \\, (N\\; {\\bf x}^k + {\\bf b}) + (1-w) \\, {\\bf x}^k\\) $0 &amp;lt; w \\le 1$. si $w = 1$ : Jacobi classique si $w = 0$ : on n√©glige les termes en dehors de la diagonale et $b$ donc √ßa ne marche pas On parle d‚Äôinertie car on avance ‚Äúmoins vite‚Äù: la nouvelle valeur de ${\\bf x}^{k+1}$ est comprise entre l‚Äôancienne valeur de ${\\bf x}^{k+1}$ et ${\\bf x}^k$. C‚Äôest la surrelaxationProgrammons l‚Äôinertie pour JacobiOn commence pour un Jacobi qui diverge.np.random.seed(799)A = np.random.randint(10, size=(4,4))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[5 7 6 0] [1 7 2 5] [5 6 5 1] [0 6 3 7]] b: [18 15 17 16] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[5 0 0 0] [0 7 0 0] [0 0 5 0] [0 0 0 7]]N: [[ 0 -7 -6 0] [-1 0 -2 -5] [-5 -6 0 -1] [ 0 -6 -3 0]]x0 = np.random.random(4)x = x0for i in range(20): x = (N @ x + b) / M...x_16 = [-4448.651 -1888.411 -4149.91 -1981.882]x_17 = [7627.267 3238.983 7114.521 3399.456]x_18 = [-13068.402 -5548.37 -12190.539 -5823.066]x_19 = [22399.965 9511.401 20894.459 9982.548] Ajoutons de l‚Äôinertie :x = x0 # on reprend la m√™me valeur initiale pour la comparaisonw = 0.5 # on choisit w for i in range(20): x = w * (N @ x + b) / M + (1-w) * x...x_17 = [1.059 0.977 0.972 1.03 ]x_18 = [1.063 0.977 0.968 1.031]x_19 = [1.067 0.978 0.963 1.032]La solution est [1,1,1,1], l&#39;inertie fonctionne.√âtudions la convergenceOn trace une courbe de: l‚Äôerreur absolue (lorsqu‚Äôon connait la solution) de l‚Äôerreur relative (entre 2 ${\\bf x}^i$ successifs) du r√©sidu ($||A \\, {\\bf x}^i - {\\bf b}||$). x = x0 # on reprend la m√™me valeur initiale pour la comparaisonw = 0.5 # on choisit w error = [np.square(x - np.ones(4)).sum()]for i in range(20): x = w * (N @ x + b) / M + (1-w) * x error.append(np.square(x - np.ones(4)).sum()) A l‚Äô√©chelle logarithmique: Il faut toujours regarder une erreur en √©chelle logarithmique.En faisant le calcul sur 200 it√©rations : On s&#39;est rapproch√© de la solution puis on a diverg√©.Erreur relativeRegardons l‚Äô√©cart entre 2 ${\\bf x}^k$ successifs.x = x0 # on reprend la m√™me valeur initiale pour la comparaisonw = 0.5 # on choisit w error2 = []for i in range(200): old_x = x x = w * (N @ x + b) / M + (1-w) * x error2.append(np.square(x - old_x).sum()) Il y a une relation entre l‚Äô√©cart de deux valeurs successives et l‚Äôerreur absolue.L&#39;√©cart entre 2 ${\\bf x}$ successifs est une facon de savoir quand arr√™ter un algorithme it√©ratif.R√©sidux = x0 # on reprend la m√™me valeur initiale pour la comparaisonw = 0.5 # on choisit w residu = []for i in range(200): old_x = x x = w * (N @ x + b) / M + (1-w) * x residu.append(np.square(A @ x - b).sum())Normaliser Si la solution est un milliard, avoir une erreur de 0.1 est tr√®s bien. Si la solution est 0.01, avoir une erreur de 0.1 est √©norme. On ne peut juger une erreur qu‚Äôavec une r√©f√©rence. Si on connait la solution exacte : \\(\\frac{||{\\bf x}^k - {\\bf x}||}{||{\\bf x}||}\\)De m√™me, l‚Äôerreur entre 2 it√©rations successives doit √™tre normalis√©e : \\(\\frac{||{\\bf x}^{k+1} - {\\bf x}^k||}{||{\\bf x}^k||}\\)def mk_A(seed): np.random.seed(seed) return np.random.randint(10, size=(4,4))def plot_error(M, N, b, x0, w, n=200): x = x0 error = [np.square(x - np.ones(4)).sum()] error2 = [] for i in range(n): old_x = x x = w * (N @ x + b) / M + (1-w) * x error.append(np.square(x - np.ones(4)).sum()) error2.append(np.square(x - old_x).sum())def plot_error_normalized(M, N, b, x0, w, n=200): x = x0 error = [np.square(x - np.ones(4)).sum()] error2 = [] for i in range(n): old_x = x x = w * (N @ x + b) / M + (1-w) * x error.append((np.square(x - np.ones(4)).sum())/4) # normalis√© par rapport √† la solution error2.append((np.square(x - old_x).sum())/np.square(x).sum()) # normalis√© par rapport √† xA = mk_A(799)b = A.sum(axis=1) M = np.diag(A) N = np.diag(M) - A x0 = np.random.random(4)plot_error(M, N, b, x0, w=0.1, n=1000) plot_error_normalized(M, N, b, x0, w=0.1, n=1000) L&#39;erreur relative normalis√©e se stabilise." }, { "title": "CAMA : ma13 - Syst√®me matriciel -- Exercices", "url": "/cours/posts/ma13-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-05-04 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 04/05Programmation vectorielle Le but des exercices est d‚Äôavoir un programme qui donne la bonne r√©ponse qui soit le plus rapide possible (et pour cela on utilise massivement Numpy) En r√®gle g√©n√©ral si vous avez des for imbriqu√©s c‚Äôest mauvais signe.M√©thode du pivot de Gauss partielL‚Äôennonc√© est dans le cours Solution def solve_gauss_partial(A, b): # on prend le max dans la colonne i parmi les lignes en dessous (plus facile) for i in range(len(A)-1): pivot = np.argmax(np.abs(A[i:, i])) # il n&#39;y a que 3 lignes √† ajouter pour √©changer les lignes A[[i, pivot]] = A[[pivot, i]] b[[i, pivot]] = b[[pivot, i]] E = np.diag(np.array([1.,] * len(A), dtype=A.dtype)) coefs = - A[i+1:,i] / A[i,i] E[i+1:,i] = coefs A[i:, i:] = E[i:,i:] @ A[i:,i:] b[i+1:] += coefs * b[i] # multiplication terme √† terme # A est maintenant triangulaire surp√©rieur res = np.zeros(len(b), dtype=b.dtype) res[-1] = b[-1] / A[-1,-1] for i in range(len(A)-1)[::-1]: res[i] = (b[i] - A[i,i+1:] @ res[i+1:]) / A[i,i] return res e = 1E-6A = np.array([[e, 1], [1, 2]], dtype=&#39;float32&#39;)b = np.array([1., 3.], dtype=&#39;float32&#39;)print(f&quot;A\\n {A} \\nb\\n {b}\\n&quot;)x = solve_gauss_partial(A, b)print(&#39;solution : &#39;,x)print(&#39;v√©rification\\n&#39;, A@x) A [[0.000001 1. ] [1. 2. ]] b [1. 3.]solution : [1.0000019 0.99999905]v√©rification [3. 0.999997] Factorisation de CholeskiIl s‚Äôagit de d√©composer A en $A = B\\, B^T$ avec B une matrice triangulaire inf√©rieure. Cela n‚Äôest possibleque si la matrice A est sym√©trique et d√©finie positive (c‚Äôest d‚Äôailleurs un facon de v√©rifier qu‚Äôunematrice est d√©finie positive).√âcrire l‚Äôalgorithme de Choleski qui prend A et retourne B (pour deviner l‚Äôalgorithme, essayez de trouver les coefficients de B √† partir des coefficients de A sur une matrice A 4x4). Solution \\(A = B\\, B^T =\\begin{bmatrix}b_{11} &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0\\\\b_{21} &amp;amp; b_{22} &amp;amp; \\dots &amp;amp; 0\\\\&amp;amp; \\vdots&amp;amp;\\\\b_{n1} &amp;amp; b_{n2} &amp;amp; \\dots&amp;amp; b_{n,n}\\end{bmatrix}\\begin{bmatrix}b_{11} &amp;amp; b_{21} &amp;amp; \\dots &amp;amp; b_{n1}\\\\0 &amp;amp; b_{22} &amp;amp; \\dots &amp;amp; b_{n2}\\\\&amp;amp; \\vdots&amp;amp;\\\\b_{n1} &amp;amp; b_{n2} &amp;amp; \\dots&amp;amp; b_{n,n}\\end{bmatrix}=\\begin{bmatrix}b_{11}^2 &amp;amp; b_{11}b_{21} &amp;amp; \\dots &amp;amp; b_{11}b_{n1}\\\\x &amp;amp; \\sum_{i=1}^2b_{2i}^2 &amp;amp; \\dots &amp;amp; \\sum_{i=1}^2b_{2i}b_{ni}\\\\&amp;amp; &amp;amp; \\vdots&amp;amp;\\\\x &amp;amp; x &amp;amp; \\dots&amp;amp; \\sum_{i=1}^2b_{n,i}^2\\end{bmatrix}\\)avec $x$ la m√™me valeur que de l‚Äôautre cot√© de la diagonale On voit que $b_{11} = \\sqrt{a_{11}}$ et maintenant qu‚Äôon a $b_{11}$ on peut trouver toute la premi√®re ligne de $B^T$ : $b_{j1}=a_{1j}/b_{11}$. Une fois qu‚Äôon connait la premi√®re ligne de $B^T$ , on s‚Äôattaque √† la deuxi√®me en commencant par trouver $b_{22}$ puis ensuite tous les autres √©l√©ments de la ligne comme on a fait pour la premi√®re ligne. On a donc dans le cas g√©n√©ral : $b_{ii} = \\sqrt{a_{ii} - \\sum_{k=1}^{i-1}b_{ik}^2}$ $b_{ji} = a_{ij} - \\sum_{k=1}^{i-1}b_{ik}b_{jk}/b_{ii} = a_{ij} - \\sum_{k=1}^{i-1}b_{ik}b_{kj}^T/b_{ii} \\space\\forall j\\gt i$ def Choleski(A): B = np.zeros(A.shape) for i in range(len(A)): B[i,i] = np.sqrt(A[i,i] - np.sum(np.square(B[i, :i]))) # garanti ok car A est def positive B[i+1:, i] = (A[i, i+1:] - B[i, :i] @ B.T[:i, i+1:]) / B[i,i] # les ‚àë sous forme de prod. scalaire return B Matrice symetriqueRappel : pas de boucles for imbriqu√©es mais des op√©rations vectorielles et matricielles (sur des sous-matrices).Cr√©er une matrice sym√©trique d√©finie positive est v√©rifier que votre programme marche bien. Solution A = np.random.randint(10, size=(4,4))A = A + A.T # symm√©triqueA = A + np.diag(A.sum(axis=0)) # diagonale dominanteprint(&#39;A:\\n&#39;, A)B = Choleski(A)print(&#39;B\\n&#39;, B)print(&#39;v√©rification\\n&#39;, B @ B.T) A: [[55 8 18 5] [ 8 33 7 10] [18 7 54 9] [ 5 10 9 28]]B [[7.4161984871 0. 0. 0. ] [1.0787197799 5.6423721639 0. 0. ] [2.4271195049 0.7765914857 6.8924593995 0. ] [0.6741998625 1.6434093681 0.8831939788 4.9055711788]]v√©rification [[55. 8. 18. 5.] [ 8. 33. 7. 10.] [18. 7. 54. 9.] [ 5. 10. 9. 28.]] Am√©liorer JacobiLorsqu‚Äôon √©crit une it√©ration de la m√©thode de Jacobi avec l‚Äôensemble des coefficients, on constate quesi on calcule la nouvelle valeur de x √©l√©ment par √©lement alors lorsqu‚Äôon veut mettre √† jour x[1], on connait d√©j√† x[0]. Idem lorsqu‚Äôon met √† jour x[2] on connait d√©j√† x[0] et x[1], etc.L‚Äôid√©e de la version amm√©lior√©e de Jacobi est d‚Äôutiliser la nouvelle valeur de x[0] et non pas l‚Äôanciennecomme c‚Äôest le cas dans l‚Äôalgorithme du cours. Ainsi en utilisant des valeurs mise √† jour on peut esp√©rerconverger plus vite.Dans ce chaque it√©ration demande un calcul ligne par ligne et donc une boucle for dans la boucle for surles it√©rations.Test d‚Äôarr√™tOn ajoutera un argument error √† la fonction qui indique la pr√©cision d√©sir√©e du r√©sultat. Pard√©faut sa valeur est de 1E-6 et pour offrir une bonne garantie on arr√™te l‚Äôalgorithme lorsque$||x_{t+1} - x_t|| &amp;lt; \\texttt{error}\\, / \\, 10$. Solution def Jacobi(A, b, error=1E-6, verbose=False): L = np.tril(A) U = -np.triu(A, k=1) if verbose: print(f&quot;L:\\n {L}\\nU\\n {U}\\n&quot;) previous_x = np.zeros(len(b)) x = np.random.random(len(b)) err = (error / 10) ** 2 while np.sum(np.square(x - previous_x)) &amp;gt; err: previous_x = x.copy() if verbose: print(f&quot;x = {x}&quot;) # on r√©soud L x = U x + b avec L matrice triangulaire inf√©rieure y = U @ x + b x[0] = y[0] / L[0,0] for i in range(1,len(L)): x[i] = (y[i] - L[i,:i] @ x[:i]) / L[i,i] return x A = np.random.randint(10, size=(4,4))A = A + np.diag(A.sum(axis=0))b = A.sum(axis=1) # ainsi la solution est [1,1,1,1]print(&#39;A:\\n&#39;, A, &quot;\\nb:\\n&quot;, b, &quot;\\n&quot;)Jacobi(A,b, verbose=True) A: [[24 2 1 7] [ 5 19 4 6] [ 9 2 20 9] [ 2 9 9 32]] b: [34 34 40 52] L: [[24 0 0 0] [ 5 19 0 0] [ 9 2 20 0] [ 2 9 9 32]]U [[ 0 -2 -1 -7] [ 0 0 -4 -6] [ 0 0 0 -9] [ 0 0 0 0]]x = [0.8870874823 0.8448958895 0.2146829205 0.8281640711]x = [1.0957657001 1.194392389 1.0147923641 0.9351814319]x = [1.0020897014 1.0168049182 1.0265474982 0.9876765266]x = [1.0010877908 0.9980164155 1.0052544156 0.9990120918]x = [1.0002345046 0.9991440665 1.000424625 1.000106649 ]x = [1.0000225291 0.9998709979 0.9999547701 1.0000475947]x = [0.999998753 0.9999948204 0.9999796615 1.0000072549]x = [0.9999991631 1.000002211 0.9999968908 1.0000003049]x = [0.9999998564 1.0000005961 0.9999998678 0.9999998785]x = [0.9999999913 1.0000000685 1.0000000518 0.9999999667] array([1.0000000018, 0.9999999991, 1.0000000142, 0.9999999961]) " }, { "title": "SOCRA : Cours du 30 avril", "url": "/cours/posts/socra-clean-code/", "categories": "S6, electif, SOCRA", "tags": "S6, SOCRA, electif", "date": "2020-04-30 10:00:00 +0200", "snippet": "Clean code, what is it ?What is your pain ? Bugs ? Not cool when a client find a bug Coding style ? Having a bad coding style Working with others ? Coordinating actions Developer life‚Ä¶ Never thanked, only complaints !By code : Compilation failed Seg fault Stack overflowBy client : ASAP Bad UX Not working‚Ä¶is awesome ! We create products We discover new trades We learn !Software craftmanship manifesto Not only working software, but also well-crafted software.Not only responding to change, but also steadily adding value.Not only individuals and interactions, but also a community of professionals.Not only customer collaboration, but also productive partnership.Technical debt impact Code readbility New features development Bug fixingBe‚Ä¶ KISS : Keep It Simple Stupid DRY : Don‚Äôt Repeat Yourself Focused YAGNI : You Ain‚Äôt Gonna Need It DIE : Duplication Is Evil plz don‚Äôt actually die Copy/paste is easy but hard to bug fix Simple rulesBugs are everywhere : one operation per line helps you identify the location list.Add(line.WordToString());become : var words = line.WordToString();list.Add(words);Do not ask twice for the same thing, it improves your system perfs Foo(lines.Where(l =&amp;gt; l.section == null).ToArray());Bar(lines.Where(l =&amp;gt; l.section == null).ToArray(), lines);become : var linesWithSection = lines.Where(l =&amp;gt; l.section == null).ToArray();Foo(linesWithSection);Bar(linesWithSection, lines); Everytime ask yourself : Sould I be able to understand my code in 6 months ? One year ? Use explicit names Read your code Code phrasesHow ?OO Principles Encapsulation Inheritance Polymorphism Overloading Templates / Generics Subtypings S.O.L.I.D. Snake SRP : Single Responsibility Principle OCP : Open/closed principle LSP : Liskov Substitution Principle ISP : Interface Segregation Principle DIP : Dependency Inversion PrincipleSingle Responsibility PrincipleA class should have only one reason to change. public class Person { public String Name { get; set; } public String Email { get; set; } public Person(String Name, String email) { Name = name; Email = email; ValidateEmail(); } private void ValidateEmail() { // throw if not an email }} public class Person{ public String name { get; set; } public Email Email { get; set; }}public class Email{ public String Adress { get; private set; } public Email(String address) { Address = address; ValidateEmail(); } private void ValidateEmail() { // throw if not an email }}Open/Close PrincipleSoftware entities should be open for extension, but closed for modification. public class Greeter { String formality; public String Greet() { if (this.formality == &quot;formal&quot;) { return &quot;Good evening, sir.&quot;; } else if (this.formality == &quot;casual&quot;) { return &quot;Sup bro?&quot;; } else if (this.formality == &quot;intimate&quot;) { return &quot;Hello Darling!&quot;; } else { return &quot;Hello.&quot;; } } public void SetFormality(String formality) { this.formality = formality; }} public class Greeter { private Personality personality; public Greeter(Personality personality) { this.personality = personality; } public String greet() { return this.personality.greet(); }}Liskov Substitution Principle If $S$ is a subtype of $T$, then objects of type $T$ in a program may be replaced with objects of type $S$ without altering any of the desirable properties of that program.Interface segregation principleMany client-specific interfaces are better than one general-purpose interface.Dependency Injection PrincipleOne should ‚Äúdepend upon abstractions, not concretions‚Äù. public class FileLogger { public void Info(String message) { // Write message into a file }}public class Application { private FileLogger logger; public Application() { this.logger = new FileLogger(); } public void Run() { logger.Info(&quot;Running&quot;); }} public class FileLogger : ILogger { public void Info(String message) { // Write message onto a file }}public class Application { private ILogger logger; public Application(ILogger logger) { this.logger = logger(); } public void Run() { logger.Info(&quot;Running&quot;); }}Be AgileV CycleAgileSCRUMMethodology Product owner Scrum master Developer team BacklogWorkflow Sprint Meeting Planning Plan what needs to be done for the next version Daily Scrum Meeting where are we at Sprint Retrospective what is well done, what is not, etc. KANBANTickets per actionThink testsWhy do we test ? Tests to help understand requirements Tests protects future developments Tests are a fall protection We are human after allHow do we test ? We create code to test our code. Unit Test : Focus on ONE function usage, mock dependencies Integration Test : Crosses the boundary between components Behaviour Test : An example of the user using the systemThe test pyramidTDD : Test Driven DevelopmentNo code without a test Write a test which fails Write the code which fulfil the test Refactor source code (feature and test !)What is a good unit test ? Easy to understanf, clear when it fails Determinist Focused AAA : Arrange / Act / AssertBDD : Behaviour Driven Development A simple test : Given‚Ä¶‚Ä¶When‚Ä¶‚Ä¶.Then‚Ä¶‚Ä¶. Given a user with an account When he tries to create a new account with existing account credentials Then it must be logged in with the existing account The double loopTest coverage A 100% covergae is not a bug-free code." }, { "title": "CCMP2 : Intermediate Representation", "url": "/cours/posts/ccmp2_intermediate-representation/", "categories": "S6, tronc commun, CCMP2", "tags": "S6, CCMP2, tronc commun", "date": "2020-04-27 11:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27/04Boulot qui reste a faire: Lineariser le programme Allocation des registres Gerer la pileCompilers structureEnds: front end: analysis lexical analysis (scanning) synctactic analysis (parsing) ast generation static semantice analysis (type checking) source language specific optimizations hir generation middle end: generic synthesis optimisations generiques back end: specific synthesis register allocation The gcc team suggests: front-end name (‚Äúa front end‚Äù) front-end adjective (‚Äúthe front-end interface‚Äù)Retargetable CompilersSi on veut generer du ARM a partir du JAVA, le trait rpz un compilateur complet. On rajoute un compilateur de JAVA a MIPS, de JAVA a IA-32, etc. et ce pour tous les compilateurs en entree.Cette strategie n‚Äôest pas bonne car il y a beaucoup de compilateurs et de la duplication de code.Supposons qu‚Äôon aie une representation intermediaire:Il suffit plus d‚Äôun traducteur de la representation intermediaire vers ARM, MIPS, etc. On a plus que 4 traducteurs, on a transforme une multiplication en addition. Comment definir cette representation intermediaire?On a besoin d‚Äôune representation flexible pour pouvoir etre la cible des langages de hauts niveaux mais assez assembleur pour etre traduit en assembleur. Le front-end ‚Äútire‚Äù le langage intermediaire vers lui Le back-end ‚Äútire‚Äù la representation intermediaire pour etre le plus proche possible du langage assembleur Premiere idee: baricentre Affecter un poids aux langages en entree et ceux en sortie: avoir un baricentreSi tout le mone a un poids de 1, le langage intermediaire sera plutot front-end, sinon plutot backend. Comment calculer le baricentre de tous mes langages ?On fait l‚Äôinstersection de toutes les fonctionnalites des langages. Qu‚Äôest-ce qui se passe le jour ou on rajoute un nouveau langage? Le baricentre va bouger.Seconde ideeDeux langages intermediaires: un pour le front-end, un pour le back-endTraduction de Java a 1 c‚Äôest facile, de 1 a 2 difficile.On aura plein de petits traducteurs simples et un gros traducteur complique, on a seulement 10 traducteurs.On rajoute deux nouveaux langages intermediaires:La traduction de 1 vers 3 et de 4 vers 2 est moins dure que de 1 vers 2. On est en train de reconstruire une multiplicite de traducteurs.Idee finale couche: j‚Äôenleve la partie objet couche: enlever le support des fonctions variadique couche: transformer les for en while couche: enlever une autre fonctionnalite etc.C‚Äôest le desucrage. Dans notre langage intermediaire on veut desucrer notre langage en entier. Comment definir tous ces langages intermediaires?Syntax, grammaire, type-checker, etc.Deux solutions: Nouveau parser/lexer mais pas coherent On va definir des langages intermediaires mais on va jamais ecrire de parser on va definir une grammaire on va traduire l‚ÄôAST de notre langage original en AST du langage choisir Other Compiling Strategies Intermediate language-based strategies: SmartEiffel, GHC Bytecode strategy: Java bytecode (JVM), CIL (.NET) Hybrid approaches: GCJ (Java bytecode or native code) Retargetable optimizing back ends: MLRISC, VPO (Very Portbale Optimizer), and somehow C‚Äì (Quick C‚Äì) Modular systems: LLVM (compiler as a library, centered on a typed IR). Contains the LLVM core libraries, Clang, LLDB, etc. Also: VMKit: a substrate for virtual machines (JVM, etc.) Emscripten: an LLVM-to-JavaScript compiler. Enables C/C++ to JS compilation Intermediate Representations (IR) are fundamental.Intermediate representationsFormat? Representation? Language?Intermediate representation: a faithful model of the source program ‚Äúwritten‚Äù in an abstract language, the intermediate language may have an external syntax may be interpreted/compiled (havm, byte code) may have different levels (gcc‚Äôs Tree is very much like C)What language flavor ? imperative? Stack based? Register based? Functional? Most function languages are compiled into a lower lever language, eventually a simple $\\lambda$-calculus. Other?What level?A whole range of expressivities, typically aiming at making some optimizations easier: Keep array expressions? Yes: adequate for dependency analysis and related optimizations No: Good for constant folding, strength reduction, loop invariant, code motion, etc. Keep loop construcs? What level of machine independence? Explicit register names? On doit construire notre langage en essayant d‚Äôetre le plus proche possible du code assembleur tout en etant suffisemment abstrait pour pas faire rentrer le nom des registresDesigning an Intermediate Representation Intermediate-language design is largely an art, not a science.Muchnink, 1997float a[20][10]...a[i][j+2]Traduction dans les langages intermediaires:t1 &amp;lt;- a[i, j+2] On va avoir besoin de temporaires pour noter les resultats intermediaires.t1 &amp;lt;- j + 2t2 &amp;lt;- i * 20t3 &amp;lt;- t1 + t2t4 &amp;lt;- 4 * t3t5 &amp;lt;- addr at6 &amp;lt;- t5 + t4t7 &amp;lt;- *t6On a une approche progressive plus agreable qu‚Äôune approche directe.r1 &amp;lt;- [fp - 4]r2 &amp;lt;- r1 + 2r3 &amp;lt;- [fp - 8]r4 &amp;lt;- r3 * 20r5 &amp;lt;- r4 + r2r6 &amp;lt;- 4 * r5r7 &amp;lt;- fp - 216f1 &amp;lt;- [r7 + r6]Sans la traduction precedente, il est impossible de comprendre comment cette traduction fonctionne.GCCStack Based: Java Byte-Codeclass Gcd { static public int gcd(int a, int b) { while (a != b) { if ( a &amp;gt; b) a -= b; else b -= a; } return a; } static public int main(String[] arg) { return gcd(12, 34) }}Stack Based (Edwards, 2003)Advantages Trivial translation of expressions Trivial interpreters No pressure on registers Often compactDisadvantages Does not fit with today‚Äôs architecture Hard to analyze Hard to optimizeRegister Based tc‚Äôs Tree Une representation sous forme de registre est fatalement plus verbeux.Du a: La pile L‚Äôepilogue Le prologueChaque fonction utilise un certain nombre de registres, il y a beaucoup de travails supplementaires pour maintenir la coherence des registres.Register Based: What structure ?How is the structure coded ? Addresses Expressions and instructions have names or (absolute) addresses. (Stack based is a bit like relative address) 2 address instructions ? (triples) 3 addresses instructions ? (quadruples) Quadruples vs Triples:i &amp;lt;- i + 1t1 &amp;lt;- i + 1t2 &amp;lt;- p + 4t3 &amp;lt;- *t2p &amp;lt;- t2t4 &amp;lt;- t1 &amp;lt; 10*r &amp;lt;- t3if t4 goto L1(1) i + 1(2) i sto (1)(3) i + 1(4) p + 4(5) *(4)(6) p sto (4)(7) (3) &amp;lt; 10(8) *r sto (5) (9) if (7), (1)On note le resultat de chaque ligne dans (nb). Autant ne pas prendre cette strategie et prendre une proche des microprocesserus actuels.Register Based (Edwards, 2003)Advantages: Suit today‚Äôs architecture Clearer data flowDisadvantages Harder to synthesize Less compact Harder to interpretTreeOn a besoin d‚Äôun langage intermediaire qui nous sert de support pour le reste du coursGrammarTree sampleMemory managementOn en train de faire remonter les infos du microprocesseur au langage intermediaire, on doit gerer le minimum possible de la memoire pour rester abstraitMemory HierarchyDifferent kinds of memory in a computer, with different performances: Registers Small memory units built on the CPU L1 Cache Last main memory acces results L2 Cache (MB, 10 cycles) Memory The usual ram (GB, 100 cycles) Storage Disks (100GB)Use the registers as much as possibleRegister Overflow Si notre langage a pas la recursion, on n‚Äôa pas de pile a gerer.What if there are not enough registers ? Use the main memory, but how?Recursion: Without: Each name is bound once. It can be statically allocated a single unit of main memory (Cobol, Concurrent Pascal, Frotran)\\ With: a single name can be part of several concurrent bindings. Memory allocation must be dynamicDynamic Memory AllocationDepending on the persistence, several models: Global: global object whose liveness is equal to that of the program, are statically allocated Automatic: liveness is bound to that of the host function Heap: Liveness is indenpendant of function liveness User controlled: malloc/free Garbage collected StackActivation Blocks In recursive languages, a single routine can be ‚Äúopened‚Äù several times concurrently An activation designates one single instance of execution Automatic variables are bound to the liveness of the activation Their location is naturally called activation block or stack frameActivation Blocks ContentsData to store on the stack: arguments: incoming local varibales: user automatic variables return address: where to return saved registers: the caller‚Äôs environment to restore temp: compiler automatic variables, spills static link: when neededActivation Blocks LayoutEst-ce qu‚Äôon peut mettre le content dans l‚Äôordre que je veux ? On doit decider d‚Äôun layout respecte par tous les compilateurs.The layout is suggested by the constructor. fp: frame pointer sp: stack pointer Au milieu de ces 2 pointers on a notre block d‚Äôactivation. Lors d‚Äôun appel de fonction, on descend fp sur sp puis on descend sp. On doit etre capable de stocker l‚Äôancienne valeur de fp.Flexible Automatic Memoryauto: Static size, automatic memorymalloc: Dynamic size, persistent memoryAutomatic memeory is extremely convenientintopen2(char* str1, char* str2, int flags, int mode){ char name[strlen(str1) + strlen(str2) + 1]; strcpy(strcpy(name, str1), str2); return open(name, flags, mode)}On est en train de faire un tableau dynamique.On est sur une variable locale stockee sur la pile, cad stockee sur le bloc d‚Äôactivation. On doit etre capable de preallouer la zone necessaire. Hors ici on dit que la taille de la zone depend des parametres au runtime et ne sera pas connu lors de la compilation.Pour une meme fonction f, on peut avoir des blocs d‚Äôactivation de taille variable. Au moment ou on rentre dans la fonction on doit pousser le stack pointer vers le bas avec alloca:intopen2(char* str1, char* str2, int flags, int mode){ char *name = (char *) alloca(strlen(str1) + strlen(str2) + 1); strcpy(strcpy(name, str1), str2); return open(name, flags, mode)Advantages of alloca Using alloca wastes very little space and is very fast On peut simuler allocaNonlocal variables Une variable est consideree comme une variable non locale si elle est declaree dans une fonction englobante et utilisee dans une autre fonction imbriquee.escapes-n-recursionlet function trace(fn: string, val: int) = (print(fn); print(&quot;(&quot;); print_int(val); print(&quot;)&quot;)) function one(input : int) = let function two() = (trace(&quot;two&quot;, input); one(input - 1)) in if input &amp;gt; 0 then (two(); trace(&quot;one&quot;, input)) endin one(3); print(&quot;\\n&quot;)endResultat de l‚Äôexecution:" }, { "title": "CAMA : ma12 M√©thodes it√©ratives", "url": "/cours/posts/ma12-methode-iterative/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-27 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27 / 04La simulation num√©rique Pour faire cette image, on transforme des √©quations physique en syst√®mes matriciels ou les inconnues sont d√©finies en chaque point d‚Äôun maillage a d√©finir.Dans ce cas l‚Äôinconnue est la pression et le maillage est une bo√Æte imaginaire comprenant l‚Äôavion et l‚Äôair qui circule autour.Si la bo√Æte est un cube avec 1000 points dans chaque direction, on a 1 milliard de points et une matrice a 1 trillion d‚Äô√©l√©ments : \\(\\begin{bmatrix}a_{11} \\; a_{12} \\ldots a_{1,10^9} \\\\a_{21} \\; a_{22} \\ldots a_{2,10^9} \\\\ \\vdots \\\\a_{10^9,1} a_{n2} \\ldots a_{10^9,10^9} \\\\\\end{bmatrix}\\;\\begin{bmatrix}p_{1} \\\\p_{2} \\\\\\vdots \\\\p_{10^9} \\\\\\end{bmatrix}=\\begin{bmatrix}f_{1} \\\\f_{2} \\\\\\vdots \\\\f_{10^9} \\\\\\end{bmatrix}\\)Cela prendrait 300 000 ans √† inverser la matrice. Inverser une matrice ou r√©soudre par une m√©thode directe n‚Äôest pas la bonne solution pour r√©soudre un grand syst√®me matriciel.M√©thodes it√©ratives Les m√©thodes it√©ratives s‚Äôapprochent pas √† pas de la solution recherch√©e et permettent de trouver une approximation de ${\\bf x}$ dans $A\\, {\\bf x} = b$.On arr√™te le calcul lorsqu‚Äôon est √† une distance choisie de la solution, appel√©e l‚Äôerreur. On cherchera jamais √† avoir une erreur plus petite que notre pr√©cision maximale.On a une formule $\\; {\\bf x}^{t+1} = B \\, {\\bf x}^t + {\\bf c}\\;$ ou en Python:x = np.random(size = c.size)while np.square(x - old_x) &amp;gt; seuil: old_x = x x = B @ x + cSi ${\\bf x}$ converge on a atteint un point fixe, c.a.d ${\\bf x}^{t+1} = {\\bf x}^t$ et donc $${\\bf x}^t = B \\, {\\bf x}^t + {\\bf c} \\quad \\textrm{c.a.d.} \\quad (Id -B) \\, {\\bf x}^t = {\\bf c}$$M√©thode de Jacobi La m√©thode de Jacobi d√©coupe la matrice A en M et N avec $M$ : matrice diagonale des √©l√©ments de la diagonale de $A$ $N = M - A$ (donc 0 sur la diagonale et l‚Äôoppos√© des √©l√©ments de $A$ ailleurs) Le syst√®me √† resoudre est $(M - N) {\\bf x} = {\\bf b}$.La formule iterative pour $k + 1$ est : \\(M \\; {\\bf x}^{k+1} = N\\; {\\bf x}^k + {\\bf b}\\)Comme $M$ est une matrice diagonale :\\(\\begin{array}{l}a_{11} x_1^{k+1} = \\qquad -a_{12} \\, x_2^k - a_{13} \\, x_3^k \\ldots - a_{1n} \\, x_n^k + b_1 \\\\a_{22} x_2^{k+1} = -a_{21} \\, x_1^k \\qquad - a_{23} \\, x_3^k \\ldots - a_{2n} \\, x_n^k + b_2 \\\\a_{33} x_3^{k+1} = -a_{31} \\, x_1^k - a_{32} \\, x_3^k \\qquad \\ldots - a_{3n} \\, x_n^k + b_3 \\\\ \\vdots \\\\a_{nn} x_n^{k+1} = -a_{n1} \\, x_1^k - a_{n2} \\, x_3^k \\ldots - a_{n-1,n-1} \\, x_{n-1}^k \\qquad + b_n \\\\\\end{array}\\)Pour calculer $x_i^{k+1}$ il faut diviser par $a_{ii}$ donc il faut que $A$ n‚Äôait pas pas de z√©ro sur sa diagonale.A = np.random.randint(10, size=(4,4))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[2 2 6 1] [3 9 6 1] [0 1 9 0] [0 9 3 4]] b: [11 19 10 16] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[2 0 0 0] [0 9 0 0] [0 0 9 0] [0 0 0 4]]N: [[ 0 -2 -6 -1] [-3 0 -6 -1] [ 0 -1 0 0] [ 0 -9 -3 0]]x = np.random.random(4)for i in range(20): x = (N @ x + b) / M...x_16 = [-4.194 -1.298 0.76 -4.026]x_17 = [6.531 3.45 1.255 6.35 ]x_18 = [-4.891 -1.608 0.728 -4.704]x_19 = [7.277 3.779 1.29 7.073] Ca ne converge pas.2e essai :A = np.random.randint(10, size=(4,4))A = A + np.diag(A.sum(axis=0))b = A.sum(axis=1) # la solution est [1,1,1,1]A: [[24 2 4 8] [ 0 24 9 3] [ 4 6 16 5] [ 6 2 1 32]] b: [38 36 31 41] M = np.diag(A) # vecteurN = np.diag(M) - A # np.diag d&#39;une matrice donne un vecteur, np.diag d&#39;un vecteur donne une matriceM: [[24 0 0 0] [ 0 24 0 0] [ 0 0 16 0] [ 0 0 0 32]]N: [[ 0 -2 -4 -8] [ 0 0 -9 -3] [-4 -6 0 -5] [-6 -2 -1 0]]x = np.random.random(4)for i in range(20): x = (N @ x + b) / M...x_17 = [1. 1. 1. 1.]x_18 = [1. 1. 1. 1.]x_19 = [1. 1. 1. 1.]Pourquoi le 2e cas marche ? Pour qu‚Äôune m√©thode it√©rative du type ${\\bf x} = B\\; {\\bf x} + {\\bf c}$ converge il faut au choix : $\\rho(B) &amp;lt; 1\\quad$ $\\rho$ : le rayon spectral (la plus grande valeur propre en valeur absolue) $||B|| &amp;lt; 1\\quad$ o√π : \\(||B|| = \\sup_{\\bf v} \\frac{||B\\, {\\bf v}||}{||\\textbf{v}||} = \\sup_{\\textbf{v} \\, t.q. ||\\textbf{v}|| = 1} ||B\\, {\\bf v}|| = \\sup_{\\textbf{v} \\, t.q. ||\\textbf{v}|| \\le 1} ||B\\, {\\bf v}||\\) Cas de la m√©thode de Jacobi On respecte ces conditions si $A$ est a diagonale dominante, c.a.d. que chaque √©l√©ment de la diagonale est plus grand que tous les autres de sa ligne et colonne. Jacobi converge aussi si $A$ est sym√©trique, r√©elle et d√©finie positive ($\\forall {\\bf x}, \\; {\\bf x}^T \\, A \\, {\\bf x} &amp;gt; 0$)." }, { "title": "CAMA : ma11 Conditionnement d&#39;une matrice", "url": "/cours/posts/ma11-conditionnement-matrice/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-27 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 27 / 04Soit la matrice sym√©trique $A$ suivante :A = np.array([[10, 7, 8, 7], [7, 5, 6, 5], [8, 6, 10, 9], [7, 5, 9, 10]])array([[10, 7, 8, 7], [ 7, 5, 6, 5], [ 8, 6, 10, 9], [ 7, 5, 9, 10]])lin.det(A) # calcul son determinant0.9999999999999869 # on peut arrondir a 1Construisons $b$ tel que $A{\\bf x} = b$ et $\\bf x = [1,1,1,1]$b = A.sum(axis=1)[32 23 33 31]x = lin.solve(A, b)array([1., 1., 1., 1.]) Perturbons $b$, comme s‚Äôil y avait une erreur de mesure ou d‚Äôarrondi.bp = [32.1, 22.9, 33.1, 30.9]eb = lin.norm(b - bp) / lin.norm(b) # une erreur se mesure par rapport √† la valeur de la donn√©e0.0033319453118976702On a une erreur de l‚Äôordre de $0,3\\%$. On note l‚Äôerreur :\\(\\frac{||{\\bf \\delta b}||}{||{\\bf b}||}\\)Regardons la solution ${\\bf x}$ de notre syst√®me matriciel perturb√©:xp = lin.solve(A, bp)array([ 9.2, -12.6, 4.5, -1.1]) La solution n‚Äôa rien n‚Äôa voir avec $[1,1,1,1]$ex = lin.norm(x - xp) / lin.norm(x) #mesure de l&#39;erreur8.19847546803699L‚Äôerreur est de l‚Äôordre de 8.ex / eb2460.567236431514 C‚Äôest $2460$ fois plus que l‚Äôerreur sur $b$.Pourquoi ?\\(\\begin{aligned} A ({\\bf x} + {\\bf \\delta x}) &amp;amp;= {\\bf b} + {\\bf \\delta b} \\quad \\textrm{et donc} \\\\ A \\, {\\bf \\delta x} &amp;amp;= {\\bf \\delta b} \\; \\textrm{ puisque } A {\\bf x} = {\\bf b} \\quad \\textrm{et finalement}\\\\{\\bf \\delta x} &amp;amp;= A^{-1} \\, {\\bf \\delta b}\\end{aligned}\\)Comme $A$ et son inverse sont des applications lin√©aires :\\[||{\\bf b}|| \\le ||A|| \\, ||{\\bf x}||\\quad \\textrm{et} \\quad ||{\\bf \\delta x}|| \\le ||A^{-1}|| \\, ||{\\bf \\delta b}||\\]donc :\\[\\frac{||{\\bf \\delta x}||}{||{\\bf x}||} \\le ||A^{-1}|| \\, \\frac{||{\\bf \\delta b}||}{||{\\bf x}||}\\le ||A^{-1}|| \\, ||A|| \\, \\frac{||{\\bf \\delta b}||}{||{\\bf b}||}\\]lin.norm(lin.inv(A)) * lin.norm(A)3009.5787080586942 On appelle cela le conditionnement de $A$ : \\(cond(A) = ||A^{-1}|| \\, ||A||\\)Une matrice mal conditionn√©e va g√©n√©rer des erreurs de calcul lors de la r√©solution du syst√®me matriciel.np.linalg.cond(A) # scipy n&#39;a pas le conditionnement mais numpy l&#39;a. 2984.0927016757555 # different de 3009Perturbons la matricenp.random.seed(0)dA = 2 * np.random.random(size = A.shape) - 1array([[ 0.098, 0.43 , 0.206, 0.09 ], [-0.153, 0.292, -0.125, 0.784], [ 0.927, -0.233, 0.583, 0.058], [ 0.136, 0.851, -0.858, -0.826]])ea = lin.norm(dA) / lin.norm(A) # erreur relative sur A0.06868857112100454Ap = A + dAarray([[10.098, 7.43 , 8.206, 7.09 ], [ 6.847, 5.292, 5.875, 5.784], [ 8.927, 5.767, 10.583, 9.058], [ 7.136, 5.851, 8.142, 9.174]])xp = lin.solve(Ap, b)array([-12.365, 15.574, 10.146, -5.94 ])ex = lin.norm(xp - x) / lin.norm(x)11.432687335993894ex / ea # valeur de l&#39;erreur166.44235204505293L&#39;erreur est moins grande. Une erreur peut fortement perturber $A$, le conditionnement et l‚Äôerreur sont tous les deux importants.Pour retrouver le conditionnement de $A$ dans ce cas : \\(\\begin{align}&amp;amp; (A + \\Delta A) \\, ({\\bf x} + {\\bf \\delta x}) = {\\bf b} \\quad \\textrm{et donc} \\\\&amp;amp; A \\, {\\bf \\delta x} + \\Delta A \\, ({\\bf x} + {\\bf \\delta x}) = 0 \\; \\textrm{ puisque } A {\\bf x} = {\\bf b} \\quad \\textrm{et finalement}\\\\&amp;amp; {\\bf \\delta x} = -A^{-1} \\,\\Delta A \\, ({\\bf x} + {\\bf \\delta x}) \\quad \\textrm{et} \\\\&amp;amp; ||{\\bf \\delta x}|| \\le ||A^{-1}|| \\, ||\\Delta A|| \\, ||{\\bf x} + {\\bf \\delta x}||\\end{align}\\)Donc \\(\\begin{align}\\frac{||{\\bf \\delta x}||}{||{\\bf x} + {\\bf \\delta x}||}\\le ||A^{-1}|| \\, ||\\Delta A|| = ||A^{-1}|| \\, ||A|| \\, \\frac{||\\Delta A||}{||A||}\\end{align}\\)et\\(\\begin{align}\\frac{||{\\bf \\delta x}||}{||{\\bf x} + {\\bf \\delta x}||}\\le cond(A) \\, \\frac{||\\Delta A||}{||A||}\\end{align}\\)Propri√©t√©s $cond(A) \\ge 1$ car $Id = A\\, A^{-1}$ et donc $1 \\le ¬† A ¬† \\, ¬† A^{-1} ¬† $ $cond(A) = cond(A^{-1})$ $\\displaystyle cond_2(A) = \\frac{\\max_i \\lambda_i }{\\min_i \\lambda_i }$ si la matrice est r√©elle 2 indique qu‚Äôon utilise la norme 2 $\\lambda_i$ sont les valeurs propres de A vp = lin.eigvals(A)vp.max() / vp.min() si A est unitaire ou orthogonale : $cond_2(A) = 1$ le conditionnement n‚Äôest pas modifi√© par transformation unitairePr√©conditionnement Le conditionnement peut etre tranform√© : \\(\\forall A, \\exists B \\; \\textrm{appel√©e matrice de pr√©conditionnement t.q.} \\quad cond(B\\, A) &amp;lt; cond(A)\\) On r√©soud $B\\, A {\\bf x} = B\\, {\\bf b}$." }, { "title": "CAMA : ma10 Syst√®me d&#39;√©quations", "url": "/cours/posts/ma10-systeme-equations/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-04-26 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 26 / 04Syst√®mes matriciels Un syst√®me de plusieurs √©quations √† autant d‚Äôinconnues peut s‚Äô√©crire comme syst√®me matriciel $A {\\bf x} = {\\bf b}$ : \\(\\begin{bmatrix}a_{11} a_{12} \\ldots a_{1n} \\\\a_{21} a_{22} \\ldots a_{2n} \\\\ \\vdots \\\\a_{n1} a_{n2} \\ldots a_{nn} \\\\\\end{bmatrix}\\;\\begin{bmatrix}x_{1} \\\\x_{2} \\\\\\vdots \\\\x_{n} \\\\\\end{bmatrix} =\\begin{bmatrix}b_{1} \\\\b_{2} \\\\\\vdots \\\\b_{n} \\\\\\end{bmatrix}\\)ExempleOn achet√© 3 fois des quantit√©s de fruits dont nous n‚Äôavons pas le prix.# A est la quantit√© de chaque fruit achet√©e# x est le prix de chaque fruit# b est la somme qu&#39;on a pay√© pour chaque courseA = np.array([[6,5,4], [5,3,2], [7,3,2]])b = np.array([11.7, 7.9, 9.5])x = lin.inv(A) @ barray([0.8, 0.9, 0.6])R√©solution d‚Äôun syst√®me matricielM√©thode du pivot de Gauss On transforme $A$ en une matrice triangulaire pour r√©soudre le syst√®me de $O(n^2)$ op√©rations.On met des $0$ sur la premi√®re colonne en dessous de la diagonale en multipliant $A$ par la matrice $E_1$ suivante : \\(E_1 = \\begin{bmatrix}\\;1 \\quad 0\\; 0 \\ldots 0 \\\\\\frac{-a_{21}}{a_{11}} \\, 1\\; 0 \\ldots 0 \\\\\\frac{-a_{31}}{a_{11}} \\, 0\\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{-a_{n1}}{a_{11}}\\; 0\\; 0 \\ldots 1 \\\\\\end{bmatrix}\\)$E_2$ sera similaire avec des termes $\\frac{-a_{k2}}{a_{22}}$ sous la diagonale, de m√™me pour les matrices $E_n$ suivantes. Si on multiplie $A$ par $E_1$ il faut √©galement multiplier $b$ par $E_1$.Syst√®me matriciel avec matrice triangulaire Il faut r√©soudre $U{\\bf x} = c$ avec $U$ une matrice triangulaire sup√©rieure.On part de la derni√®re ligne et on obtient\\({\\bf x}[-1] = \\frac{c[-1]}{U[-1, -1]}\\)Une fois ${\\bf x}[-1]$ connu, on en d√©duit la valeur de ${\\bf x}[-2]$, puis celle de ${\\bf x}[-3]$, etc.def solve_gauss(A, b): for i in range(len(A)-1): E = np.diag(np.array([1.,] * len(A), dtype=A.dtype)) coefs = - A[i+1:,i] / A[i,i] E[i+1:,i] = coefs A[i:, i:] = E[i:,i:] @ A[i:,i:] b[i+1:] += coefs * b[i] # multiplication terme √† terme # A est maintenant triangulaire sup√©rieur res = np.zeros(len(b), dtype=b.dtype) res[-1] = b[-1] / A[-1,-1] for i in range(len(A)-1)[::-1]: res[i] = (b[i] - A[i,i+1:] @ res[i+1:]) / A[i,i] return resA = 10 * np.random.random(size=(5,5))b = A.sum(axis=1)A [[5.655 3.042 3.18 9.672 8.761] [3.963 9.923 9.868 7.934 6.328] [0.697 9.189 7.799 2.046 2.184] [6.314 8.533 4.879 8.112 4.583] [3.803 6.89 2.266 6.087 0.361]] b [30.31 38.015 21.914 32.42 19.407]solve_gauss(A, b)D√©composition Lower Upper Si on a besoin de r√©soudre plusieurs syst√®mes matriciels avec $A$, on d√©compose $A$ en un produit d‚Äôune matrice triangulaire inf√©rieure et d‚Äôune matrice triangulaire sup√©rieure.\\(A = LU\\)On utilise le pivot de Gauss mais au lieu de modifier $b$, on calcule l‚Äôinverse de la matrice $E_n \\ldots E_2\\, E_1$ :\\(\\begin{aligned}E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= E_n \\ldots E_2\\, E_1 \\, b \\quad \\textrm{donc} \\\\(E_n \\ldots E_2\\, E_1)^{-1} \\, E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= b \\\\E_1^{-1} \\, E_2^{-1} \\ldots E_n^{-1} \\; E_n \\ldots E_2\\, E_1 \\, A\\, x &amp;amp;= b \\\\\\end{aligned}\\) Ce calcul est simple, la matrice inverse a les valeurs oppos√©es : \\(E_1^{-1} = \\begin{bmatrix}\\;1 \\quad 0\\; 0 \\ldots 0 \\\\\\frac{a_{21}}{a_{11}} \\, 1\\; 0 \\ldots 0 \\\\\\frac{a_{31}}{a_{11}} \\, 0\\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{a_{n1}}{a_{11}}\\; 0\\; 0 \\ldots 1 \\\\\\end{bmatrix}\\) Le produit $E^{-1} = E_1^{-1} \\,E_1^{-1} \\,E_2^{-1} \\,E_3^{-1} \\, \\ldots \\,E_n^{-1}$ est la concat√©nation des colonnes : \\(E^{-1} = \\begin{bmatrix}\\;1 \\quad 0\\; \\; 0 \\ldots 0 \\\\\\frac{a_{21}}{a_{11}} \\; \\; 1\\; \\; 0 \\ldots 0 \\\\\\frac{a_{31}}{a_{11}} \\, \\frac{a_{32}}{a_{22}} \\; 1 \\ldots 0 \\\\\\vdots \\\\\\frac{a_{n1}}{a_{11}}\\; \\frac{a_{n2}}{a_{22}}\\; \\frac{a_{n3}}{a_{33}} \\ldots 1 \\\\\\end{bmatrix}\\)Pour r√©soudre $L\\, U \\, {\\bf x} = {\\bf b}$ : on r√©soud $L\\, {\\bf y} = {\\bf b}$ obtenant ${\\bf y}$ on r√©soud $U\\, {\\bf x} = {\\bf y}$ obtenant la solution ${\\bf x}$def LU(A): L = np.diag([1.,] * len(A)) for i in range(len(A)-1): E = np.diag([1.,] * len(A)) E[i+1:,i] = - A[i+1:,i] / A[i,i] L[i+1:,i] = -E[i+1:,i] A[i:, i:] = E[i:,i:] @ A[i:,i:] return L, AA = 10 * np.random.random(size=(5,5))L,U = LU(A.copy()) # Attention, notre fonction modifie A donc si on veut le r√©utiliser il faut une copieA [[2.697 6.265 5.876 1.927 3.951] [2.495 0.021 9.085 0.504 9.23 ] [0.788 1.982 5.048 9.656 8.581] [3.19 7.474 8.344 0.124 2.577] [4.209 6.825 9.223 9.025 4.733]]L[[ 1. 0. 0. 0. 0. ] [ 0.925 1. 0. 0. 0. ] [ 0.292 -0.026 1. 0. 0. ] [ 1.183 -0.011 0.418 1. 0. ] [ 1.561 0.511 -0.529 -1.924 1. ]]U[[ 2.697 6.265 5.876 1.927 3.951] [ 0. -5.776 3.647 -1.279 5.574] [ 0. 0. 3.427 9.059 7.573] [ 0. 0. 0. -5.957 -5.201] [ 0. 0. 0. 0. -10.285]]A - (L @ U)array([[ 0., 0., 0., 0., 0.], [ 0., -0., 0., 0., 0.], [ 0., 0., -0., 0., 0.], [ 0., 0., 0., -0., 0.], [ 0., 0., 0., 0., 0.]])Gauss Jordan On diagonalise $A$ par des multiplications matricielles similaire √† celles de Gauss qui annulent aussi les termes au dessus de la diagonale : \\(E_3 = \\begin{bmatrix}1 \\; 0\\; \\frac{-a_{11}}{a_{33}} \\; 0 \\ldots 0 \\\\0 \\; 1\\; \\frac{-a_{21}}{a_{33}} \\; 0 \\ldots 0 \\\\0 \\; 0\\quad 1 \\quad 0 \\ldots 0 \\\\0 \\; 0\\; \\frac{-a_{41}}{a_{33}} 1 \\ldots 0 \\\\\\vdots \\\\0 \\; 0\\; \\frac{-a_{n1}}{a_{33}} 0 \\ldots 1 \\\\\\end{bmatrix}\\)def solve_gauss_jordan(A,b): for i in range(len(A)): d1 = np.diag([1.,] * len(A)) d1[:,i] = - A[:,i] / A[i,i] A = d1 @ A b = d1 @ b return b / np.diag(A)A = 10 * np.random.random(size=(5,5))b = A.sum(axis=1)solve_gauss_jordan(A, b)array([1., 1., 1., 1., 1.])" }, { "title": "CAMA : ma06 Vecteurs propres -- Exercice: nuage de points en 3D", "url": "/cours/posts/ma06-exo/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 12:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30/03On a des r√©sultats de mesures et on sait qu‚Äôon doit avoir une relationquadratique entre x et y :\\[y = \\alpha \\, x^2 + \\beta \\, x + \\gamma\\]Comment trouver ces 3 coefficients ?Bien s√ªr on va faire une analyse en composante principale mais attention, celane marche que pour les relations lin√©aires (ca nous donne un vecteur). Aussiil faut introduire une nouvelle variable pour que notre √©quation soit lin√©aire.Comment √©crire notre probl√®me pour qu‚Äôelle soit lin√©aire suivant 2 variables ? Solution On d√©finit $y=x^2$ et ainsi $z$ s‚Äô√©crit en fonction de $x$ et $y$.Donn√©es de l‚Äôexp√©rienceFabriquer un nuage de point 3D avec nos 3 variables en choisissant les inconnuescomme indiqu√© dans l‚Äô√©quation ci-dessous :\\[y = -1.3 \\, x^2 + 0.2 \\, x + 1.45 + U(-1,1) \\quad \\textrm{avec U la loi uniforme qui simule du bruit.}\\]N = 50x = 6 * np.random.rand(N) - 3nuage = np.array(...)fig = go.Figure(data=[go.Scatter3d(x=nuage[0,:], y=nuage[1,:], z=nuage[2,:], mode=&#39;markers&#39;)]) Solution N = 50x = 6 * np.random.random(N) - 3 # x varie entre -3 et 3z = -1.3 * np.square(x) + 0.2 * x + 1.45 + (2*np.random.random(N) - 1)nuage = np.array([x,z]) plt.plot(nuage[0], nuage[1], &#39;x&#39;)plt.title(&#39;Un nuage de points&#39;)plt.axis(&#39;equal&#39;); Calculs pour trouver les caract√©ristiques de notre nuageFabriquer √† partir de notre nuage de points 2D un nuage de points 3D en introduisant la nouvelle variable qu‚Äôon a choisit.Le nouveau nuage s‚Äôappelle nuage3D. Solution y = np.square(nuage[0])nuage3D = np.array([x,y,z]) fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;)])fig.show()fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;)])fig.show() Matrice de covarianceCalculer la matrice de covariance de notre nuage et ses vecteurs propres (on stockera les vecteurs propres dans la variable vec). Solution cov = np.cov(nuage3D.copy()) array([[ 2.723, -0.146, 0.649], [-0.146, 7.802, -9.982], [ 0.649, -9.982, 13.184]]) val, vec = lin.eig(cov) [20.852+0.j 2.733+0.j 0.124+0.j][[ 0.033 -0.994 -0.107] [-0.607 -0.106 0.787] [ 0.794 -0.039 0.607]] # On trie suivant la norme des valeurs propres par ordre d√©croissant (ce n&#39;est pas tri√© par d√©faut)idx = np.argsort(val)[::-1]val = val[idx]vec = vec.T[idx].T # ce sont les colonnes qu&#39;il faut ordonner et non les lignesprint(val, &#39;\\n&#39;, vec) [20.852+0.j 2.733+0.j 0.124+0.j] [[ 0.033 -0.994 -0.107] [-0.607 -0.106 0.787] [ 0.794 -0.039 0.607]] fig = go.Figure(data=[go.Scatter3d(x=nuage3D[0], y=nuage3D[1], z=nuage3D[2], mode=&#39;markers&#39;), go.Scatter3d(x=[0,-5*vec[0,0]], y=[0,-5*vec[1,0]], z=[0,-5*vec[2,0]]), go.Scatter3d(x=[0,vec[0,1]], y=[0,vec[1,1]], z=[0,vec[2,1]])])fig.show() Vecteur propreQue peut-on d√©duire de notre premier vecteur propre ? Solution Il nous donne la direction principale du nuage de point. En regardant bien la figure on voit que le vecteur d√©pend de y mais pas de x donc il nous donne la composante de y (c.a.d. celle de x¬≤). alpha = vec[2,0] / vec[1,0] # la pente du premier vecteur propre -1.3064566708285197 Nuage de point en 2DCr√©er un nuage de point en 2D qui ne prend plus en compte l‚Äôimpact du coefficient que l‚Äôon vient de trouver. Solution On appelle ce nouveau nuage nuage2D (ce n‚Äôest pas le m√™me que notre nuage initial). nuage2D = np.array([nuage3D[0], nuage3D[2] - alpha * nuage3D[1]]) plt.plot(nuage2D[0], nuage2D[1], &#39;x&#39;)plt.axis(&#39;equal&#39;); DeductionQue peut-on en d√©duire ? Solution cov = np.cov(nuage2D.copy()) array([[2.723, 0.459], [0.459, 0.419]]) val, vec = lin.eig(cov) [2.811+0.j 0.331+0.j][[ 0.982 -0.188] [ 0.188 0.982]] Valeurs finalesDonner les valeurs de $\\alpha, \\beta, \\gamma$ que vous avez trouv√©es √† partir de votre nuage de point 3D initial. Solution beta = vec[1,0] / vec[0,0] 0.1916825747224307 moyenne = nuage2D.mean(axis=1)print(&#39;Moyenne des points du nuage :&#39;, moyenne)eq_droite = lambda x: beta * (x - moyenne[0]) + moyenne[1]print(&quot;Le d√©calage verticale est de &quot;, eq_droite(0))gamma = eq_droite(0) Moyenne des points du nuage : [0.228 1.328]Le d√©calage verticale est de 1.2847052624609907 print(&quot;Les coefficients de z fonction polynomiale de degr√© 2 en x sont :\\n&quot;)print(f&quot;alpha = {alpha}&quot;)print(f&quot;beta = {beta}&quot;)print(f&quot;gamma = {gamma}&quot;) Les coefficients de z fonction polynomiale de degr√© 2 en x sont :alpha = -1.3064566708285197beta = 0.1916825747224307gamma = 1.2847052624609907 " }, { "title": "CAMA : ma01 et ma02 - Exercices", "url": "/cours/posts/cama_exos/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 11:00:00 +0200", "snippet": "Lien de la note HackmdExercice 1.1√âcrire sous forme d‚Äôun produit matriciel la sym√©trie axiale par rapport √† un axe qui ne passe pas par (0,0). On prendra l‚Äôaxe qui passe par (2,0) et qui a un angle de œÄ/3 par rapport √† l‚Äôhorizontale.Est-ce un automorphisme orthogonal ? Le montrer. Solution def R3(Œ±): return np.array([[np.cos(Œ±), -np.sin(Œ±), 0], [np.sin(Œ±), np.cos(Œ±), 0], [0, 0, 1]])Sx3 = np.array([[1,0,0], [0,-1,0], [0,0,1]])def T(v): # translation of v T = np.identity(3) T[0:2,2] = v return TŒ∏ = np.pi / 3a = np.array([2,0])S = T(a) @ R3(Œ∏) @ Sx3 @ R3(-Œ∏) @ T(-a)print(&quot;Matrix of symmetry:\\n&quot;, S)shape2 = S @ shape1_3dplt.plot(shape1[0], shape1[1], &quot;:&quot;)plt.plot(shape2[0], shape2[1])plt.plot([a[0]-3*np.cos(Œ∏),a[0]+np.cos(Œ∏)],[a[1]-3*np.sin(Œ∏),a[1]+np.sin(Œ∏)], &quot;-.&quot;) # axe de sym√©trieplt.axis(&#39;equal&#39;); Matrix of symmetry: [[-0.5 0.866 3. ] [ 0.866 0.5 -1.732] [ 0. 0. 1. ]] # Ce n&#39;est pas un automorphisme orthogonal car S n&#39;est pas orthogonale :S @ S.T array([[10. , -5.196, 3. ], [-5.196, 4. , -1.732], [ 3. , -1.732, 1. ]]) Exercice 3.1 (rotation de la cam√©ra autour de son axe)On a indiqu√© que ùúÉ est l‚Äôangle que la cam√©ra fait par rapport √† l‚Äôhorizontal (√† supposer que dans le monde r√©el un des axes est la verticale). Ajouter √† toutes les transformations la possibilit√© de faire tourner la cam√©ra sur son axe principal. Solution # on fait une simple matrice de rotation autour de z apr√®s √™tre dans le rep√®re de la cam√©raroll = lambda t: np.array([[np.cos(t), -np.sin(t), 0, 0], [np.sin(t), np.cos(t), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) view(F(2.3) @ roll(np.pi/4) @ R @ T(c)) Exercice 3.2D√©finir la direction dans laquelle regarde la cam√©ra avec un vecteur et non 2 angles de rotation. R√©digez pour expliquer vos calculs.direction = [1,1,0] # √† gauche √† 45 degr√© Solution On a vu que dans la monde 3D r√©el la direction initiale de la cam√©ra est x. Il faut transformer la nouvelle direction qu‚Äôon nous donne pour la cam√©ra en 2 angles de rotation ce qui donnera nos 2 matrices de rotation. On calcule les angles en fonction de la direction donn√©e grace aux formules de trigonom√©trie qu‚Äôon retrouve sur le cercle unit√©. En 2D on a : $x=\\cos(\\alpha)$ $y=\\sin(\\alpha)$ Donc si on a la direction (x,y) cela veut dire que l‚Äôangle qui nous int√©resse est $\\alpha=\\arccos(x)$ mais ATTENTION cela n‚Äôest juste que si la direction est de norme = 1. Aussi on prend le ratio entre x et y qui est √©gale au ratio des valeurs norm√©es. Ainsi\\(\\alpha=\\arctan(y/x)\\)En 3D on doit se rapportee au cas 2D qui diff√©re suivant qu‚Äôon cherche l‚Äôangle vertical ou horizontal. La rotation horizontale se fait dans le plan [x,y] : $x=\\cos(\\psi)$ $y=\\sin(\\psi)$ et donc\\(\\psi=\\arctan(y/x)\\)La rotation verticale se fait dans le plan [x+y, z] avec $\\psi\\in[‚àí\\pi/2,\\pi/2]$ $ ¬† x+y ¬† =cos(\\phi)$ $z=\\sin(\\phi)$ et donc\\(\\phi=\\arctan(z/||x+y||)\\) def D(direction): if len(direction) == 2: # 2 angles ah = direction[0] av = direction[1] else: # on convertit la direction en angle norm = np.sqrt(direction[0]**2 + direction[1]**2) if norm == 0: # alors c&#39;est vertical ah = 0 av = 1 else: av = np.arctan(direction[2]/norm) if direction[0] == 0: if direction[1] != 0: ah = np.sign(direction[1]) * np.pi/2 else: ah = np.arctan(direction[1]/direction[0]) print(ah, av) if type(ah) == int: ah = ah * 2 * np.pi / 360 av = av * 2 * np.pi / 360 rh = np.array([[np.cos(ah), -np.sin(ah), 0, 0], [np.sin(ah), np.cos(ah), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) rv = np.array([[np.cos(av), 0, np.sin(av), 0], [0, 1, 0, 0], [-np.sin(av), 0, np.cos(av), 0], [0, 0, 0, 1]]) return rv @ rh view(F(2.3) @ R @ D([1,1,0]) @ T(c)) 0.7853981633974483 0.0 " }, { "title": "CAMA : ma05 Vectors propres -- Applications", "url": "/cours/posts/ma05-application-vecteur-propre/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Nuage de points On peut √©tudier la forme d‚Äôun nuage de points par une analyse en composantes principales (ACP), c.a.d. chercher les vecteurs propres de la matrice de covariance ou de corr√©lation.On v√©rifie avec un nuage de points ayant une corr√©lation forte entre $x$ et $y$ : \\(y = 0.2 \\, x + 1.45 + U(-1,1) \\quad \\textrm{avec U la loi uniforme qui simule du bruit.}\\)Entre x et y il y a: une pente de 0.2 un d√©calage vertical de 1.45 en x = 0 On essaye de retrouver la corr√©lation entre x et y malgr√© le bruit avec seulement le nuage de points.N = 50x = 6 * np.random.rand(N) - 3nuage = np.array([x, 0.2 * x + 1.45 + np.random.rand(N)])On cherche la droite qui minimise la distance entre les points et leur projection sur la droite.On construit la **matrice de covariance**, le premier vecteur propre est √©gal au coefficient 0.2 et est le vecteur directeur de la droite recherch√©e. On fait la moyenne du nuage de point dans un point de la droite. cov = np.cov(nuage.copy()) # estime la matrice de covariancearray([[2.744, 0.48 ], [0.48 , 0.168]])val, vec = lin.eig(cov)val = val.astype(&#39;float&#39;) # on convertit puisqu&#39;on sait que ce sont des r√©elsValeurs propres de la matrice de covariance : [2.831 0.081] Vecteurs propres de la matrice de covariance : [[ 0.984 -0.177] [ 0.177 0.984]]moyenne = nuage.mean(axis=1) # Point moyen du nuage[0.328 2.085]eq_droite = lambda x: pente * (x - moyenne[0]) + moyenne[1]Matrice de covariance La covariance entre deux variables indique √† quel point elles sont li√©es.\\(\\textrm{cov}(\\textbf{x},\\textbf{y}) = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\overline{\\textbf{x}}) (y_i - \\overline{\\textbf{y}})\\) $N$ le nombre de points du nuage $\\overline{\\textbf{x}}$ et $\\overline{\\textbf{y}}$ les moyennes de $\\textbf{x}$ et de $\\textbf{y}$. La matrice de covariance exprime toutes les covariances possibles :\\[\\textrm{Cov(nuage 2D)} = \\begin{bmatrix}\\textrm{cov}(\\textbf{x},\\textbf{x}) &amp;amp; \\textrm{cov}(\\textbf{x},\\textbf{y}) \\\\\\textrm{cov}(\\textbf{y},\\textbf{x}) &amp;amp; \\textrm{cov}(\\textbf{y},\\textbf{y}) \\\\\\end{bmatrix}\\]cov = lambda x,y : np.dot((x - x.mean()), (y - y.mean())) / len(x)Cov = lambda x,y : np.array([[cov(x,x), cov(x,y)], [cov(y,x), cov(y,y)]])Cov(nuage[0], nuage[1])array([[2.69 , 0.47 ], [0.47 , 0.164]])Fibonnacci Tu le sais, je le sais, on le sais Fibonnacci c‚Äôest ca :\\(x_n = x_{n-2} + x_{n-1}\\) $x_0 = 1$ $x_1 = 1$. Quelle est la complexit√© pour calculer $x_n$?Ecrivons fibonnacci sous forme d‚Äôun syst√®me matriciel :\\[x_{n-1} = x_{n-1} \\\\x_n = x_{n-2} + x_{n-1} \\\\\\]ce qui donne\\[\\begin{bmatrix}x_{n-1}\\\\x_n \\\\\\end{bmatrix} =\\begin{bmatrix}0 &amp;amp; 1 \\\\1 &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}x_{n-2}\\\\x_{n-1} \\\\\\end{bmatrix}\\] Calculer n produits matriciels n‚Äôest pas rentable.Sachant que $F = P\\, D\\, P^{-1}$, avec P matrice des vecteurs propres et D matrice diagonale des valeurs propres : $$\\begin{bmatrix}x_{n}\\\\x_{n+1} \\\\\\end{bmatrix} =\\begin{bmatrix}0 &amp;amp; 1 \\\\1 &amp;amp; 1 \\\\\\end{bmatrix}^n\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}= (P\\, D\\, P^{-1})^n\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}= P\\, D^n\\, P^{-1}\\begin{bmatrix}x_{0}\\\\x_{1} \\\\\\end{bmatrix}$$On peut calculer $x_n$ en **temps constant**.fval, fvec = lin.eig(F)fval = fval.astype(&#39;float&#39;) # la matrice est sym√©trique donc ses valeurs propres sont r√©ellesValeurs propres de la matrice de fibonnacci : [-0.618 1.618] Vecteurs propres de la matrice de fibonnacci : [[-0.851 -0.526] [ 0.526 -0.851]]fibo = lambda n : (fvec @ np.diag(fval**n) @ lin.inv(fvec) @ x0)[0]Google page rank Soit $N$ pages web numerot√©es qui font r√©f√©rence les unes aux autres. La i-i√®me ligne montre par qui est r√©f√©renc√©e la i-i√®me page web. Il y a 1 dans la j-i√®me colonne si la page j cite la page i et 0 sinon.np.random.seed(42)A = np.random.randint(2,size=(8,8))for i in range(len(A)): A[i,i] = 0 # on ne compte pas les auto-r√©f√©rencementsarray([[0, 1, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0], [1, 1, 0, 0, 1, 0, 1, 1], [1, 1, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 1, 0], [1, 1, 0, 1, 0, 1, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0]]) Le classement des pages utilise les vecteurs propres de cette matrice.val_pr, vec_pr = lin.eig(A)np.abs(vec_pr[:,0]).astype(float) # valeur des pagesA.sum(axis=1) # nombre de citationsValeur des pages : [0.217 0.153 0.376 0.489 0.243 0.514 0.47 0.071]Nombre de citations : [2 1 5 5 3 4 5 1]* La page ayant le meilleur score n&#39;a que 4 citations mais est cit√©e par les 3 pages ayant 5 citations* une page ayant 5 citations est moins bien not√©e que les autres car elle n&#39;est pas cit√©e par la meilleure pageLa matrice A est une application lin√©aire dont l&#39;orientation principale est celle du premier vecteur propre. Le coefficient le plus important de ce vecteur indique la page web la plus importante." }, { "title": "CAMA : ma04 Vecteurs propres", "url": "/cours/posts/ma04-vecteurs-propres/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Soit A une matrice qui repr√©sente une application lin√©aire quelconque. Que se passe-t-il si on l‚Äôapplique $n$ fois ?array([[ 0.707, 0.966, 0.966, 0.707, 0.259, -0.259, -0.707, -1.061, -1.414, -1.061, -0.707, -0. , 0.707], [-0.707, -0.259, 0.259, 0.707, 0.966, 0.966, 0.707, 0.354, 0. , -0.354, -0.707, -0.707, -0.707]])# on prend une matrice de transformation au hasard (donc probablement pas orthoganale)A = np.array([[3,2], [1,2]])as1 = np.dot(A, mouse)as2 = 3 * A @ mouse # souris 3 fois plus grande La transformation n‚Äôest pas une isom√©trie donc la matrice n‚Äôest pas orthogonale. La souris 3x plus grande est isom√©trique car $A$ est une application lin√©aire.aas1 = A @ A @ mouseaaas1 = A @ A @ A @ mouseLa figure s‚Äô√©tire suivant le vecteur $(2, 1)$ Si $A{\\bf x}$ fait tourner la souris d‚Äôenviron 25¬∞, appliquer 2 ou 3 fois $A$ ne fait plus tourner la figure.Vecteurs propres et valeurs propres Les valeurs et vecteurs propres respectent cette priopri√©t√© : \\(A \\, {\\bf v_i} = \\lambda_i \\, {\\bf v_i}\\) $(\\lambda_i, {\\bf v_i})$ : couple valeur / vecteur propres val_propre, vec_propre = lin.eig(A)Valeurs propres de A : [4.+0.j 1.+0.j] Vecteurs propres de A (chaque vecteur propre est √©crit verticalement): [[ 0.894 -0.707] [ 0.447 0.707]] Les vecteurs propres sont des attracteurs qui capturent tous les points si on fait un nombre infini de multiplications par $A$.Les points s‚Äôalignent sur l‚Äôun des deux vecteurs propres.N = 100cercle = np.array([[np.cos(i * 2*np.pi/N), np.sin(i * 2*np.pi/N)] for i in range(N)]).Ta10c = np.array([x for x in (A10 @ cercle).T]).Ta10cn = np.array([x/lin.norm(x) for x in a10c.T]).T # a10c norm√©nb1 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,0]) &amp;lt; 0.01 for i in range(N)]) \\ + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,0]) &amp;lt; 0.01 for i in range(N)])nb2 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,1]) &amp;lt; 0.01 for i in range(N)]) \\ + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,1]) &amp;lt; 0.01 for i in range(N)])Nombre de points proche du 1er vecteur propre : 100Nombre de points proche du 2e vecteur propre : 0Seuls les points colin√©aires au second vecteur propre le resteront, les autres rejoignent le premier vecteur propre.Le cas des matrices de rotationQuels sont les vecteurs propres d‚Äôune matrice de rotation ?def Rot(Œ∏): return np.array([[np.cos(Œ∏), -np.sin(Œ∏)], [np.sin(Œ∏), np.cos(Œ∏)]])R = Rot(2*np.pi/10)R_valp, R_vecp = lin.eig(R)Valeurs propres de R : [0.809+0.588j 0.809-0.588j] Vecteurs propres de R : [[0.707+0.j 0.707-0.j ] [0. -0.707j 0. +0.707j]]# regardons un autre angleR = Rot(2*np.pi/3)R_valp, R_vecp = lin.eig(R)Valeurs propres de R : [-0.5+0.866j -0.5-0.866j] Vecteurs propres de R : [[ 0.-0.707j 0.+0.707j] [-0.707+0.j -0.707-0.j]] Les valeurs et vecteurs propres sont des complexes Les valeurs propres ont la m√™me norme Sym√©trie axiale horizontale\\(Sx = \\begin{bmatrix}1 &amp;amp; 0 \\\\0 &amp;amp; -1 \\\\\\end{bmatrix}\\)Sx = np.array([[1, 0], [0, -1]])Sx_valp, Sx_vecp = lin.eig(Sx)Valeurs propres de Sx : [ 1.+0.j -1.+0.j] Vecteurs propres de Sx : [[1. 0.] [0. 1.]] Une matrice diagonale modifie que la i-i√®me coordonn√©ee de ${\\bf x}$ par la i-i√®me valeur de sa diagonale. Ses vecteurs propres sont ceux de la base d‚Äôorigine :D = np.diag(np.random.randint(10,size=5))D_valp, D_vecp = lin.eig(D)Valeurs propres de D : [8.+0.j 8.+0.j 4.+0.j 7.+0.j 1.+0.j] Vecteurs propres de D : [[1. 0. 0. 0. 0.] [0. 1. 0. 0. 0.] [0. 0. 1. 0. 0.] [0. 0. 0. 1. 0.] [0. 0. 0. 0. 1.]]Diagonalisation d‚Äôune matrice En changeant de rep√®re, on peut repr√©senter une application lin√©aire par une matrice diagonale contenant ses valeurs propres.\\(\\exists P \\; / \\; A = P\\, \\Lambda \\, P^{-1} \\quad\\) avec $\\Lambda$ la matrice diagonale des valeurs propres $\\lambda_i$ P matrice de passage : vecteurs propres Avec_propre @ np.diag(val_propre) @ lin.inv(vec_propre)A : [[3 2] [1 2]] ùëÉ Œõ inv(ùëÉ) : [[3.+0.j 2.+0.j] [1.+0.j 2.+0.j] Matrice inversible : si une des valeurs propre est nulle alors $\\Lambda$ n‚Äôest pas inversible et donc A n‚Äôest pas inversible Matrice non diagonalisable : si l‚Äôensemble des vecteurs propres ne genere pas un espace de meme dimension que d‚Äôorigine, alors on ne peut pas diagonaliser la matrice" }, { "title": "CAMA : ma03 Matrice Camera", "url": "/cours/posts/ma03-matrice-camera/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03 Calculons l‚Äôimage que genere une camera : positionnee en $(c_x, c_y, c_z)$ regardant dans la direction $(v_x, v_y, v_z)$ avec un angle de rotation $c_\\theta$ (que l‚Äôon prend = 0 pour commencer) avec une focale $f$ On a pour tout point $X$ de l‚Äôespace sa position $x$ sur l‚Äôimage donn√©e par\\[x = P X\\] $P$ : matrice qui repr√©sente l‚Äôaction de la cam√©ra. Le but est de trouver $P$.Dimensions $X$ : point en 3D on rajoute une dimension pour les translations (cf ma02) : $X = (X_x, X_y, X_z, 1)$ $x$ : point en 2D pour les translation : $x = (x_x, x_y, 1)$ $P$ matrice de dimensions $3*4$Rep√®res3 reperes : celui du monde en en 3D celui de l‚Äôimage en 2D celui de la camera en 3DFocale On repr√©sente la focale comme la distance entre l‚Äôorigine est la position virtuelle de l‚Äôimage 2D.Dans le repere de la camera : $x = \\frac{f}{X_z} X = f \\frac{X}{X_z}$.Si on bouge uniquement la focale, et que le repere de la camera est le meme que celui du monde alors : \\(\\textrm{si }\\quad P = \\begin{bmatrix}f &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; f &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\quad \\textrm{ on a }\\quadP X = \\begin{bmatrix}f X_x \\\\f X_y \\\\X_z \\\\\\end{bmatrix}\\) C‚Äôest presque le resultat recherche, on a $x$ a un facteur $X_z$ pret.Pour garantir $x_z = 1$ on ajoute une normalisation : f = 0.5 # focaleF = lambda f: np.array([[f, 0, 0, 0], [0, f, 0, 0], [0, 0, 1, 0]])F = array([[0.5, 0. , 0. , 0. ], [0. , 0.5, 0. , 0. ], [0. , 0. , 1. , 0. ]])def normalize(x): x[0,:] /= x[2,:] x[1,:] /= x[2,:] return x[:2,:]Changement de rep√®re L‚Äôaxe principal de la camera est $z$, soit $x$ dans le repere du monde 3D. On choisit comme rep√®re inital de la cam√©ra : $(x,y,z){cam} = (y, z, x){3D}$. La matrice de passage est:\\(X_{cam} = \\begin{bmatrix}0 &amp;amp; 1 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\1 &amp;amp; 0 &amp;amp; 0 \\\\\\end{bmatrix}\\, X_{3D}\\)Pour respecter la notation $(x, y, z, 1)$ : \\(P = \\begin{bmatrix}f &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; f &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\quad\\begin{bmatrix}0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Translation de la cam√©ra Si la camera est en $(c_x, c_y, c_z)$ et non en $(0, 0, 0)$, c‚Äôest une translation : \\(T = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -c_x \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -c_y \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -c_z \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Axe principal de la cam√©raOn change la direction de la camera et son axe principal n‚Äôest plus $x$ du monde 3D. Pour pointer un vecteur 3D dans une direction, il faut 2 rotations autour de 2 axes orthogonaux a notre vecteur. En 2D il suffit d‚Äôune rotation autour de $z$.Pour diriger la camera dans une direction $v$, les rotations se font autour des axes $z$ et $y$ du monde: la rotation horizontale $\\psi$ tourne autour de $z$ la rotation verticale $\\phi$ tourne autour de $y$ \\(D = \\begin{bmatrix}cos(\\phi) &amp;amp; 0 &amp;amp; sin(\\phi) &amp;amp; 0 \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\-sin(\\phi) &amp;amp; 0 &amp;amp; cos(\\phi) &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\;\\begin{bmatrix}cos(\\psi) &amp;amp; -sin(\\psi) &amp;amp; 0 &amp;amp; 0 \\\\sin(\\psi) &amp;amp; cos(\\psi) &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)def D(ah, av): if type(ah) == int: ah = ah * 2 * np.pi / 360 av = av * 2 * np.pi / 360 rh = np.array([[np.cos(ah), -np.sin(ah), 0, 0], [np.sin(ah), np.cos(ah), 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) rv = np.array([[np.cos(av), 0, np.sin(av), 0], [0, 1, 0, 0], [-np.sin(av), 0, np.cos(av), 0], [0, 0, 0, 1]]) return rv @ rh" }, { "title": "CAMA : ma02 Changement de repere", "url": "/cours/posts/ma02-changement-de-repere/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03Matrice de passageUne matrice peut representer un changement de repere :O = np.array((0,0))I = np.array((1,0))J = np.array((0,1))A = np.array((3,3))B = np.array((5,4))C = np.array((1.5,4)) La matrice de passage sans la translation est l‚Äôensemble des vecteurs de la seconde base exprimes dans la premiere. D = np.array([(B-A), (C-A)]).T # d√©formation sans la translation array([[ 2. , -1.5], [ 1. , 1. ]]) Vecteurs dans le nouveau rep√®reOn exprime le vecteur $OJ$ dans la base rouge en utilisant la matrice de passage (l‚Äôorigine d‚Äôun repere n‚Äôest pas utile pour un vecteur) :D @ (J-O) # donne ACarray([-1.5, 1. ])Points dans le nouveau rep√®reIl faut prendre en compte la translation d‚Äôun repere d‚Äôun repere vers l‚Äôautre en separant la deformation de la translation pour rester en 2D :A + D @ I # passage de I en Barray([5., 4.])On peut integrer la translation dans une matrice d‚Äôune dimension superieure (cf ma01).P = np.identity(3) # definie la taille et initialise la derniere ligne (les autres seront remplacees)P[:2, :2] = D # deformationP[:2, 2] = A # translationarray([[ 2. , -1.5, 3. ], [ 1. , 1. , 3. ], [ 0. , 0. , 1. ]])def to3D(x): if len(x.shape) == 1: return np.array([*x,1]) elif len(x.shape) == 2: return np.array([*x,np.ones(len(x[0]))])P @ to3D(J) # is Carray([1.5, 4. , 1. ])Une application lin√©aire transpos√©e dans le nouveau rep√®reAppliquons une rotation qui prend un point et le fais tourner dans le sens trigonom√©trique de Œ∏ autour de (0,0).Que fait cette rotation dans notre nouveau repere? on applique plusieurs fois une rotation au point (1,0) autour de O (le cercle bleu) on d√©forme le cercle bleu avec la matrice de passage P (la forme noire) on applique plusieurs fois la rotation d√©form√©e par P du point B autour de A (la forme orange pointill√©) Pour calculer la rotation R dans le nouveau repere : \\(Q = P \\, R \\, P^{-1}\\)avec $P^{-1}$ permettant de revenir au repere d‚Äôorigine pour effectuer la rotationdef Rot(Œ∏): return np.array([[np.cos(Œ∏), -np.sin(Œ∏)], [np.sin(Œ∏), np.cos(Œ∏)]])def Rot3D(Œ∏): return np.array([[np.cos(Œ∏), -np.sin(Œ∏), 0], [np.sin(Œ∏), np.cos(Œ∏), 0], [0, 0, 1]])# plusieurs rotation qui donnent le cercle bleu :cercle = np.array([Rot(Œ±) @ I for Œ± in np.linspace(0, 2*np.pi, 10)]).T# le cercle exprim√© dans le nouveau rep√®re (noir)p_cercle = P @ to3D(cercle)# construction de QQ = lambda Œ∏: P @ Rot3D(Œ∏) @ lin.inv(P) # d√©finition de Q en fonction de Œ∏# on applique Q pour faire tourner B autour de A (orange)p_rot_A = np.array([Q(Œ±) @ to3D(B) for Œ± in np.linspace(0, 2*np.pi, 10)]).T " }, { "title": "CAMA : ma01 Transformations isometriques", "url": "/cours/posts/ma01-transformation-isometrique/", "categories": "S6, Shannon, CAMA", "tags": "S6, CAMA, Shannon", "date": "2020-03-30 10:00:00 +0200", "snippet": "Lien de la note HackmdCours du 30 / 03angle = np.array([Œ∏ for Œ∏ in np.linspace(-np.pi/2,np.pi/2,7)])shape1 = np.concatenate([np.array([np.cos(angle), np.sin(angle)]), np.array([[-0.5, -1, -1, -1], [1, 1, 0.5, 0]]), np.array([[-0.5, 0], [-0.5, -1]])], axis=1)[[ 0. 0.5 0.866 1. 0.866 0.5 0. -0.5 -1. -1. -1. -0.5 0. ] [-1. -0.866 -0.5 0. 0.5 0.866 1. 1. 1. 0.5 0. -0.5 -1. ]]Matrice de rotation centr√©e en $(0, 0)$ \\(R = \\begin{bmatrix}cos(Œ∏) &amp;amp; -sin(Œ∏) \\\\sin(Œ∏) &amp;amp; cos(Œ∏) \\\\\\end{bmatrix}\\)Propri√©t√©s Effectue une rotation de centre (0,0) et d‚Äôangle Œ∏ D√©terminant = 1 Matrice orthogonale $\\rightarrow$ pas de d√©formation ni d‚Äôagrandissement de la forme (automorphisme orthogonal)Œ∏ = np.pi / 4R = np.array([[np.cos(Œ∏), -np.sin(Œ∏)], [np.sin(Œ∏), np.cos(Œ∏)]])[[ 0.707 -0.707] [ 0.707 0.707]]R @ shape1 # multiplication de matrices Matrice orthogonale donc (par d√©finition) $R.R^T = \\textrm{Id}$. La transpos√©e est la rotation d‚Äôangle -Œ∏ puisque sinus est une fonction impaire.Sym√©trie axiale La sym√©trie horizontale tranformant (a,b) en (a,-b) est:\\(Sx = \\begin{bmatrix}1 &amp;amp; 0 \\\\0 &amp;amp; -1 \\\\\\end{bmatrix}\\) Pour avoir un sym√©trie axiale par rapport √† une droite passant par $(0,0)$ qui a un angle $\\alpha$ : rotation pour mettre l‚Äôaxe de sym√©trie a l‚Äôhorizontale appliquer la sym√©trie horizontale faire la rotation inverse\\(S = R_{-Œ±}^{-1}\\; Sx\\; R_{-Œ±} = R_Œ±\\;Sx\\; R_{-Œ±}\\) def RŒ±(Œ±): return np.array([[np.cos(Œ±), -np.sin(Œ±)], [np.sin(Œ±), np.cos(Œ±)]])Sx = np.array([[1, 0],[0,-1]])Œ∏ = 70 * (2 * np.pi)/360 # 70 degr√©sRŒ±(Œ∏) @ Sx @ RŒ±(-Œ∏) @ shape1La rotation selon l‚Äôangle est :RŒ±(Œ∏) @ Sx @ RŒ±(-Œ∏)[[-0.766 0.643] [ 0.643 0.766]]Translation La translation ne peut pas etre exprim√©e avec un produit matriciel car ce n‚Äôest pas une application lin√©aire :\\(T(2\\;\\textbf{x}) \\ne 2\\; T(\\textbf{x})\\)Ce n‚Äôest pas non plus une transformation isom√©trique. Une translation est une addition : $T(\\textbf{x}) = \\textbf{x} + \\textbf{v}_t$. On change la repr√©sentation des points pour exprimer les translations sous forme de produit matriciel : $\\textbf{x} = (x_1, x_2)$ devient $\\textbf{x} = (x_1, x_2, 1)$ La translation par le vecteur $(v_1, v_2)$ est : \\(T(X) = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; v_1\\\\0 &amp;amp; 1 &amp;amp; v_2 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}x_1 \\\\x_2 \\\\1 \\\\\\end{bmatrix}\\)v = np.array([1,2])T = np.identity(3) # matrice de translationT[0:2,2] = vMatrice de translation: [[1. 0. 1.] [0. 1. 2.] [0. 0. 1.]]shape1_3d = np.concatenate([shape1, np.ones((1, len(shape1[0])))], axis=0) # rajoute une nouvelle dimension √† la matrice pour la translationT @ shape1_3d La matrice inverse replacant la forme orange √† sa position d‚Äôorigine applique la transition $-\\textbf{v} = (-1,-2)$.\\(T^{-1} = \\begin{bmatrix}1 &amp;amp; 0 &amp;amp; -1\\\\0 &amp;amp; 1 &amp;amp; -2 \\\\0 &amp;amp; 0 &amp;amp; 1 \\\\\\end{bmatrix}\\)Ce n‚Äôest pas la transpos√©e de T, T n‚Äôest pas orthogonale.Il y a 2 types d‚Äôisom√©tries : l‚Äôisom√©trie vectorielle ou automorphisme orthogonal : $\\forall\\, \\textbf{x}, \\;||\\textbf{f}(\\textbf{x})|| = \\textbf{x}$ et conserve les angles l‚Äôisom√©trie geom√©trique :$\\forall\\, \\textbf{a}, \\textbf{b}, \\; ||\\textbf{f}(\\textbf{a}) - \\textbf{f}(\\textbf{b})|| = ||\\textbf{a} - \\textbf{b}||$ La translation est une isom√©trie geom√©trique mais pas vectorielle, c‚Äôest un automorphisme orthogonal." }, { "title": "SEDE : Be careful with fork", "url": "/cours/posts/sede_fork/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-03-03 11:00:00 +0100", "snippet": "" }, { "title": "SEDE : Buffer overflow and better API&#39;s", "url": "/cours/posts/sede_buffer_overflow/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-02-25 11:00:00 +0100", "snippet": "" }, { "title": "SEDE : Introduction", "url": "/cours/posts/sede_intro/", "categories": "S6, tronc commun, SEDE", "tags": "S6, SEDE, tronc commun", "date": "2020-02-11 11:00:00 +0100", "snippet": "" } ]
